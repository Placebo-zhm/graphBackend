FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Oppermann, M
   Munzner, T
AF Oppermann, Michael
   Munzner, Tamara
TI VizSnippets: Compressing Visualization Bundles Into Representative
   Previews for Browsing Visualization Collections
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Tools; Pipelines; Layout; Inspection;
   Image coding; visualization collections; visualization bundles; result
   snippets; visual inspection
AB Visualization collections, accessed by platforms such as Tableau Online or Power Bl, are used by millions of people to share and access diverse analytical knowledge in the form of interactive visualization bundles. Result snippets, compact previews of these bundles, are presented to users to help them identify relevant content when browsing collections. Our engagement with Tableau product teams and review of existing snippet designs on five platforms showed us that current practices fail to help people judge the relevance of bundles because they include only the title and one image. Users frequently need to undertake the time-consuming endeavour of opening a bundle within its visualization system to examine its many views and dashboards. In response, we contribute the first systematic approach to visualization snippet design. We propose a framework for snippet design that addresses eight key challenges that we identify. We present a computational pipeline to compress the visual and textual content of bundles into representative previews that is adaptive to a provided pixel budget and provides high information density with multiple images and carefully chosen keywords. We also reflect on the method of visual inspection through random sampling to gain confidence in model and parameter choices.
C1 [Oppermann, Michael; Munzner, Tamara] Univ British Columbia, Vancouver, BC, Canada.
C3 University of British Columbia
RP Oppermann, M (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM opperman@cs.ubc.ca; tmm@cs.ubc.ca
RI Munzner, Tamara/HKP-2536-2023
CR Al-Zaidy R. A., 2016, WORKSH 30 AAAI C ART, P658
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   [Anonymous], 2017, ARXIV170909215
   Armstrong Z, COVID 19 VIZ ROUNDUP
   Auber D., 2002, INT C COMPUTER VISIO, V1, P3
   Aula A., 2010, Proceedings of the 19th international conference on World Wide Web, WWW '10, P51
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brehmer M., 2019, IEEE T VISUALIZATION, V26, P364
   Capra R, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P399, DOI 10.1145/2505515.2505714
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chen WF, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1309, DOI 10.1145/3366423.3380206
   Chen YL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P37, DOI 10.1145/3123266.3123274
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Choi IK, 2019, IEEE INT CONF INF VI, P116, DOI 10.1109/IV-2.2019.00032
   Church K., 2006, Proceedings of the 2006 international cross-disciplinary workshop on Web accessibility (W4A): Building the mobile web: rediscovering accessibility?, P69
   Collaris D, 2020, IEEE PAC VIS SYMP, P26, DOI 10.1109/PacificVis48177.2020.7090
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DeLine R, 2006, IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P11
   Dziadosz S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P365
   EROL B., 2006, Proceedings of the 14th annual ACM international conference on Multimedia, P231
   Fachry K. N., 2010, P DUTCH BELG INF RET, P47
   Greene S, 2000, J AM SOC INFORM SCI, V51, P380, DOI 10.1002/(SICI)1097-4571(2000)51:4<380::AID-ASI7>3.0.CO;2-5
   Gygli M, 2016, PROC CVPR IEEE, P1001, DOI 10.1109/CVPR.2016.114
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hoffswell J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376777
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Kaasten S, 2002, BCS CONF SERIES, P247
   Kachkaev A, 2014, COMPUT GRAPH FORUM, V33, P311, DOI 10.1111/cgf.12387
   Kim H, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P116, DOI [10.1109/visual.2019.8933773, 10.1109/VISUAL.2019.8933773]
   KNUTH DE, 1984, COMPUT J, V27, P97, DOI 10.1093/comjnl/27.2.97
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Lam Heidi., 2005, P SIGCHI C HUMAN FAC, P681
   Li Z., 2008, Proceeding of the 17th international conference on World Wide Web, WWW '08, P21
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu ZP, 2020, IEEE T VIS COMPUT GR, V26, P2732, DOI 10.1109/TVCG.2019.2898186
   Madan S., 2018, ARXIV PREPRINT ARXIV
   Marchesi M, 2015, INT WORKS EMERG TREN, P1, DOI 10.1109/WETSoM.2015.9
   McKay Dana., 2012, Proceedings of the 24th Australian Computer-Human Interaction Conference OzCHI '12. Melbourne, Australia, P381, DOI DOI 10.1145/2414536.2414597
   Merejkowsky D., PYENCHANT SPELLCHECK
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Mittal VO, 1998, COMPUT LINGUIST, V24, P431
   Mu Y, 2018, WD SCI P COMP ENG, V11, P545
   Mühlbacher T, 2014, IEEE T VIS COMPUT GR, V20, P1643, DOI 10.1109/TVCG.2014.2346578
   Nallapati R, 2016, P 20 SIGNLL C COMPUT, DOI [10.18653/v1/K16-1028, DOI 10.18653/V1/K16-1028, 10.18653/v1/k16-1028]
   Northcutt CG, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P327, DOI 10.1145/3051457.3054016
   Oppermann M, 2021, IEEE T VIS COMPUT GR, V27, P495, DOI 10.1109/TVCG.2020.3030387
   Project Jupyter, JUPYTER NOTEBOOKS
   Renz I., 2003, KEYWORD EXTRACTION T
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Rogers J., 2020, IEEE T VISUALIZATION
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Song Y, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P659, DOI 10.1145/2983323.2983349
   Spyromitros-Xioufis E, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P323, DOI 10.1145/2671188.2749334
   Srivastava D., 2015, Int. J. Comput. Eng. Manage., V18, P9
   Stoffel A, 2012, COMPUT GRAPH FORUM, V31, P1165, DOI 10.1111/j.1467-8659.2012.03109.x
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Strobelt H, 2009, IEEE T VIS COMPUT GR, V15, P1145, DOI 10.1109/TVCG.2009.139
   Teevan J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2023
   Tintarev N, 2007, I C DATA ENGIN WORKS, P801, DOI 10.1109/ICDEW.2007.4401070
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wenskovitch J, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P1, DOI [10.1109/vds48975.2019.8973385, 10.1109/VDS48975.2019.8973385]
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wildemuth B. M., 2002, Research and Advanced Technology for Digital Libraries. 6th European Conference, ECDL 2002. Proceedings (Lecture Notes in Computer Science Vol.2458), P493
   Wildemuth BM, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102091
   Wu A., 2020, IEEE TVCG, DOI DOI 10.1109/TVCG.2020.3030423
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhang T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P228
NR 72
TC 2
Z9 2
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 747
EP 757
DI 10.1109/TVCG.2021.3114841
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000080
PM 34596545
DA 2024-11-06
ER

PT J
AU Zhao, ZE
   Xu, PP
   Scheidegger, C
   Ren, L
AF Zhao, Zhenge
   Xu, Panpan
   Scheidegger, Carlos
   Ren, Liu
TI Human-in-the-loop Extraction of Interpretable Concepts in Deep Learning
   Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data models; Analytical models; Predictive models;
   Computational modeling; Deep learning; Task analysis; Visual Data
   Exploration; Deep Neural Network; Model Interpretation; Explainable AI
AB The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-Ioop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.
C1 [Zhao, Zhenge; Scheidegger, Carlos] Univ Arizona, Tucson, AZ 85721 USA.
   [Xu, Panpan] Amazon AWS AI, Seattle, WA USA.
   [Ren, Liu] Bosch Res North Amer, Cambridge, MA USA.
C3 University of Arizona
RP Zhao, ZE (corresponding author), Univ Arizona, Tucson, AZ 85721 USA.
EM zhengezhao@email.arizona.edu; xupanpan@amazon.com;
   cscheid@cs.arizona.edu; Liu.Ren@us.bosch.com
CR [Anonymous], 2019, AAAI CONF ARTIF INTE
   Ba J., 2014, ADV NEURAL INFORM PR, P2654, DOI DOI 10.5555/2969033.2969123
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bojarski M, 2018, IEEE INT CONF ROBOT, P4701
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Cai CJ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300234
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Choi E, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Ghorbani A, 2019, ADV NEUR IN, V32
   Grinberg M., 2018, Flask Web Development: Developing Web Applications with Python
   Hardt, 2018, Advances in Neural Information Processing Systems (NeurIPS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hind M, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P123, DOI 10.1145/3306618.3314273
   Ho D., 2019, PMLR, P2731
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Holstein K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300830
   Huang G., 2017, P IEEE C COMP VIS PA, P4700, DOI [DOI 10.1109/CVPR.2017.243, 10.1109/CVPR.2017.243]
   Kim B., 2017, 35 INT C MACHINE LEA, V6, P4186
   Lake B., 2011, P ANN M COGN SCI SOC
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Papadopoulos DP, 2017, IEEE I CONF COMP VIS, pCP38, DOI 10.1109/ICCV.2017.528
   Paszke A, 2019, ADV NEUR IN, V32
   Petsiuk V., 2018, BRIT MACH VIS C BMVC
   Pinggera P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1099, DOI 10.1109/IROS.2016.7759186
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rudin, 2018, ABS180610574 ARXIV
   Seifert C, 2017, STUD BIG DATA, V32, P123, DOI 10.1007/978-3-319-54024-5_6
   Sener O., 2018, ICLR
   Settles B., 2010, Active learning literature survey, V15, P201
   Settles B., 2008, P C EMP METH NAT LAN, P1070
   Simonyan K., 2013, PREPRINT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Slack D., 2019, How can we fool lime and shap? adversarial attacks on post hoc explanation methods
   Spinner T., 2018, P WORKSH VIS AI EXPL
   Springenberg J. T., 2014, ARXIV
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Torlai G, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.240503
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang KZ, 2017, IEEE T CIRC SYST VID, V27, P2591, DOI 10.1109/TCSVT.2016.2589879
   Wu JJ, 2016, ADV NEUR IN, V29
   Yoo D, 2019, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2019.00018
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang QS, 2019, PROC CVPR IEEE, P6254, DOI 10.1109/CVPR.2019.00642
   Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 54
TC 21
Z9 21
U1 2
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 780
EP 790
DI 10.1109/TVCG.2021.3114837
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000081
PM 34587066
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Jia, SC
   Li, ZY
   Chen, N
   Zhang, JW
AF Jia, Shichao
   Li, Zeyu
   Chen, Nuo
   Zhang, Jiawan
TI Towards Visual Explainable Active Learning for Zero-Shot Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Semantics; Labeling; Training; Visual analytics; Testing; Task analysis;
   Navigation; Active Learning; Explainable Artificial Intelligence;
   Human-AI Teaming; Mixed-Initiative Visual Analytics
ID SEMANTIC INTERACTION; ANALYTICS
AB Zero-shot classification is a promising paradigm to solve an applicable problem when the training classes and test classes are disjoint. Achieving this usually needs experts to externalize their domain knowledge by manually specifying a class-attribute matrix to define which classes have which attributes. Designing a suitable class-attribute matrix is the key to the subsequent procedure, but this design process is tedious and trial-and-error with no guidance. This paper proposes a visual explainable active learning approach with its design and implementation called semantic navigator to solve the above problems. This approach promotes human-AI teaming with four actions (ask, explain, recommend, respond) in each interaction loop. The machine asks contrastive questions to guide humans in the thinking process of attributes. A novel visualization called semantic map explains the current status of the machine. Therefore analysts can better understand why the machine misclassifies objects. Moreover, the machine recommends the labels of classes for each attribute to ease the labeling burden. Finally, humans can steer the model by modifying the labels interactively, and the machine adjusts its recommendations. The visual explainable active learning approach improves humans' efficiency of building zero-shot classification models interactively, compared with the method without guidance. We justify our results with user studies using the standard benchmarks for zero-shot classification.
C1 [Jia, Shichao; Li, Zeyu; Chen, Nuo; Zhang, Jiawan] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Zhang, Jiawan] State Adm Cultural Heritage, Tianjin Cultural Heritage Conservat & Inheritance, Tianjin, Peoples R China.
   [Zhang, Jiawan] State Adm Cultural Heritage, Key Res Ctr Surface Monitoring & Anal Rel, Tianjin, Peoples R China.
C3 Tianjin University
RP Jia, SC (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
EM jsc_se@tju.edu.cn; lzytianda@tju.edu.cn; nicole_0420@tju.edu.cn;
   jwzhang@tju.edu.cn
RI Wang, Jiaqiang/HHN-9059-2022; Li, Zeyu/GXM-4336-2022
FU National Key Research and Development Program of China [2019YFC1521200]
FX This research is supported by the National Key Research and Development
   Program of China under Grant No.2019YFC1521200.
CR [Anonymous], 2012, 26 AAAI C ART INT
   Bennett KP, 1999, ADV NEUR IN, V11, P368
   Berg TL, 2010, LECT NOTES COMPUT SC, V6311, P663, DOI 10.1007/978-3-642-15549-9_48
   Bernard J, 2018, VISUAL COMPUT, V34, P1189, DOI 10.1007/s00371-018-1500-3
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Cai CJ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300234
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Changpinyo S, 2017, IEEE I CONF COMP VIS, P3496, DOI 10.1109/ICCV.2017.376
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Endert A, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.73
   Endert A, 2012, IEEE T VIS COMPUT GR, V18, P2879, DOI 10.1109/TVCG.2012.260
   Fails J. A., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P39, DOI 10.1145/604045.604056
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Felix C, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P153, DOI 10.1145/3242587.3242596
   Geng X, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2364
   Gentner D, 2003, J EDUC PSYCHOL, V95, P393, DOI 10.1037/0022-0663.95.2.393
   Ghorbani A, 2019, ADV NEUR IN, V32
   Gieseke Fabian, 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P45
   Gieseke F, 2014, NEUROCOMPUTING, V123, P23, DOI 10.1016/j.neucom.2012.12.056
   Guo YC, 2018, AAAI CONF ARTIF INTE, P6870
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hong MT, 2018, COMPANION OF THE 2018 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'18), P217, DOI 10.1145/3272973.3274059
   Jia SC, 2020, J VISUAL-JAPAN, V23, P141, DOI 10.1007/s12650-019-00607-z
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Kaur H., 2019, CHI 19
   Kim B, 2018, PR MACH LEARN RES, V80
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lamy JB, 2019, ARTIF INTELL MED, V94, P42, DOI 10.1016/j.artmed.2019.01.001
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   OSHERSON DN, 1991, COGNITIVE SCI, V15, P251, DOI 10.1207/s15516709cog1502_3
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Parikh D, 2011, PROC CVPR IEEE, P1681, DOI 10.1109/CVPR.2011.5995451
   Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Sacha D, 2018, IEEE T VIS COMPUT GR, V24, P120, DOI 10.1109/TVCG.2017.2744805
   Sahoo S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P251, DOI 10.1109/VIS47514.2020.00057
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Seifert C., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P418, DOI 10.1109/ICDMW.2010.181
   Settles B., 2009, TECHNICAL REPORTS
   Simard Patrice Y., 2017, ARXIV
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sun YJ, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P523, DOI 10.1145/3025171.3025208
   Tian T, 2017, AAAI CONF ARTIF INTE, P1562
   van der Maaten L., 2009, J MACH LEARN RES, P384
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yu FLX, 2013, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2013.105
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang R., 2021, P ACM HUMAN COMPUTER, V4, P1
NR 76
TC 17
Z9 18
U1 4
U2 38
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 791
EP 801
DI 10.1109/TVCG.2021.3114793
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000082
PM 34587036
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, XB
   He, JB
   Jin, ZH
   Yang, MQ
   Wang, Y
   Qu, HM
AF Wang, Xingbo
   He, Jianben
   Jin, Zhihua
   Yang, Muqiao
   Wang, Yong
   Qu, Huamin
TI M2Lens: Visualizing and Explaining Multimodal Models for Sentiment
   Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Analytical models; Sentiment analysis; Computational modeling;
   Predictive models; Data models; Lenses; Communication channels;
   Multimodal models; sentiment analysis; explainable machine learning
ID RECOGNITION
AB Multimodal sentiment analysis aims to recognize people's attitudes from multiple communication channels such as verbal content (i.e., text), voice, and facial expressions. It has become a vibrant and important research topic in natural language processing. Much research focuses on modeling the complex intra- and inter-modal interactions between different communication channels. However, current multimodal models with strong performance are often deep-learning-based techniques and work like black boxes. It is not clear how models utilize multimodal information for sentiment predictions. Despite recent advances in techniques for enhancing the explainability of machine learning models, they often target unimodal scenarios (e.g., images, sentences), and little research has been done on explaining multimodal models. In this paper, we present an interactive visual analytics system, M2 Lens, to visualize and explain multimodal models for sentiment analysis. M2 Lens provides explanations on intra- and inter-modal interactions at the global, subset, and local levels. Specifically, it summarizes the influence of three typical interaction types (i.e., dominance, complement, and conflict) on the model predictions. Moreover, M2 Lens identifies frequent and influential multimodal features and supports the multi-faceted exploration of model behaviors from language, acoustic, and visual modalities. Through two case studies and expert interviews, we demonstrate our system can help users gain deep insights into the multimodal models for sentiment analysis.
C1 [Wang, Xingbo; He, Jianben; Jin, Zhihua; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Yang, Muqiao] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Wang, Yong] Singapore Management Univ, Singapore, Singapore.
C3 Hong Kong University of Science & Technology; Carnegie Mellon
   University; Singapore Management University
RP Wang, Y (corresponding author), Singapore Management Univ, Singapore, Singapore.
EM xingbo.wang@ust.hk; jhebt@ust.hk; zjinak@ust.hk; muqiaoy@andrew.cmu.edu;
   yongwang@smu.edu.sg; huamin@ust.hk
RI Yang, Muqiao/GRX-7251-2022; Wang, Xingbo/JHS-6567-2023; Wang,
   Yong/HKF-3903-2023
OI Wang, Xingbo/0000-0001-5693-1128
FU Foshan-HKUST Projects [FSNH20EGO1]
FX The authors wish to thank anonymous reviewers for their feedback. This
   research was supported in part by grant FSNH20EGO1 under Foshan-HKUST
   Projects.
CR Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bastani C. Kim, 2017, ARXIV170609773
   Brooks M, 2015, IEEE CONF VIS ANAL, P105, DOI 10.1109/VAST.2015.7347637
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832
   Chen F, 2017, PHYS CHEM CHEM PHYS, V19, P10163, DOI 10.1039/c6cp08232g
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Degottex G, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853739
   Ekman P, 1978, Manual of the Facial Action Coding System (FACS)
   Ekman R., 1997, What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)
   Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P111
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Haasdonk B, 2005, IEEE T PATTERN ANAL, V27, P482, DOI 10.1109/TPAMI.2005.78
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Henelius A, 2014, DATA MIN KNOWL DISC, V28, P1503, DOI 10.1007/s10618-014-0368-8
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hu A, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P350, DOI 10.1145/3219819.3219853
   Johansson U., 2004, Seventh International Conference on Information Fusion, P295
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Karpathy A, 2015, CORR
   Koh PW, 2017, PR MACH LEARN RES, V70
   Konig Rikard, 2008, 2008 IEEE International Conference on Data Mining Workshops, P971, DOI 10.1109/ICDMW.2008.117
   Krakovna V., 2016, INCREASING INTERPRET
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krause J, 2016, IEEE T VIS COMPUT GR, V22, P91, DOI 10.1109/TVCG.2015.2467622
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Kulesza Todd, 2015, P 20 INT C INT US IN, P126, DOI [DOI 10.1145/2678025.2701399, 10.1145/2678025.2701399]
   Lazaridou A, 2015, P 2015 C N AM CHAPT, P153, DOI DOI 10.3115/V1/N15-1016
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Longo Luca, 2020, Machine Learning and Knowledge Extraction. 4th IFIP TC 5, TC 12, WG 8.4, WG 8.9, WG 12.9. International Cross-Domain Conference, CD-MAKE 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12279), P1, DOI 10.1007/978-3-030-57321-8_1
   Lundberg SM, 2017, ADV NEUR IN, V30
   Molnar C., 2019, Interpretable machine learning, P1
   Morency R., 2011, P 13 INT C MULT INT, P169, DOI DOI 10.1145/2070481.2070509
   Ngiam A., 2011, IEEE INT C MACH LEAR, P689
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   Patel K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P667
   Pennington J, 2014, PROCEEDING 2014 C EM, P1532, DOI DOI 10.3115/V1/D14-1162
   Pham H, 2019, AAAI CONF ARTIF INTE, P6892
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rahman W, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2359, DOI 10.18653/v1/2020.acl-main.214
   Rajagopalan SS, 2016, LECT NOTES COMPUT SC, V9911, P338, DOI 10.1007/978-3-319-46478-7_21
   Ramirez GA, 2011, LECT NOTES COMPUT SC, V6975, P396, DOI 10.1007/978-3-642-24571-8_51
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro M. T., 2020, P 58 ANN M ASS COMP, P4902
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Robnik-Sikonja M, 2008, IEEE T KNOWL DATA EN, V20, P589, DOI 10.1109/TKDE.2007.190734
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Rubin S., 2013, P 26 ANN ACM S US IN, P113
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Shapley L.S., 1953, Contributions to the Theory of Games, P307, DOI DOI 10.7249/P0295
   Smilkov D., 2017, arXiv:1708.03788
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Springenberg J., 2015, ARXIV
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Tolomei G, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P465, DOI 10.1145/3097983.3098039
   Tsai YHH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1823, DOI 10.18653/v1/2020.emnlp-main.143
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301
   Wang X., 2020, P 2020 CHI C HUMAN F, P1
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   Zadeh A, 2017, P 2017 C EMP METH NA, P1103, DOI [10.18653/v1/d17-1115, DOI 10.18653/V1/D17-1115]
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
   Zadeh Amir, 2018, Proc AAAI Conf Artif Intell, V2018, P5642
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 83
TC 42
Z9 45
U1 8
U2 73
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 802
EP 812
DI 10.1109/TVCG.2021.3114794
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000083
PM 34587037
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Park, H
   Das, N
   Duggal, R
   Wright, AP
   Shaikh, O
   Hohman, F
   Chau, DH
AF Park, Haekyu
   Das, Nilaksh
   Duggal, Rahul
   Wright, Austin P.
   Shaikh, Omar
   Hohman, Fred
   Chau, Duen Horng (Polo)
TI NeuroCartography: Scalable Automatic Visual Summarization of Concepts in
   Deep Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neurons; Dogs; Feature extraction; Visualization; Faces; Deep learning;
   Semantics; Deep learning interpretability; visual analytics; scalable
   summarization; neuron clustering; neuron embedding
ID OBJECT DETECTION
AB Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present Neurocartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. Neurocartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting "dog faces" of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting "dog face" and "dog tail" are placed closer in the embedding space). Key to our scalable techniques is the ability to efficiently compute all neuron pairs' relationships, in time linear to the number of neurons instead of quadratic time. Neurocartography scales to large data, such as the ImageNet dataset with 1.2M images. The system's tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The Neurocartography visualization runs in modern browsers and is open-sourced.
C1 [Park, Haekyu; Das, Nilaksh; Duggal, Rahul; Wright, Austin P.; Shaikh, Omar; Hohman, Fred; Chau, Duen Horng (Polo)] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Hohman, Fred] Apple, Cupertino, CA USA.
C3 University System of Georgia; Georgia Institute of Technology; Apple Inc
RP Park, H (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM haekyu@gatech.edu; nilakshdas@gatech.edu; rahulduggal@gatech.edu;
   apwright@gatech.edu; oshaikh@gatech.edu; fredhohman@gatech.edu;
   polo@gatech.edu
RI Das, Nilaksh/AHC-3955-2022
FU DARPA [HR00112030001]; NSF [IIS-1563816, CNS-1704701]
FX We thank Hannah Kim, the Georgia Tech Visualization Lab, and the
   anonymous reviewers for their support and constructive feedback. This
   work was supported in part by DARPA (HR00112030001), NSF grants
   IIS-1563816, CNS-1704701, and gifts from Intel, NVIDIA, Google.
CR [Anonymous], 2016, Advances in Neural Information Processing Systems
   [Anonymous], 2016, WORKSH VIS DEEP LEAR
   Bau D, 2020, P NATL ACAD SCI USA, V117, P30071, DOI 10.1073/pnas.1907375117
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Cammarata N., 2021, Distill, V6
   Carter S., 2019, DISTILL, V4, DOI DOI 10.23915/DISTILL.00015
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169
   Chang J., 2009, Advances in Neural Information Processing Systems, P288
   Chum O., 2008, BMVC, V810, P812, DOI [10.5244/C.22.50, DOI 10.5244/C.22.50]
   Das Abhinandan S, 2007, Proceedings of the 16th international conference on World Wide Web, P271, DOI DOI 10.1145/1242572.1242610
   Das Nilaksh, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382977
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2013, INT CONF ACOUST SPEE, P8599, DOI 10.1109/ICASSP.2013.6639344
   Duggal R, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1704, DOI 10.1145/3366423.3380241
   Duggal Rahul, 2019, ARXIV191108630
   Fong R, 2018, PROC CVPR IEEE, P8730, DOI 10.1109/CVPR.2018.00910
   Ghorbani A, 2019, ADV NEUR IN, V32
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hu Xin, 2013, 2013 USENIX ANN TECH
   Jaderberg M., 2014, ARXIV14053866, DOI DOI 10.5244/C.28.88
   Karpathy A., T SNE VISUALIZATION
   Kawaguchi K., 2017, ARXIV171005468
   Kim B, 2018, PR MACH LEARN RES, V80
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Long Jonathan., 2014, NIPS
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Mikolov Tomas, 2013, INT C LEARNING REPRE
   Mordvintsev A., 2015, INCEPTIONISM GOING D
   Neyshabur B, 2017, ADV NEUR IN, V30
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   Olah C, 2020, OVERVIEW EARLY VISIO
   Olah C., 2018, Distill, V3, P10, DOI [DOI 10.23915/DISTILL.00010, 10.23915/ distill.00010]
   Olah C., 2020, Distill, DOI [DOI 10.23915/DISTILL.00024.001, 10.2 3915/distill.00024.001]
   Rajaraman A., 2011, MINING MASSIVE DATAS
   Rajkomar A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0029-1
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Simonyan K., 2013, PREPRINT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg J. T., 2014, ARXIV
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tamersoy A, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1524, DOI 10.1145/2623330.2623342
   Wen W, 2016, ADV NEUR IN, V29
   Wright A.P., 2020, A comparative analysis of industry human-ai interaction guidelines
   Yin Z, 2018, ADV NEUR IN, V31
   Yosinski J, 2015, CoRR
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 58
TC 8
Z9 10
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 813
EP 823
DI 10.1109/TVCG.2021.3114858
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000084
PM 34587079
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Tang, T
   Wu, YH
   Yu, LY
   Li, YH
   Wu, YC
AF Tang, Tan
   Wu, Yanhong
   Yu, Lingyun
   Li, Yuhong
   Wu, Yingcai
TI VideoModerator: A Risk-aware Framework for Multimodal Video Moderation
   in E-Commerce
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Visual analytics; Machine learning; Motion
   pictures; Feature extraction; Data mining; video moderation; video
   visualization; e-commerce livestreaming
ID VIOLENCE DETECTION; VISUAL ANALYTICS; VISUALIZATION; NETWORKS
AB Video moderation, which refers to remove deviant or explicit content from e-commerce livestreams, has become prevalent owing to social and engaging features. However, this task is tedious and time consuming due to the difficulties associated with watching and reviewing multimodal video content, including video frames and audio clips. To ensure effective video moderation, we propose VideoModerator, a risk-aware framework that seamlessly integrates human knowledge with machine insights. This framework incorporates a set of advanced machine learning models to extract the risk-aware features from multimodal video content and discover potentially deviant videos. Moreover, this framework introduces an interactive visualization interface with three views, namely, a video view, a frame view, and an audio view. In the video view, we adopt a segmented timeline and highlight high-risk periods that may contain deviant information. In the frame view, we present a novel visual summarization method that combines risk-aware features and video context to enable quick video navigation. In the audio view, we employ a storyline-based design to provide a multi-faceted overview which can be used to explore audio content. Furthermore, we report the usage of VideoModerator through a case scenario and conduct experiments and a controlled user study to validate its effectiveness.
C1 [Tang, Tan; Wu, Yanhong; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Tang, Tan; Wu, Yanhong; Wu, Yingcai] Zhejiang Lab, Hangzhou, Peoples R China.
   [Yu, Lingyun] Xian Jiaotong Liverpool Univ, Dept Comp, Xian, Peoples R China.
   [Li, Yuhong] Alibaba Grp, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory; Xi'an Jiaotong-Liverpool
   University; Alibaba Group
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.; Wu, YC (corresponding author), Zhejiang Lab, Hangzhou, Peoples R China.
EM tangtan@zju.edu.cn; yanhongwu@zju.edu.cn; Lingyun.Yu@xjtlu.edu.cn;
   daniel.lyh@alibaba-inc.com; ycwu@zju.edu.cn
RI Li, Jun-Yan/IXD-8294-2023; Tang, Tan/JJD-3333-2023; wang,
   yixuan/JGM-3893-2023
OI Wu, Yanhong/0009-0008-8762-5041
FU NSFC [62072400]; Zhejiang Provincial Natural Science Foundation
   [LR18F020001]; Alibaba-Zhejiang University Joint Institute of Frontier
   Technologies; Collaborative Innovation Center of Artificial Intelligence
   by MOE; Zhejiang Provincial Government (ZJU)
FX The work was supported by NSFC (62072400) and Zhejiang Provincial
   Natural Science Foundation (LR18F020001). This work was also supported
   by Alibaba-Zhejiang University Joint Institute of Frontier Technologies
   and the Collaborative Innovation Center of Artificial Intelligence by
   MOE and Zhejiang Provincial Government (ZJU).
CR Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   [Anonymous], 2006, 2006 IEEE COMPUTER S, DOI DOI 10.1109/CVPR.2006.284
   [Anonymous], 2020, INTRO YOUTUBE POLICI
   [Anonymous], 2012, P SIGCHI C HUM FACT, DOI [10.1145/2207676.22077672, DOI 10.1145/2207676.22077672, DOI 10.1145/2207676.2207767]
   [Anonymous], 2016, INTERSECTIONAL INTER
   [Anonymous], 2020, CONTENT MODERATION S
   [Anonymous], 2020, VIDEO MODERATION REV
   [Anonymous], 2020, VIOLENT THREATS POLI
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Borgo R, 2012, COMPUT GRAPH FORUM, V31, P2450, DOI 10.1111/j.1467-8659.2012.03158.x
   Botchen RP, 2008, IEEE T VIS COMPUT GR, V14, P885, DOI 10.1109/TVCG.2008.40
   Cai J, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2548
   Chancellor S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3213, DOI 10.1145/3025453.3025985
   Chen M, 2006, IEEE T VIS COMPUT GR, V12, P1093, DOI 10.1109/TVCG.2006.194
   Chen Z., IEEE T VIS COMPUT GR, P2022
   Chinchor NA, 2010, IEEE COMPUT GRAPH, V30, P52, DOI 10.1109/MCG.2010.92
   Chollet F., 2018, MANNING
   Cox M. A., 2008, Handbook of data visualization, P315, DOI DOI 10.1007/978-3-540-33037-014
   Daniel G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P409, DOI 10.1109/VISUAL.2003.1250401
   Deng D., 2021, P CHI, P1
   Duffy B, 2015, IEEE T VIS COMPUT GR, V21, P980, DOI 10.1109/TVCG.2013.265
   Filipov V, 2021, VIS INFORM, V5, P45, DOI 10.1016/j.visinf.2021.01.001
   Giannakopoulos T, 2010, LECT NOTES ARTIF INT, V6040, P91, DOI 10.1007/978-3-642-12842-4_13
   Gillespie T., 2018, CUSTODIANS INTERNET, DOI [10.12987/9780300235029, DOI 10.12987/9780300235029]
   Guo H, 2022, J VISUAL-JAPAN, V25, P159, DOI 10.1007/s12650-021-00783-x
   Gupta D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC), P1, DOI 10.1109/ICCC.2018.00008
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Hanson A, 2019, LECT NOTES COMPUT SC, V11130, P280, DOI 10.1007/978-3-030-11012-3_24
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [10.1109/CVPRW.2012.6239348, DOI 10.1109/CVPRW.2012.6239348]
   Haubold A., 2005, 13th Annual ACM International Conference on Multimedia, P51, DOI 10.1145/1101149.1101158
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Höferlin B, 2015, INFORM VISUAL, V14, P10, DOI 10.1177/1473871613488571
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Höferlin M, 2013, IEEE T MULTIMEDIA, V15, P908, DOI 10.1109/TMM.2013.2238521
   Jäckle D, 2016, IEEE T VIS COMPUT GR, V22, P141, DOI 10.1109/TVCG.2015.2467553
   Jamonnak S, 2022, IEEE T VIS COMPUT GR, V28, P1019, DOI 10.1109/TVCG.2021.3114853
   Jhaver S, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3185593
   John M, 2019, IEEE INT CON INF VIS, P241, DOI 10.1109/IV.2019.00048
   Kiesler S, 2011, BUILDING SUCCESSFUL ONLINE COMMUNITIES: EVIDENCE-BASED SOCIAL DESIGN, P125
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Lampe C., 2004, P C HUM FACT COMP SY, P543, DOI DOI 10.1145/985692.985761
   Lan J, 2022, J VISUAL-JAPAN, V25, P143, DOI 10.1007/s12650-021-00772-0
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moritz N, 2020, INT CONF ACOUST SPEE, P6074, DOI [10.1109/icassp40776.2020.9054476, 10.1109/ICASSP40776.2020.9054476]
   Peixoto B, 2019, INT CONF ACOUST SPEE, P8276, DOI 10.1109/ICASSP.2019.8682833
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Renoust B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1235, DOI 10.1145/3123266.3127917
   Romero M, 2008, IEEE T VIS COMPUT GR, V14, P1261, DOI 10.1109/TVCG.2008.185
   Singh A, 2018, IEEE COMPUT SOC CONF, P1710, DOI 10.1109/CVPRW.2018.00214
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sun Y, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100886
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JC, 2022, J VISUAL-JAPAN, V25, P59, DOI 10.1007/s12650-021-00778-8
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wu A, 2021, IEEE Transactions on Visualization and Computer Graphics
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu P., 2020, COMPUTER VISION ECCV, P322
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zahálka J, 2014, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2014.7042476
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
NR 78
TC 12
Z9 14
U1 5
U2 33
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 846
EP 856
DI 10.1109/TVCG.2021.3114781
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000087
PM 34587029
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Tang, JX
   Zhou, YH
   Tang, T
   Weng, D
   Xie, BY
   Yu, LY
   Zhang, HQ
   Wu, YC
AF Tang, Junxiu
   Zhou, Yuhua
   Tang, Tan
   Weng, Di
   Xie, Boyang
   Yu, Lingyun
   Zhang, Huaqiang
   Wu, Yingcai
TI A Visualization Approach for Monitoring Order Processing in E-Commerce
   Warehouse
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Monitoring; Real-time systems; Schedules; Delays;
   Warehousing; Visual analytics; Streaming data; time-series data;
   e-commerce warehouse; order processing
ID ANOMALY DETECTION; VISUAL ANALYTICS; PICKING; ALGORITHMS; DESIGN;
   SYSTEM; MODEL
AB The efficiency of warehouses is vital to e-commerce. Fast order processing at the warehouses ensures timely deliveries and improves customer satisfaction. However, monitoring, analyzing, and manipulating order processing in the warehouses in real time are challenging for traditional methods due to the sheer volume of incoming orders, the fuzzy definition of delayed order patterns, and the complex decision-making of order handling priorities. In this paper, we adopt a data-driven approach and propose OrderMonitor, a visual analytics system that assists warehouse managers in analyzing and improving order processing efficiency in real time based on streaming warehouse event data. Specifically, the order processing pipeline is visualized with a novel pipeline design based on the sedimentation metaphor to facilitate real-time order monitoring and suggest potentially abnormal orders. We also design a novel visualization that depicts order timelines based on the Gantt charts and Marey's graphs. Such a visualization helps the managers gain insights into the performance of order processing and find major blockers for delayed orders. Furthermore, an evaluating view is provided to assist users in inspecting order details and assigning priorities to improve the processing performance. The effectiveness of OrderMonitor is evaluated with two case studies on a real-world warehouse dataset.
C1 [Tang, Junxiu; Zhou, Yuhua; Tang, Tan; Weng, Di; Xie, Boyang; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Yu, Lingyun] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
   [Zhang, Huaqiang] Alibaba Grp, Hangzhou, Peoples R China.
C3 Zhejiang University; Xi'an Jiaotong-Liverpool University; Alibaba Group
RP Tang, JX (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM tangjunxiu@zju.edu.cn; zhouyuhua@zju.edu.cn; tangtan@zju.edu.cn;
   dweng@zju.edu.cn; xboyang@zju.edu.cn; lingyun.yu@xjdu.edu.cn;
   huaqiang.zhq@cainiao.com; ycwu@zju.edu.cn
RI Tang, Tan/JJD-3333-2023; Weng, Di/ABG-7408-2020; Xie,
   Boyang/R-5819-2018; wang, yixuan/JGM-3893-2023
OI Tang, Junxiu/0000-0003-3594-926X; Weng, Di/0000-0003-2712-7274
FU NSFC [62072400]; Zhejiang Provincial Natural Science Foundation
   [LR18F020001]; Alibaba-Zhejiang University Joint Institute of Frontier
   Technologies; Collaborative Innovation Center of Artificial Intelligence
   by MOE; Zhejiang Provincial Government (ZJU)
FX This work was supported by NSFC (62072400) and Zhejiang Provincial
   Natural Science Foundation (LR18F020001). This work was also supported
   by Alibaba-Zhejiang University Joint Institute of Frontier Technologies
   and the Collaborative Innovation Center of Artificial Intelligence by
   MOE and Zhejiang Provincial Government (ZJU).
CR A. of Amazon, 2020, AM FULF CTR VID TOUR
   Aigner W, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P457, DOI 10.1109/IV.2005.97
   Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   [Anonymous], 2017, T EC
   Bai ZH, 2020, J VISUAL-JAPAN, V23, P745, DOI 10.1007/s12650-020-00654-x
   Bartholdi J.J., 2008, WAREHOUSE DISTRIBUTI
   Bódis T, 2018, EXPERT SYST APPL, V105, P196, DOI 10.1016/j.eswa.2018.03.043
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boysen N, 2019, EURO J TRANSP LOGIST, V8, P169, DOI 10.1007/s13676-018-0116-0
   Boysen N, 2019, EUR J OPER RES, V277, P396, DOI 10.1016/j.ejor.2018.08.023
   Cao N, 2018, IEEE T VIS COMPUT GR, V24, P23, DOI 10.1109/TVCG.2017.2744419
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Carenini G., 2004, P WORK C ADV VIS INT, P150
   Chen FY, 2013, COMPUT IND ENG, V66, P77, DOI 10.1016/j.cie.2013.06.013
   Dasgupta A, 2018, COMPUT GRAPH FORUM, V37, P254, DOI 10.1111/cgf.13264
   Erbacher RF, 2012, IEEE SYM VIS CYB SEC, P17
   Fischer F., 2014, Proc. Int. Symp. on Vis. for Cyber Security (VizSec), P65, DOI DOI 10.1145/2671491.2671495
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Gu JX, 2007, EUR J OPER RES, V177, P1, DOI 10.1016/j.ejor.2006.02.025
   Gu JX, 2010, EUR J OPER RES, V203, P539, DOI 10.1016/j.ejor.2009.07.031
   Guo Y., 2021, IEEE T VIS COMPUT GR
   Henn S, 2012, COMPUT OPER RES, V39, P2549, DOI 10.1016/j.cor.2011.12.019
   Huron S, 2013, IEEE T VIS COMPUT GR, V19, P2446, DOI 10.1109/TVCG.2013.227
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Kucher K, 2020, J VISUAL-JAPAN, V23, P1015, DOI 10.1007/s12650-020-00684-5
   Kwon BC, 2021, IEEE T VIS COMPUT GR, V27, P3685, DOI 10.1109/TVCG.2020.2985689
   Leung KH, 2018, EXPERT SYST APPL, V91, P386, DOI 10.1016/j.eswa.2017.09.026
   Lim MK, 2013, INT J PROD ECON, V145, P409, DOI 10.1016/j.ijpe.2013.05.006
   Linhares C. D. G., J VISUAL-JAPAN, V2021
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Mansoor H, 2021, VIS INFORM, V5, P39, DOI 10.1016/j.visinf.2021.07.001
   Matkovic K, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P67, DOI 10.1109/INFVIS.2002.1173149
   Matusiak M, 2014, EUR J OPER RES, V236, P968, DOI 10.1016/j.ejor.2013.06.001
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Palomo C, 2016, IEEE T VIS COMPUT GR, V22, P170, DOI 10.1109/TVCG.2015.2467592
   Pedrielli G, 2016, WINT SIMUL C PROC, P2250, DOI 10.1109/WSC.2016.7822266
   Plaisant Catherine, 2003, The craft of information visualization, P308, DOI DOI 10.1016/B978-155860915-0/50038-X
   RATLIFF HD, 1983, OPER RES, V31, P507, DOI 10.1287/opre.31.3.507
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Staff A., 2018, CAIN GEARS 11 11 SHO
   Steiger M, 2014, COMPUT GRAPH FORUM, V33, P401, DOI 10.1111/cgf.12396
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Tanahashi Y, 2015, IEEE T VIS COMPUT GR, V21, P730, DOI 10.1109/TVCG.2015.2392771
   Tang T., IEEE T VIS COMPUT GR
   Tominski C, 2021, VIS INFORM, V5, P28, DOI 10.1016/j.visinf.2021.06.004
   Tufte E., 1986, VISUAL DISPLAY QUANT
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang Y., 2021, IEEE T VIS COMPUT GR
   Wei DT, 2021, J VISUAL-JAPAN, V24, P597, DOI 10.1007/s12650-020-00717-z
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wu A, 2021, IEEE Transactions on Visualization and Computer Graphics
   Wu WC, 2018, IEEE PAC VIS SYMP, P140, DOI 10.1109/PacificVis.2018.00026
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Wu YC, 2018, IEEE T VIS COMPUT GR, V24, P2758, DOI 10.1109/TVCG.2017.2764459
   Xia M, 2021, IEEE T VIS COMPUT GR, V27, P870, DOI 10.1109/TVCG.2020.3030337
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Xu K, 2020, IEEE T VIS COMPUT GR, V26, P1107, DOI 10.1109/TVCG.2019.2934613
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zhang TY, 2021, J VISUAL-JAPAN, V24, P1051, DOI 10.1007/s12650-020-00741-z
   Zhao Z, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P158, DOI 10.1109/IEA.2017.7939198
   Zhou FF, 2018, J VISUAL LANG COMPUT, V44, P58, DOI 10.1016/j.jvlc.2017.11.004
NR 67
TC 9
Z9 10
U1 5
U2 39
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 857
EP 867
DI 10.1109/TVCG.2021.3114878
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000088
PM 34596553
DA 2024-11-06
ER

PT J
AU Tovanich, N
   Soulie, N
   Heulot, N
   Isenberg, P
AF Tovanich, Natkamon
   Soulie, Nicolas
   Heulot, Nicolas
   Isenberg, Petra
TI MiningVis: Visual Analytics of the Bitcoin Mining Economy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bitcoin; Tools; Economics; Data mining; Visual analytics; Hardware;
   Security; Visual analytics; Bitcoin; Bitcoin mining; mining pools; pool
   hopping
ID ENERGY
AB We present a visual analytics tool, MiningVis, to explore the long-term historical evolution and dynamics of the Bitcoin mining ecosystem. Bitcoin is a cryptocurrency that attracts much attention but remains difficult to understand. Particularly important to the success, stability, and security of Bitcoin is a component of the system called "mining." Miners are responsible for validating transactions and are incentivized to participate by the promise of a monetary reward. Mining pools have emerged as collectives of miners that ensure a more stable and predictable income. MiningVis aims to help analysts understand the evolution and dynamics of the Bitcoin mining ecosystem, including mining market statistics, multi-measure mining pool rankings, and pool hopping behavior. Each of these features can be compared to external data concerning pool characteristics and Bitcoin news. In order to assess the value of MiningVis, we conducted online interviews and insight-based user studies with Bitcoin miners. We describe research questions tackled and insights made by our participants and illustrate practical implications for visual analytics systems for Bitcoin mining.
C1 [Tovanich, Natkamon; Heulot, Nicolas] Paris Saclay, IRT SystemX, F-91120 Palaiseau, France.
   [Tovanich, Natkamon; Isenberg, Petra] Univ Paris Saclay, LISN, INRIA, CNRS, F-91405 Orsay, France.
   [Soulie, Nicolas] Univ Paris Saclay, Univ Evry, IMT BS, LITEM, F-91025 Evry, France.
C3 Universite Paris Saclay; Universite Paris Cite; Inria; Microsoft; Centre
   National de la Recherche Scientifique (CNRS); Universite Paris Saclay;
   Universite Paris Saclay; Universite Paris Cite; IMT - Institut
   Mines-Telecom; Institut Mines-Telecom Business School
RP Tovanich, N (corresponding author), Paris Saclay, IRT SystemX, F-91120 Palaiseau, France.
EM natkamon.tovanich@irt-systemx.fr; nicolas.soulie@imt-bs.eu;
   nicolas.heulot@irt-systemx.fr; petra.isenberg@inria.fr
RI Tovanich, Natkamon/IUM-4274-2023
OI Soulie, Nicolas/0000-0002-5045-3054; Tovanich,
   Natkamon/0000-0001-9680-9282
FU French Program Investissements d'Avenir
FX The authors wish to thank all participants in the user study, Catherine
   Plaisant for valuable feedback to improve our work and Teppakorn
   Thanuthanad for technical advice on developing the tool. This research
   work has been carried out under the leadership of the Institute for
   Technological Research SystemX, and therefore granted with public funds
   within the scope of the French Program Investissements d'Avenir.
CR [Anonymous], 1948, AM STAT
   Antonopoulos A. M., 2017, Mastering Bitcoin: Programming the Open Blockchain, V2nd
   Badea L, 2021, IEEE ACCESS, V9, P48091, DOI 10.1109/ACCESS.2021.3068636
   Belouch M, 2018, PROCEDIA COMPUT SCI, V127, P1, DOI 10.1016/j.procs.2018.01.091
   Bevand M., 2021, CAMBRIDGE BITCOIN EL
   Bitcoin Wiki, COMP MIN POOLS
   Bitcoin Wiki contributors, 2020, COMP MIN POOLS
   Bitcointalk contributors, BITC PRESS DISC FOR
   Bitcointalk contributors, BITC MIN POOLS DISC
   Block JE, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P38, DOI 10.1109/BELIV51497.2020.00012
   Blockchain.info, 2020, BLOCKCH CHARTS
   Böhme R, 2015, J ECON PERSPECT, V29, P213, DOI 10.1257/jep.29.2.213
   Bonneau J, 2015, P IEEE S SECUR PRIV, P104, DOI 10.1109/SP.2015.14
   Bradbury D, 2013, COMPUT FRAUD SECUR, P5
   Brinton WC., 1919, The Engineering Magazine Company
   BTC.com, 2020, POOL DISTR
   Fairchild S., 2014, NEW VISIONS PUBLIC S
   Few Stephen, 2008, VISUAL BUSINESS INTE
   Foteinis S, 2018, NATURE, V554, P169, DOI 10.1038/d41586-018-01625-x
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Giungato P, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9122214
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Houy N., 2014, WORKING PAPERS, V1407, DOI [10.2139/ssrn.2400519, DOI 10.2139/SSRN.2400519]
   Huron S, 2013, IEEE T VIS COMPUT GR, V19, P2446, DOI 10.1109/TVCG.2013.227
   International Monetary Fund, 2021, PRIM COMM PRIC SYST
   Isenberg P, 2011, IEEE T VIS COMPUT GR, V17, P2469, DOI 10.1109/TVCG.2011.160
   Jiang SR, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22256-3
   Jordan P.W., 1996, Usability Evaluation in Industry
   Kinkeldey C., IEEE COMPUT GRAPH, V2021, DOI [10.1109/MCG.20213070303, DOI 10.1109/MCG.20213070303]
   Köhler S, 2019, ENVIRON SCI TECHNOL, V53, P13598, DOI 10.1021/acs.est.9b05687
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Küfeoglu S, 2019, ENERGY RES SOC SCI, V58, DOI 10.1016/j.erss.2019.101273
   Liu XJ, 2018, IEEE WIREL COMMUN LE, V7, P760, DOI 10.1109/LWC.2018.2820009
   Liu XT, 2016, IEEE CONF VIS ANAL, P71, DOI 10.1109/VAST.2016.7883513
   Liu Z., 2019, ARXIV190210865
   Masanet E, 2019, NAT CLIM CHANGE, V9, P653, DOI 10.1038/s41558-019-0535-4
   Möser M, 2015, LECT NOTES COMPUT SC, V8976, P19, DOI 10.1007/978-3-662-48051-9_2
   Mora C, 2018, NAT CLIM CHANGE, V8, P932, DOI 10.1038/s41558-018-0321-8
   Nakamoto S., 2008, Bitcoin: A peer-to-peer electronic cash system
   Nguyen CT, 2019, IEEE ACCESS, V7, P85727, DOI 10.1109/ACCESS.2019.2925010
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Parino F, 2018, EPJ DATA SCI, V7, DOI 10.1140/epjds/s13688-018-0170-8
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Rendgen S., 2018, The Minard System: The Complete Statistical Graphics of Charles-Joseph Minard
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Romiti M., 2019, WORKSH EC INF SEC WE
   Rosenfeld M., 2011, ANAL BITCOIN POOLED
   Rosvall M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008694
   Salimitari M, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P267, DOI 10.1109/CIC.2017.00043
   Sauro Jeff, 2011, A practical guide to the system usability scale: Background, benchmarks & best practices
   Schmid C., 1992, Statistical graphics: design principles and practices
   Schmidt M, 2008, J IND ECOL, V12, P173, DOI 10.1111/j.1530-9290.2008.00015.x
   Shi CL, 2012, IEEE T VIS COMPUT GR, V18, P2669, DOI 10.1109/TVCG.2012.253
   Stoll C, 2019, JOULE, V3, P1647, DOI 10.1016/j.joule.2019.05.012
   Sun YJ, 2019, 2019 CRYPTO VALLEY CONFERENCE ON BLOCKCHAIN TECHNOLOGY (CVCBT 2019), P21, DOI 10.1109/CVCBT.2019.000-3
   Tovanich N., 2020, **DATA OBJECT**, DOI 10.5281/zenodo.4671055
   Tovanich N., 2021, 2021 11 IFIP INT C N, P1, DOI DOI 10.1109/NTMS49979.2021.9432675
   Tovanich N., IEEE INT C BLOCKCH C, P2021
   Tovanich N, 2021, IEEE T VIS COMPUT GR, V27, P3135, DOI 10.1109/TVCG.2019.2963018
   Truby J, 2018, ENERGY RES SOC SCI, V44, P399, DOI 10.1016/j.erss.2018.06.009
   Vranken H, 2017, CURR OPIN ENV SUST, V28, P1, DOI 10.1016/j.cosust.2017.04.011
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang CH, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING AND COMMUNICATIONS (BIGCOM 2020), P180, DOI 10.1109/BigCom51056.2020.00032
   Wang LQ, 2015, LECT NOTES COMPUT SC, V8995, P290, DOI 10.1007/978-3-319-15509-8_22
   Xia JZ, 2020, FRONT INFORM TECH EL, V21, P507, DOI 10.1631/FITEE.1900532
   Xia J, 2017, IEEE COMPUT GRAPH, V37, P42, DOI 10.1109/MCG.2017.21
   Yue XW, 2019, IEEE T VIS COMPUT GR, V25, P162, DOI 10.1109/TVCG.2018.2864814
   Zuo Y, 2016, KNOWL INF SYST, V48, P379, DOI 10.1007/s10115-015-0882-z
NR 71
TC 8
Z9 11
U1 1
U2 32
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 868
EP 878
DI 10.1109/TVCG.2021.3114821
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000089
PM 34596542
OA Green Published
DA 2024-11-06
ER

PT J
AU Knittel, J
   Koch, S
   Tang, T
   Chen, W
   Wu, YC
   Liu, SX
   Ertl, T
AF Knittel, Johannes
   Koch, Steffen
   Tang, Tan
   Chen, Wei
   Wu, Yingcai
   Liu, Shixia
   Ertl, Thomas
TI Real-Time Visual Analysis of High-Volume Social Media Posts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Social networking (online); Heuristic algorithms; Data visualization;
   Clustering algorithms; Real-time systems; Text analysis; Visual
   analytics; Social media analysis; dynamic clustering; streaming data
ID ANALYTICS; EXPLORATION; TWITTER; TOPICS
AB Breaking news and first-hand reports often trend on social media platforms before traditional news outlets cover them. The real-time analysis of posts on such platforms can reveal valuable and timely insights for journalists, politicians, business analysts, and first responders, but the high number and diversity of new posts pose a challenge. In this work, we present an interactive system that enables the visual analysis of streaming social media data on a large scale in real-time. We propose an efficient and explainable dynamic clustering algorithm that powers a continuously updated visualization of the current thematic landscape as well as detailed visual summaries of specific topics of interest. Our parallel clustering strategy provides an adaptive stream with a digestible but diverse selection of recent posts related to relevant topics. We also integrate familiar visual metaphors that are highly interlinked for enabling both explorative and more focused monitoring tasks. Analysts can gradually increase the resolution to dive deeper into particular topics. In contrast to previous work, our system also works with non-geolocated posts and avoids extensive preprocessing such as detecting events. We evaluated our dynamic clustering algorithm and discuss several use cases that show the utility of our system.
C1 [Knittel, Johannes; Koch, Steffen; Ertl, Thomas] Univ Stuttgart, Stuttgart, Germany.
   [Tang, Tan; Chen, Wei; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Liu, Shixia] Tsinghua Univ, Beijing, Peoples R China.
C3 University of Stuttgart; Zhejiang University; Tsinghua University
RP Knittel, J (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM johannes.knittel@vis.uni-stuttgart.de;
   steffen.koch@vis.uni-stuttgart.de; tangtan@zju.edu.cn;
   chenwei@zju.edu.cn; ycwu@zju.edu.cn; shixia@tsinghua.edu.cn;
   thomas.ertl@vis.uni-stuttgart.de
RI Chen, Wei/AAR-9817-2020; Tang, Tan/JJD-3333-2023; wang,
   yixuan/JGM-3893-2023; Liu, Shi-Xia/C-5574-2016
OI Liu, Shi-Xia/0000-0001-6104-4320
FU German Science Foundation (DFG), project VAOST [392087235]; joint
   Sino-German program of the NSFC [61761136020]; German Science Foundation
   (DFG), Priority Program VA4VGI [SPP 1894]
FX This research was supported by the German Science Foundation (DFG) as
   part of the project VAOST (392087235) and as part of the Priority
   Program VA4VGI (SPP 1894). It was also partially funded by the joint
   Sino-German program of the NSFC (61761136020).
CR Abel F., 2012, Proceedings of the 21st international conference companion on World Wide Web, P305
   Ackermann M R, 2010, P 12 WORKSH ALG ENG, P173, DOI DOI 10.1137/1.9781611972900.16
   Alexander E., 2016, P WORKSH ADV VIS INT, DOI [10.1145/2909132.2909252, DOI 10.1145/2909132.2909252]
   Alexander E, 2014, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2014.7042493
   Alsakran J, 2011, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2011.5742382
   [Anonymous], 2009, Advances in neural information processing systems
   Archambault D., 2011, Proceedings of the 3rd International Workshop on Search and Mining User Generated Contents, ACM CIKM, P77
   Beigi G, 2016, STUD COMPUT INTELL, V639, P313, DOI 10.1007/978-3-319-30319-2_13
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blundell Charles, 2010, P 26 C UNC ART INT, P65
   Bosch H, 2013, IEEE T VIS COMPUT GR, V19, P2022, DOI 10.1109/TVCG.2013.186
   Braverman V, 2011, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P26
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Carpineto C, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541884
   Chae J, 2012, IEEE CONF VIS ANAL, P143, DOI 10.1109/VAST.2012.6400557
   Chakrabarti D., 2006, Proceedings of the Twelfth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Philadelphia, PA, USA, August 2023, 2006, P554, DOI [10.1145/1150402.1150467, DOI 10.1145/1150402.1150467]
   Chen SM, 2021, IEEE T VIS COMPUT GR, V27, P1612, DOI 10.1109/TVCG.2020.3030411
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Chuang Jason, 2012, P SIGCHI C HUM FACT, P443, DOI DOI 10.1145/2207676.2207738
   Cui WW, 2014, IEEE T VIS COMPUT GR, V20, P2281, DOI 10.1109/TVCG.2014.2346433
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922
   Dörk M, 2008, IEEE T VIS COMPUT GR, V14, P1205, DOI 10.1109/TVCG.2008.175
   Dörk M, 2010, IEEE T VIS COMPUT GR, V16, P1129, DOI 10.1109/TVCG.2010.129
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   Dredze Mark, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P199, DOI 10.1145/1378773.1378800
   El-Assady M, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12919
   Endert Alex, 2013, 2013 IEEE International Conference on Big Data, P17, DOI 10.1109/BigData.2013.6691709
   Endo Yasunori, 2015, Modeling Decisions for Artificial Intelligence. 12th International Conference, MDAI 2015. Proceedings: 9321, P103, DOI 10.1007/978-3-319-23240-9_9
   Gad S, 2015, IEEE T VIS COMPUT GR, V21, P672, DOI 10.1109/TVCG.2014.2388208
   Gansner Emden R., 2013, Journal of Graph Algorithms and Applications, V17, P515, DOI 10.7155/jgaa.00302
   Gao ZJ., 2011, 2011 IEEE 11 INT C D, P1056, DOI DOI 10.1109/ICDM.2011.148
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Heller Katherine A., 2005, P 22 INT C MACH LEAR, P297
   Hoque E, 2019, INFORM VISUAL, V18, P318, DOI 10.1177/1473871618757228
   Hu M., 2012, P SIGCHI C HUM FACT, P2751, DOI [10.1145/2207676.2208672, DOI 10.1145/2207676.2208672]
   Hu MD, 2017, IEEE T VIS COMPUT GR, V23, P621, DOI 10.1109/TVCG.2016.2598590
   Kim Minjeong, 2017, IEEE Trans Vis Comput Graph, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Knittel J, 2021, PROCEEDINGS OF THE 21ST ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG '21), DOI 10.1145/3469096.3474930
   Knittel J, 2021, IEEE T VIS COMPUT GR, V27, P4455, DOI 10.1109/TVCG.2020.3010095
   Krstajic Milos, 2013, 2013 IEEE International Conference on Big Data, P41, DOI 10.1109/BigData.2013.6691713
   Krstajic M, 2013, INFORM VISUAL, V12, P308, DOI 10.1177/1473871613493996
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lelu Alain, 2020, DATA ANAL RATIONALIT
   Liu S., 2009, P 18 ACM C INF KNOWL, P543
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Liu SX, 2015, IEEE T KNOWL DATA EN, V27, P1533, DOI 10.1109/TKDE.2014.2373384
   MacEachren A. M., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P181, DOI 10.1109/VAST.2011.6102456
   Marcus A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P227
   Mei Qiaozhu., 2005, KDD 05, P198, DOI DOI 10.1145/1081870.1081895
   Oliveira N, 2017, EXPERT SYST APPL, V73, P125, DOI 10.1016/j.eswa.2016.12.036
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Paul C. L., 2018, TEXTONIC INTERACTIVE, DOI [10. 1177/1473871618785390, DOI 10.1177/1473871618785390]
   Peng M, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3173044
   Pirolli P., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P213, DOI 10.1145/238386.238489
   Rohrdantz C., 2011, VIS WEEK 2011 23 28
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sun GD, 2014, IEEE T VIS COMPUT GR, V20, P1753, DOI 10.1109/TVCG.2014.2346919
   Thom D, 2015, IEEE PAC VIS SYMP, P183, DOI 10.1109/PACIFICVIS.2015.7156376
   Thom D, 2012, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2012.6183572
   Viegas F., 2013, P 22 INT C WORLD WID, P1389
   Wang X, 2012, COMPUT GRAPH FORUM, V31, P1275, DOI 10.1111/j.1467-8659.2012.03120.x
   Wang XT, 2016, IEEE T VIS COMPUT GR, V22, P2508, DOI 10.1109/TVCG.2016.2515592
   Wang Xuerui, 2006, Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '06, P424, DOI DOI 10.1145/1150402.1150450
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Wise J. A., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P51, DOI 10.1109/INFVIS.1995.528686
   Wu Y., 2014, OPINIONFLOW VISUAL A, DOI [10.1109/TVCG.2014, DOI 10.1109/TVCG.2014]
   Wu YC, 2018, IEEE T VIS COMPUT GR, V24, P2758, DOI 10.1109/TVCG.2017.2764459
   Wu YC, 2016, IEEE T MULTIMEDIA, V18, P2135, DOI 10.1109/TMM.2016.2614220
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Zhang Jianwen, 2010, P 16 ACM SIGKDD INT, P2, DOI DOI 10.1145/1835804.1835940
   Zhang JW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173611
NR 79
TC 5
Z9 6
U1 1
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 879
EP 889
DI 10.1109/TVCG.2021.3114800
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000090
PM 34587041
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, Y
   Zhang, J
   Fu, CW
   Xu, ML
   Moritz, D
   Wang, YH
AF Zhao, Yue
   Zhang, Jian
   Fu, Chi-Wing
   Xu, Mingliang
   Moritz, Dominik
   Wang, Yunhai
TI KD-Box: Line-segment-based KD-tree for Interactive Exploration of
   Large-scale Time-Series Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Time series analysis; Visualization; Rendering
   (computer graphics); Market research; Clutter; Three-dimensional
   displays; Many time series; density-based visualization; interactive
   visualization for large-scale data
ID VISUAL ANALYSIS; MEAN SHIFT; VISUALIZATION; EDGE; PLOTS
AB Time-series data-usually presented in the form of lines-plays an important role in many domains such as finance, meteorology, health, and urban informatics. Yet, little has been done to support interactive exploration of large-scale time-series data, which requires a clutter-free visual representation with low-latency interactions. In this paper, we contribute a novel line-segment-based KD-tree method to enable interactive analysis of many time series. Our method enables not only fast queries over time series in selected regions of interest but also a line splatting method for efficient computation of the density field and selection of representative lines. Further, we develop KD-Box, an interactive system that provides rich interactions, e.g., timebox, attribute filtering, and coordinated multiple views. We demonstrate the effectiveness of KD-Box in supporting efficient line query and density field computation through a quantitative comparison and show its usefulness for interactive visual analysis on several real-world datasets.
C1 [Zhao, Yue; Wang, Yunhai] Shandong Univ, Qingdao, Peoples R China.
   [Zhang, Jian] Chinese Acad Sci, CNIC, Beijing, Peoples R China.
   [Fu, Chi-Wing] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Zhengzhou, Peoples R China.
   [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Shandong University; Chinese Academy of Sciences; Chinese University of
   Hong Kong; Zhengzhou University; Carnegie Mellon University
RP Wang, YH (corresponding author), Shandong Univ, Qingdao, Peoples R China.
EM jack.zhao9802@gmail.com; zhangjian@sccas.cn; cwfu@cse.cuhk.edu.hk;
   iexumingliang@zzu.edu.cn; domoritz@cmu.edu; cloudseawang@gmail.com
RI Fu, Chi-Wing/X-4703-2019
OI Zhao, Yue/0000-0003-0365-5291; Moritz, Dominik/0000-0002-3110-1053
CR Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P81, DOI 10.1109/INFVIS.2004.68
   Battle L, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1363, DOI 10.1145/2882903.2882919
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BENTLEY JL, 1979, COMPUT SURV, V11, P397, DOI 10.1145/356789.356797
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Chan SM, 2008, IEEE CONF VIS ANAL, P59, DOI 10.1109/VAST.2008.4677357
   Chaudhuri S, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P511, DOI 10.1145/3035918.3056097
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Conlen M, 2019, COMPUT GRAPH FORUM, V38, P687, DOI 10.1111/cgf.13720
   Eronana, RBUSH3D JAVASCRIPT L
   Feng D, 2010, IEEE T VIS COMPUT GR, V16, P980, DOI 10.1109/TVCG.2010.176
   Freedman D, 2009, PROC CVPR IEEE, P1818, DOI 10.1109/CVPRW.2009.5206716
   Ghysels E., 2001, ECONOMETRIC ANAL SEA, DOI [10.1017/CBO9781139164009, DOI 10.1017/CBO9781139164009]
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Heinrich J, 2011, COMPUT GRAPH FORUM, V30, P653, DOI 10.1111/j.1467-8659.2011.01914.x
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Hochheiser H., 2003, THESIS US
   Hurter C., 2015, SYNTHESIS LECT VISUA, DOI [10. 2200/s00688-d1v01y201512vis006, DOI 10.2200/S00688-D1V01Y201512VIS006]
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Lampe OD, 2011, COMPUT GRAPH FORUM, V30, P633, DOI 10.1111/j.1467-8659.2011.01912.x
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Lopez-Hernandez R, 2010, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2010.5429607
   Lu YC, 2021, COMPUT GRAPH FORUM, V40, P461, DOI 10.1111/cgf.142647
   Lysenko M, STATIC KDTREE JAVASC
   Matejka J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2707, DOI 10.1145/2702123.2702585
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   Miranda F, 2018, COMPUT GRAPH FORUM, V37, P23, DOI 10.1111/cgf.13398
   Moberts B, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P65
   Moritz D., 2018, VISUALIZING MILLION
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Muigg P, 2008, COMPUT GRAPH FORUM, V27, P775, DOI 10.1111/j.1467-8659.2008.01207.x
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   Scheepens R, 2011, IEEE T VIS COMPUT GR, V17, P2518, DOI 10.1109/TVCG.2011.181
   Swihart BJ, 2010, EPIDEMIOLOGY, V21, P621, DOI 10.1097/EDE.0b013e3181e5b06a
   T. Ltd, TIM SER DENS PLOT
   Telea A, 2010, COMPUT GRAPH FORUM, V29, P843, DOI 10.1111/j.1467-8659.2009.01680.x
   Turkay C., 2018, PROGR DATA SCI POTEN
   van Kreveld M., 2000, COMPUTATIONAL GEOMET, DOI [10. 1007/978-3-540-77974-2, DOI 10.1007/978-3-540-77974-2]
   van Liere R, 2003, IEEE T VIS COMPUT GR, V9, P206, DOI 10.1109/TVCG.2003.1196007
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Visvalingam M., 1990, Computer Graphics Forum, V9, P213, DOI 10.1111/j.1467-8659.1990.tb00398.x
   Wald I, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P61
   WATT RJ, 1982, VISION RES, V22, P449, DOI 10.1016/0042-6989(82)90193-6
   Wattenberg M., 2001, P 2001 CHI C HUM FAC, P381, DOI DOI 10.1145/634067.6342922
   Weber M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P7, DOI 10.1109/infvis.2001.963273
   Wickham Hadley., 2013, BIN SUMMARISE SMOOTH
   Yu HF, 2012, IEEE T VIS COMPUT GR, V18, P1353, DOI 10.1109/TVCG.2011.155
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
   Zwicker M, 2001, COMP GRAPH, P371, DOI 10.1145/383259.383300
NR 58
TC 20
Z9 21
U1 7
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 890
EP 900
DI 10.1109/TVCG.2021.3114865
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000091
PM 34587082
DA 2024-11-06
ER

PT J
AU Magallanes, J
   Stone, T
   Morris, PD
   Mason, S
   Wood, S
   Villa-Uriol, MC
AF Magallanes, Jessica
   Stone, Tony
   Morris, Paul D.
   Mason, Suzanne
   Wood, Steven
   Villa-Uriol, Maria-Cruz
TI Sequen-C: A Multilevel Overview of Temporal Event Sequences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Aggregates; Visual analytics; Feature extraction; Measurement; Data
   visualization; Scalability; MIMICs; Temporal event sequence
   visualization; clustering; hierarchical aggregation; multiple sequence
   alignment
ID PATTERNS; EXPLORATION; ALIGNMENT
AB Building a visual overview of temporal event sequences with an optimal level-of-detail (i.e. simplified but informative) is an ongoing challenge - expecting the user to zoom into every important aspect of the overview can lead to missing insights. We propose a technique to build a multilevel overview of event sequences, whose granularity can be transformed across sequence clusters (vertical level-of-detail) or longitudinally (horizontal level-of-detail), using hierarchical aggregation and a novel cluster data representation Align-Score-Simplify. By default, the overview shows an optimal number of sequence clusters obtained through the average silhouette width metric - then users are able to explore alternative optimal sequence clusterings. The vertical level-of-detail of the overview changes along with the number of clusters, whilst the horizontal level-of-detail refers to the level of summarization applied to each cluster representation. The proposed technique has been implemented into a visualization system called Sequence Cluster Explorer (Sequen-C) that allows multilevel and detail-on-demand exploration through three coordinated views, and the inspection of data attributes at cluster, unique sequence, and individual sequence level. We present two case studies using real-world datasets in the healthcare domain: CUREd and MIMIC-III; which demonstrate how the technique can aid users to obtain a summary of common and deviating pathways, and explore data attributes for selected patterns.
C1 [Magallanes, Jessica; Villa-Uriol, Maria-Cruz] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.
   [Stone, Tony; Mason, Suzanne] Univ Sheffield, Ctr Urgent & Emergency Care Res, Sheffield, S Yorkshire, England.
   [Morris, Paul D.] Univ Sheffield, Dept Infect Immun & Cardiovasc Dis, Sheffield, S Yorkshire, England.
   [Wood, Steven] Sheffield Teaching Hosp NHS Fdn Trust, Sheffield, S Yorkshire, England.
C3 University of Sheffield; University of Sheffield; University of
   Sheffield; University of Sheffield
RP Stone, T (corresponding author), Univ Sheffield, Ctr Urgent & Emergency Care Res, Sheffield, S Yorkshire, England.
EM tony.stone@sheffield.ac.uk; paul.morris@sheffield.ac.uk;
   s.mason@sheffield.ac.uk; steven.wood8@nhs.net;
   m.villa-uriol@sheffield.ac.uk
RI Stone, Tony/HLX-5790-2023; Morris, Paul/J-7583-2012; Villa-Uriol,
   Maria-Cruz/AAZ-4851-2020; Mason, Susan/S-7879-2018; Villa-Uriol,
   Maria-Cruz/I-5581-2015
OI Stone, Tony/0000-0002-0167-3800; Morris, Paul/0000-0002-3965-121X;
   Villa-Uriol, Maria-Cruz/0000-0002-3345-539X
FU CONACYT; Health Foundation (PathAnalyse project); Wellcome Trust
   [214567/Z/18/Z]; National Institute for Health Research (NIHR) Applied
   Research Collaboration Yorkshire and Humber [NIHR200166]; Wellcome Trust
   [214567/Z/18/Z] Funding Source: Wellcome Trust
FX The authors wish to thank CONACYT and The Health Foundation (PathAnalyse
   project) for supporting this work, and the anonymous reviewers for their
   valuable comments. CUREd Research Database is an independent project
   funded by the National Institute for Health Research (NIHR) Applied
   Research Collaboration Yorkshire and Humber (NIHR200166). The views
   expressed in this publication are those of the author(s) and not
   necessarily those of NIHR or the Department of Health and Social Care.
   Paul D Morris (PD) was funded by the Wellcome Trust [214567/Z/18/Z]. For
   the purpose of Open Access, PD has applied a CC BY public copyright
   licence to any Author Accepted Manuscript version arising from this
   submission.
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P1
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Bose RPJC, 2010, LECT NOTES COMPUT SC, V6336, P227
   Bouarfa L, 2012, J BIOMED INFORM, V45, P1185, DOI 10.1016/j.jbi.2012.08.003
   Cadez I, 2003, DATA MIN KNOWL DISC, V7, P399, DOI 10.1023/A:1024992613384
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Du F, 2017, IEEE T VIS COMPUT GR, V23, P1636, DOI 10.1109/TVCG.2016.2539960
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Fails JA, 2006, IEEE CONF VIS ANAL, P167
   FENG DF, 1987, J MOL EVOL, V25, P351, DOI 10.1007/BF02603120
   Götz D, 2016, 2016 IEEE/PES TRANSMISSION AND DISTRIBUTION CONFERENCE AND EXPOSITION (T&D)
   Goodstadt L, 2001, BIOINFORMATICS, V17, P845, DOI 10.1093/bioinformatics/17.9.845
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Gotz David, 2011, AMIA Annu Symp Proc, V2011, P481
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kaufman L., 2009, Finding Groups in Data: An Introduction to Cluster Analysis, V344
   Kuczawski M., 2019, EUSEM ABSTRACTS, P512
   Kwon BC., 2016, ACM SIGKDD 2016 Workshop on Interactive Data Exploration and Analytics, V1
   Kwon BC, 2021, IEEE T VIS COMPUT GR, V27, P3685, DOI 10.1109/TVCG.2020.2985689
   Lee C, 2003, BIOINFORMATICS, V19, P999, DOI 10.1093/bioinformatics/btg109
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li CL, 2020, J VISUAL-JAPAN, V23, P171, DOI 10.1007/s12650-019-00609-x
   Liu ZC, 2017, COMPUT GRAPH FORUM, V36, P527, DOI 10.1111/cgf.13208
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Makanju A, 2008, ANN CONF PRIV SECUR, P99, DOI 10.1109/PST.2008.17
   Monroe M., 2013, P ACM C HUMAN FACTOR, P2349
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Nguyen PH, 2020, IEEE T VIS COMPUT GR, V26, P77, DOI 10.1109/TVCG.2019.2934609
   Perer Adam., 2014, P 19 INT C INTELLIGE, P153, DOI [10.1145/ 2557500.2557508, DOI 10.1145/2557500.2557508]
   Plaisant Catherine, 2003, The craft of information visualization, P308, DOI DOI 10.1016/B978-155860915-0/50038-X
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stragier J, 2019, J MED INTERNET RES, V21, DOI 10.2196/11934
   The Scikit-Bio Development Team, 2020, SCIKIT BIO BIOINFORM
   UKKONEN E, 1992, THEOR COMPUT SCI, V92, P191, DOI 10.1016/0304-3975(92)90143-4
   van der Loo MPJ, 2014, R J, V6, P111
   Vrotsou K, 2009, IEEE T VIS COMPUT GR, V15, P945, DOI 10.1109/TVCG.2009.117
   Wang G, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P225, DOI 10.1145/2858036.2858107
   Wang LS, 2003, BIOINFORMATICS, V19, P297, DOI 10.1093/bioinformatics/19.2.297
   Wei JS, 2012, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2012.6400494
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wongsuphasawat K, 2014, IEEE CONF VIS ANAL, P113, DOI 10.1109/VAST.2014.7042487
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Zgraggen E, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2683, DOI 10.1145/2702123.2702262
   Zhang YX, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P206, DOI [10.1109/VISUAL.2019.8933584, 10.1109/visual.2019.8933584]
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhou ML, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P258, DOI 10.1109/ICHI.2017.57
NR 52
TC 7
Z9 8
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 901
EP 911
DI 10.1109/TVCG.2021.3114868
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000092
PM 34596549
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Yang, LN
   Xu, X
   Lan, XY
   Liu, ZY
   Guo, SN
   Shi, Y
   Qu, HM
   Cao, N
AF Yang, Leni
   Xu, Xian
   Lan, XingYu
   Liu, Ziyan
   Guo, Shunan
   Shi, Yang
   Qu, Huamin
   Cao, Nan
TI A Design Space for Applying the Freytag's Pyramid Structure to Data
   Stories
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Videos; Animation; Visual
   communication; Systematics; Data models; Freytag's Pyramid; Narrative
   Structure; Narrative Visualization; Data Storytelling; Data Video
AB Data stories integrate compelling visual content to communicate data insights in the form of narratives. The narrative structure of a data story serves as the backbone that determines its expressiveness, and it can largely influence how audiences perceive the insights. Freytag's Pyramid is a classic narrative structure that has been widely used in film and literature. While there are continuous recommendations and discussions about applying Freytag's Pyramid to data stories, little systematic and practical guidance is available on how to use Freytag's Pyramid for creating structured data stories. To bridge this gap, we examined how existing practices apply Freytag's Pyramid by analyzing stories extracted from 103 data videos. Based on our findings, we proposed a design space of narrative patterns, data flows, and visual communications to provide practical guidance on achieving narrative intents, organizing data facts, and selecting visual design techniques through story creation. We evaluated the proposed design space through a workshop with 25 participants. Results show that our design space provides a clear framework for rapid storyboarding of data stories with Freytag's Pyramid.
C1 [Yang, Leni; Lan, XingYu; Liu, Ziyan; Shi, Yang; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
   [Yang, Leni; Xu, Xian; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Guo, Shunan] Adobe Res, San Jose, CA USA.
C3 Tongji University; Hong Kong University of Science & Technology; Adobe
   Systems Inc.
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
EM lyangbb@connect.ust.hk; xxubq@connect.ust.hk; xingyulan@tongji.edu.cn;
   ziyan.liu.design@gmail.com; sguo@adobe.com; yangshi.idvx@tongji.edu.cn;
   huamin@cse.ust.hk; nan.cao@gmail.com
RI Guo, Shunan/AAE-2616-2019; Cao, Nan/O-5397-2014; Lan,
   Xingyu/KYO-9537-2024
OI Lan, Xingyu/0000-0001-7331-2433
FU National Natural Science Foundation of China [62072338]; NSF Shanghai
   [20ZR1461500]
FX Nan Cao is the corresponding author. This work was supported in part by
   the National Natural Science Foundation of China (62072338) and NSF
   Shanghai 20ZR1461500.
CR Adamo G., 1995, NEW READINGS, V1, P83
   Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2017, FILM ART INTRO
   Arijon Daniel, 1991, GRAMMAR FILM LANGUAG
   Aronson L, 2010, 21 CENTURY SCREENPLA, V2011
   Award S, 2010, SHORTY AWARDS WHATS
   B. News, 2010, B NEWS
   Bach B., 2018, DataDriven Storytelling, P107, DOI DOI 10.1201/9781315281575-5/NARRATIVEDESIGN-PATTERNS-DATA-DRIVEN-STORYTELLING-BENJAMIN-BACH-MORITZ-STEFANER-JEREMYBOY-STEVEN-DRUCKER-LYN-BARTRAM-JO-WOOD-PAOLO-CIUCCARELLI-YURI-ENGELHARDTULRIKE-KC3%B6PPEN-BARBARA
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Block Bruce., 2013, The visual story: Creating the visual structure of film, TV and digital media
   Bloomberg, 2015, WHATS REALL WARM WOR
   Booker C., 2004, 7 BASIC PLOTWHY WE
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Campbell J., 2008, BOLLINGEN SERIES, V17
   Capitalist V, 2017, DONALD TRUMPS 20 TRI
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   Cohn N, 2013, COGNITIVE SCI, V37, P413, DOI 10.1111/cogs.12016
   Cole K., 2020, STRUCTURES STORY
   Cutting JE, 2016, PSYCHON B REV, V23, P1713, DOI 10.3758/s13423-016-1051-4
   Dykes B, 2016, DATA STORYTELLING SE
   Dykes B, 2019, EFFECTIVE DATA STORY
   ElShafie SJ, 2018, INTEGR COMP BIOL, V58, P1213, DOI 10.1093/icb/icy103
   Freytag Gustav, 1895, TECHNIQUE DRAMA EXPO
   Genette Gerard., 1983, NARRATIVE DISCOURSE, V3
   Hayashi H, 2013, COGNITIVE STUDIES B, V20
   Hullman J, 2017, COMPUT GRAPH FORUM, V36, P365, DOI 10.1111/cgf.13194
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   IDEO, 2003, METH CARDS
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300280
   Kosara R., 2017, Proceedings of the Eurographics/IEEE VGTC Conference on Visualization: Short Papers, P31
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lyn B, 2016, NAPA CARDS
   MasterClass, 2020, MAST STOR ARC STRUCT
   Mautone PD, 2001, J EDUC PSYCHOL, V93, P377, DOI 10.1037/0022-0663.93.2.377
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Menkman R., 2011, THE GLITCH MOMENT UM
   Munzner T., 2014, AK Peters Visualization Series
   Policyviz, 2019, POL STOR STRUCT
   Pottker H., 2003, JOURNALISM STUD, V4, P501, DOI [DOI 10.1080/1461670032000136596, 10.1080/1461670032000136596]
   Propp V., 2010, MORPHOLOGY FOLKTALE, V9
   Quesenberry KA, 2014, J MARKET THEORY PRAC, V22, P437, DOI 10.2753/MTP1069-6679220406
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Rolfe B., 2010, ELECT WORKSHOPS COMP, DOI DOI 10.14236/EWIC/HCI2010.54
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Shu X., 2021, IEEE T VIS COMPUT GR, V27, DOI DOI 10.1109/TVCG.2020.3030396
   Smith J, 2019, IS YOUR DATA STORY A
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Tang JX, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P151, DOI [10.1109/vis47514.2020.00037, 10.1109/VIS47514.2020.00037]
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   TV-Tropes, 2020, MULT CUT
   Upton John., 1748, Critical Observations on Shakespeare, V2nd
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Warburton N, 2020, BASICS ESSAY WRITING
   Wenchao L, 2020, P IEEE VIS C SHORT P
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
NR 71
TC 19
Z9 20
U1 8
U2 62
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 922
EP 932
DI 10.1109/TVCG.2021.3114774
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000093
PM 34587025
DA 2024-11-06
ER

PT J
AU Lan, XY
   Shi, Y
   Wu, YQ
   Jiao, XH
   Cao, N
AF Lan, Xingyu
   Shi, Yang
   Wu, Yanqiu
   Jiao, Xiaohan
   Cao, Nan
TI Kineticharts: Augmenting Affective Expressiveness of Charts in Data
   Stories with Animation Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Data visualization; Videos; Visualization; Interviews; Mood;
   Journalism; Animation; Storytelling; Affective Design
ID VISUALIZATION; RECOGNITION; TRANSITIONS; FRAMEWORK; FEELINGS
AB Data stories often seek to elicit affective feelings from viewers. However, how to design affective data stories remains under-explored. In this work, we investigate one specific design factor, animation, and present Kineticharts, an animation design scheme for creating charts that express five positive affects: joy, amusement, surprise, tenderness, and excitement. These five affects were found to be frequently communicated through animation in data stories. Regarding each affect, we designed varied kinetic motions represented by bar charts, line charts, and pie charts, resulting in 60 animated charts for the five affects. We designed Kineticharts by first conducting a need-finding study with professional practitioners from data journalism and then analyzing a corpus of affective motion graphics to identify salient kinetic patterns. We evaluated Kineticharts through two user studies. The results suggest that Kineticharts can accurately convey affects, and improve the expressiveness of data stories, as well as enhance user engagement without hindering data comprehension compared to the animation design from DataClips, an authoring tool for data videos.
C1 [Lan, Xingyu; Shi, Yang; Wu, Yanqiu; Jiao, Xiaohan; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
C3 Tongji University
RP Lan, XY (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
EM xingyulan@tongji.edu.cn; yangshi.idvx@tongji.edu.cn;
   wuyanqiu.idvx@gmail.com; jiaoxiaohan.idvx@gmail.com; nan.cao@gmail.com
RI Lan, Xingyu/KYO-9537-2024; Cao, Nan/O-5397-2014
OI Lan, Xingyu/0000-0001-7331-2433
FU NSFC [62072338]; NSF Shanghai [20ZR1461500]
FX Nan Cao is the corresponding author. This work was supported by NSFC
   62072338 and NSF Shanghai 20ZR1461500. We would like to thank all the
   reviewers for their constructive feedback.
CR Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2013, NARRATION FICTION FI
   [Anonymous], 2003, METAPHOR EMOTION LAN
   [Anonymous], 2016, Tech. rep. MSR-TR-2016-14
   Bach B., 2018, DataDriven Storytelling, P107, DOI DOI 10.1201/9781315281575-5/NARRATIVEDESIGN-PATTERNS-DATA-DRIVEN-STORYTELLING-BENJAMIN-BACH-MORITZ-STEFANER-JEREMYBOY-STEVEN-DRUCKER-LYN-BARTRAM-JO-WOOD-PAOLO-CIUCCARELLI-YURI-ENGELHARDTULRIKE-KC3%B6PPEN-BARBARA
   Bakhshi S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P575, DOI 10.1145/2858036.2858532
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   BATRA R, 1986, J CONSUM RES, V13, P234, DOI 10.1086/209063
   BELK RW, 1988, J CONSUM RES, V15, P139, DOI 10.1086/209154
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Cairo Alberto., 2013, Emotional Data Visualization: Periscopic's 'U.S. Gun Deaths' and the Challenge of Uncertainty | | Peachpit
   Chalbi A, 2020, IEEE T VIS COMPUT GR, V26, P386, DOI 10.1109/TVCG.2019.2934288
   Chevalier F., 2016, P INT WORK C ADY VIS, P280, DOI DOI 10.1145/2909132.2909255
   Chevalier F, 2014, IEEE T VIS COMPUT GR, V20, P2241, DOI 10.1109/TVCG.2014.2346424
   COLBY BN, 1989, CONTEMP SOCIOL, V18, P957, DOI 10.2307/2074241
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   de la Torre-Diez Isabel, 2017, 2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom), P1, DOI 10.1109/HealthCom.2017.8210757
   Dillard JP, 1996, COMMUN RES, V23, P44, DOI 10.1177/009365096023001002
   Duncan C.P., 1979, J ACAD MARKET SCI, V7, P285
   EDELL JA, 1987, J CONSUM RES, V14, P421, DOI 10.1086/209124
   Erevelles S, 1998, J BUS RES, V42, P199, DOI 10.1016/S0148-2963(97)00118-5
   Feng C., 2014, P ACM S APPL PERC, P23, DOI DOI 10.1145/2628257.2628264
   Fisher D., 2010, Beautiful Visualization - Looking at Data Through the Eyes of Experts, P329
   Fujishima K., OH MY GODDESS
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Halloran N., 2016, The fallen of World War II
   Hamill H., 2014, Interview methodology
   Harrison C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1999
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Huang C., CHARLIES QUIRKY DANC
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Hung Y.-H., 2018, VIS COMM VISCOMM IEE
   ISEN AM, 1987, J PERS SOC PSYCHOL, V52, P1122, DOI 10.1037/0022-3514.52.6.1122
   Ivanova N., HAPPY LITTLE ORANGE
   Joonhwan Lee, 2006, Designing Interactive Systems. DIS2006, P41
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Khalid HM, 2006, APPL ERGON, V37, P409, DOI 10.1016/j.apergo.2006.04.005
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Lang P. J., 2008, technical report A-8)
   Lasseter J., 1987, Computer Graphics, DOI [DOI 10.1145/37402.37407, DOI 10.1145/37401.37407]
   Lecheler S, 2013, COMMUNICATIONS-GER, V38, P189, DOI 10.1515/commun-2013-0011
   LeDoux J.E., 2015, The Emotional Brain: The Mysterious Underpinnings of Emotional Life
   Lee J.C., 2002, P 15 ANN ACM S US IN, P81, DOI DOI 10.1145/571985.571997
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Lockyer M, 2012, COMPUT GRAPH-UK, V36, P776, DOI 10.1016/j.cag.2012.04.009
   Loewenstein G, 2003, SER AFFECTIVE SCI, P619
   Ma Xiaojuan, 2012, 8 INT DES EM C
   Mana, CROWD GOES WILD
   Marketplace, 2013, SURPR VIR HIT INC IN
   McCloud S., 2006, Making Comics: Storytelling Secrets of Comics, Manga, and Graphic Novels
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moghaddam A, 2006, ISS EDUC RES, V16, P52
   Monahan J.L., 1995, Designing Health Messages, P81
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006
   Quasthoff UM., 1982, ADV PSYCHOL, V8, P16, DOI 10.1016/S0166-4115(08)62677-1
   Rashid R, 2008, INT J HUM-COMPUT INT, V24, P505, DOI 10.1080/10447310802142342
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Saket B, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P133, DOI 10.1145/2993901.2993903
   Schaefer A, 2010, COGNITION EMOTION, V24, P1153, DOI 10.1080/02699930903274322
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Shi Y, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188560
   Staiano J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P427
   Thomas F., 1995, The Illusion of Life: Disney Animation
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Van Sijll J., 2005, CINEMATIC STORYTELLI
   van t Hart W., MORNING SURPRISE
   Walter Aarron., 2011, Designing for Emotion
   Wang H., 2016, CHI 04 HUM FACT COMP, DOI [DOI 10.1145/985921.986016, 10.1145/985921.986016]
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Wattenberg M, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P1, DOI 10.1109/INFVIS.2005.1532122
   Yang ZY, 2019, IEEE INT CON MULTI, P1090, DOI 10.1109/ICME.2019.00191
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
NR 97
TC 12
Z9 13
U1 4
U2 37
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 933
EP 943
DI 10.1109/TVCG.2021.3114775
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XU0IB
UT WOS:000733959000094
PM 34587026
DA 2024-11-06
ER

PT J
AU Wang, ZZ
   Romat, H
   Chevalier, F
   Riche, NH
   Murray-Rust, D
   Bach, B
AF Wang, Zezhong
   Romat, Hugo
   Chevalier, Fanny
   Riche, Nathalie Henry
   Murray-Rust, Dave
   Bach, Benjamin
TI Interactive Data Comics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Tools; Layout; Visualization; Media; Space
   exploration; Navigation; Data comics; Non-linear narrative; interactive
   storytelling
ID VISUALIZATION
AB This paper investigates how to make data comics interactive. Data comics are an effective and versatile means for visual communication, leveraging the power of sequential narration and combined textual and visual content, while providing an overview of the storyline through panels assembled in expressive layouts. While a powerful static storytelling medium that works well on paper support, adding interactivity to data comics can enable non-linear storytelling, personalization, levels of details, explanations, and potentially enriched user experiences. This paper introduces a set of operations tailored to support data comics narrative goals that go beyond the traditional linear, immutable storyline curated by a story author. The goals and operations include adding and removing panels into pre-defined layouts to support branching, change of perspective, or access to detail-on-demand, as well as providing and modifying data, and interacting with data representation, to support personalization and reader-defined data focus. We propose a lightweight specification language, COMICSCRIPT, for designers to add such interactivity to static comics. To assess the viability of our authoring process, we recruited six professional illustrators, designers and data comics enthusiasts and asked them to craft an interactive comic, allowing us to understand authoring workflow and potential of our approach. We present examples of interactive comics in a gallery. This initial step towards understanding the design space of interactive comics can inform the design of creation tools and experiences for interactive storytelling.
C1 [Wang, Zezhong; Bach, Benjamin] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Romat, Hugo] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Chevalier, Fanny] Univ Toronto, Toronto, ON, Canada.
   [Riche, Nathalie Henry] Microsoft Res, Redwood City, CA USA.
   [Murray-Rust, Dave] Delft Univ Technol, Delft, Netherlands.
C3 University of Edinburgh; Swiss Federal Institutes of Technology Domain;
   ETH Zurich; University of Toronto; Microsoft; Delft University of
   Technology
RP Wang, ZZ (corresponding author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.
EM zezhong.wang@ed.ac.uk; hugo.romat@gmail.com; fanny@cs.toronto.edu;
   nath@microsoft.com; D.S.Murray-Rust@tudelft.nl; bbach@ed.ac.uk
RI Murray-Rust, Dave/C-9234-2011
OI Murray-Rust, Dave/0000-0001-6098-7861
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Andrews Daniel, 2012, P SIGCHI C HUM FACT, P1703, DOI [10.1145/2207676.2208298, DOI 10.1145/2207676.2208298]
   [Anonymous], 2017, NEW YORK TIMES
   [Anonymous], 2020, WASH. POST
   [Anonymous], 2015, The New York Times25 November
   [Anonymous], 2014, EMPTY KINGDOM
   [Anonymous], 2015, R2D3
   Bach B, 2015, COMPUT GRAPH FORUM, V34, P31, DOI 10.1111/cgf.12615
   Bach B., 2018, DataDriven Storytelling, P107, DOI DOI 10.1201/9781315281575-5/NARRATIVEDESIGN-PATTERNS-DATA-DRIVEN-STORYTELLING-BENJAMIN-BACH-MORITZ-STEFANER-JEREMYBOY-STEVEN-DRUCKER-LYN-BARTRAM-JO-WOOD-PAOLO-CIUCCARELLI-YURI-ENGELHARDTULRIKE-KC3%B6PPEN-BARBARA
   Bach B., DATA COMICS COLLECTI
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2017, IEEE COMPUT GRAPH, V37, P6, DOI 10.1109/MCG.2017.33
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Bay-Wei Chang, 2000, Smart Graphics. Papers from the 2000 AAAI Symposium, P178
   Bigelow A, 2017, IEEE T VIS COMPUT GR, V23, P481, DOI 10.1109/TVCG.2016.2598609
   Boy J, 2016, IEEE T VIS COMPUT GR, V22, P639, DOI 10.1109/TVCG.2015.2467201
   Cagle S, 2019, HUMANS HAVE MADE 83B
   Cao Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366160
   Card M., 1999, READINGS INFORM VISU, DOI DOI 10.1002/WICS.89
   Chang R, WHAT BLOB
   Chen Bingxin, 2013, CHI 13 EXT ABSTR HUM, P2561
   Chevalier F, 2013, IEEE T VIS COMPUT GR, V19, P2426, DOI 10.1109/TVCG.2013.210
   Cisneros M., 2017, IS TRUE
   Cohn N., 2013, VISUAL LANGUAGE COMI
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Cox A, 2011, IEEE C VIS AN SCI TE, pxiii, DOI DOI 10.1109/VAST.2011.6102432.3
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   Durrant A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1767
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Farinella M, 2018, JCOM-J SCI COMMUN, V17, DOI 10.22323/2.17010401
   Goh G., 2020, Distill, V5, P29
   Goodboy Digital, TELL ME YOUR SECR
   Goodbrey D. Merlin, 2000, HIDDEN FACTIONS
   Goodbrey D. Merlin, 2012, ICARUS NEED
   Goodbrey Daniel M., 2012, A Duck Has An Adventure.
   Goodbrey Daniel Merlin, 2013, Cultural Excavation and Formal Expression in the Graphic Novel, P291
   Gramener, YIKES 6FT PLEASE
   Gramener, 2019, COMICGEN
   Hayes TB, 2011, J STEROID BIOCHEM, V127, P64, DOI 10.1016/j.jsbmb.2011.03.015
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Hinrichs U, 2008, IEEE T VIS COMPUT GR, V14, P1181, DOI 10.1109/TVCG.2008.127
   Hohman F, 2020, Distill, DOI [10.23915/distill.00028, DOI 10.23915/DISTILL.00028]
   Huynh M., The Boat
   Kang D, 2021, POLYM COMPOSITE, V42, P2171, DOI 10.1002/pc.25966
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kim NW, 2019, P 2019 CHI C HUMAN F, P1, DOI DOI 10.1145/3290605.3300309
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kuhni M, NEW SPEAK
   Kuhni M, COMING AGE
   Kuhni M., VISITING AQUARIUM
   Kuhni M., HEIDI
   Kuhni M., CLAMS 2
   Lau S., 2020, WORKSH LIV PROGRLIVE
   Lekschas F., 2020, IEEE T VIS COMPUT GR
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Loveshack Entertainment, 2018, FRAMED COLLECTION
   Mauri M, 2017, P 12 BIANN C IT SIGC, P1, DOI DOI 10.1145/3125571.3125585
   McCloud S=, 2003, RIGHT NUMBER
   McCloud Scott., 2000, Reinventing Comics: How Imagination and Technology Are Revolutionizing an Art Form
   McCloud Scott, 1998, IEEE T PROFESSIONAL, V41, P66, DOI DOI 10.1109/TPC.1998.661632
   McGuire R, HERE
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Monde Binaire, 2012, HELLO WORLD
   Muckenhoupt C, INTERACTIVE COMIC PR
   Munroe R, XKCD THROW CALCULATO
   Munroe R, XKCD CLICK DRAG
   Munroe R, XKCD LORENTZ
   Munroe R., XKCD XKCLOUD
   Munroe R., XKCD ZACH WEINER SMB
   N. Case, 2018, REMEMBER EVERYTHING
   Netwars, 2014, BUTTERFLY ATTACK
   PLASTIEK, 2018, RRR2
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Romat H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376348
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shiga J, 2010, MAKE YOUR OWN INTERA
   Shiga J, 2016, NUMBERPHILE PAPER CA
   Shiga J., MEANWHILE
   Soares de Lima Edirlei, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P230, DOI 10.1007/978-3-319-03161-3_16
   Stolper C.D., 2018, DATA DRIVEN STORYTEL, P85, DOI DOI 10.1201/9781315281575
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Sutu, 2014, MODERN POLAXIX
   Thudt A., 2011, BOHEIAN BOOKSHELF SU
   Tobita H., 2010, CHI 2010, P3751
   Tobita H, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P163, DOI 10.1145/2836041.2836057
   Tobita H, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P269, DOI 10.1109/ISM.2009.126
   Transmii Studio, 2014, MEMORY CATCHER
   Turbomedia, COUP POMPE
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Victor B, 2013, TANGLE EXPLORABLE EX
   Wang Z., 2020, IEEE T VIS COMPUT GR
   Wang Z., 2020, 2020 IEEE 91 VEHICUL, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9128938
   Wang ZZ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299043
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Wattenberg M, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P1, DOI 10.1109/INFVIS.2005.1532122
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zhao Z., 2015, DATA COMICS SEQUENTI
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
NR 105
TC 10
Z9 12
U1 4
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 944
EP 954
DI 10.1109/TVCG.2021.3114849
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000095
PM 34587073
OA Green Published
DA 2024-11-06
ER

PT J
AU Xiong, C
   Setlur, V
   Bach, B
   Lin, K
   Koh, E
   Franconeri, S
AF Xiong, Cindy
   Setlur, Vidya
   Bach, Benjamin
   Lin, Kylie
   Koh, Eunyee
   Franconeri, Steven
TI Visual Arrangements of Bar Charts Influence Comparisons in Viewer
   Takeaways
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bars; Data visualization; Visualization; Tools; Semantics; Affordances;
   Task analysis; Comparison; perception; visual grouping; bar charts;
   recommendation systems; natural language interaction
ID VISUALIZATION; FORMAT; IMPACT; RISKS
AB Well-designed data visualizations can lead to more powerful and intuitive processing by a viewer. To help a viewer intuitively compare values to quickly generate key takeaways, visualization designers can manipulate how data values are arranged in a chart to afford particular comparisons. Using simple bar charts as a case study, we empirically tested the comparison affordances of four common arrangements: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. We asked participants to type out what patterns they perceived in a chart and we coded their takeaways into types of comparisons. In a second study, we asked data visualization design experts to predict which arrangement they would use to afford each type of comparison and found both alignments and mismatches with our findings. These results provide concrete guidelines for how both human designers and automatic chart recommendation systems can make visualizations that help viewers extract the "right" takeaway.
C1 [Xiong, Cindy] UMass Amherst, Amherst, MA 01003 USA.
   [Setlur, Vidya] Tableau Res, Seattle, WA USA.
   [Bach, Benjamin] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Koh, Eunyee] Adobe Res, San Jose, CA USA.
   [Lin, Kylie; Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   University of Edinburgh; Adobe Systems Inc.; Northwestern University
RP Xiong, C (corresponding author), UMass Amherst, Amherst, MA 01003 USA.
EM cindy.xiong@cs.umass.edu
CR Ahrens JP, 2010, IEEE COMPUT GRAPH, V30, P16, DOI 10.1109/MCG.2010.100
   Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   Bakhshandeh Omid., 2015, P 2015 C EMPIRICAL M, P993
   Bierwisch M., 1989, SEMANTICS GRADATION
   CLARK HH, 1972, COGNITIVE PSYCHOL, V3, P472, DOI 10.1016/0010-0285(72)90019-9
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Conati C, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12393
   Cresswell M., 1976, Montague Grammar, P261, DOI [10.1016/B978-0-12-545850-4.50015-7, DOI 10.1016/B978-0-12-545850-4.50015-7]
   Cui Z., 2018, ABS180208621 CORR
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Franconeri S. L, IN PRESS
   Franconeri SL, 2012, COGNITION, V122, P210, DOI 10.1016/j.cognition.2011.11.002
   Franconeri Steven L, 2013, NATURE STATUS VISUAL
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Garcia-Retamero R, 2013, CURR DIR PSYCHOL SCI, V22, P392, DOI 10.1177/0963721413491570
   Garcia-Retamero R, 2009, AM J PUBLIC HEALTH, V99, P2196, DOI 10.2105/AJPH.2009.160234
   Gleich B, 2010, LECT NOTES COMPUT SC, V6182, P218, DOI 10.1007/978-3-642-14192-8_20
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gleitman LR, 2007, J MEM LANG, V57, P544, DOI 10.1016/j.jml.2007.01.007
   Graham M, 2007, IEEE T VIS COMPUT GR, V13, P1294, DOI 10.1109/TVCG.2007.70556
   Hamann C., 2005, COMP SEMANTIC THEORI
   Hawley ST, 2008, PATIENT EDUC COUNS, V73, P448, DOI 10.1016/j.pec.2008.07.023
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Kaplan J, 2010, J STAT EDUC, V18, DOI 10.1080/10691898.2010.11889491
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kennedy C., 2004, ENCY LANGUAGE LINGUI
   KENNEDY C., 1997, Projecting the adjective: The syntax and semantics of gradability and comparison
   Kim D.-K., 2021, ARXIV PREPRINT ARXIV
   Kim J., 2019, SCATTERSEARCH VISUAL
   KLEIN E, 1980, LINGUIST PHILOS, V4, P1, DOI 10.1007/BF00351812
   Korenjak-ECerne S., 2008, INFORMATICA, V32
   Larsen A, 1998, J EXP PSYCHOL HUMAN, V24, P719, DOI 10.1037/0096-1523.24.3.719
   LARSEN A, 1978, J EXP PSYCHOL HUMAN, V4, P1, DOI 10.1037/0096-1523.4.1.1
   Lee D. J.-L., 2021, DECONSTRUCTING CATEG
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Livingston MA, 2011, IEEE T VIS COMPUT GR, V17, P2053, DOI 10.1109/TVCG.2011.194
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Matlen BJ, 2020, J EXP PSYCHOL HUMAN, V46, P443, DOI 10.1037/xhp0000726
   Michal AL, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0059-2
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Pagendarm H.-G, 1995, Comparative visualization: Approaches and examples
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Qualtrics I., 2013, QUALTRICS
   Rensink RA, 2002, ANNU REV PSYCHOL, V53, P245, DOI 10.1146/annurev.psych.53.100901.135125
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Roth JC, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00464
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Sapir E., 1944, Philosophy of Science, V11, P93, DOI [10.1086/286828, DOI 10.1086/286828]
   Schwarzschild R., 2002, Nat. Lang. Semant., V10, P1, DOI [DOI 10.1023/A, 10.1023/A, DOI 10.1023/A:1015545424775]
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Srinivasan Arjun, 2018, P 2018 CHI C HUM FAC
   Tait AR, 2010, ANESTH ANALG, V111, P718, DOI 10.1213/ANE.0b013e3181e8570a
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Tufte E.R., 1990, Envisioning Information
   Tversky B., 2014, Handbook of Human Centric Visualization, P3
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Wu A, 2021, IEEE Transactions on Visualization and Computer Graphics
   Xiong C., J VISION, V2021
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Xu YQ, 2015, PSYCHOL SCI, V26, P1241, DOI 10.1177/0956797615585002
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 72
TC 14
Z9 16
U1 4
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 955
EP 965
DI 10.1109/TVCG.2021.3114823
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XU0IB
UT WOS:000733959000096
PM 34587056
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Jaunet, T
   Kervadec, C
   Vuillemot, R
   Antipov, G
   Baccouche, M
   Wolf, C
AF Jaunet, Theo
   Kervadec, Corentin
   Vuillemot, Romain
   Antipov, Grigory
   Baccouche, Moez
   Wolf, Christian
TI VisQA: X-raying Vision and Language Reasoning in Transformers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cognition; Transformers; Analytical models; Task analysis; Magnetic
   heads; Head; Biological system modeling; Transformers; Visual Question
   Answering; Visual analytics
AB Visual Question Answering systems target answering open-ended textual questions given input images. They are a testbed for learning high-level reasoning with a primary use in HCI, for instance assistance for the visually impaired. Recent research has shown that state-of-the-art models tend to produce answers exploiting biases and shortcuts in the training data, and sometimes do not even look at the input image, instead of performing the required reasoning steps. We present VisQA, a visual analytics tool that explores this question of reasoning vs. bias exploitation. It exposes the key element of state-of-the-art neural models - attention maps in transformers. Our working hypothesis is that reasoning steps leading to model predictions are observable from attention distributions, which are particularly useful for visualization. The design process of VisQA was motivated by well-known bias examples from the fields of deep learning and vision-language reasoning and evaluated in two ways. First, as a result of a collaboration of three fields, machine learning, vision and language reasoning, and data analytics, the work lead to a better understanding of bias exploitation of neural models for VQA, which eventually resulted in an impact on its design and training through the proposition of a method for the transfer of reasoning patterns from an oracle model. Second, we also report on the design of VisQA, and a goal-oriented evaluation of VisQA targeting the analysis of a model decision process from multiple experts, providing evidence that it makes the inner workings of models accessible to users.
C1 [Jaunet, Theo; Kervadec, Corentin; Wolf, Christian] INSA Lyon, Lyon, France.
   [Jaunet, Theo; Kervadec, Corentin; Vuillemot, Romain; Wolf, Christian] LIRIS, Lyon, France.
   [Kervadec, Corentin; Antipov, Grigory; Baccouche, Moez] Orange Innovat, Lyon, France.
   [Vuillemot, Romain] Ecole Cent Lyon, Lyon, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Institut
   National des Sciences Appliquees de Lyon - INSA Lyon; Ecole Centrale de
   Lyon
RP Jaunet, T (corresponding author), INSA Lyon, Lyon, France.; Jaunet, T (corresponding author), LIRIS, Lyon, France.
EM theo.jaunet.sio@gmail.com
RI Vuillemot, Romain/ABE-5719-2020
FU "Remember" of call "ANR AI chairs hors centres" [ANR-20-CHIA-0018];
   Agence Nationale de la Recherche (ANR) [ANR-20-CHIA-0018] Funding
   Source: Agence Nationale de la Recherche (ANR)
FX We would like to thank reviewers from the previous EuroVis'21
   submission, as well as coworkers for their valuable discussions, and
   proofreading: Nicolas Jacquelin, Aur ' elien Tabard, and Antoine
   Coutrot. We finally thank our experts for their time and enthusiasm
   during the evaluation of VISQA. We also acknowledge grant
   ANR-20-CHIA-0018 "Remember" of call "ANR AI chairs hors centres".
CR Abbasnejad E, 2020, PROC CVPR IEEE, P10041, DOI 10.1109/CVPR42600.2020.01006
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Agrawal Aishwarya, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, P1955
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bottou L, 2014, MACH LEARN, V94, P133, DOI 10.1007/s10994-013-5335-x
   Bugliarello E., 2021, T ASSOC COMPUT LING
   Cao J., 2020, EUROPEAN C COMPUTER, P565
   Carter S., 2019, DISTILL, V4, DOI DOI 10.23915/DISTILL.00015
   Carter S., 2016, Distill, DOI DOI 10.23915/DISTILL.00004
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Chandrasekaran A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1036
   DeRose Joseph F, 2020, IEEE T VISUALIZATION
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A., 2021, INT C LEARN REPR VIE, DOI 10.48550/arXiv.2010.11929
   Duke B., 2021, CVPR
   Eickhoff C, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P162, DOI 10.1145/3159652.3159654
   Gan Z., 2020, NeurIPS, V33, P6616
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Girdhar R., 2020, CVPR
   Gokhale T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P878
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Goyal Yash, 2016, ARXIV PREPRINT ARXIV
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Huang Z., 2020, PIXEL BERT ALIGNING
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Karpathy A, 2015, CORR
   Kervadec C., 2021, ARXIV PREPRINT ARXIV
   Kervadec Corentin, 2021, CVPR, P2776
   Kervadec Corentin, 2019, EUR C ART INT
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Li Liunian Harold, 2020, ACL, P5265
   Li X., 2020, EUR C COMP VIS, P121
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lipton Z., 2016, COMMUN ACM, DOI DOI 10.1145/3233231
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2016, ADV NEUR IN, V29
   Manjunatha V, 2019, PROC CVPR IEEE, P9554, DOI 10.1109/CVPR.2019.00979
   Olah C., 2016, Distill, DOI [10.23915/distill.00001, DOI 10.23915/DISTILL.00001]
   Paszke A, 2019, ADV NEUR IN, V32
   Ramsauer H., 2021, INT C LEARN REPR
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shrestha Robik, 2020, P 58 ANN M ASS COMPU, P8172, DOI [DOI 10.18653/V1/2020.ACL-MAIN.727, DOI 10.18653/V1/2020.ACL-MAIN.727.URL]
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710
   Tan Hao, 2019, arXiv preprint arXiv:1908.07490, DOI 10.18653/v1/D19-1514
   Teney Damien, 2020, Advances in Neural Information Processing Systems, V33
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu Y., 2016, GOOGLES NEURAL MACHI
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang P., 2021, P C COMP VIS PATT RE, P5579
   Zhao HS, 2020, PROC CVPR IEEE, P10073, DOI 10.1109/CVPR42600.2020.01009
NR 64
TC 10
Z9 10
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 976
EP 986
DI 10.1109/TVCG.2021.3114683
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000097
PM 34587013
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hong, MH
   Witt, JK
   Szafir, DA
AF Hong, Matt-Heun
   Witt, Jessica K.
   Szafir, Danielle Albers
TI The Weighted Average Illusion: Biases in Perceived Mean Position in
   Scatterplots
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Image color analysis;
   Data models; Market research; Correlation; Human-Subjects Quantitative
   Studies; Perception & Cognition
ID FEATURE-BASED ATTENTION; SETS; REPRESENTATION; ORIENTATION; PERCEPTION;
   FILTERS
AB Scatterplots can encode a third dimension by using additional channels like size or color (e.g. bubble charts). We explore a potential misinterpretation of trivariate scatterplots, which we call the weighted average illusion, where locations of larger and darker points are given more weight toward x- and y-mean estimates. This systematic bias is sensitive to a designer's choice of size or lightness ranges mapped onto the data. In this paper, we quantify this bias against varying size/lightness ranges and data correlations. We discuss possible explanations for its cause by measuring attention given to individual data points using a vision science technique called the centroid method. Our work illustrates how ensemble processing mechanisms and mental shortcuts can significantly distort visual summaries of data, and can lead to misjudgments like the demonstrated weighted average illusion.
C1 [Hong, Matt-Heun; Szafir, Danielle Albers] Univ Colorado, ATLAS Inst, Boulder, CO 80309 USA.
   [Witt, Jessica K.] Colorado State Univ, Dept Psychol, Ft Collins, CO 80523 USA.
C3 University of Colorado System; University of Colorado Boulder; Colorado
   State University
RP Hong, MH (corresponding author), Univ Colorado, ATLAS Inst, Boulder, CO 80309 USA.
EM matt.hong@colorado.edu; jessica.witt@coloradostate.edu;
   danielle.szafir@colorado.edu
FU NSF [BCS-1632222, SES2030059, IIS-2046725, IIS-1764092, IIS-1764089]
FX This work was supported in part by NSF awards BCS-1632222, SES2030059,
   IIS-2046725, IIS-1764092, and IIS-1764089.
CR Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Alexander E, 2018, IEEE T VIS COMPUT GR, V24, P2397, DOI 10.1109/TVCG.2017.2723397
   Alvarez G. A, 2011, REPRESENTING MULTIPL, DOI [DOI 10.1016/J.TICS.2011.01.003, 10.1016/j.tics.2011.01.003]
   Alvarez GA, 2008, PSYCHOL SCI, V19, P392, DOI 10.1111/j.1467-9280.2008.02098.x
   Ariely D, 2001, PSYCHOL SCI, V12, P157, DOI 10.1111/1467-9280.00327
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Burlinson D, 2018, IEEE T VIS COMPUT GR, V24, P574, DOI 10.1109/TVCG.2017.2745086
   Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012
   Clark J. H., 1924, American Journal of Physiological Optics, V5, P269
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cohen M. A., 2016, ENSEMBLE PERCEPTION, DOI [DOI 10.1016/J.TICS.2016.06.007, 10.1016/j.tics.2016.06.007]
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   Correll M., 2017, WORKSH DEAL COGN BIA
   Correll M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376222
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Dakin SC, 1997, VISION RES, V37, P3181, DOI 10.1016/S0042-6989(97)00133-8
   Dakin SC, 2011, P NATL ACAD SCI USA, V108, P19552, DOI 10.1073/pnas.1113195108
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara Evanthia, 2018, IEEE T VIS COMPUT GR
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Drew SA, 2010, J VISION, V10, DOI 10.1167/10.10.20
   DURGIN FH, 1995, J EXP PSYCHOL HUMAN, V21, P149, DOI 10.1037/0096-1523.21.1.149
   Eilers PHC, 2004, BIOINFORMATICS, V20, P623, DOI 10.1093/bioinformatics/btg454
   Feigenson L, 2011, ATTENTION PERFORM, P13, DOI 10.1016/B978-0-12-385948-8.00002-5
   FIELLER EC, 1954, J ROY STAT SOC B, V16, P175
   Franconeri SL, 2009, COGNITION, V113, P1, DOI 10.1016/j.cognition.2009.07.002
   GARNER WR, 1976, COGNITIVE PSYCHOL, V8, P98, DOI 10.1016/0010-0285(76)90006-2
   Gebuis T, 2012, J EXP PSYCHOL GEN, V141, P642, DOI 10.1037/a0026218
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Haberman J., 2012, From perception to consciousness: Searching with Anne Treisman, P339, DOI DOI 10.1093/ACPROF:OSOBL/9780199734337.003.0030
   Halberda J, 2006, PSYCHOL SCI, V17, P572, DOI 10.1111/j.1467-9280.2006.01746.x
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hessney S., 2019, NEW YORK TIMES
   Hessney S., 2020, NEW YORK TIMES
   Hochstein S, 2018, J VISION, V18, DOI 10.1167/18.13.12
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Hurewitz F, 2006, P NATL ACAD SCI USA, V103, P19599, DOI 10.1073/pnas.0609485103
   Inverso M, 2016, ATTEN PERCEPT PSYCHO, V78, P293, DOI 10.3758/s13414-015-1005-3
   Kastens KA, 2016, J ASTRON EARTH SCI E, V3, P27, DOI 10.19030/jaese.v3i1.9689
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kosara R., 2010, P BELIV 10 WORKSH TI, P63, DOI [10.1145/2110192.2110202, DOI 10.1145/2110192.2110202]
   Kramer R. S., 2017, VISUAL COMP 2 DATA S
   Lei Q, 2018, J VISION, V18, DOI 10.1167/18.7.8
   Mansoor H., 2018, COGNITIVE BIASES VIS, P87, DOI [DOI 10.1007/978-3-319-95831-6_7, 10.1007/978-3-319-95831-6, DOI 10.1007/978-3-319-95831-6]
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   Mazer JA, 2011, BIOL PSYCHIAT, V69, P1147, DOI 10.1016/j.biopsych.2011.03.014
   McNutt A., 2018, VISGUIDES 2 WORKSH C
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Morgan MJ, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.1137
   Munzner T, 2018, VISUALIZATION ANAL D, P95, DOI DOI 10.1201/B17511-5
   Myczek K, 2008, PERCEPT PSYCHOPHYS, V70, P772, DOI 10.3758/PP.70.5.772
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Parlapiano Alicia, 2014, NEW YORK TIMES
   Picon E, 2019, J EXP PSYCHOL GEN, V148, P1675, DOI 10.1037/xge0000553
   Pinker S., 1990, Artif. Intell. Future Testing, V73, P73, DOI DOI 10.1145/2046684.2046699
   Pomè A, 2019, J VISION, V19, DOI 10.1167/19.6.14
   Procopio M, 2022, IEEE T VIS COMPUT GR, V28, P3093, DOI 10.1109/TVCG.2021.3051013
   Quinan PS, 2019, COMPUT GRAPH FORUM, V38, P363, DOI 10.1111/cgf.13695
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Rensink Ronald A., 2014, HDB HUMAN CENTRIC VI, P147, DOI [DOI 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485- 2_6]
   Ritchie J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300423
   Rodriguez-Cintron LM, 2019, J VISION, V19, DOI 10.1167/19.3.3
   Rosling H, 2011, J EPIDEMIOL GLOB HEA, V1, P11, DOI 10.1016/j.jegh.2011.07.001
   Russell D. M., 2016, AVI, P7, DOI [DOI 10.1145/2909132.29332876, 10.1145/2909132.29332878, DOI 10.1145/2909132.29332878]
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Serences JT, 2009, NEUROIMAGE, V44, P223, DOI 10.1016/j.neuroimage.2008.07.043
   Smart S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300899
   Stewart T. R, 2000, UNCERTAINTY JUDGMENT
   Sun P, 2018, P NATL ACAD SCI USA, V115, pE12153, DOI 10.1073/pnas.1814657115
   Sun P, 2016, P NATL ACAD SCI USA, V113, pE6712, DOI 10.1073/pnas.1614062113
   Sun P, 2016, ATTEN PERCEPT PSYCHO, V78, P474, DOI 10.3758/s13414-015-0978-2
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tibber MS, 2012, J VISION, V12, DOI 10.1167/12.6.8
   Valdez A.C., 2018, Cognitive Biases in Visualizations, P13, DOI 10.1007/978-3-319-95831-6_2
   Veras R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300771
   Warden A.C., 2020, J VISION, V20, P1240, DOI DOI 10.1167/JOV.20.11.1240
   Ware C, 2019, INFORM VISUALIZATION
   Wei YT, 2020, IEEE T VIS COMPUT GR, V26, P321, DOI 10.1109/TVCG.2019.2934208
   Whitney D, 2018, ANNU REV PSYCHOL, V69, P105, DOI 10.1146/annurev-psych-010416-044232
   Witt J. K., 2019, MetaPsychology, V3, DOI [DOI 10.5626/MP.2018.895, DOI 10.15626/MP.2018.895, 10.5626/MP.2018.895]
   Witt JK, 2019, J EXP PSYCHOL HUMAN, V45, P1083, DOI 10.1037/xhp0000648
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
NR 94
TC 6
Z9 6
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 987
EP 997
DI 10.1109/TVCG.2021.3114783
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000098
PM 34596541
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kaul, S
   Borland, D
   Cao, N
   Gotz, D
AF Kaul, Smiti
   Borland, David
   Cao, Nan
   Gotz, David
TI Improving Visualization Interpretation Using Counterfactuals
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Social networking (online); Data
   analysis; Tools; Machine learning; Analytical models; visualization;
   counterfactuals; human-computer interaction; human-centered computing;
   empirical study
ID EXPLORATION
AB Complex, high-dimensional data is used in a wide range of domains to explore problems and make decisions. Analysis of high-dimensional data, however, is vulnerable to the hidden influence of confounding variables, especially as users apply ad hoc filtering operations to visualize only specific subsets of an entire dataset. Thus, visual data-driven analysis can mislead users and encourage mistaken assumptions about causality or the strength of relationships between features. This work introduces a novel visual approach designed to reveal the presence of confounding variables via counterfactual possibilities during visual data analysis. It is implemented in CoFact, an interactive visualization prototype that determines and visualizes counterfactual subsets to better support user exploration of feature relationships. Using publicly available datasets, we conducted a controlled user study to demonstrate the effectiveness of our approach; the results indicate that users exposed to counterfactual visualizations formed more careful judgments about feature-to-outcome relationships.
C1 [Kaul, Smiti] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.
   [Borland, David] Univ N Carolina, RENCI, Chapel Hill, NC 27515 USA.
   [Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
   [Gotz, David] Univ N Carolina, Sch Informat & Lib Sci, Chapel Hill, NC 27515 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill;
   University of North Carolina; University of North Carolina Chapel Hill;
   Tongji University; University of North Carolina; University of North
   Carolina Chapel Hill
RP Kaul, S (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27515 USA.
EM smiti@live.unc.edu; borland@renci.org; nan.cao@tongji.edu.cn;
   gotz@unc.edu
RI Cao, Nan/O-5397-2014
OI Borland, David/0000-0002-0162-4080
FU National Science Foundation [1704018]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1704018] Funding
   Source: National Science Foundation
FX The research reported in this article was supported in part by a grant
   from the National Science Foundation (#1704018). We also thank Tabitha
   Peck for her help with data analysis.
CR Artur E, 2019, COMPUT GRAPH-UK, V84, P160, DOI 10.1016/j.cag.2019.08.015
   Borland D, 2018, IEEE COMPUT GRAPH, V38, P17, DOI 10.1109/MCG.2018.2874782
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Byrne RMJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6276
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Cheng F., 2020, DECE DECISION EXPLOR
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Cleveland W. S, 1993, VISUALIZING DATA, DOI DOI 10.1002/SIM.4780141212
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   de Oliveira MCF, 2003, IEEE T VIS COMPUT GR, V9, P378, DOI 10.1109/TVCG.2003.1207445
   Diehl S, 2010, IEEE T VIS COMPUT GR, V16, P935, DOI 10.1109/TVCG.2010.209
   Draper GM, 2009, IEEE T VIS COMPUT GR, V15, P759, DOI 10.1109/TVCG.2009.23
   Elmqvist N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P189, DOI 10.1109/INFVIS.2003.1249025
   Elmqvist N., 2003, Proc. 1st ACM Symp. Softw. Vis, P17
   Elmqvist N, 2008, INFORM VISUAL, V7, P18, DOI 10.1057/palgrave.ivs.9500170
   Evans J.D., 1996, Straightforward statistics for the behavioral sciences
   Ghazimatin A, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P196, DOI 10.1145/3336191.3371824
   Gomez O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P531, DOI 10.1145/3377325.3377536
   Goyal Y., 2019, ARXIV190407451CSSTAT
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hoffman P., 1999, P WORKSH NEW PAR INF, P9, DOI [10.1145/331770.331775, DOI 10.1145/331770.331775]
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hume D., 1978, TREATISE HUMAN NATUR, V2nd
   Ingram S., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P3, DOI 10.1109/VAST.2010.5652392
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Jin Z., 2020, VISUAL CAUSALITY ANA
   JOHNSON B, 1991, VISUALIZATION 91, P284
   Kadaba NR, 2007, IEEE T VIS COMPUT GR, V13, P1254, DOI 10.1109/TVCG.2007.70528
   Kaggle, 2018, HOUSE PRICES ADV REG
   Karimi A-H, 2019, MODEL AGNOSTIC COUNT, DOI DOI 10.1145/3527848
   Keim D, 2001, COMMUN ACM, V44, P38, DOI 10.1145/381641.381656
   Keim D. A., 2002, Information Visualization, V1, P20, DOI 10.1057/palgrave/ivs/9500003
   KEIM DA, 1994, IEEE COMPUT GRAPH, V14, P40, DOI 10.1109/38.310723
   Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847
   Keim DA, 2000, IEEE T VIS COMPUT GR, V6, P59, DOI 10.1109/2945.841121
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   LEBLANC J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P230, DOI 10.1109/VISUAL.1990.146386
   Lewis D., 1973, COUNTERFACTUALS
   Liu M., 2016, BETTER ANAL DEEP CON
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Lucic Ana, 2019, ACTIONABLE INTERPRET
   Madumal P., 2019, EXPLAINABLE REINFORC
   Malinsky D, 2018, PHILOS COMPASS, V13, DOI 10.1111/phc3.12470
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mothilal RK, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P607, DOI 10.1145/3351095.3372850
   Neuberg LG, 2003, ECONOMET THEOR, V19, P675, DOI 10.1017/S026646603004109
   Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.2307/2337329
   Pearl J, 2009, STAT SURV, V3, P96, DOI 10.1214/09-SS057
   Poyiadzi R., 2020, FACE: Feasible and actionable counterfactual explanations
   ProPublica, 2016, COMP SCOR
   Raifman J, 2020, COVID-19 US state policy database
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Seo J., 2005, RANK BY FEATURE FRAM
   Shimizu S., 2014, BEHAVIORMETRIKA, V41, P65, DOI [DOI 10.2333/BHMK.41.65, 10.2333/bhmk.41.65]
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SIMPSON DG, 1987, J AM STAT ASSOC, V82, P802, DOI 10.2307/2288789
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Spirtes P., 1990, C P ADV COMP SOC SCI
   Spirtes P., 2000, CAUSATION PREDICTION, V2nd
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   T. N. Y. Times, 2020, CORONAVIRUS COVID 19
   Tatu A, 2011, IEEE T VIS COMPUT GR, V17, P584, DOI 10.1109/TVCG.2010.242
   Wachter S., 2017, SSRN Electronic Journal, V31, DOI DOI 10.2139/SSRN.3063289
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wong PC, 2004, IEEE COMPUT GRAPH, V24, P20
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 73
TC 8
Z9 8
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 998
EP 1008
DI 10.1109/TVCG.2021.3114779
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KJ
UT WOS:000736740100002
PM 34587027
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Jamonnak, S
   Zhao, Y
   Huang, XY
   Amiruzzaman, M
AF Jamonnak, Suphanut
   Zhao, Ye
   Huang, Xinyi
   Amiruzzaman, Md
TI Geo-Context Aware Study of Vision-Based Autonomous Driving Models and
   Spatial Video Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Predictive models; Data models; Autonomous vehicles; Computational
   modeling; Analytical models; Data visualization; Tools; Visualization
   System; Spatial Video; Autonomous Driving; Vision-based Deep Learning
   Models
ID VISUAL EXPLORATION; MOVEMENT; ANALYTICS; TIME
AB Vision-based deep learning (DL) methods have made great progress in learning autonomous driving models from large-scale crowd-sourced video datasets. They are trained to predict instantaneous driving behaviors from video data captured by on-vehicle cameras. In this paper, we develop a geo-context aware visualization system for the study of Autonomous Driving Model (ADM) predictions together with large-scale ADM video data. The visual study is seamlessly integrated with the geographical environment by combining DL model performance with geospatial visualization techniques. Model performance measures can be studied together with a set of geospatial attributes over map views. Users can also discover and compare prediction behaviors of multiple DL models in both city-wide and street-level analysis, together with road images and video contents. Therefore, the system provides a new visual exploration platform for DL model designers in autonomous driving. Use cases and domain expert evaluation show the utility and effectiveness of the visualization system.
C1 [Jamonnak, Suphanut; Zhao, Ye; Huang, Xinyi] Kent State Univ, Kent, OH 44242 USA.
   [Amiruzzaman, Md] West Chester Univ, W Chester, PA USA.
C3 University System of Ohio; Kent State University; Kent State University
   Kent; Kent State University Salem; Pennsylvania State System of Higher
   Education (PASSHE); West Chester University of Pennsylvania
RP Jamonnak, S (corresponding author), Kent State Univ, Kent, OH 44242 USA.
EM sjamonna@kent.edu
RI Amiruzzaman, Amir;/H-8937-2019; Huang, Xinyi/AAD-7186-2021
OI Amiruzzaman, Md/0000-0002-2292-5798
FU Kent State University;  [NSF-1739491]
FX The authors wish to thank the anonymous reviewers. This work was partly
   supported by NSF-1739491 and Kent State University graduate
   assistantship.
CR Al-Dohuki S, 2017, IEEE T VIS COMPUT GR, V23, P11, DOI 10.1109/TVCG.2016.2598416
   Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   Arras Leila, 2016, Rep4NLP @ACL, DOI 10.18653/v1/W16-1601
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Becker S., 2018, INTERPRETING EXPLAIN
   Bennett J, 2010, OPENSTREETMAP
   Bojarski M., 2017, EXPLAINING DEEP NEUR
   Bojarski M, 2018, IEEE INT CONF ROBOT, P4701
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyandin I, 2011, COMPUT GRAPH FORUM, V30, P971, DOI 10.1111/j.1467-8659.2011.01946.x
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Cordts M., 2015, CVPR WORKSH FUT DAT, P1
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gou L., IEEE T VIS COMPUT GR, V27, P261
   Grun F., 2016, Comput Graphics Forum
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   He Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P171, DOI 10.1109/VAST.2011.6102455
   Hecker S, 2018, LECT NOTES COMPUT SC, V11211, P449, DOI 10.1007/978-3-030-01234-2_27
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Huang XY, 2021, COMPUT GRAPH FORUM, V40, P227, DOI 10.1111/cgf.14302
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Jamonnak S, 2020, INT J GEOGR INF SCI, V34, P2115, DOI 10.1080/13658816.2020.1737700
   Jaritz M, 2018, IEEE INT CONF ROBOT, P2070
   Kapler T., 2005, Information Visualization, V4, P136, DOI 10.1057/palgrave.ivs.9500097
   Karpathy A., ConvNetJS: Deep learning in your browser
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Li Jie, 2020, IEEE Trans Vis Comput Graph, V26, P1789, DOI 10.1109/TVCG.2018.2882449
   Lin M., 2014, P INT C LEARN REPR, P1
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Miranda F, 2018, IEEE T VIS COMPUT GR, V24, P1394, DOI 10.1109/TVCG.2017.2671341
   Ning H, 2022, ENVIRON PLAN B-URBAN, V49, P7, DOI 10.1177/2399808321995817
   Perot E, 2017, IEEE COMPUT SOC CONF, P474, DOI 10.1109/CVPRW.2017.64
   Phan D, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P219, DOI 10.1109/INFVIS.2005.1532150
   Pomerleau DA., 1989, Adv. neural Inf. Process. Syst, DOI DOI 10.5555/2969735.2969771
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Sallab A.E., 2017, Electronic Imaging, V29, P70, DOI 10.2352/ISSN.2470-1173.2017.19.AVM-023
   Samek W., 2019, EXPLAINABLE AI INTER, P5, DOI [10.1007/978-3-030-28954-6_1, DOI 10.1007/978-3-030-28954-6_1]
   Santana E., 2016, ARXIV PREPRINT ARXIV
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen QK, 2019, INT J CONTROL, V92, P317, DOI 10.1080/00207179.2017.1352104
   Simonyan K., 2013, PREPRINT
   Springenberg J., 2015, ARXIV
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sturm I, 2016, J NEUROSCI METH, V274, P141, DOI 10.1016/j.jneumeth.2016.10.008
   Tomar S., 2006, LINUX J, V2006, P10
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wood J, 2007, IEEE T VIS COMPUT GR, V13, P1176, DOI 10.1109/TVCG.2007.70570
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Xu HZ, 2017, PROC CVPR IEEE, P3530, DOI 10.1109/CVPR.2017.376
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou H, 2019, SUSTAIN CITIES SOC, V50, DOI 10.1016/j.scs.2019.101605
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
NR 65
TC 18
Z9 19
U1 3
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1019
EP 1029
DI 10.1109/TVCG.2021.3114853
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000099
PM 34596546
OA Green Submitted
DA 2024-11-06
ER

PT J
AU He, WB
   Zou, LC
   Shekar, AK
   Gou, L
   Ren, L
AF He, Wenbin
   Zou, Lincan
   Shekar, Arvind Kumar
   Gou, Liang
   Ren, Liu
TI <i>Where Can We Help</i>? A Visual Analytics Approach to Diagnosing and
   Improving Semantic Segmentation of Movable Objects
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Semantics; Image segmentation; Autonomous vehicles; Analytical models;
   Robustness; Visual analytics; Data models; Model diagnosis; semantic
   segmentation; spatial representation learning; adversarial learning;
   autonomous driving
AB Semantic segmentation is a critical component in autonomous driving and has to be thoroughly evaluated due to safety concerns. Deep neural network (DNN) based semantic segmentation models are widely used in autonomous driving. However, it is challenging to evaluate DNN-based models due to their black-box-like nature, and it is even more difficult to assess model performance for crucial objects, such as lost cargos and pedestrians, in autonomous driving applications. In this work, we propose VASS, a Visual Analytics approach to diagnosing and improving the accuracy and robustness of Semantic Segmentation models, especially for critical objects moving in various driving scenes. The key component of our approach is a context-aware spatial representation learning that extracts important spatial information of objects, such as position, size, and aspect ratio, with respect to given scene contexts. Based on this spatial representation, we first use it to create visual summarization to analyze models' performance. We then use it to guide the generation of adversarial examples to evaluate models' spatial robustness and obtain actionable insights. We demonstrate the effectiveness of VASS via two case studies of lost cargo detection and pedestrian detection in autonomous driving. For both cases, we show quantitative evaluation on the improvement of models' performance with actionable insights obtained from VASS.
C1 [He, Wenbin; Zou, Lincan; Gou, Liang; Ren, Liu] Robert Bosch Res & Technol Ctr, Cambridge, MA 02139 USA.
   [Shekar, Arvind Kumar] Robert Bosch GmbH, Gerlingen, Germany.
C3 Bosch; Bosch
RP He, WB (corresponding author), Robert Bosch Res & Technol Ctr, Cambridge, MA 02139 USA.
EM wenbin.he2@us.bosch.com; lincan.zou@us.bosch.com;
   arvindkumar.shekar@de.bosch.com; liang.gou@us.bosch.com;
   liu.ren@us.bosch.com
RI Shekar, Arvind/AAA-3366-2019
OI Shekar, Arvind Kumar/0000-0002-5853-5310
CR Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   [Anonymous], P INT C LEARN REPR W
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Burgess C.P., 2018, Understanding disentangling in Beta-vae
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dreossi T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2071
   Ghiasi G., 2020, arXiv:2012.07177
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Goodfellow I J, 2015, P 3 INT C LEARN REPR
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He WB, 2020, IEEE PAC VIS SYMP, P36, DOI 10.1109/PacificVis48177.2020.7127
   He XM, 2004, PROC CVPR IEEE, P695
   Ilyas Andrew, 2018, PMLR, V80, P2142
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kurakin A., 2019, 5 INT C LEARN REPR I, P1
   Lee Donghoon, 2018, ADV NEUR IN
   Li W, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aaw0863
   Li YD, 2019, PR MACH LEARN RES, V97
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   NAJMAN L, 1994, SIGNAL PROCESS, V38, P99, DOI 10.1016/0165-1684(94)90059-0
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pinggera P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1099, DOI 10.1109/IROS.2016.7759186
   Pu MY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P483, DOI 10.1145/3240508.3240542
   Raidou R. G., 2016, P EG VIS COMP BIOL M, P193
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Simonyan K., 2013, PREPRINT
   Sohn K, 2015, ADV NEUR IN, V28
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Szegedy C., 2014, P INT C LEARN REPR
   Tripathi S, 2019, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2019.00055
   von Landesberger T, 2013, VISUAL COMPUT, V29, P893, DOI 10.1007/s00371-013-0852-y
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wierstra D, 2014, J MACH LEARN RES, V15, P949
   Zhang H., 2017, ARXIV PREPRINT ARXIV
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 52
TC 21
Z9 23
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1040
EP 1050
DI 10.1109/TVCG.2021.3114855
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000100
PM 34587077
DA 2024-11-06
ER

PT J
AU Deng, ZK
   Weng, D
   Xie, X
   Bao, J
   Zheng, Y
   Xu, ML
   Chen, W
   Wu, YC
AF Deng, Zikun
   Weng, Di
   Xie, Xiao
   Bao, Jie
   Zheng, Yu
   Xu, Mingliang
   Chen, Wei
   Wu, Yingcai
TI Compass: Towards Better Causal Analysis of Urban Time Series
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time series analysis; Visual analytics; Compass; Air pollution;
   Correlation; Urban planning; Indexes; Visual causal analysis; urban time
   series; causal graph analysis
ID VISUAL ANALYTICS APPROACH; GRANGER CAUSALITY; VISUALIZATION; NETWORKS;
   SELECTION; SYSTEM; MODEL; USER
AB The spatial time series generated by city sensors allow us to observe urban phenomena like environmental pollution and traffic congestion at an unprecedented scale. However, recovering causal relations from these observations to explain the sources of urban phenomena remains a challenging task because these causal relations tend to be time-varying and demand proper time series partitioning for effective analyses. The prior approaches extract one causal graph given long-time observations, which cannot be directly applied to capturing, interpreting, and validating dynamic urban causality. This paper presents Compass, a novel visual analytics approach for in-depth analyses of the dynamic causality in urban time series. To develop Compass, we identify and address three challenges: detecting urban causality, interpreting dynamic causal relations, and unveiling suspicious causal relations. First, multiple causal graphs over time among urban time series are obtained with a causal detection framework extended from the Granger causality test. Then, a dynamic causal graph visualization is designed to reveal the time-varying causal relations across these causal graphs and facilitate the exploration of the graphs along the time. Finally, a tailored multi-dimensional visualization is developed to support the identification of spurious causal relations, thereby improving the reliability of causal analyses. The effectiveness of Compass is evaluated with two case studies conducted on the real-world urban datasets, including the air pollution and traffic speed datasets, and positive feedback was received from domain experts.
C1 [Deng, Zikun; Weng, Di; Chen, Wei; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou & Zhejiang Lab, Hangzhou, Peoples R China.
   [Xie, Xiao] Zhejiang Univ, Dept Sport Sci, Hangzhou, Peoples R China.
   [Bao, Jie; Zheng, Yu] JD Tech, JD Intelligent Cities Res, Beijing, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Henan Inst Adv Technol, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhengzhou University;
   Zhengzhou University
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou & Zhejiang Lab, Hangzhou, Peoples R China.
EM zikun_rain@zju.edu.cn; dweng@zju.edu.cn; xxie@zju.edu.cn; baojie@jd.com;
   msyuzheng@outlook.com; iexumingliang@zzu.edu.cn; chenwei@cad.zju.edu.cn;
   ycwu@zju.edu.cn
RI Zheng, Yu/GRJ-5808-2022; wang, yixuan/JGM-3893-2023; Weng,
   Di/ABG-7408-2020; Chen, Wei/AAR-9817-2020; Deng, Zikun/IQT-3106-2023
OI Deng, Zikun/0000-0002-4477-5292; Weng, Di/0000-0003-2712-7274
FU NSFC [62072400]; Zhejiang Provincial Natural Science Foundation
   [LR18F020001]; Collaborative Innovation Center of Artificial
   Intelligence by MOE; Zhejiang Provincial Government (ZJU)
FX The work was supported by NSFC (62072400), Zhejiang Provincial Natural
   Science Foundation (LR18F020001), and the Collaborative Innovation
   Center of Artificial Intelligence by MOE and Zhejiang Provincial
   Government (ZJU).
CR Accorsi P, 2014, IEEE CONF VIS ANAL, P123, DOI 10.1109/VAST.2014.7042488
   Andrienko G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P161, DOI 10.1109/VAST.2011.6102454
   Andrienko G, 2017, IEEE T INTELL TRANSP, V18, P2232, DOI 10.1109/TITS.2017.2683539
   Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   Bach B., 2014, EuroVis-STARs, DOI [10.2312/eurovisstar.20141171, DOI 10.2312/EUROVISSTAR.20141171, 10.2312/EUROVISSTAR.20141171]
   Bae J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P64, DOI 10.5220/0006102300640074
   Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bello JP, 2019, COMMUN ACM, V62, P68, DOI 10.1145/3224204
   Bok J., 2020, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2020.3038446
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Cao N, 2018, IEEE T VIS COMPUT GR, V24, P23, DOI 10.1109/TVCG.2017.2744419
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   Chirigati F, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1011, DOI 10.1145/2882903.2915245
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   Deng Z., 2021, IEEE T VIS COMPUT GR
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dufour JM, 1998, ECONOMETRICA, V66, P1099, DOI 10.2307/2999631
   Eichler M, 2007, J ECONOMETRICS, V137, P334, DOI 10.1016/j.jeconom.2005.06.032
   Elmqvist N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P189, DOI 10.1109/INFVIS.2003.1249025
   Elmqvist N., 2003, Proc. 1st ACM Symp. Softw. Vis, P17
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Filipov V, 2021, VIS INFORM, V5, P45, DOI 10.1016/j.visinf.2021.01.001
   Geweke J., 1984, Handbook of Econometrics, V2, P1101
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Granger CWJ, 2004, AM ECON REV, V94, P421, DOI 10.1257/0002828041464669
   HAWKES AG, 1971, J ROY STAT SOC B, V33, P438
   Hlavácková-Schindler K, 2007, PHYS REP, V441, P1, DOI 10.1016/j.physrep.2006.12.004
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Jones E., 2001, SciPy: Open source scientific tools for 742 Python, DOI DOI 10.1214/14-STS511
   Kadaba NR, 2007, IEEE T VIS COMPUT GR, V13, P1254, DOI 10.1109/TVCG.2007.70528
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Lee C, 2020, IEEE T VIS COMPUT GR, V26, P3133, DOI 10.1109/TVCG.2019.2922597
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Li Q, 2020, COMPUT GRAPH FORUM, V39, P483, DOI 10.1111/cgf.13996
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Liao BB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P537, DOI 10.1145/3219819.3219895
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu LY, 2021, J VISUAL-JAPAN, V24, P331, DOI 10.1007/s12650-020-00713-3
   Liu QQ, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P76, DOI 10.1109/VIS47514.2020.00022
   Lozano A, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P587
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   Matasov V, 2020, FORESTS, V11, DOI 10.3390/f11070775
   Miranda F, 2017, IEEE T VIS COMPUT GR, V23, P791, DOI 10.1109/TVCG.2016.2598585
   Munzner T., 2014, AK Peters Visualization Series
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   Palomo C, 2016, IEEE T VIS COMPUT GR, V22, P170, DOI 10.1109/TVCG.2015.2467592
   Pearl J, 2009, STAT SURV, V3, P96, DOI 10.1214/09-SS057
   Pi M, 2021, IEEE T VIS COMPUT GR, V27, P2186, DOI 10.1109/TVCG.2019.2940580
   Pierce D.A., 1977, J. Econ., V5, P265, DOI [10.1016/0304-4076(77)90039-2, DOI 10.1016/0304-4076(77)90039-2]
   Qu DZ, 2020, J VISUAL-JAPAN, V23, P1129, DOI 10.1007/s12650-020-00683-6
   Nguyen QV, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.09.004
   Ramsey Joseph, 2017, Int J Data Sci Anal, V3, P121, DOI 10.1007/s41060-016-0032-z
   Runge J, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau4996
   Scheepens R, 2016, IEEE T VIS COMPUT GR, V22, P379, DOI 10.1109/TVCG.2015.2467112
   Seth AK, 2015, J NEUROSCI, V35, P3293, DOI 10.1523/JNEUROSCI.4399-14.2015
   Shi L, 2021, IEEE T VIS COMPUT GR, V27, P3881, DOI 10.1109/TVCG.2020.2992200
   SIMS CA, 1980, ECONOMETRICA, V48, P1, DOI 10.2307/1912017
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Wang H, 2019, IEEE T VIS COMPUT GR, V25, P331, DOI 10.1109/TVCG.2018.2864844
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wang M, 2021, VIS INFORM, V5, P13, DOI 10.1016/j.visinf.2021.03.002
   Wang Y., 2021, IEEE T VIS COMPUT GR
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P475, DOI 10.1109/TVCG.2021.3114790
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Wu YC, 2018, IEEE T VIS COMPUT GR, V24, P2758, DOI 10.1109/TVCG.2017.2764459
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xu HT, 2016, PR MACH LEARN RES, V48
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Zhang K, 2013, SCI TOTAL ENVIRON, V450, P307, DOI 10.1016/j.scitotenv.2013.01.074
   Zhang TY, 2021, J VISUAL-JAPAN, V24, P1051, DOI 10.1007/s12650-020-00741-z
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zheng Y, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2629592
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhu HY, 2021, VIS INFORM, V5, P51, DOI 10.1016/j.visinf.2021.06.002
   Zhu JY, 2018, IEEE T BIG DATA, V4, P571, DOI 10.1109/TBDATA.2017.2723899
NR 89
TC 23
Z9 25
U1 3
U2 53
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1051
EP 1061
DI 10.1109/TVCG.2021.3114875
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XU0IB
UT WOS:000733959000101
PM 34596550
DA 2024-11-06
ER

PT J
AU Li, CH
   Baciu, G
   Wang, YZ
   Chen, JJ
   Wang, CB
AF Li, Chenhui
   Baciu, George
   Wang, Yunzhe
   Chen, Junjie
   Wang, Changbo
TI DDLVis: Real-time Visual Query of Spatiotemporal Data Distribution via
   Density Dictionary Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Spatiotemporal phenomena; Data visualization; Real-time
   systems; Machine learning; Estimation; Encoding; Visual query;
   information visualization; spatiotemporal data; data compression;
   interaction; density map
ID K-SVD; VISUALIZATION; EXPLORATION; DISPLAY; MAPS
AB Visual query of spatiotemporal data is becoming an increasingly important function in visual analytics applications. Various works have been presented for querying large spatiotemporal data in real time. However, the real-time query of spatiotemporal data distribution is still an open challenge. As spatiotemporal data become larger, methods of aggregation, storage and querying become critical. We propose a new visual query system that creates a low-memory storage component and provides real-time visual interactions of spatiotemporal data. We first present a peak-based kernel density estimation method to produce the data distribution for the spatiotemporal data. Then a novel density dictionary learning approach is proposed to compress temporal density maps and accelerate the query calculation. Moreover, various intuitive query interactions are presented to interactively gain patterns. The experimental results obtained on three datasets demonstrate that the presented system offers an effective query for visual analytics of spatiotemporal data.
C1 [Li, Chenhui; Chen, Junjie; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
   [Baciu, George] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
   [Wang, Yunzhe] Suzhou Univ Sci & Technol, Suzhou, Peoples R China.
C3 East China Normal University; Hong Kong Polytechnic University; Suzhou
   University of Science & Technology
RP Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
EM chli@cs.ecnu.edu.cn; cbwang@cs.ecnu.edu.cn
RI Baciu, George/AAU-7143-2021; Li, Chenhui/AAR-3682-2020
FU NSFC [61802128, 62072183]
FX The authors wish to acknowledge the support from NSFC under Grants (No.
   61802128 and 62072183).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2013, X MAP
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bookstein A, 2002, INFORM RETRIEVAL, V5, P353, DOI 10.1023/A:1020499411651
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Correll M, 2016, IEEE CONF VIS ANAL, P131, DOI 10.1109/VAST.2016.7883519
   Derthick M., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P189, DOI 10.1145/263407.263545
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Ester M., 1996, P KDD, P226
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Guo T, 2018, INT CONF MANAGE DATA, P567, DOI 10.1145/3183713.3183738
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Janicke Stefan., 2013, Computer Vision, Imaging and Computer Graphics. Theory and Application, P160, DOI [10.1007/978-3-642-38241-3_11, DOI 10.1007/978-3-642-38241-3_11]
   Johansson J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P125, DOI 10.1109/INFVIS.2005.1532138
   Khelifi F, 2010, IEEE T IMAGE PROCESS, V19, P981, DOI 10.1109/TIP.2009.2038637
   Kim HR, 2014, COMPUT GRAPH FORUM, V33, P309, DOI 10.1111/cgf.12499
   Kim S, 2018, IEEE T VIS COMPUT GR, V24, P1287, DOI 10.1109/TVCG.2017.2666146
   Kister U, 2017, COMPUT GRAPH FORUM, V36, P503, DOI 10.1111/cgf.13206
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Li CH, 2018, IEEE T VIS COMPUT GR, V24, P1381, DOI 10.1109/TVCG.2017.2668409
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Lu YF, 2016, IEEE T VIS COMPUT GR, V22, P220, DOI 10.1109/TVCG.2015.2467991
   Lukasczyk J, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820817
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   MacQueen J., 1967, P 5 BERKELEY S MATH, VVolume 1, P281
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   Mei HH, 2020, IEEE T VIS COMPUT GR, V26, P1161, DOI 10.1109/TVCG.2019.2934800
   Miranda F, 2018, IEEE T VIS COMPUT GR, V24, P1394, DOI 10.1109/TVCG.2017.2671341
   Pahins CAL, 2020, IEEE T VIS COMPUT GR, V26, P3314, DOI 10.1109/TVCG.2019.2914446
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Papyan V, 2017, J MACH LEARN RES, V18, P1
   Perlin K, 2002, ACM T GRAPHIC, V21, P681, DOI 10.1145/566570.566636
   Perrot A, 2015, SYMP LARG DATA ANAL, P99, DOI 10.1109/LDAV.2015.7348077
   Pu YC, 2016, ADV NEUR IN, V29
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Sadeghi M, 2013, IEEE SIGNAL PROC LET, V20, P1195, DOI 10.1109/LSP.2013.2285218
   Scheepens R, 2011, IEEE T VIS COMPUT GR, V17, P2518, DOI 10.1109/TVCG.2011.181
   Shurkhovetskyy G, 2018, COMPUT GRAPH FORUM, V37, P125, DOI 10.1111/cgf.13237
   Silverman B. W., 1986, Density Estimation for Statistics and Data Analysis
   Slingsby A, 2016, COMPUT GRAPH FORUM, V35, P471, DOI 10.1111/cgf.12923
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang GZ, 2020, IEEE CONF VIS ANAL, P72, DOI 10.1109/VAST50239.2020.00012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yankelevsky Y, 2017, INT CONF ACOUST SPEE, P4421, DOI 10.1109/ICASSP.2017.7952992
   Zhao JH, 2021, IEEE T VIS COMPUT GR, V27, P2000, DOI 10.1109/TVCG.2019.2945960
   Zhao Y, 2020, IEEE T VIS COMPUT GR, V26, P590, DOI 10.1109/TVCG.2019.2934655
NR 59
TC 8
Z9 10
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1062
EP 1072
DI 10.1109/TVCG.2021.3114762
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000102
PM 34587020
DA 2024-11-06
ER

PT J
AU Chundury, P
   Patnaik, B
   Reyazuddin, Y
   Tang, C
   Lazar, J
   Elmqvist, N
AF Chundury, Pramod
   Patnaik, Biswaksen
   Reyazuddin, Yasmin
   Tang, Christine
   Lazar, Jonathan
   Elmqvist, Niklas
TI Towards Understanding Sensory Substitution for Accessible Visualization:
   An Interview Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Interviews; Blindness; Training;
   Navigation; Layout; Accessibility; blind users; sonification;
   visualization; spatial layouts; sound perception
ID VISUAL IMPAIRMENTS; INFORMATION; SONIFICATION; TEACHERS; STUDENTS;
   IMAGES; 2D
AB For all its potential in supporting data analysis, particularly in exploratory situations, visualization also creates barriers: accessibility for blind and visually impaired individuals. Regardless of how effective a visualization is, providing equal access for blind users requires a paradigm shift for the visualization research community. To enact such a shift, it is not sufficient to treat visualization accessibility as merely another technical problem to overcome. Instead, supporting the millions of blind and visually impaired users around the world who have equally valid needs for data analysis as sighted individuals requires a respectful, equitable, and holistic approach that includes all users from the onset. In this paper, we draw on accessibility research methodologies to make inroads towards such an approach. We first identify the people who have specific insight into how blind people perceive the world: orientation and mobility (O&M) experts, who are instructors that teach blind individuals how to navigate the physical world using non-visual senses. We interview 10 O&M experts-all of them blind-to understand how best to use sensory substitution other than the visual sense for conveying spatial layouts. Finally, we investigate our qualitative findings using thematic analysis. While blind people in general tend to use both sound and touch to understand their surroundings, we focused on auditory affordances and how they can be used to make data visualizations accessible-using sonification and auralization. However, our experts recommended supporting a combination of senses-sound and touch-to make charts accessible as blind individuals may be more familiar with exploring tactile charts. We report results on both sound and touch affordances, and conclude by discussing implications for accessible visualization for blind individuals.
C1 [Chundury, Pramod; Patnaik, Biswaksen; Lazar, Jonathan; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Reyazuddin, Yasmin] Natl Federat Blind, Baltimore, MD USA.
   [Tang, Christine] Poolesville High Sch, Poolesville, MD USA.
C3 University System of Maryland; University of Maryland College Park
RP Chundury, P (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM pchundur@umd.edu; bpatnaik@umd.edu; yasmin81065@gmail.com;
   christinetang075@gmail.com; jlazar@umd.edu; elm@umd.edu
OI Elmqvist, Niklas/0000-0001-5805-5301
CR Ackland Peter, 2017, Community Eye Health, V30, P71
   Ahmetovic D, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418041
   Alty J. L., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P574, DOI 10.1145/274644.274721
   [Anonymous], Convert audio and video to text
   Baker CatherineM., 2014, Proceedings of the 16th International ACM SIGACCESS Conference on Computers Accessibility - ASSETS '14, P75, DOI DOI 10.1145/2661334.2661366
   Batch A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376733
   Bennett CL, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300528, 10.1109/mms48040.2019.9157327]
   Bertin J., 1983, Semiology of Graphics
   Blattner M. M., 1989, Human-Computer Interaction, V4, P11, DOI 10.1207/s15327051hci0401_1
   Bowman, 2015, THESIS U ALABAMA
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brittell M., 2018, SEEKING REFERENCE FR
   Brown L.M., 2003, Design guidelines for audio presentation of graphs and tables
   Brown Lorna., 2002, Proceedings of the 16th British HCI Conference, P6
   Card SK., 1999, READINGS INFORM VISU
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Cook A.M., 2014, Assistive Technologies: Principles and Practice
   Davies JD, 2020, POLIT CULT EUR 1650, P1
   Dexter D., 2012, MATHTRAX
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/01449290110108659, 10.1080/014492901101008659]
   Elzer S, 2007, WEBIST 2007: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, VOL WIA, P59
   Engel C, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P186, DOI 10.1145/3316782.3316793
   FACCOMMAANHA AR, 2020, ACM T ACCESS COMPUT, V13, DOI DOI 10.1145/3395769
   Ferres L, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2533682.2533683
   Fitzpatrick D., 2017, P WEB ALL C FUT ACC, P1, DOI 10.1145/3058555.3058564
   Forbes, 2019, EXPLORING SONIC PARA
   Franklin KM, 2003, IEEE INFOR VIS, P4, DOI 10.1109/IV.2003.1217949
   Furness R. K., 1990, J AUDIO ENG SOC
   Gaver William W., 1986, Hum.- Comput. Interact., V2, P167, DOI [DOI 10.1207/S15327051HCI02023, 10.1207/s15327051hci0202_3, DOI 10.1207/S15327051HCI0202_3]
   Gerino A, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P13, DOI 10.1145/2700648.2809848
   Geronazzo M, 2016, INT J HUM-COMPUT ST, V85, P4, DOI 10.1016/j.ijhcs.2015.08.004
   Goncu C, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P388, DOI 10.1145/2736277.2741660
   Guha ML., 2008, Proceedings of the 7th International Conference on Interaction Design and Children, IDC 2008, P61, DOI DOI 10.1145/1463689.1463719
   Guinness D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P318, DOI 10.1145/3308561.3353804
   Hermann T, 2004, P IEEE, V92, P730, DOI 10.1109/JPROC.2004.825904
   Hermann Thomas, 2011, The sonification handbook
   Hersh M, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3375279
   Holloway L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173772
   KAPLAN STEPHEN., 1973, IMAGE ENV, P63
   Keenan RY, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3378576
   Kolb D.A., 2014, Experiential learning: Experience as the source of learning and development
   Kuipers B., 1983, SPATIAL ORIENTATION, P345, DOI [10.1007/978-1-4615-9325-6, DOI 10.1007/978-1-4615-9325-6]
   Kuipers B., 1978, COGNITIVE SCI, V2, P129, DOI [10.1016/S0364-0213(78)80003-2, DOI 10.1016/S0364-0213(78)80003-2]
   Lahav O., 2012, Processdings of the 9th International Conference on Disability, Virtual Reality Associated Technologies, P393, DOI DOI 10.3233/RNN-2012-110219
   Lazar J., 2017, RES METHODS HUMAN CO
   Lazar Jonathan., 2015, ENSURING DIGITAL ACC
   Loeliger E, 2014, INTERACT COMPUT, V26, P403, DOI 10.1093/iwc/iwt042
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/visual.2019.8933762, 10.1109/VISUAL.2019.8933762]
   Maidenbaum S, 2015, P IEEE VIRT REAL ANN, P233, DOI 10.1109/VR.2015.7223381
   Maidenbaum S, 2014, NEUROSCI BIOBEHAV R, V41, P3, DOI 10.1016/j.neubiorev.2013.11.007
   Mankoff J, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P3
   Mele ML, 2010, LECT NOTES COMPUT SC, V6179, P351, DOI 10.1007/978-3-642-14097-6_56
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Noordzij ML, 2006, COGNITION, V100, P321, DOI 10.1016/j.cognition.2005.05.006
   ODonovan A. E., 2011, PRINCIPLES APPL SPAT, P337, DOI [10. 1142/9789814299312 0027, DOI 10.1142/9789814299312_0027]
   PASSINI R, 1988, ENVIRON BEHAV, V20, P227, DOI 10.1177/0013916588202006
   POLLACK I, 1954, J ACOUST SOC AM, V26, P155, DOI 10.1121/1.1907300
   Potluri V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445040
   Ramloll R, 2001, BCS CONF SERIES, P515
   RIGAS DI, 1997, P IFIP TC13 INT C HU, V96, P228
   Roberts, 2007, SONIFICATION SPATIAL
   Rosenblum LP, 2018, J VISUAL IMPAIR BLIN, V112, P475
   Rossiter D., 1996, Proceedings. Visualization '96 (IEEE Cat. No.96CB36006), P351, DOI 10.1109/VISUAL.1996.568129
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Spiel K, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375150
   Taher F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3237, DOI 10.1145/2702123.2702604
   Tversky B, 2003, ENVIRON BEHAV, V35, P66, DOI 10.1177/0013916502238865
   Vecchi T, 1998, MEMORY, V6, P91, DOI 10.1080/741941601
   Wai Yu, 2002, ASSETS 2002. Proceedings of the Fifth International ACM SIGCAPH Conference on Assistive Technologies, P57, DOI 10.1145/638249.638261
   Walker, 2002, TICK MARKS AXES LABE
   Walker B. N., 2005, ACM Trans. Appl. Percept, V2, P407, DOI [10.1145/1101530.1101534, DOI 10.1145/1101530.1101534]
   Waller D, 2007, PSYCHOL RES-PSYCH FO, V71, P322, DOI 10.1007/s00426-006-0087-x
   WALMSLEY DJ, 1990, AUST GEOGR, V21, P164, DOI 10.1080/00049189008703012
   Ward J, 2010, CONSCIOUS COGN, V19, P492, DOI 10.1016/j.concog.2009.10.006
   Wobbrock Jacob O, 2011, ACM Transactions on Accessible Computing (TACCESS), V3, P1, DOI [10.1145/1952383.1952384, DOI 10.1145/1952383.1952384]
   Xin Qian, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382946
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu, 2007, DEVELOPING SOUNDS MU
   Zebehazy KT, 2014, J VISUAL IMPAIR BLIN, V108, P5
   Zhao, 2006, THESIS U MARYLAND
   Zhao H, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1352782.1352786
   Zou H, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P107, DOI 10.1145/2700648.2809862
NR 82
TC 22
Z9 25
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1084
EP 1094
DI 10.1109/TVCG.2021.3114829
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XU0IB
UT WOS:000733959000103
PM 34587061
DA 2024-11-06
ER

PT J
AU Jung, C
   Mehta, S
   Kulkarni, A
   Zhao, YH
   Kim, YS
AF Jung, Crescentia
   Mehta, Shubham
   Kulkarni, Atharva
   Zhao, Yuhang
   Kim, Yea-Seul
TI Communicating Visualizations without Visuals: Investigation of
   Visualization Alternative Text for People with Visual Impairments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Guidelines; Data visualization; Software; Social
   networking (online); Image color analysis; Web pages; accessible
   visualization; assistive technologies; alternative text for graphics
AB Alternative text is critical in communicating graphics to people who are blind or have low vision. Especially for graphics that contain rich information, such as visualizations, poorly written or an absence of alternative texts can worsen the information access inequality for people with visual impairments. In this work, we consolidate existing guidelines and survey current practices to inspect to what extent current practices and recommendations are aligned. Then, to gain more insight into what people want in visualization alternative texts, we interviewed 22 people with visual impairments regarding their experience with visualizations and their information needs in alternative texts. The study findings suggest that participants actively try to construct an image of visualizations in their head while listening to alternative texts and wish to carry out visualization tasks (e.g., retrieve specific values) as sighted viewers would. The study also provides ample support for the need to reference the underlying data instead of visual elements to reduce users' cognitive burden. Informed by the study, we provide a set of recommendations to compose an informative alternative text.
C1 [Jung, Crescentia; Mehta, Shubham; Kulkarni, Atharva; Zhao, Yuhang; Kim, Yea-Seul] Univ Wisconsin, Madison, WI 53706 USA.
C3 University of Wisconsin System; University of Wisconsin Madison
RP Jung, C (corresponding author), Univ Wisconsin, Madison, WI 53706 USA.
EM csjung@wisc.edu; smehta23@wisc.edu; akulkarni23@wisc.edu;
   yuhang.zhao@cs.wisc.edu; yeaseul.kim@cs.wisc.edu
RI Mehta, Shubham/KII-0872-2024
OI Jung, Crescentia/0000-0003-4434-1723; Kim, Yea-Seul/0000-0003-1854-1537
CR A. F. for the Blind, SCREEN READ
   Adobe, ADD ALT TEXT SUPPL I
   AlRoobaea R, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P48, DOI 10.1109/SAI.2014.6918171
   [Anonymous], 2020, SPECIFIC GUIDELINES
   [Anonymous], 2015, CNBC
   [Anonymous], ALT TEXT
   [Anonymous], 2018, Web Content Accessibility Guidelines (WCAG)
   [Anonymous], 2018, CHARTS ACCESSIBILITY
   Apple, VOIC US GUID
   Bennett CL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173650
   Bernardi R, 2016, J ARTIF INTELL RES, V55, P409, DOI 10.1613/jair.4900
   Berners-Lee T, 1995, HTML 2 0 MAT
   Bigham J. P., 2010, VIZWIZ NEARLY REAL T, P10
   Bird S., 2009, Natural Language Processing with Python
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Burns Richard, 2013, User Modeling, Adaptation, and Personalization. 21th International Conference, UMAP 2013. Proceedings., P114, DOI 10.1007/978-3-642-38844-6_10
   Card SK., 1999, READINGS INFORM VISU
   Chen C., 2019, CoRR, V6
   Choi Stephen H., 2010, CHI 10 EXTENDED ABST, P3445, DOI DOI 10.1145/1753846.1753999
   Corio M, GENERATION TEXTS INF, P10
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   D. visualization guidelines CFPB Design System, D VISUALIZATION GUID
   de Haan Y, 2018, JOURNALISM STUD, V19, P1293, DOI 10.1080/1461670X.2016.1267592
   Demir S, 2010, NEW REV HYPERMEDIA M, V16, P245, DOI 10.1080/13614568.2010.534186
   Elzer S, 2007, WEBIST 2007: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, VOL WIA, P59
   Engel C, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P186, DOI 10.1145/3316782.3316793
   Engel C, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P197, DOI 10.1145/3056540.3064955
   Engel C, 2018, LECT NOTES COMPUT SC, V10897, P177, DOI 10.1007/978-3-319-94274-2_24
   Engel C, 2017, LECT NOTES COMPUT SC, V10513, P187, DOI 10.1007/978-3-319-67744-6_12
   Fasciano Massimo, 1996, INT NAT LANG GEN C
   Fusco G, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P97, DOI 10.1145/2700648.2809868
   Gardner JA, 2006, LECT NOTES COMPUT SC, V4061, P1243
   Gleason C, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P549, DOI 10.1145/3308558.3313605
   Goncu C, 2011, LECT NOTES COMPUT SC, V6946, P30, DOI 10.1007/978-3-642-23774-4_5
   Granz Heather, 2013, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8009, P31, DOI 10.1007/978-3-642-39188-0_4
   Guinness D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P318, DOI 10.1145/3308561.3353804
   Hahn ME, 2019, J VISUAL IMPAIR BLIN, V113, P404, DOI 10.1177/0145482X19876463
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Help A. A, GET STARTED ANDROID
   Heuten W, 2006, INTERACTIVE 3D SONIF, V189, P164
   Hu M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P365, DOI 10.1145/2700648.2811330
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   KAHOU SE, 2017, ARXIV171007300
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim N, COMPUT GRAPH FORUM, V40, P2021
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Landau S., 2001, Information Technology and Disabilities, V7
   Law P.-M., 2020, ARXIV200813060
   Lazar J, 2013, J USABILITY STUD, V8, P93
   Microsoft, COMPL GUID NARR
   Microsoft, ADD ALT TEXT SHAP PI
   Mittal V. O, GENERATING EXPLANATO, P8
   Moraes Priscilla, 2014, P 16 INT ACM SIGACCE, P83, DOI DOI 10.1145/2661334.2661368
   Morris MR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173633
   Morris MR, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5506, DOI 10.1145/2858036.2858116
   N. Access, NVDA
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Obeid J., 2020, P 13 INT C NATURAL L, P138, DOI 10.48550/arXiv.2010.09142
   Panëels S, 2010, IEEE T HAPTICS, V3, P119, DOI [10.1109/TOH.2009.44, 10.1109/ToH.2009.44]
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Petrie Helen, 2005, P HUM COMP INT INT H, V71, P2
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Sakhardande P, 2019, LECT NOTES COMPUT SC, V11746, P247, DOI 10.1007/978-3-030-29381-9_16
   Salisbury E, 2017, SCALABLE SOCIAL ALT, P10
   Salisbury E, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5349
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Scientific F, JAWS
   Sharif A, 2018, CONSUM COMM NETWORK
   Stackoverflow, WHY DOES LINK NOT TA
   Stangl A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376404
   Taibbi M, 2014, LECT NOTES COMPUT SC, V8547, P537, DOI 10.1007/978-3-319-08596-8_84
   Upshot T, BOYS OUTPERFORM GIRL
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Voykinska V, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1584, DOI 10.1145/2818048.2820013
   W. H. Organization, GLOBAL DATA VISUAL I
   Walker B. N., 2010, ACM Trans. Access. Comput., V2, DOI DOI 10.1145/1714458.1714459
   Wall S, 2006, FEELING WHAT YOU HEA, P1123
   Watanabe T, 2018, LECT NOTES COMPUT SC, V10896, P628, DOI 10.1007/978-3-319-94277-3_97
   Watson L, USING ARIA ENHANCE S
   Wu P, 2010, LECT NOTES ARTIF INT, V6170, P220
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Wu SM, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1180, DOI 10.1145/2998181.2998364
   Yang Y, 2020, CHI 20, P1
   Yuhang Zhao, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134756
   Zhao H, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1352782.1352786
NR 85
TC 35
Z9 40
U1 3
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1095
EP 1105
DI 10.1109/TVCG.2021.3114846
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000104
PM 34591768
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Strobelt, H
   Kinley, J
   Krueger, R
   Beyer, J
   Pfister, H
   Rush, AM
AF Strobelt, Hendrik
   Kinley, Jambay
   Krueger, Robert
   Beyer, Johanna
   Pfister, Hanspeter
   Rush, Alexander M.
TI GenNI: Human-AI Collaboration for Data-Backed Text Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Visualization; Tools; Data models;
   Collaboration; Task analysis; Deep learning; Tabular Data; Text;
   Document Data; Machine Learning; Statistics; Modelling; Simulation
   Applications
AB Table2Text systems generate textual output based on structured data utilizing machine learning. These systems are essential for fluent natural language interfaces in tools such as virtual assistants; however, left to generate freely these ML systems often produce misleading or unexpected outputs. GenNI (Generation Negotiation Interface) is an interactive visual system for high-level human-AI collaboration in producing descriptive text. The tool utilizes a deep learning model designed with explicit control states. These controls allow users to globally constrain model generations, without sacrificing the representation power of the deep learning models. The visual interface makes it possible for users to interact with AI systems following a Refine-Forecast paradigm to ensure that the generation system acts in a manner human users find suitable. We report multiple use cases on two experiments that improve over uncontrolled generation approaches, while at the same time providing fine-grained control. A demo and source code are available at https://genni.vizhub.ai.
C1 [Strobelt, Hendrik] IBM Res, Cambridge, MA 02142 USA.
   [Strobelt, Hendrik] MIT IBM Watson AI Lab, Cambridge, MA 02142 USA.
   [Kinley, Jambay; Rush, Alexander M.] Cornell Univ, New York, NY 10021 USA.
   [Krueger, Robert; Beyer, Johanna; Pfister, Hanspeter] Harvard Univ, Cambridge, MA 02138 USA.
C3 International Business Machines (IBM); Cornell University; Harvard
   University
RP Strobelt, H (corresponding author), IBM Res, Cambridge, MA 02142 USA.; Strobelt, H (corresponding author), MIT IBM Watson AI Lab, Cambridge, MA 02142 USA.
EM hendrik.strobelt@ibm.com
OI Pfister, Hanspeter/0000-0002-3620-2582; Rush,
   Alexander/0000-0002-9900-1606
CR [Anonymous], 2017, ICML
   Belz A, 2007, HLTNAACL
   Bouayad-Agha N., 2011, ENLG
   Busemann S, 1998, FLEXIBLE SHALLOW APP
   C. D. C. Ltd, TABNINE COD FAST AI
   Cahill L., 2000, SEARCH REFERENCE ARC
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Chan A. T. S, 2020, P INT C LEARN REPR A
   Chen MD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5972
   Colin E., 2018, EMNLP, DOI [10.18653/v1/D18-1113, DOI 10.18653/V1/D18-1113]
   Deriu J., 2018, INLG, DOI [10.18653/v1/W18-6503, DOI 10.18653/V1/W18-6503]
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou LX, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P13
   Duboue PA, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P121
   Dusek O, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P45
   Fu Yao, 2020, ARXIV201114244
   Gao X, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P224
   Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P111
   Gehrmann S, 2020, IEEE T VIS COMPUT GR, V26, P884, DOI 10.1109/TVCG.2019.2934595
   Geldof S, 1997, ARCHITECTURE TEMPLAT
   Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   HOVY EH, 1993, ARTIF INTELL, V63, P341, DOI 10.1016/0004-3702(93)90021-3
   Howald B., 2013, P 10 INT C COMPUTATI
   Huggingface, 2021, WRIT TRANSF
   Iyyer M., 2018, P 2018 C N AM CHAPT, V1, P1875, DOI DOI 10.18653/V1/N18-1170
   Kale M, 2020, TEXT TO TEXT PRETRAI
   Karpathy A, 2015, CORR
   Keskar Nitish Shirish, 2019, ARXIV190905858
   Kingma DP, 2013, ARXIV
   Langkilde I., COLING, DOI [10.3115/980451.980963, DOI 10.3115/980451.980963]
   Lebret R., 2016, P 2016 C EMP METH NA, P1203, DOI DOI 10.18653/V1/D16-1128
   Li XL, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2731
   Luo FL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6020
   Madsen A., 2019, Distill, V4, pe16, DOI DOI 10.23915/DISTILL.00016
   McRoy S. W., 2003, Natural Language Engineering, V9, P381, DOI 10.1017/S1351324903003188
   Mei H. Y., 2016, P 2016 C N AM CHAPT, P720, DOI [DOI 10.18653/V1/N16-1086, 10.18653/v1/n16-1086]
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mnih A, 2014, PR MACH LEARN RES, V32, P1791
   Moore J. D., 1993, Computational Linguistics, V19, P651
   Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P201
   Oraby S, 2018, 19TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2018), P180
   Radford A., 2019, Language Models are Unsupervised Multitask Learners, P24
   Raffel C, 2020, J MACH LEARN RES, V21
   Reiter E., 1997, Natural Language Engineering, V3, P57, DOI 10.1017/S1351324997001502
   Reiter E., 1995, Nlg vs. templates
   Reiter E., 2000, Building natural language generation systems
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Rush AM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P335
   Shen TX, 2017, ADV NEUR IN, V30
   Shen X., 2020, P 58 ANN M ASS COMPU, P7155, DOI 10.18653/v1/2020.acl-main.641
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sutskever I, 2014, ADV NEUR IN, V27
   Theune M., 2001, Natural Language Engineering, V7, P47
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wiseman S., 2017, P 2017 C EMP METH NA, P2253
   Wiseman S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3174
   Wolf Thomas, 2019, CORR
   Zellers R., 2020, ARXIV 190512616
NR 63
TC 9
Z9 10
U1 7
U2 38
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1106
EP 1116
DI 10.1109/TVCG.2021.3114845
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000105
PM 34587072
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lohfink, AP
   Anton, SDD
   Leitte, H
   Garth, C
AF Lohfink, Anna-Pia
   Anton, Simon D. Duque
   Leitte, Heike
   Garth, Christoph
TI Knowledge Rocks: Adding Knowledge Assistance to Visualization Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Ontologies; Knowledge based systems; Lesions;
   Computer architecture; Rocks; Security; Knowledge-Assisted
   Visualization; Ontology; IT-Security
ID INFORMATION
AB We present Knowledge Rocks, an implementation strategy and guideline for augmenting visualization systems to knowledge-assisted visualization systems, as defined by the KAVA model. Visualization systems become more and more sophisticated. Hence, it is increasingly important to support users with an integrated knowledge base in making constructive choices and drawing the right conclusions. We support the effective reactivation of visualization software resources by augmenting them with knowledge-assistance. To provide a general and yet supportive implementation strategy, we propose an implementation process that bases on an application-agnostic architecture. This architecture is derived from existing knowledge-assisted visualization systems and the KAVA model. Its centerpiece is an ontology that is able to automatically analyze and classify input data, linked to a database to store classified instances. We discuss design decisions and advantages of the KR framework and illustrate its broad area of application in diverse integration possibilities of this architecture into an existing visualization system. In addition, we provide a detailed case study by augmenting an it-security system with knowledge-assistance facilities.
C1 [Lohfink, Anna-Pia; Anton, Simon D. Duque; Leitte, Heike; Garth, Christoph] Tech Univ Kaiserslautern, Kaiserslautern, Germany.
C3 University of Kaiserslautern
RP Lohfink, AP (corresponding author), Tech Univ Kaiserslautern, Kaiserslautern, Germany.
EM lohfink@cs.uni-kl.de; simon.duque_anton@posteo.de; leitte@cs.uni-kl.de;
   garth@cs.uni-kl.de
RI Garth, Christoph/Q-5901-2018; Lohfink, Anna-Pia/ITV-3979-2023; Duque
   Anton, Simon Daniel/AFT-7140-2022
OI Garth, Christoph/0000-0003-1669-8549; Duque Anton, Simon
   Daniel/0000-0003-4005-9165
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [252408385 -IRTG 2057]
FX Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) -252408385 -IRTG 2057
CR [Anonymous], 2016, ITRUST DAT
   Aranda-Corral GA, 2010, COMM COM INF SC, V108, P137
   BECHHOFER S, OWL WEB ONTOLOGY LAN
   Bhamare D, 2020, COMPUT SECUR, V89, DOI 10.1016/j.cose.2019.101677
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braei M., ANOMALY DETECTION UN
   Buzan T., 2006, MIND MAP BOOK
   Carpendale S, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.33
   Ceneda D., 2018, Guided visual exploration of cyclical patterns in time-series
   Ceneda D, 2020, COMPUT GRAPH FORUM, V39, P269, DOI 10.1111/cgf.14017
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen CM, 2005, IEEE COMPUT GRAPH, V25, P12, DOI 10.1109/MCG.2005.91
   Chen M, 2010, IEEE COMPUT GRAPH, V30, P15, DOI 10.1109/MCG.2010.8
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Dudás M, 2018, KNOWL ENG REV, V33, DOI 10.1017/S0269888918000073
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Fischer F, 2008, VIZSEC P BROWSER
   Fujishiro I, 1997, VISUALIZATION '97 - PROCEEDINGS, P245, DOI 10.1109/VISUAL.1997.663889
   Gagandeep Singh Gagandeep Singh, 2006, AFITA 2006: The fifth international conference of the Asian Federation for Information Technology in Agriculture, J. N. Tata Auditorium, Indian Institute of Science Campus, Bangalore, India, 9-11 November , 2006, P709
   Gilson O, 2008, COMPUT GRAPH FORUM, V27, P959, DOI 10.1111/j.1467-8659.2008.01230.x
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hellkamp M., 2016, BOTTLE PYTHON WEB FR
   Ishikawa T., 2010, P 9 JOINT C KNOWL BA, P145
   Kincaid R., 2006, Proceedings of the working conference on Advanced visual interfaces, P404
   Lamy J-B., 2019, Owlready2 Documentation
   Lohfink AP, 2020, IEEE T VIS COMPUT GR, V26, P1638, DOI 10.1109/TVCG.2020.2969007
   Mathur AP, 2016, 2016 INTERNATIONAL WORKSHOP ON CYBER-PHYSICAL SYSTEMS FOR SMART WATER NETWORKS (CYSWATER), P31, DOI 10.1109/CySWater.2016.7469060
   Miksch S., 2020, FDN DATA VISUALIZATI, P61, DOI 10.1007/978-3-030-34444-3
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Nie K, 2020, COMPUT GRAPH FORUM, V39, P13, DOI 10.1111/cgf.13959
   Nonaka I, 2007, HARVARD BUS REV, V85, P162
   Novak JD, 1984, LEARNING LEARN
   Noy Natalya F, 2003, AMIA Annu Symp Proc, P953
   Pike WA, 2009, INFORM VISUAL, V8, P263, DOI 10.1057/ivs.2009.22
   Raad Joe, 2015, IC3K 2015. 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, P179
   Rind A, 2019, 2019 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P33, DOI [10.1109/VAHC47919.2019.8945032, 10.1109/vahc47919.2019.8945032]
   Shenhui J., 2016, 11th Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 2: IVAPP, P212, DOI DOI 10.5220/0005714002120219
   Silva SF, 2000, PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS ENGINEERING, VOL I, P310, DOI 10.1109/WISE.2000.882407
   Sobral T, 2020, EXPERT SYST APPL, V150, DOI 10.1016/j.eswa.2020.113260
   Stitz H, 2019, IEEE T VIS COMPUT GR, V25, P120, DOI 10.1109/TVCG.2018.2865024
   Storey M.-A., 2001, WORKSH INT TOOLS KNO, V73, P12
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Verma V, 2004, IEEE T VIS COMPUT GR, V10, P609, DOI 10.1109/TVCG.2004.39
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wagner M, 2019, IEEE T VIS COMPUT GR, V25, P1528, DOI 10.1109/TVCG.2017.2785271
   Wang XY, 2009, COMPUT GRAPH-UK, V33, P616, DOI 10.1016/j.cag.2009.06.004
   Yujie Fang, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/2/022013
   Zhang CG, 2016, IEEE T VIS COMPUT GR, V22, P797, DOI 10.1109/TVCG.2015.2467435
NR 50
TC 2
Z9 2
U1 0
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1117
EP 1127
DI 10.1109/TVCG.2021.3114687
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000106
PM 34591761
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Dimara, E
   Stasko, J
AF Dimara, Evanthia
   Stasko, John
TI A Critical Reflection on Visualization Research: Where Do Decision
   Making Tasks Hide?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Decision making; Visualization; Task analysis;
   Taxonomy; Systematics; Libraries; decision making; data; visualization;
   visual analytics; taxonomies; task
ID VISUAL ANALYTICS APPROACH; INTERACTIVE VISUALIZATION; INFORMATION
   VISUALIZATION; URBAN DATA; EXPLORATION; DESIGN; UNCERTAINTY; MODEL;
   ENSEMBLES; DYNAMICS
AB It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user task, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.
C1 [Dimara, Evanthia] Univ Utrecht, Utrecht, Netherlands.
   [Dimara, Evanthia] Univ Konstanz, Constance, Germany.
   [Stasko, John] Georgia Tech, Atlanta, GA USA.
C3 Utrecht University; University of Konstanz; University System of
   Georgia; Georgia Institute of Technology
RP Dimara, E (corresponding author), Univ Utrecht, Utrecht, Netherlands.; Dimara, E (corresponding author), Univ Konstanz, Constance, Germany.
EM evanthia.dimara@gmail.com; stasko@cc.gatech.edu
OI Dimara, Evanthia/0000-0001-5212-7888
CR Adinolfi P, 2021, EUR MANAG J, V39, P9, DOI 10.1016/j.emj.2020.06.003
   Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   Amar RA, 2005, IEEE T VIS COMPUT GR, V11, P432, DOI 10.1109/TVCG.2005.63
   Ancona M., 2019, IEEE TVCG, P1
   Andrienko G, 2007, IEEE S VIS ANAL, P43, DOI 10.1109/VAST.2007.4388995
   Andrienko N., 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   [Anonymous], 2006, P 2006 AVI WORKSHOP, DOI [DOI 10.1145/1168149.1168169, 10.1145/1168149.1168169]
   [Anonymous], 1977, ADMIN SCI QUART
   [Anonymous], 2005, P INT C INTELLIGENCE
   Asahi T, 1995, INFORM SYST RES, V6, P357, DOI 10.1287/isre.6.4.357
   Aseniero BA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1479, DOI 10.1145/2702123.2702426
   Battle L, 2021, IEEE T VIS COMPUT GR, V27, P1128, DOI 10.1109/TVCG.2020.3028891
   Beach L.R., 1978, ACAD MANAGE REV, V3, P439, DOI [10.5465/amr.1978.4305717, DOI 10.5465/AMR.1978.4305717]
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Borland D, 2021, IEEE T VIS COMPUT GR, V27, P1481, DOI 10.1109/TVCG.2020.3030455
   Bosch H, 2013, IEEE T VIS COMPUT GR, V19, P2022, DOI 10.1109/TVCG.2013.186
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Broeksema B, 2013, IEEE T VIS COMPUT GR, V19, P1972, DOI 10.1109/TVCG.2013.146
   Buja A., 1996, J. Comput. Graph. Stat, V5, P78, DOI DOI 10.1080/10618600.1996.10474696
   Butson CR, 2013, IEEE T VIS COMPUT GR, V19, P108, DOI 10.1109/TVCG.2012.92
   Campitelli G, 2010, REV GEN PSYCHOL, V14, P354, DOI 10.1037/a0021256
   Card SK., 1999, READINGS INFORM VISU
   Carvalho LS, 2016, AM ECON REV, V106, P260, DOI 10.1257/aer.20140481
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Chang R, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.22
   Chen CM, 2006, IEEE CONF VIS ANAL, P59
   Chen L, 2013, ACM T INTERACT INTEL, V3, DOI 10.1145/2533670.2533675
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Chi EHH, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P63, DOI 10.1109/INFVIS.1998.729560
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Chuah MC, 1996, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION '96, PROCEEDINGS, P29, DOI 10.1109/INFVIS.1996.559213
   Coelho D, 2020, IEEE T VIS COMPUT GR, V26, P1650, DOI 10.1109/TVCG.2020.2969056
   Collins Christopher., 2007, P EUROGRAPHICSIEEE V, P51
   Conati C, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12393
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Crnovrsanin T, 2011, COMPUT GRAPH FORUM, V30, P1081, DOI 10.1111/j.1467-8659.2011.01957.x
   Dasgupta A, 2017, IEEE T VIS COMPUT GR, V23, P271, DOI 10.1109/TVCG.2016.2598544
   Dimara E., 2021, IEEE TVCG
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5475, DOI 10.1145/3025453.3025870
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Dix Alan, 1998, P WORK C ADV VIS INT, P124, DOI [10.1145/948496.948514, DOI 10.1145/948496.948514]
   Dy B., 2021, IEEE TVCG, P1
   Ebert A, 2010, IEEE T VIS COMPUT GR, V16, P120, DOI 10.1109/TVCG.2009.57
   Endert A., 2012, BELIV WORKSH, P1
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Fisher D., 2012, P SIGCHI C HUM FACT, P1673, DOI DOI 10.1145/2207676.2208294
   Gigerenzer G, 2001, DAHL WS ENV, P37
   Görg C, 2013, IEEE T VIS COMPUT GR, V19, P1646, DOI 10.1109/TVCG.2012.324
   Gosink L, 2013, IEEE T VIS COMPUT GR, V19, P2703, DOI 10.1109/TVCG.2013.138
   Gotz D, 2009, INFORM VISUAL, V8, P42, DOI 10.1057/ivs.2008.31
   Graham Jamey, 1999, P SIGCHI C HUM FACT, P481
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guo SN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300803, 10.1109/peds44367.2019.8998889]
   Gutman M., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P225, DOI 10.1109/VAST.2010.5650815
   Hakone A, 2017, IEEE T VIS COMPUT GR, V23, P601, DOI 10.1109/TVCG.2016.2598588
   Hao MC, 2011, COMPUT GRAPH FORUM, V30, P691, DOI 10.1111/j.1467-8659.2011.01918.x
   Hastie R, 2001, ANNU REV PSYCHOL, V52, P653, DOI 10.1146/annurev.psych.52.1.653
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Hillygus DS, 2003, AM J POLIT SCI, V47, P583, DOI 10.1111/1540-5907.00041
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P143, DOI 10.1145/2993901.2993919
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Im J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI [10.1145/3394231.3397889, 10.1145/3313831.3376383]
   Inselberg A, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P100, DOI 10.1109/INFVIS.1997.636793
   Ji XN, 2019, IEEE T VIS COMPUT GR, V25, P2181, DOI 10.1109/TVCG.2019.2903946
   Jiang TY, 2001, SPRING EUROGRAP, P15
   Kaastra LindaT., 2014, P 5 WORKSHOP TIME ER, P152
   Kahneman D, 2003, AM ECON REV, V93, P1449, DOI 10.1257/000282803322655392
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Keim DA, 2006, INFORMATION VISUALIZATION-BOOK, P9
   Kerracher N, 2017, COMPUT GRAPH FORUM, V36, P47, DOI 10.1111/cgf.13167
   Kery MB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300322
   Kim SH, 2012, IEEE T VIS COMPUT GR, V18, P2421, DOI 10.1109/TVCG.2012.215
   Kim S, 2007, IEEE CONF VIS ANAL, P35
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Ko S, 2012, COMPUT GRAPH FORUM, V31, P1245, DOI 10.1111/j.1467-8659.2012.03117.x
   Konev A, 2014, IEEE T VIS COMPUT GR, V20, P1873, DOI 10.1109/TVCG.2014.2346930
   Kreiser J, 2018, IEEE T VIS COMPUT GR, V24, P873, DOI 10.1109/TVCG.2017.2744299
   Kruger A., 2005, EUR IEEE VGTC S VIS
   Le Goc M, 2019, IEEE T VIS COMPUT GR, V25, P737, DOI 10.1109/TVCG.2018.2865159
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Ley B., 2012, P SIGCHI C HUM FACT, P1529
   Li Q, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376281
   Liu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376533
   Liu Y, 2021, IEEE T VIS COMPUT GR, V27, P1753, DOI 10.1109/TVCG.2020.3028985
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   Malik A, 2014, IEEE T VIS COMPUT GR, V20, P1863, DOI 10.1109/TVCG.2014.2346926
   Mansmann F, 2006, IEEE T VIS COMPUT GR, V12, P1440, DOI 10.1109/TVCG.2006.98
   Marriott K, 2011, IEEE T VIS COMPUT GR, V17, P290, DOI 10.1109/TVCG.2010.45
   Mavrotas G, 2009, APPL MATH COMPUT, V213, P455, DOI 10.1016/j.amc.2009.03.037
   Meyer J, 2012, IEEE T VIS COMPUT GR, V18, P2088, DOI 10.1109/TVCG.2012.278
   Migut M. A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P141, DOI 10.1109/VAST.2011.6102451
   MULLINS PM, 1993, INTERACT COMPUT, V5, P139, DOI 10.1016/0953-5438(93)90016-M
   Munzner T., 2014, AK Peters Visualization Series
   Newell A., 1972, Human Problem Solving
   Nguyen PH, 2019, IEEE T VIS COMPUT GR, V25, P2838, DOI 10.1109/TVCG.2018.2859969
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Padilla L, 2017, IEEE T VIS COMPUT GR, V23, P431, DOI 10.1109/TVCG.2016.2599106
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Padilla LMK, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.579267
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Pattath A, 2006, IEEE CONF VIS ANAL, P83
   Pike WA, 2009, INFORM VISUAL, V8, P263, DOI 10.1057/ivs.2009.22
   Poco J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12628
   Pu P., 2000, ACM CHI, P289
   Quinan PS, 2016, IEEE T VIS COMPUT GR, V22, P389, DOI 10.1109/TVCG.2015.2467754
   Rados S, 2016, COMPUT GRAPH FORUM, V35, P251, DOI 10.1111/cgf.12901
   Rhyne T., 1995, IEEE INFOVIS, P112
   Ribicic H, 2012, IEEE T VIS COMPUT GR, V18, P2255, DOI 10.1109/TVCG.2012.261
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rodgers J, 2011, IEEE T VIS COMPUT GR, V17, P2489, DOI 10.1109/TVCG.2011.196
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Roth S. F., 1990, SIGCHI Bulletin, P193
   Rudolph Stephen, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P195, DOI 10.1109/VAST.2009.5333920
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Savikhin A, 2008, IEEE CONF VIS ANAL, P107, DOI 10.1109/VAST.2008.4677363
   Scheepens R, 2015, COMPUT GRAPH FORUM, V34, P191, DOI 10.1111/cgf.12631
   Schneider H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300391
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Schwarz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1245
   Sedig K., 2012, JMPT, V3, P12
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shen EYT, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P809
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SIMON HA, 1990, ANNU REV PSYCHOL, V41, P1, DOI 10.1146/annurev.ps.41.020190.000245
   SIMON HA, 1985, AM POLIT SCI REV, V79, P293, DOI 10.2307/1956650
   Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852
   Sorger J, 2016, IEEE T VIS COMPUT GR, V22, P290, DOI 10.1109/TVCG.2015.2468011
   Spence R., 2014, Information Visualization: An Introduction
   Springmeyer R. R., 1992, Proceedings. Visualization '92 (Cat. No.92CH3201-1), P235, DOI 10.1109/VISUAL.1992.235203
   Stoll J, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1045
   Subramanian K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376764
   Teets JM, 2010, IEEE T VIS COMPUT GR, V16, P841, DOI 10.1109/TVCG.2010.21
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Tominski C., 2020, INTERACTIVE VISUAL D
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Tweedie L, 1997, P ACM SIGCHI C HUM F, P375, DOI DOI 10.1145/258549.258803
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   van Pelt R, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12369
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wacharamanotham C, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2693, DOI 10.1145/2702123.2702347
   Wagner M, 2019, IEEE T VIS COMPUT GR, V25, P1528, DOI 10.1109/TVCG.2017.2785271
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Ward M. O., 2015, INTERACTIVE DATA VIS
   Ward M.O., 2004, P JOINT EUROGRAPHICS, P137
   Ware C., INFORM VISUALIZATION, V4, P2021
   Waser J, 2014, COMPUT GRAPH FORUM, V33, P281, DOI 10.1111/cgf.12384
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   WEHREND S, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P139, DOI 10.1109/VISUAL.1990.146375
   Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   Wright W., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P19, DOI 10.1109/INFVIS.1995.528682
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yalçin MA, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P86, DOI 10.1145/2993901.2993902
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhang JW, 2014, IEEE T VIS COMPUT GR, V20, P1843, DOI 10.1109/TVCG.2014.2346898
   Zhang JW, 2016, COMPUT GRAPH FORUM, V35, P441, DOI 10.1111/cgf.12920
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhang YF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2211, DOI 10.1145/2702123.2702239
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
   Zhou M. X., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P392, DOI 10.1145/274644.274698
   Ziegler H., 2007, EUR IEEE VGTC S VIS
   Zuk T., 2006, P 2006 AVI WORKSH TI, P1, DOI DOI 10.1145/1168149.1168162
NR 190
TC 20
Z9 21
U1 3
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1128
EP 1138
DI 10.1109/TVCG.2021.3114813
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000107
PM 34587049
OA Green Published
DA 2024-11-06
ER

PT J
AU Brehmer, M
   Kosara, R
AF Brehmer, Matthew
   Kosara, Robert
TI From Jam Session to Recital: Synchronous Communication and Collaboration
   Around Data in Organizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Collaboration; Tools; Interviews; Organizations;
   Probes; Visualization; Interviews; design probes; presentation;
   communication; collaboration; business intelligence; qualitative
   research
AB Prior research on communicating with visualization has focused on public presentation and asynchronous individual consumption, such as in the domain of journalism. The visualization research community knows comparatively little about synchronous and multimodal communication around data within organizations, from team meetings to executive briefings. We conducted two qualitative interview studies with individuals who prepare and deliver presentations about data to audiences in organizations. In contrast to prior work, we did not limit our interviews to those who self-identify as data analysts or data scientists. Both studies examined aspects of speaking about data with visual aids such as charts, dashboards, and tables. One study was a retrospective examination of current practices and difficulties, from which we identified three scenarios involving presentations of data. We describe these scenarios using an analogy to musical performance: small collaborative team meetings are akin to jam session, while more structured presentations can range from semi-improvisational performances among peers to formal recitals given to executives or customers. In our second study, we grounded the discussion around three design probes, each examining a different aspect of presenting data: the progressive reveal of visualization to direct attention and advance a narrative, visualization presentation controls that are hidden from the audience's view, and the coordination of a presenter's video with interactive visualization. Our distillation of interviewees' responses surfaced twelve themes, from ways of authoring presentations to creating accessible and engaging audience experiences.
C1 [Brehmer, Matthew; Kosara, Robert] Tableau Res, Seattle, WA 98103 USA.
RP Brehmer, M (corresponding author), Tableau Res, Seattle, WA 98103 USA.
EM mbrehmer@tableau.com; rkosara@tableau.com
CR Aisch G, 2016, INF C PRES
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2006, TED TECHN ENT DES C
   [Anonymous], 2007, TED TECHN ENT DES C
   [Anonymous], 2011, P 44 HAW INT C SYST, DOI DOI 10.1109/HICSS.2011.339
   Blackwell A. F., 2016, SHORT PAP P EUR IEEE, DOI [10. 2312/eurovisshort.20161173, DOI 10.2312/EUROVISSHORT.20161173]
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Chattopadhyay D, 2018, HUM-COMPUT INTERACT, V33, P455, DOI 10.1080/07370024.2017.1388170
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Chu T, 2016, OPENVISCONF PRES VID
   Chung John Joon Young, 2021, P ACM C HUMAN FACTOR, DOI [10.1145/3411764.3445419, DOI 10.1145/3411764.3445419]
   Clark D, 2019, FLOURISH BLOG
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Drucker S, 2018, Data-driven storytelling, P211, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Edge D., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '13, P671
   Edge D, 2016, ACM T COMPUT-HUM INT, V23, DOI 10.1145/2898970
   Elias M., 2012, P SIGCHI C HUM FACT, P1641, DOI [DOI 10.1145/2207676.2208288, 10.1145/2207676.2208288]
   Erete S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1273, DOI 10.1145/2818048.2820068
   Fairfield H, 2015, OPENVISCONF PRES VID
   Gomez SR, 2012, IEEE T VIS COMPUT GR, V18, P2411, DOI 10.1109/TVCG.2012.214
   Halloran N, 2016, DOCUMENTARY
   Hullman J, 2017, COMPUT GRAPH FORUM, V36, P365, DOI 10.1111/cgf.13194
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Ipro Tech LLC, 2021, TRIALDIRECTOR
   Isenberg P, 2012, IEEE T VIS COMPUT GR, V18, P689, DOI 10.1109/TVCG.2011.287
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Johnson I., 2021, CODING FIRE
   Kandel S., IEEE T VISUALIZATION, V18
   Kandogan E, 2014, IEEE COMPUT GRAPH, V34, P42, DOI 10.1109/MCG.2014.62
   Kiln Enterprises Ltd, 2021, FLOURISH
   Knudsen S, 2019, 2019 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P9, DOI [10.1109/VAHC47919.2019.8945039, 10.1109/vahc47919.2019.8945039]
   Kosara R, 2016, IEEE COMPUT GRAPH, V36, P80, DOI 10.1109/MCG.2016.2
   Langner R, 2019, IEEE T VIS COMPUT GR, V25, P608, DOI 10.1109/TVCG.2018.2865235
   Lee B., IEEE T VISUALIZATION, V19
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   LexisNexis, 2018, SANCT 4
   Loorak M, 2018, COMPUT GRAPH FORUM, V37, P51, DOI 10.1111/cgf.13400
   Mahyar N, 2014, IEEE T VIS COMPUT GR, V20, P1633, DOI 10.1109/TVCG.2014.2346573
   McInnis Brian James, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415245
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Neogy R, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P146, DOI 10.1109/VIS47514.2020.00036
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Schwab M, 2021, IEEE T VIS COMPUT GR, V27, P347, DOI 10.1109/TVCG.2020.3030366
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Tang JX, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P151, DOI [10.1109/vis47514.2020.00037, 10.1109/VIS47514.2020.00037]
   TechSmith Corporation, 2020, CAMT
   Tian Sunny, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432940
   Tse A, 2016, MAL C PRES SLID
   Tufte E., 2003, COGNITIVE STYLE POWE
   Turco C. J., 2016, The conversational firm: Rethinking bureaucracy in the age of social media, DOI DOI 10.7312/TURC17898
   Viégas FB, 2006, IBM SYST J, V45, P801, DOI 10.1147/sj.454.0801
   Vogt K, 2011, LECT NOTES COMPUT SC, V6947, P589, DOI 10.1007/978-3-642-23771-3_44
   Wu S, 2021, DATAVIZ SHIRLEY
   Zgraggen E, 2014, IEEE T VIS COMPUT GR, V20, P2112, DOI 10.1109/TVCG.2014.2346293
   Zhang Amy X., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392826
   Zhao Z., 2019, THESIS U MARYLAND CO
NR 63
TC 10
Z9 10
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1139
EP 1149
DI 10.1109/TVCG.2021.3114760
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000108
PM 34587018
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Zytek, A
   Liu, DY
   Vaithianathan, R
   Veeramachaneni, K
AF Zytek, Alexandra
   Liu, Dongyu
   Vaithianathan, Rhema
   Veeramachaneni, Kalyan
TI Sibyl: Understanding and Addressing the Usability Challenges of Machine
   Learning In High-Stakes Decision Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Usability; Pediatrics; Tools; Predictive models; Decision making;
   Context modeling; Prediction algorithms; Machine learning; XAI;
   Usability; child welfare; visualization
ID MODEL
AB Machine learning (ML) is being applied to a diverse and ever-growing set of domains. In many cases, domain experts - who often have no expertise in ML or data science - are asked to use ML predictions to make high-stakes decisions. Multiple ML usability challenges can appear as result, such as lack of user trust in the model, inability to reconcile human-ML disagreement, and ethical concerns about oversimplification of complex problems to a single algorithm output. In this paper, we investigate the ML usability challenges that present in the domain of child welfare screening through a series of collaborations with child welfare screeners. Following the iterative design process between the ML scientists, visualization researchers, and domain experts (child screeners), we first identified four key ML challenges and honed in on one promising explainable ML technique to address them (local factor contributions). Then we implemented and evaluated our visual analytics tool, Sibyl, to increase the interpretability and interactivity of local factor contributions. The effectiveness of our tool is demonstrated by two formal user studies with 12 non-expert participants and 13 expert participants respectively. Valuable feedback was collected, from which we composed a list of design implications as a useful guideline for researchers who aim to develop an interpretable and interactive visualization tool for ML prediction models deployed for child welfare screeners and other similar domain experts.
C1 [Zytek, Alexandra; Liu, Dongyu; Veeramachaneni, Kalyan] MIT, Cambridge, MA 02139 USA.
   [Vaithianathan, Rhema] Auckland Univ Technol, Auckland, New Zealand.
C3 Massachusetts Institute of Technology (MIT); Auckland University of
   Technology
RP Zytek, A (corresponding author), MIT, Cambridge, MA 02139 USA.
EM zyteka@mit.edu; dongyu@mit.edu; rhema.vaithianathan@aut.ac.nz;
   kalyan@csail.mit.edu
RI Liu, Dongyu/AGT-1288-2022
OI Liu, Dongyu/0000-0002-8915-2785
FU NSF [1761812]; Direct For Computer & Info Scie & Enginr; Office of
   Advanced Cyberinfrastructure (OAC) [1761812] Funding Source: National
   Science Foundation
FX We would like to thank Rhema Vaithianathan, Diana Benavides Prado, Megh
   Mayur, Athena Ning, and Larissa Lorimer for their guidance throughout
   the process of applying machine learning explainability to child
   welfare, for connecting us to the child welfare domain experts, and for
   providing us with their trained model and dataset. We thank the child
   welfare experts at Larimer County Department of Human Services for their
   invaluable insights and feedback on the tool. We thank Iulia Ionescu,
   Sergiu Ojoc, Ionut Radu, and Ionut Margarint for their work on
   developing the Sibyl application. We thank Arash Akhgari for his work on
   our diagrams and visualizations. We thank Michaela Henry for support in
   project management and insights. We thank the participants of both user
   studies for their time and feedback. Finally, we would like to thank our
   anonymous reviewers for their comments and suggestions. This work is
   supported in part by NSF Award 1761812.
CR Children's Bureau, 2020, CHILD MALTREATMENT
   Doshi-Velez F, 2017, ARXIV
   Fisher A, 2019, J MACH LEARN RES, V20
   Google, 2020, MACH LEARN GLOSS FAI
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Hurley Dan., 2018, The New York Times Magazine
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kenton Will, 2021, INVESTOPEDIA
   Kim H, 2017, AM J PUBLIC HEALTH, V107, P274, DOI [10.2105/ajph.2016.303545, 10.2105/AJPH.2016.303545]
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lipton ZC, 2018, COMMUN ACM, V61, P36, DOI 10.1145/3233231
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0
   Mackay Wendy, 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P3558, DOI 10.1145/2851581.2856492
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   NHTSA, 2017, AUT VEH SAF
   Richardson D, 1990, IPT, V2, P226
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Vaithianathan R, 2017, DEV PREDICTIVE MODEL, P60
   Vaithianathan R., 2019, Tech. Rep.
   Wang DD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300831, 10.1109/icocn.2019.8934212]
   Wang JZ, 2018, PEER PEER NETW APPL, V11, P679, DOI 10.1007/s12083-017-0556-6
   Xu L, 2019, Advances in neural information processing systems
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 27
TC 16
Z9 17
U1 2
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1161
EP 1171
DI 10.1109/TVCG.2021.3114864
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XU0IB
UT WOS:000733959000109
PM 34587081
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Park, H
   Fussell, D
   Navratil, P
AF Park, Hyungman
   Fussell, Donald
   Navratil, Paul
TI Data-Aware Predictive Scheduling for Distributed-Memory Ray Tracing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Distributed databases; Rendering (computer graphics);
   Data visualization; Processor scheduling; Parallel processing; Ray
   tracing; Ray tracing; distributed data visualization
ID SIMULATION
AB Scientific ray tracing now can include realistic shading and material properties, but tracing rays of various depths to conclusion through partitioned data is inefficient. For such data, many ray scheduling methods have demonstrated improved rendering performance. However, synchronicity and non-adaptivity inherent in prior methods hinder further performance optimizations. In this paper, we attempt to relax these constraints. Specifically, we incorporate prediction models capable of dynamically adjusting levels of speculation in ray-data queries, making ray scheduling highly adaptable to a spectrum of scene characteristics. In addition, we organize rays in a tree of speculation nodes, where speculation is coordinated pairwise within a subtree of adaptive ray groups, facilitating concurrency and parallelism. Compared to prior non-predictive methods, we achieve up to three times higher throughput for volume and geometry rendering on a distributed system, making our method fit for both interactive and offline applications.
C1 [Park, Hyungman; Fussell, Donald; Navratil, Paul] Univ Texas Austin, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Park, H (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.
EM hyungman@utexas.edu
FU US NSF [ACI-1339863]; Intel Graphics and Visualization Institute of
   eXcellence award
FX We thank the anonymous reviewers for their thoughtful comments and
   suggestions during the review cycle. We also thank a number of people
   and organizations for providing us with the datasets and tools: the
   Noise volume generator provided by Greg Abram at the Texas Advanced
   Computing Center at the University of Texas at Austin; the RM dataset
   provided by the Lawrence Livermore National Laboratory; the DNS and
   Lambda2 datasets provided by Myoungkyu Lee at the Sandia National
   Laboratories; and the Exajet dataset provided by Dassault Syst`emes and
   the NASA Open Data Portal. This work was funded in part by US NSF award
   ACI-1339863; and an Intel Graphics and Visualization Institute of
   eXcellence award.
CR Abram G., Noise
   Abram G, 2018, SYMP LARG DATA ANAL, P72, DOI 10.1109/LDAV.2018.8739241
   Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   Aila T., 2010, P C HIGH PERF GRAPH, P113
   Aila Timo, 2009, P C HIGH PERF GRAPH, P145, DOI [10.1145/1572769.1572792, DOI 10.1145/1572769.1572792]
   Ayachit U., 2015, P 1 WORKSH IN SIT IN, P25, DOI [10.1145/2828612. 2828624, DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   Ayachit U, 2016, PROCEEDINGS OF ISAV 2016: 2ND WORKSHOP ON IN SITU INFRASTRUCTURES FOR ENABLING EXTREME-SCALE ANALYSIS AND VISUALIZATION, P40, DOI [10.1109/ISAV.2016.013, 10.1109/ISAV.2016.13]
   Binyahib R, 2019, IEEE T VIS COMPUT GR, V25, P2349, DOI 10.1109/TVCG.2018.2833113
   Brownlee C., 2013, Proceedings of the 13th Eurographics Symposium on Parallel Graphics and Visualization, EGPGV13, P65, DOI [DOI 10.2312/EGPGV/EGPGV13/065-072, 10.2312/EGPGV/EGPGV13/065-072]
   Cohen RH, 2002, PHYS FLUIDS, V14, P3692, DOI 10.1063/1.1504452
   DeMarle DE, 2003, PVG 2003 PROCEEDINGS, P87, DOI 10.1109/PVGS.2003.1249046
   Eisenacher C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12158
   Grosset A.V. P., 2016, Eurographics Symposium on Parallel Graphics and Visualization, DOI DOI 10.2312/PGV.20161184
   JEONG J, 1995, J FLUID MECH, V285, P69, DOI 10.1017/S0022112095000462
   Kato T., 2002, Fourth Eurographics Workshop on Parallel Graphics and Visualization, P7
   Lee M, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503298
   Lee M, 2015, J FLUID MECH, V774, P395, DOI 10.1017/jfm.2015.268
   Ma KL, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.120
   NASA, EX DAT PORT
   Navratil P. A., 2010, THESIS U TEXAS AUSTI
   Navrátil PA, 2014, IEEE T VIS COMPUT GR, V20, P893, DOI 10.1109/TVCG.2013.261
   Navrátil PA, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P95, DOI 10.1109/RT.2007.4342596
   Park H, 2018, SYMP LARG DATA ANAL, P77, DOI 10.1109/LDAV.2018.8739224
   Perlin K, 2002, ACM T GRAPHIC, V21, P681, DOI 10.1145/566570.566636
   Pharr M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P101, DOI 10.1145/258734.258791
   Schroeder W., 2006, VISUALIZATION TOOLKI
   Son M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105784
   Stanzione D, 2020, PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2020, PEARC 2020, P106, DOI 10.1145/3311790.3396656
   Turk MJ, 2011, ASTROPHYS J SUPPL S, V192, DOI 10.1088/0067-0049/192/1/9
   Usher W, 2018, PROCEEDINGS OF IN SITU INFRASTRUCTURES FOR ENABLING EXTREME-SCALE ANALYSIS AND VISUALIZATION (ISAV 2018), P33, DOI 10.1145/3281464.3281466
   Usher W, 2019, COMPUT GRAPH FORUM, V38, P455, DOI 10.1111/cgf.13702
   Utkarsh Ayachit, 2015, The ParaView Guide: A Parallel Visualization Application
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
NR 33
TC 0
Z9 0
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1172
EP 1181
DI 10.1109/TVCG.2021.3114838
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XU0IB
UT WOS:000733959000110
PM 34587067
DA 2024-11-06
ER

PT J
AU Gove, R
AF Gove, Robert
TI Automatic Narrative Summarization for Visualizing Cyber Security Logs
   and Incident Reports
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Tools; Task analysis; Computer crime; Schedules;
   Heuristic algorithms; Security; Summarization; incident reports; dynamic
   graphs; cyber security
ID AGREEMENT; DESIGN
AB Cyber security logs and incident reports describe a narrative, but in practice analysts view the data in tables where it can be difficult to follow the narrative. Narrative visualizations are useful, but common examples use a summarized narrative instead of the full story's narrative; it is unclear how to automatically generate these summaries. This paper presents (1) a narrative summarization algorithm to reduce the size and complexity of cyber security narratives with a user-customizable summarization level, and (2) a narrative visualization tailored for incident reports and network logs. An evaluation on real incident reports shows that the summarization algorithm reduces false positives and improves average precision by 41% while reducing average incident report size up to 79%. Together, the visualization and summarization algorithm generate compact representations of cyber narratives that earned praise from a SOC analyst. We further demonstrate that the summarization algorithm can apply to other types of dynamic graphs by automatically generating a summary of the Les Miserables character interaction graph. We find that the list of main characters in the automatically generated summary has substantial agreement with human-generated summaries. A version of this paper, data, and code is freely available at https://osf.io/ekzbp/.
C1 [Gove, Robert] Two Six Technol, Arlington, VA 22203 USA.
RP Gove, R (corresponding author), Two Six Technol, Arlington, VA 22203 USA.
EM robert.gove@twosixtech.com
FU Defense Advanced Research Projects Agency (DARPA)
FX Thanks to Chae Clark, Nathan Danneman, Tony Wong, and the other
   colleagues for feedback on this work. This research was developed with
   funding from the Defense Advanced Research Projects Agency (DARPA).
   Distribution Statement "A" (Approved for Public Release, Distribution
   Unlimited). The views, opinions, and/or findings expressed are those of
   the author(s) and should not be interpreted as representing the official
   views or policies of the Department of Defense or the U.S. Government.
CR [Anonymous], 1994, The Stanford GraphBase-A Platform for Combinatorial Computing
   Arendt D, 2017, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2017.8585487
   Barnum S., 2012, Mitre Corp., V11, P1
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowman B, 2020, P 23 INT S RES ATT I, P257
   Brewer C, 2006, ColorBrewer
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679
   Fink EJ, 2014, DRAMATIC STORY STRUCTURE: A PRIMER FOR SCREENWRITERS, P1
   Gove R., 2018, IEEE SYM VIS CYB SEC, P1
   Gronemann M, 2016, LECT NOTES COMPUT SC, V9801, P367, DOI 10.1007/978-3-319-50106-2_29
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kakar T, 2021, COMPUT GRAPH FORUM, V40, P263, DOI 10.1111/cgf.14305
   Kostitsyna I, 2015, LECT NOTES COMPUT SC, V9411, P192, DOI 10.1007/978-3-319-27261-0_16
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Marsland A. L., 2006, CLIFFSNOTES MIS PRIM
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   MORRIS P.W. G., 1994, MANAGEMENT PROJECTS
   Munroe R., 2009, Movie narrative charts
   Padia K, 2019, COMPUT GRAPH-UK, V78, P64, DOI 10.1016/j.cag.2018.11.004
   Rafiei D, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P375
   S. Editors, 2005, MISERABLES STUDY GUI
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddharthan A., 2014, ITL-International Journal of Applied Linguistics, V165, P259
   Silvia S., 2016, P WORKSH VIS DIG HUM
   Sommer R, 2003, SEC E LEARN E SERV
   Strom B.E., 2018, Mitre att&ck: Design and philosophy
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   van Dijk TC, 2017, J GRAPH ALGORITHMS A, V21, P873, DOI DOI 10.7155/JGAA.00443
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wu YH, 2015, IEEE PAC VIS SYMP, P47, DOI 10.1109/PACIFICVIS.2015.7156355
NR 37
TC 0
Z9 0
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1182
EP 1190
DI 10.1109/TVCG.2021.3114843
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KJ
UT WOS:000736740100003
PM 34587070
DA 2024-11-06
ER

PT J
AU Chen, Q
   Sun, FL
   Xu, XY
   Chen, Z
   Wang, JZ
   Cao, N
AF Chen, Qing
   Sun, Fuling
   Xu, Xinyue
   Chen, Zui
   Wang, Jiazhe
   Cao, Nan
TI VizLinter: A Linter and Fixer Framework for Data Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Encoding; Visualization; Optimization; Tools;
   Programming; Codes; Visualization Linting; Automated Visualization
   Design; Visualization Optimization
ID DESIGN
AB Despite the rising popularity of automated visualization tools, existing systems tend to provide direct results which do not always fit the input data or meet visualization requirements. Therefore, additional specification adjustments are still required in real-world use cases. However, manual adjustments are difficult since most users do not necessarily possess adequate skills or visualization knowledge. Even experienced users might create imperfect visualizations that involve chart construction errors. We present a framework, VizLinter, to help users detect flaws and rectify already-built but defective visualizations. The framework consists of two components, (1) a visualization linter, which applies well-recognized principles to inspect the legitimacy of rendered visualizations, and (2) a visualization fixer, which automatically corrects the detected violations according to the linter. We implement the framework into an online editor prototype based on Vega-Lite specifications. To further evaluate the system, we conduct an in-lab user study. The results prove its effectiveness and efficiency in identifying and fixing errors for data visualizations.
C1 [Chen, Qing; Sun, Fuling; Xu, Xinyue; Chen, Zui; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
   [Wang, Jiazhe] Ant Grp, Hangzhou, Peoples R China.
C3 Tongji University
RP Chen, Q (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
EM jane.qing.chen@gmail.com; fulingsun@tongji.edu.cn;
   xuxinyue@tongji.edu.cn; zuic10a@gmail.com; jiazhe.wjz@antgroup.com;
   nan.cao@gmail.com
RI wang, jiazhe/HSH-2060-2023; Cao, Nan/O-5397-2014
FU National Natural Science Foundation of China [62072338, 6200070909]
FX This work was supported in part by the National Natural Science
   Foundation of China 62072338, 6200070909.
CR Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Achterberg T, 2009, MATH PROGRAM COMPUT, V1, P1, DOI 10.1007/s12532-008-0001-1
   [Anonymous], 2007, EUR IEEE VGTC S VIS, DOI DOI 10.2312/VISSYM/EUROVIS07/163-170
   [Anonymous], 2005, The Grammar of Graphics (Statistics and Computing)
   Barowy DW, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276518
   Barowy DW, 2014, ACM SIGPLAN NOTICES, V49, P507, DOI [10.1145/2714064.2660207, 10.1145/2660193.2660207]
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Bertin J., 1983, Semiology of Graphics
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brachmann M, 2019, INT CONF MANAGE DATA, P1877, DOI 10.1145/3299869.3320246
   Brewka G, 2011, COMMUN ACM, V54, P92, DOI 10.1145/2043174.2043195
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cuteri B, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1688
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Forrest J., 2005, Emerging Theory, Methods, and Applications, P257, DOI DOI 10.1287/EDUC.1053.0020
   Gebser M, 2019, THEOR PRACT LOG PROG, V19, P27, DOI 10.1017/S1471068418000054
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Gotz D, 2019, INFORM VISUAL, V18, P405, DOI 10.1177/1473871618821747
   Heer J, 2006, IEEE T VIS COMPUT GR, V12, P701, DOI 10.1109/TVCG.2006.163
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hynes N., 2017, P 31 C NEUR INF PROC
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Keim DA, 2000, IEEE T VIS COMPUT GR, V6, P59, DOI 10.1109/2945.841121
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kirby RM, 2008, IEEE COMPUT GRAPH, V28, P78, DOI 10.1109/MCG.2008.103
   Lifschitz Vladimir, 2008, P 23 NAT C ART INT, P1594
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McNutt A., 2018, VISGUIDES 2 WORKSH C
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Mitchell S., 2011, Pulp: a linear programming toolkit for python, P65
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Morrison DR, 2016, DISCRETE OPTIM, V19, P79, DOI 10.1016/j.disopt.2016.01.005
   Munzner T., 2015, AK PETERS VISUALIZAT
   Muslu Kivanc, 2015, INT S SOFTWARE TESTI, P373, DOI [10.1145/27717 83.2771792, DOI 10.1145/2771783.2771792, 10.1145/2771783.2771792]
   PADBERG M, 1991, SIAM REV, V33, P60, DOI 10.1137/1033004
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Seifert C, 2008, IEEE INT CONF INF VI, P17, DOI 10.1109/IV.2008.89
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Shi DQ, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P58, DOI [10.1109/VDS48975.2019.8973383, 10.1109/vds48975.2019.8973383]
   Sondag M, 2018, IEEE T VIS COMPUT GR, V24, P729, DOI 10.1109/TVCG.2017.2745140
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tatu Andrada, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P59, DOI 10.1109/VAST.2009.5332628
   Tómasdóttir KF, 2020, IEEE T SOFTWARE ENG, V46, P863, DOI 10.1109/TSE.2018.2871058
   Trutschl M, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P131, DOI 10.1109/INFVIS.2003.1249018
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang P, 2019, INT CONF MANAGE DATA, P811, DOI 10.1145/3299869.3319855
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Ware C., 2013, INFORM VISUALIZATION, V3rd
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu A., 2021, ARXIV PREPRINT ARXIV
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Zhen Wen, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P70, DOI 10.1145/1378773.1378784
NR 63
TC 20
Z9 21
U1 2
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 206
EP 216
DI 10.1109/TVCG.2021.3114804
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW3DW
UT WOS:000735505300003
PM 34587044
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Qin, Y
   Fasy, BT
   Wenk, C
   Summa, B
AF Qin, Yu
   Fasy, Brittany Terese
   Wenk, Carola
   Summa, Brian
TI A Domain-Oblivious Approach for Learning Concise Representations of
   Filtered Topological Spaces for Clustering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Binary codes; Training; Propagation losses; Histograms; Generative
   adversarial networks; Hash functions; Water resources; Topological data
   analysis; Persistence diagrams; Persistence diagram distances; Learned
   hashing; Clustering
ID PERSISTENT HOMOLOGY; ALGORITHMS; STABILITY; COMPLEXES
AB Persistence diagrams have been widely used to quantify the underlying features of filtered topological spaces in data visualization. In many applications, computing distances between diagrams is essential; however, computing these distances has been challenging due to the computational cost. In this paper, we propose a persistence diagram hashing framework that learns a binary code representation of persistence diagrams, which allows for fast computation of distances. This framework is built upon a generative adversarial network (GAN) with a diagram distance loss function to steer the learning process. Instead of using standard representations, we hash diagrams into binary codes, which have natural advantages in large-scale tasks. The training of this model is domain-oblivious in that it can be computed purely from synthetic, randomly created diagrams. As a consequence, our proposed method is directly applicable to various datasets without the need for retraining the model. These binary codes, when compared using fast Hamming distance, better maintain topological similarity properties between datasets than other vectorized representations. To evaluate this method, we apply our framework to the problem of diagram clustering and we compare the quality and performance of our approach to the state-of-the-art. In addition, we show the scalability of our approach on a dataset with 10k persistence diagrams, which is not possible with current techniques. Moreover, our experimental results demonstrate that our method is significantly faster with the potential of less memory usage, while retaining comparable or better quality comparisons.
C1 [Qin, Yu; Wenk, Carola; Summa, Brian] Tulane Univ, New Orleans, LA 70118 USA.
   [Fasy, Brittany Terese] Montana State Univ, Bozeman, MT 59717 USA.
C3 Tulane University; Montana State University System; Montana State
   University Bozeman
RP Qin, Y (corresponding author), Tulane Univ, New Orleans, LA 70118 USA.
EM yqin2@tulane.edu; brittany.fasy@montana.edu; cwenk@tulane.edu;
   bsumma@tulane.edu
OI Fasy, Brittany Terese/0000-0003-1908-0154; Qin, Yu/0000-0003-0657-1149;
   Summa, Brian/0000-0002-5794-3355; Wenk, Carola/0000-0001-9275-5336
FU National Science Foundation; National Institutes of Health [NSF DMS
   1664848, 1664858]; NSF [CCF 2046730, IIS 2136744]
FX This work was supported by the National Science Foundation and the
   National Institutes of Health (NSF DMS 1664848 and 1664858), NSF CCF
   2046730, and NSF IIS 2136744.
CR Adams H, 2017, J MACH LEARN RES, V18
   Agarwal PK, 2000, SIAM J COMPUT, V29, P912, DOI 10.1137/S0097539795295936
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Anirudh R., 2016, P IEEE C COMP VIS PA, P68
   [Anonymous], 2009, NIPS
   [Anonymous], 2020, COMMUN ACM, DOI DOI 10.1145/3422622
   BERTSEKAS DP, 1981, MATH PROGRAM, V21, P152, DOI 10.1007/BF01584237
   Beucher S., 1979, Use of watersheds in contour detection
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Borg I., 2010, Modern multidimensional scaling, V2nd ed., DOI DOI 10.1007/s00357-006-0008-0
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carrière M, 2017, PR MACH LEARN RES, V70
   Carrière M, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12692
   Chen YC., 2015, STAT ANAL PERS INT F
   Cheng MM, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682628
   Cheng Y., 2017, A survey of model compression and acceleration for deep neural networks
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cohen-Steiner D, 2010, FOUND COMPUT MATH, V10, P127, DOI 10.1007/s10208-010-9060-6
   Cuturi M., 2013, Advances in Neural Information Processing Systems, V2, P2292
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   EDELSBRUNNER H., 2010, Computational Topology: An Introduction (Applied Mathematics)
   Fasy B. T., 2018, ARXIV181211257
   FOWLKES EB, 1983, J AM STAT ASSOC, V78, P553, DOI 10.2307/2288117
   Gameiro M, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.035203
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Hausmann JC, 1995, ANN MATH STUD, P175
   Henselman Gregory, 2016, ARXIV160600199
   Iandola F.N., 2016, SQUEEZENET ALEXNET L
   Kantorovitch L, 1942, CR ACAD SCI URSS, V37, P199
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Kather J.N., 2018, 100000 HISTOLOGICAL, DOI DOI 10.5281/ZENODO.1214456
   Kerber Michael, 2017, Journal of Experimental Algorithmics (JEA), V22, P1, DOI 10.1145/3064175
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lacombe T., 2018, Advances in Neural Information Processing Systems, V31
   Lawson P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36798-y
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee H, 2014, LECT NOTES COMPUT SC, V8675, P297, DOI 10.1007/978-3-319-10443-0_38
   Lee H, 2011, I S BIOMED IMAGING, P841, DOI 10.1109/ISBI.2011.5872535
   Lin KV, 2016, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR.2016.133
   Maljovec D., 2016, P IEEE PACIFICVIS
   Masana M., 2017, P IEEE INT C COMPUTE, P4289
   Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013
   Meng ZY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-55660-3
   Monge G., 1781, MEMOIRE THEORIE DEBL
   Munkres J. R., 1964, Algebraic Topology
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Pedregosa F., 2011, J. Mach. Learn. Res., V12, P2825, DOI DOI 10.1016/j.neubiorev.2007.12.002
   Raginsky M., 2009, Adv. Neural Inf. Process. Syst., P1509
   Reininghaus J, 2015, PROC CVPR IEEE, P4741, DOI 10.1109/CVPR.2015.7299106
   Rieck B., 2020, Topological Methods in Data Analysis and Visualization V: Theory, Algorithms, and Applications, P87, DOI DOI 10.1007/978-3-030-43036-8_6
   Robins V, 2002, LECT NOTES PHYS, V600, P261
   Saul N., 2019, SCIKIT TDA TOPOLOGIC, DOI DOI 10.5281/ZENODO.2533369
   Sheehy D. R., 2021, 37 INT S COMP GEOM S
   Shnier D, 2019, J R SOC INTERFACE, V16, DOI 10.1098/rsif.2019.0531
   Soler M, 2018, SYMP LARG DATA ANAL, P23, DOI 10.1109/LDAV.2018.8739196
   Solomon J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766963
   Song JK, 2018, AAAI CONF ARTIF INTE, P402
   Song JK, 2018, AAAI CONF ARTIF INTE, P394
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tauzin G, 2021, J MACH LEARN RES, V22
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   The GUDHI Project, 2021, GUDHI USER REFERENCE, V3
   Thorndike RL., 1953, PSYCHOMETRIKA, V18, P267, DOI 10.1007/BF02289263
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Turner K, 2014, DISCRETE COMPUT GEOM, V52, P44, DOI 10.1007/s00454-014-9604-7
   VAIDYA PM, 1989, SIAM J COMPUT, V18, P1201, DOI 10.1137/0218080
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Vietoris L, 1927, MATH ANN, V97, P454, DOI 10.1007/BF01447877
   Wagner H., 2012, Topological Methods in Data Analysis and Visualization II: Theory, Algorithms, and Applications, P91, DOI DOI 10.1007/978-3-642-23175-97
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xia KL, 2014, INT J NUMER METH BIO, V30, P814, DOI 10.1002/cnm.2655
   Xu X, 2019, ASTRON COMPUT, V27, P34, DOI 10.1016/j.ascom.2019.02.003
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zhao Q, 2019, ADV NEUR IN, V32
NR 84
TC 2
Z9 3
U1 0
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 302
EP 312
DI 10.1109/TVCG.2021.3114872
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW3DW
UT WOS:000735505300004
PM 34587087
OA Bronze, Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Castro, SC
   Hosseinpour, H
   Quinan, PS
   Padilla, L
AF Castro, Spencer C.
   Hosseinpour, Helia
   Quinan, P. Samuel
   Padilla, Lace
TI Examining Effort in 1D Uncertainty Communication Using Individual
   Differences in Working Memory and NASA-TLX
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Data visualization; Visualization; Task analysis;
   Annotations; Measurement uncertainty; Cognition; Uncertainty
   Visualization; Working Memory; Individual Differences; Online OSPAN;
   Effort; Workload; NASA-TLX
ID DECISION-MAKING; VISUALIZING UNCERTAINTY; FORECAST UNCERTAINTY;
   JUDGMENTS; RISK; PERCEPTION; ATTENTION; WORKLOAD; SKILLS; ERROR
AB As uncertainty visualizations for general audiences become increasingly common, designers must understand the full impact of uncertainty communication techniques on viewers' decision processes. Prior work demonstrates mixed performance outcomes with respect to how individuals make decisions using various visual and textual depictions of uncertainty. Part of the inconsistency across findings may be due to an over-reliance on task accuracy, which cannot, on its own, provide a comprehensive understanding of how uncertainty visualization techniques support reasoning processes. In this work, we advance the debate surrounding the efficacy of modern 1D uncertainty visualizations by conducting converging quantitative and qualitative analyses of both the effort and strategies used by individuals when provided with quantile dotplots, density plots, interval plots, mean plots, and textual descriptions of uncertainty. We utilize two approaches for examining effort across uncertainty communication techniques: a measure of individual differences in working-memory capacity known as an operation span (OSPAN) task and self-reports of perceived workload via the NASA-TLX. The results reveal that both visualization methods and working-memory capacity impact participants' decisions. Specifically, quantile dotplots and density plots (i.e., distributional annotations) result in more accurate judgments than interval plots, textual descriptions of uncertainty, and mean plots (i.e., summary annotations). Additionally, participants' open-ended responses suggest that individuals viewing distributional annotations are more likely to employ a strategy that explicitly incorporates uncertainty into their judgments than those viewing summary annotations. When comparing quantile dotplots to density plots, this work finds that both methods are equally effective for low-working-memory individuals. However, for individuals with high-working-memory capacity, quantile dotplots evoke more accurate responses with less perceived effort. Given these results, we advocate for the inclusion of converging behavioral and subjective workload metrics in addition to accuracy performance to further disambiguate meaningful differences among visualization techniques.
C1 [Castro, Spencer C.] Univ Calif Merced, Management Complex Syst, Merced, CA 95343 USA.
   [Quinan, P. Samuel] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
   [Hosseinpour, Helia; Padilla, Lace] Univ Calif Merced, Cognit & Informat Sci, Merced, CA USA.
C3 University of California System; University of California Merced; Utah
   System of Higher Education; University of Utah; University of California
   System; University of California Merced
RP Castro, SC (corresponding author), Univ Calif Merced, Management Complex Syst, Merced, CA 95343 USA.
EM scastro39@ucmerced.edu; hhosseinpour@ucmerced.edu;
   samquinan@sci.utah.edu; lace.padilla@ucmerced.edu
RI Castro, Spencer/V-6532-2019
OI Padilla, Lace/0000-0001-9251-5279; Hosseinpour,
   Helia/0009-0001-5832-0184; Castro, Spencer/0000-0003-1394-0184
FU National Science Foundation [2028374]; Divn Of Social and Economic
   Sciences; Direct For Social, Behav & Economic Scie [2028374] Funding
   Source: National Science Foundation
FX This work was supported in part by a grant from the National Science
   Foundation (#2028374).
CR Aerts C.J. H. J., 2003, Cartography and Geographic Information Science, V30, P249, DOI [DOI 10.1559/152304003100011180, 10.1559/152304003100011180 10.1559/152304003100011180]
   [Anonymous], 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P44, DOI 10.1177/1541931218621010
   Averick M., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI DOI 10.21105/JOSS.01686
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Baddeley A, 2001, PHILOS T R SOC B, V356, P1345, DOI 10.1098/rstb.2001.0957
   Belia S, 2005, PSYCHOL METHODS, V10, P389, DOI 10.1037/1082-989X.10.4.389
   Betsch T, 2010, PSYCHOL INQ, V21, P279, DOI 10.1080/1047840X.2010.517737
   Boone AP, 2018, J EXP PSYCHOL-APPL, V24, P275, DOI 10.1037/xap0000166
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Buhrmester MD, 2018, PERSPECT PSYCHOL SCI, V13, P149, DOI 10.1177/1745691617706516
   Burigat S., 2011, P 13 INT C HUM COMP, P221
   Cansino Selene, 2020, Arch Gerontol Geriatr, V89, P104074, DOI 10.1016/j.archger.2020.104074
   Castro S., 2016, P HUMAN FACTORS ERGO, V60, P1899
   Castro SC, 2019, J EXP PSYCHOL HUMAN, V45, P826, DOI 10.1037/xhp0000638
   Cheong L, 2016, INT J GEOGR INF SCI, V30, P1377, DOI 10.1080/13658816.2015.1131829
   Conway ARA, 2005, PSYCHON B REV, V12, P769, DOI 10.3758/BF03196772
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cowan N, 2017, PSYCHON B REV, V24, P1158, DOI 10.3758/s13423-016-1191-6
   Deitrick S, 2012, P AUTOCARTO
   Engle R. W., 1999, Models of working memory, V1st ed, P102, DOI [10.1017/CBO9781139174909.007, DOI 10.1017/CBO9781139174909.007]
   Evans BJ, 1997, COMPUT GEOSCI, V23, P409, DOI 10.1016/S0098-3004(97)00011-3
   Fagerlin A, 2005, MED DECIS MAKING, V25, P398, DOI 10.1177/0272989X05278931
   Feldman-Stewart D, 2007, MED DECIS MAKING, V27, P34, DOI 10.1177/0272989X06297101
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fraud detection. Qualtrics LLC, 2014, FRAUD DET
   Galy E, 2018, ERGONOMICS, V61, P517, DOI 10.1080/00140139.2017.1369583
   Garcia-Retamero R, 2009, AM J PUBLIC HEALTH, V99, P2196, DOI 10.2105/AJPH.2009.160234
   Gerrie MP, 2007, MEMORY, V15, P561, DOI 10.1080/09658210701391634
   Gigerenzer G, 1996, MED DECIS MAKING, V16, P273, DOI 10.1177/0272989X9601600312
   Greis M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174079
   Grier RA., 2015, Proc Human Factors Ergonomics Soc Annual Meeting, V59, P1727, DOI DOI 10.1177/1541931215591373
   Grounds MA, 2018, J EXP PSYCHOL-APPL, V24, P18, DOI 10.1037/xap0000165
   Grounds MA, 2017, ADV METEOROL, V2017, DOI 10.1155/2017/3932565
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Heitz RP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00150
   Hersher R, 2016, 10000 ALPACAS PERUVI
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Hulman J, 2018, IEEE T VIS COMPUT GR, V24, P446, DOI 10.1109/TVCG.2017.2743898
   Jin Yucheng, 2017, IntRS@ RecSys, V1884, P35
   Joslyn S, 2021, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.590232
   Joslyn S, 2013, WEATHER CLIM SOC, V5, P133, DOI 10.1175/WCAS-D-12-00007.1
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kaplan S, 2010, PERSPECT PSYCHOL SCI, V5, P43, DOI 10.1177/1745691609356784
   Kay M., 2020, **DATA OBJECT**, DOI [10.5281/zenodo. 1308151, DOI 10.5281/ZENODO.1308151]
   Kay M., **DATA OBJECT**, V2021, DOI [10.5281/zenodo. 3879620, DOI 10.5281/ZENODO.3879620]
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kray C, 2019, P 21 INT C HUMAN COM, P1
   Le QT, 2015, INT J ENG EDUC, V31, P713
   Lipkus IM, 2001, MED DECIS MAKING, V21, P37, DOI 10.1177/0272989X0102100105
   Liu L, 2019, IEEE T VIS COMPUT GR, V25, P882, DOI 10.1109/TVCG.2018.2865193
   Liu S., 2015, IEEE T VIS COMPUT GR
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Maehler C, 2016, LEARN INDIVID DIFFER, V49, P341, DOI 10.1016/j.lindif.2016.05.007
   McKenzie G, 2016, INT J GEOGR INF SCI, V30, P221, DOI 10.1080/13658816.2015.1082566
   Miran SM, 2019, RISK ANAL, V39, P1533, DOI 10.1111/risa.13289
   MITCHELL DB, 1989, MEM COGNITION, V17, P337, DOI 10.3758/BF03198472
   Moore CD, 2006, J NEUROSCI, V26, P11187, DOI 10.1523/JNEUROSCI.1873-06.2006
   Mulder KJ, 2020, METEOROL APPL, V27, DOI 10.1002/met.1821
   Newman GE, 2012, PSYCHON B REV, V19, P601, DOI 10.3758/s13423-012-0247-5
   Newman TS, 2004, J VISUAL LANG COMPUT, V15, P463, DOI 10.1016/j.jvlc.2003.09.001
   Nielsen Jakob., 1995, CONDUCT HEURISTIC EV, V1, P1
   Okan Y, 2019, MED DECIS MAKING, V39, P183, DOI 10.1177/0272989X19829728
   Oswald FL, 2015, BEHAV RES METHODS, V47, P1343, DOI 10.3758/s13428-014-0543-2
   Padilla L., 2021, Uncertainty Visualization, P1, DOI [DOI 10.1002/9781118445112.STAT08296, 10.1002/ 9781118445112.stat08296]
   Padilla L, 2021, PSYCHOL LEARN MOTIV, V74, P275, DOI 10.1016/bs.plm.2021.03.001
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Padilla LM, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0076-1
   Padilla LMK, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.579267
   Padilla LMK, 2020, J EXP PSYCHOL-APPL, V26, P1, DOI 10.1037/xap0000245
   Padilla LMK, 2020, IEEE T VIS COMPUT GR, V26, P332, DOI 10.1109/TVCG.2019.2934286
   PASHLER H, 1994, PSYCHOL BULL, V116, P220, DOI 10.1037/0033-2909.116.2.220
   Peer E, 2017, J EXP SOC PSYCHOL, V70, P153, DOI 10.1016/j.jesp.2017.01.006
   R Core Team, 2019, R LANG ENV STAT COMP
   Riveiro M, 2016, SPAT COGN COMPUT, V16, P133, DOI 10.1080/13875868.2015.1137576
   Riveiro M, 2014, COMPUT GRAPH-UK, V41, P84, DOI 10.1016/j.cag.2014.02.006
   Ruginski IT, 2016, SPAT COGN COMPUT, V16, P154, DOI 10.1080/13875868.2015.1137577
   Spiegelhalter D, 2017, ANNU REV STAT APPL, V4, P31, DOI 10.1146/annurev-statistics-010814-020148
   Tak S, 2014, IEEE T VIS COMPUT GR, V20, P935, DOI 10.1109/TVCG.2013.247
   Unsworth N, 2005, BEHAV RES METHODS, V37, P498, DOI 10.3758/BF03192720
   Wasserstein RL, 2019, AM STAT, V73, P1, DOI 10.1080/00031305.2019.1583913
   Waters E. A., 2016, HDB HLTH DECISION SC, P265, DOI DOI 10.1007/978-1-4939-3486-7_19
   Wickham H., 2016, ggplot2: Elegant Graphics for Data Analysis, DOI [DOI 10.1007/978-3-319-24277-4, 10.1007/978-3-319-24277-4]
   Zhang YX, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445381
   Zinke K, 2012, GERONTOLOGY, V58, P79, DOI 10.1159/000324240
NR 90
TC 15
Z9 16
U1 5
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 411
EP 421
DI 10.1109/TVCG.2021.3114803
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300005
PM 34587043
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Wesslen, R
   Karduni, A
   Markant, D
   Dou, WW
AF Wesslen, Ryan
   Karduni, Alireza
   Markant, Douglas
   Dou, Wenwen
TI Effect of uncertainty visualizations on myopic loss aversion and the
   equity premium puzzle in retirement investment decisions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Retirement; Visualization; Investment; Resource management;
   Economics; Bars; Uncertainty visualizations; myopic loss aversion;
   retirement investing; equity premium puzzle
ID RISK; HEURISTICS; JUDGMENT; CHOICE; IMPACT
AB For many households, investing for retirement is one of the most significant decisions and is fraught with uncertainty. In a classic study in behavioral economics, Benartzi and Thaler (1999) found evidence using bar charts that investors exhibit myopic loss aversion in retirement decisions: Investors overly focus on the potential for short-term losses, leading them to invest less in riskier assets and miss out on higher long-term returns. Recently, advances in uncertainty visualizations have shown improvements in decision-making under uncertainty in a variety of tasks. In this paper, we conduct a controlled and incentivized crowdsourced experiment replicating Benartzi and Thaler (1999) and extending it to measure the effect of different uncertainty representations on myopic loss aversion. Consistent with the original study, we find evidence of myopic loss aversion with bar charts and find that participants make better investment decisions with longer evaluation periods. We also find that common uncertainty representations such as interval plots and bar charts achieve the highest mean expected returns while other uncertainty visualizations lead to poorer long-term performance and strong effects on the equity premium. Qualitative feedback further suggests that different uncertainty representations lead to visual reasoning heuristics that can either mitigate or encourage a focus on potential short-term losses. We discuss implications of our results on using uncertainty visualizations for retirement decisions in practice and possible extensions for future work.
C1 [Wesslen, Ryan; Karduni, Alireza; Markant, Douglas; Dou, Wenwen] UNC Charlotte, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Wesslen, R (corresponding author), UNC Charlotte, Charlotte, NC 28223 USA.
EM rwesslen@uncc.edu; akarduni@uncc.edu; dmarkant@uncc.edu; wdou1@uncc.edu
OI Karduni, Alireza/0000-0001-9719-7513
CR [Anonymous], 2012, Financial Analysis and Risk Management, DOI [10.1007/978-3-642-32232-7_5, DOI 10.1007/978-3-642-32232-7_5]
   [Anonymous], 2009, The Myth of the Rational Market, A History of Risk, Reward, and Delusion on Wall Street
   Arora S, 2012, ANN IEEE SYMP FOUND, P1, DOI 10.1109/FOCS.2012.49
   Averick M., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI DOI 10.21105/JOSS.01686
   Benartzi S, 1999, MANAGE SCI, V45, P364, DOI 10.1287/mnsc.45.3.364
   BENARTZI S, 1995, Q J ECON, V110, P73, DOI 10.2307/2118511
   Benartzi S, 2007, J ECON PERSPECT, V21, P81, DOI 10.1257/jep.21.3.81
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Camilleri AR, 2019, J BEHAV DECIS MAKING, V32, P431, DOI 10.1002/bdm.2122
   Doonan D, 2020, GROWING BURDEN RETIR
   Fabozzi F.J., 2002, The Journal of Investing, V11, P7, DOI [10.3905/joi.2002.319510, DOI 10.3905/JOI.2002.319510]
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Gigerenzer G, 1996, MED DECIS MAKING, V16, P273, DOI 10.1177/0272989X9601600312
   Greis M, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971535
   Gunaratne J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P917, DOI 10.1145/2702123.2702408
   HALL RE, 1978, J POLIT ECON, V86, P971, DOI 10.1086/260724
   Hardin AM, 2012, ORGAN BEHAV HUM DEC, V117, P311, DOI 10.1016/j.obhdp.2011.11.005
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Jorion P., 2007, Value at Risk: The New Benchmark for Managing Financial Risk
   Jung MF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2201, DOI 10.1145/2702123.2702479
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kale Alex., 2020, IEEE Transactions on Visualization and Computer Graphics
   Karduni A, 2020, IEEE T VIS COMPUT GR
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Ko S, 2016, COMPUT GRAPH FORUM, V35, P599, DOI 10.1111/cgf.12931
   Kolm PN, 2021, J PORTFOLIO MANAGE, V47, P91, DOI 10.3905/jpm.2021.1.222
   Landreth H., 2002, History of Economic Thought, V4th
   Li CH, 2018, IEEE T VIS COMPUT GR, V24, P1381, DOI 10.1109/TVCG.2017.2668409
   Looney CA, 2009, MANAGE SCI, V55, P1688, DOI 10.1287/mnsc.1090.1052
   Lusardi A, 2017, J PENSION ECON FINAN, V16, P297, DOI 10.1017/S1474747215000323
   MANKIW NG, 1991, J FINANC ECON, V29, P97, DOI 10.1016/0304-405X(91)90015-C
   MEHRA R, 1985, J MONETARY ECON, V15, P145, DOI 10.1016/0304-3932(85)90061-3
   MERTON RC, 1969, REV ECON STAT, V51, P247, DOI 10.2307/1926560
   Mullainathan Sendhil, 2000, NBER Working Paper Series, DOI [10.3386/W7948, DOI 10.3386/W7948]
   Padilla L. M, 2020, FRONT PSYCHOL, V11
   Rudolph Stephen, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P195, DOI 10.1109/VAST.2009.5333920
   SAMUELSON PA, 1963, SCIENTIA, V98, P108
   Samuelson PA., 1975, Stoch Optimiz Models Financ, DOI [DOI 10.1016/B978-0-12-780850-5.50044-7, 10.1016/B978-0-12-780850-5.50044-7]
   Savikhin A., 2011, S2011 44 HAWAII INT, P1, DOI [10.1109/HICSS.2011.54, DOI 10.1109/HICSS.2011.54]
   Savikhin A, 2008, IEEE CONF VIS ANAL, P107, DOI 10.1109/VAST.2008.4677363
   Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852
   Thaler R., 2008, NUDGE GENTLE POWER C
   Thaler R.H, 2015, MISBEHAVING MAKING B
   Thaler RH, 1997, Q J ECON, V112, P647, DOI 10.1162/003355397555226
   Thaler RH, 2004, J POLIT ECON, V112, pS164, DOI 10.1086/380085
   TVERSKY A, 1986, J BUS, V59, pS251, DOI 10.1086/296365
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   Wesslen R, 2019, COMPUT GRAPH FORUM, V38, P161, DOI 10.1111/cgf.13679
   Wickham H., 2016, R package version
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Wulff DU, 2015, COGNITION, V144, P29, DOI 10.1016/j.cognition.2015.07.006
   Wunderlich M, 2017, COMPUT GRAPH FORUM, V36, P317, DOI 10.1111/cgf.13190
   Yue XW, 2020, IEEE T VIS COMPUT GR, V26, P601, DOI 10.1109/TVCG.2019.2934660
   Zhang YF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2211, DOI 10.1145/2702123.2702239
NR 57
TC 8
Z9 8
U1 0
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 454
EP 464
DI 10.1109/TVCG.2021.3114692
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300006
PM 34570703
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bartram, L
   Correll, M
   Tory, M
AF Bartram, Lyn
   Correll, Michael
   Tory, Melanie
TI Untidy Data: The Unreasonable Effectiveness of Tables
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tools; Data visualization; Visual analytics; Cleaning; Annotations;
   Affordances; Organizations; Data practices; Tabular data; Interview
   study; Visualization; Analytics; Data workers; Sensemaking
ID VISUALIZATION; INFORMATION; INSIGHT; DESIGN
AB Working with data in table form is usually considered a preparatory and tedious step in the sensemaking pipeline; a way of getting the data ready for more sophisticated visualization and analytical tools. But for many people, spreadsheets - the quintessential table tool - remain a critical part of their information ecosystem, allowing them to interact with their data in ways that are hidden or abstracted in more complex tools. This is particularly true for data workers [61], people who work with data as part of their job but do not identify as professional analysts or data scientists. We report on a qualitative study of how these workers interact with and reason about their data. Our findings show that data tables serve a broader purpose beyond data cleanup at the initial stage of a linear analytic flow: users want to see and "get their hands on" the underlying data throughout the analytics process, reshaping and augmenting it to support sensemaking. They reorganize, mark up, layer on levels of detail, and spawn alternatives within the context of the base data. These direct interactions and human-readable table representations form a rich and cognitively important part of building understanding of what the data mean and what they can do with it. We argue that interactive tables are an important visualization idiom in their own right; that the direct data interaction they afford offers a fertile design space for visual analytics; and that sense making can be enriched by more flexible human-data interaction than is currently supported in visual analytics tools.
C1 [Bartram, Lyn] Simon Fraser Univ, Burnaby, BC, Canada.
   [Correll, Michael] Tableau, Mountain View, CA USA.
   [Tory, Melanie] Roux Inst, Portland, ME USA.
C3 Simon Fraser University
RP Bartram, L (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM lyn@sfu.ca; mcorrell@tableau.com; m.tory@northeastern.edu
OI Tory, Melanie/0000-0002-6806-9253; Bartram, Lyn/0000-0002-7302-7365
FU Natural Sciences and Engineering Research Council of Canada
FX This work was partly supported by the Natural Sciences and Engineering
   Research Council of Canada. We thank Jonathan Drummey, Bethany Lyons,
   Maureen Stone, and the reviewers for feedback.
CR Alexander E, 2014, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2014.7042493
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Amozurrutia JA, 2011, QUAL QUANT, V45, P953, DOI 10.1007/s11135-010-9406-9
   [Anonymous], 2021, FINDING THEIR DATA V
   [Anonymous], 2014, J STAT SOFTW
   [Anonymous], 2005, P INT C INTELLIGENCE
   Averick M., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI DOI 10.21105/JOSS.01686
   Azeroual O, 2020, DATA, V5, DOI 10.3390/data5020050
   Baskarada S., 2017, UNICORN DATA SCI RAR
   Bertin J, 2011, GRAPHICS GRAPHIC INF
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Blandford A., 2010, Synth Lect Hum-Cent Inform, V3, P1, DOI 10.2200/s00227ed1v01y200911hci006
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Broman KW, 2018, AM STAT, V72, P2, DOI 10.1080/00031305.2017.1375989
   Cao T.D., 2017, P INT WORKSH SEM BIG, DOI [10.1145/3066911.3066914, DOI 10.1145/3066911.3066914]
   CARLEY K, 1992, SOC FORCES, V70, P601, DOI 10.2307/2579746
   Carter LF, 1947, J APPL PSYCHOL, V31, P640, DOI 10.1037/h0054246
   Chambers Chris, 2010, Proceedings 2010 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC 2010), P187, DOI 10.1109/VLHCC.2010.33
   Chang KSP, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2497, DOI 10.1145/2858036.2858430
   Chen Z., 2013, P 3 INT WORKSH SEM S, DOI [DOI 10.1145/2509908.2509909, 10.1145/2509908.2509909]
   Chi EH, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P17, DOI 10.1109/INFVIS.1997.636761
   Chi EHH, 1998, IEEE COMPUT GRAPH, V18, P30, DOI 10.1109/38.689659
   Contreras-Ochando L, 2020, LECT NOTES ARTIF INT, V11908, P735, DOI 10.1007/978-3-030-46133-1_44
   Convertino G., 2017, P 2017 CHI C HUM FAC, P1075, DOI [10.1145/3027063.3053359, DOI 10.1145/3027063.3053359]
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Crisan A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P46, DOI [10.1109/visual.2019.8933542, 10.1109/VISUAL.2019.8933542]
   Davenport T., 2020, Harvard Data Science Review, V2, DOI DOI 10.1162/99608F92.55546B4A
   Davies T., 2013, Proceedings of the 5th Annual ACM Web Science Conference on - WebSci'13, P75, DOI DOI 10.1145/2464464.2464472
   de Vos M, 2017, INT J HUM-COMPUT ST, V103, P63, DOI 10.1016/j.ijhcs.2017.02.006
   Dearing J., 2019, BUSINESS WIRE
   Dourish Paul, 2017, The Stuff of Bits: An Essay on the Materialities of Information, DOI [10.7551/mitpress/10999.003.0005, DOI 10.7551/MITPRESS/10999.003.0005]
   Drummey J., 2018, CREATING LISTS VALUE
   Drummey J., 2019, THOUGHTS MENTAL MODE
   Drummey Jonathan, 2019, TABL C
   Erete S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1273, DOI 10.1145/2818048.2820068
   Few Stephen, 2004, SHOW ME NUMBERS
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Groskopf C., 2021, QUARTZ GUIDE BAD DAT
   Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36
   Handel MJ, 2016, J LABOUR MARK RES, V49, P177, DOI 10.1007/s12651-016-0213-1
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   HENDRY DG, 1994, INT J HUM-COMPUT ST, V40, P1033, DOI 10.1006/ijhc.1994.1047
   Hermans F, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P7, DOI 10.1109/ICSE.2015.129
   Hoffswell J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174106
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Jankun-Kelly TJ, 2001, IEEE T VIS COMPUT GR, V7, P275, DOI 10.1109/2945.942695
   Jaroszewski S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173881
   Joslyn S, 2021, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.590232
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kandogan E, 2014, IEEE COMPUT GRAPH, V34, P42, DOI 10.1109/MCG.2014.62
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Kendrick T., 2016, USE CONTENT IDEA SPR
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Kim Y, 2019, COMPUT GRAPH FORUM, V38, P541, DOI 10.1111/cgf.13709
   Koesten LM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1277, DOI 10.1145/3025453.3025838
   Kohlhase A., 2015, SEMS ICSE, P21
   Law P.-M., 2020, ARXIV PREPRINT ARXIV
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lex A, 2011, IEEE T VIS COMPUT GR, V17, P2291, DOI 10.1109/TVCG.2011.250
   Liu J., 2018, 2018 CHI C HUM FACT
   Liu J., 2014, Proceedings of the 2014 Workshop on Human Centered Big Data Research p, P49, DOI DOI 10.1145/2609876.2609888
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   Martin J. R., 2005, READING SCI CRITICAL
   Mayr E, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P96, DOI 10.1145/2993901.2993914
   McCallum E., 2012, BAD DATA HDB
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   Murrell P., 2012, BAD DATA HDB
   Novak J.D., 2006, Information Visualization Journal, V5, P175
   Pellegrin A., 2000, SS0004 AAAI
   Perin C, 2014, IEEE T VIS COMPUT GR, V20, P2082, DOI 10.1109/TVCG.2014.2346279
   Prodromou T., 2015, International Journal of Statistics and Probability, V4, p181. DOI, DOI DOI 10.5539/IJSP.V4N3P181
   Ragsdale CT., 2014, SPREADSHEET MODELING, V7th
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776
   Rattenbury T, 2017, PRINCIPLES DATA WRAN
   Russell D. M., 2016, AVI, P7, DOI [DOI 10.1145/2909132.29332876, 10.1145/2909132.29332878, DOI 10.1145/2909132.29332878]
   Sarkar A., 2019, PEOPLE LEARN USE SPR
   Sharples M, 2002, EUR J OPER RES, V136, P310, DOI 10.1016/S0377-2217(01)00118-7
   Tanweer A, 2016, INFORM COMMUN SOC, V19, P736, DOI 10.1080/1369118X.2016.1153125
   van Assem M, 2010, LECT NOTES COMPUT SC, V6496, P16, DOI 10.1007/978-3-642-17746-0_2
   Wadsworth BJ., 1996, PIAGETS THEORY COGNI
   Wagner J. M., 2006, MODELS METHODS APPL, P148, DOI [10. 1287/educ. 1063. 0028, DOI 10.1287/EDUC.1063.0028]
   Wang C., 2021, P C HUM FACT COMP SY
   Wolstencroft K, 2011, BIOINFORMATICS, V27, P2021, DOI 10.1093/bioinformatics/btr312
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Zhang Amy X., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392826
NR 90
TC 17
Z9 21
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 686
EP 696
DI 10.1109/TVCG.2021.3114830
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300007
PM 34591767
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU McColeman, CM
   Yang, FM
   Brady, TF
   Franconeri, S
AF McColeman, Caitlyn M.
   Yang, Fumeng
   Brady, Timothy F.
   Franconeri, Steven
TI Rethinking the Ranks of Visual Channels
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Bars; Data visualization; Memory
   management; Measurement uncertainty; Correlation; DataType Agnostic;
   Human-Subjects Quantitative Studies; Perception & Cognition; Charts;
   Diagrams; and Plots
ID SHORT-TERM-MEMORY; WORKING-MEMORY; VISUALIZATION; CAPACITY;
   REPRESENTATIONS; PERCEPTION; JUDGMENTS; FRAMEWORK; MODELS; BIASES
AB Data can be visually represented using visual channels like position, length or luminance. An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is surprisingly little existing work that tests this assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values. To simulate the information extracted from a glance at a visualization, we instead asked participants to immediately reproduce a set of values from memory after they were shown the visualization. These values could be shown in a bar graph (position (bar)), line graph (position (line)), heat map (luminance), bubble chart (area), misaligned bar graph (length), or 'wind map' (angle). With a Bayesian multilevel modeling approach, we show how the rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new probabilistic ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice had an order of magnitude more influence on performance, such as the number of values in the series (e.g., more marks led to larger errors), or the value of each mark (e.g., small values were systematically overestimated). Every visual channel was worse for displays with 8 marks than 4, consistent with established limits on visual memory. These results point to the need for a body of empirical studies that move beyond two-value ratio judgments as a baseline for reliably ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).
C1 [McColeman, Caitlyn M.; Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
   [Yang, Fumeng] Brown Univ, Providence, RI 02912 USA.
   [Brady, Timothy F.] Univ San Diego, San Diego, CA 92110 USA.
C3 Northwestern University; Brown University; University of San Diego
RP McColeman, CM (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM caitlyn.mccoleman@gmail.com; fy@brown.edu; timbrady@ucsd.edu;
   franconeri@northwestern.edu
RI Yang, Fumeng/HME-2828-2023
FU National Science Foundation [BCS-1653457, IIS-1901485]
FX The authors would like to thank Satoru Suzuki and members of the Visual
   Thinking Laboratory at Northwestern University for their suggestions
   during the experimental design. The authors also thank the anonymous
   reviewers for their feedback. This work was supported in part by grants
   BCS-1653457 and IIS-1901485 from the National Science Foundation.
CR Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 1983, SEMIOLOGY GRAPHICS D
   Baddeley A, 2001, PHILOS T R SOC B, V356, P1345, DOI 10.1098/rstb.2001.0957
   Bae GY, 2017, ATTEN PERCEPT PSYCHO, V79, P2376, DOI 10.3758/s13414-017-1404-8
   Bays PM, 2009, J VISION, V9, DOI 10.1167/9.10.7
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Brady TF, 2015, J VISION, V15, DOI 10.1167/15.15.6
   Brady TF, 2015, J EXP PSYCHOL LEARN, V41, P921, DOI 10.1037/xlm0000075
   Brady TF, 2011, PSYCHOL SCI, V22, P384, DOI 10.1177/0956797610397956
   Brainard DH, 1997, SPATIAL VISION, V10, P433, DOI 10.1163/156856897X00357
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Ceja CR, 2021, IEEE T VIS COMPUT GR, V27, P1054, DOI 10.1109/TVCG.2020.3030422
   Chen M, 2010, IEEE T VIS COMPUT GR, V16, P1206, DOI 10.1109/TVCG.2010.132
   Chunharas C., 2019, ADAPTIVE MEMORY DIST, DOI [DOI 10.31234/OSF.IO/E3M5A, 10.31234/osf.io/e3m5a]
   CLEVELAND WS, 1986, INT J MAN MACH STUD, V25, P491, DOI 10.1016/S0020-7373(86)80019-0
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Franconeri S. L, 2013, NATURE STATUS VISUAL, P147, DOI [DOI 10.1093/OXFORDHB/9780195376746.013.0010, 10.1093/ oxfordhb/ 9780195376746.013.0010]
   Gabry J., 2021, Bayesplot: Plotting for Bayesian Models
   Gabry J., 2021, Cmdstanr: R interface to CmdStan
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   GAYDOS HF, 1958, AM J PSYCHOL, V71, P557, DOI 10.2307/1420251
   Gescheider G. A., 2013, Psychophysics: The fundamentals
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Guilford JP, 1932, PSYCHOL REV, V39, P73, DOI 10.1037/h0070969
   Hardman KO, 2015, J EXP PSYCHOL LEARN, V41, P325, DOI 10.1037/xlm0000031
   Harrison L., 2013, P SIGCHI C HUMAN FAC, P2949, DOI DOI 10.1145/2470654.24814109
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Hecht S, 1924, J GEN PHYSIOL, V7, P235, DOI 10.1085/jgp.7.2.235
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hollands JG, 2000, PSYCHOL REV, V107, P500, DOI 10.1037/0033-295X.107.3.500
   Hollingworth A, 2008, J EXP PSYCHOL GEN, V137, P163, DOI 10.1037/0096-3445.137.1.163
   Hua G., 2017, THESIS BROWN U, DOI [10.26300/vyf3-qw80, DOI 10.26300/VYF3-QW80]
   Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599
   Huang LQ, 2020, ATTEN PERCEPT PSYCHO, V82, P1258, DOI 10.3758/s13414-019-01913-2
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M., 2021, GGDIST VISUALIZATION, DOI DOI 10.5281/ZENODO.3879620
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Kay Matthew, 2023, TIDYBAYES TIDY DATA, DOI DOI 10.5281/ZENODO.1308151
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kleiner M, 2007, PERCEPTION, V36, P14
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   KUMAR V, 1992, AI MAG, V13, P32
   Lambert B., 2018, STUDENTS GUIDE BAYES
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McCarthy R. A., 1990, COGN NEUROPSYCHOL, P275, DOI [10.1016/B978- 0- 12- 481845- 3.50016- 3, DOI 10.1016/B978-0-12-481845-3.50016-3, 10.1016/B978-0-12-481845-3.50016-3]
   McColeman CM, 2021, IEEE T VIS COMPUT GR, V27, P1063, DOI 10.1109/TVCG.2020.3030345
   McElreath R, 2016, TEXT STAT SCI, pXI
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, AK Peters Visualization Series
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Oberauer K, 2013, MEM COGNITION, V41, P1212, DOI 10.3758/s13421-013-0333-6
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Ottley A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3251, DOI 10.1145/2702123.2702590
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Peck E. M.M., 2013, P SIGCHI C HUM FACT, P473
   Pinheiro J., 2017, PACKAGE NLME
   Pu XY, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P37
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Rensink R. A, 2016, ENTROPY THEORY CORRE, V16, P811, DOI DOI 10.1167/16.12.811
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Rensink Ronald A., 2014, HDB HUMAN CENTRIC VI, P147, DOI [DOI 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485- 2_6]
   Rosen P, 2021, IEEE T VIS COMPUT GR, V27, P1536, DOI 10.1109/TVCG.2020.3030421
   Ryan G, 2019, IEEE T VIS COMPUT GR, V25, P872, DOI 10.1109/TVCG.2018.2865264
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Schurgin MW, 2020, NAT HUM BEHAV, V4, P1156, DOI 10.1038/s41562-020-00938-0
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Trick LM, 1997, PSYCHOL SCI, V8, P124, DOI 10.1111/j.1467-9280.1997.tb00694.x
   Tufte E., 1990, Envisioning information, V2
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yang FM, 2019, IEEE T VIS COMPUT GR, V25, P1474, DOI 10.1109/TVCG.2018.2810918
   Yu D, 2019, PSYCHOL SCI, V30, P376, DOI 10.1177/0956797618822798
   Yu D, 2019, COGNITION, V182, P8, DOI 10.1016/j.cognition.2018.08.006
   Yuan L, 2019, PSYCHON B REV, V26, P669, DOI 10.3758/s13423-018-1525-7
   Zhang WW, 2008, NATURE, V453, P233, DOI 10.1038/nature06860
   Zhao MQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300462
NR 87
TC 12
Z9 13
U1 3
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 707
EP 717
DI 10.1109/TVCG.2021.3114684
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300008
PM 34606455
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Fujiwara, T
   Wei, XH
   Zhao, J
   Ma, KL
AF Fujiwara, Takanori
   Wei, Xinhai
   Zhao, Jian
   Ma, Kwan-Liu
TI Interactive Dimensionality Reduction for Comparative Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Principal component analysis; Visualization; Optimization; Task
   analysis; Dimensionality reduction; Tools; Libraries; Dimensionality
   reduction; discriminant analysis; contrastive learning; comparative
   analysis; interpretability; visual analytics
ID DISCRIMINANT-ANALYSIS; VISUAL ANALYTICS; VISUALIZATION; CRITERION
AB Finding the similarities and differences between groups of datasets is a fundamental analysis task. For high-dimensional data, dimensionality reduction (DR) methods are often used to find the characteristics of each group. However, existing DR methods provide limited capability and flexibility for such comparative analysis as each method is designed only for a narrow analysis target, such as identifying factors that most differentiate groups. This paper presents an interactive DR framework where we integrate our new DR method, called ULCA (unified linear comparative analysis), with an interactive visual interface. ULCA unifies two DR schemes, discriminant analysis and contrastive learning, to support various comparative analysis tasks. To provide flexibility for comparative analysis, we develop an optimization algorithm that enables analysts to interactively refine ULCA results. Additionally, the interactive visualization interface facilitates interpretation and refinement of the ULCA results. We evaluate ULCA and the optimization algorithm to show their efficiency as well as present multiple case studies using real-world datasets to demonstrate the usefulness of this framework.
C1 [Fujiwara, Takanori; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Wei, Xinhai; Zhao, Jian] Univ Waterloo, Waterloo, ON, Canada.
C3 University of California System; University of California Davis;
   University of Waterloo
RP Fujiwara, T (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM tfujiwara@ucdavis.edu; x67wei@uwaterloo.ca; jianzhao@uwaterloo.ca;
   klma@ucdavis.edu
RI Fujiwara, Takanori/AAY-5045-2020
OI Fujiwara, Takanori/0000-0002-6382-2752
FU U.S. National Science Foundation [IIS-1741536]; U.S. National Institute
   of Standards and Technology [70NANB20H197]; Natural Sciences and
   Engineering Research Council of Canada
FX The authors wish to thank Dr. Tzu-Ping Liu at the University of Taipei
   and Samuel Fuller at UC Davis for their guidance for the dataset used in
   Case Study 1. This work is supported in part by the U.S. National
   Science Foundation through grant IIS-1741536, the U.S. National
   Institute of Standards and Technology through grant 70NANB20H197, and
   the Natural Sciences and Engineering Research Council of Canada.
CR Abid A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04608-8
   Absil PA, 2007, FOUND COMPUT MATH, V7, P303, DOI 10.1007/s10208-005-0179-9
   Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Baldassare M., 2018, PPIC STATEWIDE SURVE
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boileau P, 2020, BIOINFORMATICS, V36, P3422, DOI 10.1093/bioinformatics/btaa176
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boumal N, 2019, IMA J NUMER ANAL, V39, P1, DOI 10.1093/imanum/drx080
   Boumal N, 2014, J MACH LEARN RES, V15, P1455
   Brehmer M., 2014, P 5 WORKSH TIM ERR N, P1, DOI DOI 10.1145/2669557.2669559
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Cantareira G. D., 2020, P EUROVA
   Cavallo M, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186508
   Clemmensen L, 2011, TECHNOMETRICS, V53, P406, DOI 10.1198/TECH.2011.08118
   Coimbra DB, 2016, INFORM VISUAL, V15, P154, DOI 10.1177/1473871615600010
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Dinkelbach W., 1967, Manag. Sci., V13, P492, DOI DOI 10.1287/MNSC.13.7.492
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   du Prel JB, 2010, DTSCH ARZTEBL INT, V107, P343, DOI 10.3238/arztebl.2010.0343
   Dua D., 2019, School of Information and Computer Science. Breast Cancer Wisconsin (Diagnostic) Data Set in
   Endert A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P121, DOI 10.1109/VAST.2011.6102449
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fayyad U, 1996, AI MAG, V17, P37
   Fujiwara T., 2020, ARXIV200704540
   Fujiwara T., 2020, ARXIV PREPRINT ARXIV
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Garcia S, 2015, INTEL SYST REF LIBR, V72, P1, DOI 10.1007/978-3-319-10247-4
   Ge R, 2016, PR MACH LEARN RES, V48
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2042, DOI 10.1109/TVCG.2013.157
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gower J. C., 2004, OX STAT SCI, V30
   Guo RC, 2020, VIS INFORM, V4, P72, DOI 10.1016/j.visinf.2020.04.001
   Guo YQ, 2007, BIOSTATISTICS, V8, P86, DOI 10.1093/biostatistics/kxj035
   Guo YF, 2003, PATTERN RECOGN LETT, V24, P147, DOI 10.1016/S0167-8655(02)00207-6
   Hare C, 2015, AM J POLIT SCI, V59, P759, DOI 10.1111/ajps.12151
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hastie T, 1996, J ROY STAT SOC B, V58, P155
   Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026
   Hofseth LJ, 2020, NAT REV GASTRO HEPAT, V17, P352, DOI 10.1038/s41575-019-0253-4
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   HUBER PJ, 1985, ANN STAT, V13, P435, DOI 10.1214/aos/1176349519
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Jia YQ, 2009, IEEE T NEURAL NETWOR, V20, P729, DOI 10.1109/TNN.2009.2015760
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Johansson J., 2009, IEEE T VIS COMPUT GR, V15
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Jolliffe I., 2022, Principal Component Analysis, P150, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1007/0-387-22440-87, 10.1007/b98835]
   JONES MC, 1987, J ROY STAT SOC A, V150, P1, DOI 10.2307/2981662
   KAISER HF, 1958, PSYCHOMETRIKA, V23, P187, DOI 10.1007/BF02289233
   Kandogan E., 2000, P IEEE S INF VIS LAT, P9
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kim H, 2016, IEEE T VIS COMPUT GR, V22, P131, DOI 10.1109/TVCG.2015.2467615
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Kvam VM, 2012, AM J BOT, V99, P248, DOI 10.3732/ajb.1100340
   Kwon BC, 2017, IEEE T VIS COMPUT GR, V23, P221, DOI 10.1109/TVCG.2016.2598446
   Lage I., 2018, P NIPS, V31
   LeCun Y, 1998, MNIST DATABASE HANDW
   Legendre P, 2013, ECOL LETT, V16, P951, DOI 10.1111/ele.12141
   Lehmann DJ, 2016, IEEE T VIS COMPUT GR, V22, P609, DOI 10.1109/TVCG.2015.2467132
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Mamani GMH, 2013, COMPUT GRAPH FORUM, V32, P291, DOI 10.1111/cgf.12116
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Moore JN, 2015, J MARKET THEORY PRAC, V23, P1, DOI 10.1080/10696679.2015.980163
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pérez D, 2015, NEUROCOMPUTING, V150, P611, DOI 10.1016/j.neucom.2014.09.061
   Pires AM, 2010, J MULTIVARIATE ANAL, V101, P2464, DOI 10.1016/j.jmva.2010.06.017
   POSSE C, 1992, COMMUN STAT THEORY, V21, P1, DOI 10.1080/03610929208830761
   Powell M. J. D., 1998, Acta Numerica, V7, P287, DOI 10.1017/S0962492900002841
   Purchase H. C., 2006, Graph Drawing. 14th International Symposium, GD 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4372), P184
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Rauber P E, 2016, P EUR IEEE VGTC C VI, P73, DOI DOI 10.2312/EUROVISSHORT.20161164
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Self J. Z., 2016, P WORKSH HUM IN THE, DOI DOI 10.1145/2939502.2939505
   Self JZ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3158230
   Sobhani I, 2019, P NATL ACAD SCI USA, V116, P24285, DOI 10.1073/pnas.1912129116
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   Townsend J, 2016, J MACH LEARN RES, V17
   Van Der Maaten L., 2009, J MACH LEARN RES, V10, P66
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang YH, 2017, COMPUT GRAPH FORUM, V36, P401, DOI 10.1111/cgf.13197
   Wenskovitch John, 2020, IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces, P177, DOI 10.1145/3377325.3377516
   Wenskovitch J, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P38, DOI [10.1109/VDS48975.2019.8973381, 10.1109/vds48975.2019.8973381]
   Wenskovitch J, 2018, IEEE T VIS COMPUT GR, V24, P131, DOI 10.1109/TVCG.2017.2745258
   Yang XH, 2021, IEEE T KNOWL DATA EN, V33, P2349, DOI 10.1109/TKDE.2019.2958342
   Yasir M, 2015, NUTR DIABETES, V5, DOI 10.1038/nutd.2015.3
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
   Zhuochen Jin, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3344258
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
   Zou J. Y, 2013, Adv. Neural Inf. Process. Syst., P2238
NR 98
TC 18
Z9 20
U1 1
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 758
EP 768
DI 10.1109/TVCG.2021.3114807
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300009
PM 34591765
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Elhamdadi, H
   Canavan, S
   Rosen, P
AF Elhamdadi, Hamza
   Canavan, Shaun
   Rosen, Paul
TI AffectiveTDA: Using Topological Data Analysis to Improve Analysis and
   Explainability in Affective Computing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Face recognition; Affective computing; Three-dimensional displays;
   Topology; Feature extraction; Data visualization; Data analysis;
   Affective computing; topological data analysis; explainability;
   visualization
ID FACIAL EXPRESSION RECOGNITION; PERSISTENCE; EMOTION; SHAPE
AB We present an approach utilizing Topological Data Analysis to study the structure of face poses used in affective computing, i.e., the process of recognizing human emotion. The approach uses a conditional comparison of different emotions, both respective and irrespective of time, with multiple topological distance metrics, dimension reduction techniques, and face subsections (e.g., eyes, nose, mouth, etc.). The results confirm that our topology-based approach captures known patterns, distinctions between emotions, and distinctions between individuals, which is an important step towards more robust and explainable emotion recognition by machines.
C1 [Elhamdadi, Hamza] Univ Massachusetts, Amherst, MA 01003 USA.
   [Canavan, Shaun; Rosen, Paul] Univ S Florida, Tampa, FL 33620 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   State University System of Florida; University of South Florida
RP Elhamdadi, H (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.
EM helhamdadi@umass.edu; scanavan@usf.edu; prosen@usf.edu
RI Rosen, Paul/AAN-1370-2021
OI Elhamdadi, Hamza/0009-0006-8767-0681
FU National Science Foundation [IIS-1845204]
FX We thank the anonymous reviewers for their feedback. This project was
   supported in part by the National Science Foundation (IIS-1845204).
CR Ahmed MU, 2018, COGN SYST RES, V52, P212, DOI 10.1016/j.cogsys.2018.06.017
   Albiero V, 2020, IEEE WINT CONF APPL, P81, DOI [10.1109/WACVW50321.2020.9096947, 10.1109/wacvw50321.2020.9096947]
   [Anonymous], 2020, ARXIV PREPRINT ARXIV
   [Anonymous], 2019, Computer Aided Design and Applications
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Bauer U., 2019, ARXIV PREPRINT ARXIV
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Canavan S, 2015, COMPUT VIS IMAGE UND, V139, P136, DOI 10.1016/j.cviu.2015.06.006
   Cernea D., 2014, PROCEEDING IVA 2014, P9
   Cernea D, 2015, PROC SPIE, V9397, DOI 10.1117/12.2076473
   Cernea Daniel., 2013, Emotion Scents - A Method of Representing User Emotions on GUI Widgets
   Chinaev N., 2018, P EUR C COMP VIS ECC
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng YL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158666
   Dhall Abhinav, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P784, DOI 10.1145/3382507.3417973
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Edelsbrunner H., 2010, American Mathematical Soc., DOI [10.1090/mbk/069, DOI 10.1090/MBK/069]
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Ekman P., 1981, Nonverbal communication, interaction, and gesture, P57, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49, DOI 10.1111/j.1467-9280.2008.02191.x]
   Ekman R., 1997, What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)
   Ertugrul Itir Onal, 2020, IEEE Trans Biom Behav Identity Sci, V2, P158, DOI [10.1109/TBIOM.2020.2977225, 10.1109/tbiom.2020.2977225]
   Fabiano D., 2020, ARXIV PREPRINT ARXIV
   Fabiano D, 2019, IEEE INT CONF AUTOMA, P453
   Fan Y., 2020, IEEE T AFFECT COMPUT, V4, P1
   Fernandes S. L., 2014, RECENT PATENTS ENG, V8
   Fleureau J, 2012, IEEE T AFFECT COMPUT, V3, P379, DOI 10.1109/T-AFFC.2012.2
   Gao WS, 2019, IEEE ACCESS, V7, P165559, DOI 10.1109/ACCESS.2019.2938671
   Grasshof S., 2020, TPAMI
   Hajij Mustafa, 2020, 2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P110, DOI 10.1109/IDSTA50958.2020.9264141
   Hajij M, 2018, IEEE PAC VIS SYMP, P125, DOI 10.1109/PacificVis.2018.00024
   Hariri W, 2017, ENG APPL ARTIF INTEL, V64, P25, DOI 10.1016/j.engappai.2017.05.009
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Hinduja S., IEEE INT C AUT FAC G, P387
   Hinduja S., 2020, ARXIV PREPRINT ARXIV
   Hinduja S., 2020, IEEE T AFFECTIVE COM
   Hoemann K, 2020, TRENDS COGN SCI, V24, P39, DOI 10.1016/j.tics.2019.10.010
   Hu Y, 2008, PROC CVPR IEEE, P85
   Kalam A., 2019, P 7 INT C COMPUTER C, P63
   Kerber M., J EXPT ALGORITHMICS, V22, P1
   Kim H., 2020, IEEE NETWORK
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kovacevic N., 2020, EUROVIS SHORT PAPERS
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li Shan, 2020, IEEE T AFFECT COMPUT, P1
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lien JJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P390, DOI 10.1109/AFGR.1998.670980
   Liu DZ, 2020, NEUROCOMPUTING, V413, P145, DOI 10.1016/j.neucom.2020.06.062
   Liu F, 2019, IEEE I CONF COMP VIS, P9407, DOI 10.1109/ICCV.2019.00950
   Lucey P, 2011, IEEE T SYST MAN CY B, V41, P664, DOI 10.1109/TSMCB.2010.2082525
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McDuff Daniel, 2012, AffectAura: An Intelligent System for Emotional Memory, P849, DOI [DOI 10.1145/2207676.2208525, 10.1145/2207676.2208525]
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Molho C, 2017, PSYCHOL SCI, V28, P609, DOI 10.1177/0956797617692000
   O'Connor K, 2020, J MED INTERNET RES, V22, DOI 10.2196/15861
   Oh S. J., 2019, Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, P121, DOI 10.1007/978-3-030-28954-6_7
   Otberdout N, 2020, IEEE T NEUR NET LEAR, V31, P3892, DOI 10.1109/TNNLS.2019.2947244
   Patil G, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P825, DOI 10.1109/SmartTechCon.2017.8358488
   Pham HX, 2016, INT C PATT RECOG, P1851, DOI 10.1109/ICPR.2016.7899906
   Picard R.W., 2000, Affective Computing
   Qin C., 2020, ARXIV200202545
   Rieck B, 2018, IEEE T VIS COMPUT GR, V24, P822, DOI 10.1109/TVCG.2017.2744321
   Rieck B, 2012, IEEE T VIS COMPUT GR, V18, P2382, DOI 10.1109/TVCG.2012.248
   Shabayek AR, 2020, INT CONF ACOUST SPEE, P2138, DOI [10.1109/icassp40776.2020.9054733, 10.1109/ICASSP40776.2020.9054733]
   Song Yale, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163081
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Uddin M. T., 2020, INT C PATTERN RECOGN
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang B, 2011, IEEE T VIS COMPUT GR, V17, P1902, DOI 10.1109/TVCG.2011.177
   Weinberger S., 2011, Notices of the AMS, V58, P36
   Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224
   Xu XJ, 2020, IEEE INT CONF AUTOMA, P786, DOI 10.1109/FG47880.2020.00087
   Xue ML, 2015, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2015.34
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   Yi Sun, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563125
   Zamzmi G., 2016, IEEE INT C PATT REC
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Z, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2890, DOI 10.1145/3394171.3413674
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
NR 87
TC 11
Z9 11
U1 3
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 769
EP 779
DI 10.1109/TVCG.2021.3114784
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300010
PM 34587031
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Feng, TH
   Yang, J
   Eppes, MC
   Yang, ZC
   Moser, F
AF Feng, Tinghao
   Yang, Jing
   Eppes, Martha-Cary
   Yang, Zhaocong
   Moser, Faye
TI EVis: Visually Analyzing Environmentally Driven Events
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time series analysis; Rocks; Earth; Visual analytics; Trajectory;
   Heating systems; Data visualization; Multivariate Time Series; RadViz;
   Event Data; Visual Analytics; Earth Sciences
ID TIME-SERIES DATA
AB Earth scientists are increasingly employing time series data with multiple dimensions and high temporal resolution to study the impacts of climate and environmental changes on Earth's atmosphere, biosphere, hydrosphere, and lithosphere. However, the large number of variables and varying time scales of antecedent conditions contributing to natural phenomena hinder scientists from completing more than the most basic analyses. In this paper, we present EVis (Environmental Visualization), a new visual analytics prototype to help scientists analyze and explore recurring environmental events (e.g. rock fracture, landslides, heat waves, floods) and their relationships with high dimensional time series of continuous numeric environmental variables, such as ambient temperature and precipitation. EVis provides coordinated scatterplots, heatmaps, histograms, and RadViz for foundational analyses. These features allow users to interactively examine relationships between events and one, two, three, or more environmental variables. EVis also provides a novel visual analytics approach to allowing users to discover temporally lagging relationships related to antecedent conditions between events and multiple variables, a critical task in Earth sciences. In particular, this latter approach projects multivariate time series onto trajectories in a 2D space using RadViz, and clusters the trajectories for temporal pattern discovery. Our case studies with rock cracking data and interviews with domain experts from a range of sub-disciplines within Earth sciences illustrate the extensive applicability and usefulness of EVis.
C1 [Feng, Tinghao; Yang, Jing; Yang, Zhaocong] UNC Charlotte, Dept Comp Sci, Charlotte, NC USA.
   [Eppes, Martha-Cary; Moser, Faye] UNC Charlotte, Dept Geog & Earth Sci, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   University of North Carolina; University of North Carolina Charlotte
RP Eppes, MC (corresponding author), UNC Charlotte, Dept Geog & Earth Sci, Charlotte, NC 28223 USA.
EM fvisco@uncc.edu; zyang19@uncc.edu
RI Eppes, Martha/GRF-3840-2022; Feng, Tinghao/JWO-1400-2024
OI Feng, Tinghao/0000-0003-2765-2765; Moser, Faye/0000-0002-8235-5117
FU National Science Foundation [00844335, 844401, 0805277]; University of
   North Carolina at Charlotte; Division Of Materials Research; Direct For
   Mathematical & Physical Scien [0805277] Funding Source: National Science
   Foundation; Marie Curie Actions (MSCA) [844401] Funding Source: Marie
   Curie Actions (MSCA)
FX We would like to thank the domain experts of sub-disciplines for their
   expert feedback. This publication is based upon work supported by the
   National Science Foundation under Grant Nos. EAR #00844335, #844401, and
   #0805277, and the University of North Carolina at Charlotte.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alt H, 2009, LECT NOTES COMPUT SC, V5760, P235, DOI 10.1007/978-3-642-03456-5_16
   Angelini M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P226, DOI [10.1109/visual.2019.8933775, 10.1109/VISUAL.2019.8933775]
   [Anonymous], 2011, P 44 HAW INT C SYST, DOI DOI 10.1109/HICSS.2011.339
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Baur D, 2010, IEEE T VIS COMPUT GR, V16, P1119, DOI 10.1109/TVCG.2010.206
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Buono P, 2005, PROC SPIE, V5669, P175, DOI 10.1117/12.587537
   Chen S, 2016, PROC BOSTON US IEEE, P1, DOI [DOI 10.1109/PESGM.2016.7741474, 10.1109/PESGM.2016.7741474, DOI 10.1109/ICIS.2016.7550830, 10.1109/NYSDS.2016.7747808]
   Chen YG, 2007, PROC INT CONF DATA, P761
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   D'Urso P, 2012, FUZZY SET SYST, V193, P33, DOI 10.1016/j.fss.2011.10.002
   Dasu T., 2005, P IEEE WORKSHOP TEMP, P25
   Eppes MC, 2020, GEOPHYS RES LETT, V47, DOI 10.1029/2020GL089062
   Eppes M. C, 2012, AGUFM, V2012
   Eppes MC, 2016, GEOL SOC AM BULL, V128, P1315, DOI 10.1130/B31422.1
   Eppes MC, 2017, REV GEOPHYS, V55, P470, DOI 10.1002/2017RG000557
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   GABRIEL KR, 1971, BIOMETRIKA, V58, P453, DOI 10.2307/2334381
   Ghassempour S, 2014, INT J ENV RES PUB HE, V11, P2741, DOI 10.3390/ijerph110302741
   Hartigan J.A., 1975, CLUSTERING ALGORITHM, DOI DOI 10.1016/j.aap.2006.07.002
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Kohonen T., 2012, SELF ORG MAPS
   Kruskal J. B., 1978, Multidimensional Scaling
   Lee JH, 2014, IEEE T VIS COMPUT GR, V20, P351, DOI 10.1109/TVCG.2013.101
   Magdy N, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P613, DOI 10.1109/IntelCIS.2015.7397286
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nakamura T, 2013, PATTERN ANAL APPL, V16, P535, DOI 10.1007/s10044-011-0262-6
   Nováková L, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P104, DOI 10.1109/IV.2009.103
   Orémus Z, 2020, IEEE PAC VIS SYMP, P216, DOI 10.1109/PacificVis48177.2020.7567
   Rauber P E, 2016, P EUR IEEE VGTC C VI, P73, DOI DOI 10.2312/EUROVISSHORT.20161164
   Ravaji B, 2019, J GEOPHYS RES-PLANET, V124, P3304, DOI 10.1029/2019JE006019
   Roy H.E., 2012, Final Rep. UK Eof. NERC Cent. Ecol. Hydrol. Nat. Hist. Mus.
   Sajadi P, 2022, GEOCARTO INT, V37, P4108, DOI 10.1080/10106049.2021.1871668
   Schreck T., 2007, SIGKDD Explorations, V9, P30, DOI 10.1145/1345448.1345454
   Singhal A, 2005, J CHEMOMETR, V19, P427, DOI 10.1002/cem.945
   Takami R, 2018, 2018 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2018), P342, DOI 10.1109/WI.2018.00-70
   Tilkov S, 2010, IEEE INTERNET COMPUT, V14, P80, DOI 10.1109/MIC.2010.145
   van den Elzen S, 2016, IEEE T VIS COMPUT GR, V22, P1, DOI 10.1109/TVCG.2015.2468078
   Ward M. O., 2002, Information Visualization, V1, P194, DOI 10.1057/palgrave.ivs.9500025
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105
   Zhou FF, 2015, IEEE COMPUT GRAPH, V35, P42, DOI 10.1109/MCG.2015.97
NR 46
TC 2
Z9 2
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 912
EP 921
DI 10.1109/TVCG.2021.3114867
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW3DW
UT WOS:000735505300011
PM 34587084
OA Bronze
DA 2024-11-06
ER

PT J
AU Wall, E
   Narechania, A
   Coscia, A
   Paden, J
   Endert, A
AF Wall, Emily
   Narechania, Arpit
   Coscia, Adam
   Paden, Jamal
   Endert, Alex
TI Left, Right, and Gender: Exploring Interaction Traces to Mitigate Human
   Biases
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Decision making; Task analysis; Data visualization;
   Visualization; History; Motion pictures; Human bias; bias mitigation;
   decision making; visual data analysis
ID COGNITION
AB Human biases impact the way people analyze data and make decisions. Recent work has shown that some visualization designs can better support cognitive processes and mitigate cognitive biases (i.e., errors that occur due to the use of mental "shortcuts"). In this work, we explore how visualizing a user's interaction history (i.e., which data points and attributes a user has interacted with) can be used to mitigate potential biases that drive decision making by promoting conscious reflection of one's analysis process. Given an interactive scatterplot-based visualization tool, we showed interaction history in real-time while exploring data (by coloring points in the scatterplot that the user has interacted with), and in a summative format after a decision has been made (by comparing the distribution of user interactions to the underlying distribution of the data). We conducted a series of in-lab experiments and a crowd-sourced experiment to evaluate the effectiveness of interaction history interventions toward mitigating bias. We contextualized this work in a political scenario in which participants were instructed to choose a committee of 10 fictitious politicians to review a recent bill passed in the U.S. state of Georgia banning abortion after 6 weeks, where things like gender bias or political party bias may drive one's analysis process. We demonstrate the generalizability of this approach by evaluating a second decision making scenario related to movies. Our results are inconclusive for the effectiveness of interaction history (henceforth referred to as interaction traces) toward mitigating biased decision making. However, we find some mixed support that interaction traces, particularly in a summative format, can increase awareness of potential unconscious biases.
C1 [Wall, Emily] Emory Univ, Atlanta, GA 30322 USA.
   [Narechania, Arpit; Coscia, Adam; Paden, Jamal; Endert, Alex] Georgia Tech, Atlanta, GA USA.
C3 Emory University; University System of Georgia; Georgia Institute of
   Technology
RP Wall, E (corresponding author), Emory Univ, Atlanta, GA 30322 USA.
EM emily.wall@emory.edu; arpitnarechania@gatech.edu; acoscia6@gatech.edu;
   jpaden@gatech.edu; endert@gatech.edu
RI ; Coscia, Adam/GUO-9221-2022
OI Narechania, Arpit Ajay/0000-0001-6980-3686; Coscia,
   Adam/0000-0002-0429-9295
FU National Science Foundation [IIS-1813281]; Siemens FutureMaker
   Fellowship
FX This work was supported in part by the National Science Foundation grant
   IIS-1813281 and the Siemens FutureMaker Fellowship. We thank the
   reviewers for their constructive feedback during the review phase. We
   also thank the Georgia Tech Visualization Lab for their feedback.
CR Aldrich J. H., 1995, WHY PARTIES ORIGIN T
   Bertrand M, 2004, AM ECON REV, V94, P991, DOI 10.1257/0002828042002561
   Brown ET, 2014, IEEE T VIS COMPUT GR, V20, P1663, DOI 10.1109/TVCG.2014.2346575
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Dimara Evanthia, 2018, IEEE T VIS COMPUT GR
   Dou WW, 2009, IEEE COMPUT GRAPH, V29, P52, DOI 10.1109/MCG.2009.49
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Feng M, 2019, IEEE T VIS COMPUT GR, V25, P501, DOI 10.1109/TVCG.2018.2865117
   Feng M, 2017, IEEE T VIS COMPUT GR, V23, P351, DOI 10.1109/TVCG.2016.2599058
   Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115
   Gigerenzer G., 2004, BLACKWELL HDB JUDGME, V62, P88, DOI DOI 10.1002/9780470752937.CH4
   Gigerenzer G, 2011, ANNU REV PSYCHOL, V62, P451, DOI 10.1146/annurev-psych-120709-145346
   Gigerenzer G, 2009, TOP COGN SCI, V1, P107, DOI 10.1111/j.1756-8765.2008.01006.x
   Gotz D, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P85, DOI 10.1145/2856767.2856779
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Greenwald AG, 2006, CALIF LAW REV, V94, P945, DOI 10.2307/20439056
   Grüne-Yanoff T, 2016, MIND MACH, V26, P149, DOI 10.1007/s11023-015-9367-9
   Jankun-Kelly TJ, 2000, IEEE VISUAL, P69, DOI 10.1109/VISUAL.2000.885678
   Kahneman D, 2011, Thinking, Fast and Slow
   Kahneman D., 2005, CAMBRIDGE HDB THINKI, P267, DOI DOI 10.1111/COGS.12119
   Law P.-M., 2018, COGNITIVE BIASES VIS, P149
   Leonard TC, 2008, CONST POLITICAL ECON, V19, P356, DOI 10.1007/s10602-008-9056-2
   Manzinit T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P615
   Monadjemi S., 2020, IEEE T VIS COMPUT GR
   Narechania A., IEEE T VIS COMPUT GR
   North C., 2011, Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, P33, DOI 10.1145/1979742.1979570
   Press A, 2020, GEORGIA PUBLIC BROAD
   Reskin BF, 1999, ANNU REV SOCIOL, V25, P335, DOI 10.1146/annurev.soc.25.1.335
   Ringel M. M., 2019, BELIEF SYSTEMS PERCE
   Romo V., 2019, NPR
   Sengers P., 2005, P 4 DEC C CRIT COMP, P49, DOI DOI 10.1145/1094562.1094569
   Sukumar R., 2018, Biases Visualizations, P161
   TUKEY JW, 1980, AM STAT, V34, P23, DOI 10.2307/2682991
   TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124
   Valdez AC, 2018, IEEE T VIS COMPUT GR, V24, P584, DOI 10.1109/TVCG.2017.2744138
   Wall E., 2018, COGNITIVE BIASES VIS, P29, DOI [10.1007/978-3-319-95831-63, DOI 10.1007/978-3-319-95831-6_3, 10.1007/978-3-319-95831-6_3, DOI 10.1007/978-3-319-95831-63]
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P111, DOI [10.1109/visual.2019.8933611, 10.1109/VISUAL.2019.8933611]
   Wall E, 2019, LECT NOTES COMPUT SC, V11747, P555, DOI 10.1007/978-3-030-29384-0_34
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
NR 44
TC 10
Z9 12
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 966
EP 975
DI 10.1109/TVCG.2021.3114862
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300012
PM 34596548
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Narechania, A
   Coscia, A
   Wall, E
   Endert, A
AF Narechania, Arpit
   Coscia, Adam
   Wall, Emily
   Endert, Alex
TI Lumos: Increasing Awareness of Analytic Behavior during Visual Data
   Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Data analysis; Measurement; History;
   Hidden Markov models; Data models; visual data analysis; interaction
   traces; analytic provenance; awareness; human bias
ID VISUALIZATION; INFORMATION
AB Visual data analysis tools provide people with the agency and flexibility to explore data using a variety of interactive functionalities. However, this flexibility may introduce potential consequences in situations where users unknowingly overemphasize or underemphasize specific subsets of the data or attribute space they are analyzing. For example, users may overemphasize specific attributes and/or their values (e.g., Gender is always encoded on the X axis), underemphasize others (e.g., Religion is never encoded), ignore a subset of the data (e.g., older people are filtered out), etc. In response, we present Lumos, a visual data analysis tool that captures and shows the interaction history with data to increase awareness of such analytic behaviors. Using in-situ (at the place of interaction) and ex-situ (in an external view) visualization techniques, Lumos provides real-time feedback to users for them to reflect on their activities. For example, Lumos highlights datapoints that have been previously examined in the same visualization (in-situ) and also overlays them on the underlying data distribution (i.e., baseline distribution) in a separate visualization (ex-situ). Through a user study with 24 participants, we investigate how Lumos helps users' data exploration and decision-making processes. We found that Lumos increases users' awareness of visual data analysis practices in real-time, promoting reflection upon and acknowledgement of their intentions and potentially influencing subsequent interactions.
C1 [Narechania, Arpit; Coscia, Adam; Endert, Alex] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Wall, Emily] Emory Univ, Atlanta, GA 30322 USA.
   Northwestern Univ, Evanston, IL 60208 USA.
C3 University System of Georgia; Georgia Institute of Technology; Emory
   University; Northwestern University
RP Narechania, A (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM arpitnarechania@gatech.edu; acoscia6@gatech.edu; emily.wall@emory.edu;
   endert@gatech.edu
RI Coscia, Adam/GUO-9221-2022
OI Coscia, Adam/0000-0002-0429-9295; Narechania, Arpit
   Ajay/0000-0001-6980-3686
FU National Science Foundation [IIS-1813281]; Siemens FutureMaker
   Fellowship
FX This work was supported in part by the National Science Foundation grant
   IIS-1813281 and the Siemens FutureMaker Fellowship. We thank the
   reviewers for their constructive feedback during the review phase. We
   also thank the Georgia Tech Visualization Lab for their feedback.
CR Alexander J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1665
   Allen Micah, 2019, Wellcome Open Res, V4, P63, DOI 10.12688/wellcomeopenres.15191.1
   Angwin J., 2016, ProPublica, V23, P139
   [Anonymous], 2010, Eyetracking Web Usability: Safari Tech Books Online
   Arroyo E., 2006, CHI 06 EXTENDED ABST, P484, DOI DOI 10.1145/1125451.1125557
   Badam S. K., SUPPORTING TEAM 1 VI
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Cutler Z, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P116, DOI 10.1109/VIS47514.2020.00030
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Dunne C., 2012, P SIGCHI C HUMAN FAC, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Feng M, 2019, IEEE T VIS COMPUT GR, V25, P501, DOI 10.1109/TVCG.2018.2865117
   Feng M, 2017, IEEE T VIS COMPUT GR, V23, P351, DOI 10.1109/TVCG.2016.2599058
   Gigerenzer G., 2004, BLACKWELL HDB JUDGME, V62, P88, DOI DOI 10.1002/9780470752937.CH4
   Gotz D, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P85, DOI 10.1145/2856767.2856779
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   Gutwin C, 2002, PROC GRAPH INTERF, P43
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hill W. C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P3, DOI 10.1145/142750.142751
   Jordan C.E., 2007, J ORG CULTURE COMMUN, V11, P19
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   MILLER GA, 1994, PSYCHOL REV, V101, P343
   North C., 2011, Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, P33, DOI 10.1145/1979742.1979570
   Ottley A, 2019, COMPUT GRAPH FORUM, V38, P41, DOI 10.1111/cgf.13670
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Sarvghad A, 2017, IEEE T VIS COMPUT GR, V23, P21, DOI 10.1109/TVCG.2016.2598466
   Sarvghad Ali., 2015, Proceedings of the Graphics Interface Conference, P123, DOI DOI 10.20380/GI2015.16
   Sauerborn R, 1996, Health Transit Rev, V6, P131
   Shrinivasan YB, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1237
   Skopik A., 2005, SIGCHI C HUMAN FACTO, P771, DOI DOI 10.1145/1054972.1055079
   Valdez AC, 2018, IEEE T VIS COMPUT GR, V24, P584, DOI 10.1109/TVCG.2017.2744138
   Wall E., 2021, IEEE Transactions on Visualization and Computer Graphics
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P81, DOI 10.1109/VISUAL.2019.8933779
   Wall E, 2019, LECT NOTES COMPUT SC, V11747, P555, DOI 10.1007/978-3-030-29384-0_34
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Zhou Z., 2021, MODELING LEVERAGING
NR 38
TC 6
Z9 8
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1009
EP 1018
DI 10.1109/TVCG.2021.3114827
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300013
PM 34587059
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Hou, YJ
   Wang, CS
   Wang, JH
   Xue, XY
   Zhang, XL
   Zhu, J
   Wang, DL
   Chen, SM
AF Hou, Yijie
   Wang, Chengshun
   Wang, Junhong
   Xue, Xiangyang
   Zhang, Xiaolong Luke
   Zhu, Jun
   Wang, Dongliang
   Chen, Siming
TI Visual Evaluation for Autonomous Driving
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Autonomous vehicles; Data visualization; Tools; Visual analytics;
   Planning; Mathematical models; Testing; Autonomous Driving;
   Spatiotemporal Visual Analytics; Visual Evaluation
ID VISUALIZATION; ANALYTICS
AB Autonomous driving technologies often use state-of-the-art artificial intelligence algorithms to understand the relationship between the vehicle and the external environment, to predict the changes of the environment, and then to plan and control the behaviors of the vehicle accordingly. The complexity of such technologies makes it challenging to evaluate the performance of autonomous driving systems and to find ways to improve them. The current approaches to evaluating such autonomous driving systems largely use a single score to indicate the overall performance of a system, but domain experts have difficulties in understanding how individual components or algorithms in an autonomous driving system may contribute to the score. To address this problem, we collaborate with domain experts on autonomous driving algorithms, and propose a visual evaluation method for autonomous driving. Our method considers the data generated in all components during the whole process of autonomous driving, including perception results, planning routes, prediction of obstacles, various controlling parameters, and evaluation of comfort. We develop a visual analytics workflow to integrate an evaluation mathematical model with adjustable parameters, support the evaluation of the system from the level of the overall performance to the level of detailed measures of individual components, and to show both evaluation scores and their contributing factors. Our implemented visual analytics system provides an overview evaluation score at the beginning and shows the animation of the dynamic change of the scores at each period. Experts can interactively explore the specific component at different time periods and identify related factors. With our method, domain experts not only learn about the performance of an autonomous driving system, but also identify and access the problematic parts of each component. Our visual evaluation system can be applied to the autonomous driving simulation system and used for various evaluation cases. The results of using our system in some simulation cases and the feedback from involved domain experts confirm the usefulness and efficiency of our method in helping people gain in-depth insight into autonomous driving systems.
C1 [Hou, Yijie; Wang, Chengshun; Wang, Junhong; Xue, Xiangyang; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Zhang, Xiaolong Luke] Penn State Univ, University Pk, PA 16802 USA.
   [Zhu, Jun; Wang, Dongliang] China FAW Nanjing Technol Dev Co Ltd, Changchun, Peoples R China.
C3 Fudan University; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
EM yijiehou@fudan.edu.cn; chengshunwang@fudan.edu.cn;
   junhongwang@fudan.edu.cn; xyxue@fudan.edu.cn; lzhang@ist.psu.edu;
   zhujun18@faw.com.cn; wangdongliang@faw.com.cn; simingchen@fudan.edu.cn
RI Chen, Siming/AAK-1874-2020; Wang, JunHong/HKE-0286-2023; Wang,
   Pengcheng/JYQ-2527-2024; ZHANG, XIAOLONG/IZQ-4553-2023
OI Zhang, Xiaolong/0000-0002-6828-4930
FU Shanghai Municipal Science and Technology Major Project [2018SHZDZX01];
   Shanghai Center for Brain Science and Brain-Inspired Technology;
   Shanghai Science and Technology Commission [21ZR1403300]; Shanghai
   Sailing Program [21YF1402900]
FX The authors wish to thank Lei Peng, Siqi Shen, Aolin Zhang, Weide Zhang
   and anonymous reviewers for their valuable suggestions. This work is
   supported by Shanghai Municipal Science and Technology Major Project
   (No.2018SHZDZX01), ZJ Lab, and Shanghai Center for Brain Science and
   Brain-Inspired Technology. This work is also supported by Shanghai
   Science and Technology Commission (Grant No. 21ZR1403300) and Shanghai
   Sailing Program No.21YF1402900.
CR Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Bernard L., 1998, GeoInformatica, V2, P59, DOI 10.1023/A:1009793022796
   Buja A., 1996, J. Comput. Graph. Stat, V5, P78, DOI DOI 10.1080/10618600.1996.10474696
   Chen JJ, 2014, IEEE INT VEH SYM, P480, DOI 10.1109/IVS.2014.6856470
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Dong F, 2015, INT SYM COMPUT INTEL, P25, DOI 10.1109/ISCID.2015.78
   Dosovitskiy G., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151
   Goodman AA, 2012, ASTRON NACHR, V333, P505, DOI 10.1002/asna.201211705
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Huang HM, 2004, P SOC PHOTO-OPT INS, V5422, P386, DOI 10.1117/12.552074
   Koopman P, 2017, IEEE INTEL TRANSP SY, V9, P90, DOI 10.1109/MITS.2016.2583491
   Litman T, 2022, Autonomous vehicle implementation predictions: Implications for Transport Planning
   Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Michalewski P, 2020, CARLA REAL TRAFFIC S
   Ren L, 2021, IEEE INTERNET THINGS, V8, P12578, DOI 10.1109/JIOT.2020.3008170
   Rong GD, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294422
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   SAE International, Technical report
   Singh KP, 2017, TENCON IEEE REGION, P393, DOI 10.1109/TENCON.2017.8227896
   Tan, EVALUATION INTELLIGE, P410
   Triantaphyllou E., 2000, APPL OPTIMIZAT, DOI 10.1007/978-1-4757-3157-6_2
   Turkay Cagatay, 2019, EUR WORKSH VIS AN EU
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255
   Wang YC, 2012, CHINESE SCI BULL, V57, P3409, DOI 10.1007/s11434-012-5183-2
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zhao Y, 2020, IEEE T VIS COMPUT GR, V26, P590, DOI 10.1109/TVCG.2019.2934655
NR 33
TC 14
Z9 14
U1 9
U2 75
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1030
EP 1039
DI 10.1109/TVCG.2021.3114777
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XW3DW
UT WOS:000735505300014
PM 34723804
DA 2024-11-06
ER

PT J
AU Lundgard, A
   Satyanarayan, A
AF Lundgard, Alan
   Satyanarayan, Arvind
TI Accessible Visualization via Natural Language Descriptions: A Four-Level
   Model of Semantic Content
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Semantics; Natural languages; Visualization; Guidelines; Data
   visualization; Media; Graphics; Visualization; natural language;
   description; caption; semantic; model; theory; alt text; blind;
   disability; accessibility
AB Natural language descriptions sometimes accompany visualizations to better communicate and contextualize their insights, and to improve their accessibility for readers with disabilities. However, it is difficult to evaluate the usefulness of these descriptions, and how effectively they improve access to meaningful information, because we have little understanding of the semantic content they convey, and how different readers receive this content. In response, we introduce a conceptual model for the semantic content conveyed by natural language descriptions of visualizations. Developed through a grounded theory analysis of 2,147 sentences, our model spans four levels of semantic content: enumerating visualization construction properties (e.g., marks and encodings); reporting statistical concepts and relations (e.g., extrema and correlations); identifying perceptual and cognitive phenomena (e.g., complex trends and patterns); and elucidating domain-specific insights (e.g., social and political context). To demonstrate how our model can be applied to evaluate the effectiveness of visualization descriptions, we conduct a mixed-methods evaluation with 30 blind and 90 sighted readers, and find that these reader groups differ significantly on which semantic content they rank as most useful. Together, our model and findings suggest that access to meaningful information is strongly reader-specific, and that research in automatic visualization captioning should orient toward descriptions that more richly communicate overall trends and statistics, sensitive to reader preferences. Our work further opens a space of research on natural language as a data interface coequal with visualization.
C1 [Lundgard, Alan; Satyanarayan, Arvind] MIT CSAIL, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT)
RP Lundgard, A (corresponding author), MIT CSAIL, Cambridge, MA 02139 USA.
EM lundgard@mit.edu; arvindsalya@mit.edu
FU National Science Foundation [GRFP-1122374, III-1900991]
FX For their valuable feedback, we thank Emilie Gossiaux, Chancey Fleet,
   Michael Correll, Frank Elavsky, Beth Semel, Stephanie Tuerk, Crystal
   Lee, and the MIT Visualization Group. This work was supported by
   National Science Foundation GRFP-1122374 and III-1900991.
CR Ackland Peter., 2017, World blindness and visual impairment: despite many successes, the problem is growing
   Adar E., 2020, TVCG
   Aiello G., 2020, Data Visualization in Society, P49
   Ali K. M., 2016, J SOCIAL ONTOLOGY
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 2005, The Grammar of Graphics (Statistics and Computing)
   B.D. Team, 2014, BOK PYTH LIB INT VIS
   Balaji Abhijit, 2018, ARXIV181210636
   Beaudouin-Lafon M., 2004, P WORK C ADV VIS INT, P15, DOI [DOI 10.1145/989863.989865, 10.1145/989863.989865]
   Beaudouin-Lafon M., 2000, Proc. of the SIGCHI Conference on Human Factors in Computing Systems, P446, DOI [DOI 10.1145/332040.332473, 10.1145/332040.332473]
   Benetech, MAK IM ACC
   Bennett C. L., CHI, P2021
   Bergstrom C. T., 2020, SARS COV 2 CORONAVIR
   Bertin J., 1983, Semiology of Graphics
   Bigham Je.rey P., 2012, P TECHNOLOGY 23ND AN, DOI [10.1145/1866029.1866080, DOI 10.1145/1866029.1866080]
   Bigham JP, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P101, DOI 10.1145/3132525.3132533
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Campolo A, 2020, GREY ROOM, P34, DOI 10.1162/grey_a_00286
   Cesal Amy, 2020, WRITING ALT TEXT DAT
   Chancey Fleet, 2021, TWITTER
   Chang R, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.22
   Chaparro A, 2017, ERGON DES, V25, P23, DOI 10.1177/1064804616635382
   Chen C., 2019, CoRR, V6
   Chen C, 2020, IEEE WINT CONF APPL, P1526, DOI 10.1109/WACV45572.2020.9093592
   Chen C, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P482, DOI 10.1145/3341162.3345601
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Demir S., 2008, INLG
   Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091
   Ehrenkranz M, 2020, VICE
   Elavsky F., 2021, Chartability
   Elzer S, 2007, WEBIST 2007: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON WEB INFORMATION SYSTEMS AND TECHNOLOGIES, VOL WIA, P59
   Elzer Stephanie, 2005, ACL
   Fisher C., 2019, CREATING ACCESSIBLE
   Fossheim SarahL., 2020, NOT MAKE ACCESSIBLE
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Geveci B., 2012, ARCHITECTURE OPEN SO
   Gould Bryan, 2008, Effective Practices for Description of Science Content within Digital Talking Books
   Hanley M, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P543, DOI 10.1145/3461702.3462620
   Hasty Lucia., 2011, GUIDELINES STANDARDS
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P36, DOI [10.1109/VISUAL.2019.8933766, 10.1109/visual.2019.8933766]
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1170, DOI 10.1145/2675133.2675207
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kahou S.E., 2018, P INT C LEARN REPR I
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Keim DA, 2007, IEEE CONF VIS ANAL, P115, DOI 10.1109/VAST.2007.4389004
   Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617
   Kim D, 2021, INT CONF UBIQUIT INF, DOI 10.1109/IMCOM51814.2021.9377409
   Kim Doo-Hyun, 2020, ISSCC
   Kim NW, 2021, COMPUT GRAPH FORUM, V40, P173, DOI 10.1111/cgf.14298
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   KOSSLYN SM, 1989, APPL COGNITIVE PSYCH, V3, P185, DOI 10.1002/acp.2350030302
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lai C., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, P1
   Law P.-M., 2020, 2020 IEEE VIS C, DOI DOI 10.1109/VIS47514.2020.00043
   Law P.-M., 2020, 2020 IEEE VIS C, DOI DOI 10.1109/VIS47514.2020.00041
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Littlefield Tyler, 2020, COVID 19 STAT TRACKE
   Livingston M. A., 2020, VIS
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/visual.2019.8933762, 10.1109/VISUAL.2019.8933762]
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   MacLeod H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5988, DOI 10.1145/3025453.3025814
   Matejka J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1290, DOI 10.1145/3025453.3025912
   Moraes Priscilla, 2014, P 16 INT ACM SIGACCE, P83, DOI DOI 10.1145/2661334.2661368
   Morash VS, 2015, ACM T ACCESS COMPUT, V7, DOI 10.1145/2764916
   Morris MR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173633
   Muller M., 2014, Ways Knowing HCI, P25, DOI DOI 10.1007/978-1-4939-0378-82
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Nuñez JR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199239
   Obeid J., 2020, P 13 INT C NATURAL L, P138, DOI 10.48550/arXiv.2010.09142
   Oliveira MM, 2013, COMPUT SCI ENG, V15, P80, DOI 10.1109/MCSE.2013.113
   Ottley A., 2019, P 2019 EUR IEEE VGTC, DOI DOI 10.2312/EVS.20191181
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Potluri V., 2021, CHI
   Qian X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2792, DOI 10.1145/3442381.3449923
   ROYER JM, 1979, J READING BEHAV, V11, P355, DOI 10.1080/10862967909547341
   Royer JM, 2001, J ADOLESC ADULT LIT, V45, P30
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schepers D, 2020, WHY ACCESSIBILITY IS
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Sharif A, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3471202
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sutton H., 2020, ACCESSIBLE COVID 19
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Vickers Paul, 2013, IEEE Trans Vis Comput Graph, V19, P1048, DOI 10.1109/TVCG.2012.294
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   W3C, 2019, WAI WEB ACC TUT COMP
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Watson L, 2018, ACCESSIBLE SVG FLOWC
   Watson L, 2017, ACCESSIBLE SVG LINE
   Weber W, 2019, IEEE INT CON INF VIS, P323, DOI 10.1109/IV.2019.00061
   Wu Keke, 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445743, DOI 10.1145/3411764.3445743]
   Xin Qian, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382946
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI [DOI 10.1145/1377966.1377971, 10.1145/1377966.1377971]
NR 108
TC 46
Z9 51
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1073
EP 1083
DI 10.1109/TVCG.2021.3114770
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300015
PM 34591762
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Kale, A
   Wu, YF
   Hultman, J
AF Kale, Alex
   Wu, Yifan
   Hultman, Jessica
TI Causal Support: Modeling Causal Inferences with Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data models; Diseases; Cognition; Bars; Analytical
   models; Benchmark testing; Causal inference; visualization; contingency
   tables; data cognition
ID EXPLORATORY DATA-ANALYSIS; REPRESENTATION; PROBABILITY; STRATEGIES;
   JUDGMENTS
AB Analysts often make visual causal inferences about possible data-generating models. However, visual analytics (VA) software tends to leave these models implicit in the mind of the analyst, which casts doubt on the statistical validity of informal visual "insights". We formally evaluate the quality of causal inferences from visualizations by adopting causal support-a Bayesian cognition model that learns the probability of alternative causal explanations given some data-as a normative benchmark for causal inferences. We contribute two experiments assessing how well crowdworkers can detect (1) a treatment effect and (2) a confounding relationship. We find that chart users' causal inferences tend to be insensitive to sample size such that they deviate from our normative benchmark. While interactively cross-filtering data in visualizations can improve sensitivity, on average users do not perform reliably better with common visualizations than they do with textual contingency tables. These experiments demonstrate the utility of causal support as an evaluation framework for inferences in VA and point to opportunities to make analysts' mental models more explicit in VA software.
C1 [Kale, Alex] Univ Washington, Seattle, WA 98195 USA.
   [Wu, Yifan] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Hultman, Jessica] Northwestern Univ, Evanston, IL 60208 USA.
C3 University of Washington; University of Washington Seattle; University
   of California System; University of California Berkeley; Northwestern
   University
RP Kale, A (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM kalea@uw.edu; yifanwu@berkeley.edu; jhullman@northwestern.edu
FU NSF [1930642]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1930642] Funding Source: National
   Science Foundation
FX We thank the UW IDL and the NU MU Collective for their feedback. We
   thank NSF (#1930642) for funding this work.
CR ANDERSON JR, 1995, MEM COGNITION, V23, P510, DOI 10.3758/BF03197251
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Bareinboim E, 2016, P NATL ACAD SCI USA, V113, P7345, DOI 10.1073/pnas.1510507113
   Batanero C, 1996, J RES MATH EDUC, V27, P151, DOI 10.2307/749598
   Becker Richard A, 1996, Journal of computational and Graphical Statistics, V5, P123, DOI DOI 10.1080/10618600.1996.10474701TISTICS
   Benjamin DJ, 2016, J EUR ECON ASSOC, V14, P515, DOI 10.1111/jeea.12139
   Bibby J., 1978, Handbook_of_Statistical_Modeling_for the_Social_and_Behavioral_Sciences, DOI 10.2307/3617686
   Breedlove JL, 2020, CURR BIOL, V30, P2211, DOI 10.1016/j.cub.2020.04.014
   Burkner P-C., 2020, BRMS BAYESIAN REGRES
   Card SK., 1999, READINGS INFORM VISU
   CHALONER K, 1987, COMMUN STAT THEORY, V16, P511, DOI 10.1080/03610928708829384
   Cheng PW, 1997, PSYCHOL REV, V104, P367, DOI 10.1037/0033-295X.104.2.367
   Cox R, 1999, LEARN INSTR, V9, P343, DOI 10.1016/S0959-4752(98)00051-6
   Elmqvist N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P189, DOI 10.1109/INFVIS.2003.1249025
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   Galesic M, 2009, HEALTH PSYCHOL, V28, P210, DOI 10.1037/a0014474
   Gelman A, 2004, J COMPUT GRAPH STAT, V13, P755, DOI 10.1198/106186004X11435
   Gelman A, 2003, INT STAT REV, V71, P369
   GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037/0033-295X.102.4.684
   Gonzalez R, 1999, COGNITIVE PSYCHOL, V38, P129, DOI 10.1006/cogp.1998.0710
   Greenland S, 1999, STAT SCI, V14, P29
   Griffiths TL, 2005, COGNITIVE PSYCHOL, V51, P334, DOI 10.1016/j.cogpsych.2005.05.004
   Grolemund G, 2014, INT STAT REV, V82, P184, DOI 10.1111/insr.12028
   Hoffrage U, 1998, ACAD MED, V73, P538, DOI 10.1097/00001888-199805000-00024
   Hollands JG, 2000, PSYCHOL REV, V107, P500, DOI 10.1037/0033-295X.107.3.500
   Hullman J., 2021, Harvard Data Science Review, V3, P3
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Kadaba NR, 2007, IEEE T VIS COMPUT GR, V13, P1254, DOI 10.1109/TVCG.2007.70528
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kale Alex, 2019, VISXVISION WORKSH IE
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Kingdom F.A.A., 2010, Psychophysics: A Practical Introduction
   Kraska T, 2018, PROC VLDB ENDOW, V11, P2150, DOI 10.14778/3229863.3240493
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   OHagan A., 2006, UNCERTAIN JUDGEMENTS, V170, DOI [10.1111/j. 1467-985x.2007.00506 14.x, DOI 10.1111/J.1467-985X.2007.0050614.X]
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Pacer M., 2015, P 37 ANN C COGNITIVE, P1805
   Pacer Michael D., 2011, Advances_in_Neural_Information_Processing_Systems_24:_25th Annual_Conference_on_Neural_Information_Processing_Systems_2011,_NIPS_2011, P1
   Pearl J., 2018, BASIC BOOKS
   Pearl J, 2015, J CAUSAL INFERENCE, V3, P259, DOI 10.1515/jci-2015-0025
   Pearl J, 2014, STAT SCI, V29, P579, DOI 10.1214/14-STS486
   Pearl J, 2009, STAT SURV, V3, P96, DOI 10.1214/09-SS057
   Pinheiro J, 2020, R package version 3.1-151
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Popper K., 1959, The logic of scientific discovery
   RUSSELL DM, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P269
   Spiegelhalter DJ, 1999, J ROY STAT SOC A STA, V162, P45, DOI 10.1111/1467-985X.00120
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tukey J. W., 1977, EXPLORATORY DATA ANA, V2
   Varshney Lav R., 2013, Significance, V10, P28, DOI DOI 10.1111/J.1740-9713.2013.00636.X
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Xie X., 2020, VISUAL ANALYTICS APP
   Xiong C., 2019, Illusion of causality in visualized data. arXiv
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
   Zhang H, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00001
NR 61
TC 9
Z9 9
U1 2
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2022
VL 28
IS 1
BP 1150
EP 1160
DI 10.1109/TVCG.2021.3114824
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XW3DW
UT WOS:000735505300016
PM 34587057
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, JY
   Chen, KY
   Zheng, JM
AF Zhang, Juyong
   Chen, Keyu
   Zheng, Jianmin
TI Facial Expression Retargeting From Human to Avatar Made Easy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Three-dimensional displays; Strain; Animation; Shape; Solid
   modeling; Machine learning; Facial expression retargeting; variational
   autoencoder; deformation transfer; cross domain translation; triplet
ID MODEL
AB Facial expression retargeting from humans to virtual characters is a useful technique in computer graphics and animation. Traditional methods use markers or blendshapes to construct a mapping between the human and avatar faces. However, these approaches require a tedious 3D modeling process, and the performance relies on the modelers' experience. In this article, we propose a brand-new solution to this cross-domain expression transfer problem via nonlinear expression embedding and expression domain translation. We first build low-dimensional latent spaces for the human and avatar facial expressions with variational autoencoder. Then we construct correspondences between the two latent spaces guided by geometric and perceptual constraints. Specifically, we design geometric correspondences to reflect geometric matching and utilize a triplet data structure to express users' perceptual preference of avatar expressions. A user-friendly method is proposed to automatically generate triplets for a system allowing users to easily and efficiently annotate the correspondences. Using both geometric and perceptual correspondences, we trained a network for expression domain translation from human to avatar. Extensive experimental results and user studies demonstrate that even nonprofessional users can apply our method to generate high-quality facial expression retargeting results with less time and effort.
C1 [Zhang, Juyong; Chen, Keyu] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
   [Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Nanyang Technological University
RP Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
EM juyong@ustc.edu.cn; cky95@mail.ustc.edu.cn; asjmzheng@ntu.edu.sg
RI Chen, KeYu/KOD-2789-2024; Zheng, Jianmin/A-3717-2011
OI Zheng, Jianmin/0000-0002-5062-6226; Chen, Keyu/0000-0002-0440-5852
FU National Natural Science Foundation of China [61672481]; Youth
   Innovation Promotion Association CAS [2018495]; Zhejiang Lab
   [2019NB0AB03]; NTU Data Science and Artificial Intelligence Research
   Center (DSAIR) [04INS000518C130]; Ministry of Education, Singapore,
   under its MoE Tier-2 Grant [MoE 2017-T2-1-076]
FX This research was supported in part by the National Natural Science
   Foundation of China (No. 61672481), Youth Innovation Promotion
   Association CAS (No. 2018495), Zhejiang Lab (NO. 2019NB0AB03), NTU Data
   Science and Artificial Intelligence Research Center (DSAIR) (No.
   04INS000518C130), and the Ministry of Education, Singapore, under its
   MoE Tier-2 Grant (MoE 2017-T2-1-076).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   [Anonymous], 2014, P INT C LEARN REPR I
   Autodesk INC, 2019, Maya
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Ribera RBI, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073674
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Choe B, 2001, J VISUAL COMP ANIMAT, V12, P67, DOI 10.1002/vis.246
   Chollet F., 2015, KERAS
   Orvalho VC, 2008, COMPUT GRAPH FORUM, V27, P1997, DOI 10.1111/j.1467-8659.2008.01187.x
   Defferrard M, 2016, ADV NEUR IN, V29
   Ekman R., 1997, What the face reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)
   Gao L, 2021, IEEE T VIS COMPUT GR, V27, P2085, DOI 10.1109/TVCG.2019.2941200
   Gao L, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Harper J.M., 2012, Mastering Autodesk 3ds Max 2013
   Hyneman W., 2005, ACM SIGGRAPH 2005 CO, P5
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   Lewis JP, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.41
   Lewis John P, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Ma L, 2019, COMPUT GRAPH FORUM, V38, P470, DOI 10.1111/cgf.13586
   Meng H.-Y., 2019, P SAI INT SYST C, P211
   Noh JY, 2001, COMP GRAPH, P277, DOI 10.1145/383259.383290
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Reed K, 2019, COMPUT GRAPH FORUM, V38, P165, DOI 10.1111/cgf.13612
   Saito J., 2013, P S DIG PROD, P7
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Seol Y., 2016, P 2016 S DIGITAL PRO, P13
   Seol Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159519
   Seol Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024196
   Settles B, 2009, ACTIVE LEARNING LIT
   Song J, 2011, COMPUT ANIMAT VIRT W, V22, P187, DOI 10.1002/cav.414
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Vemulapalli R, 2019, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2019.00583
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Williams L., 2006, SIGGRAPH 06 ACM SIGG, P16
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Xu F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601210
NR 52
TC 22
Z9 24
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1274
EP 1287
DI 10.1109/TVCG.2020.3013876
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300006
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Qiao, YL
   Gao, L
   Yang, J
   Rosin, PL
   Lai, YK
   Chen, XL
AF Qiao, Yi-Ling
   Gao, Lin
   Yang, Jie
   Rosin, Paul L.
   Lai, Yu-Kun
   Chen, Xilin
TI Learning on 3D Meshes With Laplacian Encoding and Pooling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Laplace equations; Shape; Correlation;
   Machine learning; Topology; Computational modeling; Mesh processing;
   segmentation; laplacian; deep learning
ID SHAPE SEGMENTATION; CO-SEGMENTATION
AB 3D models are commonly used in computer vision and graphics. With the wider availability of mesh data, an efficient and intrinsic deep learning approach to processing 3D meshes is in great need. Unlike images, 3D meshes have irregular connectivity, requiring careful design to capture relations in the data. To utilize the topology information while staying robust under different triangulations, we propose to encode mesh connectivity using Laplacian spectral analysis, along with mesh feature aggregation blocks (MFABs) that can split the surface domain into local pooling patches and aggregate global information amongst them. We build a mesh hierarchy from fine to coarse using Laplacian spectral clustering, which is flexible under isometric transformations. Inside the MFABs there are pooling layers to collect local information and multi-layer perceptrons to compute vertex features of increasing complexity. To obtain the relationships among different clusters, we introduce a Correlation Net to compute a correlation matrix, which can aggregate the features globally by matrix multiplication with cluster features. Our network architecture is flexible enough to be used on meshes with different numbers of vertices. We conduct several experiments including shape segmentation and classification, and our method outperforms state-of-the-art algorithms for these tasks on the ShapeNet and COSEG datasets.
C1 [Qiao, Yi-Ling; Gao, Lin; Yang, Jie] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100864, Peoples R China.
   [Qiao, Yi-Ling] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
   [Gao, Lin; Yang, Jie; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Rosin, Paul L.; Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
   [Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   University System of Maryland; University of Maryland College Park;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Cardiff University; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100864, Peoples R China.
EM yilingq97@gmail.com; gaolin@ict.ac.cn; yangjie01@ict.ac.cn;
   RosinPL@cardiff.ac.uk; LaiY4@cardiff.ac.uk; xlchen@ict.ac.cn
RI Gao, Lin/JNF-0375-2023; Chen, Xilin/A-1409-2012; Yang,
   Jie/IAO-3586-2023; Lai, Yu-Kun/D-2343-2010; Chen, Xilin/I-4153-2014
OI Rosin, Paul/0000-0002-4965-3884; Chen, Xilin/0000-0003-3024-4404; Lai,
   Yukun/0000-0002-2094-5680
FU National Natural Science Foundation of China [61872440, 61828204];
   Beijing Municipal Natural Science Foundation [L182016]; Royal Society
   Newton Advanced Fellowship [NAFnR2n192151]; Youth Innovation Promotion
   Association CAS; CCF-Tencent Open Fund; Open Project Program of the
   National Laboratory of Pattern Recognition [201900055]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61872440 and No. 61828204), Beijing Municipal Natural Science
   Foundation (No. L182016), Royal Society Newton Advanced Fellowship (No.
   NAFnR2n192151), Youth Innovation Promotion Association CAS, CCF-Tencent
   Open Fund and Open Project Program of the National Laboratory of Pattern
   Recognition (No. 201900055).
CR Adobe, 2016, AD FUS 3D CHAR FUS 3
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI [DOI 10.2312/3DOR/3DOR11/079-088, 10.2312/3DOR/3DOR11/079-088]
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2016, ADV NEUR IN, V29
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2014, P INT C LEARN REPR, P14
   Chang A.X., 2015, Technical Report
   Chen MH, 2017, AAAI CONF ARTIF INTE, P3981
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Crane K, 2017, COMMUN ACM, V60, P90, DOI 10.1145/3131280
   Defferrard M, 2016, ADV NEUR IN, V29
   Ezuz D, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13244
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   George D, 2018, GRAPH MODELS, V96, P1, DOI 10.1016/j.gmod.2018.01.001
   Giorgi D., 2008, SHREC COMPETITION, V8
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   Haim N, 2019, IEEE I CONF COMP VIS, P632, DOI 10.1109/ICCV.2019.00072
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Henaff M., 2015, ARXIV150605163
   Huang Jingwei, 2018, CoRR abs/1802.01698
   Huang QX, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024159
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   King DB, 2015, ACS SYM SER, V1214, P1
   Kostrikov I, 2018, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2018.00269
   Kwak S, 2017, AAAI CONF ARTIF INTE, P4111
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Maron H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073616
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Poulenard A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275102
   Qi C.R., 2017, ArXiv, P5099
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/SMI.2004.1314504
   Shu ZY, 2016, COMPUT AIDED GEOM D, V43, P39, DOI 10.1016/j.cagd.2016.02.015
   Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Song R, 2021, IEEE T VIS COMPUT GR, V27, P151, DOI 10.1109/TVCG.2019.2928794
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tan QY, 2018, AAAI CONF ARTIF INTE, P2452
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang PY, 2018, COMPUT GRAPH-UK, V70, P128, DOI 10.1016/j.cag.2017.07.030
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZZ, 2013, COMPUT GRAPH-UK, V37, P628, DOI 10.1016/j.cag.2013.05.015
   Xie ZG, 2014, COMPUT GRAPH FORUM, V33, P85, DOI 10.1111/cgf.12434
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
NR 61
TC 14
Z9 16
U1 1
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1317
EP 1327
DI 10.1109/TVCG.2020.3014449
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300009
PM 32755863
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Gattullo, M
   Evangelista, A
   Uva, AE
   Fiorentino, M
   Gabbard, JL
AF Gattullo, Michele
   Evangelista, Alessandro
   Uva, Antonio E.
   Fiorentino, Michele
   Gabbard, Joseph L.
TI What, How, and Why are Visual Assets Used in Industrial Augmented
   Reality? A Systematic Review and Classification in Maintenance,
   Assembly, and Training (From 1997 to 2019)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Visualization; Augmented reality; Training; Maintenance engineering;
   Hardware; Systematics; Manufacturing; Augmented reality; industry;
   reviews; user interfaces; visualization
AB Industrial Augmented Reality (iAR) has demonstrated its advantages to communicate technical information in the fields of maintenance, assembly, and training. However, literature is scattered among different visual assets (i.e., AR visual user interface elements associated with a real scene). In this work, we present a systematic literature review of visual assets used in these industrial fields. We searched five databases, initially finding 1757 papers. Then, we selected 122 iAR papers from 1997 to 2019 and extracted 348 visual assets. We propose a classification for visual assets according to (i) what is displayed, (ii) how it conveys information (frame of reference, color coding, animation), and, (iii) why it is used. Our review shows that product models, text and auxiliary models are, in order, the most common, with each most often used to support operating, checking and locating tasks respectively. Other visual assets are scarcely used. Product and auxiliary models are commonly rendered world-fixed, color coding is not used as often as expected, while animations are limited to product and auxiliary model. This survey provides a snapshot of over 20 years of literature in iAR, useful to understand established practices to orientate in iAR interface design and to present future research directions.
C1 [Gattullo, Michele; Evangelista, Alessandro; Uva, Antonio E.; Fiorentino, Michele] Polytech Inst Bari, Dept Mech Math & Management, IT-70125 Bari, Italy.
   [Gabbard, Joseph L.] Virginia Tech, Grad Dept Ind & Syst Engn, Blacksburg, VA 24061 USA.
C3 Politecnico di Bari; Virginia Polytechnic Institute & State University
RP Gattullo, M (corresponding author), Polytech Inst Bari, Dept Mech Math & Management, IT-70125 Bari, Italy.
EM michele.gattullo@poliba.it; alessandro.evangelista@poliba.it;
   antonio.uva@poliba.it; fiorentino@poliba.it; jgabbard@vt.edu
RI Uva, Antonio/A-9673-2012; Gattullo, Michele/AAG-4866-2021; Evangelista,
   Alessandro/AAO-7025-2021; Fiorentino, Michele/M-6976-2015
OI Fiorentino, Michele/0000-0003-2197-6574; Gattullo,
   Michele/0000-0003-4487-0457; Evangelista, Alessandro/0000-0003-2045-1768
FU Italian Ministry of Education, University and Research under the
   Programme "Department of Excellence" [232/2016, CUP -D94I18000260001]
FX The authors would like to thank the International Relations Office of
   Polytechnic institute of Bari that has made possible, the visiting of
   Prof. J. L. Gabbard in Bari and then this collaboration. This work was
   supported by the Italian Ministry of Education, University and Research
   under the Programme "Department of Excellence" Legge 232/2016 (Grant No.
   CUP -D94I18000260001).
CR Abramovici M, 2017, PROC CIRP, V59, P18, DOI 10.1016/j.procir.2016.09.042
   Aleksy M, 2014, INT CON ADV INFO NET, P382, DOI 10.1109/AINA.2014.146
   American Society of Mechanical Engineers (ASME), 2007, A131 ASME
   [Anonymous], 2003, 2003 PRESENTED 2003
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Booth A., 2021, Systematic Approaches to a Successful Literature Review
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chen CJ, 2015, INT J ADV MANUF TECH, V76, P753, DOI 10.1007/s00170-014-6321-6
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dini G, 2015, PROC CIRP, V38, P14, DOI 10.1016/j.procir.2015.07.044
   Endsley Tristan C., 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2100, DOI 10.1177/1541931213602007
   Engelke T., 2015, Proceedings of the 6th ACM Multimedia Systems Conference on-MMSys '15, P105, DOI 10.1145/2713168.2713169
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Gabbard JL, 2005, P IEEE VIRT REAL ANN, P11
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gattullo M, 2020, LECT N MECH ENG, P106, DOI 10.1007/978-3-030-31154-4_10
   Gattullo M, 2015, IEEE COMPUT GRAPH, V35, P52, DOI 10.1109/MCG.2015.36
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hirano H., 1995, 5 PILLARS VISUAL WOR
   IFixit, 2019, FREE REP MAN
   International Standards Organization (ISO), 1984, INT STAND SAF COL SA
   International Standards Organization (ISO), 2003, 1281 ISO
   Junfeng Wang, 2014, 2014 IEEE International Conference on Automation Science and Engineering (CASE), P309, DOI 10.1109/CoASE.2014.6899343
   Kahn Svenja, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P241, DOI 10.1109/ISMAR.2010.5643587
   Kerbl B, 2015, COMPUT GRAPH FORUM, V34, P287, DOI 10.1111/cgf.12560
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Koch C, 2014, AUTOMAT CONSTR, V48, P18, DOI 10.1016/j.autcon.2014.08.009
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lechner M, 2013, WORK SOFTW ENG, P41, DOI 10.1109/SEARIS.2013.6798107
   Lee JY, 2008, INT J ADV MANUF TECH, V37, P431, DOI 10.1007/s00170-007-0996-x
   Lorenz M, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P151, DOI 10.1109/ISMAR-Adjunct.2018.00055
   MacIntyre B, 2011, INT SYM MIX AUGMENT
   MARRADI A, 1990, QUAL QUANT, V24, P129
   Mura MD, 2016, PROC CIRP, V41, P340, DOI 10.1016/j.procir.2015.12.128
   Nee AYC, 2012, CIRP ANN-MANUF TECHN, V61, P657, DOI 10.1016/j.cirp.2012.05.010
   Ong SK, 2008, INT J PROD RES, V46, P2707, DOI 10.1080/00207540601064773
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Pathomaree N, 2005, 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN), P500
   Peirce C. S, 1931, COLLECTED WRITINGS, V58
   Pierdicca R, 2017, LECT NOTES COMPUT SC, V10324, P389, DOI 10.1007/978-3-319-60922-5_30
   Radkowski R, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 1B
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Rankohi S., 2013, Visualization in Engineering, V1, P9, DOI DOI 10.1186/2213-7459-1-9
   Riexinger G, 2018, PROC CIRP, V72, P1124, DOI 10.1016/j.procir.2018.03.160
   Rolim C, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P120, DOI 10.1109/ISMAR.2015.36
   Rolland J.P., 2016, Handbook of Visual Display Technology, P1
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001
   Stork S, 2010, ADV ENG INFORM, V24, P320, DOI 10.1016/j.aei.2010.05.010
   Syberfeldt A, 2017, IEEE ACCESS, V5, P9118, DOI 10.1109/ACCESS.2017.2703952
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   Van Krevelen D., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10.20870/ijvr.2010.9.2.2767
   Vignali G, 2018, INT J FOOD ENG, V14, DOI 10.1515/ijfe-2017-0122
   Webel S, 2013, ROBOT AUTON SYST, V61, P398, DOI 10.1016/j.robot.2012.09.013
   Werrlich S., 2017, International Journal of Computer and Information Engineering, V11, P1068
   Werrlich S., 2018, SMARTOBJECTS CHI, P58
   Werrlich S, 2018, INT SYM MIX AUGMENT, P134, DOI 10.1109/ISMAR.2018.00046
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935
   Zauner J, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P237, DOI 10.1109/ISMAR.2003.1240707
   Zhang J, 2011, INT J PROD RES, V49, P3919, DOI 10.1080/00207543.2010.492802
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 69
TC 56
Z9 58
U1 6
U2 64
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1443
EP 1456
DI 10.1109/TVCG.2020.3014614
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300018
PM 32759085
DA 2024-11-06
ER

PT J
AU Woodin, G
   Winter, B
   Padilla, L
AF Woodin, Greg
   Winter, Bodo
   Padilla, Lace
TI Conceptual Metaphor and Graphical Convention Influence the
   Interpretation of Line Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Conceptual metaphor theory; more is up; mental number line; cognition;
   linguistics; emotional valence; line graph; axis reversal; handedness;
   empirical evaluation
ID R PACKAGE; TIME; REPRESENTATIONS; ASSOCIATION; LANGUAGE; VALENCE; SPACE;
   EYE
AB Many metaphors in language reflect conceptual metaphors that structure thought. In line with metaphorical expressions such as 'high number', experiments show that people associate larger numbers with upward space. Consistent with this metaphor, high numbers are conventionally depicted in high positions on the y-axis of line graphs. People also associate good and bad (emotional valence) with upward and downward locations, in line with metaphorical expressions such as 'uplifting' and 'down in the dumps'. Graphs depicting good quantities (e.g., vacation days) are consistent with graphical convention and the valence metaphor, because 'more' of the good quantity is represented by higher y-axis positions. In contrast, graphs depicting bad quantities (e.g., murders) are consistent with graphical convention, but not the valence metaphor, because more of the bad quantity is represented by higher (rather than lower) y-axis positions. We conducted two experiments (N = 300 per experiment) where participants answered questions about line graphs depicting good and bad quantities. For some graphs, we inverted the conventional axis ordering of numbers. Line graphs that aligned (versus misaligned) with valence metaphors (up = good) were easier to interpret, but this beneficial effect did not outweigh the adverse effect of inverting the axis numbering. Line graphs depicting good (versus bad) quantities were easier to interpret, as were graphs that depicted quantity using the x-axis (versus y-axis). Our results suggest that conceptual metaphors matter for the interpretation of line graphs. However, designers of line graphs are warned against subverting graphical convention to align with conceptual metaphors.
C1 [Woodin, Greg; Winter, Bodo] Univ Birmingham, Dept English Language & Linguist, Birmingham B15 2SQ, W Midlands, England.
   [Woodin, Greg] Univ Calif Merced, Appl Cognit & Educ Lab, Spatial Percept, Merced, CA 95343 USA.
C3 University of Birmingham; University of California System; University of
   California Merced
RP Woodin, G (corresponding author), Univ Birmingham, Dept English Language & Linguist, Birmingham B15 2SQ, W Midlands, England.; Woodin, G (corresponding author), Univ Calif Merced, Appl Cognit & Educ Lab, Spatial Percept, Merced, CA 95343 USA.
EM gawoodin@gmail.com; bodo@bodowinter.com
RI Winter, Bodo/K-6975-2018
OI Woodin, Greg/0000-0001-7992-4991
FU Economic and Social Research Council [ES/P000711/1]; UKRI Future Leaders
   Fellowship [MR/T040505/1]; ESRC [2067243] Funding Source: UKRI; FLF
   [MR/T040505/1] Funding Source: UKRI
FX The work of Greg Woodin was supported by the Economic and Social
   Research Council under Grant ES/P000711/1. The work of Bodo Winter was
   supported by the UKRI Future Leaders Fellowship under Grant
   MR/T040505/1.
CR Abdul-Rahman A, 2017, INFORM VISUAL, V16, P275, DOI 10.1177/1473871616666395
   [Anonymous], 1989, POLISH PSYCHOL B
   [Anonymous], 2021, AMAZON MECH TURK
   Averick M., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI DOI 10.21105/JOSS.01686
   Barrett LF, 1999, CURR DIR PSYCHOL SCI, V8, P10, DOI 10.1111/1467-8721.00003
   Bjork R. A., 1994, Metacognition: Knowing about knowing, P185, DOI DOI 10.7551/MITPRESS/4561.003.0011
   Boroditsky L, 2002, PSYCHOL SCI, V13, P185, DOI 10.1111/1467-9280.00434
   Boroditsky L, 2000, COGNITION, V75, P1, DOI 10.1016/S0010-0277(99)00073-6
   Bürkner PC, 2018, R J, V10, P395
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Casasanto D, 2017, METAPHOR: EMBODIED COGNITION AND DISCOURSE, P46
   Casasanto D, 2014, WIRES COGN SCI, V5, P139, DOI 10.1002/wcs.1271
   Casasanto D, 2012, COGNITIVE SCI, V36, P359, DOI 10.1111/j.1551-6709.2011.01199.x
   Casasanto D, 2010, COGNITION, V115, P179, DOI 10.1016/j.cognition.2009.11.002
   Casasanto D, 2009, J EXP PSYCHOL GEN, V138, P351, DOI 10.1037/a0015854
   Chinello A, 2012, FUNCT NEUROL, V27, P177
   Conson M, 2008, EXP BRAIN RES, V187, P267, DOI 10.1007/s00221-008-1300-5
   Correll M., 2017, P IEEE DECISIVE WORK, P1
   Cotgreave A, 2016, LIES DAMN LIES STAT
   Cox D., 2006, Aesthetic Computing, P89
   Cox D.J., 2004, Technoetic Arts: A Journal of Speculative Research, V2, P71
   DEHAENE S, 1993, J EXP PSYCHOL GEN, V122, P371, DOI 10.1037/0278-7393.21.2.314
   deVilla J, 2014, LIES DAMNED LIES REU
   Engel P, 2014, GUN DEATHS FLORIDA I
   Enten Harry., 2016, FIVETHIRTYEIGHT
   Fernande<prime>z S. Ruiz, 2014, P 6 INT C MED SPAC E
   Fernández-i-Marín X, 2016, J STAT SOFTW, V70, DOI 10.18637/jss.v070.i09
   Fischer M, 2009, EXP BRAIN RES, V192, P149, DOI 10.1007/s00221-008-1622-3
   Fischer MH, 2005, APPL COGNITIVE PSYCH, V19, P953, DOI 10.1002/acp.1105
   Gibbs R. W., 1994, The poetics of mind: Figurative thought, language, and understanding
   Hartmann M, 2016, PSYCHOL RES-PSYCH FO, V80, P399, DOI 10.1007/s00426-015-0722-5
   Hartmann M, 2014, J EXP PSYCHOL HUMAN, V40, P1401, DOI 10.1037/a0036686
   Hartmann M, 2012, J EXP PSYCHOL HUMAN, V38, P1416, DOI 10.1037/a0026706
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Ishihara M, 2008, CORTEX, V44, P454, DOI 10.1016/j.cortex.2007.08.010
   Leone MJ, 2018, CONSCIOUS COGN, V59, P10, DOI 10.1016/j.concog.2018.01.005
   Kay Matthew, 2023, TIDYBAYES TIDY DATA, DOI DOI 10.5281/ZENODO.1308151
   Kim SY, 2006, STAT METHODS MED RES, V15, P3, DOI 10.1191/0962280206sm423oa
   Kosara R., 2014, When Bars Point Down
   Kovecses Z, 2010, Metaphor: a Practical introduction, Vsecond
   Lakoff G., 1980, Metaphors We Live By
   Lallanilla Marc, 2014, MISLEADING GUN DEATH
   Lang PJ, 1997, ATTENTION AND ORIENTING: SENSORY AND MOTIVATIONAL PROCESSES, P97
   Loetscher T, 2008, NEUROSCIENCE, V151, P725, DOI 10.1016/j.neuroscience.2007.07.068
   Loetscher T, 2010, CURR BIOL, V20, pR264, DOI 10.1016/j.cub.2010.01.015
   Matlin M.W., 1978, The Pollyanna principle. Selectivity in language, memory, and thought
   McGlone MS, 1998, J EXP PSYCHOL LEARN, V24, P1211, DOI 10.1037/0278-7393.24.5.1211
   Meier BP, 2006, J RES PERS, V40, P451, DOI 10.1016/j.jrp.2005.03.001
   Meier BP, 2004, PSYCHOL SCI, V15, P243, DOI 10.1111/j.0956-7976.2004.00659.x
   Padilla LM, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P69, DOI 10.1109/BELIV.2018.8634267
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Parsons P.C., 2018, 2018 IEEE VIS Workshop on Visualization for Communication (VisComm), P1
   PEETERS G, 1971, EUR J SOC PSYCHOL, V1, P455, DOI 10.1002/ejsp.2420010405
   Peeters G., 1990, EUROPEAN REV SOCIAL, V1, P33, DOI [10.1080/14792779108401856, DOI 10.1080/14792779108401856]
   Pollock L, 2018, BEHAV RES METHODS, V50, P1198, DOI 10.3758/s13428-017-0938-y
   Qualtrics, 2019, 4 COR EXP BUS 4 APPL
   R Core Team, 2020, R: a language and environment for statistical computing
   Risch J. S., 2008, ARXIV08090884
   RStudio Team, 2021, RStudio: Integrated Development for R
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Scarr S., 2011, Iraq's bloody toll
   Seno T, 2013, COGNITION, V126, P115, DOI 10.1016/j.cognition.2012.08.009
   Tanber G., 2014, REUTERS
   Tversky B, 2011, TOP COGN SCI, V3, P499, DOI 10.1111/j.1756-8765.2010.01113.x
   Vaish A, 2008, PSYCHOL BULL, V134, P383, DOI 10.1037/0033-2909.134.3.383
   Vallesi A, 2008, COGNITION, V107, P501, DOI 10.1016/j.cognition.2007.10.011
   Van Strien JW, 2000, BRAIN COGNITION, V44, P645, DOI 10.1006/brcg.1999.1137
   VESSEY I, 1991, DECISION SCI, V22, P219, DOI 10.1111/j.1540-5915.1991.tb00344.x
   Wade L, 2014, LIE STAT STAND YOUR
   Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x
   Wattenberg M, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P1, DOI 10.1109/INFVIS.2005.1532122
   Wickham H, 2011, J STAT SOFTW, V40, P1, DOI 10.18637/jss.v040.i01
   Winter B., 2013, Proceedings of the 35th annual conference of the Cognitive Science Society, P3789
   Winter B, 2017, METAPHOR: EMBODIED COGNITION AND DISCOURSE, P99
   Winter B, 2015, NEUROSCI BIOBEHAV R, V57, P209, DOI 10.1016/j.neubiorev.2015.09.005
   Winter B, 2015, CORTEX, V64, P209, DOI 10.1016/j.cortex.2014.10.015
   Wood G., 2008, Psychology Science Quarterly, V50, P489, DOI DOI 10.1027/1618-3169.52.3.187
   Woodin G, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02169
NR 80
TC 4
Z9 4
U1 2
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1209
EP 1221
DI 10.1109/TVCG.2021.3088343
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA YC3YL
UT WOS:000739630200001
PM 34110996
DA 2024-11-06
ER

PT J
AU Chen, SY
   Zhang, JQ
   Gao, L
   He, Y
   Xia, SH
   Shi, M
   Zhang, FL
AF Chen, Shu-Yu
   Zhang, Jia-Qi
   Gao, Lin
   He, Yue
   Xia, Shihong
   Shi, Min
   Zhang, Fang-Lue
TI Active Colorization for Cartoon Line Drawings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Image segmentation; Semantics; Feature extraction;
   Shape; Machine learning; Animation; Active learning; line drawing
   colorization; region matching
AB In the animation industry, the colorization of raw sketch images is a vitally important but very time-consuming task. This article focuses on providing a novel solution that semiautomatically colorizes a set of images using a single colorized reference image. Our method is able to provide coherent colors for regions that have similar semantics to those in the reference image. An active-learning-based framework is used to match local regions, followed by mixed-integer quadratic programming (MIQP) which considers the spatial contexts to further refine the matching results. We efficiently utilize user interactions to achieve high accuracy in the final colorized images. Experiments show that our method outperforms the current state-of-the-art deep learning based colorization method in terms of color coherency with the reference image. The region matching framework could potentially be applied to other applications, such as color transfer.
C1 [Chen, Shu-Yu; Gao, Lin; He, Yue; Xia, Shihong] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
   [Chen, Shu-Yu; Gao, Lin; He, Yue; Xia, Shihong] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Zhang, Jia-Qi; Shi, Min] North China Elect Power Univ, Beijing 102206, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6012, New Zealand.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; North China Electric Power University; Victoria University
   Wellington
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
EM chenshuyu@ict.ac.cn; zhangjiaqi@ncepu.edu.cn; gaolin@ict.ac.cn;
   heyue@ict.ac.cn; xsh@ict.ac.cn; shi_min@ncepu.edu.cn;
   fanglue.zhang@ecs.vuw.ac.nz
RI Gao, Lin/JNF-0375-2023
OI jiaqi, zhang/0000-0002-8482-3666
FU Royal Society Newton Advanced Fellowship [NAF\R2\192151]; National
   Natural Science Foundation of China [61872440]; CCF-Tencent Open Fund;
   Tencent AI Lab Rhino-Bird Focused Research Program [JR202024]; Beijing
   Municipal Natural Science Foundation [L182016]; Youth Innovation
   Promotion Association CAS; Victoria Early-Career Research Excellence
   Award
FX This work was supported by Royal Society Newton Advanced Fellowship (No.
   NAFnR2n192151), National Natural Science Foundation of China (No.
   61872440), CCF-Tencent Open Fund, Tencent AI Lab Rhino-Bird Focused
   Research Program (No. JR202024), Beijing Municipal Natural Science
   Foundation (No. L182016), Youth Innovation Promotion Association CAS and
   Victoria Early-Career Research Excellence Award. The author would like
   to thank Simon Finnie (CMIC, Victoria University ofWellington) for
   proofreading the article. Shu-Yu Chen and Jia-Qi Zhang contributed
   equally to this work.
CR [Anonymous], 2014, SA '14
   Barnes Connelly, 2017, [Computational Visual Media, 计算可视媒体], V3, P3
   Barnes C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766934
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gal Y, 2017, PR MACH LEARN RES, V70
   Hensman P, 2017, PROC INT CONF DOC, P72, DOI 10.1109/ICDAR.2017.295
   Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li X, 2013, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2013.116
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Qi GJ, 2008, PROC CVPR IEEE, P325
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Rouhani M, 2012, LECT NOTES COMPUT SC, V7578, P264, DOI 10.1007/978-3-642-33786-4_20
   Sangkloy, 2016, ARXIV161200835
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Varga D, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095742
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   Zhu X., 2003, P 20 INT C MACH LEAR
NR 25
TC 14
Z9 14
U1 4
U2 30
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1198
EP 1208
DI 10.1109/TVCG.2020.3009949
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300001
PM 32746275
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hinterreiter, A
   Ruch, P
   Stitz, H
   Ennemoser, M
   Bernard, J
   Strobelt, H
   Streit, M
AF Hinterreiter, Andreas
   Ruch, Peter
   Stitz, Holger
   Ennemoser, Martin
   Bernard, Jurgen
   Strobelt, Hendrik
   Streit, Marc
TI ConfusionFlow: A Model-Agnostic Visualization for Temporal Analysis of
   Classifier Confusion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Analytical models; Data models; Training; Tools;
   Adaptation models; Data visualization; Classification; performance
   analysis; time series visualization; machine learning; information
   visualization; quality assessment
ID VISUAL ANALYTICS
AB Classifiers are among the most widely used supervised machine learning algorithms. Many classification models exist, and choosing the right one for a given task is difficult. During model selection and debugging, data scientists need to assess classifiers' performances, evaluate their learning behavior over time, and compare different models. Typically, this analysis is based on single-number performance measures such as accuracy. A more detailed evaluation of classifiers is possible by inspecting class errors. The confusion matrix is an established way for visualizing these class errors, but it was not designed with temporal or comparative analysis in mind. More generally, established performance analysis systems do not allow a combined temporal and comparative analysis of class-level information. To address this issue, we propose ConfusionFlow, an interactive, comparative visualization tool that combines the benefits of class confusion matrices with the visualization of performance characteristics over time. ConfusionFlow is model-agnostic and can be used to compare performances for different model types, model architectures, and/or training and test datasets. We demonstrate the usefulness of ConfusionFlow in a case study on instance selection strategies in active learning. We further assess the scalability of ConfusionFlow and present a use case in the context of neural network pruning.
C1 [Hinterreiter, Andreas; Stitz, Holger] Johannes Kepler Univ Linz, Inst Comp Graph, A-4040 Linz, Austria.
   [Hinterreiter, Andreas] Imperial Coll London, Biomed Image Anal Grp, London SW7 2AZ, England.
   [Ruch, Peter] Johannes Kepler Univ Linz, Inst Machine Learning, A-4040 Linz, Austria.
   [Streit, Marc] Johannes Kepler Univ Linz, Visual Data Sci, A-4040 Linz, Austria.
   [Stitz, Holger] Datavisyn GmbH, A-4040 Linz, Austria.
   [Ennemoser, Martin] Salesbeat GmbH, A-4060 Leonding, Austria.
   [Strobelt, Hendrik] IBM Res, Cambridge, MA 02142 USA.
   [Bernard, Jurgen] Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.
C3 Johannes Kepler University Linz; Imperial College London; Johannes
   Kepler University Linz; Johannes Kepler University Linz; International
   Business Machines (IBM); University of British Columbia
RP Hinterreiter, A (corresponding author), Johannes Kepler Univ Linz, Inst Comp Graph, A-4040 Linz, Austria.
EM andreas.hinterreiter@jku.at; peter.ruch@jku.at; holger.stitz@jku.at;
   m.ennemoser@salesbeat.io; jubernar@cs.ubc.ca; hendrik.strobelt@ibm.com;
   marc.streit@jku.at
RI Bernard, Jürgen/AAK-5732-2021
OI Strobelt, Hendrik/0000-0002-8995-1683; Streit, Marc/0000-0001-9186-2092;
   Stitz, Holger/0000-0002-4742-2636
FU State of Upper Austria; Austrian Federal Ministry of Education, Science
   and Research via the LIT -Linz Institute of Technology
   [LIT2019-7-SEE-117]; State of Upper Austria (HumanInterpretable Machine
   Learning); Austrian Research Promotion Agency [FFG 851460]; Austrian
   Science Fund (FWF) [P27975-NBL]; Austrian Science Fund (FWF) [P27975]
   Funding Source: Austrian Science Fund (FWF)
FX This work was supported in part by the State of Upper Austria and the
   Austrian Federal Ministry of Education, Science and Research via the LIT
   -Linz Institute of Technology (LIT2019-7-SEE-117), by the State of Upper
   Austria (HumanInterpretable Machine Learning), by the Austrian Research
   Promotion Agency (FFG 851460), and by the Austrian Science Fund (FWF
   P27975-NBL). Andreas Hinterreiter and Peter Ruch contributed equally to
   this work.
CR Abadi M, ARXIV
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Andrienko N., 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   Bernard J., 2015, THESIS TU DARMSTADT
   Bernard J, 2019, COMPUT GRAPH FORUM, V38, P401, DOI 10.1111/cgf.13698
   Bernard J, 2018, VISUAL COMPUT, V34, P1189, DOI 10.1007/s00371-018-1500-3
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bruckner D., 2014, ML O SCOPE DIAGNOSTI
   Chae J., 2017, P WORKSH VIS AN DEEP
   Chung S., 2016, P ACM SIGKDD WORKSH
   Dally, 2015, Advances in Neural Information Processing Systems, P1135, DOI DOI 10.5555/2969239.2969366
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   dos Santos Cicero, 2014, P COLING 2014 25 INT, P69
   Fayyad U, 1996, AI MAG, V17, P37
   Frankle J, 2018, ARXIV
   Fu TC, 2011, ENG APPL ARTIF INTEL, V24, P164, DOI 10.1016/j.engappai.2010.09.007
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Glorot X., 2011, P 28 INT C MACH LEAR
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Griffin G., Caltech-256 Object Category Dataset
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinterreiter A., 2020, ARXIV200711353
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman Fred, 2017, Ext Abstr Hum Factors Computing Syst, V2017, P1694, DOI 10.1145/3027063.3053103
   Kahng M., 2019, IEEE T VIS COMPUT GR, V25, P1
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kapoor A, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1343
   Krizhevsky A., Learning Multiple Layers of Features from Tiny Images
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu Z., 2018, INT C LEARNING REPRE
   Mayr A, 2018, CHEM SCI, V9, P5441, DOI 10.1039/c8sc00148k
   McLachlan P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1483
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Olah C., 2018, Distill, V3, P10, DOI [DOI 10.23915/DISTILL.00010, 10.23915/ distill.00010]
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Recht B., 2018, ARXIV180600451
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Settles B., 2012, SYNTHESIS LECT ARTIF, DOI [10.2200/S00429ED1V01Y201207AIM018, DOI 10.2200/S00429ED1V01Y201207AIM018]
   Simonyan K., 2013, PREPRINT
   Smilkov D., 2017, arXiv:1708.03788
   Socher R, 2013, P ADV NEUR INF PROC, P935, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Swihart BJ, 2010, EPIDEMIOLOGY, V21, P621, DOI 10.1097/EDE.0b013e3181e5b06a
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Vanschoren J., 2013, SIGKDD EXPLORATIONS, V15, P49, DOI [10.1145/2641190.2641198, DOI 10.1145/2641190.2641198]
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wu Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P529, DOI 10.1109/ICME.2006.262442
   Xiao H., 2017, FASHION MNIST NOVEL
   Zeng H, 2017, arXiv preprint arXiv:1710.05285
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 63
TC 21
Z9 24
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1222
EP 1236
DI 10.1109/TVCG.2020.3012063
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300002
PM 32746284
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, ZX
   Zu, XR
   Wang, YY
   Lelieveldt, BPF
   Tao, Q
AF Zhou, Zixia
   Zu, Xinrui
   Wang, Yuanyuan
   Lelieveldt, Boudewijn P. F.
   Tao, Qian
TI Deep Recursive Embedding for High-Dimensional Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Feature extraction; Training; Manifolds;
   Unsupervised learning; Standards; Tools; t-distributed stochastic
   neighbor embedding; uniform manifold approximation and projection; deep
   embedding network; deep recursive embedding; unsupervised learning
ID VISUALIZATION
AB Embedding high-dimensional data onto a low-dimensional manifold is of both theoretical and practical value. In this article, we propose to combine deep neural networks (DNN) with mathematics-guided embedding rules for high-dimensional data embedding. We introduce a generic deep embedding network (DEN) framework, which is able to learn a parametric mapping from high-dimensional space to low-dimensional space, guided by well-established objectives such as Kullback-Leibler (KL) divergence minimization. We further propose a recursive strategy, called deep recursive embedding (DRE), to make use of the latent data representations for boosted embedding performance. We exemplify the flexibility of DRE by different architectures and loss functions, and benchmarked our method against the two most popular embedding methods, namely, t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP). The proposed DRE method can map out-of-sample data and scale to extremely large datasets. Experiments on a range of public datasets demonstrated improved embedding performance in terms of local and global structure preservation, compared with other state-of-the-art embedding methods. Code is available at https://github.com/tao-aimi/DeepRecursiveEmbedding.
C1 [Zhou, Zixia; Wang, Yuanyuan] Fudan Univ, Dept Elect Engn, Shanghai 200433, Peoples R China.
   [Zu, Xinrui] Univ Twente, Fac Elect Engn Math & Comp Sci EEMCS, NL-7522 NB Enschede, Netherlands.
   [Wang, Yuanyuan] Key Lab Med Imaging Comp & Comp Assisted Interven, Shanghai 200032, Peoples R China.
   [Lelieveldt, Boudewijn P. F.] Leiden Univ Med Ctr, Dept Radiol, Div Image Proc, NL-2333 ZA Leiden, Netherlands.
   [Tao, Qian] Delft Univ Technol, Dept Imaging Phys, NL-2628 CJ Delft, Netherlands.
C3 Fudan University; University of Twente; Leiden University; Leiden
   University Medical Center (LUMC); Delft University of Technology
RP Tao, Q (corresponding author), Delft Univ Technol, Dept Imaging Phys, NL-2628 CJ Delft, Netherlands.
EM 16110720022@fudan.edu.cn; x.zu@student.utwente.nl; yywang@fudan.edu.cn;
   B.P.F.Lelieveldt@lumc.nl; q.tao@tudelft.nl
RI Lelieveldt, Boudewijn/B-6501-2008
OI Lelieveldt, Boudewijn/0000-0001-8269-7603; Tao, Qian/0000-0001-7480-0703
CR Balasubramanian M, 2002, SCIENCE, V295
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440
   Chan DM, 2018, INT SYM COMP ARCHIT, P330, DOI [10.1109/CAHPC.2018.8645912, 10.1109/SBAC-PAD.2018.00060]
   Denker J, 1991, P 4 INT C NEURAL INF, P895
   Elthakeb AT, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2002, ADV NEURAL INFORM PR, V15, P857, DOI DOI 10.5555/2968618.2968725
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Kobak D, 2019, BioRxiv, P2019
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Linderman GC, 2019, NAT METHODS, V16, P243, DOI 10.1038/s41592-018-0308-4
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Maas A. L., 2011, ANN M ASS COMP LING, P142
   Makhzani A., 2016, ICLR, P1
   McInnes L., 2018, J OPEN SOURCE SOFTW, V3, DOI [DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Poliar P. G., 2019, BIORXIV, DOI DOI 10.1101/731877
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Tasic B, 2018, NATURE, V563, P72, DOI 10.1038/s41586-018-0654-5
   van der Maaten L., 2009, J MACH LEARN RES, P384
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang B, 2017, NAT METHODS, V14, P414, DOI 10.1038/nmeth.4207
   Xiao H., 2017, FASHION MNIST NOVEL
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yosinski J, 2015, CoRR
NR 36
TC 4
Z9 4
U1 6
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1237
EP 1248
DI 10.1109/TVCG.2021.3122388
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300003
PM 34699363
OA Green Published, Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Jiddi, S
   Robert, P
   Marchand, E
AF Jiddi, Salma
   Robert, Philippe
   Marchand, Eric
TI Detecting Specular Reflections and Cast Shadows to Estimate Reflectance
   and Illumination of Dynamic Indoor Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Photometric registration; illumination; reflectance; diffuse; specular;
   shadow; texture; mixed reality; retexturing
ID AUGMENTED REALITY
AB The goal of Mixed Reality (MR) is to achieve a seamless and realistic blending between real and virtual worlds. This requires the estimation of reflectance properties and lighting characteristics of the real scene. One of the main challenges within this task consists in recovering such properties using a single RGB-D camera. In this article, we introduce a novel framework to recover both the position and color of multiple light sources as well as the specular reflectance of real scene surfaces. This is achieved by detecting and incorporating information from both specular reflections and cast shadows. Our approach is capable of handling any textured surface and considers both static and dynamic light sources. Its effectiveness is demonstrated through a range of applications including visually-consistent mixed reality scenarios (e.g., correct real specularity removal, coherent shadows in terms of shape and intensity) and retexturing where the texture of the scene is altered whereas the incident lighting is preserved.
C1 [Jiddi, Salma] Geomag Labs, Mountain View, CA 94041 USA.
   [Robert, Philippe] Interdigital, F-35576 Rennes, France.
   [Marchand, Eric] Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
C3 Universite de Rennes; Inria; Centre National de la Recherche
   Scientifique (CNRS)
RP Jiddi, S (corresponding author), Geomag Labs, Mountain View, CA 94041 USA.
EM salma.jiddi.pro@gmail.com; philippe.robert@interdigital.com;
   eric.marchand@irisa.fr
RI Robert, Philippe/J-7003-2017; Marchand, Eric/AAF-2809-2019
OI Marchand, Eric/0000-0001-7096-5236; Jiddi, Salma/0000-0002-5293-4038
CR [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00707
   Anusorn B., 2016, Int. J. Phys. Sci., V11, P168
   Arief I, 2012, COLOR IMAG CONF, P111
   Boom BJ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.105
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Marques BAD, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 1: GRAPP, P303, DOI 10.5220/0006724303030311
   Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891
   Gibson S, 2001, COMPUT GRAPH FORUM, V20, pC203, DOI 10.1111/1467-8659.00513
   Jachnik J, 2012, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2012.6402544
   Jiddi S, 2018, IEEE IMAGE PROC, P1063, DOI 10.1109/ICIP.2018.8451078
   Jiddi S, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P244, DOI [10.1109/ISMAR-Adjunct.2016.0085, 10.1109/ISMAR-Adjunct.2016.76]
   Karsch K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602146
   Kronander J, 2015, COMPUT GRAPH FORUM, V34, P643, DOI 10.1111/cgf.12591
   Li YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1366, DOI 10.1109/ICCV.2003.1238649
   Li ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275055
   Meilland M, 2013, INT SYM MIX AUGMENT, P143, DOI 10.1109/ISMAR.2013.6671774
   Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573
   Ortiz F, 2006, IEEE T SYST MAN CY C, V36, P681, DOI 10.1109/TSMCC.2005.855424
   Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585
   Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Rohmer K, 2014, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2014.6948406
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Sato I, 2003, IEEE T PATTERN ANAL, V25, P290, DOI 10.1109/TPAMI.2003.1182093
   Sato I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P875, DOI 10.1109/ICCV.1999.790314
   Sharma G., 2002, Digital Color Imaging Handbook
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Thai B, 2017, SIGNAL IMAGE VIDEO P, V11, P525, DOI 10.1007/s11760-016-0990-6
   Unger J, 2013, COMPUT GRAPH-UK, V37, P923, DOI 10.1016/j.cag.2013.07.001
NR 30
TC 10
Z9 11
U1 2
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1249
EP 1260
DI 10.1109/TVCG.2020.2976986
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300004
PM 32142442
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gao, ZH
   Wang, HQ
   Lv, HW
   Wang, MS
   Qi, YF
AF Gao, Zihan
   Wang, Huiqiang
   Lv, Hongwu
   Wang, Moshu
   Qi, Yifan
TI Evaluating the Effects of Non-Isomorphic Rotation on 3D Manipulation
   Tasks in Mixed Reality Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Three-dimensional displays; Virtual reality; Solid
   modeling; User interfaces; Usability; Manipulator dynamics; Virtual
   reality; augmented reality; mixed reality simulation; 3D interaction;
   non-isomorphic rotation
ID VIRTUAL-REALITY; AUGMENTED REALITY; SEARCH; SYSTEM
AB As a hyper-natural interaction technique in 3D user interfaces, non-isomorphic rotation has been considered an effective approach for rotation tasks, where a static or dynamic control-display gain can be applied to amplify or attenuate a rotation. However, it is not clear whether non-isomorphic rotation can benefit 6-degree-of-freedom (6-DOF) manipulation tasks in AR and VR. In this article, we extended the usability studies of non-isomorphic rotation from rotation-only tasks to 6-DOF manipulation tasks and analyzed the collected data using a 2-component model. Using a mixed reality (MR) simulation approach, we also investigated whether environment (AR or VR) had an impact on 3D manipulation tasks. The results reveal that although both static and dynamic non-isomorphic rotation techniques could save time and effort in ballistic phases, only dynamic non-isomorphic rotation was significantly faster than isomorphic rotation. Interestingly, while environment had no significant impact on overall user performance, we found evidence that it could affect fine-tuning in correction phases. We also found that most participants preferred AR over VR, indicating that environmental visual realism could be helpful to improve user experience.
C1 [Gao, Zihan; Wang, Huiqiang; Lv, Hongwu; Wang, Moshu] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Wang, Huiqiang] Peng Cheng Lab, Shenzhen 518000, Guangdong, Peoples R China.
   [Qi, Yifan] Commun Univ China, Sch Animat & Digital Arts, Beijing 100024, Peoples R China.
C3 Harbin Engineering University; Peng Cheng Laboratory; Communication
   University of China
RP Wang, HQ (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM zihan@hrbeu.edu.cn; wanghuiqiang@hrbeu.edu.cn; lvhongwu@hrbeu.edu.cn;
   lijingxini@hrbeu.edu.cn; ani-evonne@cuc.edu.cn
RI Gao, Zihan/GWQ-5679-2022
OI Gao, Zihan/0000-0001-9624-5587; LV, Hongwu/0000-0002-1917-3978; Wang,
   Huiqiang/0000-0002-1007-5589
FU Natural Science Foundation of China [61872104]; Natural Science
   Foundation of Heilongjiang Province in China [F2016028]; Fundamental
   Research Fund for the Central Universities in China [3072020CF0603];
   project "PCL Future Greater-Bay Area Network Facilities for Large-scale
   Experiments and Applications'' [LZC0019]; Tianjin Key Laboratory of
   Advanced Networking (TANK), College of Intelligence and Computing,
   Tianjin University, Tianjin, China
FX The authors would like to thank all the reviewers and editors for their
   invaluable comments and feedback. They also would like to thank all the
   people participated in the user studies. This work is supported by the
   Natural Science Foundation of China (No. 61872104), the Natural Science
   Foundation of Heilongjiang Province in China (No. F2016028), the
   Fundamental Research Fund for the Central Universities in China (No.
   3072020CF0603). This work is partially supported by the project "PCL
   Future Greater-Bay Area Network Facilities for Large-scale Experiments
   and Applications (LZC0019)". This work is partially supported by Tianjin
   Key Laboratory of Advanced Networking (TANK), College of Intelligence
   and Computing, Tianjin University, Tianjin, China, H300350.
CR [Anonymous], 2008, P 16 EUR S VIRT ENV
   Arino JJ, 2014, BEHAV INFORM TECHNOL, V33, P646, DOI 10.1080/0144929X.2013.815277
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/VR.2019.8797975, 10.1109/vr.2019.8797975]
   Botden SMBI, 2007, WORLD J SURG, V31, P764, DOI 10.1007/s00268-006-0724-y
   Boud A. C., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P32, DOI 10.1109/IV.1999.781532
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.0070, 10.1109/ISMAR-Adjunct.2016.61]
   Fiorentino M, 2010, COMPUT AIDED DESIGN, V42, P462, DOI 10.1016/j.cad.2008.12.002
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Gaffary Y, 2017, IEEE T VIS COMPUT GR, V23, P2372, DOI 10.1109/TVCG.2017.2735078
   Gao ZH, 2019, MULTIMED TOOLS APPL, V78, P26569, DOI 10.1007/s11042-019-07843-3
   Gao ZH, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2018), P126, DOI 10.1145/3198910.3234659
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hinckley K., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P1, DOI 10.1145/263407.263408
   Hollerer T, 2012, INT IND TRAIN SIM ED, P1
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Irawati S., 2008, Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology, ACE 2008, P21, DOI DOI 10.1145/1501750.1501755
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Juan MC, 2010, COMPUT GRAPH-UK, V34, P756, DOI 10.1016/j.cag.2010.08.001
   KEENE ON, 1995, STAT MED, V14, P811, DOI 10.1002/sim.4780140810
   Khademi M, 2013, IEEE ENG MED BIO, P4613, DOI 10.1109/EMBC.2013.6610575
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Laha B, 2013, IEEE T VIS COMPUT GR, V19, P529, DOI 10.1109/TVCG.2013.43
   LaViola JJ, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P49
   LaViola Jr Joseph J., 2017, 3D USER INTERFACES T
   Lee C, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P77, DOI 10.1109/VR.2012.6180890
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Li L, 2017, AM J TRANSL RES, V9, P3867
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nabiyouni Mahdi., 2017, Frontiers in ICT, V3, P34
   Nieuwenhuizen K, 2009, IEEE COMPUT GRAPH, V29, P44, DOI 10.1109/MCG.2009.121
   PARSONS LM, 1995, J EXP PSYCHOL HUMAN, V21, P1259, DOI 10.1037/0096-1523.21.6.1259
   Poupyrev I., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P540, DOI 10.1145/332040.332497
   Poupyrev I., 1999, CHI'99 extended abstracts on Human factors in computing systems, P256
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Rodrigue M, 2015, P IEEE VIRT REAL ANN, P105, DOI 10.1109/VR.2015.7223331
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Sutherland Ivan, 1965, P C INT FED INF PROC, P506, DOI DOI 10.1109/MC.2005.274
   Veit M., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST'09, (New York, NY, USA), P51, DOI [10.1145/1643928.1643942, DOI 10.1145/1643928.1643942]
   Veit M, 2011, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2011.5759440
   Ware C., 1999, ACM Transactions on Computer-Human Interaction, V6, P162, DOI 10.1145/319091.319102
   Woodworth RS, 1899, PSYCHOL REV-MONOGR S, V3, P1
   Zhai S., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P320, DOI 10.1145/274644.274689
   ZHAI SM, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P459, DOI 10.1145/191666.191822
NR 53
TC 4
Z9 4
U1 3
U2 35
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1261
EP 1273
DI 10.1109/TVCG.2020.3010247
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300005
PM 32746279
DA 2024-11-06
ER

PT J
AU Angori, L
   Didimo, W
   Montecchiani, F
   Pagliuca, D
   Tappini, A
AF Angori, Lorenzo
   Didimo, Walter
   Montecchiani, Fabrizio
   Pagliuca, Daniele
   Tappini, Alessandra
TI Hybrid Graph Visualizations With ChordLink: Algorithms, Experiments, and
   Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Layout; Task analysis; Semiconductor device modeling;
   Prototypes; Sparse matrices; Stability analysis; Network visualization;
   graph drawing; hybrid visualization; chord diagrams; optimization
   algorithms; systems
ID INFORMATION; COMMUNITY; NETWORKS; NODETRIX
AB Many real-world networks are globally sparse but locally dense. Typical examples are social networks, biological networks, and information networks. This double structural nature makes it difficult to adopt a homogeneous visualization model that clearly conveys both an overview of the network and the internal structure of its communities at the same time. As a consequence, the use of hybrid visualizations has been proposed. For instance, NodeTrix combines node-link and matrix-based representations (Henry et al., 2007). In this article we describe ChordLink, a hybrid visualization model that embeds chord diagrams, used to represent dense subgraphs, into a node-link diagram, which shows the global network structure. The visualization makes it possible to interactively highlight the structure of a community while keeping the rest of the layout stable. We discuss the intriguing algorithmic challenges behind the ChordLink model, present a prototype system that implements it, and illustrate case studies on real-world networks.
C1 [Angori, Lorenzo; Didimo, Walter; Montecchiani, Fabrizio; Tappini, Alessandra] Univ Perugia, Dipartimento Ingn, Via G Duranti, I-9306125 Perugia, Italy.
   [Pagliuca, Daniele] Agenzia Entrate, I-52100 Arezzo, Italy.
C3 University of Perugia
RP Didimo, W (corresponding author), Univ Perugia, Dipartimento Ingn, Via G Duranti, I-9306125 Perugia, Italy.
EM lorenzoangori.94@gmail.com; walter.didimo@unipg.it;
   fabrizio.montecchiani@unipg.it; daniele.pagliuca@agenziaentrate.it;
   alessandra.tappini@unipg.it
RI Tappini, Alessandra/HPE-6422-2023
FU MIUR [20174LF3T8]; Universita degli Studi di Perugia [RICBA19FM]
FX tThe authors would like to thank the anonymous reviewers for their
   valuable suggestions. This work was partially supported by: oiTHORN
   MIUR, Grant 20174LF3T8 "AHeAD: efficient Algorithms for HArnessing
   networked Data", oiiTHORN Dip. di Ingegneria -Universit~a degli Studi di
   Perugia, Grant RICBA19FM: "Modelli, algoritmi e sistemi per la
   visualizzazione di grafi e reti". A preliminary version of this article
   appeared in the proceedings of the 27th International Symposium on Graph
   Drawing and Network Visualization [1].
CR Angelini P., 2017, J GRAPH ALGORITHMS A, V21, P731, DOI DOI 10.7155/JGAA.00437
   Angori L, 2019, LECT NOTES COMPUT SC, V11904, P276, DOI 10.1007/978-3-030-35802-0_22
   [Anonymous], 2013, HDB GRAPH DRAWING VI
   [Anonymous], 1993, Handbook of pattern recognition computer vision, DOI DOI 10.1142/9789814343138_0001
   Argyriou Evmorfia N., 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P153
   Arleo A, 2018, FUTURE GENER COMP SY, V87, P43, DOI 10.1016/j.future.2018.04.067
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Bedi P, 2016, WIRES DATA MIN KNOWL, V6, P115, DOI 10.1002/widm.1178
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandes U, 2002, LECT NOTES COMPUT SC, V2265, P501
   Da Lozzo G., 2018, J. Graph Algorithms Appl., V22, P139, DOI [DOI 10.7155/JGAA.00461, /10.7155/jgaa.00461]
   Di Giacomo E, 2019, ALGORITHMICA, V81, P3464, DOI 10.1007/s00453-019-00585-6
   Di Giacomo E, 2019, LECT NOTES COMPUT SC, V11355, P148, DOI 10.1007/978-3-030-10564-8_12
   Didimo W, 2018, DECIS SUPPORT SYST, V110, P71, DOI 10.1016/j.dss.2018.03.008
   Didimo W, 2014, J VISUAL LANG COMPUT, V25, P433, DOI 10.1016/j.jvlc.2014.01.002
   Didimo W, 2014, INFORM SCIENCES, V260, P185, DOI 10.1016/j.ins.2013.09.048
   Dogrusoz U, 2009, INFORM SCIENCES, V179, P980, DOI 10.1016/j.ins.2008.11.017
   Eades P., 1995, P INT S GRAPH DRAW, P202
   Eklund P, 2002, FIRST INTERNATIONAL SYMPOSIUM ON CYBER WORLDS, PROCEEDINGS, P405, DOI 10.1109/CW.2002.1180907
   Eppstein D, 2018, ALGORITHMICA, V80, P977, DOI 10.1007/s00453-017-0328-y
   Fekete J.-D., 2003, Posters compendium of InfoVis, P82
   Flake GW, 2002, COMPUTER, V35, P66, DOI 10.1109/2.989932
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gabrielli L, 2014, LECT NOTES ARTIF INT, V8313, P26, DOI 10.1007/978-3-319-04178-0_3
   Gansner ER, 2007, LECT NOTES COMPUT SC, V4372, P386
   Gansner ER, 2010, IEEE COMPUT GRAPH, V30, P54, DOI 10.1109/MCG.2010.101
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   HAREL D, 1988, COMMUN ACM, V31, P514, DOI 10.1145/42411.42414
   Henry N, 2008, IEEE T VIS COMPUT GR, V14, P1317, DOI 10.1109/TVCG.2008.141
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huang WD, 2014, J VISUAL LANG COMPUT, V25, P452, DOI 10.1016/j.jvlc.2014.03.001
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kaufmann M., 2001, DRAWING GRAPHS METHO
   Koochaksaraei RH, 2017, KNOWL-BASED SYST, V138, P134, DOI 10.1016/j.knosys.2017.09.035
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   Lee B, 2006, IEEE T VIS COMPUT GR, V12, P1414, DOI 10.1109/TVCG.2006.106
   Ley M., 2002, String Processing and Information Retrieval. 9th International Symposium, SPIRE 2002. Proceedings (Lecture Notes in Computer Science Vol.2476), P1
   Lin CC, 2020, IEEE T EMERG TOP COM, V8, P58, DOI 10.1109/TETC.2017.2671846
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mahmoud H, 2014, LECT N BIOINFORMAT, V8452, P62, DOI 10.1007/978-3-319-09042-9_5
   Meneghini IR, 2018, IEEE C EVOL COMPUTAT, P55, DOI 10.1109/CEC.2018.8477889
   Muelder C, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P231
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Onnela JP, 2004, EUR PHYS J B, V38, P353, DOI 10.1140/epjb/e2004-00128-7
   Porter MA., 2009, Notices of the American Mathematical Society, V56, P1082, DOI DOI 10.1103/PHYSREVE.69.066133
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Purchase HC, 2000, INTERACT COMPUT, V13, P147, DOI 10.1016/S0953-5438(00)00032-1
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sindre G., 1993, Proceedings 1993 IEEE Symposium on Visual Languages (Cat. No.93TH0562-9), P287, DOI 10.1109/VL.1993.269613
   Six J. M, 2003, P INT S GRAPH DRAW, P135
   Sugiyama K., 2002, GRAPH DRAWING APPL S, V11
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Weidong Huang, 2007, Journal of Graph Algorithms and Applications, V11, P397, DOI 10.7155/jgaa.00152
   Wu H, 2010, LECT NOTES COMPUT SC, V6215, P337
   Yang XS, 2017, IEEE T VIS COMPUT GR, V23, P181, DOI 10.1109/TVCG.2016.2598472
   Zhao SD, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2005.1532129
NR 60
TC 6
Z9 6
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1288
EP 1300
DI 10.1109/TVCG.2020.3016055
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300007
PM 32784142
DA 2024-11-06
ER

PT J
AU Zhu, PH
   Para, WR
   Frühstück, A
   Femiani, J
   Wonka, P
AF Zhu, Peihao
   Para, Wamiq Reyaz
   Fruhstuck, Anna
   Femiani, John
   Wonka, Peter
TI Large-Scale Architectural Asset Extraction from Panoramic Imagery
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data mining; Object detection; Solid modeling; Urban planning; Microsoft
   Windows; Visualization; Three-dimensional displays; Asset extraction;
   urban modeling; object detection; clustering; semantic segmentation
AB We present a system to extract architectural assets from large-scale collections of panoramic imagery. We automatically rectify and crop parts of the panoramic image that contain dominant planes, and then use object detection to extract assets such as facades and windows. We also provide various tools to identify attributes of the assets to determine the asset quality and index the assets for search. In addition, we propose a User Interface (UI) to visualize and query assets. Finally, we present applications for urban modeling and texture synthesis.
C1 [Zhu, Peihao; Para, Wamiq Reyaz; Fruhstuck, Anna; Wonka, Peter] King Abdullah Univ Sci & Technol, Dept Comp Sci, Jeddah 23955, Saudi Arabia.
   [Femiani, John] Miami Univ, Coll Engn & Comp, Oxford, OH 45056 USA.
C3 King Abdullah University of Science & Technology; University System of
   Ohio; Miami University
RP Wonka, P (corresponding author), King Abdullah Univ Sci & Technol, Dept Comp Sci, Jeddah 23955, Saudi Arabia.
EM peihao.zhu@kaust.edu.sa; wamiq.para@kaust.edu.sa;
   anna.fruehstueck@kaust.edu.sa; femianjc@miamioh.edu; pwonka@gmail.com
RI Zhu, Peihao/ACG-4841-2022
OI Zhu, Peihao/0000-0002-7122-1551; Wonka, Peter/0000-0003-0627-9746;
   Fruhstuck, Anna/0000-0002-3870-4850
FU KAUST Office of Sponsored Research (OSR) [OSR-CRG2018-3730,
   OSR-2019-CPF-4102.3]; Visual Computing Center at KAUST
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. This work was supported by the KAUST Office of
   Sponsored Research (OSR) under Award No. OSR-CRG2018-3730,
   OSR-2019-CPF-4102.3, and the Visual Computing Center at KAUST.
CR Affara L, 2016, LECT NOTES COMPUT SC, V9907, P437, DOI 10.1007/978-3-319-46487-9_27
   Anguelov D, 2010, COMPUTER, V43, P32, DOI 10.1109/MC.2010.170
   [Anonymous], 2017, P IEEE INT C COMPUTE
   Arietta SM, 2014, IEEE T VIS COMPUT GR, V20, P2624, DOI 10.1109/TVCG.2014.2346446
   Bazin JC, 2012, INT J ROBOT RES, V31, P63, DOI 10.1177/0278364911421954
   Brock A., 2019, P INT C LEARN REPR, P1
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178
   Crandall D., 2009, P 18 INT C WORLD WID, P761, DOI 10.1145/1526709.1526812
   Demir I, 2016, INT CONF 3D VISION, P194, DOI 10.1109/3DV.2016.28
   Desolneux A., 2007, GESTALT THEORY IMAGE, V34
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Dubey A, 2016, LECT NOTES COMPUT SC, V9905, P196, DOI 10.1007/978-3-319-46448-0_12
   Femiani J., 2018, ARXIV180508634CS
   Fond A, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P32, DOI 10.1109/ISMAR.2017.20
   Frohlich Bjorn, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3029, DOI 10.1109/ICPR.2010.742
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han F, 2005, IEEE I CONF COMP VIS, P1778
   Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI [10.1109/TPAMI.2008.65, 10.1109/TPAMI.2008.55]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Xun, 2018, LECT NOTES COMPUT SC, P172, DOI [10.1007/978-3-030-01219-9_11, DOI 10.1007/978-3-030-01219-9_11]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras T., 2018, INT C LEARNING REPRE, P1
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kelly T, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275065
   Kelly T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130823
   Kluger F, 2017, LECT NOTES COMPUT SC, V10496, P17, DOI 10.1007/978-3-319-66709-6_2
   Kosecká J, 2005, COMPUT VIS IMAGE UND, V100, P274, DOI 10.1016/j.cviu.2005.04.005
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Micusík B, 2008, PROC CVPR IEEE, P1127
   Nishida G, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13372
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Shen CH, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024218
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Simon G, 2018, LECT NOTES COMPUT SC, V11214, P323, DOI 10.1007/978-3-030-01249-6_20
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   St'ava O, 2010, COMPUT GRAPH FORUM, V29, P665, DOI 10.1111/j.1467-8659.2009.01636.x
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Tardif Jean-Philippe, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1250, DOI 10.1109/ICCV.2009.5459328
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tretyak E, 2012, INT J COMPUT VISION, V97, P305, DOI 10.1007/s11263-011-0488-1
   Tylecek R, 2013, LECT NOTES COMPUT SC, V8142, P364, DOI 10.1007/978-3-642-40602-7_39
   Vanegas CA, 2010, PROC CVPR IEEE, P358, DOI 10.1109/CVPR.2010.5540190
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Watson B, 2008, IEEE COMPUT GRAPH, V28, P18, DOI 10.1109/MCG.2008.58
   Wildenauer H, 2012, PROC CVPR IEEE, P2831, DOI 10.1109/CVPR.2012.6248008
   Wu CC, 2010, LECT NOTES COMPUT SC, V6312, P142
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181
   Zhai MH, 2016, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2016.610
   Zhou BL, 2014, LECT NOTES COMPUT SC, V8691, P519, DOI 10.1007/978-3-319-10578-9_34
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601145
   Zhu P., 2019, P IEEE CVF C COMP VI, P5104
NR 60
TC 5
Z9 5
U1 0
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1301
EP 1316
DI 10.1109/TVCG.2020.3010694
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300008
PM 32746280
DA 2024-11-06
ER

PT J
AU Patané, G
AF Patane, Giuseppe
TI Meshless Approximation and Helmholtz-Hodge Decomposition of Vector
   Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Kernel; Two dimensional displays; Three-dimensional displays; Harmonic
   analysis; Rotors; Boundary conditions; Principal component analysis;
   Vector fields; helmholtz-hodge decomposition; meshless representations;
   radial basis functions
ID OF-THE-ART; SCATTERED DATA; INTERPOLATION; COMPUTATION; FLOW;
   RECONSTRUCTION; VISUALIZATION; ALGORITHM; PARAMETER
AB The analysis of vector fields is crucial for the understanding of several physical phenomena, such as natural events (e.g., analysis of waves), diffusive processes, electric and electromagnetic fields. While previous work has been focused mainly on the analysis of 2D or 3D vector fields on volumes or surfaces, we address the meshless analysis of a vector field defined on an arbitrary domain, without assumptions on its dimension and discretisation. The meshless approximation of the Helmholtz-Hodge decomposition of a vector field is achieved by expressing the potential of its components as a linear combination of radial basis functions and by computing the corresponding conservative, irrotational, and harmonic components as solution to a least-squares or to a differential problem. To this end, we identify the conditions on the kernel of the radial basis functions that guarantee the existence of their derivatives. Finally, we demonstrate our approach on 2D and 3D vector fields measured by sensors or generated through simulation.
C1 [Patane, Giuseppe] CNR, CNR IMATI, Ist Matemat Applicata & Tecnol Informat Genova, I-16149 Genoa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Matematica
   Applicata e Tecnologie Informatiche "Enrico Magenes" (IMATI-CNR)
RP Patané, G (corresponding author), CNR, CNR IMATI, Ist Matemat Applicata & Tecnol Informat Genova, I-16149 Genoa, Italy.
EM patane@ge.imati.cnr.it
RI Patane', Giuseppe/O-1322-2013
FU ERC Advanced Grant CHANGE [694515]
FX The authors would like to thank the Reviewers for their thorough review
   and constructive comments, which helped us to improve the technical part
   and presentation of the paper, and Dr. Simone Cammarasana (CNR-IMATI)
   for his tests on the kernel-based sampling. This work was supported in
   part by the ERC Advanced Grant CHANGE, Nr. 694515.
CR Adams Bart., 2009, Eurographics 2009 Tutorials, P213
   Bauer D., 2002, Proceedings of the symposium on Data Visualisation 2002, VISSYM '02, Eurographics Association, Aire-la-Ville, Switzerland, Switzerland, P233, DOI [10.2312/VisSym/VisSym02/233-240, DOI 10.2312/VISSYM/VISSYM02/233-240]
   Bauer U, 2012, DISCRETE COMPUT GEOM, V47, P347, DOI 10.1007/s00454-011-9350-z
   Bhatia H, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12358
   Bhatia H, 2014, IEEE T VIS COMPUT GR, V20, P1566, DOI 10.1109/TVCG.2014.2312012
   Bhatia H, 2013, IEEE T VIS COMPUT GR, V19, P1386, DOI 10.1109/TVCG.2012.316
   Bhatia H, 2013, IEEE T VIS COMPUT GR, V19, P527, DOI 10.1109/TVCG.2012.62
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P305, DOI 10.1109/TVCG.2009.105
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davydov O, 2011, COMPUT MATH APPL, V62, P2143, DOI 10.1016/j.camwa.2011.06.037
   De Leeuw W., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P349, DOI 10.1109/VISUAL.1999.809907
   DYN N, 1986, SIAM J SCI STAT COMP, V7, P639, DOI 10.1137/0907043
   Edelsbrunner H., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P127, DOI 10.1145/1137856.1137878
   FARWIG R, 1986, J COMPUT APPL MATH, V16, P79, DOI 10.1016/0377-0427(86)90175-5
   Fattal R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964943
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Guskov I, 1999, COMP GRAPH, P325, DOI 10.1145/311535.311577
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Hart J.C., 1998, Mathematical Visualization, P257
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P129
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Macedo I., 2010, LEARNING DIVERGENCE
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Mann S, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P283, DOI 10.1109/VISUAL.2002.1183786
   McLoughlin T, 2010, COMPUT GRAPH FORUM, V29, P1807, DOI 10.1111/j.1467-8659.2010.01650.x
   MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414
   Morse BS, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P89, DOI 10.1109/SMA.2001.923379
   Narcowich FJ, 2006, CONSTR APPROX, V24, P175, DOI 10.1007/s00365-005-0624-7
   Ng A. Y., 2004, P 21 INT C MACH LEAR, P78, DOI DOI 10.1145/1015330.1015435
   Öztireli AC, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866190
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Patanè G, 2009, IEEE T VIS COMPUT GR, V15, P583, DOI 10.1109/TVCG.2009.22
   Pauly M, 2003, ACM T GRAPHIC, V22, P641, DOI 10.1145/882262.882319
   Petronetto F, 2010, IEEE T VIS COMPUT GR, V16, P338, DOI 10.1109/TVCG.2009.61
   Pobitzer A., 2010, EuroGraphics 2010 State of the Art Reports (STARs)
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P1789, DOI 10.1111/j.1467-8659.2011.01901.x
   Polthier K, 2000, SPRING COMP SCI, P147
   Praun E, 2000, COMP GRAPH, P465, DOI 10.1145/344779.344987
   Ribeiro PC, 2016, COMPUT GRAPH-UK, V55, P80, DOI 10.1016/j.cag.2016.01.001
   Rippa S, 1999, ADV COMPUT MATH, V11, P193, DOI 10.1023/A:1018975909870
   Rössl C, 2012, IEEE T VIS COMPUT GR, V18, P407, DOI 10.1109/TVCG.2011.78
   Sheather SJ, 2004, STAT SCI, V19, P588, DOI 10.1214/088342304000000297
   Skraba P, 2016, IEEE T VIS COMPUT GR, V22, P1683, DOI 10.1109/TVCG.2016.2534538
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Tong YY, 2003, ACM T GRAPHIC, V22, P445, DOI 10.1145/882262.882290
   Tricoche X, 2000, IEEE VISUAL, P359, DOI 10.1109/VISUAL.2000.885716
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Weinkauf T, 2004, COMPUT GRAPH FORUM, V23, P469, DOI 10.1111/j.1467-8659.2004.00778.x
   Wendland H., 1995, Advances in Computational Mathematics, V4, P389, DOI 10.1007/BF02123482
   WENDLAND H., 2004, Scattered Data Approximation, V17
   Westermann R, 2000, IEEE VISUAL, P147
   Wiebel A, 2007, IEEE T VIS COMPUT GR, V13, P641, DOI [10.1109/TVCG.2007.4293009, 10.1109/TVCG.2007.1036]
   Yu YZ, 2004, ACM T GRAPHIC, V23, P644, DOI 10.1145/1015706.1015774
   Zhao RD, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356546
   Zhong ZC, 2016, COMPUT AIDED GEOM D, V43, P68, DOI 10.1016/j.cagd.2016.02.013
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 64
TC 0
Z9 1
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1328
EP 1341
DI 10.1109/TVCG.2020.3016588
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300010
PM 32790632
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Trepkowski, C
   Marquardt, A
   Eibich, TD
   Shikanai, Y
   Maiero, J
   Kiyokawa, K
   Kruijff, E
   Schöning, J
   König, P
AF Trepkowski, Christina
   Marquardt, Alexander
   Eibich, Tom David
   Shikanai, Yusuke
   Maiero, Jens
   Kiyokawa, Kiyoshi
   Kruijff, Ernst
   Schoening, Johannes
   Koenig, Peter
TI Multisensory Proximity and Transition Cues for Improving Target
   Awareness in Narrow Field of View Augmented Reality Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Three-dimensional displays; Augmented
   reality; Urban areas; Working environment noise; Search problems;
   Augmented reality; view management; guidance; multisensory cues;
   performance; situation awareness
ID SITUATION AWARENESS; SEARCH PERFORMANCE; AUDITORY CUES; LOCALIZATION;
   ATTENTION; TACTILE; OBJECTS; RESOLUTION; MOVEMENTS; WARNINGS
AB Augmented reality applications allow users to enrich their real surroundings with additional digital content. However, due to the limited field of view of augmented reality devices, it can sometimes be difficult to become aware of newly emerging information inside or outside the field of view. Typical visual conflicts like clutter and occlusion of augmentations occur and can be further aggravated especially in the context of dense information spaces. In this article, we evaluate how multisensory cue combinations can improve the awareness for moving out-of-view objects in narrow field of view augmented reality displays. We distinguish between proximity and transition cues in either visual, auditory or tactile manner. Proximity cues are intended to enhance spatial awareness of approaching out-of-view objects while transition cues inform the user that the object just entered the field of view. In study 1, user preference was determined for 6 different cue combinations via forced-choice decisions. In study 2, the 3 most preferred modes were then evaluated with respect to performance and awareness measures in a divided attention reaction task. Both studies were conducted under varying noise levels. We show that on average the Visual-Tactile combination leads to 63% and Audio-Tactile to 65% faster reactions to incoming out-of-view augmentations than their Visual-Audio counterpart, indicating a high usefulness of tactile transition cues. We further show a detrimental effect of visual and audio noise on performance when feedback included visual proximity cues. Based on these results, we make recommendations to determine which cue combination is appropriate for which application.
C1 [Trepkowski, Christina; Marquardt, Alexander; Eibich, Tom David; Maiero, Jens; Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, D-53757 St Augustin, Germany.
   [Shikanai, Yusuke; Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Ikoma, Nara 6300192, Japan.
   [Kruijff, Ernst] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
   [Schoening, Johannes] Univ St Gallen, CH-9000 St Gallen, Switzerland.
   [Koenig, Peter] Osnabruck Univ, D-49074 Osnabruck, Germany.
C3 Hochschule Bonn Rhein Sieg; Nara Institute of Science & Technology;
   Simon Fraser University; University of St Gallen; University Osnabruck
RP Trepkowski, C; Marquardt, A (corresponding author), Bonn Rhein Sieg Univ Appl Sci, D-53757 St Augustin, Germany.
EM christina.trepkowski@h-brs.de; alexander.marquardt@h-brs.de;
   tom-david.eibich@h-brs.de; shikanai327327@gmail.com;
   jens.maiero@h-brs.de; kiyo@is.naist.jp; ernst.kruijff@h-brs.de;
   johannes.schoening@unisg.ch; pkoenig@uos.de
RI Schöning, Johannes/AAE-9585-2020; König, Peter/ABB-2380-2020
OI Shikanai, Yusuke/0000-0001-8322-5827; Marquardt,
   Alexander/0000-0002-2844-0804; Kruijff, Ernst/0000-0003-1625-0955;
   Konig, Peter/0000-0003-3654-5267; Eibich, Tom David/0000-0003-4309-9904;
   Schoning, Johannes/0000-0002-8823-4607
CR Ahmaniemi TeemuTuomas., 2009, Proceedings of the 2009 international conference on Multimodal interfaces, ICMI-MLMI '09, P335, DOI DOI 10.1145/1647314.1647383
   ALFANO PL, 1990, PERCEPT MOTOR SKILL, V70, P35, DOI 10.2466/PMS.70.1.35-45
   [Anonymous], 2002, P EUROHAPTICS
   [Anonymous], 2012, NEURAL BASEMULTISE
   [Anonymous], 2003, CHI 03 HUM FACT COMP
   [Anonymous], 2010, PSYCHOL SCI, DOI DOI 10.1177/0956797609354064
   [Anonymous], 1999, Web content accessibility guidelines 1.0
   [Anonymous], 2008, P 14 M INT C AUD DIS
   Ariza O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P327, DOI 10.1109/VR.2018.8446317
   Bajpai A, 2020, IEEE T HAPTICS, V13, P32, DOI 10.1109/TOH.2019.2962664
   Baldwin CL., 2012, P HUMAN FACTORS ERGO, V56, P1431, DOI DOI 10.1177/1071181312561404
   BECK J, 1973, PERCEPT PSYCHOPHYS, V14, P225, DOI 10.3758/BF03212381
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Blum J. R., 2012, Mobile and Ubiquitous Systems: Computing, Networking, and Services, P49
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Burigat S., 2006, P 8 C HUM COMP INT M, P239
   Burigat S., 2012, Proceedings of the 14th International Conference on Human-computer Interaction with Mobile Devices and Services, MobileHCI '12, P93
   Burke J. L., 2006, P 8 INT C MULT INT, P108, DOI DOI 10.1145/1180995.1181017
   Carrasco M, 2003, NAT NEUROSCI, V6, P699, DOI 10.1038/nn1079
   Case A., 2018, Designing with Sound: Fundamentals for Products and Services
   Chiras D.D., 2004, Environmental science: Creating a sustainable future
   Covelli JM, 2010, INT J AVIAT PSYCHOL, V20, P197, DOI 10.1080/10508411003617888
   Credé M, 2010, J PERS ASSESS, V92, P390, DOI 10.1080/00223891.2010.497393
   Oliveira VAD, 2016, IEEE HAPTICS SYM, P1, DOI 10.1109/HAPTICS.2016.7463147
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   DONDERS FC, 1969, ACTA PSYCHOL, V30, P412, DOI 10.1016/0001-6918(69)90065-1
   Driver J., 2004, CROSSMODAL SPACE CRO, DOI DOI 10.1093/ACPROF:OSO/9780198524861.001.0001
   Dubus G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082491
   Dux PE, 2006, NEURON, V52, P1109, DOI 10.1016/j.neuron.2006.11.009
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Foulsham T, 2008, VISION RES, V48, P1777, DOI 10.1016/j.visres.2008.05.018
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Grier RA., 2015, Proc Human Factors Ergonomics Soc Annual Meeting, V59, P1727, DOI DOI 10.1177/1541931215591373
   Gröhn M, 2002, VIRTUAL, SYNTHETIC, AND ENTERTAINMENT AUDIO, P337
   Gruenefeld U, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229438
   Gruenefeld U, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P742, DOI [10.1109/vr.2019.8797725, 10.1109/VR.2019.8797725]
   Gruenefeld U, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P109, DOI 10.1145/3131277.3132175
   Gustafson S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P787
   Gustafson Sean., 2007, EXTENDED ABSTRACTS H, P2399, DOI DOI 10.1145/1240866.1241014
   Haas EC, 2014, SAFETY SCI, V61, P29, DOI 10.1016/j.ssci.2013.07.011
   Henze N., 2010, Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries (NordiCHI 2010), P675, DOI [10.1145/1868914.1869002, DOI 10.1145/1868914.1869002]
   Hidaka S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10483
   HIRSCH J, 1989, VISION RES, V29, P1095, DOI 10.1016/0042-6989(89)90058-8
   Hopkins K, 2017, ERGONOMICS, V60, P692, DOI 10.1080/00140139.2016.1198495
   Jay C, 2003, PRESENCE-VIRTUAL AUG, V12, P268, DOI 10.1162/105474603765879521
   Jia DW, 2011, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2011, P263
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Kalat J. W, 2015, Biological psychology, V12th
   Katz BFG, 2012, VIRTUAL REAL-LONDON, V16, P253, DOI 10.1007/s10055-012-0213-6
   Kaul M., 2016, INPROCEEDINGS 2016 C, P2533
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kishishita N, 2014, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2014.6948425
   Knobel SEJ, 2020, IEEE ENG MED BIO, P3192, DOI [10.1109/EMBC44109.2020.9176516, 10.1109/embc44109.2020.9176516]
   Koelewijn T, 2009, EXP BRAIN RES, V195, P593, DOI 10.1007/s00221-009-1829-y
   König SU, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166647
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kruijff E, 2019, IEEE T VIS COMPUT GR, V25, P2821, DOI 10.1109/TVCG.2018.2854737
   Kuniecki M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00212
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Lehtinen V, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P445
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Lindeman R.W., 2004, ACM Symposium on Virtual Reality Software and Technology, P146, DOI DOI 10.1145/1077534.1077562
   LIPOWSKI ZJ, 1975, COMPR PSYCHIAT, V16, P199, DOI 10.1016/0010-440X(75)90047-4
   Losing V, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1093, DOI 10.1145/2638728.2641687
   M. Corporation, HOL 2 OV FEAT SPECS
   Maidenbaum S, 2014, NEUROSCI BIOBEHAV R, V41, P3, DOI 10.1016/j.neubiorev.2013.11.007
   Marquardt A, 2018, P ACM S VIRT REAL SO
   Marquardt A, 2020, IEEE T VIS COMPUT GR, V26, P3389, DOI 10.1109/TVCG.2020.3023605
   Marquardt A, 2019, INT SYM MIX AUGMENT, P190, DOI 10.1109/ISMAR.2019.000-3
   McDonald JJ, 2000, NATURE, V407, P906, DOI 10.1038/35038085
   McIntire JP, 2010, HUM FACTORS, V52, P41, DOI 10.1177/0018720810368806
   MCKEE SP, 1984, VISION RES, V24, P25, DOI 10.1016/0042-6989(84)90140-8
   Mohebbi R, 2009, HUM FACTORS, V51, P102, DOI 10.1177/0018720809333517
   Mossbridge JA, 2011, COGNITION, V121, P133, DOI 10.1016/j.cognition.2011.06.003
   MUDD SA, 1960, J APPL PSYCHOL, V44, P184, DOI 10.1037/h0045878
   Murata A, 2017, APPL ERGON, V60, P58, DOI 10.1016/j.apergo.2016.11.002
   Myles K, 2015, APPL ERGON, V48, P177, DOI 10.1016/j.apergo.2014.11.007
   N. O. A. Observatory, 2015, REC LIGHT LEV ILL OU
   Ng AWY, 2012, LECT NOTES ENG COMP, P1449
   Ngo MK, 2010, ATTEN PERCEPT PSYCHO, V72, P1654, DOI 10.3758/APP.72.6.1654
   Noonan MP, 2016, J NEUROSCI, V36, P1797, DOI 10.1523/JNEUROSCI.2133-15.2016
   OLDFIELD SR, 1984, PERCEPTION, V13, P581, DOI 10.1068/p130581
   Oviatt Sharon, 2004, P 6 INT C MULT INT, P129, DOI DOI 10.1145/1027933.1027957
   Parseihian G, 2016, IEEE T MULTIMEDIA, V18, P674, DOI 10.1109/TMM.2016.2531978
   Patterson R.D., 1982, GUIDELINES AUDITORY
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Prewett MS, 2012, IEEE T SYST MAN CY C, V42, P123, DOI 10.1109/TSMCC.2010.2103057
   Qian L, 2018, IEEE T VIS COMPUT GR, V24, P2936, DOI 10.1109/TVCG.2018.2868559
   Ragan E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P287, DOI 10.1109/VR.2009.4811058
   Ribeiro F, 2012, IEEE INT WORKSH MULT, P319, DOI 10.1109/MMSP.2012.6343462
   Roodaki H, 2017, IEEE T VIS COMPUT GR, V23, P2366, DOI 10.1109/TVCG.2017.2734327
   Ross D.A., 2000, P 4 INT ACM C ASS TE, P193, DOI [10.1145/354324.354380, DOI 10.1145/354324.354380]
   Saket B., 2013, Proceedings of the 2013 Conference on Computer Supported Cooperative Work, P149, DOI [DOI 10.1145/2441776.2441946, 10.1145/2441776.2441946]
   Sandor C, 2010, P IEEE VIRT REAL ANN, P47, DOI 10.1109/VR.2010.5444815
   Santangelo V, 2007, J EXP PSYCHOL HUMAN, V33, P1311, DOI 10.1037/0096-1523.33.6.1311
   Shi Y., 2007, CHI 07 EXTENDED ABST, P2651, DOI DOI 10.1145/1240866.1241057
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   Spence C, 2009, HEARING RES, V258, P134, DOI 10.1016/j.heares.2009.04.015
   Steed A., 2020, Interaction, V27, P62, DOI [DOI 10.1145/3406098, 10.1145/3406098]
   Stein BE, 1996, J COGNITIVE NEUROSCI, V8, P497, DOI 10.1162/jocn.1996.8.6.497
   Sungjae Hwang, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P235, DOI 10.1109/ISMAR.2010.5643584
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   TREISMAN A, 1986, SCI AM, V255, pB114
   TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9
   Trepkowski C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P575, DOI [10.1109/VR.2019.8798312, 10.1109/vr.2019.8798312]
   Uchiyama H., 2008, P 46 ANN SE REGIONAL, P336, DOI DOI 10.1145/1593105.1593195
   van de Merwe K, 2012, INT J AVIAT PSYCHOL, V22, P78, DOI 10.1080/10508414.2012.635129
   Van Erp J. B., 2001, P EUR, P99
   VERRILLO RT, 1983, PERCEPT PSYCHOPHYS, V33, P379, DOI 10.3758/BF03205886
   Wahn B, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01896
   Wahn B, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168087
   Wall S., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1123
   Wegel RL, 1924, PHYS REV, V23, P266, DOI 10.1103/PhysRev.23.266
   WELLS MJ, 1989, P SOC PHOTO-OPT INS, V1116, P126
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Wetzel E., 2016, RESPONSE BIASES, P349, DOI 10.1093/med:psych/9780199356942.003.0024
   Wightman FL, 1999, J ACOUST SOC AM, V105, P2841, DOI 10.1121/1.426899
   WILDT AR, 1978, J MARKETING RES, V15, P261, DOI 10.2307/3151256
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wolfe Jeremy M., 2005, P101, DOI 10.1016/B978-012375731-9/50021-5
   Yost WA, 2014, J ACOUST SOC AM, V136, P2737, DOI 10.1121/1.4898045
   Zhong X, 2017, J ACOUST SOC AM, V141, P2882, DOI 10.1121/1.4981118
NR 124
TC 6
Z9 7
U1 1
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1342
EP 1362
DI 10.1109/TVCG.2021.3116673
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300011
PM 34591771
DA 2024-11-06
ER

PT J
AU Liu, XH
   Ma, L
   Guo, JW
   Yan, DM
AF Liu, Xiaohan
   Ma, Lei
   Guo, Jianwei
   Yan, Dong-Ming
TI Parallel Computation of 3D Clipped Voronoi Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Graphics processing units; Heuristic
   algorithms; Two dimensional displays; Robustness; Approximation
   algorithms; Euclidean distance; Parallel algorithm; Voronoi diagram;
   clipping
ID TESSELLATIONS
AB Computing the Voronoi diagram of a given set of points in a restricted domain (e.g., inside a 2D polygon, on a 3D surface, or within a volume) has many applications. Although existing algorithms can compute 2D and surface Voronoi diagrams in parallel on graphics hardware, computing clipped Voronoi diagrams within volumes remains a challenge. This article proposes an efficient GPU algorithm to tackle this problem. A preprocessing step discretizes the input volume into a tetrahedral mesh. Then, unlike existing approaches which use the bisecting planes of the Voronoi cells to clip the tetrahedra, we use the four planes of each tetrahedron to clip the Voronoi cells. This strategy drastically simplifies the computation, and as a result, it outperforms state-of-the-art CPU methods up to an order of magnitude.
C1 [Liu, Xiaohan; Guo, Jianwei; Yan, Dong-Ming] Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China.
   [Liu, Xiaohan; Guo, Jianwei; Yan, Dong-Ming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Ma, Lei] Peking Univ, Natl Engn Lab Video Technol, Beijing 100000, Peoples R China.
   [Yan, Dong-Ming] Tsinghua Univ, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Peking University; Tsinghua University
RP Yan, DM (corresponding author), Chinese Acad Sci CASIA, Inst Automat, Natl Lab Pattern Recognit NLPR, Beijing 100190, Peoples R China.; Yan, DM (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
EM liuxiaohan2017@ia.ac.cn; malei@outlook.com; jianwei.guo@nlpr.ia.ac.cn;
   yandongming@gmail.com
RI Ma, Lei/AEI-0577-2022
OI Yan, Dong-Ming/0000-0003-2209-2404; Ma, Lei/0000-0001-6024-3854; Guo,
   Jianwei/0000-0002-3376-1725
FU National Natural Science Foundation of China [61772523, 61802406];
   Beijing Natural Science Foundation [L182059]; CCF-Tencent Open Research
   Fund [RAGR20190105]; Open Research Fund Program of State key Laboratory
   of Hydroscience and Engineering, Tsinghua University [sklhse-2020-D-07];
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University [VRLAB2019B02]; PKUBaidu Fund
   [2019BD001]
FX The authors would like to thank the reviewers for their valuable
   comments which greatly improved the article. This work was supported by
   the National Natural Science Foundation of China (61772523 and
   61802406), the Beijing Natural Science Foundation (L182059), the
   CCF-Tencent Open Research Fund (RAGR20190105), the Open Research Fund
   Program of State key Laboratory of Hydroscience and Engineering,
   Tsinghua University (sklhse-2020-D-07), the Open Project Program of
   State Key Laboratory of Virtual Reality Technology and Systems, Beihang
   University (VRLAB2019B02), and the PKUBaidu Fund (2019BD001).
CR [Anonymous], 2019, CGAL USER REFERENCE, V4.14
   [Anonymous], 2019, GEOGRAM PROGRAMMING
   [Anonymous], 2015, Comput. Vis. Media
   [Anonymous], 2009, SPATIAL TESSELLATION
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Aurenhammer F., 2013, VORONOI DIAGRAMS DEL, V8
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Cao Thanh-Tung., 2014, P 18 M ACM SIGGRAPH, P47, DOI DOI 10.1145/2556700.2556710
   CHAN TMY, 1995, PROCEEDINGS OF THE SIXTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P282, DOI 10.1109/SBEC.1995.514502
   Du Q, 2003, SIAM J SCI COMPUT, V24, P1488, DOI 10.1137/S1064827501391576
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Edelsbrunner H, 1997, INT J COMPUT GEOM AP, V7, P365, DOI 10.1142/S0218195997000223
   Gao MC, 2013, ACM T MATH SOFTWARE, V40, DOI 10.1145/2513109.2513112
   Garcia Vincent, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563100
   Garcia V, 2010, IEEE IMAGE PROC, P3757, DOI 10.1109/ICIP.2010.5654017
   Han J., 2017, P 25 PAC C COMP GRAP, P23, DOI 10.2312/pg.20171320
   Hoetzlein R C., 2014, GPU TECHNOLOGY C, V18, P2
   Hsieh HH, 2005, SIMUL MODEL PRACT TH, V13, P681, DOI 10.1016/j.simpat.2005.08.003
   Levy B., 2012, 21st International Meshing Roundtable, P349
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Liu X., 2019, P SIGGRAPH AS 2019 P
   Ma L, 2018, COMPUT GRAPH FORUM, V37, P255, DOI 10.1111/cgf.13565
   Ray N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275092
   Rong G., 2006, Jump flooding in GPU with applications to Voronoi diagram and distance transform, P109, DOI DOI 10.1145/1111411.1111431
   Rong GD, 2011, COMPUT AIDED GEOM D, V28, P475, DOI 10.1016/j.cagd.2011.06.005
   Rong GD, 2011, IEEE T VIS COMPUT GR, V17, P345, DOI 10.1109/TVCG.2010.53
   Shuai L, 2013, COMPUT AIDED DESIGN, V45, P463, DOI 10.1016/j.cad.2012.10.029
   SUTHERLAND IE, 1974, COMMUN ACM, V17, P32, DOI 10.1145/360767.360802
   Wang L, 2016, COMPUT GRAPH FORUM, V35, P152, DOI 10.1111/cgf.12716
   Yan DM, 2014, IEEE T VIS COMPUT GR, V20, P1418, DOI 10.1109/TVCG.2014.2330574
   Yan DM, 2013, COMPUT AIDED DESIGN, V45, P843, DOI 10.1016/j.cad.2011.09.004
   Yan DM, 2010, LECT NOTES COMPUT SC, V6130, P269
   Yan DM, 2009, COMPUT GRAPH FORUM, V28, P1445, DOI 10.1111/j.1467-8659.2009.01521.x
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 34
TC 9
Z9 10
U1 2
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1363
EP 1372
DI 10.1109/TVCG.2020.3012288
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300012
PM 32746286
DA 2024-11-06
ER

PT J
AU Jeong, Y
   Baek, SY
   Seok, Y
   Lee, GB
   Lee, S
AF Jeong, Yuna
   Baek, Seung Youp
   Seok, Yechan
   Lee, Gi Beom
   Lee, Sungkil
TI Real-Time Dynamic Bokeh Rendering With Efficient Look-Up Table Sampling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Real-time systems; Lenses; Table lookup;
   Sprites (computer); Optical imaging; Ray tracing; Real-time rendering;
   bokeh; depth of field; defocus blur; GPU
ID DEPTH
AB This article presents a real-time bokeh rendering technique that splats pre-computed sprites but takes dynamic visibilities and intrinsic appearances into account at runtime. To attain alias-free looks without excessive sampling on a lens, the visibilities of strong highlights are densely sampled using rasterization, while regular objects are sparsely sampled using conventional defocus-blur rendering. The intrinsic appearance is dynamically transformed from a precomputed look-up table, which encodes radial aberrations against image distances in a compact 2D texture. Our solution can render complex bokeh effects without undersampling artifacts in real time, and greatly improve the photorealism of defocus-blur rendering.
C1 [Jeong, Yuna] Korea Inst Sci & Technol Informat KISTI, Daejon 305600, South Korea.
   [Baek, Seung Youp; Seok, Yechan; Lee, Gi Beom; Lee, Sungkil] Sungkyunkwan Univ SKKU, Suwon 16419, Gyeonggi Do, South Korea.
C3 Korea Institute of Science & Technology (KIST); Sungkyunkwan University
   (SKKU)
RP Lee, S (corresponding author), Sungkyunkwan Univ SKKU, Suwon 16419, Gyeonggi Do, South Korea.
EM jeongyuna@kisti.re.kr; bsy6766@skku.edu; yechan@skku.edu;
   gibeom@skku.edu; sungkil@skku.edu
OI i, gibeom/0000-0002-6702-7684; Seok, Yechan/0000-0003-2645-2761
FU Samsung Research Funding & Incubation Center of Samsung Electronics
   [SRFC-IT1901-01]; Mid-career R&D program through the NRF - Korea
   Government [2019R1A2C2002449]
FX The Lucy model is provided through the courtesy of the Stanford 3D
   Scanning Repository. This work was supported in part by the Samsung
   Research Funding & Incubation Center of Samsung Electronics
   (SRFC-IT1901-01) and Mid-career R&D program through the NRF Grants
   (2019R1A2C2002449) funded by the Korea Government.
CR Asada N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P186, DOI 10.1109/ICPR.1996.546016
   Barsky BA, 2003, LECT NOTES COMPUT SC, V2669, P246
   Buhler J., 2002, ACM SIGGRAPH 2002 conference abstracts and applications, P142
   Cook R. L., 1984, Computers & Graphics, V18, P137
   de Rousiers C, 2012, OPENGL INSIGHTS, P205
   Décoret X, 2005, COMPUT GRAPH FORUM, V24, P393, DOI 10.1111/j.1467-8659.2005.00864.x
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Everitt Cass, 2001, White Paper
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Gotanda Y., 2015, ACM SIGGRAPH 2015 Courses, P23
   Hach T, 2015, CVMP 2015: PROCEEDINGS OF THE 12TH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/2824840.2824842
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Hanika J, 2014, COMPUT GRAPH FORUM, V33, P323, DOI 10.1111/cgf.12301
   Hold-Geoffroy Y, 2017, PROC CVPR IEEE, P2373, DOI 10.1109/CVPR.2017.255
   Hoobler N, 2011, P GAM DEV C, P42
   Hullin M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1965003
   Hullin MB, 2012, COMPUT GRAPH FORUM, V31, P1375, DOI 10.1111/j.1467-8659.2012.03132.x
   Joo H, 2016, COMPUT GRAPH FORUM, V35, P99, DOI 10.1111/cgf.12953
   Kolb C., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P317, DOI 10.1145/218380.218463
   Kraus M, 2007, COMPUT GRAPH FORUM, V26, P645, DOI 10.1111/j.1467-8659.2007.01088.x
   Lanman D., 2008, Computational Aesthetics, P81
   Lee S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3190859
   Lee S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778802
   Lee S, 2008, COMPUT GRAPH FORUM, V27, P1955, DOI 10.1111/j.1467-8659.2008.01344.x
   Liu DW, 2016, MACH VISION APPL, V27, P1325, DOI 10.1007/s00138-016-0775-5
   McGraw T, 2015, VISUAL COMPUT, V31, P601, DOI 10.1007/s00371-014-0986-6
   McIntosh L, 2012, COMPUT GRAPH FORUM, V31, P1810, DOI 10.1111/j.1467-8659.2012.02097.x
   Merklinger H. M., 1997, PHOTO TECHN, V18, P37
   Mittring M, 2011, P GAM DEV C, P48
   PELLATFINET P, 1994, OPT LETT, V19, P1388, DOI 10.1364/OL.19.001388
   Potmesil M., 1981, Computer Graphics, V15, P297, DOI 10.1145/965161.806818
   Prakel D., 2010, The visual dictionary of photography
   Schrade E, 2016, COMPUT GRAPH FORUM, V35, P89, DOI 10.1111/cgf.12952
   Smith W. J., 2000, MODERN OPTICAL ENG
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JZ, 2013, VISUAL COMPUT, V29, P41, DOI 10.1007/s00371-012-0673-4
   Wu JZ, 2010, VISUAL COMPUT, V26, P555, DOI 10.1007/s00371-010-0459-5
NR 39
TC 5
Z9 6
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1373
EP 1384
DI 10.1109/TVCG.2020.3014474
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300013
PM 32755864
DA 2024-11-06
ER

PT J
AU Li, J
   Liu, TT
   Kavan, L
AF Li, Jing
   Liu, Tiantian
   Kavan, Ladislav
TI Soft Articulated Characters in Projective Dynamics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deformable models; Computational modeling; Joints; Bones; Solid
   modeling; Couplings; Numerical models; Rigid body; deformable body;
   coupling; projective dynamics
ID SIMULATION; CONTACT; BODY
AB We propose a fast and robust solver to simulate continuum-based deformable models with constraints, in particular, rigid-body and joint constraints useful for soft articulated characters. Our method embeds the degrees of freedom of both articulated rigid bodies and deformable bodies in one unified constrained optimization problem, thus coupling the deformable and rigid bodies. Inspired by Projective Dynamics which is a fast numerical solver to simulate deformable objects, we also propose a novel local/global solver that takes full advantage of the pre-factorized system matrices to accelerate the solve of our constrained optimization problem. Therefore, our method can efficiently simulate character models, with rigid-body parts (bones) being correctly coupled with deformable parts (flesh). Our method is stable because backward Euler time integration is applied to both rigid and deformable degrees of freedom. Our unified optimization problem is rigorously derived from constrained Newtonian mechanics. When simulating only articulated rigid bodies as a special case, our method converges to the state-of-the-art rigid body simulators.
C1 [Li, Jing; Kavan, Ladislav] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
   [Li, Jing] Beijing Film Acad, Adv Innovat Ctr Future Visual Entertainment, Beijing 100080, Peoples R China.
   [Liu, Tiantian] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Utah System of Higher Education; University of Utah; Microsoft;
   Microsoft Research Asia
RP Li, J (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM jingli2070769@gmail.com; ltt1598@gmail.com; ladislav.kavan@gmail.com
FU National Key R&D Program of China [2018YB1403900]; National Science
   Foundation [IIS-1617172, IIS-1622360, IIS-1764071]
FX The authors would like to thank Eftychios Sifakis for many inspiring
   discussions. They also thank Yasmin Down for Thorndyke modelling, and
   Henry Rietra for snail modelling, Dimitar Dinev for proofreading. This
   work was supported in part by National Key R&D Program of China [Grant
   number 2018YB1403900] and the National Science Foundation under Grant
   Numbers IIS-1617172, IIS-1622360, and IIS-1764071. Any opinions,
   findings, and conclusions or recommendations expressed in this material
   are those of the author(s) and do not necessarily reflect the views of
   theNational Science Foundation. They also gratefully acknowledge the
   support of Activision, Adobe, and hardware donation fromNVIDIA
   Corporation.
CR Amestoy PR, 2019, SIAM J SCI COMPUT, V41, pA269, DOI 10.1137/17M1151882
   Andrews S, 2017, COMPUT GRAPH FORUM, V36, P235, DOI 10.1111/cgf.13122
   Armstrong W. W., 1985, The Visual Computer, V1, P231
   Baraff D., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P137, DOI 10.1145/237170.237226
   Baraff D., 1997, CMURITR9733
   Bender J., 2006, P 19 INT C COMPUTER, P3
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P246, DOI 10.1111/cgf.12272
   Bender Jan, 2006, Virtual Reality Interactions and Physical Simulations (VRIPhys), P81
   Blanco J.-L., 2010, University of Malaga, P6
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   Brandt C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201387
   Capell S., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation. SCA '05, P301
   Chen Y, 1998, COMP ANIM CONF PROC, P154, DOI 10.1109/CA.1998.681920
   Debunne G, 2001, COMP GRAPH, P31, DOI 10.1145/383259.383262
   Featherstone R., 1987, Robot Dynamics Algorithms, DOI DOI 10.1007/978-0-387-74315-8
   Fratarcangeli M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982437
   Galoppo N, 2007, COMPUT GRAPH FORUM, V26, P243, DOI 10.1111/j.1467-8659.2007.01046.x
   Hahn F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185568
   Heidelberger B.H., 2007, Consistent collision and self-collision handling for deformable objects
   James DL, 1999, COMP GRAPH, P65, DOI 10.1145/311535.311542
   Jansson J, 2003, VISUAL COMPUT, V19, P280, DOI 10.1007/s00371-002-0187-6
   Kavan L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366215
   Kim J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019640
   Kugelstadt T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13520
   Lanczos C, 1986, Dover Books on Physics, V4th
   Lenoir J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P327, DOI 10.1109/CGI.2004.1309229
   Li J, 2018, P 14 WORKSH VIRT REA, P29, DOI [10.2312/vriphys.20181065, DOI 10.2312/VRIPHYS.20181065]
   Li J, 2019, PROCEEDINGS SCA 2019: ACM SIGGRAPH/EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION, DOI 10.1145/3309486.3340249
   Liu LB, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508427
   Liu TT, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2990496
   Lloyd John E, 2012, SOFT ISSUE BIOMECHAN, V355, DOI [10.1007/8415_2012_126, DOI 10.1007/8415_2012_126]
   McAdams A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964932
   MMC16 MACKLIN MILES, 2016, P 9 INT C MOT GAM MI, P49, DOI [DOI 10.1145/2994258.29942722,3, 10.1145/2994258.2994272, DOI 10.1145/2994258.2994272]
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Muller Matthias, 2002, P 2002 ACM SIGGRAPH, P49, DOI DOI 10.1145/545261.545269
   Narain Rahul, 2016, P ACM SIGGRAPH EUR S, P21
   O'Brien JF, 2000, IEEE COMPUT GRAPH, V20, P86, DOI 10.1109/38.851756
   Peng Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201290
   Schulz C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601156
   Shabana A.A., 2020, Dynamics of Multibody Systems, V4th ed.
   Shinar Tamar., 2008, THESIS STANFORD
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P81
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P137, DOI 10.1111/cgf.13519
   Teran J., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P68
   Terzopoulos Demetri, 1987, COMPUTER GRAPHICS PR, V21, P205
   Tournier M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766969
   Verschoor M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P183, DOI 10.1109/VR.2018.8447555
   Wachter A, 2006, MATH PROGRAM, V106, P25, DOI 10.1007/s10107-004-0559-y
   Wang HM, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818063
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322952
   Weinstein R, 2006, IEEE T VIS COMPUT GR, V12, P365, DOI 10.1109/TVCG.2006.48
   Weinstein R. L, 2007, THESIS STANFORD U ST
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Zordan VB, 2005, ACM T GRAPHIC, V24, P697, DOI 10.1145/1073204.1073249
NR 56
TC 1
Z9 1
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1385
EP 1396
DI 10.1109/TVCG.2020.3010236
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300014
PM 32746278
OA Bronze
DA 2024-11-06
ER

PT J
AU Alharbi, M
   Laramee, RS
   Cheesman, T
AF Alharbi, Mohammad
   Laramee, Robert S.
   Cheesman, Tom
TI TransVis: Integrated Distant and Close Reading of Othello Translations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Task analysis; Art; Cultural
   differences; Euclidean distance; Text visualization; othello; parallel
   translations
ID VISUAL ANALYSIS; VISUALIZATION; TOOL; DYNAMICS; DESIGN
AB Studying variation among time-evolved translations is a valuable research area for cultural heritage. Understanding how and why translations vary reveals cultural, ideological, and even political influences on literature as well as author relations. In this article, we introduce a novel integrated visual application to support distant and close reading of a collection of Othello translations. We present a new interactive application that provides an alignment overview of all the translations and their correspondences in parallel with smooth zooming and panning capability to integrate distant and close reading within the same view. We provide a range of filtering and selection options to customize the alignment overview as well as focus on specific subsets. Selection and filtering are responsive to expert user preferences and update the analytical text metrics interactively. Also, we introduce a customized view for close reading which preserves the history of selections and the alignment overview state and enables backtracing and re-examining them. Finally, we present a new Term-Level Comparisons view (TLC) to compare and convey relative term weighting in the context of an alignment. Our visual design is guided by, used and evaluated by a domain expert specialist in German translations of Shakespeare.
C1 [Alharbi, Mohammad] Swansea Univ, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
   [Laramee, Robert S.] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
   [Cheesman, Tom] Swansea Univ, Coll Arts & Humanities, Swansea SA2 8PP, W Glam, Wales.
C3 Swansea University; University of Nottingham; Swansea University
RP Alharbi, M (corresponding author), Swansea Univ, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
EM m.alharbi.508205@swansea.ac.uk; robert.laramee@nottingham.ac.uk;
   t.cheesman@swansea.ac.uk
FU Technical and Vocational Training Corporation (TVTC); Saudi Cultural
   Bureau
FX The authors would like to thank Liam McNabb, Dylan Rees, and Matthew
   Roach for their help in proofreading the manuscript. The authors also
   thank the Technical and Vocational Training Corporation (TVTC) and the
   Saudi Cultural Bureau for funding and supporting this research
   endeavour.
CR Abdul-Rahman A, 2017, COMPUT GRAPH FORUM, V36, P237, DOI 10.1111/cgf.12798
   Abdul-Rahman A, 2013, COMPUT GRAPH FORUM, V32, P381, DOI 10.1111/cgf.12125
   Alharbi M, 2019, COMPUTERS, V8, DOI 10.3390/computers8010017
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   [Anonymous], 2014, P EUR C VIS JUN
   Asokarajan Bharathi, 2016, EUROVIS WORKSHOP VIS, P19, DOI [10.2312/eurova.20161119, DOI 10.2312/EUROVA.20161119]
   B_arfuss L., 2001, OTHELLO
   Baudissin W., 1832, SHAKSPEARES DRAMATIS, V8
   Behrisch M., 2012, P EUROVA INT WORKSH, P61
   Benda J. W. O., 1826, OTHELLO MOHR VENEDIG
   Berlin-Brandenburgische Akademie der Wissenschaften, 2014, DTSCH TEXTARCHIV
   Boyles N, 2012, EDUC LEADERSHIP, V70, P36
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brunner K., 1947, OTHELLO MOHR VENEDIG
   Buchler M., 2010, 5 ANN INT C ALL DIG
   Buhss W., 1996, W SHAKESPEARE
   Chang MW, 2013, IEEE PAC VIS SYMP, P9, DOI 10.1109/PacificVis.2013.6596122
   Cheesman T., 2012, ARTS HUMANITIES RES, V1
   Cheesman T, 2017, DIGIT SCHOLARSH HUM, V32, P739, DOI 10.1093/llc/fqw027
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Elliott Bill, 2007, 2007 IEEE International Engineering Management Conference (IEMC 2007), P304, DOI 10.1109/IEMC.2007.5235049
   Engel E., 1939, W SHAKESPEARE
   Flatter R., 1952, OTHELLO MOHR VENEDIG
   G_unther F., 1995, W SHAKESPEARE
   Geng Z., 2011, P INT S VIS COMP, P653
   Geng Z, 2015, INFORM VISUAL, V14, P273, DOI 10.1177/1473871613495845
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gold V., 2015, P EUR C VIS, DOI [10.2312/eurovisshort.20151130, DOI 10.2312/EUROVISSHORT.20151130]
   Gundolf F., 1909, SHAKESPEARE DTSCH SP
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Havre S, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P105, DOI 10.1109/INFVIS.2001.963287
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hogan T, 2016, IEEE T VIS COMPUT GR, V22, P2579, DOI 10.1109/TVCG.2015.2511718
   Howell S, 2014, DIGIT HUMANITIES Q, V8
   Huang A., 2008, NZCSRSC 2008
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   J_anicke S., 2014, P DIG HUM
   J_anicke S., 2015, Eurographics Conference on Visualization, P83, DOI [DOI 10.2312/EUROVISSTAR.20151113, 10.2312/eurovisstar.20151113]
   J_anicke S., 2015, P C DIG HUM
   Jänicke S, 2017, COMPUT GRAPH FORUM, V36, P226, DOI 10.1111/cgf.12873
   Jänicke S, 2017, DIGIT SCHOLARSH HUM, V32, P106, DOI 10.1093/llc/fqx033
   Jänicke S, 2015, DIGIT SCHOLARSH HUM, V30, P83, DOI 10.1093/llc/fqv049
   Janicke Stefan, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P59
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Jong C.-H., 2009, P DIG HUM
   Jurish B., 2011, THESIS U POTSDAM POT
   Keim DA, 2007, IEEE CONF VIS ANAL, P115, DOI 10.1109/VAST.2007.4389004
   Koch S, 2014, IEEE T VIS COMPUT GR, V20, P1723, DOI 10.1109/TVCG.2014.2346677
   Korenius T., 2004, P 13 ACM INT C INF K, P625, DOI [10.1145/1031171.1031285, DOI 10.1145/1031171.1031285]
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Leonard C., 2010, TYPESCRIPT
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Mehta H, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3131609
   Monroy C, 2002, LECT NOTES COMPUT SC, V2539, P39
   Moretti Franco, 2013, Distant Reading, P211
   Motschach H., 1992, OTHELLO
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   Oelke D, 2013, COMPUT GRAPH FORUM, V32, P371, DOI 10.1111/cgf.12124
   Ortlepp E., 1839, OTHELLO MOHR VENEDIG
   Ribler RL, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P173
   Riehmann P, 2015, COMPUT GRAPH FORUM, V34, P61, DOI 10.1111/cgf.12618
   Robertson G. G., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/168642.168652
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Roos A., 2017, J DATA MINING DIGITA
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Rothe H., 1956, ELISABETHANISCHE SHA, V4
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Schaller R., 1959, SHAKESPEARES WERKE, V4
   Schiller F., 1805, OTHELLO
   Schr_oder R. A., 1962, SHAKESPEARE DTSCH
   Schreibman S., 2003, Literary & Linguistic Computing, V18, P101, DOI 10.1093/llc/18.1.101
   Schwarz H., 1941, TYPESCRIPT
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siirtola H, 2014, INT J CORPUS LINGUIS, V19, P417, DOI 10.1075/ijcl.19.3.05sii
   Silvia S., 2016, P WORKSH VIS DIG HUM
   Suvanaphen E, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P2, DOI 10.1109/TPCG.2004.1314446
   TELEA A., 2007, DATA VISUALIZATION P
   Wachsmann M., 2005, W SHAKESPEARE
   Walsh J. A., 2011, P DIG HUM, P10
   Wheeles D., 2013, DIGITAL HUMANITIES, V5
   White D. R., 2004, ACM J ED RESOURCES C, V4, P1
   Wieland C., 1766, OTHELLO MOHR VENEDIG
   Wolff M. J., 1926, SHAKESPEARES WERKE U
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zeynek T. V., 1948, SHAKESPEARE OTHELLO
NR 89
TC 5
Z9 5
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1397
EP 1414
DI 10.1109/TVCG.2020.3012778
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XY1KL
UT WOS:000736740300015
PM 32746287
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Yoo, D
   Lee, S
   Jo, Y
   Cho, J
   Choi, S
   Lee, B
AF Yoo, Dongheon
   Lee, Seungjae
   Jo, Youngjin
   Cho, Jaebum
   Choi, Suyeon
   Lee, Byoungho
TI Volumetric Head-Mounted Display With Locally Adaptive Focal Blocks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Resists; Light emitting diodes; Visualization; Image reconstruction;
   Liquid crystal displays; Retina; Optical imaging; Virtual reality;
   head-mounted display; three-dimensional display; multifocal display
ID QUALITY
AB A commercial head-mounted display (HMD) for virtual reality (VR) presents three-dimensional imagery with a fixed focal distance. The VR HMD with a fixed focus can cause visual discomfort to an observer. In this article, we propose a novel design of a compact VR HMD supporting near-correct focus cues over a wide depth of field (from 18 cm to optical infinity). The proposed HMD consists of a low-resolution binary backlight, a liquid crystal display panel, and focus-tunable lenses. In the proposed system, the backlight locally illuminates the display panel that is floated by the focus-tunable lens at a specific distance. The illumination moment and the focus-tunable lens' focal power are synchronized to generate focal blocks at the desired distances. The distance of each focal block is determined by depth information of three-dimensional imagery to provide near-correct focus cues. We evaluate the focus cue fidelity of the proposed system considering the fill factor and resolution of the backlight. Finally, we verify the display performance with experimental results.
C1 [Yoo, Dongheon; Lee, Seungjae; Jo, Youngjin; Cho, Jaebum; Lee, Byoungho] Seoul Natl Univ, Sch Elect & Comp Engn, Seoul 08826, South Korea.
   [Choi, Suyeon] Stanford Univ, Elect Engn, Stanford, CA 94305 USA.
C3 Seoul National University (SNU); Stanford University
RP Lee, B (corresponding author), Seoul Natl Univ, Sch Elect & Comp Engn, Seoul 08826, South Korea.
EM dhyou93@gmail.com; seungjae1012@gmail.com; niugnas@naver.com;
   chojaebum@gmail.com; suyeon@stanford.edu; byoungho@snu.ac.kr
RI Choi, Suyeon/JVD-9950-2024; Lee, Seungjae/IZE-6034-2023
OI Lee, Seungjae/0000-0002-7194-8216; Choi, Suyeon/0000-0001-9030-0960;
   Yoo, Dongheon/0000-0002-8404-1947
FU Projects for Research and Development of Police Science and Technology
   under the Center for Research and Development of Police Science and
   Technology; Korean National Police Agency [PA-H000001]
FX This research was supported by the Projects for Research and Development
   of Police Science and Technology under the Center for Research and
   Development of Police Science and Technology and the Korean National
   Police Agency (PA-H000001). Dongheon Yoo and Seungjae Lee contributed
   equally to this work.
CR Ak K., 2020, OPT EXP, V28, P2107
   Akeley K, 2004, ACM T GRAPHIC, V23, P804, DOI 10.1145/1015706.1015804
   Aksit K, 2019, IEEE T VIS COMPUT GR, V25, P1928, DOI 10.1109/TVCG.2019.2898781
   Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   ANDERSEN AH, 1984, ULTRASONIC IMAGING, V6, P81, DOI 10.1016/0161-7346(84)90008-7
   Campbell F. W., 1957, Optica Acta: International Journal of Optics, V4, P157, DOI [10.1080/713826091, DOI 10.1080/713826091]
   Chakravarthula P, 2018, IEEE T VIS COMPUT GR, V24, P2906, DOI 10.1109/TVCG.2018.2868532
   Chang JHR, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275015
   Choi S, 2019, OPT EXPRESS, V27, P24362, DOI 10.1364/OE.27.024362
   Dabkowski P, 2017, ADV NEUR IN, V30
   Dourado AO, 2013, AEROSP SCI TECHNOL, V30, P79, DOI 10.1016/j.ast.2013.07.005
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Gao D, 2005, ADV NEURAL INFORM PR, P481
   Garrick J., 2014, TRAUMA TREATMENT TEC
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Held RT, 2012, CURR BIOL, V22, P426, DOI 10.1016/j.cub.2012.01.033
   Hu XD, 2014, OPT EXPRESS, V22, P13896, DOI 10.1364/OE.22.013896
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Huang HB, 2018, ACM T GRAPHIC, V37, DOI [10.1145/3137609, 10.1145/3072959.3073654]
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P1916, DOI 10.1109/TVCG.2019.2947038
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jang C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275069
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Koulieris GA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073622
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lanman D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508366
   Lee S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10451-2
   Lee S, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2782219
   Lee S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925971
   MacKenzie KJ, 2010, J VISION, V10, DOI 10.1167/10.8.22
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Matsuda N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073590
   Mercier O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130846
   Moro C, 2017, ANAT SCI EDUC, V10, P549, DOI 10.1002/ase.1696
   Narain R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766909
   Rathinavel K, 2018, IEEE T VIS COMPUT GR, V24, P2857, DOI 10.1109/TVCG.2018.2868570
   Reichow M. A., 2014, U.S. Patent, Patent No. [8 646 917, 8646917]
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   Sitter B., 2017, P SID S, P1150
   Spjut J, 2020, IEEE T VIS COMPUT GR, V26, P2126, DOI 10.1109/TVCG.2020.2973053
   Takahashi K, 2018, IEEE T IMAGE PROCESS, V27, P4571, DOI 10.1109/TIP.2018.2839263
   Urvoy M, 2013, ANN TELECOMMUN, V68, P641, DOI 10.1007/s12243-013-0394-3
   Wang SZ, 2018, PROC CVPR IEEE, P2031, DOI 10.1109/CVPR.2018.00217
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu W., 2014, INFORM DISPLAY, V30, P16
   Wu WM, 2016, IEEE INT CON MULTI
   Xiao L, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 TALKS, DOI 10.1145/3214745.3214769
   Yoo D, 2019, PROC SPIE, V11040, DOI 10.1117/12.2525055
   Zannoli M, 2016, J VISION, V16, DOI 10.1167/16.6.17
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 53
TC 6
Z9 6
U1 0
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1415
EP 1427
DI 10.1109/TVCG.2020.3011468
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XY1KL
UT WOS:000736740300016
PM 32746283
DA 2024-11-06
ER

PT J
AU Melo, M
   Gonçalves, G
   Monteiro, P
   Coelho, H
   Vasconcelos-Raposo, J
   Bessa, M
AF Melo, Miguel
   Goncalves, Guilherme
   Monteiro, Pedro
   Coelho, Hugo
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI Do Multisensory Stimuli Benefit the Virtual Reality Experience? A
   Systematic Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Systematics; Haptic interfaces; Olfactory; Statistical analysis; Virtual
   environments; Pain; Systematic review; virtual reality; multisensory
ID HAPTIC FEEDBACK; FORCE FEEDBACK; LAPAROSCOPIC SKILLS; PERFORMANCE;
   ENVIRONMENTS; SENSE; TOUCH; INFORMATION; MAINTENANCE; MODALITIES
AB The majority of virtual reality (VR) applications rely on audiovisual stimuli and do not exploit the addition of other sensory cues that could increase the potential of VR. This systematic review surveys the existing literature on multisensory VR and the impact of haptic, olfactory, and taste cues over audiovisual VR. The goal is to identify the extent to which multisensory stimuli affect the VR experience, which stimuli are used in multisensory VR, the type of VR setups used, and the application fields covered. An analysis of the 105 studies that met the eligibility criteria revealed that 84.8 percent of the studies show a positive impact of multisensory VR experiences. Haptics is the most commonly used stimulus in multisensory VR systems (86.6 percent). Non-immersive and immersive VR setups are preferred over semi-immersive setups. Regarding the application fields, a considerable part was adopted by health professionals and science and engineering professionals. We further conclude that smell and taste are still underexplored, and they can bring significant value to VR applications. More research is recommended on how to synthesize and deliver these stimuli, which still require complex and costly apparatus be integrated into the VR experience in a controlled and straightforward manner.
C1 [Melo, Miguel; Goncalves, Guilherme; Monteiro, Pedro; Coelho, Hugo; Vasconcelos-Raposo, Jose; Bessa, Maximino] INESC TEC, P-4200465 Porto, Portugal.
   [Goncalves, Guilherme; Monteiro, Pedro; Coelho, Hugo; Vasconcelos-Raposo, Jose; Bessa, Maximino] Univ Tras Os Montes & Alto Douro, P-5001801 Vila Real, Portugal.
C3 INESC TEC; University of Tras-os-Montes & Alto Douro
RP Melo, M (corresponding author), INESC TEC, P-4200465 Porto, Portugal.
EM mcmelo@inesctec.pt; guilhermeg@utad.pt; monteiro.p@outlook.pt;
   hugo.r.mendes@inesctec.pt; jvraposo@utad.pt; maxbessa@utad.pt
RI VASCONCELOS-RAPOSO, JOSE/JMB-6306-2023; Melo, Miguel/AAN-1855-2020;
   Bessa, Maximino/B-4729-2012; Branco VASCONCELOS-RAPOSO, JOSE
   Jacinto/G-3743-2010; Goncalves, Guilherme/ISS-7521-2023
OI Bessa, Maximino/0000-0002-3002-704X; Monteiro,
   Pedro/0000-0002-9072-6264; Melo, Miguel/0000-0003-4050-3473; Branco
   VASCONCELOS-RAPOSO, JOSE Jacinto/0000-0002-3456-9727; Goncalves,
   Guilherme/0000-0002-3264-587X
FU ERDF - European Regional Development Fund through the Operational
   Programme for Competitiveness and Internationalisation - COMPETE 2020
   Programme; National Funds through the Portuguese funding agency, FCT -
   Fundacao para a Ciencia e a Tecnologia [POCI-01-0145-FEDER-028618]
FX This work was financed by the ERDF - European Regional Development Fund
   through the Operational Programme for Competitiveness and
   Internationalisation - COMPETE 2020 Programme and by National Funds
   through the Portuguese funding agency, FCT - Fundacao para a Ciencia e a
   Tecnologia within project POCI-01-0145-FEDER-028618.
CR Adermann J, 2007, INT J COMPUT ASS RAD, V2, pS198
   Ankarali MM, 2014, J NEUROPHYSIOL, V111, P1286, DOI 10.1152/jn.00140.2013
   August K. G, 2012, P 9 IASTED INT C BIO, P450
   García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   Baus O, 2017, VIRTUAL REAL-LONDON, V21, P59, DOI 10.1007/s10055-016-0299-3
   Bessa M, 2018, COMPUT GRAPH-UK, V71, P35, DOI 10.1016/j.cag.2017.11.003
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Blom KJ, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2536764.2536772
   Bluteau J., 2009, P JOINT VIRT REAL C, P9
   Bouguila L., 2000, P 1 INT WORKSH HAPT, P135
   Bouhelal A., 2013, Int. J. Surg., V8, P704
   Brickman BJ, 1996, P IEEE VIRT REAL ANN, P147, DOI 10.1109/VRAIS.1996.490522
   Caola B, 2018, PERCEPTION, V47, P477, DOI 10.1177/0301006618758211
   Carulli M., 2015, P 35 COMP INF ENG C, V1B, P1
   Chen ZK, 2017, UIST'17 ADJUNCT: ADJUNCT PUBLICATION OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P123, DOI 10.1145/3131785.3131825
   Choi W, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8163098
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Cooper N., 2015, P EUR ASS VIRT REAL, P69
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   Cooper N, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P194, DOI [10.1109/ISMAR-Adjunct.2016.66, 10.1109/ISMAR-Adjunct.2016.0075]
   Corbett B, 2016, INT J HUM-COMPUT INT, V32, P89, DOI 10.1080/10447318.2015.1094914
   Cui Z, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1447
   Culbertson H, 2018, ANNU REV CONTR ROBOT, V1, P385, DOI 10.1146/annurev-control-060117-105043
   de Barros P. G., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P47, DOI 10.1109/3DUI.2011.5759216
   De Barros P.G., 2013, P 1 S SPAT US INT LO, P41
   de Boer IR, 2017, SIMUL HEALTHC, V12, P83, DOI 10.1097/SIH.0000000000000208
   de Visser H, 2011, MED J AUSTRALIA, V194, pS38
   Diaz I.n., 2006, Virtual Reality, V10, P31
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Durlach PJ, 2005, PRESENCE-TELEOP VIRT, V14, P450, DOI 10.1162/105474605774785299
   Dvorkin AY, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-92
   Ebrahimi E, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2947617
   Egan D., 2017, 2nd International Workshop on Multimedia Alternate Realities, P15
   Egeberg MCS, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927940
   Faroque S, 2018, COMPUT ELECTR ENG, V67, P656, DOI 10.1016/j.compeleceng.2017.04.030
   Feng M, 2016, P IEEE VIRT REAL ANN, P173, DOI 10.1109/VR.2016.7504709
   Feng M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2016.7460037
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Frohlich Julia, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P159, DOI 10.1007/978-3-642-39405-8_19
   Gard A, 2018, P CHI C HUM FACT COM
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Gibo TL, 2014, IEEE T HAPTICS, V7, P37, DOI 10.1109/TOH.2013.60
   Hagelsteen K, 2017, MINIM INVASIV THER, V26, P269, DOI 10.1080/13645706.2017.1305970
   Han I, 2011, COMPUT EDUC, V57, P2281, DOI 10.1016/j.compedu.2011.06.012
   Handrahan M, 2014, OCULUS RIFT DEV KITS
   Hecht D, 2006, PRESENCE-TELEOP VIRT, V15, P515, DOI 10.1162/pres.15.5.515
   Hiemstra E, 2011, MINIM INVASIV THER, V20, P179, DOI 10.3109/13645706.2010.532502
   Hoffman HG, 2003, INT J HUM-COMPUT INT, V16, P283, DOI 10.1207/S15327590IJHC1602_08
   Howell MJ, 2016, MULTIMED TOOLS APPL, V75, P12311, DOI 10.1007/s11042-015-2971-0
   Hu B, 2012, HUM FACTOR ERGON MAN, V22, P145, DOI 10.1002/hfm.20293
   Hulsmann F, 2014, LAVAL VIRTUAL VRIC 1, DOI [10.1145/2617841.2620712, DOI 10.1145/2617841.2620712]
   I. L. Office, 2012, INT STANDARD CLASSIF
   Ichinose A, 2017, NEUROREHAB NEURAL RE, V31, P717, DOI 10.1177/1545968317718268
   Jiang L, 2016, ENVIRON IMPACT ASSES, V60, P126, DOI 10.1016/j.eiar.2016.03.002
   Kang ZH, 2018, MULTIMED TOOLS APPL, V77, P2209, DOI 10.1007/s11042-017-4392-8
   Karafotias G, 2018, IEEE T HAPTICS, V11, P185, DOI 10.1109/TOH.2017.2781693
   Kim CM, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/420428
   Kim HK, 2003, LECT NOTES COMPUT SC, V2878, P1
   Klasnja-Milicevic A, 2019, ADV INTELL SYST, V804, P213, DOI 10.1007/978-3-319-98872-6_25
   Koritnik T, 2010, GAIT POSTURE, V32, P540, DOI 10.1016/j.gaitpost.2010.07.017
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lathan C, 2000, PRESENCE-VIRTUAL AUG, V9, P337, DOI 10.1162/105474600566844
   Lecuyer A, 2013, IEEE COMPUT GRAPH, V33, P18, DOI 10.1109/MCG.2013.80
   Lederman SJ, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P151, DOI 10.1109/HAPTIC.2003.1191261
   Lee J.-H, 2011, P INT C HUM COMP INT, P180
   Lee S, 2008, INT J HUM-COMPUT ST, V66, P701, DOI 10.1016/j.ijhcs.2008.05.001
   Li BJ, 2017, PRESENCE-TELEOP VIRT, V26, P337, DOI [10.1162/pres_a_00300, 10.1162/PRES_a_00300]
   Louison C, 2018, INT J HUM-COMPUT INT, V34, P1015, DOI 10.1080/10447318.2017.1411665
   Louison C, 2017, FUSION ENG DES, V124, P610, DOI 10.1016/j.fusengdes.2017.03.017
   Lyu SR, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-63
   Mahrer NE, 2009, CURR PAIN HEADACHE R, V13, P100, DOI 10.1007/s11916-009-0019-8
   Martin J, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P132, DOI 10.1109/HAVE.2008.4685312
   Meyer GF, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067651
   Meyer GF, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044381
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Millet G, 2013, INT J HUM-COMPUT ST, V71, P608, DOI 10.1016/j.ijhcs.2012.12.005
   Minsky Marvin, 1980, OMNIJuly, DOI DOI 10.1145/566654.566630
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.1136/bmj.i4086, 10.1186/2046-4053-4-1, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1371/journal.pmed.1000097]
   Munyan Benson G., 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P164, DOI 10.1007/978-3-319-39907-2_16
   Munyan BG III, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157568
   Murray N, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2816454
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Nam CS, 2008, COMPUT HUM BEHAV, V24, P1404, DOI 10.1016/j.chb.2007.07.014
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nishino H, 2011, J AMB INTEL HUM COMP, V2, P271, DOI 10.1007/s12652-010-0042-y
   Ogi T, 1997, MULTIMEDIA SYST, V5, P86, DOI 10.1007/s005300050044
   Ogi T., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P145
   Ogi T, 1996, JSME INT J C-DYN CON, V39, P411, DOI 10.1299/jsmec1993.39.411
   Panait L, 2009, J SURG RES, V156, P312, DOI 10.1016/j.jss.2009.04.018
   Petrolo L, 2010, COMPUT METH PROG BIO, V97, P86, DOI 10.1016/j.cmpb.2009.11.002
   Poling GL, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P187, DOI 10.1109/HAPTIC.2003.1191271
   Ramic-Brkic B, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2617917
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Richard P, 1995, PRESENCE-TELEOP VIRT, V5, P95
   Sakr N, 2010, IEEE T INSTRUM MEAS, V59, P1047, DOI 10.1109/TIM.2010.2040970
   Salkini MW, 2010, J ENDOUROL, V24, P99, DOI 10.1089/end.2009.0307
   Salzman MC, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1208
   Santos-Carreras L, 2010, APPL BIONICS BIOMECH, V7, P217, DOI 10.1080/11762322.2010.503110
   Santos-Carreras L, 2012, PRESENCE-TELEOP VIRT, V21, P435, DOI 10.1162/PRES_a_00126
   Schoor W, 2010, J VIRT REALITY BROAD, V6, P1
   Sella I, 2014, INT J PSYCHOPHYSIOL, V93, P45, DOI 10.1016/j.ijpsycho.2013.11.003
   Sengül A, 2013, EXP BRAIN RES, V227, P497, DOI 10.1007/s00221-013-3526-0
   Shing CY, 2003, ROBOTICA, V21, P211, DOI 10.1017/S0263574702004708
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Stepp CE, 2010, P IEEE RAS-EMBS INT, P58, DOI 10.1109/BIOROB.2010.5627824
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Thompson JR, 2011, SURG ENDOSC, V25, P1107, DOI 10.1007/s00464-010-1325-2
   Toet A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078721
   Tomono A, 2011, ELECTR COMMUN JPN, V94, P9, DOI 10.1002/ecj.10319
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Turner T. R., 2009, P HUM FACT ERG SOC A, V53, P1116
   Våpenstad C, 2013, SURG ENDOSC, V27, P2391, DOI 10.1007/s00464-012-2745-y
   Viciana-Abad R, 2014, MULTIMED TOOLS APPL, V68, P623, DOI 10.1007/s11042-012-1070-8
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Wang D, 2016, EUR J DENT EDUC, V20, P248, DOI 10.1111/eje.12173
   Wang JL, 2016, HUM FACTORS, V58, P496, DOI 10.1177/0018720815618808
   Wareing J, 2018, COMPUT SCI ELECTR, P214, DOI 10.1109/CEEC.2018.8674211
   Weisenberger JM, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P161, DOI 10.1109/HAPTIC.2004.1287192
   Wiebe EN, 2009, COMPUT EDUC, V53, P667, DOI 10.1016/j.compedu.2009.04.004
   Wu CM, 2017, VIRTUAL REAL-LONDON, V21, P19, DOI 10.1007/s10055-016-0296-6
   Yannier N, 2008, IEEE T HAPTICS, V1, P130, DOI [10.1109/TOH.2008.16, 10.1109/ToH.2008.16]
   Zahabi M, 2017, ERGONOMICS, V60, P1516, DOI 10.1080/00140139.2017.1324115
   Zhou M, 2012, SURG ENDOSC, V26, P1128, DOI 10.1007/s00464-011-2011-8
NR 126
TC 75
Z9 78
U1 10
U2 128
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2022
VL 28
IS 2
BP 1428
EP 1442
DI 10.1109/TVCG.2020.3010088
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA XY1KL
UT WOS:000736740300017
PM 32746276
DA 2024-11-06
ER

PT J
AU Zhao, J
   Fan, MM
   Feng, M
AF Zhao, Jian
   Fan, Mingming
   Feng, Mi
TI ChartSeer: Interactive Steering Exploratory Visual Analysis With Machine
   Intelligence
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Machine learning; Encoding; Task
   analysis; Semantics; Collaboration; Exploratory visual analysis;
   interactive steering; visualization recommendation; machine learning
ID VISUALIZATION; DESIGN; MODEL
AB During exploratory visual analysis (EVA), analysts need to continually determine which subsequent activities to perform, such as which data variables to explore or how to present data variables visually. Due to the vast combinations of data variables and visual encodings that are possible, it is often challenging to make such decisions. Further, while performing local explorations, analysts often fail to attend to the holistic picture that is emerging from their analysis, leading them to improperly steer their EVA. These issues become even more impactful in the real world analysis scenarios where EVA occurs in multiple asynchronous sessions that could be completed by one or more analysts. To address these challenges, this work proposes ChartSeer, a system that uses machine intelligence to enable analysts to visually monitor the current state of an EVA and effectively identify future activities to perform. ChartSeer utilizes deep learning techniques to characterize analyst-created data charts to generate visual summaries and recommend appropriate charts for further exploration based on user interactions. A case study was first conducted to demonstrate the usage of ChartSeer in practice, followed by a controlled study to compare ChartSeer's performance with a baseline during EVA tasks. The results demonstrated that ChartSeer enables analysts to adequately understand current EVA status and advance their analysis by creating charts with increased coverage and visual encoding diversity.
C1 [Zhao, Jian] Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Fan, Mingming] Rochester Inst Technol, Golisano Coll Comp & Informat Sci, Sch Informat, Rochester, NY 14623 USA.
   [Feng, Mi] Twitter Inc, San Francisco, CA 94103 USA.
C3 University of Waterloo; Rochester Institute of Technology; Twitter, Inc.
RP Zhao, J (corresponding author), Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM jianzhao@uwaterloo.ca; mingming.fan@rit.edu; fmamimi@gmail.com
RI Fan, Mingming/LMM-9437-2024
OI Fan, Mingming/0000-0002-0356-4712; Zhao, Jian/0000-0001-5008-4319
FU NSERC Discovery Grant; Adobe Systems, Inc.
FX This work was supported in part by an NSERC Discovery Grant and a gift
   fund from Adobe Systems, Inc.
CR Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Cavallo M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174209
   Cho K., 2014, P 2014 C EMP METH NA, P1724
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Cook K. A., 2005, Technical Report
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Curtis FE, 2015, MATH PROGRAM COMPUT, V7, P399, DOI 10.1007/s12532-015-0086-2
   Demiralp C, 2014, IEEE COMPUT GRAPH, V34, P10, DOI 10.1109/MCG.2014.18
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Feng M, 2019, IEEE T VIS COMPUT GR, V25, P501, DOI 10.1109/TVCG.2018.2865117
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gilson O, 2008, COMPUT GRAPH FORUM, V27, P959, DOI 10.1111/j.1467-8659.2008.01230.x
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Horvitz E, 1999, P CHI, P159, DOI DOI 10.1145/302979.303030
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hu XR, 2013, IEEE T VIS COMPUT GR, V19, P2052, DOI 10.1109/TVCG.2013.188
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Isenberg P., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P179, DOI 10.1109/VAST.2010.5652880
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Jankun-Kelly TJ, 2007, IEEE T VIS COMPUT GR, V13, P357, DOI 10.1109/TVCG.2007.28
   John H., 2008, INTRO AUTOMATA THEOR
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kingma D.P., 2013, CoRR
   Kruskal J. B., 1978, Multidimensional scaling, V11
   Kusner MJ, 2017, PR MACH LEARN RES, V70
   Kwan-Liu Ma, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P81, DOI 10.1109/VISUAL.1999.809871
   Kwon BC, 2017, IEEE T VIS COMPUT GR, V23, P221, DOI 10.1109/TVCG.2016.2598446
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Mahyar N, 2014, IEEE T VIS COMPUT GR, V20, P1633, DOI 10.1109/TVCG.2014.2346573
   Mikolov T., 2013, ARXIV13013781
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Peltonen J, 2015, MACH LEARN, V99, P189, DOI 10.1007/s10994-014-5464-x
   Pirolli P, 1999, PSYCHOL REV, V106, P643, DOI 10.1037/0033-295X.106.4.643
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   ROTH SF, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P112, DOI 10.1145/191666.191719
   Sarvghad A, 2017, IEEE T VIS COMPUT GR, V23, P21, DOI 10.1109/TVCG.2016.2598466
   Sarvghad Ali., 2015, Proceedings of the Graphics Interface Conference, P123, DOI DOI 10.20380/GI2015.16
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Sutskever I., 2014, Advances in neural information processing systems, P3104, DOI DOI 10.5555/2969033.2969173
   Tobiasz M, 2009, IEEE T VIS COMPUT GR, V15, P1065, DOI 10.1109/TVCG.2009.162
   Tukey JW., 1977, EXPLORATORY DATA ANA
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vartak M, 2014, PROC VLDB ENDOW, V7, P1581, DOI 10.14778/2733004.2733035
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Voigt M., 2012, 4 INT C INFORM PROCE, P101
   Wattenberg M, 2006, IEEE T VIS COMPUT GR, V12, P549, DOI 10.1109/TVCG.2006.65
   Willett W, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3131
   Witten IH, 2011, MOR KAUF D, P1
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Zhao J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173903
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P340, DOI 10.1109/TVCG.2017.2745279
   Zhao J, 2017, IEEE T VIS COMPUT GR, V23, P261, DOI 10.1109/TVCG.2016.2598543
NR 64
TC 21
Z9 25
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1500
EP 1513
DI 10.1109/TVCG.2020.3018724
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200004
PM 32833636
DA 2024-11-06
ER

PT J
AU Jadhav, S
   Dmitriev, K
   Marino, J
   Barish, M
   Kaufman, AE
AF Jadhav, Shreeraj
   Dmitriev, Konstantin
   Marino, Joseph
   Barish, Matthew
   Kaufman, Arie E.
TI 3D Virtual Pancreatography
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lesions; Pancreas; Three-dimensional displays; Ducts; Visualization;
   Computed tomography; Two dimensional displays; Visual diagnosis;
   pancreatic cancer; automatic segmentation; lesion classification; planar
   reformation
ID PLANAR REFORMATION; VISUALIZATION; PANCREAS; PERFORMANCE; PREDICTION;
   ENDOSCOPY; SUPINE
AB We present 3D virtual pancreatography (VP), a novel visualization procedure and application for non-invasive diagnosis and classification of pancreatic lesions, the precursors of pancreatic cancer. Currently, non-invasive screening of patients is performed through visual inspection of 2D axis-aligned CT images, though the relevant features are often not clearly visible nor automatically detected. VP is an end-to-end visual diagnosis system that includes: A machine learning based automatic segmentation of the pancreatic gland and the lesions, a semi-automatic approach to extract the primary pancreatic duct, a machine learning based automatic classification of lesions into four prominent types, and specialized 3D and 2D exploratory visualizations of the pancreas, lesions and surrounding anatomy. We combine volume rendering with pancreas- and lesion-centric visualizations and measurements for effective diagnosis. We designed VP through close collaboration and feedback from expert radiologists, and evaluated it on multiple real-world CT datasets with various pancreatic lesions and case studies examined by the expert radiologists.
C1 [Jadhav, Shreeraj; Dmitriev, Konstantin; Marino, Joseph; Kaufman, Arie E.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Barish, Matthew] Stony Brook Med, Dept Radiol, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   State University of New York (SUNY) System; Stony Brook University;
   Stony Brook University Hospital
RP Jadhav, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM sdjadhav@cs.stonybrook.edu; kdmitriev@cs.stonybrook.edu;
   jmarino@cs.stonybrook.edu; Matthew.Barish@stonybrookmedicine.edu;
   ari@cs.stonybrook.edu
OI Barish, Matthew/0000-0002-7521-8878; Kaufman, Arie/0000-0002-0796-6196;
   Jadhav, Shreeraj/0000-0003-0520-4857; Dmitriev,
   Konstantin/0000-0001-9740-1334
FU NSF [CNS1650499, OAC1919752, ICER1940302]; Marcus Foundation; National
   Heart, Lung, and Blood Institute of NIH [U01HL127522]; New York State
   Center for Advanced Technology in Biotechnology; Stony Brook University;
   Cold Spring Harbor; Brookhaven National; Feinstein Institute for Medical
   Research; New York State Economic Development Department [C14051]
FX The authors would like to thank their collaborators at Stony Brook
   Medicine, including Dr. Kevin Baker, for evaluating their system and
   providing feedback, and at Johns Hopkins, Drs. Ralph Hruban and Elliot
   Fishman, for the pancreas CT datasets. This work has been partially
   supported by NSF Grants CNS1650499, OAC1919752, ICER1940302; Marcus
   Foundation; and National Heart, Lung, and Blood Institute of NIH under
   Award U01HL127522; New York State Center for Advanced Technology in
   Biotechnology; Stony Brook University; Cold Spring Harbor; Brookhaven
   National; Feinstein Institute for Medical Research; and New York State
   Economic Development Department, Contract C14051. The content is solely
   the responsibility of the authors and does not necessarily represent the
   official views of the NIH. Shreeraj Jadhav and Konstantin Dmitriev
   contributed equally to this work.
CR [Anonymous], 2019, Cancer Facts and Figures
   [Anonymous], 2006, P ACM S SOL PHYS MOD
   Auzinger T, 2013, IEEE T VIS COMPUT GR, V19, P2858, DOI 10.1109/TVCG.2013.215
   Bartrolí AV, 2001, SPRING EUROGRAP, P127
   Bartz D, 2005, COMPUT GRAPH FORUM, V24, P111, DOI 10.1111/j.1467-8659.2005.00831.x
   Bartz D., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P389, DOI 10.1109/VISUAL.1999.809912
   Bitter I, 2001, IEEE T VIS COMPUT GR, V7, P195, DOI 10.1109/2945.942688
   Brambilla A, 2016, IEEE PAC VIS SYMP, P88, DOI 10.1109/PACIFICVIS.2016.7465255
   Cai Jinzheng., 2017, Improving deep pancreas segmentation in ct and mri images via recurrent neural contextual learning and direct loss function, P674
   Cho HW, 2011, KOREAN J RADIOL, V12, P731, DOI 10.3348/kjr.2011.12.6.731
   Chu CW, 2013, LECT NOTES COMPUT SC, V8150, P165, DOI 10.1007/978-3-642-40763-5_21
   Dmitriev K., 2019, IEEE Transactions on Visualization and Computer Graphics
   Dmitriev Konstantin, 2017, Med Image Comput Comput Assist Interv, V10435, P150, DOI 10.1007/978-3-319-66179-7_18
   Dmitriev K, 2016, PROC SPIE, V9784, DOI 10.1117/12.2216537
   Fridman Y, 2004, MED IMAGE ANAL, V8, P169, DOI 10.1016/j.media.2004.06.017
   Ghaderi MA, 2016, IEEE ENG MED BIO, P4391, DOI 10.1109/EMBC.2016.7591700
   Gobbetti E, 1998, VISUALIZATION '98, PROCEEDINGS, P435, DOI 10.1109/VISUAL.1998.745337
   Grippo PJ, 2011, AM J PATHOL, V179, P610, DOI 10.1016/j.ajpath.2011.04.007
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu HG, 2018, LECT NOTES COMPUT SC, V11140, P101, DOI 10.1007/978-3-030-01421-6_10
   Jinzheng Cai, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P674, DOI 10.1007/978-3-319-66179-7_77
   Kanitsar A, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P43, DOI 10.1109/VISUAL.2003.1250353
   Karasawa K, 2017, MED IMAGE ANAL, V39, P18, DOI 10.1016/j.media.2017.03.006
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kohlmann P, 2009, IEEE PAC VIS SYMP, P185, DOI 10.1109/PACIFICVIS.2009.4906855
   Kok P, 2010, IEEE T VIS COMPUT GR, V16, P1396, DOI 10.1109/TVCG.2010.134
   Kretschmer J, 2014, IEEE T VIS COMPUT GR, V20, P2496, DOI 10.1109/TVCG.2014.2346405
   Lampe OD, 2009, IEEE T VIS COMPUT GR, V15, P1235, DOI 10.1109/TVCG.2009.136
   Lennon AM, 2013, J GASTROINTEST SURG, V17, P645, DOI 10.1007/s11605-012-2072-6
   Li HW, 2019, IEEE ENG MED BIO, P2095, DOI [10.1109/embc.2019.8856745, 10.1109/EMBC.2019.8856745]
   Lichan Hong, 1995, Proceedings. 1995 Biomedical Visualization (Cat. No.95TB100001), P26, DOI 10.1109/BIOVIS.1995.528702
   Lichan Hong, 1997, Computer Graphics Proceedings, SIGGRAPH 97, P27, DOI 10.1145/258734.258750
   Marino J, 2011, COMPUT GRAPH FORUM, V30, P1051, DOI 10.1111/j.1467-8659.2011.01954.x
   Mirhosseini S, 2019, IEEE T VIS COMPUT GR, V25, P2011, DOI 10.1109/TVCG.2019.2898763
   Nadeem S, 2017, IEEE T VIS COMPUT GR, V23, P751, DOI 10.1109/TVCG.2016.2598791
   Okada T, 2015, MED IMAGE ANAL, V26, P1, DOI 10.1016/j.media.2015.06.009
   Pieper S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P632
   Raidou RG, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13413
   Raidou RG, 2016, COMPUT GRAPH FORUM, V35, P231, DOI 10.1111/cgf.12899
   Rodenwaldt J, 1997, J COMPUT ASSIST TOMO, V21, P405, DOI 10.1097/00004728-199705000-00013
   Rogalla P, 2000, MED RAD DIA IMG, P17
   Roth H. R., 2017, arXiv preprint arXiv:1704.06382
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Rowe S.P., 2019, Image Processing from 2D to 3D BT, P103, DOI [DOI 10.1007/174_2017_136, 10.1007/978-3-319-42586-3]
   Sahani DV, 2011, AM J ROENTGENOL, V197, pW53, DOI 10.2214/AJR.10.5866
   Sakas G, 2002, COMPUT GRAPH-UK, V26, P577, DOI 10.1016/S0097-8493(02)00103-6
   Sato Y, 1997, LECT NOTES COMPUT SC, V1205, P213, DOI 10.1007/BFb0029240
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   Sorantin E, 2002, IEEE T MED IMAGING, V21, P263, DOI 10.1109/42.996344
   Straka M, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P385, DOI 10.1109/VISUAL.2004.104
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vilanova A., 1999, Machine Graphics & Vision, V8, P469
   Wan M, 2001, PROC SPIE, V4321, P483, DOI 10.1117/12.428176
   Wang JH, 2016, SCI REP-UK, V6, DOI 10.1038/srep27327
   Webb LJ, 2011, MED PHYS, V38, P1972, DOI 10.1118/1.3562901
   Wegenkittl R, 2000, IEEE VISUAL, P461, DOI 10.1109/VISUAL.2000.885732
   Wei R, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033818824339
   Williams D, 2008, IEEE T VIS COMPUT GR, V14, P109, DOI 10.1109/TVCG.2007.1061
   Wolz R, 2012, LECT NOTES COMPUT SC, V7510, P10, DOI 10.1007/978-3-642-33415-3_2
   Yagel R, 1996, COMPUT GRAPH, V20, P813, DOI 10.1016/S0097-8493(96)00051-9
   Yin T, 2015, CONTRAST MEDIA MOL I, V10, P379, DOI 10.1002/cmmi.1640
   Yu QH, 2018, PROC CVPR IEEE, P8280, DOI 10.1109/CVPR.2018.00864
   Yuyin Zhou, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P222, DOI 10.1007/978-3-319-66179-7_26
   Yuyin Zhou, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P693, DOI 10.1007/978-3-319-66182-7_79
   Zeng W, 2010, IEEE T VIS COMPUT GR, V16, P1348, DOI 10.1109/TVCG.2010.200
   Zhu ZT, 2018, INT CONF 3D VISION, P682, DOI 10.1109/3DV.2018.00083
NR 66
TC 4
Z9 4
U1 1
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1457
EP 1468
DI 10.1109/TVCG.2020.3020958
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200001
PM 32870794
OA Green Accepted, Bronze
DA 2024-11-06
ER

PT J
AU Dong, X
   Li, WX
   Hu, XY
   Wang, XJ
   Wang, YH
AF Dong, Xuan
   Li, Weixin
   Hu, Xiaoyan
   Wang, Xiaojie
   Wang, Yunhong
TI A Colorization Framework for Monochrome-Color Dual-Lens Systems Using a
   Deep Convolutional Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Color; Estimation; Cameras; Feature extraction;
   Lenses; Training; Colorization CNN; weight volume; color correction;
   colorization quality estimation
ID IMAGE QUALITY ASSESSMENT
AB In monochrome-color dual-lens systems, the monochrome camera can capture images with higher quality than the color camera. To obtain high quality color images, a better approach is to colorize the gray images from the monochrome camera with the color images from the color camera serving as a reference. In addition, the colorization may fail in some cases, which makes the estimation of the colorization quality a necessary step before outputting the colorization result. To solve these problems, we propose a deep convolutional network based framework. 1) In the colorization module, the proposed colorization CNN uses deep feature representations, attention operation, 3-D regulation and color correction to make use of colors of multiple pixels in the reference image for colorizing each pixel in the input gray image. 2) In the colorization quality estimation module, based on the symmetry property of colorization, we propose to utilize the colorization CNN again to colorize the gray map of the original reference color image using the first-time colorization result from the colorization module as reference. Then, the quality loss of the second-time colorization result can be used for estimating the colorization quality. Experimental results show that our method can largely outperform the state-of-the-art colorization methods and estimate the colorization quality accurately as well.
C1 [Dong, Xuan; Hu, Xiaoyan; Wang, Xiaojie] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
   [Li, Weixin; Wang, Yunhong] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100083, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beihang University
RP Li, WX (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing 100083, Peoples R China.
EM dongxuan8811@bupt.edu.cn; weixinli@buaa.edu.cn; hxy@bupt.edu.cn;
   xjwang@bupt.edu.cn; yhwang@buaa.edu.cn
RI Xiaojie, Wang/T-5052-2019
OI Hu, Xiaoyan/0000-0001-7661-1439
FU National Nature Science Foundation of China [61802026, 61806016];
   Fundamental Research Funds for the Central University [2019RC39]
FX This work was funded by the National Nature Science Foundation of China
   (No. 61802026 and 61806016) and the Fundamental Research Funds for the
   Central University (No. 2019RC39).
CR [Anonymous], 2016, CVPR, DOI 10.1109/Cvpr.2016.182
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chen DD, 2018, PROC CVPR IEEE, P6654, DOI 10.1109/CVPR.2018.00696
   Chen JW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982423
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dong X, 2019, AAAI CONF ARTIF INTE, P8255
   Dong X, 2019, NEUROCOMPUTING, V352, P22, DOI 10.1016/j.neucom.2019.04.007
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gupta R.K., 2012, P 20 ACM INT C MULT, P369, DOI [10.1145/2393347.2393402, DOI 10.1145/2393347.2393402]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hinton G., 2012, COURSERA: Neural networks for machine learning, V4, P26
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Irony R., 2005, Rendering techniques, P201
   Jeon DS, 2018, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2018.00185
   Jeon HG, 2016, PROC CVPR IEEE, P4086, DOI 10.1109/CVPR.2016.443
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2018, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2018.00682
   Li Yijun., 2016, Proc. ECCV
   Lin Z., 2017, ICLR
   Lu JS, 2016, ADV NEUR IN, V29
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pan LY, 2017, PROC CVPR IEEE, P6987, DOI 10.1109/CVPR.2017.739
   Sander P.V., 2017, P IEEE C COMPUTER VI
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1339, DOI 10.1109/TPAMI.2007.1151
   Wang L, 2018, P IEEE C COMP VIS PA, P1
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Ye P, 2014, PROC CVPR IEEE, P4241, DOI 10.1109/CVPR.2014.540
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhou SC, 2019, PROC CVPR IEEE, P10988, DOI 10.1109/CVPR.2019.01125
NR 38
TC 8
Z9 8
U1 4
U2 47
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1469
EP 1485
DI 10.1109/TVCG.2020.3022480
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200002
PM 32897862
DA 2024-11-06
ER

PT J
AU Li, L
   Wang, WC
   Chu, YY
AF Li, Lei
   Wang, Wencheng
   Chu, Yiyao
TI A Simple and Stable Centeredness Measure for 3D Curve Skeleton
   Extraction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Skeleton; Shape; Three-dimensional displays; Shape measurement;
   Perturbation methods; Surface treatment; Time measurement; Curve
   skeleton; 3D shapes; centeredness measure; minimum set covers
ID MEDIAL AXIS; THINNING ALGORITHM; SURFACE; FRAMEWORK
AB Existing methods for extracting 3D curve skeletons mostly suffer from the difficulty of finding the center points of 3D shapes and tedious manual adjustments of the thresholds for pruning spurious branches due to the influence of shape boundary perturbations. In this article, we present a method based on medial surfaces of 3D shapes for the convenient and fast extraction of high-quality curve skeletons. Our main contribution is a simple and stable centeredness measure. It is based on simulating fire propagation via the scheme of inside-out evolution from the interior to the boundary, differentiating it from existing methods that use the scheme of outside-in evolution from the boundary to the interior. Thus, our measure is much more localized, and it can be implemented with a high degree of parallelism. In addition, we propose measures to effectively suppress the influence of details to obtain a stable measurement, and employ minimum set covers to optimize the center points to generate compact skeletons, which enables spurious branches to be effectively excluded without the tedious work of manually adjusting thresholds. Our experiments show the superiority of our method over existing methods, including its convenient generation of clean, compact and centered curve skeletons while running much faster than state-of-the-art methods.
C1 [Li, Lei; Wang, Wencheng; Chu, Yiyao] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
   [Li, Lei; Wang, Wencheng; Chu, Yiyao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Li, L; Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
EM llei@ios.ac.cn; whn@ios.ac.cn; chuyy@ios.ac.cn
RI Wang, Wencheng/A-3828-2009
OI wang, wen cheng/0000-0001-5094-4606
FU National Key R&D Program of China [2017YFB1002701]; National Natural
   Science Foundation of China [61661146002]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2017YFB1002701 and the National Natural Science Foundation
   of China under Grant 61661146002. The authors would like to thank
   Xiaoying Mou for making Figs. 4 and 6 used in the article, thank
   reviewers for their valuable suggestions and thank the Princeton Shape
   Benchmark and Aim@Shape for providing the models used in this article.
CR Agarwal AP14 Pankaj K, 2014, P 30 ANN S COMP GEOM, P271
   Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7
   Arcelli C, 2011, IEEE T PATTERN ANAL, V33, P709, DOI 10.1109/TPAMI.2010.140
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Bitter I, 2001, IEEE T VIS COMPUT GR, V7, P195, DOI 10.1109/2945.942688
   Blum H., 1967, Models for Perception of Speech and Visual Form
   Bouix S, 2003, PROC CVPR IEEE, P449
   Bouix S, 2000, LECT NOTES COMPUT SC, V1842, P603
   Boulahia SY, 2017, IEEE INT CONF AUTOMA, P462, DOI 10.1109/FG.2017.63
   Cao T.T., 2010, P ACM I3D, P83, DOI [DOI 10.1145/1730804.1730818, 10.1145/1730804.1730818]
   Chuang JH, 2000, IEEE T PATTERN ANAL, V22, P1241
   Chvatal V., 1979, Mathematics of Operations Research, V4, P233, DOI 10.1287/moor.4.3.233
   Contente O, 2015, IEEE INT CONF AUTON, P50, DOI 10.1109/ICARSC.2015.16
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Couprie M, 2016, PATTERN RECOGN LETT, V76, P22, DOI 10.1016/j.patrec.2015.03.014
   Dardenne J., 2008, CGI 2008 C P, P299
   Dey T.K., 2006, S GEOMETRY PROCESSIN, V6, P143
   Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y
   Hassouna MS, 2007, IEEE I CONF COMP VIS, P2220
   Hassouna MS, 2005, LECT NOTES COMPUT SC, V3749, P654
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Hesselink WH, 2008, IEEE T PATTERN ANAL, V30, P2204, DOI 10.1109/TPAMI.2008.21
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Jalba AC, 2016, IEEE T PATTERN ANAL, V38, P30, DOI 10.1109/TPAMI.2015.2414420
   Jalba AC, 2013, IEEE T PATTERN ANAL, V35, P1495, DOI 10.1109/TPAMI.2012.212
   Li CY, 2011, LECT NOTES COMPUT SC, V6636, P84, DOI 10.1007/978-3-642-21073-0_10
   Li L, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13570
   Li L, 2017, COMPUT GRAPH FORUM, V36, P529, DOI 10.1111/cgf.13098
   Li P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2753755
   Liu L, 2010, COMPUT GRAPH FORUM, V29, P2253, DOI 10.1111/j.1467-8659.2010.01814.x
   Livesu M, 2013, VISUAL COMPUT, V29, P907, DOI 10.1007/s00371-013-0855-8
   Livesu M, 2012, IEEE T VIS COMPUT GR, V18, P1891, DOI 10.1109/TVCG.2012.71
   Lohou C, 2007, PATTERN RECOGN, V40, P2301, DOI 10.1016/j.patcog.2006.12.032
   Lohou C, 2010, IEEE T PATTERN ANAL, V32, P1148, DOI 10.1109/TPAMI.2010.27
   Miklos B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778838
   Palágyi K, 1999, LECT NOTES COMPUT SC, V1568, P325
   Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2
   Pan YL, 2019, COMPUT AIDED GEOM D, V71, P16, DOI 10.1016/j.cagd.2019.04.007
   Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680
   Reniers D, 2008, IEEE T VIS COMPUT GR, V14, P355, DOI 10.1109/TC.2007.70786
   Saha PK, 2017, COMPUT VIS PATT REC, P1
   Saha PK, 2018, IEEE T VIS COMPUT GR, V24, P2298, DOI 10.1109/TVCG.2017.2738023
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Serino L, 2016, INT C PATT RECOG, P2854, DOI 10.1109/ICPR.2016.7900069
   Serino L, 2014, INT C PATT RECOG, P2269, DOI 10.1109/ICPR.2014.394
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/SMI.2004.1314504
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   Sirin Y, 2017, MULTIMED TOOLS APPL, V76, P7823, DOI 10.1007/s11042-016-3422-2
   Slavik P, 1997, J ALGORITHM, V25, P237, DOI 10.1006/jagm.1997.0887
   Sobiecki A, 2014, PATTERN RECOGN LETT, V47, P147, DOI 10.1016/j.patrec.2014.01.012
   Sud A, 2004, COMPUT GRAPH FORUM, V23, P557, DOI 10.1111/j.1467-8659.2004.00787.x
   Sun F, 2016, IEEE T VIS COMPUT GR, V22, P1278, DOI 10.1109/TVCG.2015.2448080
   Svensson S, 2003, COMPUT VIS IMAGE UND, V90, P242, DOI 10.1016/S1077-3142(03)00061-4
   Tagliasacchi A, 2016, COMPUT GRAPH FORUM, V35, P573, DOI 10.1111/cgf.12865
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tao Wang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P55, DOI 10.1109/ICCVW.2009.5457719
   Telea A., 2012, P THEOR PRACT COMP G, P99
   van Dortmont MAMM, 2006, LECT NOTES COMPUT SC, V4245, P617
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Yan YJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201396
   Yan YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925938
   Zhou Y, 1999, IEEE T VIS COMPUT GR, V5, P196, DOI 10.1109/2945.795212
NR 64
TC 4
Z9 5
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1486
EP 1499
DI 10.1109/TVCG.2020.3018483
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200003
PM 32822298
DA 2024-11-06
ER

PT J
AU Xu, JY
   Dutta, S
   He, WB
   Moortgat, J
   Shen, HW
AF Xu, Jiayi
   Dutta, Soumya
   He, Wenbin
   Moortgat, Joachim
   Shen, Han-Wei
TI Geometry-Driven Detection, Tracking and Visual Analysis of Viscous and
   Gravitational Fingers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Earth; Three-dimensional displays; Skeleton; Feature
   extraction; Fingers; Computer science; Viscous and gravitational
   fingering; topological and geometric data analysis; ridge detection;
   spatio-temporal visualization; tracking graph
ID FLUIDS; RIDGES
AB Viscous and gravitational flow instabilities cause a displacement front to break up into finger-like fluids. The detection and evolutionary analysis of these fingering instabilities are critical in multiple scientific disciplines such as fluid mechanics and hydrogeology. However, previous detection methods of the viscous and gravitational fingers are based on density thresholding, which provides limited geometric information of the fingers. The geometric structures of fingers and their evolution are important yet little studied in the literature. In this article, we explore the geometric detection and evolution of the fingers in detail to elucidate the dynamics of the instability. We propose a ridge voxel detection method to guide the extraction of finger cores from three-dimensional (3D) scalar fields. After skeletonizing finger cores into skeletons, we design a spanning tree based approach to capture how fingers branch spatially from the finger skeletons. Finally, we devise a novel geometric-glyph augmented tracking graph to study how the fingers and their branches grow, merge, and split over time. Feedback from earth scientists demonstrates the usefulness of our approach to performing spatio-temporal geometric analyses of fingers.
C1 [Xu, Jiayi; He, Wenbin; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Dutta, Soumya] Los Alamos Natl Lab, Data Sci Scale Team, Los Alamos, NM 87545 USA.
   [Moortgat, Joachim] Ohio State Univ, Sch Earth Sci, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Energy (DOE); Los Alamos National Laboratory; University
   System of Ohio; Ohio State University
RP Xu, JY (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM xu.2205@osu.edu; sdutta@lanl.gov; he.495@osu.edu; moortgat.1@osu.edu;
   shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012; Dutta, Soumya/AAN-2212-2020; Moortgat,
   Joachim/J-7450-2013
OI Moortgat, Joachim/0000-0002-0259-3597; Xu, Jiayi/0000-0002-9091-6412;
   Dutta, Soumya/0000-0001-5030-9979; He, Wenbin/0000-0002-5376-5803
FU UT-Battelle LLC [4000159557]; Los Alamos National Laboratory Contract
   [471415]; NSF [SBE-1738502]
FX The authors would like to thank Yujia Wang and Junpeng Wang for
   providing design suggestions on the geometricglyph augmented tracking
   graph. Also, they thank Amin Amooie for the discussion on earth science.
   This work was supported in part by UT-Battelle LLC 4000159557, Los
   Alamos National Laboratory Contract 471415, and NSF Grant SBE-1738502.
CR Aldrich G., 2016, IEEE SCI VIS CONTEST, V1, P4
   Amooie MA, 2018, PHYS REV E, V98, DOI 10.1103/PhysRevE.98.033118
   Amooie MA, 2017, GEOMECH GEOPHYS GEO, V3, P225, DOI 10.1007/s40948-017-0060-8
   Amooie MA, 2017, GEOPHYS RES LETT, V44, P3624, DOI 10.1002/2016GL072491
   [Anonymous], 2018, TECPLOT
   [Anonymous], 2012, RIDGES IMAGE DATA AN
   Ayachit U., 2015, PARAVIEW GUIDE APARA, DOI [10.5555/2789330, DOI 10.5555/2789330]
   Balzer M, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P49, DOI 10.1109/INFVIS.2005.1532128
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Brewer C. A., 2018, COLORBREWER COLOR AD
   Bruls M, 2000, SPRING COMP SCI, P33
   BUKA A, 1987, PHYS REV A, V36, P1527, DOI 10.1103/PhysRevA.36.1527
   BUKA A, 1987, PHYS REV A, V36, P3984, DOI 10.1103/PhysRevA.36.3984
   Çakiroglu OA, 2007, LECT NOTES COMPUT SC, V4525, P122
   Carr H, 2010, COMP GEOM-THEOR APPL, V43, P42, DOI 10.1016/j.comgeo.2006.05.009
   Childs H., 2012, HIGH PERFORMANCE VIS, P395
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Damon J, 1999, J MATH IMAGING VIS, V10, P163, DOI 10.1023/A:1008379107611
   de Anna P, 2014, GEOPHYS RES LETT, V41, P4586, DOI 10.1002/2014GL060068
   de Saint-Venant M., 1852, Bull. Soc. Philomath. Paris, P24
   Doraiswamy H, 2012, IEEE T VIS COMPUT GR, V18, P146, DOI 10.1109/TVCG.2011.37
   Favelier G., 2016, IEEE SCIVIS CONTEST
   Fu XJ, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2012.0355
   Furst J. D., 2001, Proceedings of the IASTED International Conference Signal and Image Processing, P22
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4
   Heine C, 2011, IEEE T VIS COMPUT GR, V17, P1599, DOI 10.1109/TVCG.2010.270
   HINRICHSEN EL, 1989, J PHYS A-MATH GEN, V22, pL271, DOI 10.1088/0305-4470/22/7/004
   HOMSY GM, 1987, ANNU REV FLUID MECH, V19, P271, DOI 10.1146/annurev.fl.19.010187.001415
   JOHNSON B, 1991, VISUALIZATION 91, P284
   LAZARUS F., 1999, P ACM S SOL MOD APPL, P130, DOI [DOI 10.1145/304012.304025, 10.1145/304012.304025]
   Li SW, 2009, PHYS REV LETT, V102, DOI 10.1103/PhysRevLett.102.174501
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Marino J, 2016, IEEE T VIS COMPUT GR, V22, P906, DOI 10.1109/TVCG.2015.2467413
   Moortgat J, 2016, ADV WATER RESOUR, V89, P53, DOI 10.1016/j.advwatres.2016.01.002
   Peikert R, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P119
   Silver D, 1996, IEEE VISUAL, P157, DOI 10.1109/VISUAL.1996.567807
   Skauge A., 2012, P SPE IMPR OIL REC S
   Soltanian MR, 2017, ENVIRON SCI TECHNOL, V51, P7732, DOI 10.1021/acs.est.7b01540
   Soltanian MR, 2016, SCI REP-UK, V6, DOI 10.1038/srep35921
   Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Wood J, 2008, IEEE T VIS COMPUT GR, V14, P1348, DOI 10.1109/TVCG.2008.165
   Yamaguchi A., 1999, Computing and Combinatorics. 5th Annual International Conference, COCOON'99. Proceedings (Lecture Notes in Computer Science Vol.1627), P81
NR 50
TC 2
Z9 2
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1514
EP 1528
DI 10.1109/TVCG.2020.3017568
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200005
PM 32809940
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, H
   Wang, SD
   Wang, WC
AF Zhao, Hui
   Wang, Shaodong
   Wang, Wencheng
TI Global Conformal Parameterization via an Implementation of Holomorphic
   Quadratic Differentials
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Harmonic analysis; Mesh generation; Visualization; Trajectory;
   Robustness; Coordinate measuring machines; Foliation; parameterization;
   differential one-form; holomorphic quadratic differential; harmonic
ID MESH; FOLIATION; MAPS
AB We propose an algorithm to compute global conformal parameterizations of high-genus meshes, which is based on an implementation of holomorphic quadratic differentials. First, we design a novel diffusion method which is capable of computing a pole-free discrete harmonic measured foliation. Second, we propose a definition for discrete holomorphic quadratic differential which consists of a horizontal and a vertical harmonic measured foliation. Third, we present a practical algorithm to approximate the discrete natural coordinates for a holomorphic quadratic differential, which represents a flat metric with cones conformal to the original metric, i.e., a parameterization. Finally, we apply the discrete natural coordinates for parameterization of high genus meshes. Our parameterization method is global conformal and simple to implement. The advantage of our method over the approach based on holomorphic differential one-forms is that ours has a larger space of parameterizations. We demonstrate our approach with hundreds of configurations on dozens of meshes to show its robustness on conformal parameterization.
C1 [Zhao, Hui; Wang, Shaodong; Wang, Wencheng] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
   [Zhao, Hui; Wang, Shaodong; Wang, Wencheng] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
EM huizhao@ios.ac.cn; wangsd@ios.ac.cn; whn@ios.ac.cn
RI Wang, Wencheng/A-3828-2009
OI Zhao, Hui/0000-0003-4442-043X; Wang, Shaodong/0000-0002-7982-6600; wang,
   wen cheng/0000-0001-5094-4606
FU National Key R&D Program of China [2017YFB1002701]; National Natural
   Science Foundation of China [61661146002]
FX The authors would like to thank anonymous reviewers for their insightful
   feedback, valuable comments, and suggestions. The first author would
   like thank Prof. Steven J. Gortler for discussion and invitation to
   visit Harvard and Prof. Xianfeng Gu's Lectures on the holomorphic
   quadratic differentials. Meshes are courtesy of the AIM@SHAPE shape
   repository, Thingi10K project [52], and the dataset provided by [2]. The
   duck model is from Keenan Crane's 3D Model Repository. This work was
   partially supported by the National Key R&D Program of China under Grant
   No.: 2017YFB1002701 and the National Natural Science Foundation of China
   under Grant No. 61661146002.
CR Aigerman N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073615
   Aigerman N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818099
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Bourque MF, 2018, INVENT MATH, V212, P319, DOI 10.1007/s00222-017-0769-6
   Bright A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073646
   Campen M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3360511
   Campen M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925890
   Chen W, 2019, COMPUT METHOD APPL M, V356, P652, DOI 10.1016/j.cma.2019.07.023
   Cohen D, 2019, COMPUT GRAPH-UK, V82, P152, DOI 10.1016/j.cag.2019.05.015
   Crane K., 2013, ACM SIGGRAPH 2013 CO, DOI DOI 10.1145/2504435.2504442
   Crane K, 2019, CONFORMAL GEOMETRY S
   Dey TK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462017
   Erickson J, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1038
   Fathi A, 2012, THURSTONS WORK SURFA
   Fisher M, 2007, COMPUTING, V81, P199, DOI 10.1007/s00607-007-0249-8
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Gardiner F., 1999, Quasiconformal Teichmuler theory
   Gardiner F.P., 2010, The Dirichlet principle for measured foliations
   Gortler S. J, 2015, DISCRETE QUADRATIC D
   Gortler SJ, 2006, COMPUT AIDED GEOM D, V23, P83, DOI 10.1016/j.cagd.2005.05.002
   Gu X., 2003, EUR S GEOM PROC EUR, DOI DOI 10.2312/SGP/SGP03/127-137
   Hefetz EF, 2019, COMPUT GRAPH FORUM, V38, P105, DOI 10.1111/cgf.13623
   HUBBARD J, 1979, ACTA MATH-DJURSHOLM, V142, P221, DOI 10.1007/BF02395062
   Jin M, 2007, LECT NOTES COMPUT SC, V4647, P209
   Jost J., 2006, Compact Riemann Surfaces
   Kovalsky SZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925920
   Lei N, 2020, COMPUT METHOD APPL M, V366
   Lei N, 2017, COMPUT METHOD APPL M, V321, P406, DOI 10.1016/j.cma.2017.04.012
   Lei N, 2017, COMPUT METHOD APPL M, V316, P758, DOI 10.1016/j.cma.2016.09.044
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Liu LG, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201331
   Mercat C, 2001, COMMUN MATH PHYS, V218, P177, DOI 10.1007/s002200000348
   Myles A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185605
   Palmer D. R., 2016, THESIS HARVARD COLL
   Pinkall U., 1993, Exp. Math, V2, P15
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Sawhney R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132705
   Schoen R.M., 1997, LECT HARMONIC MAPS, V2
   Schüller C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12179
   Sheffer A, 2005, ACM T GRAPHIC, V24, P311, DOI 10.1145/1061347.1061354
   Shtengel A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073618
   Strebel K., 1984, ERGEBNISSE MATH IHRE, V5
   Thurston William P., 1997, Three-Dimensional Geometry and Topology, V1
   Tong Y., 2006, S GEOM PROC, P201, DOI [10.2312/SGP/SGP06/201-210, DOI 10.2312/SGP/SGP06/201-210]
   Vekhter J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323043
   Wolf M, 1996, J ANAL MATH, V68, P107, DOI 10.1007/BF02790206
   Zayer R., 2007, Fifth Eurographics Symposium on Geometry Processing - SGP 2007, P135, DOI DOI 10.1145/571647.571651
   Zhao H, 2020, COMPUT GRAPH FORUM, V39, P34, DOI 10.1111/cgf.13660
   Zhao H, 2018, COMPUT AIDED GEOM D, V63, P96, DOI 10.1016/j.cagd.2018.03.001
   Zhou Q., 2016, Thingi10k: A dataset of 10,000 3d-printing models
   Zhu YF, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201359
NR 51
TC 2
Z9 2
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1529
EP 1544
DI 10.1109/TVCG.2020.3016574
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200006
PM 32790631
DA 2024-11-06
ER

PT J
AU Seinfeld, S
   Feuchtner, T
   Pinzek, J
   Müller, J
AF Seinfeld, Sofia
   Feuchtner, Tiare
   Pinzek, Johannes
   Mueller, Joerg
TI Impact of Information Placement and User Representations in VR on
   Performance and Embodiment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Virtual environments; Keyboards; Tools;
   Input devices; Computer science; Virtual reality; notifications;
   attention; near space; virtual representations; input devices
ID ILLUSORY OWNERSHIP; SPACE; ATTENTION
AB Human sensory processing is sensitive to the proximity of stimuli to the body. It is therefore plausible that these perceptual mechanisms also modulate the detectability of content in VR, depending on its location. We evaluate this in a user study and further explore the impact of the user's representation during interaction. We also analyze how embodiment and motor performance are influenced by these factors. In a dual-task paradigm, participants executed a motor task, either through virtual hands, virtual controllers, or a keyboard. Simultaneously, they detected visual stimuli appearing in different locations. We found that, while actively performing a motor task in the virtual environment, performance in detecting additional visual stimuli is higher when presented near the user's body. This effect is independent of how the user is represented and only occurs when the user is also engaged in a secondary task. We further found improved motor performance and increased embodiment when interacting through virtual tools and hands in VR, compared to interacting with a keyboard. This article contributes to better understanding the detectability of visual content in VR, depending on its location in the virtual environment, as well as the impact of different user representations on information processing, embodiment, and motor performance.
C1 [Seinfeld, Sofia; Pinzek, Johannes; Mueller, Joerg] Univ Bayreuth, Inst Comp Sci, D-95447 Bayreuth, Germany.
   [Feuchtner, Tiare] Aarhus Univ, Comp Sci Dept, DK-8200 Aarhus N, Denmark.
C3 University of Bayreuth; Aarhus University
EM sofia.seinfeld@uni-bayreuth.de; tiare.feuchtner@acm.org;
   s2jopinz@stmail.uni-bayreuth.de; joerg.mueller@uni-bayreuth.de
RI Seinfeld, Sofia/ABA-5769-2020
OI Seinfeld, Sofia/0000-0001-9649-0785; Feuchtner,
   Tiare/0000-0002-9922-5538
FU European Union [737087]; Innovation Fund Denmark (MADE Digital project,
   IFD Grant) [6151-00006B]
FX This research has received funding from the European Union's Horizon
   2020 research and innovation program under Grant agreement #737087
   (Levitate). This work was also supported in part by the Innovation Fund
   Denmark (MADE Digital project, IFD Grant no. 6151-00006B). The authors
   would like to thank Jan Milosch and Timm Seltmann for their help in
   conducting the study.
CR Alzahrani A, 2019, IEEE SOUTHEASTCON, DOI [10.1145/3290605.3300673, 10.1109/southeastcon42311.2019.9020530]
   Andersen GJ, 2011, ACCIDENT ANAL PREV, V43, P381, DOI 10.1016/j.aap.2010.09.007
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Baayen RH, 2010, INT J PSYCHOL RES, V3, P12
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bassolino M, 2010, NEUROPSYCHOLOGIA, V48, P803, DOI 10.1016/j.neuropsychologia.2009.11.009
   Bergström J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300798
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Buck LE, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P332, DOI [10.1109/VR46266.2020.1581103473496, 10.1109/VR46266.2020.00-51]
   Creem-Regehr SH, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P47, DOI 10.1145/2804408.2804422
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Gonzalez-Franco M, 2019, IEEE T HAPTICS, V12, P319, DOI 10.1109/TOH.2019.2925038
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hillaire S, 2012, IEEE T VIS COMPUT GR, V18, P356, DOI 10.1109/TVCG.2011.154
   Ho C, 2009, HUM FACTORS, V51, P539, DOI 10.1177/0018720809341735
   Hutchins EL., 1985, HUMAN COMPUTER INTER, V1, P311, DOI DOI 10.1207/S15327051HCI0104_2
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Knierim P., 2018, P CHI C HUM FACT COM, P1
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Làdavas E, 2008, COGN NEUROPSYCHOL, V25, P1099, DOI 10.1080/02643290802359113
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Lo S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01171
   Lopez MC, 2016, REV NEUROL-FRANCE, V172, P270, DOI 10.1016/j.neurol.2016.01.399
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Müller J, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3121431
   Noel JP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33961-3
   Ogawa A, 2015, HUM BRAIN MAPP, V36, P2231, DOI 10.1002/hbm.22767
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Owen R., 2005, Proceedings of Graphics Interface 2005, P17
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   Peillard E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P227, DOI [10.1109/VR.2019.8797826, 10.1109/vr.2019.8797826]
   Qian JH, 2019, PSYCHON B REV, V26, P1657, DOI 10.3758/s13423-019-01640-7
   Rzayev R, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P199, DOI 10.1145/3311350.3347190
   Schwind V, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225158
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Serino A, 2018, Front ICT, V4, P31, DOI [10.3389/fict.2017.00031, DOI 10.3389/FICT.2017.00031]
   Serino A, 2019, NEUROSCI BIOBEHAV R, V99, P138, DOI 10.1016/j.neubiorev.2019.01.016
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stojmenova K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020594
NR 49
TC 9
Z9 9
U1 1
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1545
EP 1556
DI 10.1109/TVCG.2020.3021342
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA YP1EJ
UT WOS:000748371200007
PM 32877336
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Xiao, Y
   Wu, J
   Zhang, J
   Zhou, PY
   Zheng, Y
   Leung, CS
   Kavan, L
AF Xiao, Yi
   Wu, Jin
   Zhang, Jie
   Zhou, Peiyao
   Zheng, Yan
   Leung, Chi-Sing
   Kavan, Ladislav
TI Interactive Deep Colorization and its Application for Image Compression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep convolutional neural network; interactive; residual learning; image
   colorization; image compression
ID COLOR; FEATURES
AB Recent methods based on deep learning have shown promise in converting grayscale images to colored ones. However, most of them only allow limited user inputs (no inputs, only global inputs, or only local inputs), to control the output colorful images. The possible difficulty lies in how to differentiate the influences of different inputs. To solve this problem, we propose a two-stage deep colorization method allowing users to control the results by flexibly setting global inputs and local inputs. The key steps include enabling color themes as global inputs by extracting K mean colors and generating K-color maps to define a global theme loss, and designing a loss function to differentiate the influences of different inputs without causing artifacts. We also propose a color theme recommendation method to help users choose color themes. Based on the colorization model, we further propose an image compression scheme, which supports variable compression ratios in a single network. Experiments on colorization show that our method can flexibly control the colorized results with only a few inputs and generate state-of-the-art results. Experiments on compression show that our method achieves much higher image quality at the same compression ratio when compared to the state-of-the-art methods.
C1 [Xiao, Yi] Hunan Univ, Sch Design, Changsha 410082, Hunan, Peoples R China.
   [Wu, Jin; Zhang, Jie; Zhou, Peiyao] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Zheng, Yan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Leung, Chi-Sing] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
   [Kavan, Ladislav] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
C3 Hunan University; Hunan University; Hunan University; City University of
   Hong Kong; Utah System of Higher Education; University of Utah
RP Zhang, J (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM yixiao1984@gmail.com; as850785314@qq.com; jie_zhang@hnu.edu.cn;
   dizhuyouxi@163.com; yanzheng@hnu.edu.cn; eeleungc@cityu.edu.hk;
   ladislav.kavan@gmail.com
FU National Key R&D Program of China [2018YFB0203904]; NSFC from PRC
   [61872137, 61803150]; Hunan NSF [2020JJ4009,2018JJ3067]; China
   Scholarship Council [201806135087]
FX This work was supported by the National Key R&D Program of China
   (2018YFB0203904), NSFC from PRC (61872137, 61803150), Hunan NSF
   (2020JJ4009,2018JJ3067) and China Scholarship Council (201806135087).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Agustsson E, 2017, ADV NEUR IN, V30
   An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, ABS160407904  ARXIV
   [Anonymous], 2012, ACM T GRAPHIC
   Baig M. H., 2017, Advances in Neural Information Processing Systems
   Baig MH, 2017, COMPUT VIS IMAGE UND, V164, P111, DOI 10.1016/j.cviu.2017.01.010
   Balle Johannes, 2017, INT C LEARN REPR
   Baluja S, 2019, IEEE IMAGE PROC, P1700, DOI [10.1109/icip.2019.8803147, 10.1109/ICIP.2019.8803147]
   Bellard F., BPG Image Format
   Casaca W, 2015, LECT NOTES COMPUT SC, V9257, P675, DOI 10.1007/978-3-319-23117-4_58
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chang Youngha, 2005, ACM Trans. Appl. Perception, V2, P322
   Cheng L., 2007, PROC 24 INT C MACHIN, P161, DOI DOI 10.1145/1273496.1273517
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Deshpande A, 2015, IEEE I CONF COMP VIS, P567, DOI 10.1109/ICCV.2015.72
   Endo Y, 2016, COMPUT GRAPH FORUM, V35, P189, DOI 10.1111/cgf.12822
   Frans Kevin, 2017, CoRR
   Guo CL, 2019, IEEE T IMAGE PROCESS, V28, P2545, DOI 10.1109/TIP.2018.2887029
   Gupta R.K., 2012, P 20 ACM INT C MULT, P369, DOI [10.1145/2393347.2393402, DOI 10.1145/2393347.2393402]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Horiuchi T, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P245
   Horiuchi T, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/158273
   Hua M, 2014, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2014.363
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Karos L, 2018, LECT NOTES COMPUT SC, V11182, P547, DOI 10.1007/978-3-030-01449-0_46
   Kawulok M, 2011, ADV INTEL SOFT COMPU, V95, P269
   Kawulok M, 2010, IEEE IMAGE PROC, P405, DOI 10.1109/ICIP.2010.5653544
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee S, 2013, IEEE T IMAGE PROCESS, V22, P2627, DOI 10.1109/TIP.2013.2253486
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li M, 2018, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR.2018.00339
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li Y, 2008, COMPUT GRAPH FORUM, V27, P1255, DOI 10.1111/j.1467-8659.2008.01264.x
   Limmer M, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P61, DOI [10.1109/ICMLA.2016.114, 10.1109/ICMLA.2016.0019]
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q., 2007, P 18 EUR C REND TECH, P309
   Morimoto Y., 2009, P SIGGRAPH 2009 TALK, DOI [10.1145/1597990.1598049, DOI 10.1145/1597990.1598049]
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Noda H, 2007, PATTERN RECOGN, V40, P3714, DOI 10.1016/j.patcog.2007.04.005
   Ono Shunsuke, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P230, DOI 10.1109/PCS.2010.5702473
   Peter P, 2017, IEEE T IMAGE PROCESS, V26, P860, DOI 10.1109/TIP.2016.2627800
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Theis Lucas, 2017, INT C LEARN REPR
   Toderici George, 2016, INT C LEARN REPR
   Varga D, 2016, INT C PATT RECOG, P3691, DOI 10.1109/ICPR.2016.7900208
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Xiao Y, 2019, INT CONF ACOUST SPEE, P1887, DOI 10.1109/ICASSP.2019.8683686
   Xiao Y, 2019, LECT NOTES COMPUT SC, V11364, P207, DOI 10.1007/978-3-030-20870-7_13
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618464
   Yao C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3582139
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yi-Chin Huang, 2005, 13th Annual ACM International Conference on Multimedia, P351, DOI 10.1145/1101149.1101223
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao YL, 2016, COMM COM INF SC, V634, P238, DOI 10.1007/978-981-10-2260-9_27
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V58, P53, DOI 10.1016/j.jvcir.2018.11.028
NR 68
TC 4
Z9 4
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1557
EP 1572
DI 10.1109/TVCG.2020.3021510
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200008
PM 32881687
DA 2024-11-06
ER

PT J
AU Chittaro, L
   Buttussi, F
AF Chittaro, Luca
   Buttussi, Fabio
TI Learning Safety Through Public Serious Games: A Study of "Prepare for
   Impact" on a Very Large, International Sample of Players
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Games; Safety; Training; Accidents; Scalability; Sociology; Serious
   games; training; education; user study; research-in-the-large; aviation
   safety
ID COMPUTER GAMES; EMPIRICAL-EVIDENCE
AB Recent years have witnessed a growing interest in serious games (SGs), i.e., digital games for education and training. However, although the potential scalability of SGs to large player populations is often praised in the literature, available SG evaluations did not provide evidence of it because they did not study learning on large, varied, international samples in naturalistic conditions. This article considers a SG that educates players about aircraft cabin safety. It presents the first study of learning in a SG intervention conducted in naturalistic conditions with a very large, worldwide sample, which includes 45,000 players who accepted to answer a knowledge questionnaire before and after playing the game, and more than 400,000 players whose in-game behavior was analyzed. Results show that the SG led to improvement in players' knowledge, assessed with different metrics. Moreover, analysis of repeated play shows that participants improved their in-game safety behavior over time. We also focus on the role of making errors in the game, showing how they led to improvement in knowledge. Finally, we highlight the theoretical models, such as error-based learning and Protection Motivation Theory, that oriented the game design, and can be reused to create SGs for other domains.
C1 [Chittaro, Luca; Buttussi, Fabio] Univ Udine, Dept Math Comp Sci & Phys, Human Comp Interact Lab, I-33100 Udine, Italy.
C3 University of Udine
RP Buttussi, F (corresponding author), Univ Udine, Dept Math Comp Sci & Phys, Human Comp Interact Lab, I-33100 Udine, Italy.
EM luca.chittaro@uniud.it; fabio.buttussi@uniud.it
RI Buttussi, Fabio/AAD-9210-2020
OI Buttussi, Fabio/0000-0003-0868-3638; CHITTARO, Luca/0000-0001-5975-4294
FU Federal Aviation Administration (FAA)
FX This research was supported in part by a Grant of the Federal Aviation
   Administration (FAA). Nicola Zangrando (HCI Lab, University of Udine)
   carried out 3D modeling activities for the development of the game.
CR Airbus, 2019, AIRBUS A320
   Bandura A., 1986, Social foundations of thought and action: A social cognitive theory
   Bartell AL, 2012, IEEE INT PROF COMMUN
   Boeing, 2019, BOEING 777
   Boyle EA, 2016, COMPUT EDUC, V94, P178, DOI 10.1016/j.compedu.2015.11.003
   Chittaro L, 2019, INT J HUM-COMPUT ST, V127, P112, DOI 10.1016/j.ijhcs.2018.07.006
   Chittaro L, 2016, IEEE T VIS COMPUT GR, V22, P1527, DOI 10.1109/TVCG.2015.2443787
   Chittaro L, 2016, INT J HUM-COMPUT ST, V86, P63, DOI 10.1016/j.ijhcs.2015.09.004
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Clark DB, 2016, REV EDUC RES, V86, P79, DOI 10.3102/0034654315582065
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Corbett C. L., 2008, DOTFAAAM0820 OFF AER
   Corbett C. L., 2007, P 5 TRIENN INT AIR F
   Dufau S, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0024974
   Floyd DL, 2000, J APPL SOC PSYCHOL, V30, P407, DOI 10.1111/j.1559-1816.2000.tb02323.x
   Fogg B., 2003, PERSUASIVE TECHNOLOG
   Gosling SD, 2004, AM PSYCHOL, V59, P93, DOI 10.1037/0003-066X.59.2.93
   Graesser A.C., 2009, Serious games: Mechanisms and effects, P81
   HCI Lab-University of Udine, 2019, AIR SAF WORLD WEBS
   HCI Lab-University of Udine, 2019, PREP IMP WEBS
   Henze Niels, 2013, Interactions, V20, P33, DOI 10.1145/2427076.2427084
   Ivancic K, 2000, ERGONOMICS, V43, P1966, DOI 10.1080/00140130050201427
   Keith N, 2008, J APPL PSYCHOL, V93, P59, DOI 10.1037/0021-9010.93.1.59
   Killingsworth MA, 2010, SCIENCE, V330, P932, DOI 10.1126/science.1192439
   Li Q, 2014, ACCIDENT ANAL PREV, V65, P8, DOI 10.1016/j.aap.2013.12.003
   Lin MF, 2013, INFORM SYST RES, V24, P906, DOI 10.1287/isre.2013.0480
   Malhotra N, 2008, PUBLIC OPIN QUART, V72, P914, DOI 10.1093/poq/nfn050
   Mayer RE, 2015, EDUC PSYCHOL-US, V50, P349, DOI 10.1080/00461520.2015.1133307
   Metcalfe J, 2017, ANNU REV PSYCHOL, V68, P465, DOI 10.1146/annurev-psych-010416-044022
   Miller G, 2012, PERSPECT PSYCHOL SCI, V7, P221, DOI 10.1177/1745691612441215
   Miller-Day M, 2013, HEALTH COMMUN, V28, P657, DOI 10.1080/10410236.2012.762861
   Mohan D, 2018, P NATL ACAD SCI USA, V115, P9204, DOI 10.1073/pnas.1805450115
   National Transportation Safety Board, 2010, Aircraft accident report: Loss of thrust in both engines after encountering a flock of birds and subsequent ditching on the Hudson river, us airways flight 1549, airbus a320-214, n106us, Weehawken, New Jersey
   Plass JL, 2015, EDUC PSYCHOL-US, V50, P258, DOI 10.1080/00461520.2015.1122533
   Rogers R. W., 1983, SOCIAL PSYCHOPHYSIOL, P153
   Seneviratne D, 2015, SAFETY SCI, V75, P130, DOI 10.1016/j.ssci.2015.01.006
   Skinner Burrhus F., 1965, SCI HUMAN BEHAV
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Transportation Safety Board of Canada, 2005, A05HII0002 TRANSP SA
   Williams-Bell FM, 2015, FIRE TECHNOL, V51, P553, DOI 10.1007/s10694-014-0398-1
NR 42
TC 7
Z9 7
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1573
EP 1584
DI 10.1109/TVCG.2020.3022340
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200009
PM 32894716
DA 2024-11-06
ER

PT J
AU Vasiou, E
   Shkurko, K
   Brunvand, E
   Yuksel, C
AF Vasiou, Elena
   Shkurko, Konstantin
   Brunvand, Erik
   Yuksel, Cem
TI Mach-RT: A Many Chip Architecture for High Performance Ray Tracing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ray tracing; Acceleration; Instruction sets; System-on-chip; Memory
   management; Hardware; Raytracing hardware; graphics accelerators
ID ENERGY
AB Data movement, particularly access to the main memory, has been the bottleneck of most computing problems. Ray tracing is no exception. We propose an unconventional solution that combines a ray ordering scheme that minimizes access to the scene data with a large on-chip buffer acting as near-compute storage that is spread over multiple chips. We demonstrate the effectiveness of our approach by introducing Mach-RT (Many chip - Ray Tracing), a new hardware architecture for accelerating ray tracing. Extending the concept of dual streaming, we optimize the main memory accesses to a level that allows the same memory system to service multiple processor chips at the same time. While a multiple chip solution might seem to imply increased energy consumption as well, because of the reduced memory traffic we are able to demonstrate, performance increases while maintaining reasonable energy usage compared to academic and commercial architectures. This article extends our previous work E. Vasiou, K. Shkurko, E. Brunvand, and C. Yuksel, "Mach-RT: A many chip architecture for high-performance ray tracing," in Proc. High-Perform. Graph. Conf., 2019 with design space exploration of the L3 cache size, more detailed evaluation of energy and memory performance, a discussion of energy delay product, and a brief exploration of boards with 16 chips. We also introduce new treelet enqueueing logic for the predictive scheduler.
C1 [Vasiou, Elena; Shkurko, Konstantin; Brunvand, Erik; Yuksel, Cem] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
C3 Utah System of Higher Education; University of Utah
RP Vasiou, E (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM elvasiou@cs.utah.edu; kshkurko@cs.utah.edu; elb@cs.utah.edu;
   cem@cemyuksel.com
FU US National Science Foundation [1409129]; Direct For Computer & Info
   Scie & Enginr; Division Of Computer and Network Systems [1409129]
   Funding Source: National Science Foundation
FX This material is based upon work supported by the US National Science
   Foundation under Grant no. 1409129. Scene data: Fairy Forest: U. Utah,
   Crytek Sponza: F. Meinl at Crytek and M. Dabrovic, Dragon: Stanford CG
   Lab., Vegetation: S. Laine, and San Miguel: G. Leal Laguno.
CR Aila T., 2010, P C HIGH PERF GRAPH, P113
   Aila Timo, 2009, P C HIGH PERF GRAPH, P145, DOI [10.1145/1572769.1572792, DOI 10.1145/1572769.1572792]
   Aila Timo, 2012, NVR201202 NVIDIA
   [Anonymous], 2012, Tech. Rep. UUCS-12-002
   [Anonymous], 2018, WP09183001V01 NVIDIA
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Balasubramonian R, 2000, INT SYMP MICROARCH, P245, DOI 10.1109/MICRO.2000.898075
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Barringer R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601222
   Benthin C., 2018, P C HIGH PERF GRAPH
   Bigler J, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P187
   Bikker J, 2012, COMPUT GRAPH FORUM, V31, P1936, DOI 10.1111/j.1467-8659.2012.03073.x
   Brunvand E., 2014, P ACM SIGGRAPH COURS
   Eisenacher C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12158
   Fuchs H., 1985, Computer Graphics, V19, P111, DOI 10.1145/325165.325205
   Fuchs H., 1989, Computer Graphics, V23, P79, DOI 10.1145/74334.74341
   Gonzalez R, 1996, IEEE J SOLID-ST CIRC, V31, P1277, DOI 10.1109/4.535411
   Govindaraju V, 2008, INT SYMP MICROARCH, P176, DOI 10.1109/MICRO.2008.4771789
   Gribble CR, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P59, DOI 10.1109/RT.2008.4634622
   Hadidi R, 2017, I S WORKL CHAR PROC, P66, DOI 10.1109/IISWC.2017.8167757
   Hapala Michal., 2013, Proceedings of Spring Conference on Computer Graphics, P7
   Jacob B, 2008, MEMORY SYSTEMS: CACHE, DRAM, DISK, P1
   JDEC Standard,, 2015, JESD325A JDEC SOL ST
   Jouppi NP, 2012, ICCAD-IEEE ACM INT, P294
   Kajiya James T., 1986, P ANN C COMP GRAPH I, DOI 10.1145/15886.15902
   Keely S., 2014, P HIGH PERF GRAPH LY, P29
   Kelm JH, 2009, CONF PROC INT SYMP C, P140, DOI 10.1145/1555815.1555774
   Kim HY, 2012, IEEE J SOLID-ST CIRC, V47, P518, DOI 10.1109/JSSC.2011.2171417
   Kim HY, 2010, IEEE CUST INTEGR CIR
   Kim TJ, 2010, IEEE T VIS COMPUT GR, V16, P273, DOI 10.1109/TVCG.2009.71
   Kopta D, 2015, COMPUT GRAPH FORUM, V34, P47, DOI 10.1111/cgf.12458
   Kopta D, 2010, PR IEEE COMP DESIGN, P9, DOI 10.1109/ICCD.2010.5647555
   Kopta Daniel, 2013, P 5 HIGH PERF GRAPH, P121
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Lee W.-J., 2013, Proceedings of the 5th High-Performance Graphics Conference, P109
   Lee Won-Jong, 2015, P HIGH PERF GRAPH, P21
   Lier A., 2018, P HIGH PERFORMANCE G
   Lier A, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233308
   Liktor G., 2016, P HIGH PERF GRAPH, P51
   Mai K, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P161, DOI [10.1109/ISCA.2000.854387, 10.1145/342001.339673]
   Meister D, 2018, COMPUT GRAPH FORUM, V37, P463, DOI 10.1111/cgf.13376
   Moon B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805972
   Morley RK, 2006, PROC GRAPH INTERF, P179
   Nah JH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629634
   Navrátil PA, 2007, RT07: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2007, P95, DOI 10.1109/RT.2007.4342596
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Pharr M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P101, DOI 10.1145/258734.258791
   Purcell TJ, 2002, ACM T GRAPHIC, V21, P703, DOI 10.1145/566570.566640
   Ramani K, 2009, ACM SIGPLAN NOTICES, V44, P325, DOI 10.1145/1508284.1508282
   SCHMITTLER J., 2002, HWWS 02, P27
   Schmittler Jorg., 2004, Proc. of the ACM SIGGRAPH/EUROGRAPHICS Conference on Graphics Hardware (HWWS), P95
   Selgrad K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2953877
   Shkurko K, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105771
   Shkurko K, 2018, PR GR LAK SYMP VLSI, P503, DOI 10.1145/3194554.3194650
   Son M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105784
   Spjut J, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P108, DOI 10.1109/SASP.2008.4570794
   Spjut J, 2009, IEEE T COMPUT AID D, V28, P1802, DOI 10.1109/TCAD.2009.2028981
   Thonnart Y, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P168, DOI 10.1109/NOCS.2014.7008777
   Tsakok J.A., 2009, Proc. High Performance Graphics, P151, DOI DOI 10.1145/1572769.15727932
   Usman A, 2017, IEEE T COMP PACK MAN, V7, P819, DOI 10.1109/TCPMT.2017.2674686
   Vasileska E, 2019, P HIGH PERF GRAPH C, P1
   Vasiou E, 2018, VISUAL COMPUT, V34, P875, DOI 10.1007/s00371-018-1532-8
   Viitanen T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3132702
   Wald I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601199
   Wald Ingo, 2007, UUSCI2007012 SCI I
   Woop S, 2005, ACM T GRAPHIC, V24, P434, DOI 10.1145/1073204.1073211
   Woop S, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P7
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Wyman C., 2018, P ACM SIGGRAPH COURS
   Ylitie H, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105773
   Zhang Z, 2004, IEEE T COMPUT, V53, P843, DOI 10.1109/TC.2004.27
NR 72
TC 0
Z9 0
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1585
EP 1596
DI 10.1109/TVCG.2020.3021048
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200010
PM 32870795
OA Bronze
DA 2024-11-06
ER

PT J
AU Tuffaha, M
   Stavdahl, O
   Stensdotter, AK
AF Tuffaha, Mutaz
   Stavdahl, Oyvind
   Stensdotter, Ann-Katrin
TI Modeling Movement-Induced Errors in AC Electromagnetic Trackers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Position measurement; Heuristic algorithms; Coils; Current measurement;
   Robot sensing systems; Time measurement; Tracking; Electromagnetic
   motion tracking system; motion capture; error analysis; polhemus systems
ID TRACKING; POSITION; MOTION
AB Error analysis of electromagnetic motion tracking systems is of growing interest to many researchers. Under sensor movement, it is logical to presume that the error in position and orientation measurements will increase due to the linearization used in the algorithms, among other reasons. In this article, we analyze theoretically the error, that results from linearization, in position measurement of the Polhemus tracking system for a moving sensor. We derive formulas to estimate this error in terms of the sensor position and speed. Then, we verify these formulas by numerical simulations.
C1 [Tuffaha, Mutaz] Indra Navia AS, NO-1383 Asker, Norway.
   [Stavdahl, Oyvind] Norwegian Univ Sci & Technol NTNU, Fac Informat Technol Math & Elect Engn, Dept Engn Cybernet, NO-7491 Trondheim, Norway.
   [Stensdotter, Ann-Katrin] Norwegian Univ Sci & Technol NTNU, Fac Med & Hlth Sci, Dept Neuromed & Movement Sci, NO-7491 Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU); Norwegian
   University of Science & Technology (NTNU)
RP Tuffaha, M (corresponding author), Indra Navia AS, NO-1383 Asker, Norway.
EM mutaz.tuffaha@indra.no; oyvind.stavdahl@ntnu.no;
   ann-katrin.stensdotter@ntnu.no
RI Stavdahl, Øyvind/AAC-2875-2019
OI Stavdahl, Oyvind/0000-0003-0212-3146
FU Norwegian University of Science and Technology (NTNU)
FX The authors would like to thank the Norwegian University of Science and
   Technology (NTNU) for their financial support. They would also like to
   thank Dr. Frederick H. Raab for the valuable discussions. Further, They
   also thank Polhemus for their cooperation.
CR AN KN, 1988, J BIOMECH, V21, P613, DOI 10.1016/0021-9290(88)90225-4
   BRYSON S, 1992, P SOC PHOTO-OPT INS, V1669, P244, DOI 10.1117/12.60417
   Field M, 2009, IEEE INT CONF CON AU, P1697, DOI 10.1109/ICCA.2009.5410185
   Franz AM, 2014, IEEE T MED IMAGING, V33, P1702, DOI 10.1109/TMI.2014.2321777
   Hummel J., 2009, P SPIE IMAG VISUALIZ, V7261, P1
   Kalmus HP., 1962, IRE Transactions on Aerospace and Navigational Electronics, P7
   Kindratenko V. V., 2000, Virtual Reality, V5, P169, DOI 10.1007/BF01409422
   Kobayashi K, 1997, GAIT POSTURE, V6, P63, DOI 10.1016/S0966-6362(96)01102-2
   KUIPERS JB, 1980, IEEE T INSTRUM MEAS, V29, P462, DOI 10.1109/TIM.1980.4314980
   LENZ JE, 1990, P IEEE, V78, P973, DOI 10.1109/5.56910
   Murphy MJ, 2008, INT J RADIAT ONCOL, V72, P295, DOI 10.1016/j.ijrobp.2008.05.036
   Nixon MA, 1998, PRESENCE-TELEOP VIRT, V7, P204, DOI 10.1162/105474698565587
   RAAB FH, 1981, IEEE T GEOSCI REMOTE, V19, P235, DOI 10.1109/TGRS.1981.350378
   RAAB FH, 1979, IEEE T AERO ELEC SYS, V15, P709, DOI 10.1109/TAES.1979.308860
   Stensdotter AK, 2016, PHYSIOL REP, V4, DOI 10.14814/phy2.12745
   Welch G, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.1046626
NR 16
TC 3
Z9 3
U1 3
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1597
EP 1607
DI 10.1109/TVCG.2020.3019700
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200011
PM 32845841
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ferrari, V
   Cattari, N
   Fontana, U
   Cutolo, F
AF Ferrari, Vincenzo
   Cattari, Nadia
   Fontana, Umberto
   Cutolo, Fabrizio
TI Parallax Free Registration for Augmented Reality Optical See-Through
   Displays in the Peripersonal Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; optical see-through; registration
AB Egocentric augmented reality (AR) interfaces are quickly becoming a key asset for assisting high precision activities in the peripersonal space in several application fields. In these applications, accurate and robust registration of computer-generated information to the real scene is hard to achieve with traditional Optical See-Through (OST) displays given that it relies on the accurate calibration of the combined eye-display projection model. The calibration is required to efficiently estimate the projection parameters of the pinhole model that encapsulate the optical features of the display and whose values vary according to the position of the user's eye. In this article, we describe an approach that prevents any parallax-related AR misregistration at a pre-defined working distance in OST displays with infinity focus; our strategy relies on the use of a magnifier placed in front of the OST display, and features a proper parameterization of the virtual rendering camera achieved through a dedicated calibration procedure that accounts for the contribution of the magnifier. We model the registration error due to the viewpoint parallax outside the ideal working distance. Finally, we validate our strategy on a OST display, and we show that sub-millimetric registration accuracy can be achieved for working distances of +/- 100mm around the focal length of the magnifier.
C1 [Ferrari, Vincenzo; Fontana, Umberto; Cutolo, Fabrizio] Univ Pisa, Informat Engn Dept, Via G Caruso 16, I-56122 Pisa, Italy.
   [Ferrari, Vincenzo; Cutolo, Fabrizio] Univ Pisa, EndoCAS Ctr, Dept Translat Res & New Technol Med & Surg, I-56124 Pisa, Italy.
   [Cattari, Nadia] Univ Pisa, Dept Translat Res & New Technol Med & Surg, I-56124 Pisa, Italy.
C3 University of Pisa; University of Pisa; University of Pisa
RP Ferrari, V (corresponding author), Univ Pisa, Informat Engn Dept, Via G Caruso 16, I-56122 Pisa, Italy.; Ferrari, V (corresponding author), Univ Pisa, EndoCAS Ctr, Dept Translat Res & New Technol Med & Surg, I-56124 Pisa, Italy.
EM vincenzo.ferrari@unipi.it; nadia.cattari@endocas.unipi.it;
   umbertofontana93@gmail.com; fabrizio.cutolo@endocas.unipi.it
RI Cattari, Nadia/AAC-3748-2022; Ferrari, Vincenzo/H-9908-2015; Cutolo,
   Fabrizio/K-2408-2018
OI Ferrari, Vincenzo/0000-0001-9294-2828; Fontana,
   Umberto/0000-0002-8353-7051; Cutolo, Fabrizio/0000-0001-6773-3741;
   Cattari, Nadia/0000-0002-7091-2908
FU HORIZON2020 Project VOSTARS (Video-Optical See Through AR surgical
   System) [731974, ICT-29-2016 Photonics KET 2016]; Italian Ministry of
   Education and Research (MIUR) within CrossLab project (Departments of
   Excellence) of the University of Pisa, laboratory of Augmented Reality
FX This research was supported in part by the HORIZON2020 Project VOSTARS
   (Video-Optical See Through AR surgical System), Project ID: 731974.
   Call: ICT-29-2016 Photonics KET 2016. Thisworkwas also supported in part
   by the Italian Ministry of Education and Research (MIUR) within the
   framework of the CrossLab project (Departments of Excellence) of the
   University of Pisa, laboratory of Augmented Reality.
CR Badiali G, 2014, J CRANIO MAXILL SURG, V42, P1970, DOI 10.1016/j.jcms.2014.09.001
   Benton S, 2001, SPIE MILESTONE SERIE
   Calabro Emanuele Maria., 2017, Wireless Mobile Communication and Healthcare, P345
   Cattari N, 2019, IEEE ACCESS, V7, P159698, DOI 10.1109/ACCESS.2019.2950877
   Chakravarthula P, 2018, IEEE T VIS COMPUT GR, V24, P2906, DOI 10.1109/TVCG.2018.2868532
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Condino S, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5435097
   Cutolo F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010193
   Cutolo F, 2020, IEEE ACCESS, V8, P706, DOI 10.1109/ACCESS.2019.2962122
   Cutolo F, 2019, ANN BIOMED ENG, V47, P2151, DOI 10.1007/s10439-019-02299-w
   Cutolo F, 2018, INT J ADV COMPUT SC, V9, P12
   Cutolo F, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6010009
   Cutolo F, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P52, DOI 10.1109/ISMAR-Adjunct.2017.31
   Cutolo F, 2016, LECT NOTES COMPUT SC, V9769, P43, DOI 10.1007/978-3-319-40651-0_4
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Grubert J, 2018, IEEE T VIS COMPUT GR, V24, P2649, DOI 10.1109/TVCG.2017.2754257
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Holliman NS, 2011, IEEE T BROADCAST, V57, P362, DOI 10.1109/TBC.2011.2130930
   Hua H, 2017, PROC SPIE, V10219, DOI 10.1117/12.2264157
   Hua H, 2017, P IEEE, V105, P805, DOI 10.1109/JPROC.2017.2648796
   Itoh Y, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P75, DOI 10.1109/3DUI.2014.6798846
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lanman D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508366
   Lee S, 2015, J DISP TECHNOL, V11, P845, DOI 10.1109/JDT.2014.2386216
   Liao H, 2004, IEEE T INF TECHNOL B, V8, P114, DOI 10.1109/TITB.2004.826734
   Liao HE, 2011, IEEE T VIS COMPUT GR, V17, P1690, DOI 10.1109/TVCG.2010.267
   Maimone A, 2013, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2013.6671761
   Oshima K, 2016, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2016.7504749
   Pieptu D, 2003, MICROSURG, V23, P181, DOI 10.1002/micr.10126
   Plopski A, 2015, IEEE T VIS COMPUT GR, V21, P481, DOI 10.1109/TVCG.2015.2391857
   Rolland J, 2005, PROC SPIE, V5638, P368, DOI 10.1117/12.575697
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Sarayeddine K, 2013, PROC SPIE, V8720, DOI 10.1117/12.2018184
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Vávra P, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4574172
NR 36
TC 14
Z9 14
U1 1
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1608
EP 1618
DI 10.1109/TVCG.2020.3021534
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200012
PM 32881688
DA 2024-11-06
ER

PT J
AU Yoon, L
   Yang, D
   Kim, J
   Chung, C
   Lee, SH
AF Yoon, Leonard
   Yang, Dongseok
   Kim, Jaehyun
   Chung, Choongho
   Lee, Sung-Hee
TI Placement Retargeting of Virtual Avatars to Dissimilar Indoor
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Telepresence; Semantics; Three-dimensional displays; Layout;
   Prototypes; Indoor environment; Telepresence; avatar; augmented reality;
   similarity learning
ID DISTANCE
AB Rapidly developing technologies are realizing a 3D telepresence, in which geographically separated users can interact with each other through their virtual avatars. In this article, we present novel methods to determine the avatar's position in an indoor space to preserve the semantics of the user's position in a dissimilar indoor space with different space configurations and furniture layouts. To this end, we first perform a user survey on the preferred avatar placements for various indoor configurations and user placements, and identify a set of related attributes, including interpersonal relation, visual attention, pose, and spatial characteristics, and quantify these attributes with a set of features. By using the obtained dataset and identified features, we train a neural network that predicts the similarity between two placements. Next, we develop an avatar placement method that preserves the semantics of the placement of the remote user in a different space as much as possible. We show the effectiveness of our methods by implementing a prototype AR-based telepresence system and user evaluations.
C1 [Yoon, Leonard; Yang, Dongseok; Kim, Jaehyun; Chung, Choongho; Lee, Sung-Hee] Korea Adv Inst Sci & Technol KAIST, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, SH (corresponding author), Korea Adv Inst Sci & Technol KAIST, Daejeon 34141, South Korea.
EM lyoon@kaist.ac.kr; dsyang@kaist.ac.kr; chrisjkim@kaist.ac.kr;
   thegenuine@kaist.ac.kr; sunghee.lee@kaist.ac.kr
OI Yang, Dongseok/0000-0002-4696-3465; Kim, Jaehyun/0000-0001-7469-9043;
   Yoon, Leonard/0000-0002-4015-7550; Lee, Sung-Hee/0000-0001-6604-4709
FU Samsung Research Funding Incubation Center of Samsung Electronics
   [SRFC-IT1701-14]
FX This work was partly supported by Samsung Research Funding Incubation
   Center of Samsung Electronics (SRFC-IT1701-14).
CR AL-ASQHAR R. A., 2013, P 12 ACM SIGGRAPH EU, P45, DOI [10.1145/2485895, DOI 10.1145/2485895]
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Choi KJ, 2000, J VISUAL COMP ANIMAT, V11, P223, DOI 10.1002/1099-1778(200012)11:5<223::AID-VIS236>3.0.CO;2-5
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]
   Eberhart RC, 2000, IEEE C EVOL COMPUTAT, P84, DOI 10.1109/CEC.2000.870279
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Guye-Vuilleme A., 1999, Virtual Reality, V4, P49, DOI 10.1007/BF01434994
   Hall ET, 1966, The hidden dimension, V609
   Harms C., 2004, P PRES 2004, P7
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu RZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925870
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Huang YZ, 2016, IEEE T VIS COMPUT GR, V22, P1568, DOI 10.1109/TVCG.2015.2446494
   Jin T, 2018, COMPUT GRAPH FORUM, V37, P311, DOI 10.1111/cgf.13363
   Jo D, 2015, COMPUT ANIMAT VIRT W, V26, P259, DOI 10.1002/cav.1645
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Kim Y, 2016, IEEE T VIS COMPUT GR, V22, P2405, DOI 10.1109/TVCG.2016.2593780
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Lehment NH, 2014, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2014.6948428
   Lei CY, 2016, PROC CVPR IEEE, P2545, DOI 10.1109/CVPR.2016.279
   Li XT, 2019, PROC CVPR IEEE, P12360, DOI 10.1109/CVPR.2019.01265
   Lombard Matthew, 2009, P 12 ANN INT WORKSH, P1
   Lu R, 2017, INT CONF ACOUST SPEE, P121, DOI 10.1109/ICASSP.2017.7952130
   Lund Arnold M., 2001, Usability interface, V8, P3
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   McFee B., 2010, P 27 INT C MACH LEAR, P775, DOI DOI 10.0RG/PAPERS/504.PDF
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pedica C, 2010, APPL ARTIF INTELL, V24, P575, DOI 10.1080/08839514.2010.492165
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Pirk R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083725
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Qi XY, 2017, AAAI CONF ARTIF INTE, P4979
   Rae I, 2015, P 33 ANN ACM C EXT A, P2409, DOI DOI 10.1145/2702613.2702639
   Savva M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925867
   Savva M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661230
   Scheflen A., 1976, Human territories: How we behave in space-time
   Schleipen M., 2015, 2015 IEEE 20 C EM TE, P1, DOI DOI 10.1109/ETFA.2015.7301640
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Wang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2503177
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wilcox Laurie M., 2006, ACM Transactions on Applied Perception, V3, P412, DOI DOI 10.1145/1190036.1190041
   Zhao X, 2017, COMPUT GRAPH FORUM, V36, P119, DOI 10.1111/cgf.13112
NR 46
TC 15
Z9 15
U1 1
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1619
EP 1633
DI 10.1109/TVCG.2020.3018458
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200013
PM 32822297
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cuenca, E
   Sallaberry, A
   Ienco, D
   Poncelet, P
AF Cuenca, Erick
   Sallaberry, Arnaud
   Ienco, Dino
   Poncelet, Pascal
TI VERTIGo: A Visual Platform for Querying and Exploring Large Multilayer
   Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Nonhomogeneous media; Task analysis; Social networking
   (online); Query processing; Databases; Standards; Visual querying
   system; visual pattern suggestion; multilayer networks
ID EXPLORATION
AB Many real world data can be modeled by a graph with a set of nodes interconnected to each other by multiple relationships. Such a rich graph is called multilayer graph or network. Providing useful visualization tools to support the query process for such graphs is challenging. Although many approaches have addressed the visual query construction, few efforts have been done to provide a contextualized exploration of query results and suggestion strategies to refine the original query. This is due to several issues such as i) the size of the graphs ii) the large number of retrieved results and iii) the way they can be organized to facilitate their exploration. In this article, we present VERTIGo, a novel visual platform to query, explore and support the analysis of large multilayer graphs. VERTIGo provides coordinated views to navigate and explore the large set of retrieved results at different granularity levels. In addition, the proposed system supports the refinement of the query by visual suggestions to guide the user through the exploration process. Two examples and a user study demonstrate how VERTIGo can be used to perform visual analysis (query, exploration, and suggestion) on real world multilayer networks.
C1 [Cuenca, Erick] Yachay Tech Univ, Urcuqui 100650, Ecuador.
   [Sallaberry, Arnaud] Univ Montpellier, Paul Valery Univ Montpellier, LIRMM, AMIS Res Grp, F-34000 Montpellier, France.
   [Sallaberry, Arnaud; Poncelet, Pascal] CNRS, F-75016 Paris, France.
   [Ienco, Dino] INRAE, F-69100 Villeurbanne, France.
   [Poncelet, Pascal] Univ Montpellier, LIRMM, F-34000 Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Centre National de la Recherche Scientifique (CNRS); INRAE;
   Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Cuenca, E (corresponding author), Yachay Tech Univ, Urcuqui 100650, Ecuador.
EM ecuenca@yachaytech.edu.ec; arnaud.sallaberry@lirmm.fr;
   dino.ienco@inrae.fr; pascal.poncelet@lirmm.fr
RI Ienco, Dino/ABB-5260-2021; Cuenca, Erick/GYA-3972-2022; Sallaberry,
   Arnaud/IRY-9056-2023
OI Cuenca, Erick/0000-0002-3996-2851; Ienco, Dino/0000-0002-8736-3132
CR Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   [Anonymous], 2012, INFORM VISUAL
   Bhowmick SS, 2013, P C INN DAT SYST RES, P1
   Bonchi F, 2014, EDBT, P547
   Bourqui R, 2016, IEEE PAC VIS SYMP, P184, DOI 10.1109/PACIFICVIS.2016.7465267
   Carletti V, 2017, LECT NOTES COMPUT SC, V10310, P128, DOI 10.1007/978-3-319-58961-9_12
   Chen F., 2020, J. Graph Algorithms Appl., V24, P683, DOI [10.7155/jgaa.00532, DOI 10.7155/JGAA.00532]
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, P151
   Cuenca E, 2018, 30TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT (SSDBM 2018), DOI 10.1145/3221269.3223027
   Dinkla K, 2012, COMPUT GRAPH FORUM, V31, P875, DOI 10.1111/j.1467-8659.2012.03080.x
   Duen Horng Chau, 2008, 2008 IEEE International Conference on Data Mining Workshops, P963, DOI 10.1109/ICDMW.2008.99
   Fitzgibbon W., 2016, INT CONSORTIUM INVES
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Han W-S, 2013, P 2013 ACM SIGMOD IN, P337, DOI DOI 10.1145/2463676.2465300
   Huang WD, 2005, Ninth International Conference on Information Visualisation, Proceedings, P697
   Ingalalli V, 2016, LECT NOTES COMPUT SC, V9827, P387, DOI 10.1007/978-3-319-44403-1_24
   Jayaram N, 2015, PROC VLDB ENDOW, V8, P1941
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Libkin L., 2013, Proceedings of the 32nd symposium on principles of database systems, P201
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   Morin L., 2019, P INT WORKSH CHALL M
   Mottin D, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P825, DOI 10.1145/2783258.2783343
   Paradies M., 2015, ARXIV150600394
   Paradies M, 2015, PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, DOI 10.1145/2791347.2791383
   Perrot A, 2015, SYMP LARG DATA ANAL, P99, DOI 10.1109/LDAV.2015.7348077
   Pienta R, 2018, IEEE T VIS COMPUT GR, V24, P215, DOI 10.1109/TVCG.2017.2744898
   Pienta Robert, 2016, AVI, V2016, P272, DOI 10.1145/2909132.2909246
   Pienta R, 2015, INT CONF BIG DATA, P271, DOI 10.1109/35021BIGCOMP.2015.7072812
   Pietro Cordella Luigi, 2001, 3 IAPR TC15 WORKSH G, P149, DOI [10.1016/S0167-8655(02)00248-9, DOI 10.1016/S0167-8655(02)00248-9]
   Pohl M., 2019, P INT WORKSH CHALL S
   Redondo D, 2015, IEEE INT CONF INF VI, P50, DOI 10.1109/iV.2015.20
   Renoust B, 2015, COMPUT GRAPH FORUM, V34, P321, DOI 10.1111/cgf.12644
   Schreiber F, 2005, BIOINFORMATICS, V21, P3572, DOI 10.1093/bioinformatics/bti556
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Smith N., 2015, P SCIPY, P6
   Tong HH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P737
   Wagner D., 2003, DRAWING GRAPHS METHO
   Yan XF, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P721, DOI 10.1109/ICDM.2002.1184038
   Yi PP, 2016, PROC VLDB ENDOW, V9, P1505, DOI 10.14778/3007263.3007295
   Zhang A, 2009, PROTEIN INTERACTION NETWORKS: COMPUTATIONAL ANALYSIS, P1, DOI 10.1017/CBO9780511626593
NR 43
TC 6
Z9 6
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1634
EP 1647
DI 10.1109/TVCG.2021.3067820
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200014
PM 33750712
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hämäläinen, P
   Toikka, J
   Babadi, A
   Liu, CK
AF Hamalainen, Perttu
   Toikka, Juuso
   Babadi, Amin
   Liu, C. Karen
TI Visualizing Movement Control Optimization Landscapes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Linear programming; Animation; Trajectory optimization;
   Two dimensional displays; Visualization; animation; movement synthesis;
   trajectory optimization; policy optimization; control optimization
AB A large body of animation research focuses on optimization of movement control, either as action sequences or policy parameters. However, as closed-form expressions of the objective functions are often not available, our understanding of the optimization problems is limited. Building on recent work on analyzing neural network training, we contribute novel visualizations of high-dimensional control optimization landscapes; this yields insights into why control optimization is hard and why common practices like early termination and spline-based action parameterizations make optimization easier. For example, our experiments show how trajectory optimization can become increasingly ill-conditioned with longer trajectories, but parameterizing control as partial target states-e.g., target angles converted to torques using a PD-controller-can act as an efficient preconditioner. Both our visualizations and quantitative empirical data also indicate that neural network policy optimization scales better than trajectory optimization for long planning horizons. Our work advances the understanding of movement optimization and our visualizations should also provide value in educational use.
C1 [Hamalainen, Perttu; Toikka, Juuso; Babadi, Amin] Aalto Univ, Dept Comp Sci, Espoo 02150, Finland.
   [Liu, C. Karen] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Aalto University; Stanford University
RP Hämäläinen, P (corresponding author), Aalto Univ, Dept Comp Sci, Espoo 02150, Finland.
EM perttu.hamalainen@aalto.fi; juuso.toikka@aalto.fi; amin.babadi@aalto.fi;
   karenliu@cs.stanford.edu
OI Babadi, Amin/0000-0003-4930-9917; Hamalainen,
   Perttu/0000-0001-7764-3459; Liu, Karen/0000-0001-5926-0905
FU Academy of Finland [299358]; Academy of Finland (AKA) [299358] Funding
   Source: Academy of Finland (AKA)
FX This research has been supported by Academy of Finland Grant 299358.
CR Al Borno M, 2013, IEEE T VIS COMPUT GR, V19, P1405, DOI 10.1109/TVCG.2012.325
   [Anonymous], 2014, ARXIV14126544
   [Anonymous], 2017, ARXIV170204283
   Bergamin K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356536
   Brockman Greg, 2016, arXiv
   Carney RN, 2002, EDUC PSYCHOL REV, V14, P5, DOI 10.1023/A:1013176309260
   COHEN MF, 1992, COMP GRAPH, V26, P293
   Dinh L, 2017, PR MACH LEARN RES, V70
   Fang AC, 2003, ACM T GRAPHIC, V22, P417, DOI 10.1145/882262.882286
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Haarnoja T, 2018, PR MACH LEARN RES, V80
   Hämäläinen P, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P497, DOI 10.1145/3116595.3116617
   Hämäläinen P, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2767002
   Hämäläinen P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601218
   Hansen N, 2004, LECT NOTES COMPUT SC, V3242, P282
   Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398
   Hansen N., 2016, The CMA evolution strategy: A tutorial. arXiv preprint arXiv:1604.00772
   Hill A., 2018, Stable baselines
   Jones C. V., 1994, ORSA Journal on Computing, V6, P221, DOI 10.1287/ijoc.6.3.221
   Juliani A, 2018, ARXIVABS180902627 CO
   Keskar N.S., 2017, P 5 INT C LEARN REPR
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Levine S, 2013, INT C MACHINE LEARNI, V28, P1
   Li H, 2018, ADV NEUR IN, V31
   LI KC, 1992, J AM STAT ASSOC, V87, P1025, DOI 10.1080/01621459.1992.10476258
   Liu LB, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778865
   Loshchilov I, 2019, IEEE T EVOLUT COMPUT, V23, P353, DOI 10.1109/TEVC.2018.2855049
   Maclaurin D., 2015, ICML 2015 AUTOML WOR, V238
   Meignan D, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2808234
   Mordatch I., 2014, Robotics: Science and Systems (RSS)
   Mordatch I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185539
   Naderi K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073707
   Ngo J. T., 1993, Computer Graphics Proceedings, P343, DOI 10.1145/166117.166160
   Park S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356501
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Peng XB, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099567
   Rajamäki J, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099579
   Rajamäki J, 2019, IEEE T VIS COMPUT GR, V25, P2540, DOI 10.1109/TVCG.2018.2849386
   Rajeswaran A., 2017, ICLR
   Safonova A, 2004, ACM T GRAPHIC, V23, P514, DOI 10.1145/1015706.1015754
   Schulman J., 2017, ARXIV170706347, DOI 10.1007/s00038-010-0125-8
   Sok KW, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276511, 10.1145/1239451.1239558]
   Such FP., 2017, ARXIV PREPRINT ARXIV
   Tassa Y., 2018, abs/1801.00690
   Tassa Y, 2012, IEEE INT C INT ROBOT, P4906, DOI 10.1109/IROS.2012.6386025
   Todorov E, 2008, IEEE DECIS CONTR P, P4286, DOI 10.1109/CDC.2008.4739438
   Todorov E, 2009, P NATL ACAD SCI USA, V106, P11478, DOI 10.1073/pnas.0710743106
   Wampler K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531366
   Witkin A., 1988, Computer Graphics, V22, P159, DOI 10.1145/378456.378507
   Yu WH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201397
NR 50
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1648
EP 1660
DI 10.1109/TVCG.2020.3018187
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200015
PM 32816675
OA Green Published, Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Morais, L
   Jansen, Y
   Andrade, N
   Dragicevic, P
AF Morais, Luiz
   Jansen, Yvonne
   Andrade, Nazareno
   Dragicevic, Pierre
TI Showing Data About People: A Design Space of Anthropographics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Tools; Psychology; Urban areas;
   Indexes; Anthropographics; design space; empathy; compassion; prosocial
   behavior
ID VISUALIZATION; EMPATHY; COMPASSION
AB When showing data about people, visualization designers and data journalists often use design strategies that presumably help the audience relate to those people. The term anthropographics has been recently coined to refer to this practice and the resulting visualizations. Anthropographics is a rich and growing area, but the work so far has remained scattered. Despite preliminary empirical work and a few web essays written by practitioners, there is a lack of clear language for thinking about and communicating about anthropographics. We address this gap by introducing a conceptual framework and a design space for anthropographics. Our design space consists of seven elementary design dimensions that can be reasonably hypothesized to have some effect on prosocial feelings or behavior. It extends a previous design space and is informed by an analysis of 105 visualizations collected from newspapers, websites, and research articles. We use our conceptual framework and design space to discuss trade-offs, common design strategies, as well as future opportunities for design and research in the area of anthropographics.
C1 [Morais, Luiz; Andrade, Nazareno] Univ Fed Campina Grande, BR-58428830 Campina Grande, Paraiba, Brazil.
   [Morais, Luiz; Dragicevic, Pierre] Univ Paris Saclay, CNRS, INRIA, LRI, F-91405 Orsay, France.
   [Jansen, Yvonne] Sorbonne Univ, CNRS, ISIR, F-75005 Paris, France.
C3 Universidade Federal de Campina Grande; Universite Paris Cite; Centre
   National de la Recherche Scientifique (CNRS); Universite Paris Saclay;
   Microsoft; Inria; Centre National de la Recherche Scientifique (CNRS);
   Sorbonne Universite
RP Morais, L (corresponding author), Univ Fed Campina Grande, BR-58428830 Campina Grande, Paraiba, Brazil.
EM luiz.morais@inria.fr; yvonne.jansen@sorbonne-universite.fr;
   nazareno@computacao.ufcg.edu.br; pierre.dragicevic@inria.fr
RI Dragicevic, Pierre/HKV-4981-2023; Jansen, Yvonne/A-9998-2015
OI Jansen, Yvonne/0000-0001-5092-551X; Morais, Luiz
   Augusto/0000-0002-5506-9473
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq);
   Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)
   [88881.188888/2018-01]; Agence Nationale de la Recherche (ANR)
   [ANR-19-CE33-0012]; Agence Nationale de la Recherche (ANR)
   [ANR-19-CE33-0012] Funding Source: Agence Nationale de la Recherche
   (ANR)
FX The authors would like to thank the reviewers for their insightful
   suggestions. The first author gratefully acknowledges the financial
   support of the Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq) and the Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES), Grant No. 88881.188888/2018-01. This work was
   supported in part by the Agence Nationale de la Recherche (ANR), Grant
   No. ANR-19-CE33-0012.
CR Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2017, EMPATHY CASE RATIONA
   [Anonymous], 1973, Semiologie graphique. Les diagrammes, les reseaux
   [Anonymous], 2016, Tech. rep. MSR-TR-2016-14
   [Anonymous], 2017, INT ENCY GEOGRAPHY, DOI DOI 10.1002/9781118786352.WBIEG0761
   Bach B., 2018, DataDriven Storytelling, P107, DOI DOI 10.1201/9781315281575-5/NARRATIVEDESIGN-PATTERNS-DATA-DRIVEN-STORYTELLING-BENJAMIN-BACH-MORITZ-STEFANER-JEREMYBOY-STEVEN-DRUCKER-LYN-BARTRAM-JO-WOOD-PAOLO-CIUCCARELLI-YURI-ENGELHARDTULRIKE-KC3%B6PPEN-BARBARA
   Bach B., 2014, EuroVis-STARs, DOI [10.2312/eurovisstar.20141171, DOI 10.2312/EUROVISSTAR.20141171, 10.2312/EUROVISSTAR.20141171]
   Bach B, 2013, P IEEE C VIS
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Beaudouin-Lafon M., 2004, P WORK C ADV VIS INT, P15, DOI [DOI 10.1145/989863.989865, 10.1145/989863.989865]
   Bertini E., CAN VISUALIZATION EL
   Bloom P, 2017, TRENDS COGN SCI, V21, P24, DOI 10.1016/j.tics.2016.11.004
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bronshtein T., 2017, 200 YEARS IMMIGRATIO
   Calvert J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P868, DOI [10.1109/VR.2019.8797864, 10.1109/vr.2019.8797864]
   Campbell S., 2018, THESIS NE U BOSTON
   COHEN J, 1994, AM PSYCHOL, V49, P997, DOI 10.1037/0003-066X.50.12.1103
   Concannon S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376462
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Morais LAD, 2019, IEEE PAC VIS SYMP, P92, DOI 10.1109/PacificVis.2019.00019
   DeSteno D, 2015, CURR OPIN BEHAV SCI, V3, P80, DOI 10.1016/j.cobeha.2015.02.002
   DIgnazio C, 2020, STRONG IDEAS SERIES, P1
   Dork Marian., 2013, PROC ACM CHI EXTENDE, P2189, DOI 10.1145/2468356.2468739
   Dos Santos S. R., 2004, THESIS U LEEDS LEEDS
   Drucker S., 2015, Tech. Rep. MSR-TR-2015-65
   Erlandsson A, 2018, J APPL SOC PSYCHOL, V48, P618, DOI 10.1111/jasp.12552
   Few Stephen, 2011, Visual Business Intelligence Newsletter, P1
   Fragapane F., STORIES LINE
   Genevsky A, 2013, J NEUROSCI, V 33, P17188, DOI 10.1523/JNEUROSCI.2348-13.2013
   Goetz JL, 2010, PSYCHOL BULL, V136, P351, DOI 10.1037/a0018807
   Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847
   Gray CM, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174108
   Gun Violence Archive, 2019, GUN VIOL CHART DEATH
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harris J., 2015, CONNECTING DOTS
   Haug H., 100 MONTREAL
   Huang DD, 2015, IEEE T VIS COMPUT GR, V21, P420, DOI 10.1109/TVCG.2014.2359887
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Ivanov A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188544
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jordan MR, 2016, EMOTION, V16, P1107, DOI 10.1037/emo0000228
   Kandaurova M, 2019, J BUS RES, V100, P571, DOI 10.1016/j.jbusres.2018.10.027
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kirk Chris., How Many People Have Been Killed by Guns Since Newtown?
   Kogut T, 2005, J BEHAV DECIS MAKING, V18, P157, DOI 10.1002/bdm.492
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Le Goc M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/2984511.2984547
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee S, 2016, SOC INFLUENCE, V11, P199, DOI 10.1080/15534510.2016.1216891
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Lupi G., 2014, FAMOUS WRITERS SLEEP
   Lupi G, Data Humanism, The Revolution will be Visualized
   Lupi Giorgia., BRUISES DATA WE DONT
   Macaskill W., 2015, DOING GOOD BETTER
   Microsoft, SANDD
   Morais L., SMALL DATA CANC MAMA
   Morais L., 2020, EVALUATING SITUATED, DOI [10.13140/RG.2.2.10719.69283, DOI 10.13140/RG.2.2.10719.69283]
   Munzner T., 2014, AK Peters Visualization Series
   NEURATH M, 1974, INSTR SCI, V3, P127, DOI 10.1007/BF00053495
   Neurath O, 1936, INT PICTURE LANGUAGE
   Newman GE, 2014, P NATL ACAD SCI USA, V111, P3705, DOI 10.1073/pnas.1313637111
   Offenhuber D, 2020, IEEE T VIS COMPUT GR, V26, P98, DOI 10.1109/TVCG.2019.2934788
   Offenhuber Dietmar., 2015, Indexical Visualization-the Data-Less Information Display, P288, DOI DOI 10.4324/9781315781129-31
   Onuoha M, MISSING DATA SETS
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Perin C, 2017, P IEEE VIS EL C
   Perin C, 2018, P IEEE VIS EL C
   Periscopic, US GUN DEATHS 2010 2
   Rawles T., PICTURE 1993 REMINDS
   Regan Tom., 1989, ANIMAL RIGHTS HUMAN
   Riek L. D., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P245
   Rosenberg J., KNOWN UNKNOWN
   Rost L. C., DATA POINT MOVES BAR
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Senay H., 1990, Rules and principles of scientific data visualization
   Stefaner M., EMOTO VISUALIZING ON
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   Thudt Alice, 2017, Information Design Journal, V23, P48, DOI 10.1075/idj.23.1.07thu
   Tomasik B., 2015, Relations: Beyond Anthropocentrism, V3, P133, DOI DOI 10.7358/RELA-2015-002-TOMA
   Västfjäll D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100115
   Wilhelm MO, 2010, SOC PSYCHOL QUART, V73, P11, DOI 10.1177/0190272510361435
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Worrell L. A., GREAT WAR
NR 91
TC 20
Z9 21
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1661
EP 1679
DI 10.1109/TVCG.2020.3023013
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA YP1EJ
UT WOS:000748371200016
PM 32903184
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Khan, D
   Plopski, A
   Fujimoto, Y
   Kanbara, M
   Jabeen, G
   Zhang, YJ
   Zhang, XP
   Kato, H
AF Khan, Dawar
   Plopski, Alexander
   Fujimoto, Yuichiro
   Kanbara, Masayuki
   Jabeen, Gul
   Zhang, Yongjie Jessica
   Zhang, Xiaopeng
   Kato, Hirokazu
TI Surface Remeshing: A Systematic Literature Review of Methods and
   Research Directions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Systematics; Data mining; Quality assessment; Libraries; Search
   problems; Three-dimensional displays; Solid modeling; Mesh generation;
   surface remeshing; meshing quality; finite element method; systematic
   literature review
ID CENTROIDAL VORONOI TESSELLATIONS; TETRAHEDRAL MESH GENERATION; QUALITY;
   TRIANGULATION; COMPUTATION; EFFICIENT; APPROXIMATION; OBTUSE; ERROR; CVT
AB Triangle meshes are used in many important shape-related applications including geometric modeling, animation production, system simulation, and visualization. However, these meshes are typically generated in raw form with several defects and poor-quality elements, obstructing them from practical application. Over the past decades, different surface remeshing techniques have been presented to improve these poor-quality meshes prior to the downstream utilization. A typical surface remeshing algorithm converts an input mesh into a higher quality mesh with consideration of given quality requirements as well as an acceptable approximation to the input mesh. In recent years, surface remeshing has gained significant attention from researchers and engineers, and several remeshing algorithms have been proposed. However, there has been no survey article on remeshing methods in general with a defined search strategy and article selection mechanism covering the recent approaches in surface remeshing domain with a good connection to classical approaches. In this article, we present a survey on surface remeshing techniques, classifying all collected articles in different categories and analyzing specific methods with their advantages, disadvantages, and possible future improvements. Following the systematic literature review methodology, we define step-by-step guidelines throughout the review process, including search strategy, literature inclusion/exclusion criteria, article quality assessment, and data extraction. With the aim of literature collection and classification based on data extraction, we summarized collected articles, considering the key remeshing objectives, the way the mesh quality is defined and improved, and the way their techniques are compared with other previous methods. Remeshing objectives are described by angle range control, feature preservation, error control, valence optimization, and remeshing compatibility. The metrics used in the literature for the evaluation of surface remeshing algorithms are discussed. Meshing techniques are compared with other related methods via a comprehensive table with indices of the method name, the remeshing challenge met and solved, the category the method belongs to, and the year of publication. We expect this survey to be a practical reference for surface remeshing in terms of literature classification, method analysis, and future prospects.
C1 [Khan, Dawar; Plopski, Alexander; Fujimoto, Yuichiro; Kanbara, Masayuki; Kato, Hirokazu] Nara Inst Sci & Technol, IMD Lab, Informat Sci, Nara 6300192, Japan.
   [Jabeen, Gul] Tsinghua Univ, Sch Software Engn, Beijing, Peoples R China.
   [Jabeen, Gul] Karakuram Int Univ, Dept Comp Sci, Gilgit 15100, Pakistan.
   [Zhang, Yongjie Jessica] Carnegie Mellon Univ CMU, Dept Mech Engn, Pittsburgh, PA 15213 USA.
   [Zhang, Xiaopeng] Chinese Acad Sci, NLPR, Inst Automat, Beijing 100190, Peoples R China.
C3 Nara Institute of Science & Technology; Tsinghua University; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Khan, D (corresponding author), Nara Inst Sci & Technol, IMD Lab, Informat Sci, Nara 6300192, Japan.
EM dawar@is.naist.jp; plopski@is.naist.jp; yfujimoto@is.naist.jp;
   kanbara@is.naist.jp; jgl14@mails.tsinghua.edu.cn;
   jessicaz@andrew.cmu.edu; xiaopeng.zhang@ia.ac.cn; kato@is.naist.jp
RI Khan, Dawar/Q-7730-2019; Kanbara, Masayuki/ABD-7780-2021; Fujimoto,
   Yuichiro/HTS-3801-2023; Zhang, Yongjie Jessica/F-8733-2012
OI Fujimoto, Yuichiro/0000-0002-8270-2609; ZHANG,
   Xiaopeng/0000-0002-0092-6474; Zhang, Yongjie
   Jessica/0000-0001-7436-9757; Kato, Hirokazu/0000-0003-3921-2871;
   Plopski, Alexander/0000-0003-1354-0279; Khan, Dawar/0000-0001-5864-1888
FU Japan Society for the Promotion of Science (JSPS) KAKENHI [19K24346]; US
   NSF [CMMI-1953323, CBET-1804929]; National Natural Science Foundation of
   China (NSFC) [61620106003, 61972459]; Grants-in-Aid for Scientific
   Research [19K24346] Funding Source: KAKEN
FX This work was partially supported by the Japan Society for the Promotion
   of Science (JSPS) KAKENHI Grant number 19K24346. Y. J. Zhang was
   supported in part by US NSF Grants CMMI-1953323 and CBET-1804929. X.
   Zhang was supported in part by the National Natural Science Foundation
   of China (NSFC) with Grants 61620106003 and 61972459. The authors are
   thankful to the anonymous reviewers for their valuable comments.
CR Abdelkader A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3337680
   Abdelkader A, 2017, COMPUT GRAPH FORUM, V36, P189, DOI 10.1111/cgf.13256
   Aghdaii N, 2012, COMPUT GRAPH-UK, V36, P1072, DOI 10.1016/j.cag.2012.09.005
   Ahmed AGM, 2017, IEEE T VIS COMPUT GR, V23, P2496, DOI 10.1109/TVCG.2016.2641963
   Al Lily AE, 2017, INFORM DEV, V33, P270, DOI 10.1177/0266666916646415
   Alliez P, 2005, GRAPH MODELS, V67, P204, DOI 10.1016/j.gmod.2004.06.007
   Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   Alliez P, 2002, ACM T GRAPHIC, V21, P347, DOI 10.1145/566570.566588
   Alliez P, 2008, MATH VIS, P53, DOI 10.1007/978-3-540-33265-7_2
   Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   [Anonymous], 2013, P 21 INT MESH ROUNDT, DOI DOI 10.1007/978-3-642-33573-021
   [Anonymous], 2015, P 21 ACM S VIRT REAL, DOI DOI 10.1145/2821592.2821594
   [Anonymous], 1996, International Meshing Roundtable
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Attene M, 2003, GRAPH MODELS, V65, P260, DOI 10.1016/S1524-0703(03)00048-1
   BABUSKA I, 1976, SIAM J NUMER ANAL, V13, P214, DOI 10.1137/0713021
   BAKER BS, 1988, DISCRETE COMPUT GEOM, V3, P147, DOI 10.1007/BF02187904
   Barton M, 2010, COMPUT AIDED GEOM D, V27, P580, DOI 10.1016/j.cagd.2010.04.004
   Beall M. W., 2003, 12 INT MESH ROUNDT S, P2003
   Boissonnat JD, 2001, COMP GEOM-THEOR APPL, V19, P155, DOI 10.1016/S0925-7721(01)00018-9
   Boissonnat JD, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2721895
   Boissonnat JD, 2010, DISCRETE COMPUT GEOM, V44, P281, DOI 10.1007/s00454-010-9256-1
   Boissonnat JD, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P270, DOI 10.1145/1377676.1377724
   Boltcheva D, 2009, COMPUT GRAPH FORUM, V28, P1455, DOI 10.1111/j.1467-8659.2009.01522.x
   Borah S, 2016, 2016 INTERNATIONAL CONFERENCE ON ACCESSIBILITY TO DIGITAL WORLD (ICADW), P57, DOI 10.1109/ICADW.2016.7942513
   Botsch Mario, 2004, P 2004 EUR ACM SIGGR, P185, DOI DOI 10.1145/1057432.1057457
   Boubekeur T, 2008, COMPUT GRAPH FORUM, V27, P102, DOI 10.1111/j.1467-8659.2007.01040.x
   Budninskiy M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980245
   Cai YQ, 2017, IEEE T VIS COMPUT GR, V23, P2613, DOI 10.1109/TVCG.2016.2623779
   Cañas GD, 2006, VISUAL COMPUT, V22, P885, DOI 10.1007/s00371-006-0073-8
   Chen L, 2004, J COMPUT MATH, V22, P299
   Chen L., 2004, P 13 INT MESH ROUNDT, P109
   Chen LG, 2007, LECT NOTES COMPUT SC, V4487, P318
   Chen L, 2011, COMPUT METHOD APPL M, V200, P967, DOI 10.1016/j.cma.2010.11.007
   Chen ZG, 2018, COMPUT AIDED DESIGN, V102, P12, DOI 10.1016/j.cad.2018.04.010
   Chen ZG, 2012, COMPUT GRAPH FORUM, V31, P2077, DOI 10.1111/j.1467-8659.2012.03200.x
   Cheng S-W., 2012, DELAUNAY MESH GENERA
   Cheng SW, 2007, SIAM J COMPUT, V37, P1199, DOI 10.1137/060665889
   Cheng XX, 2019, COMPUT GRAPH-UK, V82, P163, DOI 10.1016/j.cag.2019.05.019
   Chiang CH, 2011, VISUAL COMPUT, V27, P811, DOI 10.1007/s00371-011-0555-1
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cignoni P., 2008, 6 EUR IT CHAPT C 200, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALCHAPCONF/129-138, 10.2312/LocalChapterEvents/ItalChap, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/ 129-136, DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136]
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   D'Amato JP, 2013, J PARALLEL DISTR COM, V73, P1127, DOI 10.1016/j.jpdc.2013.03.007
   Dassi F, 2016, PROCEDIA ENGINEER, V163, P72, DOI 10.1016/j.proeng.2016.11.022
   Dassi F, 2014, PROCEDIA ENGINEER, V82, P253, DOI 10.1016/j.proeng.2014.10.388
   de Araújo BR, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2732197
   de Goes F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602143
   de Goes F, 2011, COMPUT GRAPH-UK, V35, P112, DOI 10.1016/j.cag.2010.11.012
   DELAUNAY B. N., 1934, Bull. Acad. Sci. URSS, V1934, P793
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y
   Dietrich CA, 2009, IEEE T VIS COMPUT GR, V15, P150, DOI 10.1109/TVCG.2008.60
   Du Q, 2005, SIAM J SCI COMPUT, V26, P737, DOI 10.1137/S1064827503428527
   Du Q, 2003, SIAM J SCI COMPUT, V24, P1488, DOI 10.1137/S1064827501391576
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Du XY, 2018, COMPUT GRAPH FORUM, V37, P343, DOI 10.1111/cgf.13329
   Dunbar D, 2006, ACM T GRAPHIC, V25, P503, DOI 10.1145/1141911.1141915
   Dunyach M., 2013, EUROGRAPHICS, P29
   Dyer R., 2007, SGP 07, P273
   Ebeida MS, 2012, COMPUT GRAPH FORUM, V31, P785, DOI 10.1111/j.1467-8659.2012.03059.x
   EDELSBRUNNER H, 2001, P 17 ACM S COMP GEOM, P115
   Edwards J., 2012, P 21 INT MESH ROUNDT, P403, DOI [10.1007/978-3-642-33573-0_24, DOI 10.1007/978-3-642-33573-0_24]
   Erten H, 2009, 2009 6TH INTERNATIONAL SYMPOSIUM ON VORONOI DIAGRAMS (ISVD 2009), P192, DOI 10.1109/ISVD.2009.32
   Fang QQ, 2009, I S BIOMED IMAGING, P1142, DOI 10.1109/ISBI.2009.5193259
   Fang XZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201354
   Feng LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201358
   FIELD DA, 1988, COMMUN APPL NUMER M, V4, P709, DOI 10.1002/cnm.1630040603
   Floater MS, 1997, COMPUT AIDED GEOM D, V14, P231, DOI 10.1016/S0167-8396(96)00031-3
   Frey P. J., 1998, Computing and Visualization in Science, V1, P113, DOI 10.1007/s007910050011
   Frey P.J., 1997, 6th International Meshing Roundtable, P363
   Frey P. J., 2013, MESH GENERATION APPL
   Fu XM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661235
   Fu Y, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P115
   Fuhrmann S., 2010, VMV, P9, DOI DOI 10.2312/PE/VMV/VMV10/009-016
   Gao XF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073676
   Gao ZH, 2013, GRAPH MODELS, V75, P23, DOI 10.1016/j.gmod.2012.10.007
   Gargallo-Peiró A, 2018, J COMPUT PHYS, V375, P209, DOI 10.1016/j.jcp.2018.08.031
   Garland M., 1997, P 24 ANN C COMP GRAP, P209, DOI DOI 10.1145/258734.258849
   George J. A., 1971, THESIS STANDFORD U
   Gu XD, 2018, J DIFFER GEOM, V109, P223, DOI 10.4310/jdg/1527040872
   Gui S, 2018, VIS COMPUT IND BIOME, V1, DOI 10.1186/s42492-018-0007-0
   Guo JW, 2019, COMPUT AIDED DESIGN, V109, P49, DOI 10.1016/j.cad.2018.12.005
   Guo JW, 2015, COMPUT GRAPH-UK, V46, P72, DOI 10.1016/j.cag.2014.09.015
   Guthe M., 2005, Journal of WSCG, V13, P41
   Gutiérrez LF, 2012, COMPUT ANIMAT VIRT W, V23, P425, DOI 10.1002/cav.1462
   Har-Peled Sariel., 2005, P 21 ACM S COMPUTATI, P228
   Hartmann E, 1998, VISUAL COMPUT, V14, P95, DOI 10.1007/s003710050126
   Heckbert P., 1997, SIGGRAPH 97 COURS NO, P1
   Heckbert PS, 1999, COMP GEOM-THEOR APPL, V14, P49, DOI 10.1016/S0925-7721(99)00030-9
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Hormann K., 2000, Proceedings of Vision, Modeling and Vizualization, 2000, P153
   Hu KM, 2017, IEEE T VIS COMPUT GR, V23, P2560, DOI 10.1109/TVCG.2016.2632720
   Hu KK, 2018, COMP M BIO BIO E-IV, V6, P331, DOI 10.1080/21681163.2016.1244017
   Hu KK, 2016, COMPUT METHOD APPL M, V305, P405, DOI 10.1016/j.cma.2016.03.021
   Huang J, 2011, SCI CHINA INFORM SCI, V54, P1172, DOI 10.1007/s11432-011-4261-4
   Hudson B, 2007, SPAA'07: PROCEEDINGS OF THE NINETEENTH ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P339
   Hudson B, 2006, PROCEEDINGS OF THE 15TH INTERNATIONAL MESHING ROUNDTABLE, P339, DOI 10.1007/978-3-540-34958-7_20
   Hussain M, 2003, 2003 INTERNATIONAL CONFERENCE ON GEOMETRIC MODELING AND GRAPHICS, PROCEEDINGS, P137, DOI 10.1109/GMAG.2003.1219678
   Hussain M, 2009, J COMPUT SCI TECH-CH, V24, P604, DOI 10.1007/s11390-009-9249-9
   Hussain M, 2008, LECT NOTES COMPUT SC, V5358, P119, DOI 10.1007/978-3-540-89639-5_12
   Igarashi T., 2003, PROC ACM S INTERACTI, P139
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Khan Dawar, 2018, Computational Visual Media, V4, P113, DOI 10.1007/s41095-018-0107-y
   Khan D, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19051383
   Khan DW, 2018, COMPUT MATH APPL, V75, P582, DOI 10.1016/j.camwa.2017.09.041
   Kitchenham B., 2007, Technical Report EBSE-2007-01, DOI DOI 10.1145/1134285.1134500
   Kobbelt L, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P43
   Kobbelt LP, 2001, COMP GRAPH, P57, DOI 10.1145/383259.383265
   Kobbelt LP, 1999, COMPUT GRAPH FORUM, V18, pC119, DOI 10.1111/1467-8659.00333
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Krishnamoorthy B, 2003, BIOINFORMATICS, V19, P1540, DOI 10.1093/bioinformatics/btg186
   Labelle F., 2003, P 19 ANN S COMP GEOM, P191, DOI DOI 10.1145/777792.777822
   Labelle F, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239508
   Lai YK, 2010, IEEE T VIS COMPUT GR, V16, P95, DOI 10.1109/TVCG.2009.59
   Lee A, 2000, COMP GRAPH, P85, DOI 10.1145/344779.344829
   Leng J., 2013, QUALITY IMPROVEMENT, P195, DOI [10.1007/978-94-007-4255-0_11, DOI 10.1007/978-94-007-4255-0_11]
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Li YY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866179
   Liang XH, 2014, ENG COMPUT-GERMANY, V30, P211, DOI 10.1007/s00366-013-0328-8
   Liang XH, 2012, ENG COMPUT-GERMANY, V28, P375, DOI 10.1007/s00366-011-0221-2
   Liang XH, 2011, COMPUT METHOD APPL M, V200, P2005, DOI 10.1016/j.cma.2011.03.002
   Liang XH, 2009, PROCEEDINGS OF THE 18TH INTERNATIONAL MESHING ROUNDTABLE, P45, DOI 10.1007/978-3-642-04319-2_4
   Liao Tao, 2013, Mol Based Math Biol, V1, DOI 10.2478/mlbmb-2013-0009
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Liu LG, 2007, COMPUT AIDED DESIGN, V39, P772, DOI 10.1016/j.cad.2007.03.004
   Liu SJ, 2005, INT C COMP AID DES C, P133
   Liu TT, 2018, SIAM J SCI COMPUT, V40, pB507, DOI 10.1137/16M1099704
   Liu TT, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184206
   Liu Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559758
   Liu YJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2999532
   Liu YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982424
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   Liu ZG, 2018, COMPUT GRAPH-UK, V76, P60, DOI 10.1016/j.cag.2018.07.002
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lo SH, 2013, COMPUT STRUCT, V123, P15, DOI 10.1016/j.compstruc.2013.04.004
   Lohner R, 1996, ENG COMPUT, V12, P186, DOI 10.1007/BF01198734
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Lu L, 2012, IEEE T VIS COMPUT GR, V18, P1880, DOI 10.1109/TVCG.2012.28
   Ma M, 2017, PROCEDIA ENGINEER, V203, P297, DOI 10.1016/j.proeng.2017.09.811
   Ma XG, 2012, WOR CONG SOFTW ENG, P136, DOI 10.1109/WCSE.2012.32
   Mansouri S, 2016, J VISUAL-JAPAN, V19, P141, DOI 10.1007/s12650-015-0288-8
   Marchandise E, 2011, INT J NUMER METH ENG, V86, P1303, DOI 10.1002/nme.3099
   Marchandise E, 2014, ENG COMPUT-GERMANY, V30, P383, DOI 10.1007/s00366-012-0309-3
   Marton ZC, 2009, IEEE INT CONF ROBOT, P2829
   Medeiros E, 2018, IEEE T VIS COMPUT GR, V24, P1983, DOI 10.1109/TVCG.2017.2704078
   Men Y., 2018, P SIGGRAPH POST 2018
   Methirumangalath S, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149447
   NASH J, 1954, ANN MATH, V60, P383, DOI 10.2307/1969840
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276429, 10.1145/1239451.1239492]
   Ng KW, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, IMAGING AND VISUALIZATION (CGIV): NEW TECHNIQUES AND TRENDS, P11, DOI 10.1109/CGiV.2014.9
   Nguyen H, 2009, COMP GEOM-THEOR APPL, V42, P1, DOI 10.1016/j.comgeo.2008.04.002
   Ni SF, 2018, COMPUT GRAPH FORUM, V37, P161, DOI 10.1111/cgf.13499
   Nieser M, 2012, IEEE T VIS COMPUT GR, V18, P865, DOI 10.1109/TVCG.2011.118
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Nunes Cassia R. S., 2010, 2010 14th Biennial IEEE Conference on Electromagnetic Field Computation (CEFC 2010), DOI 10.1109/CEFC.2010.5481516
   Nunes CRS, 2011, IEEE T MAGN, V47, P1202, DOI 10.1109/TMAG.2010.2090944
   Owen SJ, 1998, IMR, V239, P15
   Ozaki H., 2015, P EGPGV EUROVIS CAG, P87
   Payan F, 2015, COMPUT GRAPH FORUM, V34, P86, DOI 10.1111/cgf.12461
   Peyré G, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P995, DOI 10.1109/TDPVT.2004.1335424
   Peyré G, 2006, INT J COMPUT VISION, V69, P145, DOI 10.1007/s11263-006-6859-3
   Qian J, 2009, PROCEEDINGS OF THE 18TH INTERNATIONAL MESHING ROUNDTABLE, P211, DOI 10.1007/978-3-642-04319-2_13
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Rong G., 2010, Proceedings of Symposium of Solid and Physical Modeling (SPM 2010), P117
   Rong GD, 2011, COMPUT AIDED GEOM D, V28, P475, DOI 10.1016/j.cagd.2011.06.005
   Rong GD, 2011, IEEE T VIS COMPUT GR, V17, P345, DOI 10.1109/TVCG.2010.53
   Ruiz-Gironés E, 2016, PROCEDIA ENGINEER, V163, P315, DOI 10.1016/j.proeng.2016.11.108
   Ruppert J., 1992, UCBCSD92694
   Sander P. V., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P87
   Schlomer T., 2011, P ACM SIGGRAPH S HIG, P135, DOI DOI 10.1145/2018323.2018345
   Schreiner J, 2006, IEEE T VIS COMPUT GR, V12, P1205, DOI 10.1109/TVCG.2006.149
   Schreiner J, 2006, COMPUT GRAPH FORUM, V25, P527, DOI 10.1111/j.1467-8659.2006.00972.x
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Sheffer A, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000011
   Shewchuk J. R., 1996, LECT NOTES COMPUTER, P203, DOI [10.1007/BFb0014497, DOI 10.1007/BFB0014497]
   Shewchuk JR, 1997, THESIS CARNEGIE MELL
   Shimada Kenji., 1996, 6 INT MESHING ROUNDT, P375
   Shuai L, 2013, COMPUT AIDED DESIGN, V45, P463, DOI 10.1016/j.cad.2012.10.029
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Sieger D., 2010, Proceedings of the 19th international meshing roundtable, P335
   Sifri O., 2003, IMR, P189
   SIMPSON RB, 1994, APPL NUMER MATH, V14, P183, DOI 10.1016/0168-9274(94)90025-6
   Singh N, 2019, J COMPUT DES ENG, V6, P316, DOI 10.1016/j.jcde.2018.12.001
   Sloan IH, 2000, J APPROX THEORY, V103, P91, DOI 10.1006/jath.1999.3426
   Smit M. S., 2011, THESIS DELFT U TECHN
   Sorkine O., 2004, P S GEOM PROC, P175, DOI [DOI 10.1145/1057432.1057456, 10.]
   Sorkine O, 2006, COMPUT GRAPH FORUM, V25, P789, DOI 10.1111/j.1467-8659.2006.00999.x
   Su KH, 2019, COMPUT AIDED DESIGN, V111, P1, DOI 10.1016/j.cad.2019.01.004
   Sun F, 2011, COMPUT AIDED GEOM D, V28, P537, DOI 10.1016/j.cagd.2011.09.007
   Surazhsky V., 2003, Symposium on Geometry Processing, P20
   Surazhsky V, 2004, ENG COMPUT-GERMANY, V20, P147, DOI 10.1007/s00366-004-0282-6
   SURAZHSKY V., 2003, P 12 INT MESHING ROU, P215
   Taubin G., 1995, P 22 ANN C COMP GRAP, P351, DOI [10.1145/218380.218473, DOI 10.1145/218380.218473]
   Tristano J. R., 1998, P 7 INT MESH ROUNDT, P429
   Üngör A, 2009, COMP GEOM-THEOR APPL, V42, P109, DOI 10.1016/j.comgeo.2008.06.002
   Valette S, 2004, COMPUT GRAPH FORUM, V23, P381, DOI 10.1111/j.1467-8659.2004.00769.x
   Valette S, 2008, IEEE T VIS COMPUT GR, V14, P369, DOI 10.1109/TVCG.2007.70430
   Vollmer J, 1999, COMPUT GRAPH FORUM, V18, pC131, DOI 10.1111/1467-8659.00334
   Vorsatz J., 2003, Proceedings of the Eighth ACM Symposium on Solid Modeling and Applications, P167, DOI DOI 10.1145/781606.781633
   Wang J, 2012, COMPUT AIDED DESIGN, V44, P597, DOI 10.1016/j.cad.2012.03.001
   Wang L, 2016, COMPUT GRAPH FORUM, V35, P152, DOI 10.1111/cgf.12716
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang XN, 2015, COMPUT AIDED DESIGN, V58, P51, DOI 10.1016/j.cad.2014.08.023
   Wang YQ, 2019, IEEE T VIS COMPUT GR, V25, P2430, DOI 10.1109/TVCG.2018.2837115
   Wang YF, 2017, AEBMR ADV ECON, V48, P81
   Wang Y, 2012, COMPUT MATH APPL, V64, P2663, DOI 10.1016/j.camwa.2012.07.011
   Wei J, 2010, J COMPUT SCI TECH-CH, V25, P595, DOI 10.1007/s11390-010-9348-7
   Wohlin C., 2014, P 18 INT C EV ASS SO, P1, DOI [10.1145/2601248.2601268, 10.1145/2601248]
   Xiao L, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9245437
   Xing LP, 2014, IEEE COMPUT GRAPH, V34, P52, DOI 10.1109/MCG.2013.84
   Xu QC, 2019, COMPUT GRAPH FORUM, V38, P755, DOI 10.1111/cgf.13877
   Yan DM, 2016, IEEE T VIS COMPUT GR, V22, P2136, DOI 10.1109/TVCG.2015.2505279
   Yan DM, 2014, IEEE T VIS COMPUT GR, V20, P1579, DOI 10.1109/TVCG.2014.2322357
   Yan DM, 2014, IEEE T VIS COMPUT GR, V20, P1418, DOI 10.1109/TVCG.2014.2330574
   Yan DM, 2014, COMPUT GRAPH FORUM, V33, P167, DOI 10.1111/cgf.12442
   Yan DM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516973
   Yan DM, 2009, COMPUT GRAPH FORUM, V28, P1445, DOI 10.1111/j.1467-8659.2009.01521.x
   Yi R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275068
   You YH, 2015, COMPUT AIDED DESIGN, V62, P176, DOI 10.1016/j.cad.2014.11.011
   Yue W, 2007, P 2007 ACM S SOL PHY, P23
   Zangeneh R, 2018, COMP GEOM-THEOR APPL, V70-71, P31, DOI 10.1016/j.comgeo.2018.01.006
   Zhang X, 2017, NAT COMMUN, V8, P1, DOI [10.1038/ncomms15280, 10.1038/ncomms14542]
   Zhang Y., 2003, P 8 ACM S SOL MOD AP, P286
   Zhang Y. J., 2010, GEOMETRIC MODELING M
   Zhang YMZ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.83
   Zhang YJ, 2005, COMPUT METHOD APPL M, V194, P5083, DOI 10.1016/j.cma.2004.11.026
   Zhang YJ, 2006, COMPUT AIDED GEOM D, V23, P510, DOI 10.1016/j.cagd.2006.01.008
   Zhong ZC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201369
   Zhong ZC, 2014, GRAPH MODELS, V76, P468, DOI 10.1016/j.gmod.2014.03.011
   Zhong ZC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461946
   Zhou Kun, 2004, P 2004 EUROGRAPHICSA, P45, DOI [DOI 10.1145/1057432.1057439, 10.1145/1057432.1057439]
   Zhou Q., 2011, PRIVILEGED CHIRAL LI, P214
   Zhuang YX, 2014, COMPUT GRAPH FORUM, V33, P111, DOI 10.1111/cgf.12479
NR 238
TC 32
Z9 36
U1 6
U2 52
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2022
VL 28
IS 3
BP 1680
EP 1713
DI 10.1109/TVCG.2020.3016645
PG 34
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YP1EJ
UT WOS:000748371200017
PM 32795969
OA Green Published, Bronze
DA 2024-11-06
ER

PT J
AU Mueller, K
AF Mueller, Klaus
TI Editorial
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
OI Mueller, Klaus/0000-0002-0996-8590
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1714
EP 1714
DI 10.1109/TVCG.2022.3149021
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900001
OA Bronze
DA 2024-11-06
ER

PT J
AU Zhuang, MD
   Concannon, D
   Manley, E
AF Zhuang, Mengdie
   Concannon, David
   Manley, Ed
TI A Framework for Evaluating Dashboards in Healthcare
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Refining; Medical services; Market research; Software;
   Usability; Task analysis; Visualization; dashboard; evaluation;
   healthcare
ID INFORMATION VISUALIZATION; DIABETES DASHBOARD; QUALITY; DESIGN; SYSTEM;
   IMPLEMENTATION; SATISFACTION; TECHNOLOGY; IMPROVE; MODEL
AB In the era of 'information overload', effective information provision is essential for enabling rapid response and critical decision making. In making sense of diverse information sources, dashboards have become an indispensable tool, providing fast, effective, adaptable, and personalized access to information for professionals and the general public alike. However, these objectives place heavy requirements on dashboards as information systems in usability and effective design. Understanding these issues is challenging given the absence of consistent and comprehensive approaches to dashboard evaluation. In this article we systematically review literature on dashboard implementation in healthcare, where dashboards have been employed widely, and where there is widespread interest for improving the current state of the art, and subsequently analyse approaches taken towards evaluation. We draw upon consolidated dashboard literature and our own observations to introduce a general definition of dashboards which is more relevant to current trends, together with seven evaluation scenarios - task performance, behaviour change, interaction workflow, perceived engagement, potential utility, algorithm performance and system implementation. These scenarios distinguish different evaluation purposes which we illustrate through measurements, example studies, and common challenges in evaluation study design. We provide a breakdown of each evaluation scenario, and highlight some of the more subtle questions. We demonstrate the use of the proposed framework by a design study guided by this framework. We conclude by comparing this framework with existing literature, outlining a number of active discussion points and a set of dashboard evaluation best practices for the academic, clinical and software development communities alike.
C1 [Zhuang, Mengdie] Univ Sheffield, Informat Sch, Sheffield S10 2TN, S Yorkshire, England.
   [Zhuang, Mengdie; Concannon, David] UCL, Ctr Adv Spatial Anal, London WC1E 6BT, England.
   [Manley, Ed] Univ Leeds, Sch Geog, Leeds LS2 9JT, W Yorkshire, England.
   [Manley, Ed] Alan Turing Inst Data Sci & Artificial Intelligen, London NW1 2DB, England.
C3 University of Sheffield; University of London; University College
   London; University of Leeds
RP Zhuang, MD (corresponding author), Univ Sheffield, Informat Sch, Sheffield S10 2TN, S Yorkshire, England.
EM m.zhuang@sheffield.ac.uk; david.concannon.14@ucl.ac.uk;
   E.J.Manley@leeds.ac.uk
OI Zhuang, Mengdie/0000-0002-4546-1033; Manley, Ed/0000-0002-8904-0513
FU i-sense EPSRC IRC in Agile Early Warning Sensing Systems for Infectious
   Diseases and Antimicrobial Resistance [EP/R00529X/1.]; EPSRC
   [EP/K031953/1, EP/R00529X/1] Funding Source: UKRI
FX This work was supported by i-sense EPSRC IRC in Agile Early Warning
   Sensing Systems for Infectious Diseases and Antimicrobial Resistance
   under Grant EP/R00529X/1.
CR [Anonymous], 1993, Usability Engineering, Vfirst, P165
   Arora S, 2009, COMPUTATIONAL COMPLEXITY: A MODERN APPROACH, P1, DOI 10.1017/CBO9780511804090
   Azad TD, 2016, J NEUROSURG-SPINE, V24, P176, DOI 10.3171/2015.3.SPINE141127
   BATES MJ, 1989, ONLINE REV, V13, P407, DOI 10.1108/eb024320
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Brooke J., 1995, USABILITY EVAL IND, P189
   Cacioppo JT, 2007, HANDBOOK OF PSYCHOPHYSIOLOGY, 3RD EDITION, P1, DOI 10.2277/ 0521844711
   Calisir F, 2004, COMPUT HUM BEHAV, V20, P505, DOI 10.1016/j.chb.2003.10.004
   Case D O., 2016, Studies in Information, DOI DOI 10.1108/S2055-53772016
   Concannon David, 2019, JMIR Form Res, V3, pe11342, DOI 10.2196/11342
   Cox ZL, 2017, AM HEART J, V183, P40, DOI 10.1016/j.ahj.2016.10.001
   Dagliati A, 2018, J AM MED INFORM ASSN, V25, P538, DOI 10.1093/jamia/ocx159
   Damschroder LJ, 2009, IMPLEMENT SCI, V4, DOI 10.1186/1748-5908-4-50
   Dickson R, 2017, PREHOSPITAL DISASTER, V32, P343, DOI 10.1017/S1049023X17000097
   Dolan JG, 2013, BMC MED INFORM DECIS, V13, DOI 10.1186/1472-6947-13-51
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Dowding D, 2015, INT J MED INFORM, V84, P87, DOI 10.1016/j.ijmedinf.2014.10.001
   Drutsa A, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P27, DOI 10.1145/2684822.2685318
   Dunn S, 2016, IMPLEMENT SCI, V11, DOI 10.1186/s13012-016-0427-1
   Eckerson WW, 2010, Performance Dashboards: Measuring, Monitoring, and Managing Your Business
   El Turabi A, 2011, HEALTH RES POLICY SY, V9, DOI 10.1186/1478-4505-9-13
   Fereday J., 2006, International Journal of Qualitative Research, V5, P80, DOI [DOI 10.1063/1.2011295, https://doi.org/10.1177/160940690600500107, DOI 10.1177/160940690600500107]
   Few S., 2013, Information Dashboard Design: The Effective Visual Communication of Data
   George D, 2017, SCIENCE, V358, DOI 10.1126/science.aag2612
   Greenland S, 2002, INT J EPIDEMIOL, V31, P1030, DOI 10.1093/ije/31.5.1030
   Harris JK, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15050833
   Independent SAGE, 2020, FIN INT FIND TEST TR
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   ISO, 2011, ISO/IEC 25010:2011
   Jackson TW, 2012, INT J INFORM MANAGE, V32, P523, DOI 10.1016/j.ijinfomgt.2012.04.006
   Jeffries M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205419
   Kamienkowski JE, 2012, J VISION, V12, DOI 10.1167/12.7.4
   Karami Mahtab, 2017, Open Med Inform J, V11, P52, DOI 10.2174/1874431101711010052
   Kelly Diane, 2009, Foundations and Trends in Information Retrieval, V3, P1, DOI 10.1561/1500000012
   Koopman RJ, 2011, ANN FAM MED, V9, P398, DOI 10.1370/afm.1286
   Lalmas Mounia, 2014, Synthesis Lectures on Information Concepts, Retrieval, and Services, V6, P1, DOI DOI 10.2200/S00605ED1V01Y201410ICR038
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lehmann M., 2012, P INT C US MOD AD PE, P164
   Lenglet A, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9118
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   Lopatovska I, 2011, INFORM PROCESS MANAG, V47, P575, DOI 10.1016/j.ipm.2010.09.001
   Mahendrawathi E. R., 2010, 2010 IEEE Conference on Open Systems (ICOS 2010), P86, DOI 10.1109/ICOS.2010.5720069
   Martinez William, 2018, JMIR Hum Factors, V5, pe26, DOI 10.2196/humanfactors.9569
   Martinez-Millana A, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16020199
   May C, 2007, BMC HEALTH SERV RES, V7, DOI 10.1186/1472-6963-7-148
   Meijers JMM, 2013, NUTRITION, V29, P1037, DOI 10.1016/j.nut.2013.02.007
   Ménard T, 2019, DRUG SAFETY, V42, P1045, DOI 10.1007/s40264-019-00831-4
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Michie S, 2012, HEALTH PSYCHOL REV, V6, P1, DOI 10.1080/17437199.2012.654964
   Moshfeghi Y, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/2911451.2911534
   Moullin JC, 2015, HEALTH RES POLICY SY, V13, DOI 10.1186/s12961-015-0005-z
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Ni YZ, 2019, JMIR MED INF, V7, DOI 10.2196/14185
   Norman Donald A., 1986, User Centered System Design; New Perspectives on Human-Computer Interaction
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Park C, 2019, JMIR MED INF, V7, P437, DOI 10.2196/13353
   Patel MS, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.0818
   Peterson JF, 2014, J AM GERIATR SOC, V62, P2148, DOI 10.1111/jgs.13057
   Pickering BW, 2015, INT J MED INFORM, V84, P299, DOI 10.1016/j.ijmedinf.2015.01.017
   Plaisant C., 1996, P AMIA ANN FALL S, P884
   POWSNER SM, 1994, LANCET, V344, P386, DOI 10.1016/S0140-6736(94)91406-0
   Rainer R.K., 2020, Introduction to information systems
   Reimann P, 2009, INT J COMP-SUPP COLL, V4, P239, DOI 10.1007/s11412-009-9070-z
   Robson J, 2014, NPJ PRIM CARE RESP M, V24, P1
   SANDERSON PM, 1994, HUM-COMPUT INTERACT, V9, P251, DOI 10.1207/s15327051hci0903&4_2
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Schwendimann BA, 2017, IEEE T LEARN TECHNOL, V10, P30, DOI 10.1109/TLT.2016.2599522
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Simpao AF, 2015, J AM MED INFORM ASSN, V22, P361, DOI 10.1136/amiajnl-2013-002538
   Soh JY, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/12204
   Toms EG, 2000, INT J HUM-COMPUT ST, V52, P423, DOI 10.1006/ijhc.1999.0345
   Touray K, 2016, J INFECT DIS, V213, pS67, DOI 10.1093/infdis/jiv493
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Valacich J., 2009, INFORM SYSTEMS TODAY, V4th
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Verbert K, 2014, PERS UBIQUIT COMPUT, V18, P1499, DOI 10.1007/s00779-013-0751-2
   Waller RG, 2019, J AM MED INFORM ASSN, V26, P479, DOI 10.1093/jamia/ocy193
   Weiner BJ, 2009, IMPLEMENT SCI, V4, DOI 10.1186/1748-5908-4-67
   West VL, 2015, J AM MED INFORM ASSN, V22, P330, DOI 10.1136/amiajnl-2014-002955
   Wexler S., 2017, BIG BOOK DASHBOARDS
   Whidden C, 2018, J GLOB HEALTH, V8, DOI 10.7189/jogh.08.020418
   Whittemore R, 2005, J ADV NURS, V52, P546, DOI 10.1111/j.1365-2648.2005.03621.x
   Wohlin C., 2014, P 18 INT C EV ASS SO, P1, DOI [10.1145/2601248.2601268, 10.1145/2601248]
   Yigitbasioglu Ogan M., 2012, International Journal of Accounting Information Systems, V13, P41, DOI 10.1016/j.accinf.2011.08.002
   Yoo J, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/10666
   Zahanova S, 2017, CAN J DIABETES, V41, P603, DOI 10.1016/j.jcjd.2016.12.012
   Zhu Y, 2007, LECT NOTES COMPUT SC, V4842, P652
   Zhuang MD, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1507, DOI 10.1145/3269206.3269243
NR 90
TC 13
Z9 14
U1 5
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1715
EP 1731
DI 10.1109/TVCG.2022.3147154
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA ZH9CR
UT WOS:000761227900002
PM 35213306
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Huang, RP
   Li, Q
   Chen, L
   Yuan, XR
AF Huang, Renpei
   Li, Quan
   Chen, Li
   Yuan, Xiaoru
TI A Probability Density-Based Visual Analytics Approach to Forecast Bias
   Calibration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Weather forecasting; Calibration; Data visualization; Spatiotemporal
   phenomena; Atmospheric modeling; Uncertainty; Weather forecast; pattern
   extraction; calibration; visual analytics
ID ENSEMBLE-MOS METHODS; VISUALIZATION; PRECIPITATION; VARIABILITY; TOOL;
   UNCERTAINTY; EXPLORATION
AB Biases inevitably occur in numerical weather prediction (NWP) due to an idealized numerical assumption for modeling chaotic atmospheric systems. Therefore, the rapid and accurate identification and calibration of biases is crucial for NWP in weather forecasting. Conventional approaches, such as various analog post-processing forecast methods, have been designed to aid in bias calibration. However, these approaches fail to consider the spatiotemporal correlations of forecast bias, which can considerably affect calibration efficacy. In this article, we propose a novel bias pattern extraction approach based on forecasting-observation probability density by merging historical forecasting and observation datasets. Given a spatiotemporal scope, our approach extracts and fuses bias patterns and automatically divides regions with similar bias patterns. Termed BicaVis, our spatiotemporal bias pattern visual analytics system is proposed to assist experts in drafting calibration curves on the basis of these bias patterns. To verify the effectiveness of our approach, we conduct two case studies with real-world reanalysis datasets. The feedback collected from domain experts confirms the efficacy of our approach.
C1 [Huang, Renpei; Chen, Li] Tsinghua Univ, Sch Software, BNRIST, Beijing 100084, Peoples R China.
   [Li, Quan] WeBank, AI Grp, Shenzhen, Guangdong, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Tsinghua University; Peking University; Peking University
RP Chen, L (corresponding author), Tsinghua Univ, Sch Software, BNRIST, Beijing 100084, Peoples R China.
EM huangrp2013@gmail.com; forrestli@webank.com; chenlee@tsinghua.edu.cn;
   xiaoru.yuan@pku.edu.cn
RI Li, yuancheng/IUO-3866-2023; Yuan, Xiaoru/E-1798-2013
OI Li, Quan/0000-0003-2249-0728
FU National Natural Science Foundation of China [61972221, 61572274];
   National Numerical Windtunnel Project [NNW2018-ZT6B12]
FX The authors were grateful for the valuable feedback and comments
   provided by the anonymous reviewers. This research was partially
   supported by the National Natural Science Foundation of China (Grant
   Nos. 61972221, 61572274) and NNW2018-ZT6B12 (National Numerical
   Windtunnel Project).
CR Bernard J, 2014, COMPUT GRAPH FORUM, V33, P291, DOI 10.1111/cgf.12385
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Dasgupta A, 2020, IEEE T VIS COMPUT GR, V26, P1043, DOI 10.1109/TVCG.2019.2934540
   Dee DP, 1998, Q J ROY METEOR SOC, V124, P269, DOI 10.1002/qj.49712454512
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P2896, DOI 10.1109/TVCG.2013.131
   Ebert EE, 2001, MON WEATHER REV, V129, P2461, DOI 10.1175/1520-0493(2001)129<2461:AOAPMS>2.0.CO;2
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Glahn H. R., 1972, Journal of Applied Meteorology, V11, P1203, DOI 10.1175/1520-0450(1972)011<1203:TUOMOS>2.0.CO;2
   Gneiting T, 2005, MON WEATHER REV, V133, P1098, DOI 10.1175/MWR2904.1
   Gneiting T, 2007, J R STAT SOC B, V69, P243, DOI 10.1111/j.1467-9868.2007.00587.x
   Gong C, 2016, J VISUAL-JAPAN, V19, P769, DOI 10.1007/s12650-015-0341-7
   Hamill TM, 2006, MON WEATHER REV, V134, P3209, DOI 10.1175/MWR3237.1
   Hamill TM, 2017, MON WEATHER REV, V145, P3441, DOI 10.1175/MWR-D-16-0331.1
   Hamill TM, 2015, MON WEATHER REV, V143, P3300, DOI 10.1175/MWR-D-15-0004.1
   Hamill TM, 2013, B AM METEOROL SOC, V94, P1553, DOI 10.1175/BAMS-D-12-00014.1
   Hankin S, 1996, J VISUAL COMP ANIMAT, V7, P149, DOI 10.1002/(SICI)1099-1778(199607)7:3<149::AID-VIS148>3.0.CO;2-X
   He WB, 2017, IEEE PAC VIS SYMP, P151, DOI 10.1109/PACIFICVIS.2017.8031589
   Helbig C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123811
   HIBBARD B, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P28, DOI 10.1109/VISUAL.1990.146361
   Hogan RJ, 2010, WEATHER FORECAST, V25, P710, DOI 10.1175/2009WAF2222350.1
   Hou DC, 2014, J HYDROMETEOROL, V15, P2542, DOI 10.1175/JHM-D-11-0140.1
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Liao HS, 2018, IEEE T VIS COMPUT GR, V24, P2531, DOI 10.1109/TVCG.2017.2754480
   Liao HS, 2016, IEEE T MULTIMEDIA, V18, P2196, DOI 10.1109/TMM.2016.2614227
   Liao HS, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P25, DOI 10.1109/SciVis.2015.7429488
   Lim T, 2001, J FINANC, V56, P369, DOI 10.1111/0022-1082.00329
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Raftery AE, 2005, MON WEATHER REV, V133, P1155, DOI 10.1175/MWR2906.1
   Rautenhaus M, 2015, GEOSCI MODEL DEV, V8, P2329, DOI 10.5194/gmd-8-2329-2015
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Russell I., 2010, ECMWF NEWSLETT, V126, P23
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   TREINISH LA, 1995, IEEE COMPUT GRAPH, V15, P20, DOI 10.1109/38.391486
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang XG, 2003, J ATMOS SCI, V60, P1140, DOI 10.1175/1520-0469(2003)060<1140:ACOBAE>2.0.CO;2
   Wang YH, 2015, COMPUT GRAPH FORUM, V34, P99, DOI 10.1111/cgf.12520
   Wessel Paul, 2013, Eos, Transactions American Geophysical Union, V94, P409, DOI 10.1002/2013EO450001
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wilks DS, 2006, METEOROL APPL, V13, P243, DOI 10.1017/S1350482706002192
   Wilks DS, 2007, MON WEATHER REV, V135, P2379, DOI 10.1175/MWR3402.1
NR 48
TC 1
Z9 2
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1732
EP 1744
DI 10.1109/TVCG.2020.3025072
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900003
PM 32946394
DA 2024-11-06
ER

PT J
AU Du, ZJ
   Huang, SS
   Mu, TJ
   Zhao, Q
   Martin, RR
   Xu, K
AF Du, Zheng-Jun
   Huang, Shi-Sheng
   Mu, Tai-Jiang
   Zhao, Qunhe
   Martin, Ralph R.
   Xu, Kun
TI Accurate Dynamic SLAM Using CRF-Based Long-Term Consistency
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Simultaneous localization and mapping; Three-dimensional
   displays; Visualization; Pose estimation; Dynamics; Robustness; RGB-D
   SLAM; dynamic SLAM; long-term consistency; conditional random fields;
   graph-cut RANSAC
ID SIMULTANEOUS LOCALIZATION; TRACKING
AB Accurate camera pose estimation is essential and challenging for real world dynamic 3D reconstruction and augmented reality applications. In this article, we present a novel RGB-D SLAM approach for accurate camera pose tracking in dynamic environments. Previous methods detect dynamic components only across a short time-span of consecutive frames. Instead, we provide a more accurate dynamic 3D landmark detection method, followed by the use of long-term consistency via conditional random fields, which leverages long-term observations from multiple frames. Specifically, we first introduce an efficient initial camera pose estimation method based on distinguishing dynamic from static points using graph-cut RANSAC. These static/dynamic labels are used as priors for the unary potential in the conditional random fields, which further improves the accuracy of dynamic 3D landmark detection. Evaluation using the TUM and Bonn RGB-D dynamic datasets shows that our approach significantly outperforms state-of-the-art methods, providing much more accurate camera trajectory estimation in a variety of highly dynamic environments. We also show that dynamic 3D reconstruction can benefit from the camera poses estimated by our RGB-D SLAM approach.
C1 [Du, Zheng-Jun] Qinghai Univ, Dept Comp Technol & Applicat, Xining 810016, Qinghai, Peoples R China.
   [Du, Zheng-Jun; Huang, Shi-Sheng; Mu, Tai-Jiang; Xu, Kun] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
   [Zhao, Qunhe] Shanghai Co Ltd, DeepBlue Technol, Shanghai 200336, Peoples R China.
   [Martin, Ralph R.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
C3 Qinghai University; Tsinghua University; Cardiff University
RP Mu, TJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
EM duzj19@mails.tsinghua.edu.cn; shishenghuang.net@gmail.com;
   taijiang@tsinghua.edu.cn; zhaoqh@deepblueai.com; MartinRR@cardiff.ac.uk;
   xukun@tsinghua.edu.cn
RI Xu, Kun/K-7134-2012; Mu, Tai-Jiang/JWO-1381-2024; Martin,
   Ralph/D-2366-2010
OI Du, Zheng-Jun/0009-0001-7060-9773; Du, Zheng-Jun/0000-0002-6763-2892;
   Mu, Tai-Jiang/0000-0002-9197-346X
FU Natural Science Foundation of China [61863031, 61902210, 61521002];
   China Postdoctoral Science Foundation [2019M660646]
FX The authors would like to thank the reviewers for their detailed and
   constructive comments on this article. This work was supported by the
   Natural Science Foundation of China (Grant No. 61863031, 61902210,
   61521002) and the China Postdoctoral Science Foundation (Grant No.
   2019M660646).
CR Alcantarilla PF, 2012, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2012.6224690
   [Anonymous], 2017, ACM Transactions on Graphics (TOG)
   Bapat A, 2016, IEEE T VIS COMPUT GR, V22, P2358, DOI 10.1109/TVCG.2016.2593757
   Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bujanca M, 2019, IEEE INT CONF COMP V, P2168, DOI 10.1109/ICCVW.2019.00272
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Dai A, 2018, LECT NOTES COMPUT SC, V11214, P458, DOI 10.1007/978-3-030-01249-6_28
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Gao W, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Garon M, 2017, IEEE T VIS COMPUT GR, V23, P2410, DOI 10.1109/TVCG.2017.2734599
   Halber M, 2019, IEEE I CONF COMP VIS, P2541, DOI 10.1109/ICCV.2019.00263
   He K., 2020, IEEE T PATTERN ANAL, V42, P386, DOI [DOI 10.1109/TPAMI.2018.2844175, 10.1109/TPAMI.2018.2844175.]
   Huang JH, 2020, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR42600.2020.00224
   Huang JH, 2019, IEEE I CONF COMP VIS, P5874, DOI 10.1109/ICCV.2019.00597
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Kim DH, 2016, IEEE T ROBOT, V32, P1565, DOI 10.1109/TRO.2016.2609395
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Klein George, 2007, P1
   Krahenbuhl P, 2011, ADV NEURAL INF PROCE, V24, P109
   Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759
   Meerits Siim, 2018, Computational Visual Media, V4, P287, DOI 10.1007/s41095-018-0121-0
   Moratuwage D, 2013, IEEE INT CONF ROBOT, P5702, DOI 10.1109/ICRA.2013.6631397
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Narita G, 2019, IEEE INT C INT ROBOT, P4205, DOI [10.1109/iros40897.2019.8967890, 10.1109/IROS40897.2019.8967890]
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Palazzolo E, 2019, IEEE INT C INT ROBOT, P7855, DOI [10.1109/IROS40897.2019.8967590, 10.1109/iros40897.2019.8967590]
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rambach JR, 2016, INT SYM MIX AUGMENT, P71, DOI 10.1109/ISMAR.2016.19
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rünz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024
   Scona R, 2018, IEEE INT CONF ROBOT, P3849, DOI 10.1109/ICRA.2018.8460681
   Slavcheva M, 2018, PROC CVPR IEEE, P2646, DOI 10.1109/CVPR.2018.00280
   Slavcheva M, 2017, PROC CVPR IEEE, P5474, DOI 10.1109/CVPR.2017.581
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229
   Yan ZX, 2017, IEEE T VIS COMPUT GR, V23, P2389, DOI 10.1109/TVCG.2017.2734458
   Yang S, 2020, IEEE T VIS COMPUT GR, V26, P3217, DOI 10.1109/TVCG.2019.2919619
   Yang SF, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P2398, DOI 10.1109/CompComm.2017.8322965
   Zhang H, 2018, IEEE T VIS COMPUT GR, V24, P3137, DOI 10.1109/TVCG.2017.2786233
   Zhang JH, 2019, IEEE T VIS COMPUT GR, V25, P3052, DOI 10.1109/TVCG.2019.2932216
   Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
NR 51
TC 37
Z9 38
U1 12
U2 70
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1745
EP 1757
DI 10.1109/TVCG.2020.3028218
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900004
PM 33001804
DA 2024-11-06
ER

PT J
AU Guan, YR
   Liu, H
   Liu, K
   Yin, KX
   Hu, RZ
   van Kaick, O
   Zhang, Y
   Yumer, E
   Carr, N
   Mech, R
   Zhang, H
AF Guan, Yanran
   Liu, Han
   Liu, Kun
   Yin, Kangxue
   Hu, Ruizhen
   van Kaick, Oliver
   Zhang, Yan
   Yumer, Ersin
   Carr, Nathan
   Mech, Radomir
   Zhang, Hao
TI FAME: 3D Shape Generation via Functionality-Aware Model Evolution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Three-dimensional displays; Tools; Solid modeling; Computational
   modeling; Sociology; Statistics; Cross-category hybrids;
   functionality-aware shape modeling; functionality partial matching; set
   evolution
AB We introduce a modeling tool which can evolve a set of 3D objects in a functionality-aware manner. Our goal is for the evolution to generate large and diverse sets of plausible 3D objects for data augmentation, constrained modeling, as well as open-ended exploration to possibly inspire new designs. Starting with an initial population of 3D objects belonging to one or more functional categories, we evolve the shapes through part recombination to produce generations of hybrids or crossbreeds between parents from the heterogeneous shape collection. Evolutionary selection of offsprings is guided both by a functional plausibility score derived from functionality analysis of shapes in the initial population and user preference, as in a design gallery. Since cross-category hybridization may result in offsprings not belonging to any of the known functional categories, we develop a means for functionality partial matching to evaluate functional plausibility on partial shapes. We show a variety of plausible hybrid shapes generated by our functionality-aware model evolution, which can complement existing datasets as training data and boost the performance of contemporary data-driven segmentation schemes, especially in challenging cases. Our tool supports constrained modeling, allowing users to restrict or steer the model evolution with functionality labels. At the same time, unexpected yet functional object prototypes can emerge during open-ended exploration owing to structure breaking when evolving a heterogeneous collection.
C1 [Guan, Yanran; van Kaick, Oliver] Carleton Univ, Sch Comp Sci, Ottawa, ON K1S 5B6, Canada.
   [Liu, Han] Elect Arts, Ashburn, VA 20147 USA.
   [Liu, Kun; Zhang, Yan] Nanjing Univ, Dept Comp Sci & Technol, Nanjing 210093, Peoples R China.
   [Yin, Kangxue] NVIDIA, Toronto, ON M5V 3M4, Canada.
   [Hu, Ruizhen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Yumer, Ersin] Uber ATG, Pittsburgh, PA 15201 USA.
   [Carr, Nathan; Mech, Radomir] Adobe, San Jose, CA 95110 USA.
   [Zhang, Hao] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
C3 Carleton University; Nanjing University; Shenzhen University; Adobe
   Systems Inc.; Simon Fraser University
RP Hu, RZ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM yanran.guan@carleton.ca; han.liu@kaust.edu.sa;
   mf1733036@smail.nju.edu.cn; kangxue.yin@gmail.com; ruizhen.hu@gmail.com;
   Oliver.vanKaick@carleton.ca; zhangyannju@nju.edu.cn; meyumer@gmail.ccmi;
   ncarr@adobe.com; rmech@adobe.com; haoz@cs.sfu.ca
RI Guan, Yanran/JZT-6135-2024; Zhang, Hao/HHM-1940-2022
OI Guan, Yanran/0000-0002-7348-366X; Mech, Radomir/0000-0002-5558-0327; van
   Kaick, Oliver/0000-0001-9869-6832; Carr, Nathan/0000-0003-2324-6428;
   Zhang, Hao/0000-0003-1991-119X
FU NSERC Canada [611370, 611649, 2015-05407]; NSFC [61872250, 62032011]
FX The authors would like to thank the reviewers for their comments and
   suggestions. This work was supported in part by NSERC Canada (under
   Grant Nos. 611370, 611649, and 2015-05407), NSFC (under Grant Nos.
   61872250 and 62032011), and in part by a gift funding from Adobe.
CR Chang A.X., 2015, Technical Report
   Chaudhuri S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964930
   Chaudhuri S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866205
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Fu Qiang, 2017, IEEE Trans Vis Comput Graph, V23, P2574, DOI 10.1109/TVCG.2017.2739159
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Hu R, 2018, COMPUT GRAPH FORUM, V37, P603, DOI 10.1111/cgf.13385
   Hu RZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201287
   Hu RZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925870
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Hyo Jong Shin, 2007, Proceedings Graphics Interface 2007, P63, DOI 10.1145/1268517.1268530
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Khetarpal K, 2020, PR MACH LEARN RES, V119
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Kim VG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185550
   Kreavoy A, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P129, DOI 10.1109/PG.2007.40
   Lipson H, 2000, NATURE, V406, P974, DOI 10.1038/35023115
   Lun ZL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980237
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   Mitra N. J., 2012, P EUROGRAPHICS STATE, P29
   Mitra NJ, 2013, EUROGRAPHICS STATE A, P175
   Nagarajan T., 2020, P NEURAL INF PROCESS
   Norman D., 2013, The Design of Everyday Things: Revised and Expanded Edition
   Pilat ML, 2008, IEEE C EVOL COMPUTAT, P3289, DOI 10.1109/CEC.2008.4631243
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Savva M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661230
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   SIMS K, 1991, COMP GRAPH, V25, P319, DOI 10.1145/127719.122752
   Sorkine O., 2005, Eurographics 2005 - State of the Art Reports, P53
   Xu K, 2017, COMPUT GRAPH FORUM, V36, P101, DOI 10.1111/cgf.12790
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Zheng YY, 2013, COMPUT GRAPH FORUM, V32, P195, DOI 10.1111/cgf.12039
NR 34
TC 4
Z9 6
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1758
EP 1772
DI 10.1109/TVCG.2020.3029759
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900005
PM 33044933
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Chatzimparmpas, A
   Martins, RM
   Kucher, K
   Kerren, A
AF Chatzimparmpas, Angelos
   Martins, Rafael M.
   Kucher, Kostiantyn
   Kerren, Andreas
TI FeatureEnVi: Visual Analytics for Feature Engineering Using Stepwise
   Selection and Semi-Automatic Extraction Approaches
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature extraction; Visual analytics; Data visualization; Transforms;
   Prediction algorithms; Interviews; Speech recognition; Feature
   selection; feature extraction; feature engineering; machine learning;
   visual analytics; visualization
ID CANCER CLASSIFICATION; DISCRIMINANT-ANALYSIS; GENE SELECTION; SVM-RFE;
   MODELS; EXPLORATION; ALGORITHMS; FRAMEWORK
AB The machine learning (ML) life cycle involves a series of iterative steps, from the effective gathering and preparation of the data-including complex feature engineering processes-to the presentation and improvement of results, with various algorithms to choose from in every step. Feature engineering in particular can be very beneficial for ML, leading to numerous improvements such as boosting the predictive results, decreasing computational times, reducing excessive noise, and increasing the transparency behind the decisions taken during the training. Despite that, while several visual analytics tools exist to monitor and control the different stages of the ML life cycle (especially those related to data and algorithms), feature engineering support remains inadequate. In this paper, we present FeatureEnVi, a visual analytics system specifically designed to assist with the feature engineering process. Our proposed system helps users to choose the most important feature, to transform the original features into powerful alternatives, and to experiment with different feature generation combinations. Additionally, data space slicing allows users to explore the impact of features on both local and global scales. FeatureEnVi utilizes multiple automatic feature selection techniques; furthermore, it visually guides users with statistical evidence about the influence of each feature (or subsets of features). The final outcome is the extraction of heavily engineered features, evaluated by multiple validation metrics. The usefulness and applicability of FeatureEnVi are demonstrated with two use cases and a case study. We also report feedback from interviews with two ML experts and a visualization researcher who assessed the effectiveness of our system.
C1 [Chatzimparmpas, Angelos; Martins, Rafael M.; Kucher, Kostiantyn; Kerren, Andreas] Linnaeus Univ, Dept Comp Sci & Media Technol, S-35195 Vaxjo, Sweden.
   [Kucher, Kostiantyn; Kerren, Andreas] Linkoping Univ, Dept Sci & Technol, S-60233 Norrkoping, Sweden.
C3 Linnaeus University; Linkoping University
RP Chatzimparmpas, A (corresponding author), Linnaeus Univ, Dept Comp Sci & Media Technol, S-35195 Vaxjo, Sweden.
EM angelos.chatzimparmpas@lnu.se; rafael.martins@lnu.se;
   kostiantyn.kucher@lnu.se; andreas.kerren@lnu.se
RI Martins, Rafael/H-9192-2019; Kerren, Andreas/AAV-9187-2020
OI Chatzimparmpas, Angelos/0000-0002-9079-2376
CR ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933
   [Anonymous], 2001, QUANTITATIVE APPL SO
   [Anonymous], 2018, PROC FMT
   [Anonymous], 2018, ARXIV181208032
   Aphinyanaphongs Y, 2014, J ASSOC INF SCI TECH, V65, P1964, DOI 10.1002/asi.23110
   Artur E, 2019, COMPUT GRAPH-UK, V84, P160, DOI 10.1016/j.cag.2019.08.015
   Babaev D, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2183, DOI 10.1145/3292500.3330693
   Barlowe S, 2008, IEEE CONF VIS ANAL, P147, DOI 10.1109/VAST.2008.4677368
   Bernard J, 2014, COMPUT GRAPH FORUM, V33, P291, DOI 10.1111/cgf.12385
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Breiman L., 2001, MACH LEARN, V45, P5
   Brereton RG, 2014, J CHEMOMETR, V28, P213, DOI 10.1002/cem.2609
   Brooks M, 2015, IEEE CONF VIS ANAL, P105, DOI 10.1109/VAST.2015.7347637
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chatzimparmpas A, 2021, IEEE T VIS COMPUT GR, V27, P1547, DOI 10.1109/TVCG.2020.3030352
   Chatzimparmpas A, 2020, IEEE T VIS COMPUT GR, V26, P2696, DOI 10.1109/TVCG.2020.2986996
   Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cheng J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P600, DOI 10.1145/2675133.2675214
   Collaris D, 2020, IEEE PAC VIS SYMP, P26, DOI 10.1109/PacificVis48177.2020.7090
   Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016
   Cramer J. S, 2002, 20021194 TINB INS
   Dennig FL, 2019, IEEE CONF VIS ANAL, P69, DOI [10.1109/vast47406.2019.8986940, 10.1109/VAST47406.2019.8986940]
   Ding J, 2011, INT J DATA MIN BIOIN, V5, P73, DOI 10.1504/IJDMB.2011.038578
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Dohoo IR, 1997, PREV VET MED, V29, P221, DOI 10.1016/S0167-5877(96)01074-4
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Dua D, 2017, UCI MACHINE LEARNING
   Duan KB, 2005, IEEE T NANOBIOSCI, V4, P228, DOI 10.1109/TNB.2005.853657
   Duboue P., 2020, The art of feature engineering: essentials for machine learning
   Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863
   El-kenawy ESM, 2020, IEEE ACCESS, V8, P179317, DOI 10.1109/ACCESS.2020.3028012
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797
   Fogarty J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P135
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Friendly M, 2002, AM STAT, V56, P316, DOI 10.1198/000313002533
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guo D., 2003, Information Visualization, V2, P232, DOI 10.1057/palgrave.ivs.9500053
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hall M. A., 2000, P 17 INT C MACH LEAR, P359, DOI DOI 10.5555/645529.657793
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Heaton J, 2016, IEEE SOUTHEASTCON
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Hong Sungsoo Ray, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392878
   Jain S, 2022, EVOL INTELL, V15, P609, DOI 10.1007/s12065-020-00536-z
   Janecek A., 2008, Journal of Machine Learning Research: Workshop and Conference Proceedings, P90
   Jeon H., 2020, APPL SCI, V10, P1
   Johansson S, 2009, IEEE T VIS COMPUT GR, V15, P993, DOI 10.1109/TVCG.2009.153
   Johnston R, 2018, QUAL QUANT, V52, P1957, DOI 10.1007/s11135-017-0584-6
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kankanige Y, 2014, LECT NOTES ARTIF INT, V8862, P117, DOI 10.1007/978-3-319-13560-1_10
   Khurana U, 2018, AAAI CONF ARTIF INTE, P3407
   Klemm P, 2016, IEEE T VIS COMPUT GR, V22, P81, DOI 10.1109/TVCG.2015.2468291
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Laughter Ashley, 2020, Intelligent Computing. Proceedings of the 2020 Computing Conference. Advances in Intelligent Systems and Computing (AISC 1228), P373, DOI 10.1007/978-3-030-52249-0_27
   Lex A, 2010, IEEE PAC VIS SYMP, P57, DOI 10.1109/PACIFICVIS.2010.5429609
   Li Y, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1711
   Lin HF, 2018, IEEE T VIS COMPUT GR, V24, P2223, DOI 10.1109/TVCG.2017.2711030
   Liu H, 1998, IEEE INTELL SYST APP, V13, P26
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Louppe G., 2013, ADV NEURAL INF PROCE, V26
   Lu YF, 2014, IEEE CONF VIS ANAL, P193, DOI 10.1109/VAST.2014.7042495
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   MacEachren A, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P31, DOI 10.1109/INFVIS.2003.1249006
   Mansouri K, 2013, J CHEM INF MODEL, V53, P867, DOI 10.1021/ci4000213
   Markovitch S, 2002, MACH LEARN, V49, P59, DOI 10.1023/A:1014046307775
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   May T., 2011, P INT EUR VIS WORKSH, P13
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Moosavi SM, 2020, J AM CHEM SOC, V142, P20273, DOI 10.1021/jacs.0c09105
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Nogueira F., 2014, Bayesian Optimization: Open source constrained global optimization tool for Python
   Patel K, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P667
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI [10.1098/rspl.1895.0041, DOI 10.1098/RSPL.1895.0041]
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Perez-Riverol Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189875
   Piringer H, 2010, COMPUT GRAPH FORUM, V29, P983, DOI 10.1111/j.1467-8659.2009.01684.x
   Piringer H, 2008, IEEE INT CONF INF VI, P240, DOI 10.1109/IV.2008.17
   Radivojac P, 2004, LECT NOTES COMPUT SC, V3201, P334
   Rauber P.E., 2015, P INT EUR VIS WORKSH, P19
   Rojo D., 2020, P EUR C VIS, P127
   Sanchez A, 2018, EXPERT SYST APPL, V100, P182, DOI 10.1016/j.eswa.2018.01.054
   Schuller B, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P5, DOI 10.1109/ICME.2006.262500
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Shwartz-Ziv R, 2022, INFORM FUSION, V81, P84, DOI 10.1016/j.inffus.2021.11.011
   Siebert J.P., 1987, Turing Institute Research Memorandum TIRM-87-018
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Swearingen T, 2017, IEEE INT CONF BIG DA, P151, DOI 10.1109/BigData.2017.8257923
   Turkay C, 2011, IEEE T VIS COMPUT GR, V17, P2591, DOI 10.1109/TVCG.2011.178
   Vittinghoff E, 2005, STAT BIOL HEALTH, pVII
   Wang YH, 2017, COMPUT GRAPH FORUM, V36, P401, DOI 10.1111/cgf.13197
   Xu K, 2019, IEEE T VIS COMPUT GR, V25, P109, DOI 10.1109/TVCG.2018.2864825
   Yang J, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P73
   Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105
   Yang J., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P19
   Yang JH, 1998, IEEE INTELL SYST APP, V13, P44, DOI 10.1109/5254.671091
   Yang Y, 1997, ICML, V97, P35
   Zhao JQ, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P161, DOI [10.1109/VISUAL.2019.8933619, 10.1109/visual.2019.8933619]
   Zhou JL, 2018, HUM-COMPUT INT-SPRIN, P3, DOI 10.1007/978-3-319-90403-0_1
NR 107
TC 13
Z9 13
U1 0
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1773
EP 1791
DI 10.1109/TVCG.2022.3141040
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900006
PM 34990365
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hashemian, AM
   Lotfaliei, M
   Adhikari, A
   Kruijff, E
   Riecke, BE
AF Hashemian, Abraham M.
   Lotfaliei, Matin
   Adhikari, Ashu
   Kruijff, Ernst
   Riecke, Bernhard E.
TI HeadJoystick: Improving Flying in VR Using a Novel Leaning-Based
   Interface
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Telepresence; Visualization; Three-dimensional displays;
   Drones; Standards; 3D user interface; motion sickness; cybersickness;
   flying; travel techniques; virtual reality
ID VIRTUAL-REALITY; MOTION SICKNESS; ENVIRONMENTS; ROTATION
AB Flying in virtual reality (VR) using standard handheld controllers can be cumbersome and contribute to unwanted side effects such as motion sickness and disorientation. This article investigates a novel hands-free flying interface-HeadJoystick, where the user moves their head similar to a joystick handle toward the target direction to control virtual translation velocity. The user sits on a regular office swivel chair and rotates it physically to control virtual rotation using 1:1 mapping. We evaluated short-term (Study 1) and extended usage effects through repeated usage (Study 2) of the HeadJoystick versus handheld interfaces in two within-subject studies, where participants flew through a sequence of increasingly difficult tunnels in the sky. Using the HeadJoystick instead of handheld interfaces improved both user experience and performance, in terms of accuracy, precision, ease of learning, ease of use, usability, long-term use, presence, immersion, sensation of self-motion, workload, and enjoyment in both studies. These findings demonstrate the benefits of using leaning-based interfaces for VR flying and potentially similar telepresence applications such as remote flight with quadcopter drones. From a theoretical perspective, we also show how leaning-based motion cueing interacts with full physical rotation to improve user experience and performance compared to the gamepad.
C1 [Hashemian, Abraham M.; Lotfaliei, Matin; Adhikari, Ashu; Kruijff, Ernst; Riecke, Bernhard E.] Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, D-53757 St Augustin, Germany.
C3 Simon Fraser University; Hochschule Bonn Rhein Sieg
RP Hashemian, AM (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
EM hashemia@sfu.ca; mlotfali@sfu.ca; ashua@sfu.ca; ernst.kruijff@h-brs.de;
   ber1@sfu.ca
RI Riecke, Bernhard/C-6399-2011
OI Riecke, Bernhard/0000-0001-7974-0850; Hashemian, Abraham
   M./0000-0001-8385-4332; Kruijff, Ernst/0000-0003-1625-0955
CR [Anonymous], 2001, P 2001 S INT 3D GRAP
   Badcock DR, 2015, HUM FACTORS ERGON, P39
   Beckhaus S., 2005, COMP SCI MAG C
   Beckhaus Steffi., 2005, New Directions in 3D User Interfaces Workshop of IEEE VR, P57
   Bowman D. A., 2017, 3D USER INTERFACES T
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Cauchard JR, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P361, DOI 10.1145/2750858.2805823
   Cherpillod A, 2019, 2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019), P386, DOI 10.1109/IRC.2019.00070
   Chester MR, 2002, INT J IND ERGONOM, V29, P289, DOI 10.1016/S0169-8141(01)00069-5
   de Vries S. C., 1997, TNOTM97B024
   Farrell MJ, 1998, J EXP PSYCHOL LEARN, V24, P227, DOI 10.1037/0278-7393.24.1.227
   Freiberg J., 2015, Master's thesis,
   Grechkin T.Y., 2014, ACM International Conference Proceedings Series, Proceedings, SAP 2014: Vancouver, British Columbia, Canada, August 08-09, 2014, P99, DOI [10.1145/2628257, DOI 10.1145/2628257]
   Groen EL, 2004, J VESTIBUL RES-EQUIL, V14, P375
   Guy Emilie, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2015.7131725
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hashemian A. M., 2017, SOFTW AUGM VIRT REAL
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Higuchi K, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P28
   Ikeuchi K., 2014, P 5 AUGMENTED HUMAN, P2, DOI [10.1145/2582051.2582104, DOI 10.1145/2582051.2582104]
   Jia Wang, 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P31, DOI 10.1109/3DUI.2012.6184181
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Krishna RV, 2015, 2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Krupke D, 2015, GI WORKSH VR AR
   Krupke D, 2016, P IEEE VIRT REAL ANN, P329
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   Lawson BD, 2015, HUM FACTORS ERGON, P163
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   McMahan R., 2014, HDB VIRTUAL ENV, P285
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miehlbradt J, 2018, P NATL ACAD SCI USA, V115, P7913, DOI 10.1073/pnas.1718648115
   Miermeister P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3024, DOI 10.1109/IROS.2016.7759468
   Mirk D., 2015, Proceedings of the First Workshop on Micro Aerial Vehicle Networks, Systems, and Applications for Civilian Use-DroNet15, P45, DOI DOI 10.1145/2750675.2750681
   Monajjemi M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4410, DOI 10.1109/IROS.2016.7759649
   Nguyen-Vo Thinh, 2019, IEEE T VIS COMPUT GR
   Perusquia-Hernandez M., 2017, P 8 AUGM HUM INT C, V4, DOI [10.1145/3041164.3041173, DOI 10.1145/3041164.3041173]
   Peshkova E, 2016, INTELLIGENT TECHNOLO, P47
   Pfeil K., 2013, P INT C INT US INT, P257, DOI [DOI 10.1145/2449396.2449429, 10.1145/2449396.2449429]
   Pittman C., 2014, P 19 INT C INT US IN, P323
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Quigley M., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2457
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Reason J.T., 1975, Motion Sickness
   Rheiner M, 2014, P ACM SIGGRAPH EM TE
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2012, vection") in virtual reality?, P17
   Riecke B. E., 2015, P 3 S SPAT US INT LO, P123, DOI DOI 10.1145/2788940.2788956
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI [10.1145/1180495.1180517, DOI 10.1145/1180495.1180517, 10.1145/ 1180495.1180517]
   Riecke BE, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P295, DOI [10.1109/VRW50115.2020.00066, 10.1109/VRW50115.2020.0-210]
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Riecke BE, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P147
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Rognon C, 2018, IEEE ROBOT AUTOM LET, V3, P2362, DOI 10.1109/LRA.2018.2810955
   Ruddle R.A., 2013, HUMAN WALKING VIRTUA, P99, DOI [10.1007/978-1-4419-8432-6_5, DOI 10.1007/978-1-4419-8432-6_5]
   Ruddle RA, 1999, PRESENCE-TELEOP VIRT, V8, P157, DOI 10.1162/105474699566143
   Sarkar A, 2016, 2016 INT C IND INF C, P1, DOI DOI 10.1109/ICCSII.2016.7462401
   Schulte B., 2016, P GI WORKSHOP VRAR, P109
   Sikström E, 2015, P IEEE VIRT REAL ANN, P281, DOI 10.1109/VR.2015.7223405
   Silva MaraG., 2009, CHI'09 Extended Abstracts on Human Factors in Computing Systems (CHI EA'09), P4249, DOI DOI 10.1145/1520340.1520648
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Stepanova Ekaterina R., 2017, Human-Computer Interaction: Interaction Contexts. 19th International Conference, held as part of HCI International 2017. Proceedings: LNCS 10272, P562, DOI 10.1007/978-3-319-58077-7_45
   Stoica A, 2014, ACMIEEE INT CONF HUM, P296, DOI [10.1145/2559636.2559853, 10.1145/2559636.255985]
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Trindade DR, 2014, MULTIMED TOOLS APPL, V73, P939, DOI 10.1007/s11042-012-1127-8
   van Erp J. B., 2006, P HUM FACT RES I
   Ventura R, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P12, DOI 10.1109/EST.2012.40
   Viirre E, 2015, HUM FACTORS ERGON, P521
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang Jia., 2012, ACM S VIRT REAL SOFT, P121
   Yu YP, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P669
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P297, DOI [10.1109/VRW50115.2020.0-209, 10.1109/VRW50115.2020.00067]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 81
TC 20
Z9 20
U1 1
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1792
EP 1809
DI 10.1109/TVCG.2020.3025084
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA ZH9CR
UT WOS:000761227900007
PM 32946395
DA 2024-11-06
ER

PT J
AU Shi, WQ
   Dorsey, J
   Rushmeier, H
AF Shi, Weiqi
   Dorsey, Julie
   Rushmeier, Holly
TI Learning-Based Inverse Bi-Scale Material Fitting From Tabular BRDFs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geometry; Training; Lighting; Rendering (computer graphics); Analytical
   models; Computational modeling; Two dimensional displays; Reflectance;
   material appearance; bi-scale materials
ID REFLECTANCE
AB Relating small-scale structures to large-scale appearance is a key element in material appearance design. Bi-scale material design requires finding small-scale structures - meso-scale geometry and micro-scale BRDFs - that produce a desired large-scale appearance expressed as a macro-scale BRDF. The adjustment of small-scale geometry and reflectances to achieve a desired appearance can become a tedious trial-and-error process. We present a learning-based solution to fit a target macro-scale BRDF with a combination of a meso-scale geometry and micro-scale BRDF. We confront challenges in representation at both scales. At the large scale we need macro-scale BRDFs that are both compact and expressive. At the small scale we need diverse combinations of geometric patterns and potentially spatially varying micro-BRDFs. For large-scale macro-BRDFs, we propose a novel 2D subset of a tabular BRDF representation that well preserves important appearance features for learning. For small-scale details, we represent geometries and BRDFs in different categories with different physical parameters to define multiple independent continuous search spaces. To build the mapping between large-scale macro-BRDFs and small-scale details, we propose an end-to-end model that takes the subset BRDF as input and performs classification and parameter estimation on small-scale details to find an accurate reconstruction. Compared with other fitting methods, our learning-based solution provides higher reconstruction accuracy and covers a wider gamut of appearance.
C1 [Shi, Weiqi; Dorsey, Julie; Rushmeier, Holly] Yale Univ, Dept Comp Sci, New Haven, CT 06511 USA.
C3 Yale University
RP Shi, WQ (corresponding author), Yale Univ, Dept Comp Sci, New Haven, CT 06511 USA.
EM weiqi.shi@yale.edu; julie.dorsey@yale.edu; holly.rushmeier@yale.edu
OI Rushmeier, Holly/0000-0001-5241-0886; Shi, Weiqi/0000-0002-6413-8557
FU National Science Foundation [2007283]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [2007283] Funding
   Source: National Science Foundation
FX This work was supported by the National Science Foundation under Grant
   No. 2007283.
CR Aliaga C, 2017, COMPUT GRAPH FORUM, V36, P35, DOI 10.1111/cgf.13222
   [Anonymous], 2008, ACM SIGGRAPH 2008 classes, page
   Ashikhmin M, 2000, COMP GRAPH, P65, DOI 10.1145/344779.344814
   Bagher MM, 2012, COMPUT GRAPH FORUM, V31, P1509, DOI 10.1111/j.1467-8659.2012.03147.x
   Bagher MM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2907941
   Belcour L, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073620
   Brabec S, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P397
   Brady A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601193
   Bruneton E, 2012, IEEE T VIS COMPUT GR, V18, P242, DOI 10.1109/TVCG.2011.81
   Burley B., 2012, ACM SIGGRAPH, P1
   Cook RL., 1982, ACM T GRAPHIC, V1, P7, DOI [DOI 10.1145/357290.357293, 10.1145/357290.357293]
   Dong Z, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2815618
   Dupuy J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275059
   Dupuy J, 2015, COMPUT GRAPH FORUM, V34, P21, DOI 10.1111/cgf.12675
   Filip J, 2014, COMPUT GRAPH FORUM, V33, P91, DOI 10.1111/cgf.12477
   Fleming RW, 2017, ANNU REV VIS SCI, V3, P365, DOI 10.1146/annurev-vision-102016-061429
   Fleming RW, 2014, VISION RES, V94, P62, DOI 10.1016/j.visres.2013.11.004
   Fores A, 2012, COLOR IMAG CONF, P142
   Georgoulis S, 2018, IEEE T PATTERN ANAL, V40, P1932, DOI 10.1109/TPAMI.2017.2742999
   Heidrich W, 2000, COMP GRAPH, P455, DOI 10.1145/344779.344984
   Heitz E., 2014, J COMP GRAPH TECH, V3, P32
   Heitz E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925943
   Holzschuch N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073621
   Innamorati C, 2017, COMPUT GRAPH FORUM, V36, P15, DOI 10.1111/cgf.13220
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim K, 2017, IEEE I CONF COMP VIS, P20, DOI 10.1109/ICCV.2017.12
   Kingma DP, 2014, ADV NEUR IN, V27
   Kuznetsov A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356525
   Lan YX, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461989
   Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345, DOI 10.1007/978-3-642-33765-9_25
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Liu GL, 2017, IEEE I CONF COMP VIS, P2280, DOI 10.1109/ICCV.2017.248
   Löw J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077350
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Matusik W., 2005, Rendering Techniques, V2005
   Meka A, 2018, PROC CVPR IEEE, P6315, DOI 10.1109/CVPR.2018.00661
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Nielsen JB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818085
   Oren M., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P239, DOI 10.1145/192161.192213
   Paul S., 2019, ST PAUL ENGRAVING
   Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4
   Rouiller O, 2013, IEEE COMPUT GRAPH, V33, P48, DOI 10.1109/MCG.2013.82
   Shukla S. K., 2019, DURABILITY CUSTOMER
   SLOAN P.-P. J., 2001, GRAPHICS INTERFACE, P143, DOI DOI 10.20380/GI2001.17
   Sun TC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275026
   Vidaurre R, 2019, IEEE WINT CONF APPL, P1347, DOI 10.1109/WACV.2019.00148
   Walter B., 2007, RENDERING TECHNIQUES
   Weyrich T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531338
   Wisconsin, 2019, WISC ENGR
   Wu HZ, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508394
   Wu HZ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024179
   Wu LF, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322936
   Xu ZX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982396
   Yu Y, 2017, IEEE INT CONF COMP V, P526, DOI 10.1109/ICCVW.2017.69
   Zhao S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185571
   Zhao S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964939
   Zsolnai-Fehér K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201307
NR 58
TC 4
Z9 4
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1810
EP 1823
DI 10.1109/TVCG.2020.3026021
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900008
PM 32960764
OA Bronze
DA 2024-11-06
ER

PT J
AU Xin, HG
   Zheng, SK
   Xu, K
   Yan, LQ
AF Xin, Hanggao
   Zheng, Shaokun
   Xu, Kun
   Yan, Ling-Qi
TI Lightweight Bilateral Convolutional Neural Networks for Interactive
   Single-Bounce Diffuse Indirect Illumination
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Neural networks; Rendering (computer graphics);
   Three-dimensional displays; Coherence; Monte Carlo methods; Lattices;
   Real-time rendering; global illumination
AB Physically correct, noise-free global illumination is crucial in physically-based rendering, but often takes a long time to compute. Recent approaches have exploited sparse sampling and filtering to accelerate this process but still cannot achieve interactive performance. It is partly due to the time-consuming ray sampling even at 1 sample per pixel, and partly because of the complexity of deep neural networks. To address this problem, we propose a novel method to generate plausible single-bounce indirect illumination for dynamic scenes in interactive framerates. In our method, we first compute direct illumination and then use a lightweight neural network to predict screen space indirect illumination. Our neural network is designed explicitly with bilateral convolution layers and takes only essential information as input (direct illumination, surface normals, and 3D positions). Also, our network maintains the coherence between adjacent image frames efficiently without heavy recurrent connections. Compared to state-of-the-art works, our method produces single-bounce indirect illumination of dynamic scenes with higher quality and better temporal coherence and runs at interactive framerates.
C1 [Xin, Hanggao; Zheng, Shaokun; Xu, Kun] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
   [Yan, Ling-Qi] UC Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
C3 Tsinghua University; University of California System; University of
   California Santa Barbara
RP Xu, K (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
EM xhg18@mails.tsinghua.edu.cn; mango@live.cn; xukun@tsinghua.edu.cn;
   lingqi@cs.ucsb.edu
RI Xu, Kun/K-7134-2012
OI Zheng, Shaokun/0009-0003-7221-6521; Xin, Hanggao/0000-0003-1292-2427
FU National Natural Science Foundation of China [61822204, 61932003,
   61521002]; Beijing Higher Institution Engineering Research Center
FX This work was supported by the National Natural Science Foundation of
   China (Project Number 61822204, 61932003, 61521002), a research Grant
   from the Beijing Higher Institution Engineering Research Center.
CR Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073708, 10.1145/3072959.3073703]
   Bitterli B., 2016, Rendering resources
   Bitterli B, 2016, COMPUT GRAPH FORUM, V35, P107, DOI 10.1111/cgf.12954
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203
   Fernando Randima., 2005, SIGGRAPH 05, P35
   Gadde R, 2016, LECT NOTES COMPUT SC, V9905, P597, DOI 10.1007/978-3-319-46448-0_36
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Hasan M, 2006, ACM T GRAPHIC, V25, P1089, DOI 10.1145/1141911.1141998
   Hochreiter S., 1997, NEURAL COMPUT, V9, DOI [10.1162/neco.1997.9.8.1735, DOI 10.1162/NECO.1997.9.8.1735]
   Huang HZ, 2017, PROC CVPR IEEE, P7044, DOI 10.1109/CVPR.2017.745
   id Software,, 1999, Quake
   Jampani V, 2016, PROC CVPR IEEE, P4452, DOI 10.1109/CVPR.2016.482
   Kallweit S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130880
   Karis B., 2014, P ADV REAL TIM REND, P24
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Kontkanen J, 2006, MONTE CARLO AND QUASI-MONTE CARLO METHODS 2004, P259, DOI 10.1007/3-540-31186-6_16
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]
   Li YJ, 2016, LECT NOTES COMPUT SC, V9908, P154, DOI 10.1007/978-3-319-46493-0_10
   Majercik Z., 2019, J COMPUTER GRAPHICS, V8, P1
   Mass A. L., 2013, INT C MACH LEARN
   McGuire M., 2017, Computer graphics archive
   Mehta SU, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461947
   Moon B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766992
   Munkberg J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982407
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Nvidia, 2018, DEEP LEARN SAMPL
   Parker SG, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778803
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Ren PR, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462009
   Ritschel T., 2009, P S INT 3D GRAPH GAM, P75, DOI [10.1145/1507149.1507161, DOI 10.1145/1507149.1507161, 10.1145/1507149.1507161.5,7]
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shanmugam P, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P73
   Silvennoinen A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130852
   Sloan PP, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P97, DOI 10.1109/PG.2007.28
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Sun X, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239478
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yan LQ, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2816814
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 48
TC 8
Z9 9
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1824
EP 1834
DI 10.1109/TVCG.2020.3023129
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900009
PM 32915740
DA 2024-11-06
ER

PT J
AU Lu, XQ
   Schaefer, S
   Luo, J
   Ma, LZ
   He, Y
AF Lu, Xuequan
   Schaefer, Scott
   Luo, Jun
   Ma, Lizhuang
   He, Ying
TI Low Rank Matrix Approximation for 3D Geometry Filtering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Estimation; Shape; Faces; Robustness; Noise
   reduction; Geometry; 3D geometry filtering; point cloud filtering; mesh
   denoising; point upsampling; surface reconstruction; geometric texture
   removal
ID ROBUST NORMAL ESTIMATION; CLOUD NORMAL ESTIMATION; POINT
AB We propose a robust normal estimation method for both point clouds and meshes using a low rank matrix approximation algorithm. First, we compute a local isotropic structure for each point and find its similar, non-local structures that we organize into a matrix. We then show that a low rank matrix approximation algorithm can robustly estimate normals for both point clouds and meshes. Furthermore, we provide a new filtering method for point cloud data to smooth the position data to fit the estimated normals. We show the applications of our method to point cloud filtering, point set upsampling, surface reconstruction, mesh denoising, and geometric texture removal. Our experiments show that our method generally achieves better results than existing methods.
C1 [Lu, Xuequan] Deakin Univ, Sch Informat Technol, Geelong, Vic 3216, Australia.
   [Luo, Jun; He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Schaefer, Scott] Texas A&M Univ, Dept Comp Sci, College Stn, TX 77843 USA.
   [Ma, Lizhuang] Shanghai Jiao Tong Univ, Dept Comp Sci, Shanghai 200240, Peoples R China.
C3 Deakin University; Nanyang Technological University; Texas A&M
   University System; Texas A&M University College Station; Shanghai Jiao
   Tong University
RP Lu, XQ (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3216, Australia.
EM xuequan.lu@deakin.edu.au; schaefer@cs.tamu.edu; junluo@ntu.edu.sg;
   ma-lz@cs.sjtu.edu.cn; YHe@ntu.edu.sg
RI Luo, Jun/A-3699-2011; He, Ying/A-3708-2011
OI He, Ying/0000-0002-6749-4485; Luo, Jun/0000-0002-7036-5158; Lu,
   Xuequan/0000-0003-0959-408X
FU Deakin University [CY01-251301-F003-PJ03906-PG00447]; AcRF 20/20; 
   [PJ06625]
FX Xuequan Lu is supported in part by Deakin University internal Grant
   (CY01-251301-F003-PJ03906-PG00447) and industry Grant (PJ06625). YingHe
   is supported by AcRF 20/20.
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Alliez Pierre, 2007, P 5 EUROGRAPHICS S G, V7, P39, DOI DOI 10.2312/SGP/SGP07/039-048(VERP.39
   [Anonymous], 2012, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2011.250
   [Anonymous], 2014, ARXIV14054734
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Boulch A, 2012, COMPUT GRAPH FORUM, V31, P1765, DOI 10.1111/j.1467-8659.2012.03181.x
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Dey T.K., 2004, PROC 20 ACM ANN S CO, P330, DOI DOI 10.1145/997817.997867
   Digne J., 2012, P IEEE CVF C COMP VI, P73
   Digne J, 2018, IEEE T VIS COMPUT GR, V24, P2238, DOI 10.1109/TVCG.2017.2719024
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Lange C, 2005, COMPUT AIDED GEOM D, V22, P680, DOI 10.1016/j.cagd.2005.06.010
   Lee KW, 2005, INT C COMP AID DES C, P275
   Li B, 2010, COMPUT GRAPH-UK, V34, P94, DOI 10.1016/j.cag.2010.01.004
   Li XZ, 2018, COMPUT GRAPH FORUM, V37, P155, DOI 10.1111/cgf.13556
   Liu G., 2010, P 27 INT C MACH LEAR, P663, DOI DOI 10.1109/ICDMW.2010.64
   Liu XP, 2015, COMPUT GRAPH-UK, V51, P106, DOI 10.1016/j.cag.2015.05.024
   Lu XQ, 2018, IEEE T VIS COMPUT GR, V24, P2315, DOI 10.1109/TVCG.2017.2725948
   Lu XQ, 2017, COMPUT AIDED GEOM D, V54, P49, DOI 10.1016/j.cagd.2017.02.011
   Lu XQ, 2016, IEEE T VIS COMPUT GR, V22, P1181, DOI 10.1109/TVCG.2015.2500222
   Mattei E, 2017, COMPUT GRAPH FORUM, V36, P123, DOI 10.1111/cgf.13068
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pan W, 2020, COMPUT AIDED DESIGN, V121, DOI 10.1016/j.cad.2019.102807
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Shen YZ, 2004, IEEE T VIS COMPUT GR, V10, P252, DOI 10.1109/TVCG.2004.1272725
   Sun XF, 2008, COMPUT AIDED GEOM D, V25, P437, DOI 10.1016/j.cagd.2007.12.008
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang CCL, 2006, IEEE T VIS COMPUT GR, V12, P629, DOI 10.1109/TVCG.2006.60
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang PS, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818068
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wright J., 2009, ADV NEURAL INFORM PR, V22, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wu SH, 2018, IEEE T PATTERN ANAL, V40, P2529, DOI 10.1109/TPAMI.2017.2754254
   Yadav SK, 2018, COMPUT GRAPH-UK, V74, P234, DOI 10.1016/j.cag.2018.05.014
   Yadav SK, 2019, IEEE T VIS COMPUT GR, V25, P2304, DOI 10.1109/TVCG.2018.2828818
   Yadav SK, 2018, IEEE T VIS COMPUT GR, V24, P2366, DOI 10.1109/TVCG.2017.2740384
   Yagou H, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P28, DOI 10.1109/CGI.2003.1214444
   Yagou H, 2002, GEOMETRIC MODELING AND PROCESSING: THEORY AND APPLICATIONS, PROCEEDINGS, P124, DOI 10.1109/GMAP.2002.1027503
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zhang J, 2019, IEEE T VIS COMPUT GR, V25, P1693, DOI 10.1109/TVCG.2018.2827998
   Zhang J, 2013, COMPUT GRAPH-UK, V37, P697, DOI 10.1016/j.cag.2013.05.008
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x
   Zheng QA, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778831
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
NR 61
TC 40
Z9 40
U1 4
U2 47
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1835
EP 1847
DI 10.1109/TVCG.2020.3026785
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900010
PM 33001803
DA 2024-11-06
ER

PT J
AU Cmolík, L
   Pavlovec, V
   Wu, HY
   Nöllenburg, M
AF Cmolik, Ladislav
   Pavlovec, Vaclav
   Wu, Hsiang-Yun
   Noellenburg, Martin
TI Mixed Labeling: Integrating Internal and External Labels
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Labeling; Layout; Three-dimensional displays; Shape; Solid modeling; Two
   dimensional displays; Labeling; mixed labeling; internal labeling;
   external labeling; expert evaluation
AB In this article, we present an algorithm capable of mixed labeling of 2D and 3D objects. In mixed labeling, the given objects are labeled with both internal labels placed (at least partially) over the objects and external labels placed in the space around the objects and connected with the labeled objects with straight-line leaders. The proposed algorithm determines the position and type of each label based on the user-specified ambiguity threshold and eliminates overlaps between the labels, as well as between the internal labels and the straight-line leaders of external labels. The algorithm is a screen-space technique; it operates in an image where the 2D objects or projected 3D objects are encoded. In other words, we can use the algorithm whenever we can render the objects to an image, which makes the algorithm fit for use in many domains. The algorithm operates in real-time, giving the results immediately. Finally, we present results from an expert evaluation, in which a professional illustrator has evaluated the label layouts produced with the proposed algorithm.
C1 [Cmolik, Ladislav; Pavlovec, Vaclav] Czech Tech Univ, Fac Elect Engn, Prague 16000, Czech Republic.
   [Wu, Hsiang-Yun] TU Wien, Inst Visual Comp & Human Ctr Technol, A-1040 Vienna, Austria.
   [Noellenburg, Martin] TU Wien, Inst Log & Computat, A-1040 Vienna, Austria.
C3 Czech Technical University Prague; Technische Universitat Wien;
   Technische Universitat Wien
RP Cmolík, L (corresponding author), Czech Tech Univ, Fac Elect Engn, Prague 16000, Czech Republic.
EM cmolikl@fel.cvut.cz; pavlova1@fel.cvut.cz; hsiang.yun.wu@acm.org;
   noellenburg@ac.tuwien.ac.at
RI Čmolík, Ladislav/GXW-1250-2022; WU, Hsiang-Yun/T-8434-2018
OI WU, Hsiang-Yun/0000-0003-1028-0010; Pavlovec,
   Vaclav/0000-0002-6782-7788; Cmolik, Ladislav/0000-0002-8546-6568;
   Nollenburg, Martin/0000-0003-0454-3937
FU MEYS of Czechia OP VVV-Research Center for Informatics
   [CZ.02.1.01/0.0/0.0/16_019/0000765]; Grant Agency of CTU in Prague
   [SGS19/179/OHK3/3T/13]; EU Horizon 2020 MSCA grant [747985]; Austrian
   Science Fund (FWF) [P 31119]
FX This work was supported by MEYS of Czechia OP VVV grant No.
   CZ.02.1.01/0.0/0.0/16_019/0000765-Research Center for Informatics, Grant
   Agency of CTU in Prague grant No. SGS19/179/OHK3/3T/13, EU Horizon 2020
   MSCA grant No. 747985, and the Austrian Science Fund (FWF) grant P
   31119.
CR [Anonymous], 1999, HUMAN FACTORS COMPUT
   [Anonymous], 2017, INFORM DESIGN RES PR
   Barrault M., 2001, Computers, Environment and Urban Systems, V25, P33, DOI 10.1016/S0198-9715(00)00039-9
   Barth L, 2019, INFORM VISUAL, V18, P110, DOI 10.1177/1473871618799500
   Been K, 2010, COMP GEOM-THEOR APPL, V43, P312, DOI 10.1016/j.comgeo.2009.03.006
   Bekos MA, 2019, COMPUT GRAPH FORUM, V38, P833, DOI 10.1111/cgf.13729
   Bekos MA, 2011, LECT NOTES COMPUT SC, V6543, P111, DOI 10.1007/978-3-642-18381-2_9
   Bekos MA, 2010, COMPUT J, V53, P827, DOI 10.1093/comjnl/bxp087
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   BELLMAN RE, 1970, MANAGE SCI B-APPL, V17, pB141
   Cipriano G, 2008, IEEE T VIS COMPUT GR, V14, P1675, DOI 10.1109/TVCG.2008.168
   Cmolík L, 2019, IEEE T VIS COMPUT GR, V25, P2458, DOI 10.1109/TVCG.2018.2833479
   Cmolík L, 2010, COMPUT GRAPH-UK, V34, P378, DOI 10.1016/j.cag.2010.05.002
   Freeman H, 2005, PATTERN RECOGN LETT, V26, P287, DOI 10.1016/j.patrec.2004.10.023
   Gemsa A., 2014, ACM T SPATIAL ALGORI, V1, P289
   Götzelmann T, 2006, LECT NOTES COMPUT SC, V4073, P24
   Gotzelmann T., 2005, Proceedings of the 13th Pacific Conference of Computer Graphics and Applications, P64
   Gotzelmann Timo., 2005, Computational Aesthetics in Graphics, Visualization and Imaging, P193
   Hartmann K., 2005, Journal of the WSCG, V13, P1
   Hensley J, 2005, COMPUT GRAPH FORUM, V24, P547, DOI 10.1111/j.1467-8659.2005.00880.x
   Huang ZD, 2014, LECT NOTES COMPUT SC, V8344, P44, DOI 10.1007/978-3-319-04657-0_7
   Kouril D, 2019, IEEE T VIS COMPUT GR, V25, P977, DOI 10.1109/TVCG.2018.2864491
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   Löffler M, 2016, J SPAT INT SCI, P3, DOI 10.5311/JOSIS.2016.13.264
   Luboschik M, 2008, IEEE T VIS COMPUT GR, V14, P1237, DOI 10.1109/TVCG.2008.152
   Maass S, 2006, LECT NOTES COMPUT SC, V4073, P1
   Maass S, 2006, WSCG 2006: FULL PAPERS PROCEEDINGS, P327
   Niedermann B, 2017, IEEE PAC VIS SYMP, P295, DOI 10.1109/PACIFICVIS.2017.8031608
   Nielsen J., 1994, USABILITY ENG, DOI [10.1016/B978-0-08052029-2.50010-3, DOI 10.1016/B978-0-08052029-2.50010-3]
   Nollenburg M., 2010, PROC 18 C ADV GEOGRA, P310
   Oeltze-Jafra Steffen, 2014, P 4 EUR WORKSH VIS C, P199, DOI DOI 10.2312/VCBM.20141192
   Prado RD, 2013, INT C COMP AID DES C, P337, DOI 10.1109/CADGraphics.2013.51
   Preim Bernhard, 1995, P COMPUGRAPHICS, P201
   Rong G., 2006, Jump flooding in GPU with applications to Voronoi diagram and distance transform, P109, DOI DOI 10.1145/1111411.1111431
   Ropinski T., 2007, Internal labels as shape cues for medical illustration, P203
   Rylov M, 2017, CARTOGR J, V54, P61, DOI 10.1179/1743277414Y.0000000091
   Scheuermann T, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P33
   Stein T Decoret., 2008, Proceedings of the 6th international symposium on Non-photorealistic animation and rendering, P15, DOI DOI 10.1145/1377980.1377986
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   VANROESSEL JW, 1989, AM CARTOGRAPHER, V16, P201, DOI 10.1559/152304089783814034
   Wu HY, 2011, LECT NOTES COMPUT SC, V6815, P91, DOI 10.1007/978-3-642-22571-0_8
   Yoeli P., 1972, Cartogr J, V9, P99, DOI [DOI 10.1179/000870472787352505, 10.1179/caj.1972.9.2.99, DOI 10.1179/CAJ.1972.9.2.99]
NR 43
TC 4
Z9 5
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1848
EP 1861
DI 10.1109/TVCG.2020.3027368
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900011
PM 32986554
DA 2024-11-06
ER

PT J
AU Su, ZQ
   Wan, WL
   Yu, T
   Liu, LJ
   Fang, L
   Wang, WP
   Liu, YB
AF Su, Zhaoqi
   Wan, Weilin
   Yu, Tao
   Liu, Lingjie
   Fang, Lu
   Wang, Wenping
   Liu, Yebin
TI MulayCap: Multi-Layer Human Performance Capture Using a Monocular Video
   Camera
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Clothing; Geometry; Image reconstruction; Shape; Three-dimensional
   displays; Strain; Solid modeling; Human performance capture; 3D pose
   estimation; cloth animation; non-rigid deformation; intrinsic
   decomposition
ID INTRINSIC IMAGES; SHAPE ESTIMATION; MOTION CAPTURE; TRACKING
AB We introduce MulayCap, a novel human performance capture method using a monocular video camera without the need for pre-scanning. The method uses "multi-layer" representations for geometry reconstruction and texture rendering, respectively. For geometry reconstruction, we decompose the clothed human into multiple geometry layers, namely a body mesh layer and a garment piece layer. The key technique behind is a Garment-from-Video (GfV) method for optimizing the garment shape and reconstructing the dynamic cloth to fit the input video sequence, based on a cloth simulation model which is effectively solved with gradient descent. For texture rendering, we decompose each input image frame into a shading layer and an albedo layer, and propose a method for fusing a fixed albedo map and solving for detailed garment geometry using the shading layer. Compared with existing single view human performance capture systems, our "multi-layer" approach bypasses the tedious and time consuming scanning step for obtaining a human specific mesh template. Experimental results demonstrate that MulayCap produces realistic rendering of dynamically changing details that has not been achieved in any previous monocular video camera systems. Benefiting from its fully semantic modeling, MulayCap can be applied to various important editing applications, such as cloth editing, re-targeting, relighting, and AR applications.
C1 [Su, Zhaoqi; Yu, Tao; Fang, Lu; Liu, Yebin] Tsinghua Univ, Beijing 100084, Peoples R China.
   [Wan, Weilin; Liu, Lingjie; Wang, Wenping] Univ Hong Kong, Hong Kong, Peoples R China.
C3 Tsinghua University; University of Hong Kong
RP Liu, YB (corresponding author), Tsinghua Univ, Beijing 100084, Peoples R China.
EM suzq13@tsinghua.org.cn; weilinwan1223@gmail.com;
   ytrock@mail.tsinghua.edu.cn; liulingjie0206@gmail.com;
   fanglu@sz.tsinghua.edu.cn; Wenping@cs.hku.hk;
   liuyebin@mail.tsinghua.edu.cn
RI Wan, Weilin/KVB-3834-2024; Li, Yan/JRW-0176-2023
OI Su, Zhaoqi/0000-0003-3651-8373
FU Tsinghua University; University of Hong Kong
FX The authors would like to thank Tsinghua University and The University
   of Hong Kong for supporting this work.
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2017, ACM Transactions on Graphics (TOG)
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bogo F, 2015, IEEE I CONF COMP VIS, P2300, DOI 10.1109/ICCV.2015.265
   Bonet J., 1997, Nonlinear Continuum Mechanics for Finite Element Analysis
   Bonneel N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661253
   Bouaziz S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601116
   Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698
   Brostow GJ, 2011, IEEE T PATTERN ANAL, V33, P2104, DOI 10.1109/TPAMI.2011.37
   Brox T, 2010, IEEE T PATTERN ANAL, V32, P402, DOI 10.1109/TPAMI.2009.32
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Casas D, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12296
   Chen XW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818059
   Choi Kwang-Jin., 2005, ACM SIGGRAPH 2005 CO, P1, DOI DOI 10.1145/1198555.1198571
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Danerek R, 2017, COMPUT GRAPH FORUM, V36, P269, DOI 10.1111/cgf.13125
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Duch ^ene S, 2015, ACM T GRAPHIC, V34
   Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x
   Fuhrmann S., 2014, P WORKSH GRAPH CULT, P11, DOI [10.2312/gch.20141299, DOI 10.2312/GCH.20141299]
   Gall J, 2009, PROC CVPR IEEE, P1746, DOI 10.1109/CVPRW.2009.5206755
   Gallardo M, 2017, IEEE I CONF COMP VIS, P3904, DOI 10.1109/ICCV.2017.419
   Garces E, 2012, COMPUT GRAPH FORUM, V31, P1415, DOI 10.1111/j.1467-8659.2012.03137.x
   Gilbert A, 2018, LECT NOTES COMPUT SC, V11215, P591, DOI 10.1007/978-3-030-01252-6_35
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Guo KW, 2015, IEEE I CONF COMP VIS, P3083, DOI 10.1109/ICCV.2015.353
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Habermann Marc., 2018, ReTiCaM: Real-time Human Performance Capture from Monocular Video
   Hasler N, 2010, PROC CVPR IEEE, P1823, DOI 10.1109/CVPR.2010.5539853
   Helten T, 2013, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2013.141
   Huang Z, 2018, LECT NOTES COMPUT SC, V11220, P351, DOI 10.1007/978-3-030-01270-0_21
   Innmann M, 2016, LECT NOTES COMPUT SC, V9912, P362, DOI 10.1007/978-3-319-46484-8_22
   Janner M, 2017, ADV NEUR IN, V30
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Kanazawa A, 2018, LEARNING 3D HUMAN DY
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lähner Z, 2018, LECT NOTES COMPUT SC, V11208, P698, DOI 10.1007/978-3-030-01225-0_41
   Laffont PY, 2015, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2015.57
   Laffont PY, 2013, IEEE T VIS COMPUT GR, V19, P210, DOI 10.1109/TVCG.2012.112
   Lempitsky V, 2007, PROC CVPR IEEE, P829
   Li C, 2018, LECT NOTES COMPUT SC, V11212, P324, DOI 10.1007/978-3-030-01237-3_20
   Li GN, 2013, COMPUT GRAPH FORUM, V32, P275, DOI 10.1111/cgf.12047
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   Liu YB, 2013, IEEE T PATTERN ANAL, V35, P2720, DOI 10.1109/TPAMI.2013.47
   Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Matsushita Y, 2004, LECT NOTES COMPUT SC, V3022, P274
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   Meka A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925907
   Mustafa A, 2015, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2015.109
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Nestmeyer T, 2017, PROC CVPR IEEE, P1771, DOI 10.1109/CVPR.2017.192
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Plänkers R, 2001, COMPUT VIS IMAGE UND, V81, P285, DOI 10.1006/cviu.2000.0891
   Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711
   Popa T, 2009, COMPUT GRAPH FORUM, V28, P427, DOI 10.1111/j.1467-8659.2009.01382.x
   PROVOT X, 1995, GRAPH INTER, P147
   Rogge L, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2634212
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Sigal L., 2008, ADV NEURAL INFORM PR, V20, P1337
   Slavcheva M, 2018, PROC CVPR IEEE, P2646, DOI 10.1109/CVPR.2018.00280
   Slavcheva M, 2017, PROC CVPR IEEE, P5474, DOI 10.1109/CVPR.2017.581
   Song D, 2016, COMPUT GRAPH FORUM, V35, P147, DOI 10.1111/cgf.13012
   Starck J, 2007, IEEE COMPUT GRAPH, V27, P21, DOI 10.1109/MCG.2007.68
   Stoll C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866161
   Tang SC, 2019, IEEE I CONF COMP VIS, P7749, DOI 10.1109/ICCV.2019.00784
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Terzopoulos Demetri, 1987, COMPUTER GRAPHICS PR, V21, P205
   Teukolsky S.A., 2007, Numerical Recipes: the Art of Scientific Computing
   Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Walsman A, 2017, INT CONF 3D VISION, P38, DOI 10.1109/3DV.2017.00015
   Wang Tuanfeng Y., 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3272127.3275074
   Waschbüsch M, 2005, VISUAL COMPUT, V21, P629, DOI 10.1007/s00371-005-0346-7
   White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485
   Wu CL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508418
   Wu CL, 2011, IEEE I CONF COMP VIS, P1108, DOI 10.1109/ICCV.2011.6126358
   Wu CL, 2011, PROC CVPR IEEE, P969, DOI 10.1109/CVPR.2011.5995388
   Xiang DL, 2019, PROC CVPR IEEE, P10957, DOI 10.1109/CVPR.2019.01122
   Xu L, 2020, IEEE T PATTERN ANAL, V42, P2508, DOI 10.1109/TPAMI.2019.2915229
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Xu Y, 2019, INT SYM MIX AUGMENT, P37, DOI 10.1109/ISMAR.2019.00-28
   Yang S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3026479
   Ye GZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601135
   Ye GZ, 2012, LECT NOTES COMPUT SC, V7573, P828, DOI 10.1007/978-3-642-33709-3_59
   Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301
   Yu T, 2019, PROC CVPR IEEE, P5499, DOI 10.1109/CVPR.2019.00565
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Yu T, 2017, IEEE I CONF COMP VIS, P910, DOI 10.1109/ICCV.2017.104
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zhao Q, 2012, IEEE T PATTERN ANAL, V34, P1437, DOI 10.1109/TPAMI.2012.77
   Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhou B, 2013, COMPUT GRAPH FORUM, V32, P85, DOI 10.1111/cgf.12215
   Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 118
TC 11
Z9 11
U1 0
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1862
EP 1879
DI 10.1109/TVCG.2020.3027763
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900012
PM 32991282
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Debarba, HG
   Chague, S
   Charbonnier, C
AF Debarba, Henrique Galvan
   Chague, Sylvain
   Charbonnier, Caecilia
TI On the Plausibility of Virtual Body Animation Features in Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Virtual environments; Avatars; Tracking; Solid modeling;
   Color; Self-representing avatar animation; character animation;
   plausibility illusion; presence; sense of control; agency
ID EMOTION CONTAGION; EMBODIMENT; APPEARANCE; PLACE; SENSE
AB We present two experiments to assess the relative impact of different levels of body animation fidelity on plausibility illusion (Psi). The first experiment presents a virtual character that is not controlled by the user (n=13), while the second experiment presents a user-controlled virtual avatar (n=24, all male). Psi concerns how realistic and coherent the events in a virtual environment look and feel and is part of Slater's proposition of two orthogonal components of presence in virtual reality (VR). In the experiments, the face, hands, upper and lower bodies of the character or self-avatar were manipulated to present different degrees of animation fidelity, such as no animation, procedural animation, and motion captured animation. Participants started the experiment experiencing the best animation configuration. Then, animation features were reduced to limit the amount of captured information made available to the system. Participants had to move from this basic animation configuration towards a more complete one, and declare when the avatar animation realism felt equivalent to the initial and most complete configuration, which could happen before all animation features were maxed out. Participants in the self-avatar experiment were also asked to rate how each animation feature affected their sense of control of the virtual body. We found that a virtual body with upper and lower body animated using eight tracked rigid bodies and inverse kinematics (IK) was often perceived as equivalent to a professional capture pipeline relying on 53 markers. Compared to what standard VR kits in the market are offering, i.e., a tracked headset and two hand controllers, we found that foot tracking, followed by mouth animation and finger tracking, were the features that added the most to the sense of control of a self-representing avatar. In addition, these features were often among the first to be improved in both experiments.
C1 [Debarba, Henrique Galvan] IT Univ Copenhagen, DK-2300 Copenhagen, Denmark.
   [Chague, Sylvain; Charbonnier, Caecilia] Artanim Fdn, CH-1217 Meyrin, Switzerland.
C3 IT University Copenhagen
RP Debarba, HG (corresponding author), IT Univ Copenhagen, DK-2300 Copenhagen, Denmark.
EM hgdebarba@gmail.com; sylvain.chague@artanim.ch;
   caecilia.charbonnier@artanim.ch
RI Galvan Debarba, Henrique/D-8081-2015; Charbonnier,
   Caecilia/HLV-7680-2023
OI Galvan Debarba, Henrique/0000-0003-2090-9409; Charbonnier,
   Caecilia/0000-0002-7018-885X
FU European Commission as part of the H2020 program [762111]; H2020 -
   Industrial Leadership [762111] Funding Source: H2020 - Industrial
   Leadership
FX The authors would like to thank the anonymous reviewers for their
   comments. They also thank Entropy Studio, for directing the cinematic
   capture used in the first experiment. This work was funded by the
   European Commission as part of the H2020 program, under the Grant
   agreement 762111, VRTogether.
CR Azevedo AS, 2015, PRESENCE-TELEOP VIRT, V23, P354, DOI 10.1162/PRES_a_00205
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Dodds TJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025759
   DVgroup, 2017, AL VIRT REAL PLAY
   Franck N, 2001, AM J PSYCHIAT, V158, P454, DOI 10.1176/appi.ajp.158.3.454
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Gao B., 2018, P COMP GRAPH INT 201, P201, DOI DOI 10.1145/3208159.3208171
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hodgins J, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823740
   Hoyet L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508367
   Jeannerod M., 1997, The cognitive neuroscience of action
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E., 2015, P 8 ACM SIGGRAPH C M, P221
   Lang P, 2016, INVERSE KINEMATICS D
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Moore JW, 2009, COGNITION, V110, P279, DOI 10.1016/j.cognition.2008.11.006
   NIELSEN TI, 1963, SCAND J PSYCHOL, V4, P225, DOI 10.1111/j.1467-9450.1963.tb01326.x
   Pra M, 2010, P ACM SIGGRAPH AS SK
   Rubin P, 2018, ENTER DREAMSCAPE LOC
   Skarbez R, 2018, ARXIV181203441
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2003, Presence Conn, V3, P1
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wisessing P., 2016, ACM S APPL PERC, P25, DOI DOI 10.1145/2931002.2931015
   Wu YX, 2014, IEEE T VIS COMPUT GR, V20, P626, DOI 10.1109/TVCG.2014.19
   Zibrek K, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119887
NR 35
TC 9
Z9 9
U1 2
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1880
EP 1893
DI 10.1109/TVCG.2020.3025175
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900013
PM 32946397
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lyu, Q
   Chai, ML
   Chen, X
   Zhou, K
AF Lyu, Qing
   Chai, Menglei
   Chen, Xiang
   Zhou, Kun
TI Real-Time Hair Simulation With Neural Interpolation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Hair; Computational modeling; Interpolation; Data models; Generators;
   Shape; Neural networks; Real-time hair simulation; neural interpolator;
   generative models; computer animation; CNN; GAN
ID DYNAMICS
AB Traditionally, reduced hair simulation methods are either restricted to heuristic approximations or bound to specific hairstyles. We introduce the first CNN-integrated framework for simulating various hairstyles. The approach produces visually realistic hairs with an interactive speed. To address the technical challenges, our hair simulation pipeline is designed as a two-stage process. First, we present a fully-convolutional neural interpolator as the backbone generator to compute dynamic weights for guide hair interpolation. Then, we adopt a second generator to produce fine-scale displacements to enhance the hair details. We train the neural interpolator with a dedicated loss function and the displacement generator with an adversarial discriminator. Experimental results demonstrate that our method is effective, efficient, and superior to the state-of-the-art on a wide variety of hairstyles. We further propose a performance-driven digital avatar system and an interactive hairstyle editing tool to illustrate the practical applications.
C1 [Lyu, Qing; Chen, Xiang; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chai, Menglei] Snap Res, Venice, CA 90291 USA.
C3 Zhejiang University
RP Chen, X (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM lyuqing@zju.edu.cn; cmlatsim@gmail.com; xchen.cs@gmail.com;
   kunzhou@acm.org
RI Zhou, Kun/ITT-3967-2023
OI Chen, Xiang/0000-0002-6955-8729
FU National Natural Science Foundation of China [61772024, 61732016,
   61890954]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was supported in part by the National
   Natural Science Foundation of China (under Grant Nos. 61772024,
   61732016, and 61890954).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   ANJYO K, 1992, COMP GRAPH, V26, P111, DOI 10.1145/142920.134021
   [Anonymous], 2017, ACM T GRAPHIC, DOI DOI 10.1145/3072959.3073623
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bailey SW, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201300
   Bando Y, 2003, COMPUT GRAPH FORUM, V22, P411, DOI 10.1111/1467-8659.00688
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Bertails F., 2008, P ACM SIGGRAPH CLASS
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2017, IEEE T VIS COMPUT GR, V23, P1725, DOI 10.1109/TVCG.2016.2551242
   Chai ML, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601211
   Chang Johnny T., 2002, P 2002 ACM SIGGRAPH, P73
   Choe B., 2005, SCA 05, P153, DOI DOI 10.1145/1073368.1073389
   Chollet F., 2015, KERAS
   Daldegan A., 1993, Computer Graphics Forum, V12, pC211, DOI 10.1111/1467-8659.1230211
   Daviet G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024173
   Derouet-Jourdan A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508398
   Fei Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073630
   Fulton L, 2019, COMPUT GRAPH FORUM, V38, P379, DOI 10.1111/cgf.13645
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hadap S, 2001, COMPUT GRAPH FORUM, V20, pC329, DOI 10.1111/1467-8659.00525
   Kaufman DM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601100
   Kingma D.P., 2014, P INT C LEARNING REP
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu LJ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322969
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Luo R, 2020, IEEE T VIS COMPUT GR, V26, P1745, DOI 10.1109/TVCG.2018.2881451
   McAdams A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531368
   Muller Matthias, 2012, P VRIPHYS, V12, P39
   Olszewski K, 2020, PROC CVPR IEEE, P7444, DOI 10.1109/CVPR42600.2020.00747
   Petrovic L., 2005, VOLUMETRIC METHODS S
   Plante E, 2001, SPRING EUROGRAP, P139
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosenblum R. E., 1991, Journal of Visualization and Computer Animation, V2, P141, DOI 10.1002/vis.4340020410
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Wang LD, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531362
   Ward K, 2003, COMP ANIM CONF PROC, P41, DOI 10.1109/CASA.2003.1199302
   Ward K, 2007, IEEE T VIS COMPUT GR, V13, P213, DOI 10.1109/TVCG.2007.30
   Wu K, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P59, DOI 10.1145/2856400.2856412
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yuksel C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618512
   Zhang M, 2019, VIS INFORM, V3, P102, DOI 10.1016/j.visinf.2019.06.001
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
NR 47
TC 4
Z9 4
U1 0
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1894
EP 1905
DI 10.1109/TVCG.2020.3029823
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900014
PM 33044934
DA 2024-11-06
ER

PT J
AU Qiao, YL
   Lai, YK
   Fu, HB
   Gao, L
AF Qiao, Yi-Ling
   Lai, Yu-Kun
   Fu, Hongbo
   Gao, Lin
TI Synthesizing Mesh Deformation Sequences With Bidirectional LSTM
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Strain; Shape; Three-dimensional displays; Animation; Feature
   extraction; Machine learning; Computer architecture; Mesh deformation;
   mesh sequences; LSTM; deep learning; shape generation
ID INTERPOLATION; SKELETON
AB Synthesizing realistic 3D mesh deformation sequences is a challenging but important task in computer animation. To achieve this, researchers have long been focusing on shape analysis to develop new interpolation and extrapolation techniques. However, such techniques have limited learning capabilities and therefore often produce unrealistic deformation. Although there are already networks defined on individual meshes, deep architectures that operate directly on mesh sequences with temporal information remain unexplored due to the following major barriers: irregular mesh connectivity, rich temporal information, and varied deformation. To address these issues, we utilize convolutional neural networks defined on triangular meshes along with a shape deformation representation to extract useful features, followed by long short-term memory (LSTM) that iteratively processes the features. To fully respect the bidirectional nature of actions, we propose a new share-weight bidirectional scheme to better synthesize deformations. An extensive evaluation shows that our approach outperforms existing methods in sequence generation, both qualitatively and quantitatively.
C1 [Qiao, Yi-Ling; Gao, Lin] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100864, Peoples R China.
   [Qiao, Yi-Ling] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
   [Gao, Lin] Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   University System of Maryland; University of Maryland College Park;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Cardiff University; City University of Hong Kong
RP Gao, L (corresponding author), Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100864, Peoples R China.; Gao, L (corresponding author), Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
EM yilingq97@gmail.com; laiY4@cardiff.ac.uk; hongbofu@cityu.edu.hk;
   gaolin@ict.ac.cn
RI Lai, Yu-Kun/D-2343-2010; Gao, Lin/JNF-0375-2023
OI FU, Hongbo/0000-0002-0284-726X; Lai, Yukun/0000-0002-2094-5680
FU Beijing Program for International S&T Cooperation Project
   [Z191100001619003]; Beijing Municipal Natural Science Foundation
   [L182016]; National Natural Science Foundation of China [61872440,
   61828204]; Royal Society Newton Advanced Fellowship [NAF\R2\192151];
   Youth Innovation Promotion Association CAS; Tencent AI Lab Rhino-Bird
   Focused Research Program [JR202024]
FX This work was supported by Beijing Program for International S&T
   Cooperation Project (No. Z191100001619003), Beijing Municipal Natural
   Science Foundation (No. L182016), National Natural Science Foundation of
   China (No. 61872440 and No. 61828204), Royal Society Newton Advanced
   Fellowship (No. NAFnR2n192151), Youth Innovation Promotion Association
   CAS, Tencent AI Lab Rhino-Bird Focused Research Program(No.JR202024).
CR [Anonymous], 2017, ABS170705363 CORR
   Bianchi FM, 2018, IEEE T NEUR NET LEAR, V29, P427, DOI 10.1109/TNNLS.2016.2630802
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Bowman SR, 2017, P 20 SIGNLL C COMP N, P10, DOI [10.18653/v1/K16-1002, DOI 10.18653/V1/K16-1002]
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Cai HY, 2018, LECT NOTES COMPUT SC, V11206, P374, DOI [10.1007/978-3-030-01216-8_, 10.1007/978-3-030-01216-8_23]
   Cho K., 2014, P 2014 C EMP METH NA, P1724
   Chung J, 2015, ADV NEUR IN, V28
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gao L, 2021, IEEE T VIS COMPUT GR, V27, P2085, DOI 10.1109/TVCG.2019.2941200
   Gao L, 2017, COMPUT GRAPH FORUM, V36, P19, DOI 10.1111/cgf.12991
   Gao L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2908736
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Hansen N, 2001, EVOL COMPUT, V9, P159, DOI 10.1162/106365601750190398
   Huang HB, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12694
   Huber P, 2017, COMPUT AIDED GEOM D, V52-53, P313, DOI 10.1016/j.cagd.2017.02.008
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kingma D.P., 2014, P INT C LEARNING REP
   Kingma DP, 2013, ARXIV
   Levi Z, 2015, IEEE T VIS COMPUT GR, V21, P264, DOI 10.1109/TVCG.2014.2359463
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Lotter W., 2017, ICLR, P1, DOI DOI 10.48550/ARXIV.1605.08104
   Lyu Q, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4138
   Marchi Erik, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2164, DOI 10.1109/ICASSP.2014.6853982
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Mathieu M., 2015, INT C LEARN REPR ICL
   Melamud O., 2016, P 20 SIGNLL C COMPUT, P51, DOI [DOI 10.18653/V1/K16-1006, 10.18653/v1/k16-1006]
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Oh J, 2015, ADV NEUR IN, V28
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Stoll C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866161
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tan QY, 2018, AAAI CONF ARTIF INTE, P2452
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang TY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356512
   Wu JJ, 2016, ADV NEUR IN, V29
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Yan HB, 2008, IEEE T VIS COMPUT GR, V14, P693, DOI 10.1109/TVCG.2008.28
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
NR 51
TC 3
Z9 5
U1 2
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1906
EP 1916
DI 10.1109/TVCG.2020.3028961
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900015
PM 33031040
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Sawada, N
   Uemura, M
   Beyer, J
   Pfister, H
   Fujishiro, I
AF Sawada, Naoko
   Uemura, Makoto
   Beyer, Johanna
   Pfister, Hanspeter
   Fujishiro, Issei
TI TimeTubesX: A Query-Driven Visual Exploration of Observable,
   Photometric, and Polarimetric Behaviors of Blazars
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Feature extraction; Image color analysis;
   Correlation; Three-dimensional displays; Visual analytics; Visual
   analytics; feature extraction; visual query; multi-dimensional;
   time-dependent visualization; astrophysics; blazar
ID GAMMA-RAY
AB Blazars are celestial bodies of high interest to astronomers. In particular, through the analysis of photometric and polarimetric observations of blazars, astronomers aim to understand the physics of the blazar's relativistic jet. However, it is challenging to recognize correlations and time variations of the observed polarization, intensity, and color of the emitted light. In our prior study, we proposed TimeTubes to visualize a blazar dataset as a 3D volumetric tube. In this paper, we build primarily on the TimeTubes representation of blazar datasets to present a new visual analytics environment named TimeTubesX, into which we have integrated sophisticated feature and pattern detection techniques for effective location of observable and recurring time variation patterns in long-term, multi-dimensional datasets. Automatic feature extraction detects time intervals corresponding to well-known blazar behaviors. Dynamic visual querying allows users to search long-term observations for time intervals similar to a time interval of interest (query-by-example) or a sketch of temporal patterns (query-by-sketch). Users are also allowed to build up another visual query guided by the time interval of interest found in the previous process and refine the results. We demonstrate how TimeTubesX has been used successfully by domain experts for the detailed analysis of blazar datasets and report on the results.
C1 [Sawada, Naoko; Fujishiro, Issei] Keio Univ, Yokohama, Kanagawa 2238522, Japan.
   [Uemura, Makoto] Hiroshima Univ, Higashihiroshima 7398511, Japan.
   [Beyer, Johanna; Pfister, Hanspeter] Harvard Univ, Cambridge, MA 02138 USA.
   [Fujishiro, Issei] Hangzhou Dianzi Univ, Hangzhou 310018, Peoples R China.
C3 Keio University; Hiroshima University; Harvard University; Hangzhou
   Dianzi University
RP Sawada, N (corresponding author), Keio Univ, Yokohama, Kanagawa 2238522, Japan.
EM naoko.sawada@fj.ics.keio.ac.jp; uemuram@hiroshima-u.ac.jp;
   jbeyer@seas.harvard.edu; pfister@seas.harvard.edu; fuji@ics.keio.ac.jp
RI Uemura, Makoto/AEF-1123-2022
OI Pfister, Hanspeter/0000-0002-3620-2582; Fujishiro,
   Issei/0000-0002-8898-730X; Uemura, Makoto/0000-0002-7375-7405; Beyer,
   Johanna/0000-0002-3505-9171; Sawada, Naoko/0000-0002-9281-441X
FU MEXT KAKENHI [17H00737]; King Abdullah University of Science and
   Technology (KAUST); KAUST Office of Sponsored Research (OSR)'s Award
   [OSR-2015-CCF-2533-0]
FX The authors have benefited from useful discussions with Mahito Sasada at
   Hiroshima University, Yannis Liodakis at Stanford University, and Alan
   Marscher, Svetlana Jorstad, Manasvita Joshi, and Zachary Weaver at
   Boston University. They would like to thank Carolina Nobre at Harvard
   University for inserting the narration into the accompanying video. The
   present work has been financially supported in part by a MEXT KAKENHI
   Grant-in-Aid for Scientific Research(A) No. 17H00737 and King Abdullah
   University of Science and Technology (KAUST) and the KAUSTOffice of
   Sponsored Research (OSR)'s Award, OSR-2015-CCF-2533-0. Sawada, the first
   author, would also like to thank the Yoshida Scholarship Foundation.
CR Almryde KR, 2015, 2015 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P73
   [Anonymous], 2014, PROC EUROVA INT WORK
   ANTONUCCI R, 1993, ANNU REV ASTRON ASTR, V31, P473, DOI 10.1146/annurev.aa.31.090193.002353
   Atoyan A, 2001, PHYS REV LETT, V87, DOI 10.1103/PhysRevLett.87.221102
   Baines D, 2017, PUBL ASTRON SOC PAC, V129, DOI 10.1088/1538-3873/129/972/028001
   Bednarek W, 1999, MON NOT R ASTRON SOC, V302, P373, DOI 10.1046/j.1365-8711.1999.02132.x
   Bernard J, 2010, INT J DIGIT LIBRARIE, V11, P111, DOI 10.1007/s00799-011-0072-x
   Berndt D.J., 1994, P 3 INT C KNOWL DISC, P359
   Bock A, 2020, IEEE T VIS COMPUT GR, V26, P633, DOI 10.1109/TVCG.2019.2934259
   Bostock, 2020, D3 JS
   Boussejra MO, 2019, VIS INFORM, V3, P1, DOI 10.1016/j.visinf.2019.03.001
   Brown R. G, 1956, P OPS RES SOC AM
   Bruckner S, 2009, IEEE T VIS COMPUT GR, V15, P1497, DOI 10.1109/TVCG.2009.121
   Buono P, 2005, PROC SPIE, V5669, P175, DOI 10.1117/12.587537
   Buono P., 2008, P WORK C ADV VIS INT, P480, DOI DOI 10.1145/1385569.1385666
   Burchett JN, 2019, COMPUT GRAPH FORUM, V38, P491, DOI 10.1111/cgf.13705
   Correll M, 2016, IEEE CONF VIS ANAL, P131, DOI 10.1109/VAST.2016.7883519
   Eichmann Philipp., 2015, Proceedings ofthe 20th International Conference on Intelligent UserInterfaces, P28
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Elmqvist N, 2007, IEEE CONF VIS ANAL, P187, DOI 10.1109/VAST.2007.4389013
   Fujishiro Issei, 2018, Journal of Physics: Conference Series, V1036, DOI 10.1088/1742-6596/1036/1/012011
   Gaur H, 2014, ASTROPHYS J LETT, V781, DOI 10.1088/2041-8205/781/1/L4
   Haroz S, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P207
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Holz C, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P213
   Igarashi T, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P403, DOI 10.1145/2984511.2984537
   Ikejiri Y, 2011, PUBL ASTRON SOC JPN, V63, P639, DOI 10.1093/pasj/63.3.327
   Kent BR, 2017, PUBL ASTRON SOC PAC, V129, DOI 10.1088/1538-3873/aa5fa6
   Lee DJL, 2020, IEEE T VIS COMPUT GR, V26, P1267, DOI 10.1109/TVCG.2019.2934666
   Lehni J., 2020, PAPER JS
   Li HW, 2008, IEEE T VIS COMPUT GR, V14, P1555, DOI 10.1109/TVCG.2008.182
   Mannino M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018)
   Marscher AP, 2008, NATURE, V452, P966, DOI 10.1038/nature06895
   Martin AR, 1995, VISUALIZATION '95 - PROCEEDINGS, P271, DOI 10.1109/VISUAL.1995.485139
   McCurdy N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P276, DOI [10.1109/visual.2019.8933671, 10.1109/VISUAL.2019.8933671]
   Muthumanickam PK, 2016, IEEE CONF VIS ANAL, P121, DOI 10.1109/VAST.2016.7883518
   Nielsen M., 2016, P 28 AUSTR C COMP HU, P381
   Owada S., 2005, PROC I3D, P111, DOI [10.1145/1053427.1053445, DOI 10.1145/1053427.1053445]
   Palshikar G., 2009, P 1 INT C ADV DAT AN, V122
   Preston A, 2016, IEEE PAC VIS SYMP, P48, DOI 10.1109/PACIFICVIS.2016.7465250
   Rouxel B, 2014, LECT NOTES COMPUT SC, V8511, P139, DOI 10.1007/978-3-319-07230-2_14
   Ruochen H, 2019, STUDY MAGNETIC FIELD
   Ruta N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P236, DOI [10.1109/visual.2019.8933618, 10.1109/VISUAL.2019.8933618]
   Ryall K., 2005, P 2005 CHI C HUM FAC, P1765, DOI [10.1145/1056808.10570172, DOI 10.1145/1056808.10570172]
   Sasada M, 2012, PUBL ASTRON SOC JPN, V64, DOI 10.1093/pasj/64.3.58
   Sawada N, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P67, DOI 10.1109/SciVis.2018.8823802
   Shokoohi-Yekta M., 2015, P 2015 SIAM INT C DA, P289, DOI DOI 10.1137/1.9781611974010.33
   three.js, 2020, 3 JS
   Tzeng FY, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P505, DOI 10.1109/VISUAL.2003.1250413
   Uemura M, 2017, PUBL ASTRON SOC JPN, V69, DOI 10.1093/pasj/psx111
   Uemura M, 2016, GALAXIES, V4, DOI 10.3390/galaxies4030023
   Wattenberg M., 2001, P 2001 CHI C HUM FAC, P381, DOI DOI 10.1145/634067.6342922
NR 52
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1917
EP 1929
DI 10.1109/TVCG.2020.3025090
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900016
PM 32946396
DA 2024-11-06
ER

PT J
AU Danyluk, K
   Ulusoy, T
   Wei, W
   Willett, W
AF Danyluk, Kurtis
   Ulusoy, Teoman
   Wei, Wei
   Willett, Wesley
TI Touch and Beyond: Comparing Physical and Virtual Reality Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Tools; Three-dimensional displays; Virtual reality;
   Bars; Task analysis; Visualization; Human-computer interaction;
   visualization; data visualization; virtual reality; physicalization
ID DISPLAYS; CAVE
AB We compare physical and virtual reality (VR) versions of simple data visualizations and explore how the addition of virtual annotation and filtering tools affects how viewers solve basic data analysis tasks. We report on two studies, inspired by previous examinations of data physicalizations. The first study examines differences in how viewers interact with physical hand-scale, virtual hand-scale, and virtual table-scale visualizations and the impact that the different forms had on viewer's problem solving behavior. A second study examines how interactive annotation and filtering tools might support new modes of use that transcend the limitations of physical representations. Our results highlight challenges associated with virtual reality representations and hint at the potential of interactive annotation and filtering tools in VR visualizations.
C1 [Danyluk, Kurtis; Ulusoy, Teoman; Wei, Wei; Willett, Wesley] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
C3 University of Calgary
RP Danyluk, K (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
EM kdanylu@ucalgary.ca; ttulusoy@ucalgary.ca; wei.wei2@ucalgary.ca;
   wesley.willett@ucalgary.ca
OI Wei, Wei/0000-0003-0780-1276; Danyluk, Kurtis/0000-0002-7957-5223
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN2016-04564]; Mitacs Globalink Internship
FX The authors wish to thank our participants as well as the members of the
   Data Experience Lab for their help constructing the Lego charts. This
   work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada (NSERC) [RGPIN2016-04564] and a Mitacs
   Globalink Internship.
CR Andrews C, 2011, INFORM VISUAL, V10, P341, DOI 10.1177/1473871611415997
   [Anonymous], Google
   [Anonymous], 2017, PUBL MAN AM PSYCH AS, V6th
   [Anonymous], 2013, Evaluating the Efciency of Physical Visualizations, DOI DOI 10.1145/2470654.2481359
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Barlow J., 2012, AIRFIELD ATLANTA INT
   Berard F, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4396, DOI 10.1145/3025453.3025806
   Burdett Richard., 2007, GLOBAL CITIES ELEVAT
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Demiralp Ç, 2006, IEEE T VIS COMPUT GR, V12, P323, DOI 10.1109/TVCG.2006.42
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Dragicevic Pierre, 2014, CHI 14 HUM FACT COMP, P607, DOI DOI 10.1145/2559206.2578881
   Follmer S., 2013, P 26 ANN ACM S US IN, V13, P417, DOI [10.1145/2501988.2502032, DOI 10.1145/2501988.2502032]
   Goods D., 2007, ECLOUD
   GUIARD Y, 1987, J MOTOR BEHAV, V19, P486
   Gusai E, 2017, LECT NOTES COMPUT SC, V10590, P290, DOI 10.1007/978-3-319-70742-6_27
   Han SC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201399
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hogan Trevor, 2012, Haptic and Audio Interaction Design. Proceedings 7th International Conference, HAID 2012, P141, DOI 10.1007/978-3-642-32796-4_15
   Ivanov A, 2019, IEEE COMPUT GRAPH, V39, P19, DOI 10.1109/MCG.2019.2898941
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jansen Y, 2016, IEEE T VIS COMPUT GR, V22, P479, DOI 10.1109/TVCG.2015.2467951
   Jungblut Michael, 2013, LIVING FUTURE DEMOGR
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Leithinger D, 2010, TEI 2010, P221
   Lindley SE, 2017, COMPUT SUPP COOP W J, V26, P135, DOI 10.1007/s10606-017-9263-3
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Olshannikova E., 2015, J BIG DATA-GER, V2, P22
   Perin C, 2019, CARTOGR GEOGR INF SC, V46, P176, DOI 10.1080/15230406.2018.1470942
   Sauvé K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376312
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Stusak S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3247, DOI 10.1145/2702123.2702248
   Sutherland I. E., 1968, P DEC 9 11 1968 FA 1, P757, DOI [https://doi.org/10.1145/1476589.1476686, DOI 10.1145/1476589.1476686]
   Taher F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3237, DOI 10.1145/2702123.2702604
   Tang S. K., 2013, Tangible Cityscape
   Theart RP, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1446-2
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
NR 41
TC 16
Z9 18
U1 2
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1930
EP 1940
DI 10.1109/TVCG.2020.3023336
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900017
PM 32915741
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Chen, CJ
   Wu, J
   Wang, XH
   Xiang, SX
   Zhang, SH
   Tang, QF
   Liu, SX
AF Chen, Changjian
   Wu, Jing
   Wang, Xiaohan
   Xiang, Shouxing
   Zhang, Song-Hai
   Tang, Qifeng
   Liu, Shixia
TI Towards Better Caption Supervision for Object Detection
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Detectors; Annotations; Object detection; Visualization; Training;
   Labeling; Noise measurement; Machine learning; interactive
   visualization; object detection; caption supervision; co-clustering
ID VISUAL ANALYTICS
AB As training high-performance object detectors requires expensive bounding box annotations, recent methods resort to free-available image captions. However, detectors trained on caption supervision perform poorly because captions are usually noisy and cannot provide precise location information. To tackle this issue, we present a visual analysis method, which tightly integrates caption supervision with object detection to mutually enhance each other. In particular, object labels are first extracted from captions, which are utilized to train the detectors. Then, the objects detected from images are fed into caption supervision for further improvement. To effectively loop users into the object detection process, a node-link-based set visualization supported by a multi-type relational co-clustering algorithm is developed to explain the relationships between the extracted labels and the images with detected objects. The co-clustering algorithm clusters labels and images simultaneously by utilizing both their representations and their relationships. Quantitative evaluations and a case study are conducted to demonstrate the efficiency and effectiveness of the developed method in improving the performance of object detectors.
C1 [Chen, Changjian; Xiang, Shouxing; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff CF10 3AT, Wales.
   [Wang, Xiaohan] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Tang, Qifeng] Shanghai Lianshu IoT Co Ltd, Shanghai 200072, Peoples R China.
C3 Tsinghua University; Cardiff University; Zhejiang University; Tsinghua
   University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM chencjgene@gmail.com; wuj11@cardiff.ac.uk; wxh1996111@gmail.com;
   xsx1996@163.com; shz@tsinghua.edu.cn; keven@iotsh.com.cn;
   shixia@tsinghua.edu.cn
RI Tang, Qi/KSL-8607-2024; Wang, Xiaohan/JKI-4414-2023; Chen,
   Changjian/KBA-9462-2024; Liu, Shi-Xia/C-5574-2016
OI Wu, Jing/0000-0001-5123-9861; Liu, Shi-Xia/0000-0001-6104-4320; Chen,
   Changjian/0000-0003-2715-8839
CR Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   [Anonymous], 2011, P 44 HAW INT C SYST, DOI DOI 10.1109/HICSS.2011.339
   Arazo E., 2020, IEEE IJCNN, P1
   Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Bochkovskiy A, YOLOV4 OPTIMAL SPEED
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen Y., 2021, P IEEE CVF C COMP VI, P9563
   Damen D, 2018, LECT NOTES COMPUT SC, V11208, P753, DOI 10.1007/978-3-030-01225-0_44
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dingwall N., 2018, C N AM CHAPT ASS COM, P212, DOI [10.18653/v1/N18-2034, DOI 10.18653/V1/N18-2034]
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Felix C, 2018, IEEE T VIS COMPUT GR, V24, P657, DOI 10.1109/TVCG.2017.2746018
   Furnas G. W., 1986, SIGCHI Bull, V17, P16, DOI DOI 10.1145/22339.22342
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Guan Chaoyu, 2019, INT C MACH LEARN, P2454
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Jeong J, 2019, ADV NEUR IN, V32
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Khayat M, 2020, IEEE T VIS COMPUT GR, V26, P874, DOI 10.1109/TVCG.2019.2934266
   Kumar M., 2010, P NIPS, V23
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lei N, 2020, ENGINEERING-PRC, V6, P361, DOI 10.1016/j.eng.2019.09.010
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long B., 2010, Relational Data Clustering: Models
   Long B., 2006, P 23 INT C MACH LEAR, P585, DOI [10.1145/1143844.1143918, DOI 10.1145/1143844.1143918]
   Moehrmann J, 2011, LECT NOTES COMPUT SC, V6761, P618, DOI 10.1007/978-3-642-21602-2_67
   Park JH, 2016, IEEE CONF VIS ANAL, P21, DOI 10.1109/VAST.2016.7883508
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Ren S., 2015, PROC ADVNEURAL INF P, P91
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen Y., 2020, P 34 INT C NEUR INF, P7005
   Snyder LS, 2020, IEEE T VIS COMPUT GR, V26, P558, DOI 10.1109/TVCG.2019.2934614
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/vast47406.2019.8986917, 10.1109/VAST47406.2019.8986917]
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Thinsungnoen T., 2015, P 3 INT C IND APPL E, P44, DOI [10.12792/iciae2015.012, DOI 10.12792/ICIAE2015.012]
   Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489
   Wang KZ, 2018, PROC CVPR IEEE, P1605, DOI 10.1109/CVPR.2018.00173
   Wang YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9072, DOI 10.1109/ICCV48922.2021.00896
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yandong Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P589, DOI 10.1007/978-3-030-58526-6_35
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Ye KR, 2019, IEEE I CONF COMP VIS, P9685, DOI 10.1109/ICCV.2019.00978
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
NR 56
TC 10
Z9 13
U1 0
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1941
EP 1954
DI 10.1109/TVCG.2021.3138933
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900018
PM 34962870
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Athawale, TM
   Maljovec, D
   Yan, L
   Johnson, CR
   Pascucci, V
   Wang, B
AF Athawale, Tushar M.
   Maljovec, Dan
   Yan, Lin
   Johnson, Chris R.
   Pascucci, Valerio
   Wang, Bei
TI Uncertainty Visualization of 2D Morse Complex Ensembles Using
   Statistical Summary Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Morse complexes; uncertainty visualization; topological data analysis
ID CRITICAL-POINTS; NONPARAMETRIC MODELS; FLOW VISUALIZATION; SMALE
   COMPLEXES; TOPOLOGY; SIMULATION; ERRORS
AB Morse complexes are gradient-based topological descriptors with close connections to Morse theory. They are widely applicable in scientific visualization as they serve as important abstractions for gaining insights into the topology of scalar fields. Data uncertainty inherent to scalar fields due to randomness in their acquisition and processing, however, limits our understanding of Morse complexes as structural abstractions. We, therefore, explore uncertainty visualization of an ensemble of 2D Morse complexes that arises from scalar fields coupled with data uncertainty. We propose several statistical summary maps as new entities for quantifying structural variations and visualizing positional uncertainties of Morse complexes in ensembles. Specifically, we introduce three types of statistical summary maps - the probabilistic map, the significance map, and the survival map - to characterize the uncertain behaviors of gradient flows. We demonstrate the utility of our proposed approach using wind, flow, and ocean eddy simulation datasets.
C1 [Athawale, Tushar M.; Maljovec, Dan; Yan, Lin; Johnson, Chris R.; Pascucci, Valerio; Wang, Bei] Univ Utah, Sci Comp & Imaging SCI Inst, Salt Lake City, UT 84112 USA.
C3 Utah System of Higher Education; University of Utah
RP Athawale, TM (corresponding author), Univ Utah, Sci Comp & Imaging SCI Inst, Salt Lake City, UT 84112 USA.
EM tushar.athawale@sci.utah.edu; maljovec@sci.utah.edu;
   linyan@sci.utah.edu; crj@sci.utah.edu; pascucci@sci.utah.edu;
   beiwang@sci.utah.edu
RI Yan, Lin/HJY-9781-2023; pascucci, Valerio/GXF-0616-2022
OI pascucci, valerio/0000-0002-8877-2042; Yan, Lin/0000-0001-7017-0329;
   Athawale, Tushar/0000-0003-3163-6274
FU NIH [P41 GM103545-18, R24 GM136986]; Intel Graphics and Visualization
   Institutes of XeLLENCE; DOE [DE-FE0031880];  [IIS-1910733]; 
   [DBI-1661375];  [IIS-1513616]; National Institute of General Medical
   Sciences [R24GM136986] Funding Source: NIH RePORTER
FX This work is supported in part by IIS-1910733, DBI-1661375, and
   IIS-1513616; the NIH Grants P41 GM103545-18 and R24 GM136986; the DOE
   Grant DE-FE0031880; and the Intel Graphics and Visualization Institutes
   of XeLLENCE.
CR Ackley D.H., 1987, CONNECTIONIST MACHIN
   Athawale T, 2019, IEEE T VIS COMPUT GR, V25, P1163, DOI 10.1109/TVCG.2018.2864505
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Beucher S., 1993, Mathematical Morphology in Image Processing, V12, P433
   Bhatia H, 2012, IEEE T VIS COMPUT GR, V18, P1383, DOI 10.1109/TVCG.2011.265
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bremer PT, 2015, COMPUT VIS SCI, V17, P1, DOI 10.1007/s00791-015-0241-3
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Camarri Simone., 2005, XVII Congresso AIMeTA di Meccanica Teorica e Applicata, Volume II, V1, P23
   Chen YC, 2017, ELECTRON J STAT, V11, P1390, DOI 10.1214/17-EJS1271
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   G_unther D., 2014, Topological Methods in Data Analysis and Visualization, VIII, P135
   Gerber S, 2013, J COMPUT GRAPH STAT, V22, P193, DOI 10.1080/10618600.2012.657132
   Gerber S, 2010, IEEE T VIS COMPUT GR, V16, P1271, DOI 10.1109/TVCG.2010.213
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Gyulassy A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P535
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hoteit I, 2013, DYNAM ATMOS OCEANS, V63, P1, DOI 10.1016/j.dynatmoce.2013.03.002
   Huettenberger L, 2013, COMPUT GRAPH FORUM, V32, P341, DOI 10.1111/cgf.12121
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kraus M, 2010, IMAGAPP & IVAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS, P132
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liebmann T, 2016, COMPUT GRAPH FORUM, V35, P361, DOI 10.1111/cgf.12912
   Maljovec D, 2016, IEEE PAC VIS SYMP, P64, DOI 10.1109/PACIFICVIS.2016.7465252
   Mihai M, 2014, COMPUT GRAPH-UK, V41, P13, DOI 10.1016/j.cag.2014.01.007
   Milnor J, 1963, MORSE THEORY AM 51, V51, DOI [DOI 10.1515/9781400881802, 10.1515/9781400881802]
   Morse M, 1925, T AM MATH SOC, V27, P345, DOI 10.2307/1989110
   Nagaraj S., 2011, P EUROGRAPHICS IEEE, V30
   Otto M, 2011, IEEE PAC VIS SYMP, P67, DOI 10.1109/PACIFICVIS.2011.5742374
   Otto M, 2010, COMPUT GRAPH FORUM, V29, P347, DOI 10.1111/j.1467-8659.2009.01604.x
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Potter K, 2010, COMPUT GRAPH FORUM, V29, P823, DOI 10.1111/j.1467-8659.2009.01677.x
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Potter K, 2012, INT J UNCERTAIN QUAN, V2, P397, DOI 10.1615/Int.J.UncertaintyQuantification.2012004074
   Reininghaus J, 2012, IEEE T VIS COMPUT GR, V18, P1563, DOI 10.1109/TVCG.2011.269
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Shusen Liu, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P73, DOI 10.1109/LDAV.2012.6378978
   Sivareddy S., 2020, J GEOPHYS RES-OCEANS, V125
   SMALE S, 1961, ANN MATH, V74, P199, DOI 10.2307/1970311
   Thompson D., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P23, DOI 10.1109/LDAV.2011.6092313
   Vitart F, 2017, B AM METEOROL SOC, V98, P163, DOI 10.1175/BAMS-D-16-0017.1
   von Funck W, 2008, IEEE T VIS COMPUT GR, V14, P1396, DOI 10.1109/TVCG.2008.163
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wei Zhang, 2015, 2015 23rd International Conference on Geoinformatics. Proceedings, P1, DOI 10.1109/GEOINFORMATICS.2015.7378551
   Weissenböck J, 2019, IEEE T VIS COMPUT GR, V25, P1040, DOI 10.1109/TVCG.2018.2864510
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Zhan P, 2019, GEOPHYS RES LETT, V46, P2167, DOI 10.1029/2018GL081387
NR 63
TC 7
Z9 8
U1 0
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1955
EP 1966
DI 10.1109/TVCG.2020.3022359
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900019
PM 32897861
OA Bronze, Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Henkin, R
   Turkay, C
AF Henkin, Rafael
   Turkay, Cagatay
TI Words of Estimative Correlation: Studying Verbalizations of Scatterplots
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Correlation; Task analysis; Data analysis; Taxonomy;
   Natural language processing; Information visualization; natural language
   generation; natural language processing; human-computer interaction
ID RANKING VISUALIZATIONS; LANGUAGE; PERCEPTION
AB Natural language and visualization are being increasingly deployed together for supporting data analysis in different ways, from multimodal interaction to enriched data summaries and insights. Yet, researchers still lack systematic knowledge on how viewers verbalize their interpretations of visualizations, and how they interpret verbalizations of visualizations in such contexts. We describe two studies aimed at identifying characteristics of data and charts that are relevant in such tasks. The first study asks participants to verbalize what they see in scatterplots that depict various levels of correlations. The second study then asks participants to choose visualizations that match a given verbal description of correlation. We extract key concepts from responses, organize them in a taxonomy and analyze the categorized responses. We observe that participants use a wide range of vocabulary across all scatterplots, but particular concepts are preferred for higher levels of correlation. A comparison between the studies reveals the ambiguity of some of the concepts. We discuss how the results could inform the design of multimodal representations aligned with the data and analytical tasks, and present a research roadmap to deepen the understanding about visualizations and natural language.
C1 [Henkin, Rafael] Queen Mary Univ London, Ctr Translat Bioinformat, London E1 4NS, England.
   [Turkay, Cagatay] Univ Warwick, Ctr Interdisciplinary Methodol, Coventry CV4 7AL, W Midlands, England.
C3 University of London; Queen Mary University London; University of
   Warwick
RP Henkin, R (corresponding author), Queen Mary Univ London, Ctr Translat Bioinformat, London E1 4NS, England.
EM r.henkin@qmul.ac.uk; cagatay.turkay@warwick.ac.uk
RI Turkay, Cagatay/AAA-3810-2020
OI Turkay, Cagatay/0000-0001-6788-251X; Henkin, Rafael/0000-0002-5511-5230
FU UK Engineering and Physical Sciences Research Council (EPSRC)
   [EP/P025501/1]; EPSRC [EP/P025501/1] Funding Source: UKRI
FX RH performed this worked while with the giCentre, City, University of
   London. The authors would like to thank Johannes Liem for helping to set
   up the online studies and discussions and Radu Jianu for helpful
   comments. This work was supported by the UK Engineering and Physical
   Sciences Research Council (EPSRC) with Grant number EP/P025501/1.
CR [Anonymous], 2008, Artifacts in behavioral research: Robert Rosenthal and Ralph L. Rosnows classic books
   [Anonymous], 2018, P WORKSH VIS AI EXPL
   Basseville M, 2013, SIGNAL PROCESS, V93, P621, DOI 10.1016/j.sigpro.2012.09.003
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Bird S., 2009, NATURAL LANGUAGE PRO
   BOBKO P, 1979, PERS PSYCHOL, V32, P313, DOI 10.1111/j.1744-6570.1979.tb02137.x
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Fast E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174047
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Hauke J, 2011, QUAEST GEOGR, V30, P87, DOI 10.2478/v10117-011-0021-1
   Hearst M., 2019, 2019 IEEE VISUALIZAT, P1
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Heer J., 2012, P SIGCHI C HUM FACT, P1007, DOI [DOI 10.1145/2207676.22085472,4, 10.1145/2207676.2208547, DOI 10.1145/2207676.2208547, 10.1145/2207676.22085472,4]
   Hervás R, 2013, INFORM PROCESS MANAG, V49, P817, DOI 10.1016/j.ipm.2013.01.006
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Jain A, 2015, IEEE ENG MED BIO, P7634, DOI 10.1109/EMBC.2015.7320160
   James G, 2013, SPRINGER TEXTS STAT, V103, P15, DOI 10.1007/978-1-4614-7138-7_2
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Kent S., 1964, STUDIES INTELLIGENCE, V8, P49
   Kim Joo-Kyung., 2016, ACL 2016 workshop on Representation Learning for NLP (RepL4NLP), P62, DOI DOI 10.18653/V1/W16-1607
   Kim Y., 2019, P 21 EUR C VIS, P31
   Krahmer E, 2012, COMPUT LINGUIST, V38, P173, DOI 10.1162/COLI_a_00088
   Latif S, 2019, VIS INFORM, V3, P27, DOI 10.1016/j.visinf.2019.03.004
   Liu S., 2010, Proceedings 2010 IEEE Spoken Language Technology Workshop (SLT 2010), P223, DOI 10.1109/SLT.2010.5700855
   Manning C., 1999, Foundations of Statistical Natural Language Processing
   Mitchell M, 2014, Proceedings of the INLG and SIGDIAL 2014 Joint Session, P172, DOI DOI 10.3115/V1/W14-5003
   Mitchell M., 2013, P 2013 C N AM CHAPT, P1174
   Mumtaz H, 2020, IEEE T VIS COMPUT GR, V26, P1129, DOI 10.1109/TVCG.2019.2934669
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   POLLACK I, 1960, J EXP PSYCHOL, V59, P351, DOI 10.1037/h0042245
   Reiter E, 2003, J ARTIF INTELL RES, V18, P491, DOI 10.1613/jair.1176
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Sher V, 2017, COMPUT GRAPH FORUM, V36, P61, DOI 10.1111/cgf.13168
   Skylark WJ, 2018, JUDGM DECIS MAK, V13, P547
   Srinivasan A., 2017, EUR IEEE VGTC C VIS, P55, DOI 10.2312/eurovisshort.20171133
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Sun YW, 2010, LECT NOTES COMPUT SC, V6133, P184
   Toutanova K, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P252, DOI 10.3115/1073445.1073478
   Vaismoradi M, 2013, NURS HEALTH SCI, V15, P398, DOI 10.1111/nhs.12048
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
NR 50
TC 2
Z9 2
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2022
VL 28
IS 4
BP 1967
EP 1981
DI 10.1109/TVCG.2020.3023537
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ZH9CR
UT WOS:000761227900020
PM 32915742
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Yu, K
   Eck, U
   Pankratz, F
   Lazarovici, M
   Wilhelm, D
   Navab, N
AF Yu, Kevin
   Eck, Ulrich
   Pankratz, Frieder
   Lazarovici, Marc
   Wilhelm, Dirk
   Navab, Nassir
TI Duplicated Reality for Co-located Augmented Reality Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Collaboration; Task analysis; Three-dimensional displays; Real-time
   systems; Surgery; Annotations; Image reconstruction; User Interaction;
   Mixed Reality; 3D Reconstruction
ID RECONSTRUCTION
AB When two or more users attempt to collaborate in the same space with Augmented Reality, they often encounter conflicting intentions regarding the occupation of the same working area and self-positioning around such without mutual interference. Augmented Reality is a powerful tool for communicating ideas and intentions during a co-assisting task that requires multi-disciplinary expertise. To relax the constraint of physical co-location, we propose the concept of Duplicated Reality, where a digital copy of a 3D region of interest of the users' environment is reconstructed in real-time and visualized in-situ through an Augmented Reality user interface. This enables users to remotely annotate the region of interest while being co-located with others in Augmented Reality. We perform a user study to gain an in-depth understanding of the proposed method compared to an in-situ augmentation, including collaboration, effort, awareness, usability, and the quality of the task. The result indicates almost identical objective and subjective results, except a decrease in the consulting user's awareness of co-located users when using our method. The added benefit from duplicating the working area into a designated consulting area opens up new interaction paradigms to be further investigated for future co-located Augmented Reality collaboration systems.
C1 [Yu, Kevin; Wilhelm, Dirk] Tech Univ Munich, Univ Hosp Rechts Isar, Munich, Germany.
   [Pankratz, Frieder; Lazarovici, Marc] Ludwig Maximilians Univ Munchen, Inst Emergency Med, Munich, Germany.
   [Eck, Ulrich; Navab, Nassir] Tech Univ Munich, Chair Comp Aided Med Procedure, Munich, Germany.
C3 Technical University of Munich; University of Munich; Technical
   University of Munich
RP Yu, K (corresponding author), Tech Univ Munich, Univ Hosp Rechts Isar, Munich, Germany.
EM kevin.yu@tum.de
RI Wilhelm, Dirk/JZC-9499-2024
OI Wilhelm, Dirk/0000-0002-2972-9802; Lazarovici, Marc/0000-0003-2694-810X
FU German Federal Ministry of Education and Research (BMBF) [16SV8092,
   16SV8090, 16SV8088]
FX This work was funded by the German Federal Ministry of Education and
   Research (BMBF), Grant No.: 16SV8092, 16SV8090, 16SV8088.
CR Ames Christopher P, 2013, Spine Deform, V1, P51, DOI 10.1016/j.jspd.2012.10.004
   Andrew M., 2011, International Conference on Artificial reality and telexistance, P4
   [Anonymous], 1994, P 1 INT C MED ROB CO
   [Anonymous], 3D OBJECT SCANNER AR
   Baird K. M., 1999, Virtual Reality, V4, P250, DOI 10.1007/BF01421808
   Barrera-Machuca Mayra D., 2020, UIST '20: 33rd Annual ACM Symposium on User Interface Software and Technology, P73, DOI 10.1145/3379350.3416190
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Bellarbi A, 2017, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL 2017 (ACM VRIC), DOI 10.1145/3110292.3110310
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bifulco P, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-153
   Billinghurst M., 2002, Virtual Reality, V6, P107, DOI 10.1007/s100550200012
   Billinghurst M., 2002, INT J HUMAN COMPUTER
   Bluff A., 2019, 17 INT C VIRT REAL C, P1
   Broll W., 2004, JVRB - Journal of Virtual Reality and Broadcasting, V1, P1, DOI [10.20385/1860-2037/1.2004.1, DOI 10.20385/1860-2037/1.2004.1]
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Chang YS, 2017, IEEE SYMP 3D USER, P182, DOI 10.1109/3DUI.2017.7893337
   Cheng I, 2020, J NEUROSURG-SPINE, V33, P560, DOI 10.3171/2020.3.SPINE2016
   Clark J., 1924, AM J PHYSL OPTICS
   Coffey D., 2011, S INTERACTIVE 3D GRA, P191
   Davis MJ, 2021, SURG-J R COLL SURG E, V19, P49, DOI 10.1016/j.surge.2020.02.005
   Gamelin G, 2021, PERS UBIQUIT COMPUT, V25, P467, DOI 10.1007/s00779-020-01431-1
   Gao L., 2016, SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Applications, p8:1
   Grasset R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P90
   Gupta MC, 2015, SPINE, V40, pE1169, DOI 10.1097/BRS.0000000000001107
   Haddock NT, 2018, MICROSURG, V38, P14, DOI 10.1002/micr.30191
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hirose M., MULTISCALE MANIPULAT
   Huang YT, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR-AMH.2009.5336752
   Irlitti A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P31, DOI [10.1109/ISMAR-Adjunct.2016.25, 10.1109/ISMAR-Adjunct.2016.0032]
   Jun H, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P665, DOI [10.1109/VRW50115.2020.00183, 10.1109/VRW50115.2020.00-92]
   Kang HJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P275, DOI [10.1109/VR46266.2020.00047, 10.1109/VR46266.2020.00-57]
   Kasahara S, 2012, SIGGRAPH ASIA 2012 E, P1, DOI DOI 10.1145/2407707.2407727
   Kolkmeier J, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281542
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Ladwig P., 2018, International conference on remote engineering and virtual instrumentation, P591
   Lewis J.R., 2009, LECT NOTES COMPUTER, V5619, P94, DOI DOI 10.1007/978-3-642-02806-9_12
   Lukosch S, 2015, COMPUT SUPP COOP W J, V24, P515, DOI 10.1007/s10606-015-9239-0
   Machuca MDB, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364254
   Machuca MDB, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P36, DOI 10.1145/3267782.3267786
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P217, DOI [10.1109/ISMAR50242.2020.00045, 10.1109/1SMA1R50242.2020.00045]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mulloni A, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P212, DOI 10.1145/2254556.2254595
   Mummaneni PV, 2008, NEUROSURGERY, V63, pA171, DOI 10.1227/01.NEU.0000325680.32776.82
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piekarski W., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P19, DOI 10.1145/769953.769956
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Qiu C., 2019, Virtual Real. Intell. Hardw, V1, P597, DOI [10.1016/j.vrih.2019.10.002, DOI 10.1016/J.VRIH.2019.10.002]
   Ranatunga D, 2013, INT SYM MIX AUGMENT
   Regenbrecht H, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P90, DOI 10.1109/ISMAR.2017.26
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Renner R., 2014, IN PRESS, V2014
   Roth D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P693, DOI 10.1109/VRW52623.2021.00229
   Salzmann H., 2009, P 15 JOINT VIRT REAL, P85
   Schafer W. A., 2004, Virtual Reality, V7, P164, DOI 10.1007/s10055-004-0123-3
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Stotko P., 2019, CVPR WORKSHOP COMPUT, V3
   Stotko P, 2019, IEEE T VIS COMPUT GR, V25, P2102, DOI 10.1109/TVCG.2019.2899231
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Tang A., 2014, C HUM FACT COMP SYST, V5, P73, DOI DOI 10.1145/642611.642626
   Truman S., 2020, INT C FDN DIGITAL GA, P19
   Tsai R. Y., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P554, DOI 10.1109/ROBOT.1988.12110
   TUCERYAN M, 1995, IEEE T VIS COMPUT GR, V1, P255, DOI 10.1109/2945.466720
   Vidal-Balea A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10249073
   Wang S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102294
   Wang TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1221, DOI [10.1109/VR.2019.8798044, 10.1109/vr.2019.8798044]
   Weibel N., 2020, 2020 CHI C HUM FACT, P1
   Wellek S., 2002, Testing Statistical Hypotheses of Equivalence
   Wilson AD, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P100, DOI 10.1145/3132272.3134144
   Wingrave CA, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P11, DOI 10.1109/TRIDUI.2006.1618264
   Yang MD, 2013, AUTOMAT CONSTR, V33, P48, DOI 10.1016/j.autcon.2012.09.017
   Young J., 2020, P ACM INTERACTIVE MO, V4, P1
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
NR 78
TC 22
Z9 23
U1 1
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2190
EP 2200
DI 10.1109/TVCG.2022.3150520
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400031
PM 35148264
DA 2024-11-06
ER

PT J
AU Zhang, WX
   Han, B
   Hui, P
AF Zhang, Wenxiao
   Han, Bo
   Hui, Pan
TI SEAR: Scaling Experiences in Multi-user Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalability; Task analysis; Collaboration; Servers; Image edge
   detection; Mobile handsets; Annotations; Augmented Reality (AR);
   Multi-user AR; Edge-assisted AR; Scalability; User Experience; Latency
AB In this paper, we present the design, implementation, and evaluation of SEAR, a collaborative framework for Scaling Experiences in multi-user Augmented Reality (AR). Most AR systems benefit from computer vision (CV) algorithms to detect, classify, or recognize physical objects for augmentation. A widely used acceleration method for mobile AR is to offload the compute-intensive tasks (e.g., CV algorithms) to the network edge. However, we show that the end-to-end latency, an important metric of mobile AR, may dramatically increase when offloading AR tasks from a large number of concurrent users to the edge. SEAR tackles this scalability issue through the innovation of a lightweight collaborative local caching scheme. Our key observation is that nearby AR users may share some common interests, and may even have overlapped views to augment (e.g., when playing a multi-user AR game). Thus, SEAR opportunistically exchanges the results of offloaded AR tasks among users when feasible and leverages compute resources on mobile devices to relieve, if necessary, the edge workload by intelligently reusing these results. We build a prototype of SEAR to demonstrate its efficacy in scaling AR experiences. We conduct extensive evaluations through both real-world experiments and trace-driven simulations. We observe that SEAR not only reduces the end-to-end latency, by up to 130x, compared to the state-of-the-art adaptive edge offloading scheme, but also achieves high object-recognition accuracy for mobile AR.
C1 [Zhang, Wenxiao; Hui, Pan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Han, Bo] George Mason Univ, Fairfax, VA 22030 USA.
C3 Hong Kong University of Science & Technology; George Mason University
RP Zhang, WX (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM wzhangal@cse.ust.hk; bohan@gmu.edu; panhui@cse.ust.hk
RI Zhang, Wenxiao/KCK-3295-2024
FU 4-VA; collaborative partnership for advancing the Commonwealth of
   Virginia; General Research Fund from the Research Grants Council of Hong
   Kong [26211515, 16214817]; Academy of Finland [318927, 325570]; Academy
   of Finland (AKA) [325570] Funding Source: Academy of Finland (AKA)
FX We thank the anonymous reviewers for their insightful comments and Vijay
   Gopalakrishnan, Eric Zavesky, and Feng Qian for the initial discussion.
   The research of Bo Han was funded in part by 4-VA, a collaborative
   partnership for advancing the Commonwealth of Virginia. The research of
   Pan Hui was supported in part by the General Research Fund from the
   Research Grants Council of Hong Kong under Grant 26211515 and Grant
   16214817 and the 5GEAR project (Decision No. 318927) and the FIT project
   (Decision No. 325570) funded by the Academy of Finland.
CR Ahuja K, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418452
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Ananthanarayanan G, 2017, COMPUTER, V50, P58, DOI 10.1109/MC.2017.3641638
   [Anonymous], 2017, OpenCV
   [Anonymous], 2015, P ACM MOBISYS
   Apicharttrisorn K, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS '19), P96, DOI 10.1145/3356250.3360044
   Apple Inc, 2018, CREAT MULT AR EXP
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Biehl JT, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P183, DOI 10.1145/2632048.2636083
   Björkman M, 2014, COMPUT VIS IMAGE UND, V118, P111, DOI 10.1016/j.cviu.2013.10.007
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Butz A., 1999, P INT WORKSH AUGM RE
   Chen KF, 2018, SENSYS'18: PROCEEDINGS OF THE 16TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P292, DOI 10.1145/3274783.3274834
   Chen TYH, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P155, DOI 10.1145/2809695.2809711
   Cheng Y, 2020, COMPUT COMMUN, V158, P24, DOI 10.1016/j.comcom.2020.04.054
   Coates A., 2011, P AISTATS
   Cranmer E., 2016, Information and Communication Technologies in Tourism 2016, P637, DOI [10.1007/978-3-319-28231-2_46, DOI 10.1007/978-3-319-28231-2_46]
   Gautier L, 1999, IEEE INFOCOM SER, P1470, DOI 10.1109/INFCOM.1999.752168
   Google, 2018, INTR CLOUD ANCH ANDR
   Han B, 2012, IEEE T MOBILE COMPUT, V11, P821, DOI 10.1109/TMC.2011.101
   Han S, 2016, Harvard Yenching Ins, V101, P123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henrysson A, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P80
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   ImageNet, IMAGENET IS IM DAT O
   Ioannidis S, 2010, PERF E R SI, V38, P311, DOI 10.1145/1811099.1811075
   Jain P, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'16), P237, DOI 10.1145/2999572.2999587
   Jana Suman, 2013, USENIX SECURITY, P415
   Juan A, 2004, INT C PATT RECOG, P367, DOI 10.1109/ICPR.2004.1334543
   Juan L., 2009, Int. J. Image Process, V3, P143
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Krizhevsky Alex., 2012, u International Conference on Neural Information Processing Systems - Volume, V1
   Lebeck K, 2017, P IEEE S SECUR PRIV, P320, DOI 10.1109/SP.2017.13
   Lebeck K, 2016, HOTMOBILE'16: PROCEEDINGS OF THE 17TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P45, DOI 10.1145/2873587.2873595
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lin KCJ, 2012, IEEE INFOCOM SER, P1960, DOI 10.1109/INFCOM.2012.6195573
   Liu LY, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3300116
   Liu ZD, 2020, 2020 19TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN 2020), P301, DOI 10.1109/IPSN48710.2020.00-26
   Livingston MA, 2011, HANDBOOK OF AUGMENTED REALITY, P671, DOI 10.1007/978-1-4614-0064-6_31
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WJ, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P39, DOI 10.1145/2911996.2911997
   Maheshwari S, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P286, DOI 10.1109/SEC.2018.00028
   McNamara L, 2008, MOBICOM'08: PROCEEDINGS OF THE FOURTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P58, DOI 10.1145/1409944.1409953
   NVIDIA, 2017, CUDA
   Ohshima T, 1998, P IEEE VIRT REAL ANN, P268, DOI 10.1109/VRAIS.1998.658505
   OpenCV, 2017, OPENCV4ANDROID
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Ran X., 2020, ACM CONEXT
   Ran XK, 2019, PROCEEDINGS OF THE EIGHTEENTH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '19), P109, DOI 10.1145/3365609.3365867
   Ran XK, 2018, IEEE INFOCOM SER, P1421, DOI 10.1109/INFOCOM.2018.8485905
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Regenbrecht H. T., 2002, Virtual Reality, V6, P151, DOI 10.1007/s100550200016
   Reitmayr G, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P114, DOI 10.1109/ISAR.2001.970521
   Ren P., IEEE T CLOUD COMPUTI, P2021
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   robots.ox.ac.uk/, CMU OXFORD SCULPTURE
   robots.ox.ac.uk, PAINT DAT
   Roesner F, 2014, COMMUN ACM, V57, P88, DOI 10.1145/2580723.2580730
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Seo YJ, 2021, IEEE WIREL COMMUN LE, V10, P1061, DOI 10.1109/LWC.2021.3057114
   Srinivasan V, 2006, MOBICOM 2006, P86, DOI 10.1145/1161089.1161100
   Szalavari Z., 1998, VIRTUAL REAL-LONDON, V3, P3748
   VLFeat, 2017, VLFEAT OP SOURC LIB
   Wagner D, 2005, LECT NOTES COMPUT SC, V3468, P208
   Wang JJ, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P152, DOI 10.1145/3318216.3363308
   Younis A, 2020, IEEE INT CONF SENS, DOI 10.1109/secon48991.2020.9158429
   Yusof CS, 2019, 2019 IEEE CONFERENCE ON GRAPHICS AND MEDIA (GAME), P32, DOI [10.1109/game47560.2019.8980979, 10.1109/GAME47560.2019.8980979]
   Zhang WX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P355, DOI 10.1145/3240508.3240561
   Zhang WX, 2018, HOTMOBILE'18: PROCEEDINGS OF THE 19TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS & APPLICATIONS, P25, DOI 10.1145/3177102.3177107
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 72
TC 18
Z9 20
U1 1
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 1982
EP 1992
DI 10.1109/TVCG.2022.3150467
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400018
PM 35167456
DA 2024-11-06
ER

PT J
AU Martin, D
   Serrano, A
   Bergman, AW
   Wetzstein, G
   Masia, B
AF Martin, Daniel
   Serrano, Ana
   Bergman, Alexander W.
   Wetzstein, Gordon
   Masia, Belen
TI ScanGAN360: A Generative Model of Realistic Scanpaths for 360° Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc
DE Scanpath generation; 360 degrees images; virtual reality; generative
   adversarial models; saliency; human behavior
ID VISUAL-ATTENTION; SALIENCY MAPS; EYE-MOVEMENTS; PREDICTION; GAZE
AB Understanding and modeling the dynamics of human gaze behavior in 360 degrees environments is crucial for creating, improving, and developing emerging virtual reality applications. However, recruiting human observers and acquiring enough data to analyze their behavior when exploring virtual environments requires complex hardware and software setups, and can be time-consuming. Being able to generate virtual observers can help overcome this limitation, and thus stands as an open problem in this medium. Particularly, generative adversarial approaches could alleviate this challenge by generating a large number of scanpaths that reproduce human behavior when observing new scenes, essentially mimicking virtual observers. However, existing methods for scanpath generation do not adequately predict realistic scanpaths for 360 degrees images. We present ScanGAN360, a new generative adversarial approach to address this problem. We propose a novel loss function based on dynamic time warping and tailor our network to the specifics of 360 degrees images. The quality of our generated scanpaths outperforms competing approaches by a large margin, and is almost on par with the human baseline. ScanGAN360 allows fast simulation of large numbers of virtual observers, whose behavior mimics real users, enabling a better understanding of gaze behavior, facilitating experimentation, and aiding novel applications in virtual reality and beyond.
C1 [Martin, Daniel; Serrano, Ana; Masia, Belen] Univ Zaragoza, I3A, Zaragoza, Spain.
   [Bergman, Alexander W.; Wetzstein, Gordon] Stanford Univ, Stanford, CA 94305 USA.
C3 University of Zaragoza; Stanford University
RP Martin, D (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM danims@unizar.es
RI Martin, Daniel/KLZ-9356-2024; Serrano Pacheu, Ana Belen/ABC-3358-2021
OI Martin, Daniel/0000-0002-0073-6398; Serrano Pacheu, Ana
   Belen/0000-0002-7796-3177
FU European Research Council (ERC) under the EU [682080]; Leonardo Grant
   for Researchers and Cultural Creators, BBVA Foundation; NSF [1839974];
   Gobierno de Aragon; European Research Council (ERC) [682080] Funding
   Source: European Research Council (ERC)
FX We thank Diego Gutierrez for the revision of the manuscript. This work
   has received funding from the European Research Council (ERC) under the
   EU's Horizon 2020 research and innovation programme (project CHAMELEON,
   Grant no. 682080). This project was also supported by a 2020 Leonardo
   Grant for Researchers and Cultural Creators, BBVA Foundation (the BBVA
   Foundation accepts no responsibility for the opinions, statements and
   contents included in the project and/or the results thereof, which are
   entirely the responsibility of the authors). This project was in part
   supported by NSF award 1839974. Additionally, Daniel Martin was
   supported by a Gobierno de Aragon (2020-2024) predoctoral grant.
CR Alghofaili R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P464, DOI [10.1109/vr.2019.8797816, 10.1109/VR.2019.8797816]
   Anderson NC, 2015, BEHAV RES METHODS, V47, P1377, DOI 10.3758/s13428-014-0550-3
   Nguyen A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1190, DOI 10.1145/3240508.3240669
   [Anonymous], 2018, SALGAN VISUAL SALIEN
   [Anonymous], 1985, EYE MOVEMENTS HUMAN
   Assens M., 2018, P EUROPEAN C COMPUTE
   Assens M, 2018, SIGNAL PROCESS-IMAGE, V69, P8, DOI 10.1016/j.image.2018.06.006
   Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275
   Bao WT, 2020, NEUROCOMPUTING, V404, P154, DOI 10.1016/j.neucom.2020.03.060
   Blondel, 2017, ARXIV PREPRINT ARXIV
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Cao Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601183
   Chao FY, 2018, IEEE INT CONF MULTI
   Colburn Alex., 2000, ROLE EYE GAZE AVATAR
   Coors B, 2018, LECT NOTES COMPUT SC, V11213, P525, DOI 10.1007/978-3-030-01240-3_32
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Fahimi R, 2021, BEHAV RES METHODS, V53, P609, DOI 10.3758/s13428-020-01441-0
   Horley K, 2004, PSYCHIAT RES, V127, P43, DOI 10.1016/j.psychres.2004.02.016
   Hu ZM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P543, DOI [10.1109/VRW50115.2020.0-153, 10.1109/VRW50115.2020.00123]
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Hu ZM, 2019, IEEE T VIS COMPUT GR, V25, P2002, DOI 10.1109/TVCG.2019.2899187
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kapoula Z, EYE MOVEMENTS PSYCHO, P2021
   Kerkouri M. A, 2021, ABS210700559 CORR, P1464
   Kingma D. P., 2017, 3 INT C LEARNING REP
   Kummerer M., 2021, ARXIV PREPRINT ARXIV
   Kummerer Matthias, 2016, CoRR
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Li CG, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P297, DOI 10.1109/MIPR.2019.00060
   Ling SY, 2019, IEEE J EM SEL TOP C, V9, P204, DOI 10.1109/JETCAS.2019.2893484
   Liu HY, 2013, IEEE I CONF COMP VIS, P3232, DOI 10.1109/ICCV.2013.401
   Liu R, 2018, ADV NEUR IN, V31
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785
   Martin D., 2021, MULTIMODALITY VR SUR
   Martin D., 2020, P IEEE C COMP VIS PA, P1
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Mirza M., 2014, arXiv preprint arXiv:1411.1784, DOI 10.48550/arXiv.1411.1784
   Monroy R, 2018, SIGNAL PROCESS-IMAGE, V69, P26, DOI 10.1016/j.image.2018.05.005
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Perera SL, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401052
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Sela M, 2017, ARXIV PREPRINT ARXIV
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Startsev M, 2018, SIGNAL PROCESS-IMAGE, V69, P43, DOI 10.1016/j.image.2018.03.013
   Su Y.-C, 2017, 2017 IEEE C COMPUTER
   Su Y.-C, 2016, ASIAN C 105
   Sun WJ, 2021, IEEE T PATTERN ANAL, V43, P2101, DOI 10.1109/TPAMI.2019.2956930
   Tatler BW, 2009, VIS COGN, V17, P1029, DOI 10.1080/13506280902764539
   Tavakoli HR, 2013, IMAGE VISION COMPUT, V31, P686, DOI 10.1016/j.imavis.2013.06.006
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972
   Wu CL, 2020, AAAI CONF ARTIF INTE, V34, P14003
   Xia C, 2019, IEEE T IMAGE PROCESS, V28, P3502, DOI 10.1109/TIP.2019.2897966
   Xu M, 2019, IEEE T PATTERN ANAL, V41, P2693, DOI 10.1109/TPAMI.2018.2858783
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yun K, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00917
   Zanca D, 2020, IEEE T PATTERN ANAL, V42, P2983, DOI 10.1109/TPAMI.2019.2920636
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zhu YC, 2018, SIGNAL PROCESS-IMAGE, V69, P15, DOI 10.1016/j.image.2018.05.010
NR 69
TC 24
Z9 23
U1 6
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2003
EP 2013
DI 10.1109/TVCG.2022.3150502
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400019
PM 35167469
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Tsao, CA
   Wu, TC
   Tsai, HR
   Wei, TY
   Liao, FY
   Chapman, S
   Chen, BY
AF Tsao, Chih-An
   Wu, Tzu-Chun
   Tsai, Hsin-Ruey
   Wei, Tzu-Yun
   Liao, Fang-Ying
   Chapman, Sean
   Chen, Bing-Yu
TI FrictShoes: Providing Multilevel Nonuniform Friction Feedback on Shoes
   in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Friction; Foot; Wheels; Force; Haptic interfaces; Legged locomotion;
   Force feedback; Haptic feedback; friction force; force feedback; on
   feet; virtual reality; wearable device
AB Many haptic feedback methods have been proposed to enhance realism in virtual reality (VR). However, friction on the feet in VR, which renders feedback as if walking on different terrains or ground textures or stepping on objects is still less explored. Herein, we propose a wearable device, FrictShoes a pair of foot accessories, to provide multilevel nonuniform friction feedback to feet. This is achieved by the independent functioning of six brakes on six wheels underneath each FrictShoe, which allows the friction levels of the wheels from each to be either matched or to vary. We conducted a magnitude estimation study to understand users' distinguishability of friction force magnitudes (or levels). Based on the results, we performed an exploratory study to realize how users adjust and map the multilevel nonuniform friction patterns to common VR terrains or ground textures. Finally, a VR experience study was conducted to evaluate the performance of the proposed multilevel nonuniform friction feedback to the feet in VR experiences.
C1 [Tsao, Chih-An; Wu, Tzu-Chun; Wei, Tzu-Yun; Liao, Fang-Ying; Chen, Bing-Yu] Natl Taiwan Univ, Taipei, Taiwan.
   [Tsai, Hsin-Ruey] Natl Chengchi Univ, Taipei, Taiwan.
   [Chapman, Sean] Univ Maryland, College Pk, MD 20742 USA.
C3 National Taiwan University; National Chengchi University; University
   System of Maryland; University of Maryland College Park
RP Tsao, CA (corresponding author), Natl Taiwan Univ, Taipei, Taiwan.
EM hl6540@gmail.com; nicole2092455@gmail.com; hsnuhrt@gmail.com;
   r07922130@ntu.edu.tw; fyjh21317@gmail.com; seankchapman@gmail.com;
   robin@ntu.edu.tw
RI Wu, Danny/JYP-1520-2024
FU Ministry of Scienceand Technologyof Taiwan [MOST
   110-2634-F-002-051,110-2218-E-002029, 1l0-2221-E-004-006]
FX This researchwas supportedin part by the Ministry of Scienceand
   Technologyof Taiwan(MOST 110-2634-F-002-051,110-2218-E-002029,
   1l0-2221-E-004-006),NationalTaiwanUniversity andNational
   ChengchiUniversity. We alsothankto XanderKoo for his assistance.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   [Anonymous], 2016, SIGGRAPH ASIA 2016 E
   Bau O., 2010, P 23ND ANN ACM S USE, P283
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Chang HY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P927, DOI 10.1145/3242587.3242588
   Cho YJ, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P195, DOI 10.1145/2984511.2984550
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Choi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P986, DOI 10.1109/IROS.2016.7759169
   Fontanaand F.., 2012, WALKING SENSES
   Gu XC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1991, DOI 10.1145/2858036.2858487
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P227, DOI 10.1145/2984511.2984535
   Han T, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P131, DOI 10.1145/3126594.3126622
   Heo S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186544
   Horodniczy D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P255, DOI 10.1145/3025453.3025625
   Iwata H., 2006, ACM SIGGRAPH 2006 Emerging technologies, P28, DOI DOI 10.1145/1179133.1179162
   Iwata H., 2007, ACM SIGGRAPH 2007 ME, p20es
   Je SWO, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P763, DOI 10.1145/3332165.3347926
   Je S, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214915
   Kato G., 2016, Demonstration in AsiaHaptics, P105
   Law AW, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P126, DOI 10.1109/HAVE.2008.4685311
   Lee C.-J., 2021, P 2021 CHI C HUMAN 3, P1
   Lo JY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P839, DOI 10.1145/3242587.3242627
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lopes P, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P11, DOI 10.1145/2807442.2807443
   Masuda Y, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P541, DOI 10.1109/SII.2012.6426966
   Millet G, 2017, MECHATRONICS, V46, P115, DOI 10.1016/j.mechatronics.2017.07.005
   Mullenbach J., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P407, DOI 10.1109/HAPTIC.2012.6183823
   Nilsson Niels C., 2012, Haptic and Audio Interaction Design. Proceedings 7th International Conference, HAID 2012, P61, DOI 10.1007/978-3-642-32796-4_7
   Nordahl R, 2010, LECT NOTES COMPUT SC, V6192, P123, DOI 10.1007/978-3-642-14075-4_18
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Rasmussen CM, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0602-0
   Sagheb S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P751, DOI 10.1145/3332165.3347870
   Sasaki T, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214913
   Schmidt D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2157, DOI 10.1145/2702123.2702253
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Shigeyama J, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214923
   Sinclair M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P815, DOI 10.1145/3332165.3347891
   Son H, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186474
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Strohmeier P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4994, DOI 10.1145/3025453.3025812
   Strohmeier P, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P185, DOI 10.1145/2839462.2839494
   Sun YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300682
   Teng SY, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P639, DOI 10.1145/3332165.3347958
   Teng SY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P5, DOI 10.1145/3242587.3242628
   Teng SY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300902
   Tsai H.-R., 2020, P 33 ANN ACM S US IN, P1023, DOI 10.1145/3379337.3415836
   Tsai HR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376408
   Tsai HR, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P429, DOI 10.1145/3332165.3347931
   Tsai HR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300450
   Tsetserukou D., 2010, Proc. Augment. Human, P1, DOI [DOI 10.1145/1785455.1785456, 10.1145/1785455.1785456]
   Turchet Luca, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P269, DOI 10.1109/MMSP.2010.5662031
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Winfield L, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P421
   Yokota T., 2015, P 6 AUGM HUM INT C, P45, DOI 10.1145/2735711.2735829
   Zenner A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300441
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
NR 58
TC 5
Z9 5
U1 0
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2026
EP 2036
DI 10.1109/TVCG.2022.3150492
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400020
PM 35167465
DA 2024-11-06
ER

PT J
AU Dewez, D
   Hoyet, L
   Lécuyer, A
   Argelaguet, F
AF Dewez, Diane
   Hoyet, Ludovic
   Lecuyer, Anatole
   Argelaguet, Ferran
TI Do You Need Another Hand? Investigating Dual Body Representations During
   Anisomorphic 3D Manipulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Avatars; Task analysis; Distortion; Arms; Visualization;
   Three-dimensional displays; Rubber; Avatar; Sense of embodiment;
   Interaction; Virtual reality
ID SELF-AVATAR; EMBODIMENT; SENSE; IMPACT; ARM
AB In virtual reality, several manipulation techniques distort users' motions, for example to reach remote objects or increase precision. These techniques can become problematic when used with avatars, as they create a mismatch between the real performed action and the corresponding displayed action, which can negatively impact the sense of embodiment. In this paper, we propose to use a dual representation during anisomorphic interaction. A co-located representation serves as a spatial reference and reproduces the exact users' motion, while an interactive representation is used for distorted interaction. We conducted two experiments, investigating the use of dual representations with amplified motion (with the Go-Go technique) and decreased motion (with the PRISM technique). Two visual appearances for the interactive representation and the co-located one were explored. This exploratory study investigating dual representations in this context showed that people globally preferred having a single representation, but opinions diverged for the Go-Go technique. Also, we could not find significant differences in terms of performance. While interacting seemed more important than showing exact movements for agency during out-of-reach manipulation, people felt more in control of the realistic arm during close manipulation.
C1 [Dewez, Diane; Hoyet, Ludovic; Lecuyer, Anatole; Argelaguet, Ferran] Univ Rennes, IRISA, CNRS, INRIA, Irisa, France.
C3 Inria; Centre National de la Recherche Scientifique (CNRS)
RP Argelaguet, F (corresponding author), Univ Rennes, IRISA, CNRS, INRIA, Irisa, France.
EM diane.dewez@inria.fr; ludovic.hoyet@inria.fr; anatole.lecuyer@inria.fr;
   ferran.argelaguet@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049
FU Inria Research Challenge Avatar
FX We wish to thank all the participants who took part in these two
   experiments. This work was sponsored by the Inria Research Challenge
   Avatar.
CR Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Canales R., 2019, ACM S APPL PERCEPTIO, DOI [10.1145/3343036.3343132, DOI 10.1145/3343036.3343132]
   Chen WY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19662-x
   Chinthammit W, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/646347
   David N, 2008, CONSCIOUS COGN, V17, P523, DOI 10.1016/j.concog.2008.03.004
   Dewez D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445379
   Draper MH, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1146
   Ehrsson HH, 2009, PERCEPTION, V38, P310, DOI 10.1068/p6304
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.1581285352835, 10.1109/VR46266.2020.00-38]
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Feuchtner T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P31, DOI 10.1145/3242587.3242594
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Frees S, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1229855.1229857
   Guterstam A, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201911
   Han PH, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875237
   Heydrich L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00946
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kocur Martin, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P193, DOI 10.1145/3410404.3414261
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Laha B, 2016, PRESENCE-VIRTUAL AUG, V25, P129, DOI 10.1162/PRES_a_00251
   Latoschik M. E., 2017, VRST 17 P 23 ACM S V, P1, DOI DOI 10.1145/3139131.3139156
   Lin LPY, 2020, J EXP PSYCHOL HUMAN, V46, P474, DOI 10.1037/xhp0000724
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Miura R, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P1, DOI 10.1145/3458709.3458878
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1964, DOI 10.1109/TVCG.2020.2973061
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/VR.2019.8797716, 10.1109/vr.2019.8797716]
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Rosa N, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3341225
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Schjerlund J., 2021, P 2021 CHI C HUMAN F, P1
   Skarbez R., 2021, CHI 2021 WORKSHOP EV
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tran TQ, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139149
   Tian Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376557
   Yang UY, 2002, PRESENCE-VIRTUAL AUG, V11, P304, DOI 10.1162/105474602317473240
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 47
TC 7
Z9 7
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2047
EP 2057
DI 10.1109/TVCG.2022.3150501
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400021
PM 35167468
OA Green Published
DA 2024-11-06
ER

PT J
AU Biener, V
   Gesslein, T
   Schneider, D
   Kawala, F
   Otte, A
   Kristensson, PO
   Pahud, M
   Ofek, E
   Campos, C
   Kljun, M
   Pucihar, KC
   Grubert, J
AF Biener, Verena
   Gesslein, Travis
   Schneider, Daniel
   Kawala, Felix
   Otte, Alexander
   Kristensson, Per Ola
   Pahud, Michel
   Ofek, Eyal
   Campos, Cuauhtli
   Kljun, Matjaz
   Pucihar, Klen Copic
   Grubert, Jens
TI PoVRPoint: Authoring Presentations in Mobile Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Three-dimensional displays; Task analysis; Mobile handsets;
   Visualization; Animation; Usability; Shape; Virtual Reality;
   Presentation Authoring; Mobile Knowledge Work; Pen and Touch Interaction
AB Virtual Reality (VR) has the potential to support mobile knowledge workers by complementing traditional input devices with a large three-dimensional output space and spatial input. Previous research on supporting VR knowledge work explored domains such as text entry using physical keyboards and spreadsheet interaction using combined pen and touch input. Inspired by such work, this paper probes the VR design space for authoring presentations in mobile settings. We propose PoVRPoint-a set of tools coupling pen- and touch-based editing of presentations on mobile devices, such as tablets, with the interaction capabilities afforded by VR. We study the utility of extended display space to, for example, assist users in identifying target slides, supporting spatial manipulation of objects on a slide, creating animations, and facilitating arrangements of multiple, possibly occluded shapes or objects. Among other things, our results indicate that 1) the wide field of view afforded by VR results in significantly faster target slide identification times compared to a tablet-only interface for visually salient targets; and 2) the three-dimensional view in VR enables significantly faster object reordering in the presence of occlusion compared to two baseline interfaces. A user study further confirmed that the interaction techniques were found to be usable and enjoyable.
C1 [Biener, Verena; Gesslein, Travis; Schneider, Daniel; Kawala, Felix; Otte, Alexander; Grubert, Jens] Coburg Univ Appl Sci, Coburg, Germany.
   [Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
   [Pahud, Michel; Ofek, Eyal] Microsoft Res, Redmond, WA USA.
   [Campos, Cuauhtli; Kljun, Matjaz; Pucihar, Klen Copic] Univ Primorska, Koper, Slovenia.
C3 Hochschule Coburg; University of Cambridge; Microsoft; University of
   Primorska
RP Biener, V (corresponding author), Coburg Univ Appl Sci, Coburg, Germany.
EM verena.biener@hs-coburg.de; travis.gesslein@hs-coburg.de;
   daniel.schneider@hs-coburg.de; felix.kawala@hs-coburg.de;
   alexander.otte@hs-coburg.de; pok21@cam.ac.uk; mpahud@microsoft.com;
   eyalofek@microsoft.com; cc.mijangos@gmail.com; matjaz.kljun@upr.si;
   klen.copic@famnit.upr.si; jens.grubert@hs-coburg.de
RI Ofek, Eyal/LPP-8746-2024; Grubert, Jens/B-1012-2018; Kljun,
   Matjaz/G-6415-2015
OI Kljun, Matjaz/0000-0002-6988-3046; Ofek, Eyal/0000-0003-4750-1569
CR [Anonymous], P 17 ANN ACM S US IN
   [Anonymous], 2021, MICROSOFT RES MT ROG
   [Anonymous], 1994, INTERACTING PAPER DI
   Arora R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P463, DOI 10.1145/3332165.3347942
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Cami D, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P825, DOI 10.1145/3242587.3242652
   Cannavò A, 2019, IEEE ACCESS, V7, P125463, DOI 10.1109/ACCESS.2019.2939427
   Checa D, 2020, MULTIMED TOOLS APPL, V79, P5501, DOI 10.1007/s11042-019-08348-9
   Chen X.A., 2014, P 27 ANN ACM S USER, P519, DOI DOI 10.1145/2642918.2647392
   Drey T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376628
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Fellion N, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P375, DOI 10.1145/3126594.3126597
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grasset Raphael., 2007, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems Extended Abstracts (CHI EA'07), P1953, DOI DOI 10.1145/1240866.1240931
   Grossman T., 2006, Conference on Human Factors in Computing Systems. CHI2006, P861
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   HART S G, 1988, P139
   Hilliges O, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P139
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley K., 2013, Proceedings of Graphics Interface 2013, P71, DOI DOI 10.5555/2532129.2532143
   Hinckley K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2869, DOI 10.1145/2858036.2858095
   Hinckley Ken, 2010, P 23 ANN ACM S US IN, P27, DOI [DOI 10.1145/1866029.1866036, DOI 10.1145/1866029.18660362]
   Hirzle T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300855
   Hürst W, 2011, LECT NOTES COMPUT SC, V6524, P230
   Jordan P.W., 1996, Usability Evaluation in Industry
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kockro RA, 2015, ANN ANAT, V201, P91, DOI 10.1016/j.aanat.2015.05.006
   Kry P.G., 2008, P ACM S VIRTUAL REAL, P53
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.00101, 10.1109/VRW50115.2020.0-175]
   Li NL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376698
   Li Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300917
   Marquardt N, 2011, LECT NOTES COMPUT SC, V6948, P461, DOI 10.1007/978-3-642-23765-2_32
   Matulic F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376147
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2020, VIRTUAL REAL-LONDON, V24, P583, DOI 10.1007/s10055-019-00420-x
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376637
   Ofek E., 2020, MICROSOFT NEW FUTURE
   Pantelidis P., 2018, Medical and Surgical Education: Past, Present and Future, P77, DOI [DOI 10.5772/INTECHOPEN.71963, 10.5772/intechopen.71963]
   Parmar Dhaval., 2020, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V4, P1
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Pfeuffer K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3254, DOI 10.1145/3025453.3025567
   Pfeuffer K, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P373, DOI 10.1145/2807442.2807460
   Pham D.-M., 2019, 25 ACM S VIRT REAL S, P1
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Rekimoto J., 1999, P SIGCHI C HUMAN FAC, P378, DOI [10.1145/302979.303113, DOI 10.1145/302979.303113]
   Ruvimova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376724
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Schweigert Robin, 2019, 2019 P MENSCH COMP A, P719, DOI [DOI 10.1145/3340764.3344897, 10.1145/3340764.3344897]
   Sidenmark L, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391312
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Song H, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1323
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Szalavari Z, 1997, COMPUT GRAPH FORUM, V16, pC335, DOI 10.1111/1467-8659.00171
   Tang A, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P271
   Tian F, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1371
   Unger R., 2012, A project guide to UX design: For user experience designers in the field or in the making, V2nd edition
   Vogel DHV, 2020, PHENOMENOL COGN SCI, V19, P235, DOI 10.1007/s11097-018-9573-z
   Wacker P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300849
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wolfe JM, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0058
   Zielasko D, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809589
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1884, DOI [10.1109/vr.2019.8797837, 10.1109/VR.2019.8797837]
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1287, DOI [10.1109/VR.2019.8797900, 10.1109/vr.2019.8797900]
NR 77
TC 11
Z9 11
U1 3
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2069
EP 2079
DI 10.1109/TVCG.2022.3150474
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400022
PM 35167458
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kim, H
   Lee, IK
AF Kim, Hayeon
   Lee, In-Kwon
TI Studying the Effects of Congruence of Auditory and Visual Stimuli on
   Virtual Reality Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Visualization; User experience; Solid modeling; Psychology; Multisensory
   integration; Semantics; Legged locomotion; Virtual reality; sensory
   simulation; multisensory integration; congruence; user experience
ID MULTISENSORY INTEGRATION; PERCEPTION; CORRESPONDENCES; SICKNESS;
   INFANTS; SPACE
AB Studies in virtual reality (VR) have introduced numerous multisensory simulation techniques for more immersive VR experiences. However, although they primarily focus on expanding sensory types or increasing individual sensory quality, they lack consensus in designing appropriate interactions between different sensory stimuli. This paper explores how the congruence between auditory and visual (AV) stimuli, which are the sensory stimuli typically provided by VR devices, affects the cognition and experience of VR users as a critical interaction factor in promoting multisensory integration. We defined the types of (in)congruence between AV stimuli, and then designed 12 virtual spaces with different types or degrees of congruence between AV stimuli. We then evaluated the presence, immersion, motion sickness, and cognition changes in each space. We observed the following key findings: 1) there is a limit to the degree of temporal or spatial incongruence that can be tolerated, with few negative effects on user experience until that point is exceeded; 2) users are tolerant of semantic incongruence; 3) a simulation that considers synesthetic congruence contributes to the user's sense of immersion and presence. Based on these insights, we identified the essential considerations for designing sensory simulations in VR and proposed future research directions.
C1 [Kim, Hayeon; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
C3 Yonsei University
RP Kim, H (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM qoocrab@gmail.com; iklee@yonsei.ac.kr
RI Lee, In-Kwon/AGP-6124-2022; Kim, Hayeon/AAY-5003-2021
OI Kim, Hayeon/0000-0002-6529-0921
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2021-2018-0-01419];
   National Research Foundation of Korea(NRF) - Korea government(MSIT)
   [NRF2020R1A2C2014622]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2021-2018-0-01419) supervised by the IITP(Institute for
   Information and Communications Technology Planning and Evaluation) and
   the National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIT). (No. NRF2020R1A2C2014622)
CR [Anonymous], P 2020 CHI C HUM FAC, P1
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bertelson P., 1999, Cognitive Contributions to the Perception of Spatial and Temporal Events, P347, DOI [10.1016/S0166-4115(99)80034-X, DOI 10.1016/S0166-4115(99)80034-X]
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Burdea G. C., 2003, VIRTUAL REALITY TECH, DOI 10.1162/105474603322955950
   Byrne R, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P45, DOI 10.1145/3242671.3242689
   Byrne R, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P159, DOI 10.1145/2967934.2968080
   Calvert G.A., 2004, HDB MULTISENSORY PRO, DOI DOI 10.1103/PhysRevLett.90.058701
   Choi W, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8163098
   Covaci A, 2020, IEEE T MULTIMEDIA, V22, P1249, DOI 10.1109/TMM.2019.2941274
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   Dolscheid S, 2014, PSYCHOL SCI, V25, P1256, DOI 10.1177/0956797614528521
   Doukakis E, 2019, IEEE T VIS COMPUT GR, V25, P1865, DOI 10.1109/TVCG.2019.2898823
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Finnegan DJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P200, DOI 10.1145/2858036.2858065
   FRENS MA, 1995, PERCEPT PSYCHOPHYS, V57, P802, DOI 10.3758/BF03206796
   Fujino Y, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P929, DOI [10.1109/VR.2019.8797727, 10.1109/vr.2019.8797727]
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Grantham DW, 2003, J ACOUST SOC AM, V114, P1009, DOI 10.1121/1.1590970
   Guenther S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376195
   Han T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376190
   Hein G, 2007, J NEUROSCI, V27, P7881, DOI 10.1523/JNEUROSCI.1740-07.2007
   Hoppe M., 2020, P 2020 CHI C HUMAN F, P1
   Hoppe M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300776
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jones JA, 2006, EXP BRAIN RES, V174, P588, DOI 10.1007/s00221-006-0634-0
   Kaliuzhna M, 2015, J VISION, V15, DOI 10.1167/15.1.10
   Karunanayaka K, 2018, IEEE T VIS COMPUT GR, V24, P1496, DOI 10.1109/TVCG.2018.2794073
   Kohli L, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P79, DOI 10.1109/3DUI.2013.6550201
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Laurienti PJ, 2004, EXP BRAIN RES, V158, P405, DOI 10.1007/s00221-004-1913-2
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lewkowicz DJ, 2014, PSYCHOL SCI, V25, P832, DOI 10.1177/0956797613516011
   Lin A., 2021, P 2021 CHI C HUMAN F
   Lombard Matthew, 2009, P 12 ANN INT WORKSH, P1
   Lubeck AJA, 2015, DISPLAYS, V38, P55, DOI 10.1016/j.displa.2015.03.001
   MacArthur C., 2021, Association for Computing Machinery, DOI DOI 10.1145/3411764.3445701
   Maggioni E., 2019, INT J HUM-COMPUT ST, V130, P248, DOI [10.1016/j.ijhcs.2019.06.014, DOI 10.1016/j.ijhcs.2019.06.014]
   Marshall J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300930
   Marucci M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84196-8
   McDonald JJ, 2000, NATURE, V407, P906, DOI 10.1038/35038085
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mégevand P, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0071608
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Metatla O, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300689
   Mollon JD, 1996, NATURE, V380, P101, DOI 10.1038/380101a0
   Narumi T, 2011, P IEEE VIRT REAL ANN, P265, DOI 10.1109/VR.2011.5759500
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Parise CV, 2016, MULTISENS RES, V29, P7, DOI 10.1163/22134808-00002502
   Parise CV, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005664
   Ranasinghe N., P 2018 CHI C HUMAN F, P113
   Reason J.T., 1975, Motion Sickness
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Saito H, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188512
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spence C, 2003, CURR BIOL, V13, pR519, DOI 10.1016/S0960-9822(03)00445-7
   Spence C., 2004, Crossmodal space and crossmodal attention
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stevenson RA, 2012, EXP BRAIN RES, V219, P121, DOI 10.1007/s00221-012-3072-1
   Stone JV, 2001, P ROY SOC B-BIOL SCI, V268, P31, DOI 10.1098/rspb.2000.1326
   Tennent P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376812
   Tennent P, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1265, DOI 10.1145/3064663.3064763
   Tsai SE, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P279, DOI 10.1109/VR50410.2021.00050
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vroomen J, 2000, J EXP PSYCHOL HUMAN, V26, P1583, DOI 10.1037/0096-1523.26.5.1583
   Vroomen J, 2004, J EXP PSYCHOL HUMAN, V30, P513, DOI 10.1037/0096-1523.30.3.513
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   WALKER S, 1995, PERCEPT PSYCHOPHYS, V57, P1124, DOI 10.3758/BF03208369
   Wolf D, 2019, IEEE T VIS COMPUT GR, V25, P3169, DOI 10.1109/TVCG.2019.2932215
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 81
TC 9
Z9 10
U1 7
U2 55
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2080
EP 2090
DI 10.1109/TVCG.2022.3150514
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400023
PM 35167477
DA 2024-11-06
ER

PT J
AU Robotham, T
   Rummukainen, OS
   Kurz, M
   Eckert, M
   Habets, EAP
AF Robotham, Thomas
   Rummukainen, Olli S.
   Kurz, Miriam
   Eckert, Marie
   Habets, Emanuel A. P.
TI Comparing Direct and Indirect Methods of Audio Quality Evaluation in
   Virtual Reality Scenes of Varying Complexity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Task analysis; Visualization; Virtual reality; Rendering (computer
   graphics); Real-time systems; Complexity theory; Testing; Multi-modal;
   virtual reality; 6-Degrees-of-freedom; audio quality; direct scaling;
   indirect scaling; evaluation methods
ID MULTISENSORY INTEGRATION; BIASES
AB Many quality evaluation methods are used to assess uni-modal audio or video content without considering perceptual, cognitive, and interactive aspects present in virtual reality (VR) settings. Consequently, little is known regarding the repercussions of the employed evaluation method, content, and subject behavior on the quality ratings in VR. This mixed between- and within-subjects study uses four subjective audio quality evaluation methods (viz. multiple-stimulus with and without reference for direct scaling, and rank-order elimination and pairwise comparison for indirect scaling) to investigate the contributing factors present in multi-modal 6-DoF VR on quality ratings of real-time audio rendering. For each between-subjects employed method, two sets of conditions in five VR scenes were evaluated within-subjects. The conditions targeted relevant attributes for binaural audio reproduction using scenes with various amounts of user interactivity. Our results show all referenceless methods produce similar results using both condition sets. However, rank-order elimination proved to be the fastest method, required the least amount of repetitive motion, and yielded the highest discrimination between spatial conditions. Scene complexity was found to be a main effect within results, with behavioral and task load index results implying more complex scenes and interactive aspects of 6-DoF VR can impede quality judgments.
C1 [Robotham, Thomas; Habets, Emanuel A. P.] Int Audio Labs Erlangen, Erlangen, Germany.
   [Rummukainen, Olli S.; Kurz, Miriam; Eckert, Marie] Fraunhofer Inst Integrierte Schaltungen IIS, Erlangen, Germany.
C3 University of Erlangen Nuremberg; Fraunhofer Gesellschaft
RP Robotham, T (corresponding author), Int Audio Labs Erlangen, Erlangen, Germany.
EM thomas.robotham@audiolabs-erlangen.de;
   olli.rummukainen@iis.fraunhofer.de; kurzmm@iis.fraunhofer.de;
   eckertme@iis.fraunhofer.de; emanuel.habets@audiolabs-erlangen.de
RI Habets, Emanuël/F-7298-2011
OI Robotham, Thomas/0000-0002-2899-2916
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [444832250 -SPP 2236]
FX This research was partially funded by the Deutsche
   Forschungsgemeinschaft (DFG, German Research Foundation) project number
   444832250 -SPP 2236
CR Alais D, 2004, CURR BIOL, V14, P257, DOI 10.1016/j.cub.2004.01.029
   Andreopoulou A, 2015, IEEE J-STSP, V9, P895, DOI 10.1109/JSTSP.2015.2400417
   [Anonymous], 2006, PERCEPTUAL AUDIO EVA, DOI DOI 10.1002/9780470869253
   [Anonymous], 2020, Github Repository
   [Anonymous], 2009, P AUD ENG SOC 126 CO
   Armstrong C, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112029
   Beresford K., 2006, 121 CONV AUD ENG SOC, P1
   Beresford Kathryn, 2006, AUD ENG SOC 120 CONV, P1
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Bertelson P, 1998, PSYCHON B REV, V5, P482, DOI 10.3758/BF03208826
   Bertelson P., 1999, Cognitive Contributions to the Perception of Spatial and Temporal Events, P347, DOI [10.1016/S0166-4115(99)80034-X, DOI 10.1016/S0166-4115(99)80034-X]
   Bevan N., 2016, HUMAN COMPUTER INTER, P268, DOI [10.1007/978-3-319, DOI 10.1007/978-3-319, 10.1007/978-3-319-39510-4_25, DOI 10.1007/978-3-319-39510-4_25]
   Blackler A., 2003, Design Studies, V24, P491, DOI 10.1016/S0142-694X(03)00038-3
   Blauert Jens, 1996, Spatial hearing: the psychophysics of human sound source localization, DOI DOI 10.7551/MITPRESS/6391.001.0001
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Bresciani JP, 2005, EXP BRAIN RES, V162, P172, DOI 10.1007/s00221-004-2128-2
   Brown A, 2011, EDUC PSYCHOL MEAS, V71, P460, DOI 10.1177/0013164410375112
   Cardello AV, 2005, J SENS STUD, V20, P373, DOI 10.1111/j.1745-459X.2005.00032.x
   Carlyon RP, 2004, TRENDS COGN SCI, V8, P465, DOI 10.1016/j.tics.2004.08.008
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   De Gelder B, 2003, TRENDS COGN SCI, V7, P460, DOI 10.1016/j.tics.2003.08.014
   Dodds P., 2019, PROC 5 INT C SPATIAL, P1
   Eramudugolla R, 2005, CURR BIOL, V15, P1108, DOI 10.1016/j.cub.2005.05.051
   Girard S, 2013, EXP BRAIN RES, V224, P275, DOI 10.1007/s00221-012-3308-0
   Hairston WD, 2003, J COGNITIVE NEUROSCI, V15, P20, DOI 10.1162/089892903321107792
   HART S G, 1988, P139
   Honda A, 2013, I-PERCEPTION, V4, P253, DOI 10.1068/i0522
   International Telecommunications Union, 1996, TELECOMMUNICATIONS S
   International Telecommunications Union: Radiocommunication Sector, 2015, BS15343 INT TEL UN R
   International Telecommunications Union: Radiocommunication Sector, 2015, BS11163 INT TEL UN R
   International Telecommunications Union: Radiocommunication Sector, 2019, BS21320 INT TEL UN R
   International Telecommunications Union: Radiocommunication Sector, 2019, BS12842 INT TEL UN R
   Jaeger SR, 2009, FOOD QUAL PREFER, V20, P249, DOI 10.1016/j.foodqual.2008.10.005
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kim H., 2020, LECT NOTES COMPUTER
   KISTLER DJ, 1992, J ACOUST SOC AM, V91, P1637, DOI 10.1121/1.402444
   Larsson P, 2002, VIRTUAL, SYNTHETIC, AND ENTERTAINMENT AUDIO, P31
   Lindau A, 2014, ACTA ACUST UNITED AC, V100, P984, DOI 10.3813/AAA.918778
   LUCE RD, 1977, J MATH PSYCHOL, V15, P215, DOI 10.1016/0022-2496(77)90032-3
   Mantiuk R. K., 2020, MANTIUK PWCMP
   McGarrigle R, 2014, INT J AUDIOL, V53, P433, DOI 10.3109/14992027.2014.890296
   Mehra R, 2014, IEEE T VIS COMPUT GR, V20, P495, DOI 10.1109/TVCG.2014.38
   Mihajlov M, 2015, INTERACT COMPUT, V27, P344, DOI 10.1093/iwc/iwu044
   Morillon B, 2017, P NATL ACAD SCI USA, V114, pE8913, DOI 10.1073/pnas.1705373114
   Moskowitz HR, 2005, J SENS STUD, V20, P347, DOI 10.1111/j.1745-459X.2005.00029.x
   Naef M., 2002, VIRTUAL REALITY SOFT, P65
   Nagel F., 2010, P AUD ENG SOC 128 CO, P1
   Newman E.B., 1933, T KANSAS ACAD SCI, V36, P172, DOI DOI 10.2307/3625353
   Parseihian G, 2012, J ACOUST SOC AM, V131, P2948, DOI 10.1121/1.3687448
   Perez-Ortiz M., 2017, arXiv preprint arXiv:1712.03686
   Pimentel T.C., 2016, Encyclopedia of Food and Health, P744, DOI [10.1016/B978-0-12-384947-2.00617-6, DOI 10.1016/B978-0-12-384947-2.00617-6]
   Plackett R. L., 1975, Applied Statistics, V24, P193, DOI 10.2307/2346567
   POULTON EC, 1979, PSYCHOL BULL, V86, P777, DOI 10.1037/0033-2909.86.4.777
   Quackenbush SR, 2021, P IEEE, V109, P1578, DOI 10.1109/JPROC.2021.3075390
   Robotham T., 2018, PROC AUDIO ENG SOC 1, P110
   Robotham T., 2018, PROC AUDIO ENG SOC 1, P15
   Rummukainen O., 2018, AUD ENG SOC C AUD VI, P1
   Rumsey F, 2005, J ACOUST SOC AM, V118, P968, DOI 10.1121/1.1945368
   Sarampalis A, 2009, J SPEECH LANG HEAR R, V52, P1230, DOI 10.1044/1092-4388(2009/08-0111)
   Scheer M, 2016, FRONT HUM NEUROSCI, V10, DOI [10.3389/fnhum.2010.00073, 10.3389/fnhum.2016.00073]
   Schinkel-Bielefeld N., 2015, PROC AUDIO ENG SOC 1, P1
   Schroeder CE, 2010, CURR OPIN NEUROBIOL, V20, P172, DOI 10.1016/j.conb.2010.02.010
   Servotte JC, 2020, CLIN SIMUL NURS, V38, P35, DOI 10.1016/j.ecns.2019.09.006
   Sporer T., 2009, PROC AUDIO ENG SOC 1, P1
   Stein B. E., 2009, MULTISENSORY COVERGE, DOI [10.1016/b978-008045046-9.01112-8, DOI 10.1016/B978-008045046-9.01112-8]
   Stein BE, 2014, NAT REV NEUROSCI, V15, P520, DOI 10.1038/nrn3742
   Stone H., 2004, Sensory evaluation practices
   Streijl RC, 2016, MULTIMEDIA SYST, V22, P213, DOI 10.1007/s00530-014-0446-1
   Susal J., 2016, PROC 2016 AUDIO ENG, P1
   Sussman ES, 2005, J ACOUST SOC AM, V117, P1285, DOI 10.1121/1.1854312
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   TVERSKY A, 1972, PSYCHOL REV, V79, P281, DOI 10.1037/h0032955
   Udesen J., 2015, PROC AUDIO ENG SOC 5, P14
   van der Heiden RMA, 2020, ACTA PSYCHOL, V205, DOI 10.1016/j.actpsy.2020.103058
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Welti T., 2019, PROC AUDIO ENG SOC 1, P1
   Wickelmaier F., 2009, P AUD ENG SOC 126 CO, P110
   Zacharov N., 1999, PROC AUDIO ENG SOC 1
   Zacharov N., 2007, PROC AUDIO ENG SOC 1, P1
   Zacharov N., 2016, 2016 Eighth International Conference on Quality of Multimedia Experience (QoMEX), P1
   Zerman E., 2018, HUMAN VISION ELECT I, V2018, P1
   Zhong XL, 2009, J ACOUST SOC AM, V125, P2209, DOI 10.1121/1.3087433
   Zielinski S, 2008, J AUDIO ENG SOC, V56, P427
NR 83
TC 6
Z9 6
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2091
EP 2101
DI 10.1109/TVCG.2022.3150491
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400024
PM 35167464
OA hybrid
DA 2024-11-06
ER

PT J
AU Mehringer, W
   Wirth, M
   Roth, D
   Michelson, G
   Eskofier, BM
AF Mehringer, Wolfgang
   Wirth, Markus
   Roth, Daniel
   Michelson, Georg
   Eskofier, Bjoern M.
TI Stereopsis Only: Validation of a Monocular Depth Cues Reduced Gamified
   Virtual Reality with Reaction Time Measurement
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Games; Stereo image processing; Training;
   Headphones; Vision defects; Software verification and validation;
   Virtual reality; Stereo vision; Visualization design
ID OCCLUSION THERAPY; VISUAL CUES; AMBLYOPIA; ADULTS; CONTRAST; GAME
AB The visual depth perception is composed of monocular and binocular depth cues. Studies show that in absence of binocular depth cues the performance of visuomotor tasks like pointing to or grasping objects is limited. Thus, binocular depth cues are of great importance for motor control required in everyday life. However, binocular depth cues like retinal disparity (basis for stereopsis) might be influenced due to developmental disorders of the visual system. For example, amblyopia in which one eye's visual input is not processed leads to loss of stereopsis. The primary amblyopia treatment is occlusion of the healthy eye to force the amblyopic eye to train. However, improvements in stereopsis are poor. Therefore, binocular treatments arose that equilibrate both eyes' visual input to enable binocular vision. However, most approaches rely on divided stimuli which do not account for loss of stereopsis. We created a Virtual Reality (VR) with reduced monocular depth cues in which a stereoscopic task is shown to both eyes simultaneously, consisting of two balls jumping towards the user. One ball appears closer to the user which must be identified. To evaluate the task performance the reaction time is measured. We validated our approach with 18 participants with stereopsis under three contrast settings including one leading to monocular vision. The number of correct responses reduces from 90% under binocular vision to 52% under monocular vision corresponding to random guessing. Our results indicate that it is possible to disable monocular depth cues and create a dynamic stereoscopic task inside a VR.
C1 [Mehringer, Wolfgang; Wirth, Markus; Eskofier, Bjoern M.] Friedrich Alexander Univ Erlangen Nurnberg, Machine Learning & Data Analyt Lab, Erlangen, Bavaria, Germany.
   [Roth, Daniel] Friedrich Alexander Univ Erlangen Nurnberg, Human Ctr Comp & Extended Real, Erlangen, Bavaria, Germany.
   [Michelson, Georg] Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Ophthalmol, Erlangen, Bavaria, Germany.
C3 University of Erlangen Nuremberg; University of Erlangen Nuremberg;
   University of Erlangen Nuremberg
RP Mehringer, W (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Machine Learning & Data Analyt Lab, Erlangen, Bavaria, Germany.
EM wolfgang.mehringer@fau.de
RI Eskofier, Bjoern/ABF-1284-2021; Roth, Daniel/AFK-2613-2022
OI Mehringer, Wolfgang/0000-0003-3513-2524
FU German Research Foundation (DFG) within the framework of the Heisenberg
   professorship programme [ES 434/8-1]
FX Bjoern Eskofier gratefully acknowledges the support of the German
   Research Foundation (DFG) within the framework of the Heisenberg
   professorship programme (grant number ES 434/8-1).
CR Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Aydindogan G, 2021, BIOMED OPT EXPRESS, V12, P511, DOI 10.1364/BOE.405026
   Beardsell R, 1999, J PEDIAT OPHTH STRAB, V36, P19
   Birch EE, 2015, J AAPOS, V19, P6, DOI 10.1016/j.jaapos.2014.09.009
   Black JM, 2011, OPTOMETRY VISION SCI, V88, pE334, DOI 10.1097/OPX.0b013e318205a162
   Blaha J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P163, DOI 10.1109/VR.2014.6802102
   Eastgate RM, 2006, EYE, V20, P370, DOI 10.1038/sj.eye.6701882
   Foss AJE, 2017, CURR OPIN OPHTHALMOL, V28, P276, DOI 10.1097/ICU.0000000000000358
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   Gaier Eric D, 2017, Int Ophthalmol Clin, V57, P117, DOI 10.1097/IIO.0000000000000184
   Gambacorta C, 2018, VISION RES, V148, P1, DOI 10.1016/j.visres.2018.04.005
   Gao TY, 2021, CLIN EXP OPTOM, V104, P773, DOI 10.1080/08164622.2021.1878834
   Gao TY, 2018, JAMA OPHTHALMOL, V136, P172, DOI 10.1001/jamaophthalmol.2017.6090
   Gerig N, 2018, ADV INTELL SYST, V663, P113, DOI 10.1007/978-3-319-67846-7_12
   Godinez A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89064-z
   Guo CX, 2016, TRIALS, V17, DOI 10.1186/s13063-016-1635-3
   Halicka J, 2020, Cesk Slov Oftalmol, V76, P24, DOI 10.31348/2020/3
   Hess RF, 2015, VISION RES, V114, P4, DOI 10.1016/j.visres.2015.02.009
   Hess RF, 2014, CLIN EXP OPTOM, V97, P389, DOI 10.1111/cxo.12192
   Hettinger J., 1992, Presence: Teleoperators Virtual Environ., V1, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Holmes JM, 2006, LANCET, V367, P1343, DOI 10.1016/S0140-6736(06)68581-4
   Howard I.P., 2012, Perceiving in Depth: Volume 2 Stereoscopic Vision, DOI [10.1093/acprof:oso/9780199764150.001.0001, DOI 10.1093/ACPROF:OSO/9780199764150.001.0001]
   Jayaram S., 2001, Journal of Computing and Information Science in Engineering, V1, P72, DOI DOI 10.1115/1.1353846
   Knill DC, 2005, J VISION, V5, P103, DOI 10.1167/5.2.2
   KUKKONEN H, 1993, VISION RES, V33, P1431, DOI 10.1016/0042-6989(93)90049-3
   Lamprogiannis L., 2020, NEUROOPHTHALMOLOGY, V14, P34, DOI DOI 10.17925/EOR.2020.14.1.34
   Lee SY, 2003, OPHTHALMOLOGY, V110, P2088, DOI 10.1016/S0161-6420(03)00865-0
   Levi DM, 2015, VISION RES, V114, P17, DOI 10.1016/j.visres.2015.01.002
   Li JR, 2011, INVEST OPHTH VIS SCI, V52, P4169, DOI 10.1167/iovs.11-7233
   Li JR, 2015, VISION RES, V114, P161, DOI 10.1016/j.visres.2015.01.017
   Loyola M, 2018, VIRTUAL REAL-LONDON, V22, P235, DOI 10.1007/s10055-017-0331-2
   Mckee SP, 2010, J VISION, V10, DOI 10.1167/10.10.5
   Melmoth DR, 2009, INVEST OPHTH VIS SCI, V50, P3711, DOI 10.1167/iovs.08-3229
   Noorden GKV., 2002, Binocular Vision and Ocular Motility: Theory and Management of Strabismus
   O'Connor AR, 2018, CLIN EXP OPTOM, V101, P485, DOI 10.1111/cxo.12655
   Pang PCK, 2021, ACTA OPHTHALMOL, V99, pE423, DOI 10.1111/aos.14595
   Papageorgiou E, 2019, GRAEF ARCH CLIN EXP, V257, P1061, DOI 10.1007/s00417-019-04254-w
   Paulus J, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01186
   Paulus J, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P310, DOI 10.1109/3DV.2013.48
   Polat U, 2009, EXPERT REV OPHTHALMO, V4, P573, DOI 10.1586/EOP.09.54
   Rice ML, 2008, J AAPOS, V12, P365, DOI 10.1016/j.jaapos.2008.01.017
   Schoemann MD, 2017, RESTOR NEUROL NEUROS, V35, P413, DOI 10.3233/RNN-170729
   Searle A, 2002, EYE, V16, P150, DOI 10.1038/sj/EYE/6700086
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Simons K, 2005, SURV OPHTHALMOL, V50, P123, DOI 10.1016/j.survophthal.2004.12.005
   To L, 2011, IEEE T NEUR SYS REH, V19, P280, DOI 10.1109/TNSRE.2011.2115255
   van de Graaf E S, 2004, Strabismus, V12, P181
   Vedamurthy I, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0264
   Vedamurthy I, 2015, SCI REP-UK, V5, DOI 10.1038/srep08482
   VONNOORDEN GK, 1979, T OPHTHAL SOC UK, V99, P442
   Waddingham PE, 2006, EYE, V20, P375, DOI 10.1038/sj.eye.6701883
   Waddingham PE., 2011, INT J DISABIL HUM DE, DOI [10.1515/IJDHD.2006.5.2.155, DOI 10.1515/IJDHD.2006.5.2.155]
   Wirth M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113728
   Ziak P, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-017-0501-8
NR 54
TC 3
Z9 3
U1 1
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2114
EP 2124
DI 10.1109/TVCG.2022.3150486
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400025
PM 35167462
DA 2024-11-06
ER

PT J
AU Nomoto, T
   Li, WL
   Peng, HL
   Watanabe, Y
AF Nomoto, Takashi
   Li, Wanlong
   Peng, Hao-Lun
   Watanabe, Yoshihiro
TI Dynamic Multi-projection Mapping Based on Parallel Intensity Control
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Low latency communication; Shape; Image
   color analysis; Geometry; Surface structures; Real-time systems;
   Projection mapping; Multi-projector; Parallel computing methodologies
ID SHADER LAMPS
AB Projection mapping using multiple projectors is promising for spatial augmented reality; however, it is difficult to apply it to dynamic scenes. This is because the conventional method decides all pixel intensities of multiple images simultaneously based on the global optimization method, and it is hard to reduce the latency from motion to projection. To mitigate this, we propose a novel method of controlling the intensity based on a pixel-parallel calculation for each projector in real-time with low latency. This parallel calculation leverages the insight that the projected pixels from different projectors in overlapping areas can be approximated independently if the pixel is sufficiently small relative to the surface structure. Additionally, our pixel-parallel calculation method allows a distributed system configuration, such that the number of projectors can be increased to form a network for high scalability. We demonstrate a seamless mapping into dynamic scenes at 360 fps with a 9.5-ms latency using ten cameras and four projectors.
C1 [Nomoto, Takashi; Li, Wanlong; Peng, Hao-Lun; Watanabe, Yoshihiro] Tokyo Inst Technol, Tokyo, Japan.
C3 Institute of Science Tokyo; Tokyo Institute of Technology
RP Nomoto, T (corresponding author), Tokyo Inst Technol, Tokyo, Japan.
EM nomoto.t.ab@m.titech.ac.jp; li.w.am@m.titech.ac.jp;
   peng.h.ab@m.titech.ac.jp; watanabe.y.cl@m.titech.ac.jp
FU Grants-in-Aid for Scientific Research [20H05959] Funding Source: KAKEN
CR Aliaga DG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159518
   [Anonymous], 2010, IEEE INT C COMPUTATI
   Asayama H., 2015, SIGGRAPH ASIA 2015 E, P7
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bermano A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508416
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409103
   Chang JHR, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275015
   Gao W, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Hiratani K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1309, DOI [10.1109/VR.2019.8798245, 10.1109/vr.2019.8798245]
   Hisaichi S., 2021, SIGGRAPH ASIA 2021 E
   Jo Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356577
   Jones A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239491, 10.1145/1276377.1276427]
   Kaminokado T., 2019, IEEE INT S MIXED AUG
   Kowdle A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275062
   Kurth P, 2018, IEEE T VIS COMPUT GR, V24, P2886, DOI 10.1109/TVCG.2018.2868530
   Lincoln P, 2011, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2011.5759447
   Lippmann U., 2021, INT DISPLAY WORKSHOP, P636
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Nomoto T., 2020, SIGGRAPH Asia 2020 Emerging Technologies, P1
   Nomoto T, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3407297
   Park H., 2006, PACIFIC RIM S IMAGE
   Peng HL, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093753
   Pjanic P, 2018, IEEE T VIS COMPUT GR, V24, P2963, DOI 10.1109/TVCG.2018.2868597
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar R, 2001, SPRING EUROGRAP, P89
   Rathinavel K, 2018, IEEE T VIS COMPUT GR, V24, P2857, DOI 10.1109/TVCG.2018.2868570
   Resch C, 2016, IEEE T VIS COMPUT GR, V22, P1291, DOI 10.1109/TVCG.2015.2450934
   Shimazu S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2011.6092393
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl Christian, 2017, [Computational Visual Media, 计算可视媒体], V3, P263
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   Watanabe Y., 2019, 26 INT DISPLAY WORKS, P1350
   Watanabe Y, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P52, DOI 10.1109/ISMAR.2017.22
   Watanabe Y, 2014, OPT REV, V21, P875, DOI 10.1007/s10043-014-0140-8
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yamazaki T, 2017, ISSCC DIG TECH PAP I, P82, DOI 10.1109/ISSCC.2017.7870271
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
NR 43
TC 13
Z9 14
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2125
EP 2134
DI 10.1109/TVCG.2022.3150488
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400026
PM 35167463
DA 2024-11-06
ER

PT J
AU Arora, N
   Suomalainen, M
   Pouke, M
   Center, EG
   Mimnaugh, KJ
   Chambers, AP
   Pouke, S
   LaValle, SM
AF Arora, Nikunj
   Suomalainen, Markku
   Pouke, Matti
   Center, Evan G.
   Mimnaugh, Katherine J.
   Chambers, Alexis P.
   Pouke, Sakaria
   LaValle, Steven M.
TI Augmenting Immersive Telepresence Experience with a Virtual Body
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Telepresence; Robots; Cameras; Resists; Robot vision systems; Avatars;
   Task analysis; Telepresence; 360-degree live streaming; Presence; Place
   Illusion
ID ENHANCES REALISTIC RESPONSE; R PACKAGE
AB We propose augmenting immersive telepresence by adding a virtual body, representing the user's own arm motions, as realized through a head-mounted display and a 360-degree camera. Previous research has shown the effectiveness of having a virtual body in simulated environments; however, research on whether seeing one's own virtual arms increases presence or preference for the user in an immersive telepresence setup is limited. We conducted a study where a host introduced a research lab while participants wore a head-mounted display which allowed them to be telepresent at the host's physical location via a 360-degree camera, either with or without a virtual body. We first conducted a pilot study of 20 participants, followed by a pre-registered 62 participant confirmatory study. Whereas the pilot study showed greater presence and preference when the virtual body was present, the confirmatory study failed to replicate these results, with only behavioral measures suggesting an increase in presence. After analyzing the qualitative data and modeling interactions, we suspect that the quality and style of the virtual arms, and the contrast between animation and video, led to individual differences in reactions to the virtual body which subsequently moderated feelings of presence.
C1 [Arora, Nikunj; Suomalainen, Markku; Pouke, Matti; Center, Evan G.; Mimnaugh, Katherine J.; Chambers, Alexis P.; Pouke, Sakaria; LaValle, Steven M.] Univ Oulu, Oulu, Finland.
C3 University of Oulu
RP Suomalainen, M (corresponding author), Univ Oulu, Oulu, Finland.
EM nikunj.arora@oulu.fi; markku.suomalainen@oulu.fi; matti.pouke@oulu.fi;
   evan.center@oulu.fi; katherine.mimnaugh@oulu.fi;
   alexis.chambers@oulu.fi; sakaria.pouke@oulu.fi; steven.lavalle@oulu.fi
RI Mimnaugh, Katherine/AAL-6536-2021
OI Pouke, Matti/0000-0002-0105-5164; Center, Evan/0009-0008-4541-713X
FU Business Finland project HUMOR [3656/31/2019]; Academy of Finland
   [322637, 331822]; SRC [293389]; European Research Council [101020977];
   European Research Council (ERC) [101020977, 322637] Funding Source:
   European Research Council (ERC); Academy of Finland (AKA) [322637,
   331822] Funding Source: Academy of Finland (AKA)
FX This work was supported by the Business Finland project HUMOR
   3656/31/2019, Academy of Finland projects PERCEPT 322637, PIXIE 331822,
   and SRC project COMBAT 293389, and European Research Council project
   ILLUSIVE 101020977.
CR [Anonymous], 2014, P 2014 CHI C EXTENDE, DOI DOI 10.1145/2559206.2581162
   [Anonymous], 2001, P ANN C SA I COMP SC
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Baldis J. J., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P166, DOI 10.1145/365024.365092
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Becerra I, 2020, IEEE ROBOT AUTOM LET, V5, P6489, DOI 10.1109/LRA.2020.3015191
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Bolt E., 2021, SCI REP-UK, V11, P1, DOI DOI 10.1038/S41598-021-94869-Z
   Casanueva J., 2001, Hardware, Software and Peopleware. South African Institute of Computer Scientist and Information Technologists Annual Conference, P19
   Chen J., 2017, EFFECT USER EMBODIME
   Danieau F, 2017, IEEE INT CON MULTI, P697, DOI 10.1109/ICME.2017.8019388
   Delignette-Muller ML, 2015, J STAT SOFTW, V64, P1, DOI 10.18637/jss.v064.i04
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   Garau M, 2008, PRESENCE-TELEOP VIRT, V17, P293, DOI 10.1162/pres.17.3.293
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Hirk R, 2020, J STAT SOFTW, V93, P1, DOI 10.18637/jss.v093.i04
   Jones Brennan, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449133
   Jung S, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P3, DOI 10.1145/3131277.3132186
   Kasahara S., 2015, P 21 ACM S VIRT REAL, P217
   Keskinen T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P423, DOI 10.1109/VR.2019.8797843
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim Jangyoon, 2017, P 27 INT C ART REAL, P153
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Koskela T, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174926
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   McLeod S.A., 2008, Likert Scale
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Mimnaugh K. J., 2021, 2021 IEEERSJ INT C I
   Minsky M., 1980, OMNI
   Noe Alva., 2006, ACTION PERCEPTION
   NOMA H, 1995, IEICE T COMMUN, VE78B, P970
   Pan Y, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00104
   Patton M.Q., 2005, ENCY STAT BEHAV SCI
   Pouke M., 2021, FRONT VIRTUAL REALIT, V2, P48
   Rae I, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2153, DOI 10.1145/2556288.2557047
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Stavar A, 2011, IFIP ADV INF COMM TE, V349, P402
   Stoll B, 2018, ACMIEEE INT CONF HUM, P14, DOI 10.1145/3171221.3171243
   Suomalainen M., 2022, P 2022 17 ACM IEEE I, P511, DOI [10.1109/HRI53351.2022.9889388, DOI 10.1109/HRI53351.2022.9889388]
   Suomalainen M, 2021, LECT NOTES COMPUT SC, V13105, P3, DOI 10.1007/978-3-030-90739-6_1
   Tang A, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1327, DOI 10.1145/3064663.3064707
   Tree JEF, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102629
   Uriu D., 2021, P 2021 CHI C HUM FAC, P1
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Whitton M, 2020, IEEE T VIS COMPUT GR
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
   Zhang GT, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382939
   Zhou S, 2014, LECT NOTES ARTIF INT, V8637, P528, DOI 10.1007/978-3-319-09767-1_63
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 65
TC 5
Z9 5
U1 0
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2135
EP 2145
DI 10.1109/TVCG.2022.3150473
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400027
PM 35167457
OA Green Submitted, hybrid, Green Published
DA 2024-11-06
ER

PT J
AU Zhang, YZ
   Yang, JL
   Liu, Z
   Wang, RC
   Chen, GJ
   Tong, X
   Guo, BN
AF Zhang, Yizhong
   Yang, Jiaolong
   Liu, Zhen
   Wang, Ruicheng
   Chen, Guojun
   Tong, Xin
   Guo, Baining
TI VirtualCube: An Immersive 3D Video Communication System
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Rendering (computer graphics); Videoconferences; Three-dimensional
   displays; Virtual environments; Real-time systems; Geometry; Cameras; 3D
   video; teleportation; telecollaboration
ID DISPLAY
AB The VirtualCube system is a 3D video conference system that attempts to overcome some limitations of conventional technologies. The key ingredient is VirtualCube, an abstract representation of a real-world cubicle instrumented with RGBD cameras for capturing the user's 3D geometry and texture. We design VirtualCube so that the task of data capturing is standardized and significantly simplified, and everything can be built using off-the-shelf hardware. We use VirtualCubes as the basic building blocks of a virtual conferencing environment, and we provide each VirtualCube user with a surrounding display showing life-size videos of remote participants. To achieve real-time rendering of remote participants, we develop the V-Cube View algorithm, which uses multi-view stereo for more accurate depth estimation and Lumi-Net rendering for better rendering quality. The VirtualCube system correctly preserves the mutual eye gaze between participants, allowing them to establish eye contact and be aware of who is visually paying attention to them. The system also allows a participant to have side discussions with remote participants as if they were in the same room. Finally, the system sheds lights on how to support the shared space of work items (e.g., documents and applications) and track participants' visual attention to work items.
C1 [Zhang, Yizhong; Yang, Jiaolong; Liu, Zhen; Chen, Guojun; Tong, Xin; Guo, Baining] Microsoft Res Asia, Beijing, Peoples R China.
   [Liu, Zhen] Nanjing Univ, Nanjing, Peoples R China.
   [Wang, Ruicheng] Univ Sci & Technol, Hefei, Peoples R China.
C3 Microsoft Research Asia; Microsoft; Nanjing University; Chinese Academy
   of Sciences; University of Science & Technology of China, CAS
RP Zhang, YZ (corresponding author), Microsoft Res Asia, Beijing, Peoples R China.
EM yizzhan@microsoft.com; jiaoyan@microsoft.com; zhenliu@smail.nju.edu.cn;
   wangrc2018cs@mail.ustc.edu.cn; guoch@microsoft.com; xtong@microsoft.com;
   baingguo@microsoft.com
OI Yang, Jiaolong/0000-0002-7314-6567; Tong, Xin/0000-0001-8788-2453; Liu,
   Zhen/0000-0002-8962-1211
CR Alexander O., 2009, ACM SIGGRAPH 2009 CO
   [Anonymous], 2017, ACM Transactions on Graphics (TOG)
   Bagautdinov T., 2021, ACM T GRAPHIC, V40
   Baker H., 2002, INT WORKSH IMM TEL, V6
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Burkov E., 2020, CVPR, P13786
   Buxton William AS, 1997, VIDEO MEDIATED COMMU, P385, DOI DOI 10.1145/142750.143070
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen Anpei, 2021, ICCV
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Chen M., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P49, DOI 10.1145/503376.503386
   Chen WC, 2000, IEEE VISUAL, P327, DOI 10.1109/VISUAL.2000.885712
   Choi I, 2019, IEEE I CONF COMP VIS, P7780, DOI 10.1109/ICCV.2019.00787
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Dong Chen, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9909, P122, DOI 10.1007/978-3-319-46454-1_8
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Elgharib M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417808
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Flynn J, 2016, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2016.595
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Garner TA, 2018, PALGRAVE STUD SOUND, P1, DOI 10.1007/978-3-319-65708-0
   Geng JH, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275043
   Gibbs SJ, 1999, MULTIMEDIA SYST, V7, P214, DOI 10.1007/s005300050123
   Giger D, 2014, IEEE INT CON MULTI
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Gotsch D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174096
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Gu KX, 2020, AAAI CONF ARTIF INTE, V34, P10861
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hsu CF, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311784
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jones A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531370
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kauff Peter, 2002, P 4 INT C COLL VIRT, P105, DOI [10.1145/571878.571895, DOI 10.1145/571878.571895]
   Kim H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P120, DOI 10.1109/VR.2019.8798247
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kuechler M, 2006, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VR.2006.71
   Kuster C., 2012, 2012 3DTV-Conference: The True Vision-Capture, Transmission and Display of 3D Video (3DTV-CON), P1
   Kuster C., 2011, Proc. Annual Workshop on Vision, P17
   Kuster C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366193
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Lipski C, 2010, COMPUT GRAPH FORUM, V29, P2555, DOI 10.1111/j.1467-8659.2010.01824.x
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Ma LX, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P881
   Maimone A, 2011, INT SYM MIX AUGMENT
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Nagata Hidenobu, 2017, J INFORM PROCESSING, V25, P142
   Nguyen David, 2005, P SIGCHI C HUM FACT, P799, DOI DOI 10.1145/1054972.1055084
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Ohl S, 2018, IEEE T VIS COMPUT GR, V24, P2827, DOI 10.1109/TVCG.2017.2767590
   Olszewski K, 2017, IEEE I CONF COMP VIS, P5439, DOI 10.1109/ICCV.2017.580
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Pluss C., 2016, P INT C COMP AN SOC, P89
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadagic A., 2001, 4th Annual International Workshop on Presence, P21
   Sengupta S, 2020, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR42600.2020.00236
   Shi JL, 2020, PROC CVPR IEEE, P2552, DOI 10.1109/CVPR42600.2020.00263
   Simonyan K., 2015, P INT C LEARN REPR I, P1
   Tausif Md Tahsin, 2020, UIST '20: 33rd Annual ACM Symposium on User Interface Software and Technology, P96, DOI 10.1145/3379350.3416197
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182644
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tola E., 2009, Virtual View Generation with a Hybrid Camera Array
   Towles H., 2002, INT WORKSHOP IMMERSI
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wang TC, 2021, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR46437.2021.00991
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
   Xu Sicheng, 2020, P IEEE CVF C COMP VI, P7710
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Zakharov Egor, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P524, DOI 10.1007/978-3-030-58610-2_31
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang C, 2013, IEEE MULTIMEDIA, V20, P17, DOI 10.1109/MMUL.2013.12
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 91
TC 26
Z9 26
U1 2
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2146
EP 2156
DI 10.1109/TVCG.2022.3150512
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400028
PM 35167475
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, SY
   Duinkharjav, B
   Sun, X
   Wei, LY
   Petrangeli, S
   Echevarria, J
   Silva, C
   Sun, Q
AF Chen, Shaoyu
   Duinkharjav, Budmonde
   Sun, Xin
   Wei, Li-Yi
   Petrangeli, Stefano
   Echevarria, Jose
   Silva, Claudio
   Sun, Qi
TI Instant Reality: Gaze-Contingent Perceptual Optimization for 3D Virtual
   Reality Streaming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Three-dimensional displays; Visualization; Rendering (computer
   graphics); Cloud computing; Streaming media; Mathematical models;
   Sensitivity; Streaming; Level of detail; Virtual reality; Head-mounted
   display; Human perception
ID IMAGE QUALITY; DISCRIMINATION; COMPRESSION
AB Media streaming, with an edge-cloud setting, has been adopted for a variety of applications such as entertainment, visualization, and design. Unlike video/audio streaming where the content is usually consumed passively, virtual reality applications require 3D assets stored on the edge to facilitate frequent edge-side interactions such as object manipulation and viewpoint movement. Compared to audio and video streaming, 3D asset streaming often requires larger data sizes and yet lower latency to ensure sufficient rendering quality, resolution, and latency for perceptual comfort. Thus, streaming 3D assets faces remarkably additional than streaming audios/videos, and existing solutions often suffer from long loading time or limited quality. To address this challenge, we propose a perceptually-optimized progressive 3D streaming method for spatial quality and temporal consistency in immersive interactions. On the cloud-side, our main idea is to estimate perceptual importance in 2D image space based on user gaze behaviors, including where they are looking and how their eyes move. The estimated importance is then mapped to 3D object space for scheduling the streaming priorities for edge-side rendering. Since this computational pipeline could be heavy, we also develop a simple neural network to accelerate the cloud-side scheduling process. We evaluate our method via subjective studies and objective analysis under varying network conditions (from 3G to 5G) and edge devices (HMD and traditional displays), and demonstrate better visual quality and temporal consistency than alternative solutions.
C1 [Chen, Shaoyu; Duinkharjav, Budmonde; Silva, Claudio; Sun, Qi] NYU, New York, NY 10003 USA.
   [Sun, Xin; Wei, Li-Yi; Petrangeli, Stefano; Echevarria, Jose] Adobe Res, San Jose, CA USA.
C3 New York University; Adobe Systems Inc.
RP Chen, SY (corresponding author), NYU, New York, NY 10003 USA.
EM sc6439@nyu.edu; budmonde@nyu.edu; xinsun@adobe.com; lwei@adobe.com;
   petrange@adobe.com; echevarr@adobe.com; csilva@nyu.edu; qisun@nyu.edu
RI Wei, Li-Yi/F-4469-2011; Sun, Xin/HSF-4456-2023
OI Chen, Shaoyu/0000-0002-1856-6294
FU NSF [CNS-1229185, CCF-1533564, CNS-1544753, CNS-1730396, CNS-1828576,
   CNS1626098]; DARPA PTG program
FX This work was supported in part by: NSF awards CNS-1229185, CCF-1533564,
   CNS-1544753, CNS-1730396, CNS-1828576, CNS1626098; and a generous gift
   from Adobe, Inc. C. T. Silva and Q. Sun are partially supported by the
   DARPA PTG program. Any opinions, findings, and conclusions or
   recommendations expressed in this material are those of the authors and
   do not necessarily reflect the views of DARPA.
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Arabadzhiyska E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073642
   BARTEN PGJ, 1990, J OPT SOC AM A, V7, P2024, DOI 10.1364/JOSAA.7.002024
   Brown R., 2021, EFFICIENT DATAFLOW M
   Bruckert A., 2021, LOOK MOVIES ANAL VIS
   Cohen MA, 2020, P NATL ACAD SCI USA, V117, P13821, DOI 10.1073/pnas.1922294117
   Cohen-Or D, 1999, COMP GRAPH, P261, DOI 10.1145/311535.311564
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   ELLIOTT DB, 1995, OPTOMETRY VISION SCI, V72, P186, DOI 10.1097/00006324-199503000-00006
   Ferwerda J. A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P143, DOI 10.1145/258734.258818
   Griffin W, 2015, IEEE T VIS COMPUT GR, V21, P970, DOI 10.1109/TVCG.2015.2429576
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Gutterman C, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P327, DOI 10.1145/3339825.3397044
   Hillaire S, 2012, IEEE T VIS COMPUT GR, V18, P356, DOI 10.1109/TVCG.2011.154
   Hladky J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356530
   Hu P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356490
   Ibbotson M, 2011, CURR OPIN NEUROBIOL, V21, P553, DOI 10.1016/j.conb.2011.05.012
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Knöll J, 2011, J VISION, V11, DOI 10.1167/11.14.15
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Lavoué G, 2019, IEEE T VIS COMPUT GR, V25, P1336, DOI 10.1109/TVCG.2018.2805355
   Levoy M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P21, DOI 10.1145/218380.218392
   Luebke D., 2003, LEVEL DETAIL 3D GRAP, V301, pxvii
   Luidolt LR, 2020, IEEE T VIS COMPUT GR, V26, P3557, DOI 10.1109/TVCG.2020.3023604
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Mengtian Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P473, DOI 10.1007/978-3-030-58536-5_28
   Murphy H., 2001, Eurographics
   Párraga CA, 2005, VISION RES, V45, P3145, DOI 10.1016/j.visres.2005.08.006
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Petrangeli S, 2019, IEEE INT SYM MULTIM, P56, DOI 10.1109/ISM46123.2019.00017
   Raca D, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P303, DOI 10.1145/3339825.3394938
   Rashidi S., 2020, Advances in Neural Information Processing Systems, V33, P9288
   Riiser H., 2013, P 4 ACM MULT SYST C, P114
   Romero-Rondón MF, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P494, DOI 10.1145/3204949.3208114
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Schütz M, 2020, COMPUT GRAPH FORUM, V39, P51, DOI 10.1111/cgf.13911
   Schwarz M., 2009, Proceedings of the 6th symposium on applied perception in graphics and visualization, DOI DOI 10.1145/1620993.1621012
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Serrano C., 2009, VTC SPRING 2009 IEEE, P1, DOI [10.1109/VETECS 2009.5073642, DOI 10.1109/VETECS2009.5073642]
   Shi Shu., 2019, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services, P130
   Shuai YT, 2015, IEEE ICC, P6874, DOI 10.1109/ICC.2015.7249421
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Stengel M, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P159, DOI 10.1145/3458305.3463379
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130807
   Tursun OT, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322985
   Walton DR, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459943
   Wang LL, 2020, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR50242.2020.00017
   Wang YZ, 1997, VISION RES, V37, P283, DOI 10.1016/S0042-6989(96)00160-5
   WATSON AB, 1986, J OPT SOC AM A, V3, P300, DOI 10.1364/JOSAA.3.000300
   Watson AB, 2014, J VISION, V14, DOI 10.1167/14.7.15
   Weier M, 2017, COMPUT GRAPH FORUM, V36, P611, DOI 10.1111/cgf.13150
   Zhang WX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2232, DOI 10.1145/3442381.3449829
NR 57
TC 13
Z9 15
U1 3
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2157
EP 2167
DI 10.1109/TVCG.2022.3150522
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400029
PM 35148266
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Robles, M
   Namdarian, N
   Otto, J
   Wassiljew, E
   Navab, N
   Falter-Wagner, C
   Roth, D
AF Robles, Marta
   Namdarian, Negar
   Otto, Julia
   Wassiljew, Evelyn
   Navab, Nassir
   Falter-Wagner, Christine
   Roth, Daniel
TI A Virtual Reality Based System for the Screening and Classification of
   Autism
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Autism; Avatars; Tutorials; Virtual environments; Reliability; Machine
   learning; Three-dimensional displays; Virtual reality; autism; machine
   learning; agents; embodiment; diagnosis
ID HIGH-FUNCTIONING AUTISM; EYE-TRACKING; CHILDREN; ADULTS; GAZE; QUOTIENT
AB Autism - also known as Autism Spectrum Disorders or Autism Spectrum Conditions - is a neurodevelopmental condition characterized by repetitive behaviours and differences in communication and social interaction. As a consequence, many autistic individuals may struggle in everyday life, which sometimes manifests in depression, unemployment, or addiction. One crucial problem in patient support and treatment is the long waiting time to diagnosis, which was approximated to thirteen months on average. Yet, the earlier an intervention can take place the better the patient can be supported, which was identified as a crucial factor. We propose a system to support the screening of Autism Spectrum Disorders based on a virtual reality social interaction, namely a shopping experience, with an embodied agent. During this everyday interaction, behavioral responses are tracked and recorded. We analyze this behavior with machine learning approaches to classify participants from an autistic participant sample in comparison to a typically developed individuals control sample with high accuracy, demonstrating the feasibility of the approach. We believe that such tools can strongly impact the way mental disorders are assessed and may help to further find objective criteria and categorization.
C1 [Robles, Marta; Wassiljew, Evelyn; Falter-Wagner, Christine] Ludwig Maximilians Univ Munchen, Outpatient Clin, Munich, Germany.
   [Robles, Marta] Autonomus Univ Barcelona UAB, Dept Clin & Hlth Psychol, Barcelona, Spain.
   [Namdarian, Negar; Otto, Julia; Navab, Nassir] Tech Univ Munich, Munich, Germany.
   [Roth, Daniel] Friedrich Alexander Univ Erlangen Nurnberg, Erlangen, Germany.
C3 University of Hamburg; University Medical Center Hamburg-Eppendorf;
   University of Munich; Autonomous University of Barcelona; Technical
   University of Munich; University of Erlangen Nuremberg
RP Roth, D (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Erlangen, Germany.
EM d.roth@fau.de
RI Roth, Daniel/AFK-2613-2022
CR A. der Wissenschaftlichen Medizinischen Fachgesellschaften e.V. (AWMF), 2015, S3 LEITINLE AUTISMUS
   Adjorlu A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P294, DOI 10.1109/ISMAR-Adjunct.2017.93
   [Anonymous], 2000, JAMA, V284, P3043
   Areces D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201039
   Areces D, 2018, J ATTEN DISORD, V22, P1081, DOI 10.1177/1087054716629711
   Arzt D, 2006, GRUNDINTELLIGENZTEST
   Au-Yeung SK, 2019, AUTISM, V23, P1508, DOI 10.1177/1362361318818167
   Bailenson J., AVATARS
   Baron-Cohen S, 2001, J AUTISM DEV DISORD, V31, P5, DOI 10.1023/A:1005653411471
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Berenguer C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176143
   Bruining H, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010887
   Camero R, 2021, CHILDREN-BASEL, V8, DOI 10.3390/children8020113
   Clark J. H., 1924, American Journal of Physiological Optics, V5, P269
   Clay V, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.1.3
   Cusack J., 2016, YOUR QUESTIONS SHAPI
   de Borst AW, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00576
   Drimalla H, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0227-5
   DSM-5 American Psychiatric Association, 2013, Diagnostic and Statistical Manual of Mental Disorders, V5th ed., DOI [10.1176/appi.books.9780890425596.dsm10, DOI 10.1176/APPI.BOOKS.9780890425596.DSM10]
   Elsabbagh M, 2009, BIOL PSYCHIAT, V65, P31, DOI 10.1016/j.biopsych.2008.09.034
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fabiano D, 2020, PATTERN RECOGN LETT, V135, P204, DOI 10.1016/j.patrec.2020.04.028
   Fridenson-Hayo S, 2017, EUR CHILD ADOLES PSY, V26, P979, DOI 10.1007/s00787-017-0968-0
   Georgescu AL, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00132
   Georgescu AL, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00807
   Geron A., 2019, HANDS ON MACHINE LEA
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hautzinger M., 2006, BECK DEPRESSIONS INV
   Hodges H, 2020, TRANSL PEDIATR, V9, P55, DOI 10.21037/tp.2019.09.09
   Hosozawa M, 2021, AUTISM, V25, P70, DOI 10.1177/1362361320945540
   Huang YH, 2020, AUTISM, V24, P1311, DOI 10.1177/1362361320903128
   Hume K, 2021, J AUTISM DEV DISORD, V51, P4013, DOI 10.1007/s10803-020-04844-2
   Jiang M, 2017, IEEE I CONF COMP VIS, P3287, DOI 10.1109/ICCV.2017.354
   Kirby A, 2010, RES DEV DISABIL, V31, P131, DOI 10.1016/j.ridd.2009.08.010
   Klin A, 2002, ARCH GEN PSYCHIAT, V59, P809, DOI 10.1001/archpsyc.59.9.809
   Koehler JC, 2022, J AUTISM DEV DISORD, V52, P3718, DOI 10.1007/s10803-021-05194-3
   Koirala A, 2021, IEEE T NEUR SYS REH, V29, P619, DOI 10.1109/TNSRE.2021.3064148
   Lai MC, 2015, LANCET PSYCHIAT, V2, P1013, DOI 10.1016/S2215-0366(15)00277-1
   Leedham A, 2020, AUTISM, V24, P135, DOI 10.1177/1362361319853442
   Lehrl S., 1991, Mehrfachwahl-Wortschatz-Intelligenztest: MWT-B. Nurnberg
   Liu WB, 2016, AUTISM RES, V9, P888, DOI 10.1002/aur.1615
   Liu WB, 2015, INT CONF AFFECT, P649, DOI 10.1109/ACII.2015.7344638
   Lord C, 2006, ARCH GEN PSYCHIAT, V63, P694, DOI 10.1001/archpsyc.63.6.694
   LORD C, 2012, AUTISM DIAGNOSTIC 2
   Maddox BB, 2017, J AUTISM DEV DISORD, V47, P2703, DOI 10.1007/s10803-017-3188-z
   Maskey M, 2019, AUTISM ADULTHOOD, V1, P134, DOI 10.1089/aut.2018.0019
   Maskey M, 2019, J AUTISM DEV DISORD, V49, P1912, DOI 10.1007/s10803-018-3861-x
   Moon J, 2019, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2019.1613665
   Mottron L, 2020, MOL PSYCHIATR, V25, P3178, DOI 10.1038/s41380-020-0748-y
   Neumann D, 2006, SOC COGN AFFECT NEUR, V1, P194, DOI 10.1093/scan/nsl030
   Newbutt N, 2016, ANN REV CYBERTHERAPY, V14, P149
   Optical S, OR STER FLY STER
   Orlosky J, 2017, IEEE T VIS COMPUT GR, V23, P1417, DOI 10.1109/TVCG.2017.2657018
   Papagiannopoulou EA, 2014, SOC NEUROSCI-UK, V9, P610, DOI 10.1080/17470919.2014.934966
   Penner M, 2018, AUTISM, V22, P517, DOI 10.1177/1362361316685879
   Rajpurkar P., 2017, ARXIV171105225 CS ST
   Ramachandiran C. R., 2015, VIRTUAL REALITY BASE
   Roth Daniel, 2015, i-com: A Journal of Interactive and Cooperative Media, V14, P107, DOI 10.1515/icom-2015-0030
   Roth D., 2019, VR DEVELOPER GEMS, P26
   Roth D, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P115, DOI 10.1109/AIVR50618.2020.00029
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P103, DOI 10.1109/ISMAR-Adjunct.2018.00044
   Roth D, 2016, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2016.7504760
   Rubido MD, 2018, AUTISM RES, V11, P1567, DOI 10.1002/aur.2026
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   W. H. Organization, 2019, ICD11
   Wade J, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2892636
   Yaneva V, 2020, IEEE T NEUR SYS REH, V28, P1254, DOI 10.1109/TNSRE.2020.2991675
   Yaneva V, 2018, 15TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A) 2018, DOI 10.1145/3192714.3192819
   Zhao H, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3231938
   Zheng Z, 2017, IEEE T NEUR SYS REH, V25, P668, DOI 10.1109/TNSRE.2016.2598727
NR 72
TC 14
Z9 15
U1 4
U2 51
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2168
EP 2178
DI 10.1109/TVCG.2022.3150489
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400030
PM 35171773
OA hybrid
DA 2024-11-06
ER

PT J
AU Dibene, JC
   Maldonado, Y
   Trujillo, L
   Dunn, E
AF Dibene, Juan Carlos
   Maldonado, Yazmin
   Trujillo, Leonardo
   Dunn, Enrique
TI Prepare for Ludicrous Speed: Marker-based Instantaneous Binocular
   Rolling Shutter Localization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Absolute pose estimation; Cross ratio; Rolling shutter; FPGA
ID CROSS-RATIO; CLUSTER
AB We propose a marker-based geometric framework for the high-frequency absolute 3D pose estimation of a binocular camera system by using the data captured during the exposure of a single rolling shutter scanline. In contrast to existing approaches enforcing temporal or motion models among scanlines (e.g. linear motion, constant velocity or small motion assumptions), we strive to determine the pose from instantaneous binocular capture (i.e. without using data from previous scanlines) and achieve drift-free pose estimation. We leverage the projective invariants of a novel rigid planar pattern, to both define a geometric reference as well as to determine 2D-3D correspondences from raw edge detection measurements from individual scanlines. Moreover, to tackle the ensuing multi-view estimation problem, achieve real-time operation, and minimize latency, we develop a pair of custom solvers leveraging our geometric setup. To mitigate sensitivity to noise, we propose a geometrically consistent measurement refinement mechanism. We verify the quality of our solvers by comparing with state of the art general solvers for absolute pose estimation of generalized cameras. Finally, we demonstrate the effectiveness of our proposed approach with an FPGA-based implementation which achieves a localization throughput of 129.6 KHz with a 1.5 mu s latency.
C1 [Dibene, Juan Carlos; Dunn, Enrique] Stevens Inst Technol, Hoboken, NJ 07030 USA.
   [Maldonado, Yazmin; Trujillo, Leonardo] Inst Tecnol Tijuana, Tijuana, Mexico.
C3 Stevens Institute of Technology
RP Dibene, JC (corresponding author), Stevens Inst Technol, Hoboken, NJ 07030 USA.
EM jdibenes@stevens.edu; yaz.maldonado@tectijuana.edu.mx;
   leonardo.trujillo@tectijuana.edu.mx; edunn@stevens.edu
RI Trujillo, Leonardo/L-2939-2017
OI Trujillo, Leonardo/0000-0003-1812-5736; Dunn,
   Enrique/0000-0002-5436-0023
CR Albl C, 2020, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR42600.2020.00258
   Albl C, 2016, PROC CVPR IEEE, P3355, DOI 10.1109/CVPR.2016.365
   Albl C, 2015, PROC CVPR IEEE, P2292, DOI 10.1109/CVPR.2015.7298842
   [Anonymous], 2005, 6th OmniVis WS
   Bapat A, 2018, PROC CVPR IEEE, P4824, DOI 10.1109/CVPR.2018.00507
   Bapat A, 2016, IEEE T VIS COMPUT GR, V22, P2358, DOI 10.1109/TVCG.2016.2593757
   Blate A, 2019, IEEE T VIS COMPUT GR, V25, P1970, DOI 10.1109/TVCG.2019.2899233
   Dai YC, 2016, PROC CVPR IEEE, P4132, DOI 10.1109/CVPR.2016.448
   Dhall A, 2019, IEEE INT VEH SYM, P494, DOI 10.1109/IVS.2019.8814089
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Güzel AE, 2020, SIG PROCESS COMMUN, DOI 10.1109/siu49456.2020.9302192
   Han I, 2016, FORENSIC SCI INT, V269, P89, DOI 10.1016/j.forsciint.2016.11.014
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759
   HORAUD R, 1993, IEEE T ROBOTIC AUTOM, V9, P71, DOI 10.1109/70.210796
   Huynh D., 2000, PROCEDINGS BRIT MACH, P27, DOI [10.5244/c.14.27, DOI 10.5244/C.14.27]
   Ito E, 2017, PROC CVPR IEEE, P4512, DOI 10.1109/CVPR.2017.480
   Ke T, 2017, PROC CVPR IEEE, P4618, DOI 10.1109/CVPR.2017.491
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464
   Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9
   Lao YZ, 2018, PROC CVPR IEEE, P4795, DOI 10.1109/CVPR.2018.00504
   Lao YZ, 2018, LECT NOTES COMPUT SC, V11206, P477, DOI 10.1007/978-3-030-01216-8_29
   Li DD, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.014104
   Li DD, 2014, OPT LASER ENG, V62, P119, DOI 10.1016/j.optlaseng.2014.03.004
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Magerand L, 2012, LECT NOTES COMPUT SC, V7572, P456, DOI 10.1007/978-3-642-33718-5_33
   MAYBANK SJ, 1995, INT J COMPUT VISION, V14, P199, DOI 10.1007/BF01679682
   Merzban MH, 2014, INT CONF 3D IMAG
   Nakai T., 2005, INT WORKSHOP CAMERA, P87
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nistér D, 2004, PROC CVPR IEEE, P652
   Persson Mikael, 2018, P EUR C COMP VIS ECC
   Ramalingam S, 2015, PROC CVPR IEEE, P1238, DOI 10.1109/CVPR.2015.7298728
   Rengarajan V, 2016, PROC CVPR IEEE, P2773, DOI 10.1109/CVPR.2016.303
   Saurer O, 2016, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2016.363
   Saurer O, 2015, IEEE INT C INT ROBOT, P1328, DOI 10.1109/IROS.2015.7353540
   Saurer O, 2013, IEEE I CONF COMP VIS, P465, DOI 10.1109/ICCV.2013.64
   Schubert D, 2018, LECT NOTES COMPUT SC, V11212, P699, DOI 10.1007/978-3-030-01237-3_42
   Su D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061885
   Usamentiaga R, 2020, APPL OPTICS, V59, P9443, DOI 10.1364/AO.404774
   Vasu S, 2018, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2018.00073
   Wang B, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104009
   Wang K., IEEE ROBOT AUTOM LET, P2021, DOI [10.1109/LRA.2021.306369, DOI 10.1109/LRA.2021.306369]
   Xilinx, Ultrascale architecture configuration
   Yu J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051829
   Zhang YI, 2009, IEEE IMAGE PROC, P3549, DOI 10.1109/ICIP.2009.5414338
   Zhuang BB, 2019, PROC CVPR IEEE, P4546, DOI 10.1109/CVPR.2019.00468
   Zhuang BB, 2017, IEEE I CONF COMP VIS, P948, DOI 10.1109/ICCV.2017.108
NR 47
TC 3
Z9 3
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2201
EP 2211
DI 10.1109/TVCG.2022.3150485
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400032
PM 35167461
DA 2024-11-06
ER

PT J
AU Bao, HJ
   Xie, WJ
   Qian, QH
   Chen, DP
   Zhai, SJ
   Wang, N
   Zhang, GF
AF Bao, Hujun
   Xie, Weijian
   Qian, Quanhao
   Chen, Danpeng
   Zhai, Shangjin
   Wang, Nan
   Zhang, Guofeng
TI Robust Tightly-Coupled Visual-Inertial Odometry with Pre-built Maps in
   High Latency Situations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Location awareness; Real-time systems; Visualization; Point cloud
   compression; Global Positioning System; Trajectory; Servers; Pre-built
   Map; VIO; Tightly-Coupled; High Latency
ID MONOCULAR SLAM; LARGE-SCALE; LOCALIZATION; LIDAR; OPTIMIZATION;
   VERSATILE; VISION; FUSION
AB In this paper, we present a novel monocular visual-inertial odometry system with pre-built maps deployed on the remote server, which can robustly run in real-time on a mobile device even in high latency situations. By tightly coupling VIO with geometric priors from pre-built maps, our system can tolerate the high latency and low frequency of global localization service, which is especially suitable for practical applications when the localization service is deployed on the remote server. Firstly, sparse point clouds are obtained from the dense mesh by the ray casting method according to the localization results. The dense mesh can be reconstructed from the point clouds generated by Structure-from-Motion. We directly use the sparse point clouds in feature tracking and state update to suppress drift. In the process of feature tracking, the high local accuracy of VIO is fully utilized to effectively remove outliers and make our system robust. The experiments on EurocMav datasets and simulation datasets show that compared with state-of-the-art methods, our method can achieve better results in terms of both precision and robustness. The effectiveness of the proposed method is further demonstrated through a real-time AR demo on a mobile phone with the aid of visual localization on the remote server.
C1 [Bao, Hujun; Xie, Weijian; Chen, Danpeng; Zhang, Guofeng] Zhejiang Univ, State Key Lab CADCG, Hangzhou, Zhejiang, Peoples R China.
   [Xie, Weijian; Qian, Quanhao; Chen, Danpeng; Zhai, Shangjin; Wang, Nan] SenseTime Res, Hangzhou, Zhejiang, Peoples R China.
   [Xie, Weijian; Qian, Quanhao; Chen, Danpeng; Zhai, Shangjin; Wang, Nan] Tetras AI, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CADCG, Hangzhou, Zhejiang, Peoples R China.
EM baohujun@zju.edu.cn; xieweijian@sensetime.com;
   qianquanhao1@sensetime.com; chendanpeng@tetras.ai;
   zhaishangjin@sensetime.com; wangnan@tetras.ai; zhangguofeng@zju.edu.cn
RI Zhang, Ge/K-9118-2019
FU NSF of China [61932003]
FX The authors would like to thank Youji Feng, Liyang Zhou, Fei Jiao,
   Mingxuan Jiang, Chongshan Sheng, Yuequ Cai for their kind help in the
   development of the global localization service and the real-time AR
   demo. This work was partially supported by NSF of China (No. 61932003).
CR AHMED NA, 1989, IEEE T INFORM THEORY, V35, P688, DOI 10.1109/18.30996
   [Anonymous], 2017, FSR
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Campos C., 2020, ORB SLAM3 ACCURATE O
   Caselitz T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1926, DOI 10.1109/IROS.2016.7759304
   Cioffi G, 2020, IEEE INT C INT ROBOT, P5089, DOI 10.1109/IROS45743.2020.9341697
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI [10.1109/ICRA40945.2020.9196524, 10.1109/icra40945.2020.9196524]
   Huang H.-L., 2020, ARXIV PREPRINT ARXIV
   Huang HY, 2020, IEEE ROBOT AUTOM LET, V5, P5043, DOI 10.1109/LRA.2020.3005130
   Kim Y, 2018, IEEE INT C INT ROBOT, P5826
   Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251
   Li T, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060610
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2020, SPR PROC ADV ROBOT, V10, P727, DOI 10.1007/978-3-030-28619-4_51
   Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Mascaro R, 2018, IEEE INT CONF ROBOT, P1421
   Maybeck P. S., 1982, STOCHASTIC MODELS ES
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Platinsky L, 2020, INT SYM MIX AUGMENT, P533, DOI 10.1109/ISMAR50242.2020.00081
   Qin T, 2018, IEEE INT CONF ROBOT, P1197
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Qin Tong, 2019, arXiv preprint arXiv:1901.03642
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   ROTH SD, 1982, COMPUT VISION GRAPH, V18, P109, DOI 10.1016/0146-664X(82)90169-1
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662
   Schonberger JL., 2016, AS C COMP VIS, P321
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Svärm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Wu KJ, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Ye HY, 2020, IEEE INT CONF ROBOT, P8892, DOI 10.1109/icra40945.2020.9197022
   Zuo XX, 2019, IEEE ROBOT AUTOM LET, V4, P3394, DOI 10.1109/LRA.2019.2927123
NR 52
TC 5
Z9 5
U1 0
U2 30
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2212
EP 2222
DI 10.1109/TVCG.2022.3150495
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400033
PM 35167466
DA 2024-11-06
ER

PT J
AU Kageyama, Y
   Iwai, D
   Sato, K
AF Kageyama, Yuta
   Iwai, Daisuke
   Sato, Kosuke
TI Online Projector Deblurring Using a Convolutional Neural Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Generators; Attenuation; Cameras; Deep learning; Calibration; Neural
   networks; Estimation; Projector deblurring; dynamic projection mapping;
   deep neural network
ID ALGORITHMS; TRACKING; ROBUST
AB Projector deblurring is an important technology for dynamic projection mapping (PM), where the distance between a projector and a projection surface changes in time. However, conventional projector deblurring techniques do not support dynamic PM because they need to project calibration patterns to estimate the amount of defocus blur each time the surface moves. We present a deep neural network that can compensate for defocus blur in dynamic PM. The primary contribution of this paper is a unique network structure that consists of an extractor and a generator. The extractor explicitly estimates a defocus blur map and a luminance attenuation map. These maps are then injected into the middle layers of the generator network that computes the compensation image. We also propose a pseudo-projection technique for synthesizing physically plausible training data, considering the geometric misregistration that potentially happens in actual PM systems. We conducted simulation and actual PM experiments and confirmed that: (1) the proposed network structure is more suitable than a simple, more general structure for projector deblurring; (2) the network trained with the proposed pseudo-projection technique can compensate projection images for defocus blur artifacts in dynamic PM; and (3) the network supports the translation speed of the surface movement within a certain range that covers normal human motions.
C1 [Kageyama, Yuta; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
   [Iwai, Daisuke] Japan Sci & Technol Agcy, PRESTO, Kawaguchi, Saitama, Japan.
C3 Osaka University; Japan Science & Technology Agency (JST)
RP Kageyama, Y (corresponding author), Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
EM kageyama@sens.sys.es.osaka-u.ac.jp; daisuke.iwai@sys.es.osaka-u.ac.jp;
   sato@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Iwai, Daisuke/0000-0002-3493-5635
FU JSPS KAKENHI [JP20H05958]; JST,PRESTO, Japan [JPMJPRI 9J2];
   Grants-in-Aid for Scientific Research [20H05958] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI Grant Numbers JP20H05958 and
   JST,PRESTO Grant Number JPMJPRI 9J2, yJapan.
CR Aliaga DG, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159518
   Amano T, 2014, IEEE COMPUT SOC CONF, P449, DOI 10.1109/CVPRW.2014.72
   [Anonymous], 2015, MICCAL, DOI DOI 10.1007/978-3-319-24574-4_28
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bermano A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508416
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber D., 2008, ACM SIGGRAPH 2008 CL, P1
   Bimber O, 2006, IEEE T VIS COMPUT GR, V12, P658, DOI 10.1109/TVCG.2006.75
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Brown M. S., 2006, 2006 IEEE COMP SOC C, V2, P1956
   Deng Senyou, 2021, ICCV., P14030
   Favaro P, 2005, IEEE T PATTERN ANAL, V27, P406, DOI 10.1109/TPAMI.2005.43
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Grosse M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805966
   Grundhöfer A, 2015, IEEE T IMAGE PROCESS, V24, P5086, DOI 10.1109/TIP.2015.2478388
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   He K., 2016, IEEE C COMPUTER VISI, P770, DOI DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang B., 2021, IEEE T PATTERN ANAL
   Huang BY, 2021, IEEE T VIS COMPUT GR, V27, P2725, DOI 10.1109/TVCG.2021.3067771
   Huang BY, 2019, IEEE I CONF COMP VIS, P7164, DOI 10.1109/ICCV.2019.00726
   Huang BY, 2019, PROC CVPR IEEE, P6803, DOI 10.1109/CVPR.2019.00697
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P2659, DOI 10.1109/TVCG.2021.3067764
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Iwai D, 2015, IEEE T VIS COMPUT GR, V21, P462, DOI 10.1109/TVCG.2015.2391861
   Iwai D, 2011, VIRTUAL REAL-LONDON, V15, P147, DOI 10.1007/s10055-010-0159-5
   Jones B., 2013, P SIGCHI C HUM FACT, P869, DOI DOI 10.1145/2470654.2466112
   Joshi N, 2008, PROC CVPR IEEE, P3823
   Kageyama Y, 2020, OPT EXPRESS, V28, P20391, DOI 10.1364/OE.396159
   Kingma DP, 2014, ADV NEUR IN, V27
   Matsushita K., 2011, P 2 AUGM HUM INT C
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Nagase M, 2011, VIRTUAL REAL-LONDON, V15, P119, DOI 10.1007/s10055-010-0168-4
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Oyamada Y, 2007, PROC CVPR IEEE, P3520
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sueishi T, 2016, PRESENCE-VIRTUAL AUG, V25, P299, DOI 10.1162/PRES_a_00275
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takezawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI [10.1109/vr.2019.8797923, 10.1109/VR.2019.8797923]
   Tone D, 2020, IEEE T VIS COMPUT GR, V26, P2030, DOI 10.1109/TVCG.2020.2973444
   Wang D., 2005, 2005 IEEE COMPUTER S
   Wang LH, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3408333
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Zhang L, 2006, ACM T GRAPHIC, V25, P907, DOI 10.1145/1141911.1141974
NR 52
TC 11
Z9 12
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2223
EP 2233
DI 10.1109/TVCG.2022.3150465
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400034
PM 35167455
OA hybrid
DA 2024-11-06
ER

PT J
AU Groth, C
   Tauscher, JP
   Heesen, N
   Hattenbach, M
   Castillo, S
   Magnor, M
AF Groth, Colin
   Tauscher, Jan-Philipp
   Heesen, Nikkel
   Hattenbach, Max
   Castillo, Susana
   Magnor, Marcus
TI Omnidirectional Galvanic Vestibular Stimulation in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Visualization; Games; Cybersickness; Streaming media; Cameras; Motion
   pictures; Three-dimensional displays; Galvanic Vestibular Stimulation;
   GVS; Virtual Reality; VR; 360 Videos; Cybersickness; Presence
ID MOTION SICKNESS; MOVEMENT; TDCS
AB In this paper we propose omnidirectional galvanic vestibular stimulation (GVS) to mitigate cybersickness in virtual reality applications. One of the most accepted theories indicates that Cybersickness is caused by the visually induced impression of ego motion while physically remaining at rest. As a result of this sensory mismatch, people associate negative symptoms with VR and sometimes avoid the technology altogether. To reconcile the two contradicting sensory perceptions, we investigate GVS to stimulate the vestibular canals behind our ears with low-current electrical signals that are specifically attuned to the visually displayed camera motion. We describe how to calibrate and generate the appropriate GVS signals in real-time for pre-recorded omnidirectional videos exhibiting ego-motion in all three spatial directions. For validation, we conduct an experiment presenting real-world 360 degrees videos shot from a moving first-person perspective in a VR head-mounted display. Our findings indicate that GVS is able to significantly reduce discomfort for cybersickness-susceptible VR users, creating a deeper and more enjoyable immersive experience for many people.
C1 [Groth, Colin; Tauscher, Jan-Philipp; Heesen, Nikkel; Castillo, Susana; Magnor, Marcus] TU Braunschweig, Inst Comp Graph, Braunschweig, Germany.
   [Hattenbach, Max] Univ Osnabruck, Osnabruck, Germany.
C3 Braunschweig University of Technology; University Osnabruck
RP Groth, C (corresponding author), TU Braunschweig, Inst Comp Graph, Braunschweig, Germany.
EM groth@cg.cs.tu-bs.de; tauscher@cg.cs.tu-bs.de; heesen@cg.cs.tu-bs.de;
   mhattenbach@uni-osnabrueck.de; castillo@cg.cs.tu-bs.de;
   magnor@cg.cs.tu-bs.de
RI Castillo, Susana/U-6432-2019
OI Groth, Colin/0000-0001-6445-5563; Magnor, Marcus/0000-0003-0579-480X;
   Castillo, Susana/0000-0003-1245-4758
FU German Science Foundation [DFG MA2555/15-1]
FX The authors gratefully acknowledge funding by the German Science
   Foundation (DFG MA2555/15-1 "Immersive Digital Reality").
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   [Anonymous], INSTA360 PRO
   [Anonymous], GOOD VIBRATIONS ENG
   Aoyama K, 2015, SCI REP-UK, V5, DOI 10.1038/srep10168
   Bala Paulo, 2020, IMX '20: ACM International Conference on Interactive Media Experiences, P82, DOI 10.1145/3391614.3393658
   Bala P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P244, DOI 10.1109/ISMAR-Adjunct.2018.00077
   Brunoni AR, 2011, INT J NEUROPSYCHOPH, V14, P1133, DOI 10.1017/S1461145710001690
   Budhiraja P., 2017, ARXIV PREPRINT ARXIV
   Byrne R, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P159, DOI 10.1145/2967934.2968080
   Cevette MJ, 2012, AVIAT SPACE ENVIR MD, V83, P549, DOI 10.3357/ASEM.3239.2012
   Danieau F., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P541, DOI 10.1109/HAPTIC.2012.6183844
   Day BL, 1997, J PHYSIOL-LONDON, V500, P661, DOI 10.1113/jphysiol.1997.sp022051
   DiZio P, 1997, ADV HUM FACT ERGON, V21, P893
   Doyle DD, 2014, MEASUREMENT, V48, P195, DOI 10.1016/j.measurement.2013.10.025
   Ebrahimi Elham, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P97, DOI 10.1109/3DUI.2015.7131732
   Ebrahimi E., 2014, P ACM INT S APPL PER, P103
   Elwardy M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P477, DOI [10.1109/VRW50115.2020.00100, 10.1109/VRW50115.2020.0-176]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   FITZPATRICK R, 1994, J PHYSIOL-LONDON, V478, P363, DOI 10.1113/jphysiol.1994.sp020257
   Fujimoto C, 2016, SCI REP-UK, V6, DOI 10.1038/srep37575
   Galvani A, 1791, VIRIBUS ELECTRICITAT
   Grassini S, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01604
   Groth Colin, 2021, 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P486, DOI 10.1109/VRW52623.2021.00125
   Groth C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P169, DOI 10.1109/VRW52623.2021.00039
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Irwin J. A., 1881, The Lancet, V118, P907
   Kennedy RS, 2010, APPL ERGON, V41, P494, DOI 10.1016/j.apergo.2009.11.006
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim S., 2021, FRONT VIRTUAL REAL, V2, DOI [10.3389/frvir.2021.5821561[25]P, DOI 10.3389/FRVIR.2021.582156]
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E., 2019, ACM S APPL PERCEPTIO
   LAWTHER A, 1988, AVIAT SPACE ENVIR MD, V59, P399
   Lim K, 2021, VIRTUAL REAL-LONDON, V25, P331, DOI 10.1007/s10055-020-00457-3
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Maeda T, 2005, P IEEE VIRT REAL ANN, P289
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   Moore ST, 2011, AVIAT SPACE ENVIR MD, V82, P535, DOI 10.3357/ASEM.2942.2011
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Narciso David G., 2019, Immersive 360 video user experience: impact of different variables in the sense of presence and cybersickness
   Nitsche MA, 2009, EXP NEUROL, V219, P14, DOI 10.1016/j.expneurol.2009.03.038
   Reason J.T., 1975, Motion Sickness
   Reed-Jones R. J., 2007, CAN GALVANIC VESTIBU
   Rheingold H., 1991, VIRTUAL REALITY EXPL
   Sherman CR, 2002, J TRAVEL MED, V9, P251
   Singla A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P198, DOI 10.1109/VR50410.2021.00041
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Song B, 2016, IEEE T BIO-MED ENG, V63, P176, DOI 10.1109/TBME.2015.2468672
   Sra M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300905
   Sra M, 2017, P IEEE VIRT REAL ANN, P405, DOI 10.1109/VR.2017.7892348
   Sra Misha, 2017, P 23 ACM S VIRT REAL, P1, DOI DOI 10.1145/3139131.3141219
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Tauscher JP, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1953
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Utz KS, 2010, NEUROPSYCHOLOGIA, V48, P2789, DOI 10.1016/j.neuropsychologia.2010.06.002
   Weech S, 2020, EXP BRAIN RES, V238, P427, DOI 10.1007/s00221-019-05718-5
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
NR 59
TC 16
Z9 16
U1 2
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2234
EP 2244
DI 10.1109/TVCG.2022.3150506
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400035
PM 35167472
DA 2024-11-06
ER

PT J
AU Yin, TR
   Hoyet, L
   Christie, M
   Cani, MP
   Pettre, J
AF Yin, Tairan
   Hoyet, Ludovic
   Christie, Marc
   Cani, Marie-Paule
   Pettre, Julien
TI The One-Man-Crowd: Single User Generation of Crowd Motions Using Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Solid modeling; Context modeling; Trajectory; Legged
   locomotion; Ethics; Decision making; Crowd motion data; human
   interaction; virtual reality
ID PEDESTRIAN MOVEMENT; PERSONAL-SPACE; FLOW; PERCEPTION; DYNAMICS;
   WALKING; INFLOW; SPEED
AB Crowd motion data is fundamental for understanding and simulating realistic crowd behaviours. Such data is usually collected through controlled experiments to ensure that both desired individual interactions and collective behaviours can be observed. It is however scarce, due to ethical concerns and logistical difficulties involved in its gathering, and only covers a few typical crowd scenarios. In this work, we propose and evaluate a novel Virtual Reality based approach lifting the limitations of real-world experiments for the acquisition of crowd motion data. Our approach immerses a single user in virtual scenarios where he/she successively acts each crowd member. By recording the past trajectories and body movements of the user, and displaying them on virtual characters, the user progressively builds the overall crowd behaviour by him/herself. We validate the feasibility of our approach by replicating three real experiments, and compare both the resulting emergent phenomena and the individual interactions to existing real datasets. Our results suggest that realistic collective behaviours can naturally emerge from virtual crowd data generated using our approach, even though the variety in behaviours is lower than in real situations. These results provide valuable insights to the building of virtual crowd experiences, and reveal key directions for further improvements.
C1 [Yin, Tairan; Hoyet, Ludovic; Christie, Marc; Pettre, Julien] Univ Rennes, IRISA, CNRS, INRIA, Rennes, France.
   [Cani, Marie-Paule] Ecole Polytech, IP Paris, CNRS LIX, Paris, France.
C3 Inria; Universite de Rennes; Centre National de la Recherche
   Scientifique (CNRS); Centre National de la Recherche Scientifique
   (CNRS); Institut Polytechnique de Paris; Ecole Polytechnique
RP Yin, TR (corresponding author), Univ Rennes, IRISA, CNRS, INRIA, Rennes, France.
EM tairan.yin@inria.fr
RI Pettré, Julien/AAB-2590-2022; Hoyet, Ludovic/IWU-9100-2023
OI Hoyet, Ludovic/0000-0002-7373-6049
FU European Union [860768]; Marie Curie Actions (MSCA) [860768] Funding
   Source: Marie Curie Actions (MSCA)
FX This work has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie SklodowskaCurie grant
   agreement No 860768 (CLIPE project).
CR Adrian J., 2018, ARXIV PREPRINT ARXIV
   Adrian J, 2020, J R SOC INTERFACE, V17, DOI 10.1098/rsif.2019.0871
   Andreas Winkens, 2009, ARXIV PREPRINT ARXIV
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Cao SC, 2019, COMMUN NONLINEAR SCI, V69, P329, DOI 10.1016/j.cnsns.2018.10.007
   Cao SC, 2016, PHYS REV E, V94, DOI 10.1103/PhysRevE.94.012312
   Carstens R. L., 1970, Traffic Engineering, V41, P38
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Chattaraj U, 2009, ADV COMPLEX SYST, V12, P393, DOI 10.1142/S0219525909002209
   Chen J, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa79ad
   Daamen W., 2003, Pedestrian Evacuation Dynamics, P121
   EVANS GW, 1973, PSYCHOL BULL, V80, P334, DOI 10.1037/h0034946
   Ezaki T., 2016, Collective Dynamics, V1, P1, DOI [10.17815/CD.2016.42, DOI 10.17815/CD.2016.42]
   Ezaki T, 2015, TRAFFIC AND GRANULAR FLOW '13, P227, DOI 10.1007/978-3-319-10629-8_27
   Ezaki T, 2012, PHYSICA A, V391, P291, DOI 10.1016/j.physa.2011.07.056
   Fang ZM, 2019, SAFETY SCI, V113, P264, DOI 10.1016/j.ssci.2018.11.022
   Fink PW, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1227134.1227136
   FRUIN J.J., 1971, Metropolitan Association of Urban Designers and Environmental Planners
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI 10.1145/1836248.1836259
   Gulhare S, 2018, COLLECT DYN, V3, P1, DOI DOI 10.17815/CD.2018.16
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   Helbing D, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.168001
   Hollman JH, 2007, GAIT POSTURE, V26, P289, DOI 10.1016/j.gaitpost.2006.09.075
   Huang SS, 2018, PHYSICA A, V509, P1023, DOI 10.1016/j.physa.2018.06.079
   Jelic A, 2012, PHYS REV E, V86, DOI 10.1103/PhysRevE.86.046111
   Jelic A, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.036111
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Liao WC, 2014, TRANSP RES PROC, V2, P26, DOI 10.1016/j.trpro.2014.09.005
   Liu XD, 2016, PHYS LETT A, V380, P1526, DOI 10.1016/j.physleta.2016.02.028
   Liu XD, 2016, PHYSICA A, V442, P224, DOI 10.1016/j.physa.2015.09.026
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Loomis JM, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P21
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moussaïd M, 2009, P ROY SOC B-BIOL SCI, V276, P2755, DOI 10.1098/rspb.2009.0405
   Navin F.P., 1969, PEDESTRIAN FLOW CHAR, V39
   Older S. J., 1968, TRAFFIC ENG CONTROL, V10, P160
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Ren XX, 2019, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aafa7b
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rio KW, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.0611
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Seyfried A, 2010, PEDESTRIAN AND EVACUATION DYNAMICS 2008, P145, DOI 10.1007/978-3-642-04504-2_11
   Seyfried A, 2009, TRANSPORT SCI, V43, P395, DOI 10.1287/trsc.1090.0263
   Sharma Sharad, 2011, Proceedings of the 2011 16th International Conference on Computer Games: AI, Animation, Mobile, Interactive Multimedia, Educational & Serious Games (CGAMES 2011), P12, DOI 10.1109/CGAMES.2011.6000319
   Shi XM, 2018, J ADV TRANSPORT, DOI 10.1155/2018/1063043
   SOMMER R, 1959, SOCIOMETRY, V22, P247, DOI 10.2307/2785668
   Steffen B, 2010, PHYSICA A, V389, P1902, DOI 10.1016/j.physa.2009.12.015
   Sun JL, 2018, PHYSICA A, V490, P476, DOI 10.1016/j.physa.2017.08.031
   Was J, 2006, LECT NOTES COMPUT SC, V4173, P492
   Willemsen P., 2004, P 1 S APPL PERC GRAP, P35, DOI [DOI 10.1145/1012551.1012558, 10.1145/1012551.1012558]
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Yamori K, 1998, PSYCHOL REV, V105, P530, DOI 10.1037/0033-295X.105.3.530
   Yanagisawa D, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.016111
   Zeng G, 2019, PHYS LETT A, V383, P1011, DOI 10.1016/j.physleta.2018.12.019
   Zhao HT, 2020, J R SOC INTERFACE, V17, DOI 10.1098/rsif.2020.0116
NR 64
TC 9
Z9 9
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2245
EP 2255
DI 10.1109/TVCG.2022.3150507
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400036
PM 35167473
OA Green Published
DA 2024-11-06
ER

PT J
AU Ebner, C
   Mori, S
   Mohr, P
   Peng, YF
   Schmalstieg, D
   Wetzstein, G
   Kalkofen, D
AF Ebner, Christoph
   Mori, Shohei
   Mohr, Peter
   Peng, Yifan
   Schmalstieg, Dieter
   Wetzstein, Gordon
   Kalkofen, Denis
TI Video See-Through Mixed Reality with Focus Cues
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Virtual reality; Rendering (computer graphics); Mixed reality; Real-time
   systems; Lenses; Additives; Pipelines; Mixed reality; Video see-through;
   Focus cues
ID DEPTH
AB This work introduces the first approach to video see-through mixed reality with full support for focus cues. By combining the flexibility to adjust the focus distance found in varifocal designs with the robustness to eye-tracking error found in multifocal designs, our novel display architecture reliably delivers focus cues over a large workspace. In particular, we introduce gaze-contingent layered displays and mixed reality focal stacks, an efficient representation of mixed reality content that lends itself to fast processing for driving layered displays in real time. We thoroughly evaluate this approach by building a complete end-to-end pipeline for capture, render, and display of focus cues in video see-through displays that uses only off-the-shelf hardware and compute components.
C1 [Ebner, Christoph; Mori, Shohei; Mohr, Peter; Schmalstieg, Dieter; Kalkofen, Denis] Graz Univ Technol, Graz, Austria.
   [Peng, Yifan; Wetzstein, Gordon] Stanford Univ, Stanford, CA 94305 USA.
C3 Graz University of Technology; Stanford University
RP Ebner, C (corresponding author), Graz Univ Technol, Graz, Austria.
EM christoph.ebner@icg.tugraz.at; gordonwz@stanford.edu
RI Mori, Shohei/AAL-6642-2020; Peng, Yifan/M-1605-2016
OI Kalkofen, Denis/0000-0002-0359-206X; Ebner,
   Christoph/0000-0002-1449-4780; Mori, Shohei/0000-0003-0540-7312
FU Austrian Science Fund FWF [P30694]; BMK; BMDW, Styria; SFG, Tyrol;
   Vienna Business Agency [879730]; Austrian Science Fund (FWF) [P30694]
   Funding Source: Austrian Science Fund (FWF)
FX This work was enabled by the Austrian Science Fund FWF (grant no.
   P30694) and the Competence Center VRVis, which is funded by BMK, BMDW,
   Styria, SFG, Tyrol and Vienna Business Agency in the scope of COMET
   -Competence Centers for Excellent Technologies (879730) which is managed
   by FFG.
CR Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   Alexander E, 2016, LECT NOTES COMPUT SC, V9907, P667, DOI 10.1007/978-3-319-46487-9_41
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   [Anonymous], 2005, TECHNICAL REPORT STA
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Breen DE, 1996, COMPUT GRAPH FORUM, V15, pC11, DOI 10.1111/1467-8659.1530011
   Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932
   Chakravarthula P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356539
   Chang C, 2020, OPTICA, V7, P1563, DOI 10.1364/OPTICA.406004
   Chang JHR, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275015
   Cholewiak SA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130815
   Demers J., 2004, GPU GEMS, P375
   Dunn D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1838, DOI [10.1109/VR.2019.8798273, 10.1109/vr.2019.8798273]
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Hainich R. R., 2017, DISPLAYS FUNDAMENTAL
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929
   Jang C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275069
   Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695
   Kim H, 2016, INT CONF 3D VISION, P370, DOI 10.1109/3DV.2016.46
   Kim J., 2019, P 2019 CHI C HUM FAC, P1
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Kuthirummal S, 2011, IEEE T PATTERN ANAL, V33, P58, DOI 10.1109/TPAMI.2010.66
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10451-2
   Lee S, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2782219
   Lee S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925971
   Liang CK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360654
   Liu S, 2008, INT SYM MIX AUGMENT, P33, DOI 10.1109/ISMAR.2008.4637321
   Liu X, 2016, COMPUT GRAPH-UK, V55, P21, DOI 10.1016/j.cag.2015.10.015
   MacKenzie KJ, 2011, PROC SPIE, V7863, DOI 10.1117/12.872503
   Mandl D, 2021, INT SYM MIX AUGMENT, P508, DOI 10.1109/ISMAR52148.2021.00068
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Mercier O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130846
   Miau D, 2013, IEEE INT CONF COMPUT
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Moon S, 2017, IEEE J-STSP, V11, P1223, DOI 10.1109/JSTSP.2017.2738614
   Narain R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766909
   Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256
   Padmanaban N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356517
   Padmanaban N, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6187
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   Peng YF, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg5040
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Potmesil M., 1982, ACM T GRAPHIC, V1, P85, DOI DOI 10.1145/357299.357300
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rathinavel K, 2018, IEEE T VIS COMPUT GR, V24, P2857, DOI 10.1109/TVCG.2018.2868570
   Riguer G., 2004, ShaderX2: Shader Programming Tips and Tricks with DirectX, V9, P529
   Scheuermann T., 2004, SHADERX3 ADV RENDERI
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shi L, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130832
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Shroff N., 2012, PROC IEEE INT C COMP, DOI [10.1109/ICCPhot.2012.6215219, DOI 10.1109/ICCPHOT.2012.6215219]
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   Suwajanakorn S, 2015, PROC CVPR IEEE, P3497, DOI 10.1109/CVPR.2015.7298972
   Tang HX, 2017, PROC CVPR IEEE, P4773, DOI 10.1109/CVPR.2017.507
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P21, DOI 10.1109/VR.2014.6802045
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Wetzstein G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964990
   Wilburn B, 2002, PROC SPIE, V4674, P29
   Wu WM, 2016, IEEE INT CON MULTI
   Xiao L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275032
   Yang J. C., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P77
   Yu H, 2019, IEEE T VIS COMPUT GR, V25, P1940, DOI 10.1109/TVCG.2019.2898821
   Yu P, 2012, COMM COM INF SC, V331, P15
   Zhan T, 2020, PHOTONIX, V1, DOI 10.1186/s43074-020-00010-0
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 72
TC 11
Z9 11
U1 1
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2256
EP 2266
DI 10.1109/TVCG.2022.3150504
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400037
PM 35167471
OA hybrid
DA 2024-11-06
ER

PT J
AU Brubach, L
   Westermeier, F
   Wienrich, C
   Latoschik, ME
AF Brubach, Larissa
   Westermeier, Franziska
   Wienrich, Carolin
   Latoschik, Marc Erich
TI Breaking Plausibility Without Breaking Presence-Evidence For The
   Multi-Layer Nature Of Plausibility
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)
CY MAR 12-16, 2022
CL ELECTR NETWORK
SP IEEE, IEEE Comp Soc, ChristchurchNZ, Virbela, Univ Canterbury, Immers Learning Res Network, Qualcomm, HIT Lab NZ, Appl Immers Gaming Initiat
DE Coherence; X reality; Cognitive science; High-temperature
   superconductors; Physics; Marine vehicles; Licenses; plausibility;
   coherence; presence; XR; experience; evaluation
AB A novel theoretical model recently introduced coherence and plausibility as the essential conditions of XR experiences, challenging contemporary presence-oriented concepts. This article reports on two experiments validating this model, which assumes coherence activation on three layers (cognition, perception, and sensation) as the potential sources leading to a condition of plausibility and from there to other XR qualia such as presence or body ownership. The experiments introduce and utilize breaks in plausibility (in analogy to breaks in presence): We induce incoherence on the perceptual and the cognitive layer simultaneously by a simulation of object behaviors that do not conform to the laws of physics, i.e., gravity. We show that this manipulation breaks plausibility and hence confirm that it results in the desired effects in the theorized condition space but that the breaks in plausibility did not affect presence. In addition, we show that a cognitive manipulation by a storyline framing is too weak to successfully counteract the strong bottom-up inconsistencies. Both results are in line with the predictions of the recently introduced three-layer model of coherence and plausibility, which incorporates well-known top-down and bottom-up rivalries and its theorized increased independence between plausibility and presence.
C1 [Brubach, Larissa] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Brubach, Larissa] Univ Wurzburg, Human Technol Syst HTS Grp, Wurzburg, Germany.
   [Westermeier, Franziska; Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
   [Westermeier, Franziska; Wienrich, Carolin] Univ Wurzburg, HTS Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg;
   University of Wurzburg
RP Brubach, L (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.; Brubach, L (corresponding author), Univ Wurzburg, Human Technol Syst HTS Grp, Wurzburg, Germany.
EM larissa.bruebach@uni-wuerzburg.de;
   franziska.westermeier@uni-wuerzburg.de;
   carolin.wienrich@uni-wuerzburg.de; marc.latoschik@uni-wuerzburg.de
OI Westermeier, Franziska/0000-0003-2534-4857
FU Bavarian State Ministry For Digital Affairs [A5-3822-2-16]
FX This research has been funded by the Bavarian State Ministry For Digital
   Affairs in the project XR Hub (project number A5-3822-2-16).
CR Bacherle P., 2015, EINTAUCHEN NARRATIVE
   Bent T, 2016, J ACOUST SOC AM, V140, P3775, DOI 10.1121/1.4966677
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Busselle R, 2008, COMMUN THEOR, V18, P255, DOI 10.1111/j.1468-2885.2008.00322.x
   de Graaf A, 2012, COMMUN RES, V39, P802, DOI 10.1177/0093650211408594
   Graesser AC, 2002, NARRATIVE IMPACT: SOCIAL AND COGNITIVE FOUNDATIONS, P229
   Green M.C., 2021, Entertainment-Education Behind the Scenes, P87, DOI [DOI 10.1007/978-3-030-63614-2_6, 10.1007/978-3-030-63614-26, DOI 10.1007/978-3-030-63614-26]
   Hamzeheinejad N, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P382, DOI 10.1109/VR50410.2021.00061
   Hein Rebecca, 2021, AIMS Electronics and Electrical Engineering, V5, P117
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI DOI 10.3389/FRVIR.2020.00002
   HTC corporation, 2021, US
   Jörges B, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00203
   Kahneman D., 2013, THINKING FAST SLOW F, V1st ed.
   Kern F., 2021, FRONTIERS VIRTUAL RE, V2, P69
   Latoschik M. E., 2021, ARXIV210404846 CS
   Minsky Marvin, 1980, OMNIJuly, DOI DOI 10.1145/566654.566630
   Popova L., 2010, Perceived reality of media messages: Concept explication and testing
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   v. Goethe J. W., 2006, MAXIMS REFLECTIONS
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.686783
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 29
TC 12
Z9 12
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2267
EP 2276
DI 10.1109/TVCG.2022.3150496
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 1R1AK
UT WOS:000803110400038
PM 35167467
OA hybrid
DA 2024-11-06
ER

PT J
AU Azmandian, M
   Yahata, R
   Grechkin, T
   Rosenberg, ES
AF Azmandian, Mahdi
   Yahata, Rhys
   Grechkin, Timofey
   Rosenberg, Evan Suma
TI Adaptive Redirection: A Context-Aware Redirected Walking Meta-Strategy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Planning; Trajectory; Virtual environments; Task
   analysis; Copper; Adaptive systems; Virtual reality; redirected walking;
   locomotion; combinatorial optimization
ID MOTION COMPRESSION
AB Previous research has established redirected walking as a potential answer to exploring large virtual environments via natural locomotion within a limited physical space. However, much of the previous work has either focused on investigating human perception of redirected walking illusions or developing novel redirection techniques. In this paper, we take a broader look at the problem and formalize the concept of a complete redirected walking system. This work establishes the theoretical foundations for combining multiple redirection strategies into a unified framework known as adaptive redirection. This meta-strategy adapts based on the context, switching between a suite of strategies with a priori knowledge of their performance under the various circumstances. This paper also introduces a novel static planning strategy that optimizes gain parameters for a predetermined virtual path, known as the Combinatorially Optimized Pre-Planned Exploration Redirector (COPPER). We conducted a simulation-based experiment that demonstrates how adaptation rules can be determined empirically using machine learning, which involves partitioning the spectrum of contexts into regions according to the redirection strategy that performs best. Adaptive redirection provides a foundation for making redirected walking work in practice and can be extended to improve performance in the future as new techniques are integrated into the framework.
C1 [Azmandian, Mahdi; Yahata, Rhys; Grechkin, Timofey] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90007 USA.
   [Rosenberg, Evan Suma] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Southern California; University of Minnesota System;
   University of Minnesota Twin Cities
RP Rosenberg, ES (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
EM suma@umn.edu
OI Suma Rosenberg, Evan/0000-0002-4826-4561
FU U.S. Army Research Laboratory [W911NF-14-D-0005]
FX The authors would like to thank Jerald Thomas for his assistance with
   the paper. This work was sponsored by the U.S. Army Research Laboratory
   under contract number W911NF-14-D-0005. Statements and opinions
   expressed do not necessarily reflect the position or the policy of the
   Government, and no official endorsement should be inferred.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   [Anonymous], 2017, J VISION
   Azmandian M., 2014, P ACM S APPL PERCEPT, P129
   Azmandian M, 2018, THESIS U SO CALIFORN
   Azmandian M., IN PRESS
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Azmandian M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P65, DOI 10.1109/VR.2014.6802053
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Brument Hugo, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P20, DOI 10.1007/978-3-030-62655-6_2
   Congdon BJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364277
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Grechkin T, 2015, P IEEE VIRT REAL ANN, P185, DOI 10.1109/VR.2015.7223357
   Hayashi D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P386, DOI [10.1109/VR.2019.8797989, 10.1109/vr.2019.8797989]
   Hildebrandt J, 2018, LECT NOTES COMPUT SC, V10909, P82, DOI 10.1007/978-3-319-91581-4_7
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Holm Jeannette E, 2012, THESIS
   Hutton C., 2018, ICAT-EGVE
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Langbehn E, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343125
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li XL, 2018, SPRINGERBRIEF MATH, P1, DOI 10.1007/978-3-319-89617-5_1
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Matsumoto K, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P105, DOI 10.1109/3DUI.2016.7460038
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nitzsche N, 2004, PRESENCE-TELEOP VIRT, V13, P44, DOI 10.1162/105474604774048225
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Razzaque S., 2005, Redirected Walking
   Razzaque S., 2001, P 22 ANN C EUR ASS C, P289, DOI DOI 10.2312/EGS.20011036
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Su JB, 2007, PRESENCE-VIRTUAL AUG, V16, P385, DOI 10.1162/pres.16.4.385
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Thomas J., 2020, 26th ACM Symposium on Virtual Reality Software and Technology, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Unity3D Game Engine, UNITY3DCOM
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams N. L., IEEE T VIS COMPUT GR, V27, P2021
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376243
   You C, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3358757
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 65
TC 6
Z9 6
U1 2
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
BP 2277
EP 2287
DI 10.1109/TVCG.2022.3150500
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400039
PM 35175921
DA 2024-11-06
ER

PT J
AU Mueller, K
   Bowman, D
AF Mueller, Klaus
   Bowman, Doug
TI IEEE VR 2022 Introducing the Special Issue
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
AB Welcome to the 11 th IEEE Transactions on Visualization and Computer Graphics (TVCG) special issue on IEEE Virtual Reality and 3D User Interfaces. This volume contains a total of 29 full papers selected for and presented at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2022), held fully virtual in Christchurch, New Zealand from March 12 to 16, 2022.
C1 [Mueller, Klaus] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Bowman, Doug] Virginia Tech, Blacksburg, VA USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   Virginia Polytechnic Institute & State University
RP Mueller, K (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
OI Mueller, Klaus/0000-0002-0996-8590
NR 0
TC 0
Z9 0
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
DI 10.1109/TVCG.2022.3156765
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400004
OA Bronze
DA 2024-11-06
ER

PT J
AU Nedel, L
   Argelaguet, F
   Wang, LL
   Stefannuci, J
   Iwai, D
AF Nedel, Luciana
   Argelaguet, Ferran
   Wang, Lili
   Stefannuci, Jeanine
   Iwai, Daisuke
TI IEEE VR 2022 Message from the Journal Paper Chairs and Guest Editors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
AB In this special issue of IEEE Transactions on Visualization and Computer Graphics (TVCG), we are pleased to present a subset of papers from the 29th IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2022), held virtually March 12-16, 2022, in Christchurch, New Zealand.
C1 [Nedel, Luciana] Fed Univ Rio Grande do Sul UFRGS, Porto Alegre, RS, Brazil.
   [Argelaguet, Ferran] Inria Rennes, Rennes, France.
   [Wang, Lili] Beihang Univ, Beijing, Peoples R China.
   [Stefannuci, Jeanine] Univ Utah, Salt Lake City, UT 84112 USA.
   [Iwai, Daisuke] Osaka Univ, Suita, Osaka, Japan.
C3 Universidade Federal do Rio Grande do Sul; Universite de Rennes; Beihang
   University; Utah System of Higher Education; University of Utah; Osaka
   University
RP Nedel, L (corresponding author), Fed Univ Rio Grande do Sul UFRGS, Porto Alegre, RS, Brazil.
RI wang, lili/HJP-8047-2023; Iwai, Daisuke/R-8174-2019; Nedel,
   Luciana/G-3506-2012
OI Nedel, Luciana/0000-0002-2390-1392; Iwai, Daisuke/0000-0002-3493-5635
NR 0
TC 0
Z9 0
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY 1
PY 2022
VL 28
IS 5
DI 10.1109/TVCG.2022.3156766
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1R1AK
UT WOS:000803110400005
OA Bronze
DA 2024-11-06
ER

PT J
AU Li, WW
   Huang, HK
   Solomon, T
   Esmaeili, B
   Yu, LA
AF Li, Wanwan
   Huang, Haikun
   Solomon, Tomay
   Esmaeili, Behzad
   Yu, Lap-Fai
TI Synthesizing Personalized Construction Safety Training Scenarios for VR
   Training
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Hazards; Training; Vehicle dynamics; Virtual reality; Costs; Task
   analysis; Inspection; virtual reality; construction safty; training;
   optimization; personalization
ID VIRTUAL ENVIRONMENTS; IMPACT; MANAGEMENT; INDUSTRIAL; SYSTEM
AB Construction industry has the largest number of preventable fatal injuries, providing effective safety training practices can play a significant role in reducing the number of fatalities. Building on recent advancements in virtual reality-based training, we devised a novel approach to synthesize construction safety training scenarios to train users on how to proficiently inspect the potential hazards on construction sites in virtual reality. Given the training specifications such as individual training preferences and target training time, we synthesize personalized VR training scenarios through an optimization approach. We validated our approach by conducting user studies where users went through our personalized guidance VR training, free exploration VR training, or slides training. Results suggest that personalized guidance VR training approach can more effectively improve users' construction hazard inspection skills.
C1 [Li, Wanwan; Huang, Haikun; Solomon, Tomay; Esmaeili, Behzad; Yu, Lap-Fai] George Mason Univ, Fairfax, VA 22030 USA.
C3 George Mason University
RP Yu, LA (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
EM craigyu@gmu.edu
RI Huang, Haikun/AAL-2838-2021; Li, Wanwan/Q-3692-2016
OI Esmaeili, Behzad/0000-0003-3858-1843; Li, Wanwan/0000-0002-9425-2633
FU National Science Foundation [1942531, 2128867]; Direct For Computer &
   Info Scie & Enginr; Div Of Information & Intelligent Systems [1942531]
   Funding Source: National Science Foundation; Div Of Electrical, Commun &
   Cyber Sys; Directorate For Engineering [2128867] Funding Source:
   National Science Foundation
FX This research is supported by the National Science Foundation under
   award numbers 1942531 and 2128867.
CR Aati K, 2020, TRANSPORT RES REC
   Akintoye A., 2000, Construction Management Economics, V18, P77, DOI [DOI 10.1080/014461900370979, 10.1080/014461900370979]
   Apostolellis P., 2015, P 14 INT C INTERACTI, P160, DOI [10.1145/2771839.2771856, DOI 10.1145/2771839.2771856]
   Apostolellis P, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P299, DOI 10.1145/2930674.2930700
   Benjaoran V, 2010, SAFETY SCI, V48, P395, DOI 10.1016/j.ssci.2009.09.009
   Benvegnù G, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P316, DOI 10.1109/VR50410.2021.00054
   Bhoir S, 2015, AEI 2015: BIRTH AND LIFE OF THE INTEGRATED BUILDING, P457
   Brouwer AE, 2012, UNIVERSITEXT, P1, DOI 10.1007/978-1-4614-1939-6
   Casella G., 2008, Statistical design, DOI DOI 10.1007/978-0-387-75965-4
   Chester M, 2005, J CONSTR ENG M, V131, P102, DOI 10.1061/(ASCE)0733-9364(2005)131:1(102)
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Eiris R, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102969
   Furuya H, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451626
   Gheisari M., 2019, PARS: Using augmented panoramas of reality for construction safety training
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711
   Hanna AS, 2005, J CONSTR ENG M, V131, P734, DOI 10.1061/(ASCE)0733-9364(2005)131:6(734)
   Harris William., SAMANTHA BROWN WILLI
   Hasanzadeh S, 2017, J MANAGE ENG, V33, DOI 10.1061/(ASCE)ME.1943-5479.0000526
   Hines K., 2015, ADJ P 2015 ACM INT J, P101
   Huang HK, 2018, IEEE T VIS COMPUT GR, V24, P2516, DOI 10.1109/TVCG.2017.2761820
   Hwang BG, 2009, J CONSTR ENG M, V135, P187, DOI 10.1061/(ASCE)0733-9364(2009)135:3(187)
   Karimi H, 2017, CONSTR MANAG ECON, V35, P368, DOI 10.1080/01446193.2017.1294257
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Laarhoven van, 1987, Simulated Annealing: Theory and Applications, P7, DOI DOI 10.1007/978-94-015-7744-1_2
   Lang YN, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P297, DOI 10.1109/VR.2018.8448290
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Li H, 2015, SAFETY SCI, V75, P107, DOI 10.1016/j.ssci.2015.01.013
   Li H, 2012, J COMPUT CIVIL ENG, V26, P638, DOI 10.1061/(ASCE)CP.1943-5487.0000170
   Li W., ACM T GRAPHIC, V39, P115
   Li W., 2020, IEEE VIRTUAL REALITY
   Liang W, 2019, IEEE T VIS COMPUT GR, V25, P1836, DOI 10.1109/TVCG.2019.2898721
   Lin FH, 2002, INFORM SCIENCES, V140, P153, DOI 10.1016/S0020-0255(01)00185-2
   Mantovani F, 2003, EMERG COMMUNICAT, V5, P167
   McTague Bob., 2002, Productivity Improvements on Alberta Major Construction Projects Phase 1-Back to Basics
   Moore HF, 2019, COMPUTING IN CIVIL ENGINEERING 2019: VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P55
   Palmas F, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P463, DOI 10.1109/VR50410.2021.00070
   Pereira RE, 2018, CONSTRUCTION RESEARCH CONGRESS 2018: SAFETY AND DISASTER MANAGEMENT, P29
   QUENELL G, 1994, ADV MATH, V106, P122, DOI 10.1006/aima.1994.1052
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   Sacks R, 2013, CONSTR MANAG ECON, V31, P1005, DOI 10.1080/01446193.2013.828844
   Sinnott CB, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364272
   Wang YG, 2008, J CONSTR ENG M ASCE, V134, P795, DOI 10.1061/(ASCE)0733-9364(2008)134:10(795)
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   Xie B, 2018, IEEE T VIS COMPUT GR, V24, P1661, DOI 10.1109/TVCG.2018.2793618
   Xie H., 2006, DIGITAL LIB CONSTRUC
   Zhang L, 2019, INT CONF GAMES VIRTU, P33, DOI [10.1109/vs-games.2019.8864531, 10.1109/TCC.2019.2903254]
   Zhang YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300784
   Zhao D, 2015, INT J INJ CONTROL SA, V22, P57, DOI 10.1080/17457300.2013.861853
NR 50
TC 34
Z9 34
U1 17
U2 95
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 1993
EP 2002
DI 10.1109/TVCG.2022.3150510
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0M8RI
UT WOS:000782415400001
PM 35167474
OA Bronze
DA 2024-11-06
ER

PT J
AU Arefin, MS
   Phillips, N
   Plopski, A
   Gabbard, JL
   Swan, JE
AF Arefin, Mohammed Safayet
   Phillips, Nate
   Plopski, Alexander
   Gabbard, Joseph L.
   Swan, J. Edward, II
TI The Effect of Context Switching, Focal Switching Distance, Binocular and
   Monocular Viewing, and Transient Focal Blur on Human Performance in
   Optical See-Through Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optical switches; Task analysis; Monitoring; Transient analysis;
   Fatigue; Augmented reality; Meters; Augmented reality; context
   switching; focal distance switching; transient focal blur; accommodation
ID VISUAL FATIGUE; ACCOMMODATION; DISPLAYS; WORK; TEXT
AB In optical see-through augmented reality (AR), information is often distributed between real and virtual contexts, and often appears at different distances from the user. To integrate information, users must repeatedly switch context and change focal distance. If the user's task is conducted under time pressure, they may attempt to integrate information while their eye is still changing focal distance, a phenomenon we term transient focal blur. Previously, Gabbard, Mehra, and Swan (2018) examined these issues, using a text-based visual search task on a one-eye optical see-through AR display. This paper reports an experiment that partially replicates and extends this task on a custom-built AR Haploscope. The experiment examined the effects of context switching, focal switching distance, binocular and monocular viewing, and transient focal blur on task performance and eye fatigue. Context switching increased eye fatigue but did not decrease performance. Increasing focal switching distance increased eye fatigue and decreased performance. Monocular viewing also increased eye fatigue and decreased performance. The transient focal blur effect resulted in additional performance decrements, and is an addition to knowledge about AR user interface design issues.
C1 [Arefin, Mohammed Safayet; Phillips, Nate; Swan, J. Edward, II] Mississippi State Univ, Mississippi State, MS 39762 USA.
   [Plopski, Alexander] Univ Otago, Dunedin, New Zealand.
   [Gabbard, Joseph L.] Virginia Tech, Blacksburg, VA USA.
C3 Mississippi State University; University of Otago; Virginia Polytechnic
   Institute & State University
RP Arefin, MS (corresponding author), Mississippi State Univ, Mississippi State, MS 39762 USA.
EM arefin@acm.org; Nathaniel.C.Phillips@ieee.org;
   alexander.plopski@otago.ac.nz; jgabbard@vt.edu; swan@acm.org
RI Arefin, Mohammed Safayet/ABF-8521-2020; Phillips, Nate/GPT-4922-2022
OI Phillips, Nate/0000-0001-9085-383X
FU National Science Foundation [IIS-1320909, IIS-1937565]
FX This material is based upon work supported by the National Science
   Foundation, under awards IIS-1320909 and IIS-1937565, to J. Edward Swan
   II. This work was conducted at the Center for Advanced Vehicular
   Systems, at Mississippi State University.
CR Arefin M. S., 2020, IMPACT CONTEXT SWITC
   Arefin MS, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P571, DOI [10.1109/VRW50115.2020.0-139, 10.1109/VRW50115.2020.00137]
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/VR.2019.8797975, 10.1109/vr.2019.8797975]
   Bernard ML, 2003, INT J HUM-COMPUT ST, V59, P823, DOI 10.1016/S1071-5819(03)00121-6
   CAMPBELL FW, 1960, J PHYSIOL-LONDON, V151, P285, DOI 10.1113/jphysiol.1960.sp006438
   Carter J. H., 1962, THESIS INDIANA U
   Chellappan KV, 2010, APPL OPTICS, V49, pF79, DOI 10.1364/AO.49.000F79
   Cholewiak SA, 2018, J VISION, V18, DOI 10.1167/18.9.1
   Cohen J., 2014, Applied Multiple Regression/Correlation Analysis for the Behavioral Sciences, DOI [10.4324/9780203774441, DOI 10.1002/0471264385.WEI0219, 10.4324/9781410606266, DOI 10.4324/9780203774441]
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Drouot M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P476, DOI 10.1109/VRW52623.2021.00120
   Duane A, 1912, J AMER MED ASSOC, V59, P1010
   Eiberger A, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357588
   Gabbard JL, 2008, IEEE T VIS COMPUT GR, V14, P513, DOI 10.1109/TVCG.2008.24
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Gross H., 2015, HUMAN EYE, DOI [10.1002/9783527699247.ch1, DOI 10.1002/9783527699247.CH1]
   Hand R. E., 2019, patentus, Patent No. [20190311527A1, 20190311527]
   Held RT, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731057
   HENDRICK C, 1990, J SOC BEHAV PERS, V5, P41
   HERON G, 1989, OPHTHAL PHYSL OPT, V9, P176, DOI 10.1111/j.1475-1313.1989.tb00839.x
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Huckauf A., 2010, P 7 S APPL PERC GRAP, P41, DOI [10.1145/1836248.1836255, DOI 10.1145/1836248.1836255]
   IAVECCHIA JH, 1988, HUM FACTORS, V30, P689, DOI 10.1177/001872088803000605
   Imamov S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P851, DOI [10.1109/VR46266.2020.1581435674325, 10.1109/VR46266.2020.00110]
   KERSTEN D, 1983, J OPT SOC AM, V73, P332, DOI 10.1364/JOSA.73.000332
   Koulieris GA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073622
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   KRISHNAN VV, 1977, IEEE T BIO-MED ENG, V24, P44, DOI 10.1109/TBME.1977.326207
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Love GD, 2009, OPT EXPRESS, V17, P15716, DOI 10.1364/OE.17.015716
   Machuca M. D. Barrera, 2019, EFFECT STEREO DISPLA, P1
   Miles WR, 1930, J GEN PSYCHOL, V3, P412, DOI 10.1080/00221309.1930.9918218
   MILLER RJ, 1983, PERCEPT PSYCHOPHYS, V34, P532, DOI 10.3758/BF03205906
   Mon-Williams M, 2000, ERGONOMICS, V43, P391, DOI 10.1080/001401300184486
   Mon-Williams M, 1998, HUM FACTORS, V40, P42, DOI 10.1518/001872098779480622
   Musa A, 2022, Q J EXP PSYCHOL, V75, P277, DOI 10.1177/17470218211050280
   Neveu C, 1998, PRESENCE-TELEOP VIRT, V7, P278, DOI 10.1162/105474698565712
   OWENS DA, 1987, INVEST OPHTH VIS SCI, V28, P743
   Pedhazur E., 1997, Multiple Regression in Behavioral Research: Explanation and Prediction
   Phillips N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1770, DOI [10.1109/VR.2019.8798335, 10.1109/vr.2019.8798335]
   Phillips N, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P75, DOI 10.1109/ISMAR-Adjunct.2018.00037
   PORAC C, 1976, PSYCHOL BULL, V83, P880, DOI 10.1037/0033-2909.83.5.880
   Schroeger A, 2021, EXP BRAIN RES, V239, P3343, DOI 10.1007/s00221-021-06184-8
   Schwerdtfeger B, 2009, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2009.5336484
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Tufano DR, 1997, HUM FACTORS, V39, P303, DOI 10.1518/001872097778543840
   Ukai K, 2008, DISPLAYS, V29, P106, DOI 10.1016/j.displa.2007.09.004
   Viirre E, 1997, J LASER APPL, V9, P253, DOI 10.2351/1.4745467
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   West R.W., 2001, Introduction to the Optics of the Eye
   Yeh M., 2016, DOTVNTSCFAA1702
NR 54
TC 14
Z9 16
U1 0
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2014
EP 2025
DI 10.1109/TVCG.2022.3150503
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0M8RI
UT WOS:000782415400002
PM 35167470
OA Bronze, Green Accepted
DA 2024-11-06
ER

PT J
AU Kelly, JW
   Hoover, M
   Doty, TA
   Renner, A
   Zimmerman, M
   Knuth, K
   Cherep, LA
   Gilbert, SB
AF Kelly, Jonathan W.
   Hoover, Melynda
   Doty, Taylor A.
   Renner, Alex
   Zimmerman, Moriah
   Knuth, Kimberly
   Cherep, Lucia A.
   Gilbert, Stephen B.
TI Remote research on locomotion interfaces for virtual reality:
   Replication of a lab-based study on teleporting interfaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Navigation; Games; Virtual environments; Legged
   locomotion; Headphones; Green products; Navigation; Spatial cognition;
   Virtual reality; Teleporting; Online data collection
ID PATH-INTEGRATION; ENVIRONMENTS; COMBINATION; POSITION
AB The wide availability of consumer-oriented virtual reality (VR) equipment has enabled researchers to recruit existing VR owners to participate remotely using their own equipment. Yet, there are many differences between lab environments and home environments, as well as differences between participant samples recruited for lab studies and remote studies. This paper replicates a lab-based experiment on VR locomotion interfaces using a remote sample. Participants completed a triangle-completion task (travel two path legs, then point to the path origin) using their own VR equipment in a remote, unsupervised setting. Locomotion was accomplished using two versions of the teleporting interface varying in availability of rotational self-motion cues. The size of the traveled path and the size of the surrounding virtual environment were also manipulated. Results from remote participants largely mirrored lab results, with overall better performance when rotational self-motion cues were available. Some differences also occurred, including a tendency for remote participants to rely less on nearby landmarks, perhaps due to increased competence with using the teleporting interface to update self-location. This replication study provides insight for VR researchers on aspects of lab studies that may or may not replicate remotely.
C1 [Kelly, Jonathan W.; Hoover, Melynda; Doty, Taylor A.; Renner, Alex; Zimmerman, Moriah; Knuth, Kimberly; Cherep, Lucia A.; Gilbert, Stephen B.] Iowa State Univ, Ames, IA 50011 USA.
C3 Iowa State University
RP Kelly, JW (corresponding author), Iowa State Univ, Ames, IA 50011 USA.
EM jonkelly@iastate.edu; mthoover@iastate.edu; tdoty@iastate.edu;
   arenner@iastate.edu; moriahz@iastate.edu; kimberly.n.knuth@gmail.com;
   lacherep@arizona.edu; gilbert@iastate.edu
RI Kelly, Jonathan/A-4793-2013; Gilbert, Stephen/F-3138-2018
OI Renner, Alex Raymond/0009-0004-7714-5731; Gilbert,
   Stephen/0000-0002-5332-029X
FU National Science Foundation [CHS-1816029]
FX This material is based upon work supported by the National Science
   Foundation under Grant Number CHS-1816029. Thanks to Owen Perrin for
   help with calculation of Bhattacharyya coefficients and to Phillip Dixon
   for the idea. Videos, data, supplemental analyses, and links to
   experiment code are available on the Open Science Framework:
   https://osf.io/y25ft/.
CR Allen GL, 2004, PERCEPT PSYCHOPHYS, V66, P170, DOI 10.3758/BF03194870
   Bhattacharyya A., 1943, Bull. Calcutta Math. Soc, V35, P99, DOI DOI 10.1016/j.neuroimage.2004.07.012
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Chen XL, 2017, COGNITIVE PSYCHOL, V95, P105, DOI 10.1016/j.cogpsych.2017.04.003
   Cherep L., 2021, Journal of Experimental Psychology: Applied, DOI [DOI 10.31234/OSF.IO/B6CYD, 10.31234/OSF.IO/B6CYD]
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   HARTIG T, 1991, ENVIRON BEHAV, V23, P3, DOI 10.1177/0013916591231001
   Huber B, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227629
   Kelly JW, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3488284
   Kelly JW, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P687, DOI 10.1109/VR50410.2021.00095
   Kelly JW, 2020, IEEE T VIS COMPUT GR, V26, P1841, DOI 10.1109/TVCG.2020.2973051
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Lim AF, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418443
   Ma X, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P33, DOI 10.1145/3178876.3186034
   Machuca M. D. Barrera, 2019, EFFECT STEREO DISPLA, P1
   MILGRAM S, 1969, J PERS SOC PSYCHOL, V13, P79, DOI 10.1037/h0028070
   Mottelson A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681482
   Nardini M, 2008, CURR BIOL, V18, P689, DOI 10.1016/j.cub.2008.04.021
   NASEM, 2019, Reproducibility and Replicability in Science, DOI [10.17226/25303, DOI 10.17226/25303]
   Newman PM, 2021, BEHAV RES METHODS, V53, P390, DOI 10.3758/s13428-020-01451-y
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Petersen G. B., 2021, PEDAGOGICAL AGENTS E
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Saffo David, 2021, REMOTE COLLABORATIVE
   Sjolund LA, 2018, MEM COGNITION, V46, P89, DOI 10.3758/s13421-017-0747-7
   Steed A., 2020, Interaction, V27, P62, DOI [DOI 10.1145/3406098, 10.1145/3406098]
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Tang A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1181
   ULRICH RS, 1991, J ENVIRON PSYCHOL, V11, P201, DOI 10.1016/S0272-4944(05)80184-7
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhang L, 2017, J EXP PSYCHOL LEARN, V43, P472, DOI 10.1037/xlm0000324
   Zhao JY, 2021, INT SYM MIX AUGMENT, P450, DOI 10.1109/ISMAR52148.2021.00062
NR 34
TC 2
Z9 2
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2037
EP 2046
DI 10.1109/TVCG.2022.3150475
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0M8RI
UT WOS:000782415400003
PM 35167459
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Solah, M
   Huang, HK
   Sheng, JC
   Feng, T
   Pomplun, M
   Yu, LF
AF Solah, Michael
   Huang, Haikun
   Sheng, Jiachuan
   Feng, Tian
   Pomplun, Marc
   Yu, Lap-Fai
TI Mood-Driven Colorization of Virtual Indoor Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mood; Image color analysis; Feature extraction; Three-dimensional
   displays; Optimization; Task analysis; Electronic mail; Virtual reality;
   Perception; Visualization design and evaluation methods
ID COLOR; CIEDE2000
AB One of the challenging tasks in virtual scene design for Virtual Reality (VR) is causing it to invoke a particular mood in viewers. The subjective nature of moods brings uncertainty to the purpose. We propose a novel approach to automatic adjustment of the colors of textures for objects in a virtual indoor scene, enabling it to match a target mood. A dataset of 25,000 images, including building/home interiors, was used to train a classifier with the features extracted via deep learning. It contributes to an optimization process that colorizes virtual scenes automatically according to the target mood. Our approach was tested on four different indoor scenes, and we conducted a user study demonstrating its efficacy through statistical analysis with the focus on the impact of the scenes experienced with a VR headset.
C1 [Solah, Michael; Huang, Haikun; Yu, Lap-Fai] George Mason Univ, Fairfax, VA 22030 USA.
   [Sheng, Jiachuan] Tianjin Univ Finance & Econ, Tianjin, Peoples R China.
   [Feng, Tian] Zhejiang Univ, Hangzhou, Peoples R China.
   [Pomplun, Marc] Univ Massachusetts Boston, Boston, MA USA.
C3 George Mason University; Tianjin University of Finance & Economics;
   Zhejiang University; University of Massachusetts System; University of
   Massachusetts Boston
RP Sheng, JC (corresponding author), Tianjin Univ Finance & Econ, Tianjin, Peoples R China.
EM msolah@gmu.edu; hhuang25@gmu.edu; jiachuansheng@tjufe.edu.cn;
   t.feng@zju.edu.cn; marc@cs.umb.edu; craigyu@gmu.edu
RI Huang, Haikun/AAL-2838-2021
OI Sheng, Jiachuan/0000-0002-4286-1365
FU National Science Foundation [1942531, 2128867]; Div Of Electrical,
   Commun & Cyber Sys; Directorate For Engineering [2128867] Funding
   Source: National Science Foundation; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1942531] Funding
   Source: National Science Foundation
FX This research is supported by the National Science Foundation under
   award numbers 1942531 and 2128867.
CR ADAMS FM, 1973, J CROSS CULT PSYCHOL, V4, P135, DOI 10.1177/002202217300400201
   Akazawa Y., 2005, INTELLIGENZA ARTIFIC, V8
   Al-Akkam A., 2013, Arch. Planning, V25, P21
   Bares W. H., 1998, IUI '98. 1998 International Conference on Intelligent User Interfaces, P81, DOI 10.1145/268389.268405
   Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002
   Brodschelm L., 2021, MOOD ADAPTIVE DISPLA
   Cha SH, 2020, J INTERIOR DES, V45, P51, DOI 10.1111/joid.12179
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen GM, 2016, COMPUT GRAPH-UK, V60, P34, DOI 10.1016/j.cag.2016.08.009
   Chen K, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818096
   CHIB S, 1995, AM STAT, V49, P327, DOI 10.2307/2684568
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Elliot AJ, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00368
   Elliot AJ, 2014, ANNU REV PSYCHOL, V65, P95, DOI 10.1146/annurev-psych-010213-115035
   Feng T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925894
   Fu Q, 2020, COMPUT GRAPH FORUM, V39, P543, DOI 10.1111/cgf.14166
   Han S., 2018, VRST18
   Hassan MR., 2017, GJCST, V17, P33
   Hu X., 2017, FRONT HUM NEUROSCI
   Jiang CFF, 2018, INT J COMPUT VISION, V126, P920, DOI 10.1007/s11263-018-1103-5
   Jonauskaite D, 2020, PSYCHOL SCI, V31, P1245, DOI 10.1177/0956797620948810
   Karayev S, 2013, Recognizing image style
   Katukuri S. K., 2019, THESIS
   Koliska M, 2023, JOURNAL PRACT, V17, P354, DOI 10.1080/17512786.2021.1916402
   Kurt S, 2014, SAGE OPEN, V4, DOI 10.1177/2158244014525423
   Lee YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095415
   Lin JC, 2022, IEEE T VIS COMPUT GR, V28, P2895, DOI 10.1109/TVCG.2020.3041728
   Liu T, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P429, DOI 10.1145/3123266.3123398
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Mahmoud Heba-Talla Hamdy, 2017, The Academic Research Community Publication, V1, P10, DOI DOI 10.21625/ARCHIVE.V1I1.112
   Melgosa M, 2004, J OPT SOC AM A, V21, P2269, DOI 10.1364/JOSAA.21.002269
   Paul R, 2016, TOMOGRAPHY, V2, P388, DOI 10.18383/j.tom.2016.00211
   Pazda AD, 2014, COLOR RES APPL, V39, P208, DOI 10.1002/col.21804
   Pelowski M, 2016, FRONT HUM NEUROSCI, V10, DOI [10.3389/fnhum.2016.00160, 10.3339/fnhum.2016.00160]
   Pintore G, 2020, COMPUT GRAPH FORUM, V39, P667, DOI 10.1111/cgf.14021
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Sra M., 2017, C COMP VIS PATT REC
   Sultana F, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P122, DOI 10.1109/ICRCICN.2018.8718718
   Touvron H., 2020, Fixing the train-test resolution discrepancy: fixEfficientNet
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Vasin Yu G., 2015, Pattern Recognition and Image Analysis, V25, P278, DOI 10.1134/S105466181502025X
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Wardono P, 2012, PROCD SOC BEHV, V38, P362, DOI 10.1016/j.sbspro.2012.03.358
   Wozniak P., 2018, ICCVG 2018, P09
   Yeerken Yesiboli, 2017, J Clin Diagn Res, V11, pZC119, DOI 10.7860/JCDR/2017/23950.9754
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yusoff SKM, 2011, COMM COM INF SC, V180, P448
   Zhang X., 1996, 1996 SID International Symposium. Digest of Technical Papers. First Edition, P731
   Zhao N., 2018, P SIGGRAPH 2018, V37
   Zhao NX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447647
   Zhu J, 2018, IEEE T VIS COMPUT GR, V24, P2473, DOI 10.1109/TVCG.2017.2753255
NR 51
TC 5
Z9 5
U1 1
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2058
EP 2068
DI 10.1109/TVCG.2022.3150513
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0M8RI
UT WOS:000782415400004
PM 35167476
OA Bronze
DA 2024-11-06
ER

PT J
AU Buck, LE
   Chakraborty, S
   Bodenheimer, B
AF Buck, Lauren E.
   Chakraborty, Soumyajit
   Bodenheimer, Bobby
TI The Impact of Embodiment and Avatar Sizing on Personal Space in
   Immersive Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual environments; Avatars; Aerospace electronics; Extraterrestrial
   measurements; Contracts; Visualization; Particle measurements; Virtual
   reality; Perception; Interpersonal space; Peripersonal space; Proxemics
ID PERIPERSONAL SPACE; SELF-REPRESENTATION; TOOL USE; BODY; DISTANCE;
   SENSE; OWNERSHIP; REALITY; ONLINE
AB In this paper, we examine how embodiment and manipulation of a self-avatar's dimensions - specifically the arm length - affect users' judgments of the personal space around them in an immersive virtual environment. In the real world, personal space is the immediate space around the body in which physical interactions are possible. Personal space is increasingly studied in virtual environments because of its importance to social interactions. Here, we specifically look at two components of personal space, interpersonal and peripersonal space, and how they are affected by embodiment and the sizing of a self-avatar. We manipulated embodiment, hypothesizing that higher levels of embodiment will result in larger measures of interpersonal space and smaller measures of peripersonal space. Likewise, we manipulated the arm length of a self-avatar, hypothesizing that while interpersonal space would change with changing arm length, peripersonal space would not. We found that the representation of both interpersonal and peripersonal space change when the user experiences differing levels of embodiment in accordance with our hypotheses, and that only interpersonal space was sensitive to changes in the dimensions of a self-avatar's arms. These findings provide increased understanding of the role of embodiment and self-avatars in the regulation of personal space, and provide foundations for improved design of social interaction in virtual environments.
C1 [Buck, Lauren E.; Chakraborty, Soumyajit; Bodenheimer, Bobby] Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
C3 Vanderbilt University
RP Buck, LE (corresponding author), Vanderbilt Univ, 221 Kirkland Hall, Nashville, TN 37235 USA.
EM lauren.e.buck.1@vanderbilt.edu; soumyajit.chakraborty@yanderbilt.edu;
   bobby.bodenheimer@vanderbilt.edu
RI Buck, Lauren/AAD-2235-2022; Chakraborty, Soumyajit/KVY-5937-2024
OI Chakraborty, Soumyajit/0000-0003-4318-0681
FU Office of Naval Research [N0001418-1-2964]; National Science Foundation
   [1763966]; Div Of Information & Intelligent Systems; Direct For Computer
   & Info Scie & Enginr [1763966] Funding Source: National Science
   Foundation
FX The authors wish to thank Dr. Sohee Park and Dr. Jeanine Stefanucci for
   their advice, and the reviewers for their constructive criticism. This
   work was supported by the Office of Naval Research grant
   #N0001418-1-2964. and the National Science Foundation under 1763966.
CR Adams H, 2018, IEEE T VIS COMPUT GR, V24, P1408, DOI 10.1109/TVCG.2018.2794072
   Alcorn A, 2011, LECT NOTES ARTIF INT, V6738, P7, DOI 10.1007/978-3-642-21869-9_4
   ARGYLE M, 1965, SOCIOMETRY, V28, P289, DOI 10.2307/2786027
   Arning K, 2009, LECT NOTES COMPUT SC, V5889, P20
   Bailenson JN, 2008, J APPL SOC PSYCHOL, V38, P2673, DOI 10.1111/j.1559-1816.2008.00409.x
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Berton F., 2020, IEEE T VIS COMPUT GR
   Blakemore SJ, 2002, TRENDS COGN SCI, V6, P237, DOI 10.1016/S1364-6613(02)01907-1
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Bloesch EK, 2013, PSYCHOL SCI, V24, P557, DOI 10.1177/0956797612457385
   Boyd LE, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173778
   Buck LE, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P332, DOI [10.1109/VR46266.2020.1581103473496, 10.1109/VR46266.2020.00-51]
   Buck LE, 2019, IEEE T VIS COMPUT GR, V25, P2123, DOI 10.1109/TVCG.2019.2899232
   Canzoneri E, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0044306
   CARELLO C, 1989, Ecological Psychology, V1, P27, DOI 10.1207/s15326969eco0101_3
   Coello Y, 2012, COGN PROCESS, V13, pS131, DOI 10.1007/s10339-012-0470-z
   Creem-Regehr SH, 2015, PSYCHOL LEARN MOTIV, V62, P195, DOI 10.1016/bs.plm.2014.09.006
   di Pellegrino G, 2015, NEUROPSYCHOLOGIA, V66, P126, DOI 10.1016/j.neuropsychologia.2014.11.011
   DOSEY MA, 1969, J PERS SOC PSYCHOL, V11, P93, DOI 10.1037/h0027040
   Duverne Tristan, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P3, DOI 10.1007/978-3-030-62655-6_1
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Farnè A, 2000, NEUROREPORT, V11, P1645, DOI 10.1097/00001756-200006050-00010
   Feldstein IT, 2021, IEEE T VIS COMPUT GR, V27, P3611, DOI 10.1109/TVCG.2020.2980527
   Fox J., 2009, J. Media Psychol., V21, P95, DOI [10.1027/1864-1105.21.3.95, DOI 10.1027/1864-1105.21.3.95]
   Franck N, 2001, AM J PSYCHIAT, V158, P454, DOI 10.1176/appi.ajp.158.3.454
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gagnon HC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P798, DOI 10.1109/VR50410.2021.00107
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Hall ET, 1966, The hidden dimension, V609
   HAYDUK LA, 1983, PSYCHOL BULL, V94, P293, DOI 10.1037/0033-2909.94.2.293
   Holmes N. P., 2006, HUMAN BODY PERCEPTIO, V1, P15
   Hrimech H, 2010, INT J INTERACT DES M, V4, P149, DOI 10.1007/s12008-010-0090-8
   Iachini T, 2016, J ENVIRON PSYCHOL, V45, P154, DOI 10.1016/j.jenvp.2016.01.004
   Iachini T, 2015, COGN PROCESS, V16, pS255, DOI 10.1007/s10339-015-0717-6
   Iachini T, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111511
   Iriki A, 1996, NEUROREPORT, V7, P2325
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Kammerlander RK, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P402, DOI 10.1109/VR50410.2021.00063
   Kandula M, 2017, EXP BRAIN RES, V235, P2511, DOI 10.1007/s00221-017-4965-9
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Làdavas E, 2008, COGN NEUROPSYCHOL, V25, P1099, DOI 10.1080/02643290802359113
   Lara AH, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05146-z
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Le Chenechal M., 2018, ICAT EGVE 2018
   Lee H.-S., 2021, Schizophrenia Bulletin
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   LIN Q., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P7
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Meier U, 2006, PHARM STAT, V5, P253, DOI 10.1002/pst.210
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Pazhoohi F, 2019, PSYCHOL RES-PSYCH FO, V83, P1184, DOI 10.1007/s00426-017-0968-1
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Podkosova I, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281523
   Quesque F, 2017, PSYCHOL RES-PSYCH FO, V81, P709, DOI 10.1007/s00426-016-0782-1
   Rochat P, 1997, J EXP PSYCHOL HUMAN, V23, P199, DOI 10.1037/0096-1523.23.1.199
   Rouder JN, 2009, PSYCHON B REV, V16, P225, DOI 10.3758/PBR.16.2.225
   Ruggiero G., 2019, PSYCHOBIT
   Ruggiero G, 2017, PSYCHOL RES-PSYCH FO, V81, P1232, DOI 10.1007/s00426-016-0806-x
   Sato A, 2005, COGNITION, V94, P241, DOI 10.1016/j.cognition.2004.04.003
   Serino A, 2018, Front ICT, V4, P31, DOI [10.3389/fict.2017.00031, DOI 10.3389/FICT.2017.00031]
   Seyama J, 2007, PRESENCE-TELEOP VIRT, V16, P337, DOI 10.1162/pres.16.4.337
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Stefanucci JK, 2010, ATTEN PERCEPT PSYCHO, V72, P1338, DOI 10.3758/APP.72.5.1338
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Teneggi C, 2013, CURR BIOL, V23, P406, DOI 10.1016/j.cub.2013.01.043
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wilcox Laurie M., 2006, ACM Transactions on Applied Perception, V3, P412, DOI DOI 10.1145/1190036.1190041
   Witt JK, 2005, J EXP PSYCHOL HUMAN, V31, P880, DOI 10.1037/0096-1523.31.5.880
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2007, CYBERPSYCHOL BEHAV, V10, P115, DOI 10.1089/cpb.2006.9984
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zanini A, 2021, PSYCHON B REV, V28, P1894, DOI 10.3758/s13423-021-01942-9
   Zibrek K, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419985
   Zibrek K, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119887
NR 90
TC 10
Z9 11
U1 5
U2 43
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2102
EP 2113
DI 10.1109/TVCG.2022.3150483
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0M8RI
UT WOS:000782415400005
PM 35167460
OA Bronze
DA 2024-11-06
ER

PT J
AU Peck, TC
   Good, JJ
   Erickson, A
   Bynum, I
   Bruder, G
AF Peck, Tabitha C.
   Good, Jessica J.
   Erickson, Austin
   Bynum, Isaac
   Bruder, Gerd
TI Effects of Transparency on Perceived Humanness: Implications for
   Rendering Skin Tones Using Optical See-Through Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; optical see-through displays; additive light model;
   transparency; race; skin tone; diversity
ID DEHUMANIZATION; PERCEPTION; STEREOTYPES; EMBODIMENT; PREJUDICE; RACE;
   EYE
AB Current optical see-through displays in the field of augmented reality are limited in their ability to display colors with low lightness in the hue, saturation, lightness (HSL) color space, causing such colors to appear transparent. This hardware limitation may add unintended bias into scenarios with virtual humans. Humans have varying skin tones including HSL colors with low lightness. When virtual humans are displayed with optical see-through devices, people with low lightness skin tones may be displayed semi-transparently while those with high lightness skin tones will be displayed more opaquely. For example, a Black avatar may appear semi-transparent in the same scene as a White avatar who will appear more opaque. We present an exploratory user study (N = 160) investigating whether differing opacity levels result in dehumanizing avatar and human faces. Results support that dehumanization occurs as opacity decreases. This suggests that in similar lighting, low lightness skin tones (e.g., Black faces) will be viewed as less human than high lightness skin tones (e.g., White faces). Additionally, the perceived emotionality of virtual human faces also predicts perceived humanness. Angry faces were seen overall as less human, and at lower opacity levels happy faces were seen as more human. Our results suggest that additional research is needed to understand the effects and interactions of emotionality and opacity on dehumanization. Further, we provide evidence that unintentional racial bias may be added when developing for optical see-through devices using virtual humans. We highlight the potential bias and discuss implications and directions for future research.
C1 [Peck, Tabitha C.; Good, Jessica J.; Bynum, Isaac] Davidson Coll, Davidson, NC 28036 USA.
   [Erickson, Austin; Bruder, Gerd] Univ Cent Florida, Orlando, FL 32816 USA.
C3 Davidson College; State University System of Florida; University of
   Central Florida
RP Peck, TC (corresponding author), Davidson Coll, Davidson, NC 28036 USA.
EM tapeck@davidson.edu; jegood@davidson.edu; ericksona@knights.ucf.edu;
   isbynum@davidson.edu; Gerd.Bruder@ucf.edu
RI Peck, Tabitha/AAH-2032-2021; Erickson, Austin/AAV-9677-2020
FU Davidson College's Faculty Study and Research program; National Science
   Foundation [1800961, 1800947, 1800922]; Office of Naval Research
   [N00014-21-1-2578, N00014-17-1-2927, 34]
FX Funding for this work was supported by Davidson College's Faculty Study
   and Research program. This material includes work supported in part by
   the National Science Foundation under Collaborative Award Numbers
   1800961, 1800947, and 1800922 (Dr. Ephraim P. Glinert, IIS) to the
   University of Central Florida, University of Florida, and Stanford
   University, respectively, and the Office of Naval Research under Award
   Numbers N00014-21-1-2578 and N00014-17-1-2927 (Dr. Peter Squire, Code
   34).
CR Albarello F, 2018, J SOC PSYCHOL, V158, P309, DOI 10.1080/00224545.2017.1346581
   Albarello F, 2012, EUR J SOC PSYCHOL, V42, P875, DOI 10.1002/ejsp.1902
   Andrighetto L, 2014, BRIT J SOC PSYCHOL, V53, P573, DOI 10.1111/bjso.12066
   Bastian B, 2012, SOC PSYCHOL PERS SCI, V3, P421, DOI 10.1177/1948550611425106
   Cakmakci O, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P16, DOI 10.1109/ISMAR.2004.2
   de Cunsel S, 2020, PROC SPIE, V11350, DOI 10.1117/12.2555472
   DEVINE PG, 1989, J PERS SOC PSYCHOL, V56, P5, DOI 10.1037/0022-3514.56.5.680
   DEVINE PG, 1995, PERS SOC PSYCHOL B, V21, P1139, DOI 10.1177/01461672952111002
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Erickson A, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418445
   Erickson A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3456874
   Feliciano C, 2016, AM BEHAV SCI, V60, P390, DOI 10.1177/0002764215613401
   Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878
   Fuchs H., 2016, US Patent, Patent No. [9,265,572, 9265572]
   Gabbard JL, 2022, IEEE T VIS COMPUT GR, V28, P2834, DOI 10.1109/TVCG.2020.3044715
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Geiger H.J., 2003, UNEQUAL TREATMENT CO, P417, DOI DOI 10.17226/12875
   Genay A. C. S., 2021, TVCG, P1
   Goff PA, 2008, J PERS SOC PSYCHOL, V94, P292, DOI 10.1037/0022-3514.94.2.292
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Grasset R, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P90
   Halberstadt AG, 2018, CONTEMP EDUC PSYCHOL, V54, P125, DOI 10.1016/j.cedpsych.2018.06.004
   Harms C., 2004, Seventh Annual International Workshop: Presence 2004
   Haslam N, 2008, SOC COGNITION, V26, P248, DOI 10.1521/soco.2008.26.2.248
   Haslam N, 2014, ANNU REV PSYCHOL, V65, P399, DOI 10.1146/annurev-psych-010213-115045
   Hewes HA, 2018, PREHOSP EMERG CARE, V22, P189, DOI 10.1080/10903127.2017.1367444
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Hugenberg K, 2003, PSYCHOL SCI, V14, P640, DOI 10.1046/j.0956-7976.2003.psci_1478.x
   Hunter M., 2013, MELANIN MILLENNIUM S, P247, DOI DOI 10.1007/978-94-007-4608-4_16
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Itoh Y, 2019, IEEE T VIS COMPUT GR, V25, P1951, DOI 10.1109/TVCG.2019.2899229
   Jacoby Karl., 1994, SLAVERY ABOLITION, V15, P89
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kiyokawa K, 1998, P SOC PHOTO-OPT INS, V3517, P2, DOI 10.1117/12.326923
   Kubota JT, 2017, SOC NEUROSCI-UK, V12, P468, DOI 10.1080/17470919.2016.1182585
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P9, DOI 10.1109/3DCVE.2016.7563559
   Lee Y.-H., 2019, Virtual Reality Intelligent Hardware, V1, P10, DOI [10.3724/SP.J.2096-5796.2018.0009, DOI 10.3724/SP.J.2096-5796.2018.0009]
   Lhommet M., 2014, The Oxford Handbook of Affective Computing, P273
   Lin J.C.P., 2020, WHAT ALUMS WISH THEY, P1
   Little R. J., 2019, STAT ANAL MISSING DA, V793
   Little TD, 2014, J PEDIATR PSYCHOL, V39, P151, DOI 10.1093/jpepsy/jst048
   Mori M., 1970, Energy, V7, P33, DOI [DOI 10.1037/a0038814, DOI 10.1109/MRA.2012.2192811]
   Morning Ann., 2011, The Nature of Race
   Norouzi N., 2020, INT C ARTIFICIAL REA, P101
   Onyeador IN, 2021, POL INS BEH BRAIN SC, V8, P19, DOI 10.1177/2372732220983840
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Peck TC, 2021, IEEE T VIS COMPUT GR, V27, P2502, DOI 10.1109/TVCG.2021.3067767
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Rudman LA, 2012, PERS SOC PSYCHOL B, V38, P734, DOI 10.1177/0146167212436401
   Scott K, 2017, J SOC ISSUES, V73, P701, DOI 10.1111/josi.12243
   Smedley Audrey., 2018, Race in North America: Origin and Evolution of a Worldview
   Thompson JC, 2011, PERCEPTION, V40, P695, DOI 10.1068/p6900
   Trawalter S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048546
   Utzig S, 2019, AEROSP CONF PROC
   Viki GT, 2013, J EXP SOC PSYCHOL, V49, P325, DOI 10.1016/j.jesp.2012.11.006
   Waldow K, 2019, LECT NOTES COMPUT SC, V11883, P246, DOI 10.1007/978-3-030-31908-3_15
   Waytz A, 2015, SOC PSYCHOL PERS SCI, V6, P352, DOI 10.1177/1948550614553642
   White C, 2015, CRITICAL QUALITATIVE RESEARCH IN SOCIAL EDUCATION, P1
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Yu K, 2021, IEEE T VIS COMPUT GR, V27, P4129, DOI 10.1109/TVCG.2021.3106480
   Zlobina A.N., 2021, PEACE CONFL
NR 63
TC 8
Z9 8
U1 4
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2179
EP 2189
DI 10.1109/TVCG.2022.3150521
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0M8RI
UT WOS:000782415400006
PM 35148265
OA Bronze
DA 2024-11-06
ER

PT J
AU Azmandian, M
   Yahata, R
   Grechkin, T
   Thomas, J
   Rosenberg, ES
AF Azmandian, Mahdi
   Yahata, Rhys
   Grechkin, Timofey
   Thomas, Jerald
   Rosenberg, Evan Suma
TI Validating Simulation-Based Evaluation of Redirected Walking Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Solid modeling; Prediction algorithms; Biological
   system modeling; Task analysis; Virtual environments; Heuristic
   algorithms; Virtual reality; redirected walking; locomotion; simulation
ID MOTION COMPRESSION
AB Developing effective strategies for redirected walking requires extensive evaluations across a variety of factors that influence performance. Because these large-scale experiments are often not practical with user studies, researchers have instead utilized simulations to systematically test different algorithm parameters, physical space configurations, and virtual walking paths. Although simulation offers an efficient way to evaluate redirected walking algorithms, it remains an open question whether this evaluation methodology is ecologically valid. In this paper, we investigate the interaction between locomotion behavior and redirection gains at a micro-level (across small path segments) and macro-level (across an entire experience). This examination involves analyzing data from real users and comparing algorithm performance metrics with a simulated user model. The results identify specific properties of user locomotion behavior that influence the application of redirected walking gains and resets. Overall, we found that the simulation provided a conservative estimate of the average performance with real users and observed that performance trends when comparing two redirected walking algorithms were preserved. In general, these results indicate that simulation is an empirically valid evaluation methodology for redirected walking algorithms.
C1 [Azmandian, Mahdi; Yahata, Rhys; Grechkin, Timofey] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
   [Thomas, Jerald; Rosenberg, Evan Suma] Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Southern California; University of Minnesota System;
   University of Minnesota Twin Cities
RP Thomas, J (corresponding author), Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
EM thoma891@umn.edu; suma@umn.edu
OI Suma Rosenberg, Evan/0000-0002-4826-4561; Thomas,
   Jerald/0000-0002-0931-6920
FU U.S. Army Research Laboratory (ARL) [W911NF-14-D-0005]
FX This work was sponsored by the U.S. Army Research Laboratory (ARL) under
   contract number W911NF-14-D-0005. Statements and opinions expressed do
   not necessarily reflect the position or the policy of the Government,
   and no official endorsement should be inferred.
CR [Anonymous], 2001, P EUROGRAPHICS
   Azmandian M., 2014, P ACM S APPL PERCEPT, P129
   Azmandian M, 2018, THESIS U SE CALIFORN
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   Boulic R., 1990, Visual Computer, V6, P344, DOI 10.1007/BF01901021
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Grechkin T, 2015, P IEEE VIRT REAL ANN, P185, DOI 10.1109/VR.2015.7223357
   Günther M, 2003, BIOL CYBERN, V89, P89, DOI 10.1007/s00422-003-0414-x
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Holm J. E., 2012, THESIS MIAMI U
   Hutton C., 2018, ICAT-EGVE
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   LISHMAN JR, 1973, PERCEPTION, V2, P287, DOI 10.1068/p020287
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Montano-Murillo RA, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1123, DOI 10.1145/3332165.3347914
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nitzsche N, 2004, PRESENCE-TELEOP VIRT, V13, P44, DOI 10.1162/105474604774048225
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Razzaque Sharif, 2005, CITESEER
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Su JB, 2007, PRESENCE-VIRTUAL AUG, V16, P385, DOI 10.1162/pres.16.4.385
   Suma E. A., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P35, DOI 10.1109/3DUI.2011.5759214
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Thomas J., 2020, 26th ACM Symposium on Virtual Reality Software and Technology, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Yang QS, 2015, J SOUND VIB, V357, P437, DOI 10.1016/j.jsv.2015.07.017
   You C, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3358757
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 47
TC 5
Z9 5
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2022
VL 28
IS 5
BP 2288
EP 2298
DI 10.1109/TVCG.2022.3150466
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0M8RI
UT WOS:000782415400007
PM 35175920
DA 2024-11-06
ER

PT J
AU Cao, N
   Ropinski, T
   Zhao, J
AF Cao, Nan
   Ropinski, Timo
   Zhao, Jian
TI Guest Editors' Introduction: Special Section on IEEE PacificVis 2022
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Cao, Nan] Tongji Univ, Coll Design & Innovat, Shanghai 200092, Peoples R China.
   [Ropinski, Timo] Ulm Univ, Inst Media Informat, D-89081 Ulm, Germany.
   [Zhao, Jian] Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON, Canada.
C3 Tongji University; Ulm University; University of Waterloo
RP Cao, N (corresponding author), Tongji Univ, Coll Design & Innovat, Shanghai 200092, Peoples R China.
EM nan.cao@tongji.edu.cn; timo.ropinski@uni-ulm.de; jianzhao@uwaterloo.ca
RI Cao, Nan/O-5397-2014
OI Ropinski, Timo/0000-0002-7857-5512
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2299
EP 2300
DI 10.1109/TVCG.2022.3165393
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100003
OA Bronze
DA 2024-11-06
ER

PT J
AU Shi, N
   Xu, JY
   Wurster, SW
   Guo, HQ
   Woodring, J
   Van Roekel, LP
   Shen, HW
AF Shi, Neng
   Xu, Jiayi
   Wurster, Skylar W.
   Guo, Hanqi
   Woodring, Jonathan
   Van Roekel, Luke P.
   Shen, Han-Wei
TI GNN-Surrogate: A Hierarchical and Adaptive Graph Neural Network for
   Parameter Space Exploration of Unstructured-Mesh Ocean Simulations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Parameter Space Exploration; Ensemble Visualization; Unstructured Mesh;
   Surrogate Modeling; Graph Neural Network; Adaptive Resolution
ID VISUALIZATION
AB We propose GNN-Surrogate, a graph neural network-based surrogate model to explore the parameter space of ocean climate simulations. Parameter space exploration is important for domain scientists to understand the influence of input parameters (e.g., wind stress) on the simulation output (e.g., temperature). The exploration requires scientists to exhaust the complicated parameter space by running a batch of computationally expensive simulations. Our approach improves the efficiency of parameter space exploration with a surrogate model that predicts the simulation outputs accurately and efficiently. Specifically, GNN-Surrogate predicts the output field with given simulation parameters so scientists can explore the simulation parameter space with visualizations from user-specified visual mappings. Moreover, our graph-based techniques are designed for unstructured meshes, making the exploration of simulation outputs on irregular grids efficient. For efficient training, we generate hierarchical graphs and use adaptive resolutions. We give quantitative and qualitative evaluations on the MPAS-Ocean simulation to demonstrate the effectiveness and efficiency of GNN-Surrogate.
C1 [Shi, Neng; Xu, Jiayi; Wurster, Skylar W.; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Guo, Hanqi] Argonne Natl Lab, Math & Comp Sci Div, Lemont, IL 60439 USA.
   [Woodring, Jonathan] Los Alamos Natl Lab, Appl Comp Sci Grp CCS 7, Los Alamos, NM 87544 USA.
   [Van Roekel, Luke P.] Los Alamos Natl Lab, Fluid Dynam & Solid Mech Grp T3, Los Alamos, NM 87544 USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Energy (DOE); Argonne National Laboratory; United States
   Department of Energy (DOE); Los Alamos National Laboratory; United
   States Department of Energy (DOE); Los Alamos National Laboratory
RP Shi, N (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM shi.1337@osu.edu; xu.2205@osu.edu; wurster.18@osu.edu; hguo@anl.gov;
   woodring@lanl.gov; lvanroekel@lanl.gov; shen.94@osu.edu
RI Guo, Hanqi/AAL-1929-2021; Shen, Han-wei/A-4710-2012; Guo,
   Hanqi/ADW-4234-2022
OI Wurster, Skylar/0000-0001-6685-615X; Guo, Hanqi/0000-0001-7776-1834
FU National Science Foundation Division of Information and Intelligent
   Systems [1955764]; National Science Foundation Office of Advanced
   Cyberinfrastructure [2112606]; U.S. Department of Energy Los Alamos
   National Laboratory [47145]; UT-Battelle LLC [4000159447]; SciDAC
   program - U.S. Department of Energy, Office of Science, Advanced
   Scientific Computing Research; DOE Office of Science User Facility
   [DE-AC02-06CH11357]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1955764] Funding Source: National
   Science Foundation; Office of Advanced Cyberinfrastructure (OAC); Direct
   For Computer & Info Scie & Enginr [2112606] Funding Source: National
   Science Foundation
FX This work is supported in part by the National Science Foundation
   Division of Information and Intelligent Systems-1955764, the National
   Science Foundation Office of Advanced Cyberinfrastructure2112606, U.S.
   Department of Energy Los Alamos National Laboratory contract 47145, and
   UT-Battelle LLC contract 4000159447 program manager Margaret Lentz. This
   work is also supported in part by the SciDAC program funded by the U.S.
   Department of Energy, Office of Science, Advanced Scientific Computing
   Research. This research used resources of the Argonne Leadership
   Computing Facility, which is a DOE Office of Science User Facility
   supported under Contract DE-AC02-06CH11357.
CR Alden K., 2018, IEEEACM T COMPUT BIO, V17, P302
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Bock A, 2015, 2015 IEEE Scientific Visualization Conference (SciVis), P17, DOI 10.1109/SciVis.2015.7429487
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Chen FW, 2012, PADDY WATER ENVIRON, V10, P209, DOI 10.1007/s10333-012-0319-1
   Chen HD, 2015, IEEE T VIS COMPUT GR, V21, P1072, DOI 10.1109/TVCG.2015.2410278
   Coffey D, 2013, IEEE T VIS COMPUT GR, V19, P2783, DOI 10.1109/TVCG.2013.147
   Defferrard M., 2019, ARXIV PREPRINT ARXIV
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]
   Erdal D, 2020, STOCH ENV RES RISK A, V34, P1813, DOI 10.1007/s00477-020-01867-0
   Feld J, 1940, PLANE SPHERICAL TRIG
   Fey Matthias., 2021, PyTorch Sparse
   Han J., 2020, IEEE T VIS COMPUT GR, V27, P1290
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Hazarika S, 2020, IEEE T VIS COMPUT GR, V26, P34, DOI 10.1109/TVCG.2019.2934591
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kindlmann G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P299, DOI 10.1109/VISUAL.2002.1183788
   Kuchaiev Oleksii, 2018, 6 INT C LEARNING REP
   Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109
   Lu GY, 2008, COMPUT GEOSCI-UK, V34, P1044, DOI 10.1016/j.cageo.2007.07.010
   Matkovic K, 2009, IEEE T VIS COMPUT GR, V15, P1351, DOI 10.1109/TVCG.2009.155
   Miyato T., 2018, INT C LEARN REPR, P1
   Moreland K., 2016, EI, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.16.HVEI-133, DOI 10.2352/ISSN.2470-1173.2016.16.HVEI-133]
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Obermaier H, 2016, IEEE T VIS COMPUT GR, V22, P2331, DOI 10.1109/TVCG.2015.2507592
   Orban D, 2019, IEEE T VIS COMPUT GR, V25, P256, DOI 10.1109/TVCG.2018.2865051
   Paszke A, 2019, ADV NEUR IN, V32
   Perraudin N, 2019, ASTRON COMPUT, V27, P130, DOI 10.1016/j.ascom.2019.03.004
   Petersen M., 2018, **DATA OBJECT**, DOI 10.5281/zenodo.1252437
   Pfaff Tobias, 2020, ARXIV PREPRINT ARXIV
   Poco J, 2014, IEEE T VIS COMPUT GR, V20, P1923, DOI 10.1109/TVCG.2014.2346755
   Ringler T, 2013, OCEAN MODEL, V69, P211, DOI 10.1016/j.ocemod.2013.04.010
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Splechtna R, 2015, IEEE CONF VIS ANAL, P89, DOI 10.1109/VAST.2015.7347635
   Ulyanov D, 2016, ARXIV
   Urban NM, 2010, COMPUT GEOSCI-UK, V36, P746, DOI 10.1016/j.cageo.2009.11.004
   Valsesia D, 2021, IEEE T MULTIMEDIA, V23, P402, DOI 10.1109/TMM.2020.2976627
   Wang J., IEEE T VIS COMPUT GR, V25, P2853
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang Q, 2021, IEEE Transactions on Visualization and Computer Graphics, P1
   Wild SM, 2008, SIAM J SCI COMPUT, V30, P3197, DOI 10.1137/070691814
NR 43
TC 13
Z9 14
U1 3
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2301
EP 2313
DI 10.1109/TVCG.2022.3165345
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100004
PM 35389867
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Rapp, T
   Peters, C
   Dachsbacher, C
AF Rapp, Tobias
   Peters, Christoph
   Dachsbacher, Carsten
TI Image-based Visualization of Large Volumetric Data Using Moments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image-based visualization; volume rendering; unstructured volumes;
   moments; MESE; Fourier reconstruction
ID OF-THE-ART; MODELS
AB We present a novel image-based representation to interactively visualize large and arbitrarily structured volumetric data. This image-based representation is created from a fixed view and models the scalar densities along each viewing ray. Then, any transfer function can be applied and changed interactively to visualize the data. In detail, we transform the density in each pixel to the Fourier basis and store Fourier coefficients of a bounded signal, i.e. bounded trigonometric moments. To keep this image-based representation compact, we adaptively determine the number of moments in each pixel and present a novel coding and quantization strategy. Additionally, we perform spatial and temporal interpolation of our image representation and discuss the visualization of introduced uncertainties. Moreover, we use our representation to add single scattering illumination. Lastly, we achieve accurate results even with changes in the view configuration. We evaluate our approach on two large volume datasets and a time-dependent SPH dataset.
C1 [Rapp, Tobias; Peters, Christoph; Dachsbacher, Carsten] Karlsruhe Inst Technol, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Rapp, T (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM tobias.rapp@kit.edu; christoph.peters@kit.edu; dachsbacher@kit.edu
FU bwVisu project - Ministry for Science, Research and Art of the country
   of Baden-Wurttemberg, Germany; bwVisu2 project - Ministry for Science,
   Research and Art of the country of Baden-Wurttemberg, Germany
FX This work has been supported by the bwVisu and bwVisu2 projects funded
   by the Ministry for Science, Research and Art of the country of
   Baden-Wurttemberg, Germany.
CR Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   [Anonymous], 1978, P 5 ANN C COMPUTER G, P270
   [Anonymous], 1999, P IEEE VISUALIZATION
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Bujack R., 2018, LEIPZ S VIS APPL LEV
   Childs Hank, 2015, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V2, P5
   Engel K., 2001, Proceedings of the ACM SIGGRAPH/EUROGRAPHICS Workshop on Graphics Hardware, P9, DOI [10.1145/383507.383515, DOI 10.1145/383507.383515]
   Fernandes O, 2014, SYMP LARG DATA ANAL, P59, DOI 10.1109/LDAV.2014.7013205
   Frey Steffen, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P123, DOI 10.1109/SIBGRAPI.2013.26
   JAIN R, 1985, COMMUN ACM, V28, P1076, DOI 10.1145/4372.4378
   Kern M., 2020, IEEE T VIS COMPUT GR, P1
   Li S, 2018, COMPUT GRAPH FORUM, V37, P422, DOI 10.1111/cgf.13336
   Lindemann F, 2011, IEEE T VIS COMPUT GR, V17, P1922, DOI 10.1109/TVCG.2011.161
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Lukasczyk J, 2020, SYMP LARG DATA ANAL, P37, DOI 10.1109/LDAV51489.2020.00011
   Lukasczyk J, 2018, SYMP LARG DATA ANAL, P12, DOI 10.1109/LDAV.2018.8739204
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Muenstermann C, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203206
   Peters C., 2017, J COMPUTER GRAPHICS, V6
   Peters C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322964
   Peters C, 2015, PROCEEDINGS - I3D 2015, P7, DOI 10.1145/2699276.2699277
   Peters C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818103
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Rojo I. Baeza, 2019, IEEE T VIS COMPUT GR, P1
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shareef N., 2006, VOLUME GRAPHICS
   Shusen Liu, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P73, DOI 10.1109/LDAV.2012.6378978
   Tikhonova A, 2010, COMPUT GRAPH FORUM, V29, P783, DOI 10.1111/j.1467-8659.2009.01690.x
   Tikhonova A, 2010, IEEE PAC VIS SYMP, P177, DOI 10.1109/PACIFICVIS.2010.5429595
   Tikhonova A, 2010, IEEE T VIS COMPUT GR, V16, P1551, DOI 10.1109/TVCG.2010.215
   Wang KC, 2020, IEEE T VIS COMPUT GR, V26, P3299, DOI 10.1109/TVCG.2019.2920130
   Wang KC, 2018, IEEE PAC VIS SYMP, P26, DOI 10.1109/PacificVis.2018.00013
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   YEO BL, 1995, IEEE T VIS COMPUT GR, V1, P29, DOI 10.1109/2945.468390
NR 38
TC 3
Z9 3
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2314
EP 2325
DI 10.1109/TVCG.2022.3165346
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100005
PM 35442887
DA 2024-11-06
ER

PT J
AU Xuan, XW
   Zhang, XY
   Kwon, OH
   Ma, KL
AF Xuan, Xiwei
   Zhang, Xiaoyu
   Kwon, Oh-Hyun
   Ma, Kwan-Liu
TI VAC-CNN: A Visual Analytics System for Comparative Studies of Deep
   Convolutional Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; machine learning; convolutional neural network; model
   comparison; visual explanation
AB The rapid development of Convolutional Neural Networks (CNNs) in recent years has triggered significant breakthroughs in many machine learning (ML) applications. The ability to understand and compare various CNN models available is thus essential. The conventional approach with visualizing each model's quantitative features, such as classification accuracy and computational complexity. is not sufficient for a deeper understanding and comparison of the behaviors of different models. Moreover, most of the existing tools for assessing CNN behaviors only support comparison between two models and lack the flexibility of customizing the analysis tasks according to user needs. This paper presents a visual analytics system, VAC-CNN (Visual Analytics for Comparing CNNs), that supports the in-depth inspection of a single CNN model as well as comparative studies of two or more models. The ability to compare a larger number of (e.g., tens of) models especially distinguishes our system from previous ones. With a carefully designed model visualization and explaining support : VAC-CNN facilitates a highly interactive workflow that promptly presents both quantitative and qualitative information at each analysis stage. We demonstrate VAC-CNN's effectiveness for assisting novice ML practitioners in evaluating and comparing multiple CNN models through two use cases and one preliminary evaluation study using the image classification tasks on the ImageNet dataset.
C1 [Xuan, Xiwei; Zhang, Xiaoyu; Kwon, Oh-Hyun; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Xuan, XW (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM xwxuan@ucdavis.edu; xybzhang@ucdavis.edu; kw@ucdavis.edu;
   klma@ucdavis.edu
RI Kwon, Oh-Hyun/GWC-9169-2022; Zhang, Xiaoyu/HGD-2946-2022; Xuan,
   Xiwei/JNS-6414-2023
OI Zhang, Xiaoyu/0000-0002-8057-3997; Xuan, Xiwei/0000-0002-0828-8761
FU U.S. National Science Foundation [IIS-1741536]; Bosch Research
FX This research is supported in part by the U.S. National Science
   Foundation through grant IIS-1741536 and a gift grant from Bosch
   Research. We would like to thank all the participants of our preliminary
   evaluation study during this challenging time. We also want show our
   gratitude to Norma Gowans for narrating in our demonstration video. We
   appreciated Takanori Fujiwara, Jianping (Kelvin) Li, and Qi Wu for their
   precious suggestions that improve this work. We wish to extend our
   special thanks to anonymous reviewers for their thoughtful feedbacks and
   comments.
CR Adebayo J, 2018, 6 INT C LEARN REPR I
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Arendt DL, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P259, DOI 10.1145/3377325.3377514
   Aydogdu MF, 2017, IEEE INT C SEMANT CO, P372, DOI 10.1109/ICSC.2017.61
   Baker N, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006613
   Bhatt D., ELECTRONICS, V10, P2021
   Cai W., 2019, ARXIV PREPRINT ARXIV
   Canziani Alfredo, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1605.07678
   Carter S, 2020, OpenAI Microscope
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Das S, 2019, IEEE COMPUT GRAPH, V39, P20, DOI 10.1109/MCG.2019.2922592
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Geirhos R., 2018, IMAGENET TRAINED CNN
   Gunning D., 2017, Defense advanced research projects agency (DARPA), and Web
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Howard A.G., 2017, MOBILENETS EFFICIENT
   Hu YJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P368, DOI 10.1145/3219819.3219846
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Iandola F.N., 2016, SQUEEZENET ALEXNET L
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, Neural Networks: The Statistical Mechanics Perspective. Proceedings of the CTP-PBSRI. Joint Workshop on Theoretical Physics, P261
   Li YR, 2020, VIS INFORM, V4, P122, DOI 10.1016/j.visinf.2020.04.005
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P1385, DOI 10.1109/TVCG.2020.3028888
   Malakar A., 2013, Int. J. Sci. Res, V2, P532
   Mordvintsev A., 2015, GOOGLE RES, V2
   Mukhopadhyay A, 2019, ICGSP '19 - PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON GRAPHICS AND SIGNAL PROCESSING, P29, DOI 10.1145/3338472.3338480
   Murugesan S, 2019, IEEE COMPUT GRAPH, V39, P47, DOI 10.1109/MCG.2019.2919033
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   Omeiza D., 2019, ABS190801224 CORR
   Phetnuam S, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P327, DOI 10.1109/SITIS.2018.00057
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Roy K., 2013, Int. J. Sci. Res., V2, P538
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   SIMONYAN K., 2013, ABS13126034 CORR
   Springenberg J. T., 2014, ARXIV
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang H., 2019, P 23 C COMP NAT LANG, P696
   Waskom M. L., 2021, Journal of Open-Source Software, V6, P3021, DOI [DOI 10.21105/JOSS.03021, 10.21105/joss.03021]
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng H., 2017, PROC IEEE 25 INT C I, DOI DOI 10.1109/ICIP.2018.8451285
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 55
TC 13
Z9 13
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2326
EP 2337
DI 10.1109/TVCG.2022.3165347
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100006
PM 35389868
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shilpika
   Fujiwara, T
   Sakamoto, N
   Nonaka, J
   Ma, KL
AF Shilpika
   Fujiwara, Takanori
   Sakamoto, Naohisa
   Nonaka, Jorji
   Ma, Kwan-Liu
TI A Visual Analytics Approach for Hardware System Monitoring with
   Streaming Functional Data Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Functional data analysis; magnitude-shape plot; time-series data;
   progressive data analysis; performance
ID TIME-SERIES DATA
AB Many real-world applications involve analyzing time-dependent phenomena, which are intrinsically functional, consisting of curves varying over a continuum (e.g., time). When analyzing continuous data, functional data analysis (FDA) provides substantial benefits, such as the ability to study the derivatives and to restrict the ordering of data. However, continuous data inherently has infinite dimensions, and for a long time series, FDA methods often suffer from high computational costs. The analysis problem becomes even more challenging when updating the FDA results for continuously arriving data. In this paper, we present a visual analytics approach for monitoring and reviewing time series data streamed from a hardware system with a focus on identifying outliers by using FDA. To perform FDA while addressing the computational problem, we introduce new incremental and progressive algorithms that promptly generate the magnitude-shape (MS) plot, which conveys both the functional magnitude and shape outlyingness of time series data. In addition, by using an MS plot in conjunction with an FDA version of principal component analysis, we enhance the analyst's ability to investigate the visually-identified outliers. We illustrate the effectiveness of our approach with two use scenarios using real-world datasets. The resulting tool is evaluated by industry experts using real-world streaming datasets.
C1 [Shilpika; Fujiwara, Takanori; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Sakamoto, Naohisa] Kobe Univ, Grad Sch Syst Informat, Kobe, Hyogo, Japan.
   [Nonaka, Jorji] RIKEN R CCS, Operat & Comp Technol Div, Wako, Saitama, Japan.
C3 University of California System; University of California Davis; Kobe
   University
RP Shilpika (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM fshilpika@ucdavis.edu; tfujiwara@ucdavis.edu;
   naohisa.sakamoto@people.kobe-u.ac.jp; jorji@riken.jp; klma@ucdavis.edu
RI Fujiwara, Takanori/AAY-5045-2020; NONAKA, JORJI/C-5338-2016; Sakamoto,
   Naohisa/M-6414-2016
OI NONAKA, JORJI/0000-0001-6809-6393; Fujiwara,
   Takanori/0000-0002-6382-2752; Sakamoto, Naohisa/0000-0002-9210-467X
FU U.S. National Science Foundation [IIS-1741536]; Argonne National
   Laboratory [8F-30225]
FX This research was supported in part by the U.S. National Science
   Foundation through grant IIS-1741536 and the Argonne National Laboratory
   through contract 8F-30225. We thank Keiji Yamamoto for providing useful
   information regarding the supercomputer data.
CR Ali M, 2019, IEEE ACCESS, V7, P181314, DOI 10.1109/ACCESS.2019.2958551
   [Anonymous], 2018, ARXIV181208032
   [Anonymous], 2005, Functional Data Analysis
   CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10
   Crnovrsanin T., 2017, J. Graph Algorithms Appl., V21, P55
   Dai W., 2019, COMPUT STAT DATA AN
   Dai WL, 2018, J COMPUT GRAPH STAT, V27, P923, DOI 10.1080/10618600.2018.1473781
   Dasgupta A, 2018, COMPUT GRAPH FORUM, V37, P254, DOI 10.1111/cgf.13264
   Ferraty F., 2006, SPR S STAT
   Fong D.D., 2018, Smart Health, V9-10, P23, DOI [DOI 10.1016/J.SMHL.2018.07.011, 10.1016/j.smhl.2018.07.011]
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Guo H., 2018, P EGPGV, P91
   Harms K, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4336
   Higdon R., 2013, Encycl. Syst. Biol., P814, DOI DOI 10.1007/978-1-4419-9863-7_1197
   Horvath L., 2012, Inference for functional data with applications
   Hyndman RJ, 2007, COMPUT STAT DATA AN, V51, P4942, DOI 10.1016/j.csda.2006.07.028
   Hyndman RJ, 2010, J COMPUT GRAPH STAT, V19, P29, DOI 10.1198/jcgs.2009.08158
   Karhunen K, 1946, Ann Acad Sci Fenn, AI, P34
   Katragadda S., 2019, P PEARC, P1
   Kesavan SP, 2020, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis48177.2020.9280
   Kneip A, 2001, J AM STAT ASSOC, V96, P519, DOI 10.1198/016214501753168235
   Ko H.-K., 2020, Proc. EuroVis, P133, DOI DOI 10.2312/EVS.20201061
   Krstajic Milos, 2013, 2013 IEEE International Conference on Big Data, P41, DOI 10.1109/BigData.2013.6691713
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Love M., 1946, REV SCI, V84, P159
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Millán-Roures L, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5129735
   Miyazaki H, 2012, FUJITSU SCI TECH J, V48, P255
   Mosler K., 2013, Robustness and Complex Data Structures: Festschrift in Honour of Ursula Gather, P17, DOI DOI 10.1007/978-3-642-35494-6_2
   Park BH, 2018, IEEE INT C CL COMP, P571, DOI 10.1109/CLUSTER.2018.00073
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   RAO CR, 1958, BIOMETRICS, V14, P1, DOI 10.2307/2527726
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sato M., 2020, Proc. ISPDC, P1
   Shang HL, 2014, ASTA-ADV STAT ANAL, V98, P121, DOI 10.1007/s10182-013-0213-1
   Shilpika, 2019, PROCEEDINGS OF DAAC 2019: THE 3RD IEEE/ACM INDUSTRY/UNIVERSITY JOINT INTERNATIONAL WORKSHOP ON DATA-CENTER AUTOMATION, ANALYTICS, AND CONTROL (DAAC), P13, DOI 10.1109/DAAC49578.2019.00008
   Tanahashi Y, 2015, IEEE T VIS COMPUT GR, V21, P730, DOI 10.1109/TVCG.2015.2392771
   Tukey J. W., 1975, P INT C MATH, V2, P523
   Turkay C, 2017, IEEE T VIS COMPUT GR, V23, P131, DOI 10.1109/TVCG.2016.2598470
   Vardi Y, 2000, P NATL ACAD SCI USA, V97, P1423, DOI 10.1073/pnas.97.4.1423
   Viviani R, 2005, HUM BRAIN MAPP, V24, P109, DOI 10.1002/hbm.20074
   Wang JL, 2016, ANNU REV STAT APPL, V3, P257, DOI 10.1146/annurev-statistics-041715-033624
   Wang Q, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942056
   Weiss GM, 2019, IEEE ACCESS, V7, P133190, DOI 10.1109/ACCESS.2019.2940729
   Xu K, 2020, IEEE T VIS COMPUT GR, V26, P1107, DOI 10.1109/TVCG.2019.2934613
   Xu K, 2019, IEEE T VIS COMPUT GR, V25, P109, DOI 10.1109/TVCG.2018.2864825
   Zuo YJ, 2004, ANN STAT, V32, P167
NR 49
TC 4
Z9 6
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2338
EP 2349
DI 10.1109/TVCG.2022.3165348
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100007
PM 35394909
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bhatia, H
   Hoang, D
   Morrical, N
   Pascucci, V
   Bremer, PT
   Lindstrom, P
AF Bhatia, Harsh
   Hoang, Duong
   Morrical, Nate
   Pascucci, Valerio
   Bremer, Peer-Timo
   Lindstrom, Peter
TI AMM: Adaptive Multilinear Meshes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptive Meshes; Wavelets; Compression Techniques; Multiresolution
   Techniques; Streaming Data; Scalar Field Data
ID COMPRESSION; EFFICIENT; VISUALIZATION; INSTABILITY; REFINEMENT;
   SIMULATION; FRAMEWORK; WAVELETS
AB Adaptive representations are increasingly indispensable for reducing the in-memory and on-disk footprints of large-scale data. Usual solutions are designed broadly along two themes: reducing data precision, e.g., through compression, or adapting data resolution, e.g., using spatial hierarchies. Recent research suggests that combining the two approaches, i.e., adapting both resolution and precision simultaneously, can offer significant gains over using them individually. However, there currently exist no practical solutions to creating and evaluating such representations at scale. In this work, we present a new resolution-precision-adaptive representation to support hybrid data reduction schemes and offer an interface to existing tools and algorithms. Through novelties in spatial hierarchy, our representation, Adaptive Multilinear Meshes (AMM), provides considerable reduction in the mesh size. AMM creates a piecewise multilinear representation of uniformly sampled scalar data and can selectively relax or enforce constraints on conformity, continuity, and coverage, delivering a flexible adaptive representation. AMM also supports representing the function using mixed-precision values to further the achievable gains in data reduction. We describe a practical approach to creating AMM incrementally using arbitrary orderings of data and demonstrate AMM on six types of resolution and precision datastreams. By interfacing with state-of-the-art rendering tools through VTK, we demonstrate the practical and computational advantages of our representation for visualization techniques. With an open-source release of our tool to create AMM, we make such evaluation of data reduction accessible to the community, which we hope will foster new opportunities and future data reduction schemes.
C1 [Bhatia, Harsh; Bremer, Peer-Timo; Lindstrom, Peter] Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94550 USA.
   [Hoang, Duong; Morrical, Nate; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
C3 United States Department of Energy (DOE); Lawrence Livermore National
   Laboratory; Utah System of Higher Education; University of Utah
RP Bhatia, H (corresponding author), Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94550 USA.
RI Hoang, Thanh/ABZ-4320-2022; pascucci, Valerio/GXF-0616-2022
OI pascucci, valerio/0000-0002-8877-2042; Hoang, DT/0000-0002-4463-4270;
   Lindstrom, Peter/0000-0003-3817-4199
FU U.S. Department of Energy (DOE) by Lawrence Livermore National
   Laboratory [DE-AC52-07NA27344]; LLNL-LDRD Program [17-SI-004]; NSF OAC
   [2127548, 1941085, 2138811]; DOE award [DE-FE0031880]; Intel Graphics
   and Visualization Institute of XeLLENCE; oneAPI Center of Excellence
   [LLNL-JRNL-771697]; NSF CMMI awards [1629660]; Div Of Civil, Mechanical,
   & Manufact Inn; Directorate For Engineering [1629660] Funding Source:
   National Science Foundation
FX This work was performed under the auspices of the U.S. Department of
   Energy (DOE) by Lawrence Livermore National Laboratory under Contract
   DE-AC52-07NA27344 and supported by the LLNL-LDRD Program under Project
   No. 17-SI-004. We thank Jeffrey Hittinger for insightful discussions
   during this project. This work was funded in part by NSF OAC awards
   2127548, 1941085, 2138811 NSF CMMI awards 1629660, DOE award
   DE-FE0031880, and the Intel Graphics and Visualization Institute of
   XeLLENCE, and oneAPI Center of Excellence. LLNL-JRNL-771697.
CR Ahrens James, 2005, VISUALIZATION HDB, V717, P8
   Ainsworth M, 2019, SIAM J SCI COMPUT, V41, pA1278, DOI 10.1137/18M1166651
   Ainsworth M, 2018, COMPUT VIS SCI, V19, P65, DOI 10.1007/s00791-018-00303-9
   Ament M, 2010, IEEE T VIS COMPUT GR, V16, P1505, DOI 10.1109/TVCG.2010.145
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   BERGER MJ, 1989, J COMPUT PHYS, V82, P64, DOI 10.1016/0021-9991(89)90035-1
   Bertram M, 2004, IEEE T VIS COMPUT GR, V10, P326, DOI 10.1109/TVCG.2004.1272731
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Cabot WH, 2006, NAT PHYS, V2, P562, DOI 10.1038/nphys361
   Chen J., 2013, Synergistic challenges in data-intensive science and exascale computing
   Childs H., 2012, HIGH PERFORMANCE VIS, P395
   CHRYSAFIS C, 2000, ACOUST SPEECH SIG PR, V4, P2035
   Cignoni P, 2000, COMPUT GRAPH-UK, V24, P399, DOI 10.1016/S0097-8493(00)00036-4
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Cohen RH, 2002, PHYS FLUIDS, V14, P3692, DOI 10.1063/1.1504452
   Dubey A, 2014, J PARALLEL DISTR COM, V74, P3217, DOI 10.1016/j.jpdc.2014.07.001
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Eisemann E., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   Frisken S.F., 2002, Journal of Graphics Tools, V7, P1, DOI [10.1080/10867651.2002.10487560, DOI 10.1080/10867651.2002.10487560]
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Gross MH, 1996, IEEE T VIS COMPUT GR, V2, P130, DOI 10.1109/2945.506225
   Guo F, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.155005
   Hatcher P., 2010, P C HIGH PERF GRAPH, P57, DOI DOI 10.2312/EGGH/HPG10/057-066
   Hoang D, 2021, IEEE T VIS COMPUT GR, V27, P603, DOI 10.1109/TVCG.2020.3030381
   Iverson J, 2012, LECT NOTES COMPUT SC, V7484, P843, DOI 10.1007/978-3-642-32820-6_83
   JACKINS CL, 1980, COMPUT VISION GRAPH, V14, P249, DOI 10.1016/0146-664X(80)90055-6
   Laney D, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503283
   Li SM, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10090488
   Li SM, 2017, IEEE INT C CL COMP, P216, DOI 10.1109/CLUSTER.2017.15
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Linsen L., 2004, DAGST SEM GEOM MOD
   Ljung P., 2006, P EUR IEEE VGTC S VI, P259
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Mallat S., 1999, WAVELET TOUR SIGNAL
   Moran PJ, 2011, IEEE T VIS COMPUT GR, V17, P1862, DOI 10.1109/TVCG.2011.252
   Morrical Nate, 2019, 2019 IEEE Visualization Conference (VIS), P256, DOI 10.1109/VISUAL.2019.8933539
   Morrical N., 2020, IEEE T VIS COMP GRAP
   Museth K., 2021, ACM SIGGRAPH TALKS
   Museth K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487235
   Nielson GM, 2003, IEEE T VIS COMPUT GR, V9, P283, DOI 10.1109/TVCG.2003.1207437
   Pascucci V., 2001, P INT C HIGH PERF CO, P45
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schroeder W., 2006, The Visualization Toolkit: An Object-Oriented Approach to 3D Graphics
   Setaluri R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661269
   Shekhar R, 1996, IEEE VISUAL, P335, DOI 10.1109/VISUAL.1996.568127
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Tao DW, 2017, INT PARALL DISTRIB P, P1129, DOI 10.1109/IPDPS.2017.115
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Wang F, 2019, IEEE T VIS COMPUT GR, V25, P1142, DOI 10.1109/TVCG.2018.2864850
   Weber GH, 2001, SPRING EUROGRAP, P25
   Weiss K, 2016, IEEE T VIS COMPUT GR, V22, P985, DOI 10.1109/TVCG.2015.2467412
   Woodring J., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P31, DOI 10.1109/LDAV.2011.6092314
   Woodring J, 2011, COMPUT GRAPH FORUM, V30, P1151, DOI 10.1111/j.1467-8659.2011.01964.x
   Zenger C., 1991, RES WORKSHOP ISRAEL, P86
   Zhao K., IEEE 37 INT C DATA E, V2021, P1643
NR 59
TC 3
Z9 4
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2350
EP 2363
DI 10.1109/TVCG.2022.3165392
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100008
PM 35394910
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, ZB
   Ling, JW
   Feng, CZ
   Lu, M
   Xu, F
AF Wang, Zhibo
   Ling, Jingwang
   Feng, Chengzeng
   Lu, Ming
   Xu, Feng
TI Emotion-Preserving Blendshape Update With Real-Time Face Tracking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Facial animation; real-time tracking; blendshape animation
ID MODEL
AB Blendshape representations are widely used in facial animation. Consistent semantics must be maintained for all the blendshapes to build the blendshapes of one character. However, this is difficult for real characters because the face shape of the same semantics varies significantly across identities. Previous studies have handled this issue by asking users to perform a set of predefined expressions with specified semantics. We observe that facial emotions can be used to define semantics. Herein, we propose a real-time technique that directly updates blendshapes without predefined expressions. Its aim is to preserve semantics based on the emotion information extracted from an arbitrary facial motion sequence. In addition, we have designed corresponding algorithms to efficiently update blendshapes with large- and middle-scale face shapes and fine-scale facial details, such as wrinkles, in a real-time face tracking system. The experimental results indicate that using a commodity RGBD sensor, we can achieve real-time online blendshape updates with well-preserved semantics and user-specific facial features and details.
C1 [Wang, Zhibo; Ling, Jingwang; Feng, Chengzeng; Lu, Ming; Xu, Feng] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
   [Wang, Zhibo; Ling, Jingwang; Feng, Chengzeng; Lu, Ming; Xu, Feng] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Xu, F (corresponding author), Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.; Xu, F (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM wzb17@mails.tsinghua.edu.cn; lingjw16@mails.tsinghua.edu.cn;
   fcz18@mails.tsinghua.edu.cn; lu-m13@mails.tsinghua.edu.cn;
   feng-xu@tsinghua.edu.cn
RI Wang, Zhibo/GSD-3371-2022
OI Feng, Chengzeng/0009-0002-3760-701X
FU National Key R&D Program of China [2018YFA0704000]; NSFC [61822111,
   61727808, 61671268]; Beijing Natural Science Foundation [JQ19015,
   L182052]
FX This work was supported by the National Key R&D Program of China under
   Grant 2018YFA0704000, the NSFC under Grant Nos. 61822111, 61727808,
   61671268 and Beijing Natural Science Foundation under Grants JQ19015,
   L182052.
CR [Anonymous], 2009, 2009 6 IEEE INT C AD, DOI DOI 10.1109/AVSS.2009.58
   Arriaga O., 2019, EUR S ART NEUR NETW
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970
   Blanz V., 1999, Proceedings of the 26th annual conference on computer graphics and interactive techniques, P187, DOI DOI 10.1145/311535.311556
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Braden D.R., 2010, 3 ELECT SYSTEM INTEG, P1
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Furukawa Y, 2009, PROC CVPR IEEE, P1674, DOI 10.1109/CVPRW.2009.5206868
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Garrido P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508380
   Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407
   Li Y, 2018, PROCEEDINGS CVMP 2018: THE 15TH ACM SIGGRAPH EUROPEAN CONFERENCE ON VISUAL MEDIA PRODUCTION, DOI 10.1145/3278471.3278473
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma Luming, 2019, P ACM SIGGRAPH S INT, P1
   Ma W, 2007, PROGRESS OF INFORMATION TECHNOLOGY IN AGRICULTURE, P61
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   OFER MZ, 2018, COMPUT GRAPH FORUM, V37, P523
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Tewari A, 2019, PROC CVPR IEEE, P10804, DOI 10.1109/CVPR.2019.01107
   Tewari A, 2020, IEEE T PATTERN ANAL, V42, P357, DOI 10.1109/TPAMI.2018.2876842
   Tewari A, 2018, PROC CVPR IEEE, P2549, DOI 10.1109/CVPR.2018.00270
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Tianye Li, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3130800.3130813
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925882
   Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232
   Xu Y, 2012, COMPUT GRAPH-UK, V36, P232, DOI 10.1016/j.cag.2012.02.005
NR 42
TC 2
Z9 2
U1 2
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2364
EP 2375
DI 10.1109/TVCG.2020.3033838
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100009
PM 33104513
DA 2024-11-06
ER

PT J
AU Nickel, S
   Sondag, M
   Meulemans, W
   Kobourov, S
   Peltonen, J
   Nöllenburg, M
AF Nickel, Soeren
   Sondag, Max
   Meulemans, Wouter
   Kobourov, Stephen
   Peltonen, Jaakko
   Noellenburg, Martin
TI Multicriteria Optimization for Dynamic Demers cartograms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time-varying data; cartograms; mental map preservation
ID TIME
AB Cartograms are popular for visualizing numerical data for administrative regions in thematic maps. When there are multiple data values per region (over time or from different datasets) shown as animated or juxtaposed cartograms, preserving the viewer's mental map in terms of stability between multiple cartograms is another important criterion alongside traditional cartogram criteria such as maintaining adjacencies. We present a method to compute stable stable Demers cartograms, where each region is shown as a square scaled proportionally to the given numerical data and similar data yield similar cartograms. We enforce orthogonal separation constraints using linear programming, and measure quality in terms of keeping adjacent regions close (cartogram quality) and using similar positions for a region between the different data values (stability). Our method guarantees the ability to connect most lost adjacencies with minimal-length planar orthogonal polylines. Experiments show that our method yields good quality and stability on multiple quality criteria.
C1 [Nickel, Soeren] TU Wien, A-1040 Vienna, Austria.
   [Noellenburg, Martin] TU Wien, Algorithms & Complex Grp, A-1040 Vienna, Austria.
   [Sondag, Max] Swansea Univ, Swansea SA2 8PP, W Glam, Wales.
   [Meulemans, Wouter] TU Eindhoven, Algorithms Geometry & Applicat Cluster, NL-5612 AZ Eindhoven, Netherlands.
   [Kobourov, Stephen] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
   [Peltonen, Jaakko] Tampere Univ, Fac Informat Technol & Commun Sci, Stat & Data Anal, Tampere 33100, Finland.
C3 Technische Universitat Wien; Technische Universitat Wien; Swansea
   University; Eindhoven University of Technology; University of Arizona;
   Tampere University
RP Nickel, S (corresponding author), TU Wien, A-1040 Vienna, Austria.
EM soeren.nickel@tuwien.ac.at; m.f.m.sondag@swansea.ac.uk;
   w.meulemans@tue.nl; kobourov@cs.arizona.edu; jaakko.peltonen@tuni.fi;
   noellenburg@ac.tuwien.ac.at
RI Peltonen, Jaakko/ABD-1698-2020; sondag, max/KIJ-0026-2024; Kobourov,
   Stephen/A-3016-2008
OI Peltonen, Jaakko/0000-0003-3485-8585; Terziadis,
   Soeren/0000-0001-5161-3841; Kobourov, Stephen/0000-0002-0477-2724;
   Nollenburg, Martin/0000-0003-0454-3937; sondag, max/0000-0003-3309-638X;
   Meulemans, Wouter/0000-0002-4978-3400
CR Alam MJ, 2015, COMPUT GRAPH FORUM, V34, P351, DOI 10.1111/cgf.12647
   Alam MJ, 2013, DISCRETE COMPUT GEOM, V50, P784, DOI 10.1007/s00454-013-9521-1
   Bortins I., 2002, CARTOGRAMTYPES
   Bowen C, 2015, LECT NOTES COMPUT SC, V9411, P447, DOI 10.1007/978-3-319-27261-0_37
   Breu H, 1998, COMP GEOM-THEOR APPL, V9, P3, DOI 10.1016/S0925-7721(97)00014-X
   Buchin Kevin, 2012, Geographic Information Science. Proceedings of the 7th International Conference (GIScience 2012), P29, DOI 10.1007/978-3-642-33024-7_3
   Buchin K., 2014, P 30 EUR WORKSH COMP
   Buchin K., 2011, Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems - GIS'11, P142
   Cano RG, 2015, COMPUT GRAPH FORUM, V34, P361, DOI 10.1111/cgf.12648
   Di Giacomo E., 2015, Information, Intelligence, Systems and Applications (IISA), 2015 6th International Conference on, P1
   DORLING D, 1992, CARTOGR GEOGR INFORM, V19, P215, DOI 10.1559/152304092783721259
   Dorling D., 1996, CONCEPTS TECHNIQUES
   Duncan IK, 2021, IEEE T VIS COMPUT GR, V27, P2136, DOI 10.1109/TVCG.2020.3041745
   Eppstein David, 2015, International Journal of Computational Geometry & Applications, V25, P101, DOI 10.1142/S0218195915500077
   Eppstein D, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P267, DOI 10.1145/1542362.1542411
   Gastner MT, 2018, P NATL ACAD SCI USA, V115, pE2156, DOI 10.1073/pnas.1712674115
   Gastner MT, 2004, P NATL ACAD SCI USA, V101, P7499, DOI 10.1073/pnas.0400280101
   Hlineny P, 2001, DISCRETE MATH, V235, P95, DOI 10.1016/S0012-365X(00)00263-6
   Hoog van der IH, 2019, LECT NOTES COMPUT SC, V11355, P43, DOI 10.1007/978-3-030-10564-8_4
   House DH, 1998, VISUALIZATION '98, PROCEEDINGS, P197, DOI 10.1109/VISUAL.1998.745303
   Inoue R, 2011, P 25 INT CART C, P3
   Inoue R, 2011, CARTOGR GEOGR INF SC, V38, P147, DOI 10.1559/15230406382147
   Johnson T., 2015, P EUR C VIS, P43, DOI 10.2312/eurovisshort.20151123
   Keim DA, 2004, IEEE T VIS COMPUT GR, V10, P95, DOI 10.1109/TVCG.2004.1260761
   Klemz B, 2015, LECT NOTES COMPUT SC, V9411, P433, DOI 10.1007/978-3-319-27261-0_36
   Meulemans W, 2019, COMPUT GRAPH FORUM, V38, P713, DOI 10.1111/cgf.13722
   Meulemans W, 2021, IEEE T VIS COMPUT GR, V27, P1236, DOI 10.1109/TVCG.2020.3028953
   Meulemans W, 2018, LECT NOTES COMPUT SC, V10807, P805, DOI 10.1007/978-3-319-77404-6_58
   Meulemans W, 2017, IEEE T VIS COMPUT GR, V23, P381, DOI 10.1109/TVCG.2016.2598542
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Munzner T., 2014, AK Peters Visualization Series
   Nusrat S, 2016, COMPUT GRAPH FORUM, V35, P619, DOI 10.1111/cgf.12932
   Raisz E, 1934, GEOGR REV, V24, P292, DOI 10.2307/208794
   Shneiderman B, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P73, DOI 10.1109/INFVIS.2001.963283
   Sondag M, 2018, IEEE T VIS COMPUT GR, V24, P729, DOI 10.1109/TVCG.2017.2745140
   Sun SP, 2020, CARTOGR GEOGR INF SC, V47, P381, DOI 10.1080/15230406.2020.1745092
   Tarjan R., 1971, Conference record 1971 12th annual symposium on switching and automata theory, P114, DOI 10.1137/0201010
   Tobler W R, 1973, Ann N Y Acad Sci, V219, P215, DOI 10.1111/j.1749-6632.1973.tb41401.x
   van Kreveld M, 2007, COMP GEOM-THEOR APPL, V37, P175, DOI 10.1016/j.comgeo.2006.06.002
   Vernier E, 2020, COMPUT GRAPH FORUM, V39, P393, DOI 10.1111/cgf.13989
   Wulms J, 2021, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis52677.2021.00016
NR 41
TC 3
Z9 3
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2376
EP 2387
DI 10.1109/TVCG.2022.3151227
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100010
PM 35157586
OA Green Published, hybrid
DA 2024-11-06
ER

PT J
AU Ahmed, R
   De Luca, F
   Devkota, S
   Kobourov, S
   Li, MW
AF Ahmed, Reyan
   De Luca, Felice
   Devkota, Sabin
   Kobourov, Stephen
   Li, Mingwei
TI Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent,
   (<i>SGD</i>)<SUP>2</SUP>
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graph drawing; gradient descent; quality metrics
ID STRESS MAJORIZATION; ALGORITHM
AB Readability criteria, such as distance or neighborhood preservation, are often used to optimize node-link representations of graphs to enable the comprehension of the underlying data. With few exceptions, graph drawing algorithms typically optimize one such criterion, usually at the expense of others. We propose a layout approach, Multicriteria Scalable Graph Drawing via Stochastic Gradient Descent, (SGD)(2), that can handle multiple readability criteria. (SGD)(2) can optimize any criterion that can be described by a differentiable function. Our approach is flexible and can be used to optimize several criteria that have already been considered earlier (e.g., obtaining ideal edge lengths, stress, neighborhood preservation) as well as other criteria which have not yet been explicitly optimized in such fashion (e.g., node resolution, angular resolution, aspect ratio). The approach is scalable and can handle large graphs. A variation of the underlying approach can also be used to optimize many desirable properties in planar graphs, while maintaining planarity. Finally, we provide quantitative and qualitative evidence of the effectiveness of (SGD)(2): we analyze the interactions between criteria, measure the quality of layouts generated from (SGD)(2) as well as the runtime behavior, and analyze the impact of sample sizes. The source code is available on github and we also provide an interactive demo for small graphs.
C1 [Ahmed, Reyan; De Luca, Felice; Devkota, Sabin; Kobourov, Stephen; Li, Mingwei] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Ahmed, R (corresponding author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
EM abureyanahmed@email.arizona.edu; felicedeluca@me.com;
   devkotasabin@email.arizona.edu; kobourov@cs.arizona.edu;
   mwli@email.arizona.edu
RI Kobourov, Stephen/A-3016-2008
CR Abrego B. M. ~, 2013, P 30 ESS GEOM GRAPH, P518
   Ahmed Reyan, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P3, DOI 10.1007/978-3-030-68766-3_1
   Bassily R., 2018, ARXIV 181102564
   Bekos MA, 2018, LECT NOTES COMPUT SC, V11282, P271, DOI 10.1007/978-3-030-04414-5_19
   BENTLEY JL, 1979, IEEE T COMPUT, V28, P643, DOI 10.1109/TC.1979.1675432
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Blank J, 2020, IEEE ACCESS, V8, P89497, DOI 10.1109/ACCESS.2020.2990567
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Buchheim C., 2013, HDB GRAPH DRAWING VI, P43, DOI DOI 10.1201/B15385-5
   Chollet F., 2015, KERAS
   Davidson R, 1996, ACM T GRAPHIC, V15, P301, DOI 10.1145/234535.234538
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Demel A, 2018, LECT NOTES COMPUT SC, V11282, P286, DOI 10.1007/978-3-030-04414-5_20
   Devanny W., 2017, P 25 INT S GRAPH DRA, P575
   Devkota S, 2019, LECT NOTES COMPUT SC, V11904, P291, DOI 10.1007/978-3-030-35802-0_23
   Duncan CA, 1998, LECT NOTES COMPUT SC, V1547, P111
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   Dwyer T, 2009, DISCRETE MATH, V309, P1895, DOI 10.1016/j.disc.2007.12.103
   Dwyer Tim., 2009, INT S GRAPH DRAWING, DOI [10.1007/978-3-642-11805-0_37, DOI 10.1007/978-3-642-11805-0_37]
   Eades P., 2010, ARXIV10124559
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Fowler J. J., 2012, P INT S GRAPH DRAW, P388
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gower RM, 2019, PR MACH LEARN RES, V97
   Griewank A, 2008, OTHER TITL APPL MATH, V105, P1, DOI 10.1137/1.9780898717761
   Hagberg A., 2008, P 7 PYTH SCI C
   Hinton G., 2012, COURSERA: Neural networks for machine learning, V4, P26
   Huang WD, 2013, J VISUAL LANG COMPUT, V24, P262, DOI 10.1016/j.jvlc.2011.12.002
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Ioffe Sergey, 2015, P MACHINE LEARNING R, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Keskar N.S., 2016, ARXIV
   Kingma DP, 2014, ADV NEUR IN, V27
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li H., 2017, ARXIV 171209913
   Orosz T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196653
   Paszke A, 2019, ADV NEUR IN, V32
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Radermacher M., 2018, 2018 P 20 WORKSH ALG, P129
   Schulz Andre, 2011, Journal of Graph Algorithms and Applications, V15, P33, DOI 10.7155/jgaa.00216
   Shabbeer A., 2010, PROC NIPS WORKSHOP C, P1
   Smilkov Daniel, 2019, Proceedings of Machine Learning and Systems, V1, P309, DOI 10.48550/arXiv.1901.05350
   Tiezzi M., 2021, ARXIV210910061
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P566, DOI 10.1109/TVCG.2018.2864911
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Zeiler M. D., 2012, ARXIV, DOI DOI 10.1145/1830483.1830503
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 50
TC 6
Z9 8
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2388
EP 2399
DI 10.1109/TVCG.2022.3155564
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100011
PM 35230951
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Huang, JW
   Sugawara, R
   Chu, K
   Komura, T
   Kitamura, Y
AF Huang, Jiawei
   Sugawara, Ryo
   Chu, Kinfung
   Komura, Taku
   Kitamura, Yoshifumi
TI Reconstruction of Dexterous 3D Motion Data From a Flexible Magnetic
   Sensor With Deep Learning and Structure-Aware Filtering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D user interface; 3D interaction; motion capture; input devices;
   filtering; deep learning
ID KALMAN FILTER; BEHAVIOR
AB We propose IM3D+, a novel approach to reconstructing 3D motion data from a flexible magnetic flux sensor array using deep learning and a structure-aware temporal bilateral filter. Computing the 3D configuration of markers (inductor-capacitor (LC) coils) from flux sensor data is difficult because the existing numerical approaches suffer from system noise, dead angles, the need for initialization, and limitations in the sensor array's layout. We solve these issues with deep neural networks to learn the regression from the simulation flux values to the LC coils' 3D configuration, which can be applied to the actual LC coils at any location and orientation within the capture volume. To cope with the influence of system noise and the dead-angle limitation caused by the characteristics of the hardware and sensing principle, we propose a structure-aware temporal bilateral filter for reconstructing motion sequences. Our method can track various movements, including fingers that manipulate objects, beetles that move inside a vivarium with leaves and soil, and the flow of opaque fluid. Since no power supply is needed for the lightweight wireless markers, our method can robustly track movements for a very long time, making it suitable for various types of observations whose tracking is difficult with existing motion-tracking systems. Furthermore, the flexibility of the flux sensor layout allows users to reconfigure it based on their own applications, thus making our approach suitable for a variety of virtual reality applications.
C1 [Huang, Jiawei; Sugawara, Ryo; Chu, Kinfung; Kitamura, Yoshifumi] Tohoku Univ, Res Inst Elect Commun, Sendai, Miyagi 9808577, Japan.
   [Komura, Taku] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Tohoku University; University of Hong Kong
RP Huang, JW (corresponding author), Tohoku Univ, Res Inst Elect Commun, Sendai, Miyagi 9808577, Japan.
EM swfly@riec.tohoku.ac.jp; rsugawara@riec.tohoku.ac.jp;
   kennychu@riec.tohoku.ac.jp; tkomura@ed.ac.uk; kitamura@riec.tohoku.ac.jp
OI Huang, Jiawei/0000-0001-7670-2971; Kitamura,
   Yoshifumi/0000-0002-7047-627X; Chu, Kinfung/0000-0003-0816-3130
FU JSPS KAKENHI [18H04103, 17J04295]; Grants-in-Aid for Scientific Research
   [17J04295, 18H04103] Funding Source: KAKEN
FX This work was supported in part by the JSPS KAKENHI 18H04103 and
   Grant-in-Aid for JSPS Fellows 17J04295.
CR 5DT, US
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Antonello R, 2016, IEEE T IND ELECTRON, V63, P1953, DOI 10.1109/TIE.2015.2512224
   ascopost, About Us
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen KY, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1504, DOI 10.1145/2858036.2858125
   Chollet F., 2015, KERAS
   Crall JD, 2018, SCIENCE, V362, P683, DOI 10.1126/science.aat1598
   Dammertz H., 2010, P C HIGH PERF GRAPH, P67, DOI DOI 10.2312/EGGH/HPG10/067-075
   Foxlin E., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P159
   Han SC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201399
   Hashi S, 2009, IEEE T MAGN, V45, P2736, DOI 10.1109/TMAG.2009.2020541
   Holden D, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201302
   Holden Daniel, 2015, SIGGRAPH Asia 2015 Technical Briefs
   Huang J., 2014, ACM SIGGRAPH EM TECH, P12
   Huang JW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818135
   Iyer V., 2019, LIVING IOT FLYING WI, P15, DOI [10.1145/3300061.3300136, DOI 10.1145/3300061.3300136]
   Jörg S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366208
   Kingma DP, 2014, ADV NEUR IN, V27
   Kitamura Y, 2001, COMP GRAPH, P231, DOI 10.1145/383259.383285
   Liang RH, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4233, DOI 10.1145/2858036.2858527
   Liang Rong-Hao., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1391
   Ligorio G, 2015, IEEE T BIO-MED ENG, V62, P2033, DOI 10.1109/TBME.2015.2411431
   LJUNG L, 1979, IEEE T AUTOMAT CONTR, V24, P36, DOI 10.1109/TAC.1979.1101943
   McIntosh J, 2017, P 2017 CHI C HUM FAC, P1885, DOI DOI 10.1145/3027063.3053152
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   NaturalPoint, US
   Noitom, ABOUT US
   Polhemus, About us
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Sandilands P, 2013, COMPUT ANIMAT VIRT W, V24, P527, DOI 10.1002/cav.1537
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Shin HJ, 2001, ACM T GRAPHIC, V20, P67, DOI 10.1145/502122.502123
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Sutherland I. E., 1968, P DEC 9 11 1968 FA 1, P757, DOI [https://doi.org/10.1145/1476589.1476686, DOI 10.1145/1476589.1476686]
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   vice, US
   Wan CD, 2017, PROC CVPR IEEE, P1196, DOI 10.1109/CVPR.2017.132
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Xsens, About us
   Ye YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185537
   Yoshida S, 2016, OPT EXPRESS, V24, P13194, DOI 10.1364/OE.24.013194
   Zhao WP, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508412
   Zhu KN, 2014, IEICE T INF SYST, VE97D, P2597, DOI 10.1587/transinf.2013THP0001
NR 46
TC 4
Z9 4
U1 2
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2400
EP 2414
DI 10.1109/TVCG.2020.3031632
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100012
PM 33079669
OA hybrid
DA 2024-11-06
ER

PT J
AU Du, D
   Han, XG
   Fu, HB
   Wu, FY
   Yu, YZ
   Cui, SG
   Liu, LG
AF Du, Dong
   Han, Xiaoguang
   Fu, Hongbo
   Wu, Feiyang
   Yu, Yizhou
   Cui, Shuguang
   Liu, Ligang
TI <i>SAniHead</i>: Sketching Animal-Like 3D Character Heads Using a
   View-Surface Collaborative Mesh Generative Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sketch-based 3D modeling; graph convolutional neural network;
   animal-like character heads
AB In the game and film industries, modeling 3D heads plays a very important role in designing characters. Although human head modeling has been researched for a long time, few works have focused on animal-like heads, which are of more diverse shapes and richer geometric details. In this article, we present SAniHead, an interactive system for creating animal-like heads with a mesh representation from dual-view sketches. Our core technical contribution is a view-surface collaborative mesh generative network. Initially, a graph convolutional neural network (GCNN) is trained to learn the deformation of a template mesh to fit the shape of sketches, giving rise to a coarse model. It is then projected into vertex maps where image-to-image translation networks are performed for detail inference. After back-projecting the inferred details onto the meshed surface, a new GCNN is trained for further detail refinement. The modules of view-based detail inference and surface-based detail refinement are conducted in an alternating cascaded fashion, collaboratively improving the model. A refinement sketching interface is also implemented to support direct mesh manipulation. Experimental results show the superiority of our approach and the usability of our interactive system. Our work also contributes a 3D animal head dataset with corresponding line drawings.
C1 [Du, Dong] Univ Sci & Technol China, Hefei 230052, Anhui, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
   [Han, Xiaoguang; Wu, Feiyang; Cui, Shuguang] Chinese Univ Hong Kong, Shenzhen, Peoples R China.
   [Han, Xiaoguang; Wu, Feiyang; Cui, Shuguang] Shenzhen Res Inst Big Data, Shenzhen 518172, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   [Yu, Yizhou] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS; The Chinese University of Hong Kong, Shenzhen;
   Shenzhen Research Institute of Big Data; City University of Hong Kong;
   University of Hong Kong
RP Han, XG (corresponding author), Chinese Univ Hong Kong, Shenzhen, Peoples R China.
EM dongdu@mail.ustc.edu.cn; hanxiaoguang@cuhk.edu.cn; fuplus@gmail.com;
   feiyangwu@link.cuhk.edu.cn; yizhouy@acm.org; shuguangcui@cuhk.edu.cn;
   lgliu@ustc.edu.cn
RI Cui, Shuguang/D-4677-2014; Liu, Ligang/IZQ-5817-2023; Du,
   Dong/AEG-5685-2022
OI Du, Dong/0000-0001-5481-389X; Wu, Feiyang/0000-0003-3494-4205
FU National Key R&D Program of China [2018YFB1800800]; Key Area R&D Program
   of Guangdong Province [2018B030338001]; Shenzhen Outstanding Talents
   Training Fund; Guangdong Research Project [2017ZT07X152]; Research
   Grants Council of the Hong Kong Special Administrative Region, China
   [CityU 11212119]; City University of Hong Kong [7005176]; Hong Kong
   Research Grants Council under General Research Funds [HKU17206218];
   National Natural Science Foundation of China [61902334, 61629101,
   61672482]; Zhejiang Lab [2019NB0AB03]
FX The authors would like to thank the reviewers for their constructive
   comments, and the participants of our user study for their precious
   time. The work was supported in part by the National Key R&D Program of
   China under Grant No. 2018YFB1800800, by the Key Area R&D Program of
   Guangdong Province under Grant No. 2018B030338001, by Shenzhen
   Outstanding Talents Training Fund, by Guangdong Research Project No.
   2017ZT07X152, by Zhejiang Lab (No. 2019NB0AB03), by the Research Grants
   Council of the Hong Kong Special Administrative Region, China (Project
   No. CityU 11212119), by the City University of Hong Kong (Project No.
   7005176), by Hong Kong Research Grants Council under General Research
   Funds Grant HKU17206218, and by the National Natural Science Foundation
   of China under Grant 61902334, 61629101, 61672482.
CR [Anonymous], 2013, ACM Transactions on Graphics (TOG)
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Cordier F, 2011, IEEE T VIS COMPUT GR, V17, P1650, DOI 10.1109/TVCG.2010.258
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fan LB, 2013, COMPUT GRAPH FORUM, V32, P157, DOI 10.1111/cgf.12223
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guo XK, 2016, COMPUT GRAPH FORUM, V35, P89, DOI 10.1111/cgf.12966
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karpenko OA, 2006, ACM T GRAPHIC, V25, P589, DOI 10.1145/1141911.1141928
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kobayashi K.G., 2003, Proceedings of the eighth ACM symposium on Solid modeling and applications. SM '03, P226
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C., 2018, PROC SIGGRAPH ASIA 2
   Li CJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073632
   Li L, 2019, IEEE COMPUT GRAPH, V39, P38, DOI 10.1109/MCG.2018.2884192
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Nealen A, 2005, ACM T GRAPHIC, V24, P1142, DOI 10.1145/1073204.1073324
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276429, 10.1145/1239451.1239492]
   Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Pan H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766990
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Peng MQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201297
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Schmidt Ryan., 2006, ACM SIGGRAPH 2006 CO, P14, DOI [10.1145/1185657.1185775, DOI 10.1145/1185657.1185775]
   Shao C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185541
   Singh K., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P405, DOI 10.1145/280814.280946
   Smirnov D, 2020, PROC CVPR IEEE, P558, DOI 10.1109/CVPR42600.2020.00064
   Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269
   Sorkine O., 2004, P S GEOM PROC, P175, DOI [DOI 10.1145/1057432.1057456, 10.]
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang LJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1820, DOI 10.1145/3240508.3240699
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang PS, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275050
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie XH, 2013, COMPUT GRAPH FORUM, V32, P233, DOI 10.1111/cgf.12200
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Yang Y, 2019, IEEE T VIS COMPUT GR, V25, P2999, DOI 10.1109/TVCG.2018.2861396
   Zhang XM, 2018, ADV NEUR IN, V31
NR 61
TC 7
Z9 8
U1 1
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2415
EP 2429
DI 10.1109/TVCG.2020.3030330
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100013
PM 33048679
DA 2024-11-06
ER

PT J
AU Lin, C
   Liu, LJ
   Li, CJ
   Kobbelt, L
   Wang, B
   Xin, SQ
   Wang, WP
AF Lin, Cheng
   Liu, Lingjie
   Li, Changjian
   Kobbelt, Leif
   Wang, Bin
   Xin, Shiqing
   Wang, Wenping
TI SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape analysis; shape segmentation; medial axis transform; geometry
ID POLYHEDRAL SURFACE DECOMPOSITION; MESH SEGMENTATION; CO-SEGMENTATION
AB Segmenting arbitrary 3D objects into constituent parts that are structurally meaningful is a fundamental problem encountered in a wide range of computer graphics applications. Existing methods for 3D shape segmentation suffer from complex geometry processing and heavy computation caused by using low-level features and fragmented segmentation results due to the lack of global consideration. We present an efficient method, called SEG-MAT, based on the medial axis transform (MAT) of the input shape. Specifically, with the rich geometrical and structural information encoded in the MAT, we are able to develop a simple and principled approach to effectively identify the various types of junctions between different parts of a 3D shape. Extensive evaluations and comparisons show that our method outperforms the state-of-the-art methods in terms of segmentation quality and is also one order of magnitude faster.
C1 [Lin, Cheng; Liu, Lingjie; Li, Changjian; Wang, Wenping] Univ Hong Kong, Hong Kong, Peoples R China.
   [Kobbelt, Leif] Rhein Westfal TH Aachen, Comp Sci, D-52062 Aachen, Germany.
   [Wang, Bin] Tsinghua Univ, Beijing 100084, Peoples R China.
   [Wang, Bin] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.
   [Xin, Shiqing] Shandong Univ, Sch Comp Sci, Qingdao 266237, Peoples R China.
C3 University of Hong Kong; RWTH Aachen University; Tsinghua University;
   Shandong University
RP Lin, C (corresponding author), Univ Hong Kong, Hong Kong, Peoples R China.
EM chlin@hku.hk; liulingjie0206@gmail.com; chjili2011@gmail.com;
   kobbelt@cs.rwth-aachen.de; wangbins@tsinghua.edu.cn;
   xinshiqing@gmail.com; wenping@cs.hku.hk
OI Wang, Bin/0000-0002-5176-9202
FU Gottfried Wilhelm Leibniz program by DFG; National Natural Science
   Foundation of China (NSFC) [61772301, 61772016]
FX The authors would like to thank the anonymous reviewers for their
   valuable feedback and Yiling Pan for her help with data processing. This
   work is supported by the Gottfried Wilhelm Leibniz program by DFG and
   the National Natural Science Foundation of China (NSFC) under Grants No.
   61772301 and No. 61772016.
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Agathos A, 2007, Comput-Aided Des Appl, V4, P827, DOI DOI 10.1080/16864360.2007.10738515
   Asafi S, 2013, COMPUT GRAPH FORUM, V32, P23, DOI 10.1111/cgf.12169
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Au OKC, 2012, IEEE T VIS COMPUT GR, V18, P1125, DOI 10.1109/TVCG.2011.131
   Blum H., 1967, Models for Perception of Speech and Visual Form
   Brunner D, 2004, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND IMAGING, P48
   Chang A.X., 2015, Technical Report
   Chazelle B, 1997, COMP GEOM-THEOR APPL, V7, P327, DOI 10.1016/S0925-7721(96)00024-7
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Chen ZQ, 2019, IEEE I CONF COMP VIS, P8489, DOI 10.1109/ICCV.2019.00858
   Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z
   Dey T.K., 2006, S GEOMETRY PROCESSIN, V6, P143
   Feng C, 2015, LECT NOTES COMPUT SC, V9082, P607, DOI 10.1007/978-3-319-18720-4_51
   Ferreira A, 2010, INT J COMPUT VISION, V89, P327, DOI 10.1007/s11263-009-0257-6
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Golovinskiy A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409098
   Guo K, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2835487
   HARPELED S, 2001, P 17 ANN S COMP GEOM, P177
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Hu RZ, 2012, COMPUT GRAPH FORUM, V31, P1703, DOI 10.1111/j.1467-8659.2012.03175.x
   Huang J., 2018, ARXIV 180201698
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Kalvin AD, 1996, IEEE COMPUT GRAPH, V16, P64, DOI 10.1109/38.491187
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Lai YK, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P183
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2753755
   Lin C., 2020, ARXIV 200312397
   Liu R, 2009, COMPUT GRAPH FORUM, V28, P397, DOI 10.1111/j.1467-8659.2009.01379.x
   Lu L, 2007, COMPUT GRAPH FORUM, V26, P329, DOI 10.1111/j.1467-8659.2007.01055.x
   Maglo A., 2011, P COMP GRAPH INT, P1
   Page DL, 2003, PROC CVPR IEEE, P27
   Reniers D, 2008, COMPUT GRAPH FORUM, V27, P1845, DOI 10.1111/j.1467-8659.2008.01331.x
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581
   Shu ZY, 2016, COMPUT AIDED GEOM D, V43, P39, DOI 10.1016/j.cagd.2016.02.015
   Sun CY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356529
   Sun Y, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P825, DOI 10.1109/ICIP.2002.1039099
   Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38
   Todorovic D., 2008, SCHOLARPEDIA, V3, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160
   van Kaick O, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2611811
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Wu ZZ, 2013, COMPUT GRAPH-UK, V37, P628, DOI 10.1016/j.cag.2013.05.015
   Xu H., 2017, P IEEE INT C COMP VI, P2698
   Yan YJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201396
   Yan YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925938
   Zhou Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818074
   Zhu CY, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275008
   Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0
NR 54
TC 18
Z9 19
U1 1
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2430
EP 2444
DI 10.1109/TVCG.2020.3032566
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100014
PM 33079671
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Han, J
   Wang, CL
AF Han, Jun
   Wang, Chaoli
TI SSR-TVD: Spatial Super-Resolution for Time-Varying Data Analysis and
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time-varying data visualization; deep learning; super-resolution;
   generative adversarial network
AB We present SSR-TVD, a novel deep learning framework that produces coherent spatial super-resolution (SSR) of time-varying data (TVD) using adversarial learning. In scientific visualization, SSR-TVD is the first work that applies the generative adversarial network (GAN) to generate high-resolution volumes for three-dimensional time-varying data sets. The design of SSR-TVD includes a generator and two discriminators (spatial and temporal discriminators). The generator takes a low-resolution volume as input and outputs a synthesized high-resolution volume. To capture spatial and temporal coherence in the volume sequence, the two discriminators take the synthesized high-resolution volume(s) as input and produce a score indicating the realness of the volume(s). Our method can work in the in situ visualization setting by downscaling volumetric data from selected time steps as the simulation runs and upscaling downsampled volumes to their original resolution during postprocessing. To demonstrate the effectiveness of SSR-TVD, we show quantitative and qualitative results with several time-varying data sets of different characteristics and compare our method against volume upscaling using bicubic interpolation and a solution solely based on CNN.
C1 [Han, Jun; Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Han, J (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM jhan5@nd.edu; chaoli.wang@nd.edu
RI Wang, Chaoli/AAJ-5173-2020
OI Han, Jun/0000-0002-7286-062X
FU U.S. National Science Foundation [IIS-1455886, CNS-1629914, DUE-1833129,
   IIS-1955395]; NVIDIA GPU Grant Program
FX This work was supported in part by the U.S. National Science Foundation
   under Grants IIS-1455886, CNS-1629914, DUE-1833129, and IIS-1955395, and
   the NVIDIA GPU Grant Program. The authors would like to thank the
   anonymous reviewers for their insightful comments.
CR Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2019, IEEE COMPUT GRAPH, V39, P54, DOI 10.1109/MCG.2018.2881523
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hensel M, 2017, ADV NEUR IN, V30
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Hong F, 2018, IEEE PAC VIS SYMP, P76, DOI 10.1109/PacificVis.2018.00018
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma DP, 2014, ADV NEUR IN, V27
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Liang X, 2018, IEEE INT C CL COMP, P179, DOI 10.1109/CLUSTER.2018.00036
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mathieu M., 2015, ARXIV151105440
   Mirza M., 2014, arXiv preprint arXiv:1411.1784, DOI 10.48550/arXiv.1411.1784
   Miyato T, 2018, ARXIV180205957, DOI DOI 10.48550/ARXIV.1802.05957
   Nair V., 2010, P 27 INT C MACHINE L, P807
   P ~erez-Pellitero E., 2018, ARXIV 180707930
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/visual.2019.8933759, 10.1109/VISUAL.2019.8933759]
   Radford A., 2015, ARXIV151106434
   Reed Scott E., 2016, Advances in Neural Information Processing Systems
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Ulyanov D, 2016, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang YF, 2020, IEEE T VIS COMPUT GR, V26, P960, DOI 10.1109/TVCG.2019.2934369
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2019, ARXIV 190206068
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yoo D, 2016, LECT NOTES COMPUT SC, V9912, P517, DOI 10.1007/978-3-319-46484-8_31
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhou YP, 2016, LECT NOTES COMPUT SC, V9912, P262, DOI 10.1007/978-3-319-46484-8_16
   Zhou Z., 2017, P COMP GRAPH INT C
NR 48
TC 26
Z9 27
U1 2
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2445
EP 2456
DI 10.1109/TVCG.2020.3032123
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100015
PM 33074824
DA 2024-11-06
ER

PT J
AU Zhao, J
   Sun, MY
   Chen, F
   Chiu, P
AF Zhao, Jian
   Sun, Maoyuan
   Chen, Francine
   Chiu, Patrick
TI Understanding Missing Links in Bipartite Networks With MissBiN
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Missing link prediction; bipartite network; bi-clique; interactive
   visualization; visual analytics
ID VISUALIZATION; EXPLORATION; PREDICTION
AB The analysis of bipartite networks is critical in a variety of application domains, such as exploring entity co-occurrences in intelligence analysis and investigating gene expression in bio-informatics. One important task is missing link prediction, which infers the existence of unseen links based on currently observed ones. In this article, we propose a visual analysis system, MissBiN, to involve analysts in the loop for making sense of link prediction results. MissBiN equips a novel method for link prediction in a bipartite network by leveraging the information of bi-cliques in the network. It also provides an interactive visualization for understanding the algorithm outputs. The design of MissBiN is based on three high-level analysis questions (what, why, and how) regarding missing links, which are distilled from the literature and expert interviews. We conducted quantitative experiments to assess the performance of the proposed link prediction algorithm, and interviewed two experts from different domains to demonstrate the effectiveness of MissBiN as a whole. We also provide a comprehensive usage scenario to illustrate the usefulness of the tool in an application of intelligence analysis.
C1 [Zhao, Jian] Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Sun, Maoyuan] Northern Illinois Univ, Dept Comp Sci, De Kalb, IL 60115 USA.
   [Chen, Francine; Chiu, Patrick] FXPAL, Palo Alto, CA 94304 USA.
C3 University of Waterloo; Northern Illinois University
RP Zhao, J (corresponding author), Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM jianzhao@uwaterloo.ca; smaoyuan@niu.edu; francine@acm.org;
   patrick_chiu@acm.org
RI Sun, Maoyuan/AAJ-4301-2020
OI Sun, Maoyuan/0000-0002-0990-2620; Zhao, Jian/0000-0001-5008-4319
FU NSERC Discovery Grant; US National Science Foundation [IIS-1850036,
   IIS-2002082]
FX This work was supported in part by the NSERC Discovery Grant and US
   National Science Foundation under Grants IIS-1850036 and IIS-2002082.
   Part of the work was completed while the authors were at FXPAL.
CR Abello J, 2004, LECT NOTES COMPUT SC, V3383, P431
   Abello J., 2002, P WORK C ADV VIS INT, P290, DOI [10.1145/1556262.1556308, DOI 10.1145/1556262.1556308]
   Al Hasan M, 2011, SOCIAL NETWORK DATA ANALYTICS, P243
   [Anonymous], 2018, WASHINGTON 600 NEIGH
   Asratian A. S., 1998, BIPARTITEGRAPHS THEI
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   Borgatti S.P., 2012, COMPUT COMPLEX, P2912, DOI DOI 10.1007/978-1-4614-1800-9_179
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Burt R.S., 2018, Social Stratification, P659
   Cannistraci CV, 2013, SCI REP-UK, V3, DOI 10.1038/srep01613
   Carrubba C, 2008, LEGIS STUD QUART, V33, P543, DOI 10.3162/036298008786403079
   Chang YJ, 2012, CONF TECHNOL APPL, P50, DOI 10.1109/TAAI.2012.49
   Dumas M, 2012, IEEE NETWORK, V26, P12, DOI 10.1109/MNET.2012.6375888
   Fiaux P, 2013, COMPUTER, V46, P90, DOI 10.1109/MC.2013.269
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Goadrich M, 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Grothaus GA, 2006, ALGORITHM MOL BIOL, V1, DOI 10.1186/1748-7188-1-15
   Heckerman D., 2004, PROBABILISTIC ENTITY, P201
   Heinrich Julian, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P641
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hu YF, 2015, WIRES COMPUT STAT, V7, P115, DOI 10.1002/wics.1343
   Huang Z, 2005, ACM-IEEE J CONF DIG, P141, DOI 10.1145/1065385.1065415
   Hughes F., 2003, DISCOVERY PROOF CHOI
   Isenberg P., 2018, VISUALIZATION PUBLIC
   Kapushesky M, 2004, NUCLEIC ACIDS RES, V32, pW465, DOI 10.1093/nar/gkh470
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kluger Y, 2003, GENOME RES, V13, P703, DOI 10.1101/gr.648603
   Lex A, 2011, IEEE T VIS COMPUT GR, V17, P2291, DOI 10.1109/TVCG.2011.250
   Lex A, 2010, IEEE T VIS COMPUT GR, V16, P1027, DOI 10.1109/TVCG.2010.138
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Litchenwalter R., 2012, Proceedings of the 21st World Wide Web Conference (WWW'12), P1019, DOI [10.1145/2187836.2187973, DOI 10.1145/2187836.2187973]
   Lü LY, 2011, PHYSICA A, V390, P1150, DOI 10.1016/j.physa.2010.11.027
   Madeira SC, 2004, IEEE ACM T COMPUT BI, V1, P24, DOI 10.1109/TCBB.2004.2
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   Misue K, 2007, LECT NOTES COMPUT SC, V4551, P106
   Partl C, 2014, IEEE T VIS COMPUT GR, V20, P1883, DOI 10.1109/TVCG.2014.2346752
   Prell C., 2011, Social network analysis: History, theory and methodology
   Riche NH, 2010, COMPUT GRAPH FORUM, V29, P1193, DOI 10.1111/j.1467-8659.2009.01678.x
   Santamaría R, 2008, BIOINFORMATICS, V24, P1212, DOI 10.1093/bioinformatics/btn076
   Santamaría R, 2014, BIOINFORMATICS, V30, P1785, DOI 10.1093/bioinformatics/btu120
   Scellato Salvatore, 2011, P 17 ACM SIGKDD INT
   Schulz H.-J., 2008, Proceedings of the Eurographics Workshop on Visual Computing for Biomedicine (VCBM'08), P135, DOI DOI 10.2312/VCBM/VCBM08/135-142
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Streit M, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S6-S4
   Sun MY, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P246, DOI [10.1109/visual.2019.8933546, 10.1109/VISUAL.2019.8933546]
   Sun MY, 2019, IEEE T VIS COMPUT GR, V25, P2983, DOI 10.1109/TVCG.2018.2861397
   Sun MY, 2016, IEEE T VIS COMPUT GR, V22, P310, DOI 10.1109/TVCG.2015.2467813
   Tong HH, 2006, IEEE DATA MINING, P613
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   Uno T, 2004, LECT NOTES COMPUT SC, V3245, P16
   Wang Peng, 2015, [Science China. Information Science, 中国科学. 信息科学], V58, P011101
   Wohlfarth T, 2008, LECT NOTES ARTIF INT, V5345, P50, DOI 10.1007/978-3-540-89447-6_7
   Wu H, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3047017
   Wu H, 2014, DATA MIN KNOWL DISC, V28, P1398, DOI 10.1007/s10618-014-0370-1
   Xia S, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P153, DOI 10.1109/ASONAM.2012.35
   Xu PP, 2016, IEEE PAC VIS SYMP, P32, DOI 10.1109/PACIFICVIS.2016.7465248
   Yu K., 2008, Proc. of European Symp. on Artificial Neural Networks, V20, P1657
   Zhang Y, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-110
   Zhao J, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P71, DOI [10.1109/visual.2019.8933639, 10.1109/VISUAL.2019.8933639]
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P195, DOI 10.1109/TVCG.2017.2744458
   Zhao JM, 2018, PROCEEDINGS OF THE 2018 AUDIO/VISUAL EMOTION CHALLENGE AND WORKSHOP (AVEC'18), P65, DOI 10.1145/3266302.3266313
NR 64
TC 7
Z9 8
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2457
EP 2469
DI 10.1109/TVCG.2020.3032984
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100016
PM 33090955
OA Bronze
DA 2024-11-06
ER

PT J
AU Wu, E
AF Wu, Eugene
TI View Composition Algebra for Ad Hoc Comparison
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; algebra; comparison; databases
ID VISUALIZATION; QUERY
AB Comparison is a core task in visual analysis. Although there are numerous guidelines to help users design effective visualizations to aid known comparison tasks, there are few techniques available when users want to make ad hoc comparisons between marks, trends, or charts during data exploration and visual analysis. For instance, to compare voting count maps from different years, two stock trends in a line chart, or a scatterplot of country GDPs with a textual summary of the average GDP. Ideally, users can directly select the comparison targets and compare them, however what elements of a visualization should be candidate targets, which combinations of targets are safe to compare, and what comparison operations make sense? This article proposes a conceptual model that lets users compose combinations of values, marks, legend elements, and charts using a set of composition operators that summarize, compute differences, merge, and model their operands. We further define a View Composition Algebra (VCA) that is compatible with datacube-based visualizations, derive an interaction design based on this algebra that supports ad hoc visual comparisons, and illustrate its utility through several use cases.
C1 [Wu, Eugene] Columbia Univ, New York, NY 10027 USA.
C3 Columbia University
RP Wu, E (corresponding author), Columbia Univ, New York, NY 10027 USA.
EM ewu@cs.columbia.edu
CR Abuzaid F, 2018, PROC VLDB ENDOW, V12, P419, DOI 10.14778/3297753.3297761
   Aiken A, 1996, PROC INT CONF DATA, P208, DOI 10.1109/ICDE.1996.492109
   [Anonymous], TIBCO SPOTFIRE
   [Anonymous], 2020, CALCULATE DISPLAY DI
   [Anonymous], SIGMA COMPUTING
   [Anonymous], 2014, AK PETERS VISUALIZAT
   [Anonymous], MICROSOFT POWERBI
   [Anonymous], CALCULATE DIFFERENCE
   [Anonymous], CALCULATING DIFFEREN
   [Anonymous], 2012, DATA MATCHING, DOI DOI 10.1007/978-3-642-31164-2
   [Anonymous], TABLEAU SOFTWARE
   BATINI C, 1986, COMPUT SURV, V18, P323, DOI 10.1145/27633.27634
   Chaudhuri S., 1997, SIGMOD Record, V26, P65, DOI 10.1145/248603.248616
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Derthick M., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P2
   Doan A., 2012, Principles of Data Integration
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kamat N, 2014, PROC INT CONF DATA, P472, DOI 10.1109/ICDE.2014.6816674
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Livny M., 1997, SIGMOD Record, V26, P301, DOI [10.1145/253262.253379, 10.1145/253262.253335]
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Naumann F, 2018, ENCY SOCIAL NETWORK
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI DOI 10.1145/345513.345282
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Roy S, 2015, PROC VLDB ENDOW, V9, P348
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Scheidegger CE, 2007, IEEE T VIS COMPUT GR, V13, P1560, DOI 10.1109/TVCG.2007.70584
   Seeling C, 2004, SECOND INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SHNEIDERMAN B, 1994, IEEE SOFTWARE, V11, P70, DOI 10.1109/52.329404
   Slingsby A, 2009, IEEE T VIS COMPUT GR, V15, P977, DOI 10.1109/TVCG.2009.128
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Stolte C. R., 2003, THESIS STANFORD U DE
   Suvanaphen E, 2004, THEORY AND PRACTICE OF COMPUTER GRAPHICS 2004, PROCEEDINGS, P2, DOI 10.1109/TPCG.2004.1314446
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2719, DOI 10.1109/TVCG.2012.237
   Tukey J. W, 1997, EXPLORATORY DATA ANA, V2
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Wickham H., 2016, Ggplot2: Elegant Graphics for Data Analysis
   Wilkinson L., 2006, The grammar of graphics
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu E., 2017, PROC 8 BIENNIAL C IN
   Wu E., 2021, ARXIV220207836
   Wu E, 2013, PROC VLDB ENDOW, V6, P553, DOI 10.14778/2536354.2536356
   Wu YF, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P136, DOI 10.1109/VIS47514.2020.00034
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zacks J, 1998, J EXP PSYCHOL-APPL, V4, P119
   Zeng Z., 2021, ARXIV210901271
   Zhang D, 2020, PROC VLDB ENDOW, V13, P1835, DOI 10.14778/3407790.3407793
NR 65
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2470
EP 2485
DI 10.1109/TVCG.2022.3152515
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100017
PM 35180082
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Deng, ZK
   Weng, D
   Liang, YX
   Bao, J
   Zheng, Y
   Schreck, T
   Xu, ML
   Wu, YC
AF Deng, Zikun
   Weng, Di
   Liang, Yuxuan
   Bao, Jie
   Zheng, Yu
   Schreck, Tobias
   Xu, Mingliang
   Wu, Yingcai
TI Visual Cascade Analytics of Large-Scale Spatiotemporal Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial cascade; pattern mining; spatiotemporal data
ID VISUALIZATION DESIGN; EXPLORATION; DYNAMICS; MOBILITY; MODEL
AB Many spatiotemporal events can be viewed as contagions. These events implicitly propagate across space and time by following cascading patterns, expanding their influence, and generating event cascades that involve multiple locations. Analyzing such cascading processes presents valuable implications in various urban applications, such as traffic planning and pollution diagnostics. Motivated by the limited capability of the existing approaches in mining and interpreting cascading patterns, we propose a visual analytics system called VisCas. VisCas combines an inference model with interactive visualizations and empowers analysts to infer and interpret the latent cascading patterns in the spatiotemporal context. To develop VisCas, we address three major challenges 1) generalized pattern inference; 2) implicit influence visualization; and 3) multifaceted cascade analysis. For the first challenge, we adapt the state-of-the-art cascading network inference technique to general urban scenarios, where cascading patterns can be reliably inferred from large-scale spatiotemporal data. For the second and third challenges, we assemble a set of effective visualizations to support location navigation, influence inspection, and cascading exploration, and facilitate the in-depth cascade analysis. We design a novel influence view based on a three-fold optimization strategy for analyzing the implicit influences of the inferred patterns. We demonstrate the capability and effectiveness of VisCas with two case studies conducted on real-world traffic congestion and air pollution datasets with domain experts.
C1 [Deng, Zikun; Weng, Di; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
   [Deng, Zikun; Weng, Di; Wu, Yingcai] Zhejiang Lab, Hangzhou 311121, Peoples R China.
   [Liang, Yuxuan] Natl Univ Singapore, Sch Comp, Singapore 119077, Singapore.
   [Bao, Jie; Zheng, Yu] JD Technol, JD Intelligent Cities Res, Beijing 100176, Peoples R China.
   [Schreck, Tobias] Graz Univ Technol, A-8010 Graz, Austria.
   [Xu, Mingliang] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450052, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Henan Inst Adv Technol, Zhengzhou 450052, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory; National University of
   Singapore; Graz University of Technology; Zhengzhou University;
   Zhengzhou University
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM zikun_rain@zju.edu.cn; dweng@zju.edu.cn; yuxliang@outlook.com;
   baojie@jd.com; msyuzheng@outlook.com; tobias.schreck@cgv.tugraz.at;
   iexumingliang@zzu.edu.cn; ycwu@zju.edu.cn
RI Zheng, Yu/GRJ-5808-2022; Weng, Di/ABG-7408-2020; wang,
   yixuan/JGM-3893-2023; Liang, Yuxuan/KXR-3882-2024; Deng,
   Zikun/IQT-3106-2023
OI Deng, Zikun/0000-0002-4477-5292; Weng, Di/0000-0003-2712-7274
FU National Natural Science Foundation of China [62072400, 61822701];
   Zhejiang Provincial Natural Science Foundation [LR18F020001]; 100
   Talents Program of Zhejiang University
FX The authors would like to thank editor and all reviewers for their
   constructive comments. They also thank Huachang Yu for his contribution
   to the system development. This work was supported by the National
   Natural Science Foundation of China under Grants 62072400 and 61822701,
   Zhejiang Provincial Natural Science Foundation under Grant LR18F020001,
   and the 100 Talents Program of Zhejiang University.
CR Accorsi P, 2014, IEEE CONF VIS ANAL, P123, DOI 10.1109/VAST.2014.7042488
   Andrienko N, 2019, IEEE T VIS COMPUT GR, V25, P54, DOI 10.1109/TVCG.2018.2864811
   Berndt D.J., 1994, P 3 INT C KNOWL DISC, P359
   Chae J, 2012, IEEE CONF VIS ANAL, P143, DOI 10.1109/VAST.2012.6400557
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Chen ZH, 2018, IEEE ACCESS, V6, P69481, DOI 10.1109/ACCESS.2018.2881039
   Chierichetti F, 2010, PROC APPL MATH, V135, P293
   DAGANZO CF, 1994, TRANSPORT RES B-METH, V28, P269, DOI 10.1016/0191-2615(94)90002-7
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Doraiswamy H, 2014, IEEE T VIS COMPUT GR, V20, P2634, DOI 10.1109/TVCG.2014.2346449
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gomez-Rodriguez M, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086741
   Goodwin S, 2013, IEEE T VIS COMPUT GR, V19, P2516, DOI 10.1109/TVCG.2013.145
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Halim AH, 2019, ARCH COMPUT METHOD E, V26, P367, DOI 10.1007/s11831-017-9247-y
   He Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P171, DOI 10.1109/VAST.2011.6102455
   Nguyen H, 2017, IEEE T BIG DATA, V3, P169, DOI 10.1109/TBDATA.2016.2587669
   Huang ZS, 2020, IEEE T VIS COMPUT GR, V26, P1256, DOI 10.1109/TVCG.2019.2934671
   Ioffe S., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P246, DOI 10.1109/ICDM.2010.80
   Kapler T., 2005, Information Visualization, V4, P136, DOI 10.1057/palgrave.ivs.9500097
   Laird CD, 2005, J WATER RES PLAN MAN, V131, P125, DOI 10.1061/(ASCE)0733-9496(2005)131:2(125)
   Lee C, 2020, IEEE T VIS COMPUT GR, V26, P3133, DOI 10.1109/TVCG.2019.2922597
   Lee TY, 2009, IEEE T VIS COMPUT GR, V15, P1359, DOI 10.1109/TVCG.2009.200
   Leskovec J, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P551
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Liang Y., 2017, P IEEE C EN INT EN S, P1, DOI [10.1109/EI2.2017.8245507, DOI 10.1109/EI2.2017.8245507]
   Little R. G, 2010, DISRUPTED CITIES, P39
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu W., 2011, P 17 ACM SIGKDD INT, P1010, DOI [DOI 10.1145/2020408.2020571, 10.1145/2020408.2020571]
   Long JC, 2008, SCI CHINA SER F, V51, P948, DOI 10.1007/s11432-008-0038-9
   Long JC, 2011, NETW SPAT ECON, V11, P43, DOI 10.1007/s11067-008-9080-9
   Ma T, 2019, J ENVIRON SCI, V83, P8, DOI 10.1016/j.jes.2019.02.031
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   Mittelstadt S, 2015, P ANN HICSS, P1118, DOI 10.1109/HICSS.2015.136
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Ng Wei-Shiuen., 2010, Journal of Transport and Land Use, V3, DOI [10.5198/jtlu.v3i3.151, DOI 10.5198/JTLU.V3I3.151]
   Ni B, 2017, VIS INFORM, V1, P57, DOI 10.1016/j.visinf.2017.01.007
   Palomo C, 2016, IEEE T VIS COMPUT GR, V22, P170, DOI 10.1109/TVCG.2015.2467592
   Pi M, 2021, IEEE T VIS COMPUT GR, V27, P2186, DOI 10.1109/TVCG.2019.2940580
   Pu JS, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 1, P127, DOI 10.1109/MDM.2013.23
   Qu H, 2007, IEEE T VIS COMPUT GR, V13, P1408, DOI 10.1109/TVCG.2007.70523
   Rahman MS, 2005, INFORM PROCESS LETT, V94, P37, DOI 10.1016/j.ipl.2004.12.002
   Rego C, 2011, EUR J OPER RES, V211, P427, DOI 10.1016/j.ejor.2010.09.010
   Shen QM, 2018, IEEE T VIS COMPUT GR, V24, P1004, DOI 10.1109/TVCG.2017.2744159
   Sitzenfrei R, 2011, WATER SCI TECHNOL, V64, P1885, DOI 10.2166/wst.2011.813
   Stein AF, 2015, B AM METEOROL SOC, V96, P2059, DOI 10.1175/BAMS-D-14-00110.1
   Stutzle T., 2000, Parallel Problem Solving from Nature PPSN VI. 6th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1917), P661
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Vaessens R. J. M., 1996, INFORMS Journal on Computing, V8, P302, DOI 10.1287/ijoc.8.3.302
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wang H, 2019, IEEE T VIS COMPUT GR, V25, P331, DOI 10.1109/TVCG.2018.2864844
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Weng D, 2021, IEEE T INTELL TRANSP, V22, P1185, DOI 10.1109/TITS.2020.2964012
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   World Health Organization, 2006, WHO Air Quality Guidelines for Particulate. Matter, Ozone, Nitrogen Dioxide and Sulfur Dioxide - Global Update 2005, DOI DOI 10.4067/S0370-41062009000400012
   Wu J, 2020, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST50239.2020.00009
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Xiong HY, 2018, PROCEEDINGS OF THE 11TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON COMPUTATIONAL TRANSPORTATION SCIENCE (IWCTS 2018), P60, DOI 10.1145/3283207.3283213
   Yixian Zheng, 2016, IEEE Transactions on Big Data, V2, P276, DOI 10.1109/TBDATA.2016.2586447
   Zeng W, 2019, COMPUT GRAPH FORUM, V38, P581, DOI 10.1111/cgf.13712
   Zeng W, 2014, IEEE T VIS COMPUT GR, V20, P1833, DOI 10.1109/TVCG.2014.2346893
   Zhang AMH, 2012, PROCD SOC BEHV, V43, P628, DOI 10.1016/j.sbspro.2012.04.136
   Zhang HB, 2010, TRANSPORT RES REC, P30, DOI 10.3141/2178-04
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zheng Y, 2014, ACM T INTEL SYST TEC, V5, DOI 10.1145/2629592
   Zhu JY, 2018, IEEE T BIG DATA, V4, P571, DOI 10.1109/TBDATA.2017.2723899
   Zio E, 2011, RISK ANAL, V31, P1196, DOI 10.1111/j.1539-6924.2011.01584.x
NR 75
TC 17
Z9 19
U1 4
U2 34
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2486
EP 2499
DI 10.1109/TVCG.2021.3071387
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100018
PM 33822726
DA 2024-11-06
ER

PT J
AU Liu, ZP
   Wang, Y
   Bernard, J
   Munzner, T
AF Liu, Zipeng
   Wang, Yang
   Bernard, Juergen
   Munzner, Tamara
TI Visualizing Graph Neural Networks With CorGIE: Corresponding a Graph to
   Its Embedding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization for machine learning; graph neural network; graph layout
ID OF-THE-ART; LAYOUT
AB Graph neural networks (GNNs) are a class of powerful machine learning tools that model node relations for making predictions of nodes or links. GNN developers rely on quantitative metrics of the predictions to evaluate a GNN, but similar to many other neural networks, it is difficult for them to understand if the GNN truly learns characteristics of a graph as expected. We propose an approach to corresponding an input graph to its node embedding (aka latent space), a common component of GNNs that is later used for prediction. We abstract the data and tasks, and develop an interactive multi-view interface called CorGIE to instantiate the abstraction. As the key function in CorGIE, we propose the K-hop graph layout to show topological neighbors in hops and their clustering structure. To evaluate the functionality and usability of CorGIE, we present how to use CorGIE in two usage scenarios, and conduct a case study with five GNN experts.
C1 [Liu, Zipeng] Beihang Univ, Coll Software, Beijing 100190, Peoples R China.
   [Wang, Yang] Facebook Inc, Menlo Pk, CA 94025 USA.
   [Bernard, Juergen] Univ Zurich, Dept Comp Sci, CH-8006 Zurich, Switzerland.
   [Munzner, Tamara] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
C3 Beihang University; Facebook Inc; University of Zurich; University of
   British Columbia
RP Liu, ZP (corresponding author), Beihang Univ, Coll Software, Beijing 100190, Peoples R China.
EM zipeng@buaa.edu.cn; yvv@fb.com; bernard@ifi.uzh.ch; tmm@cs.ubc.ca
RI Bernard, Jürgen/AAK-5732-2021; Munzner, Tamara/HKP-2536-2023
CR Bernard J, 2015, PROC SPIE, V9397, DOI 10.1117/12.2079841
   Borg I., 2010, Modern multidimensional scaling, V2nd ed., DOI DOI 10.1007/s00357-006-0008-0
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chami I., 2020, ARXIV200503675
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Coenen A., 2019, UNDERSTANDING UMAP
   Cutura R., 2020, P INT C ADV VIS INT
   Dwivedi V. P., 2020, ARXIV 200300982
   Dwyer T, 2006, IEEE T VIS COMPUT GR, V12, P821, DOI 10.1109/TVCG.2006.156
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Gansner ER, 2011, IEEE PAC VIS SYMP, P187, DOI 10.1109/PACIFICVIS.2011.5742389
   Ghosh A, 2022, IEEE T VIS COMPUT GR, V28, P2791, DOI 10.1109/TVCG.2020.3039106
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Guo SN, 2019, AAAI CONF ARTIF INTE, P922
   Heimerl F, 2022, IEEE T VIS COMPUT GR, V28, P2953, DOI 10.1109/TVCG.2020.3045918
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hu W, 2020, Advances in neural information processing systems, 2020-Dec(NeurIPS), P1
   Huang Q., 2020, ARXIV200106216
   Jin Z., 2020, ARXIV201111048
   Kipf T., 2016, ARXIV
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Muelder C, 2008, IEEE T VIS COMPUT GR, V14, P1301, DOI 10.1109/TVCG.2008.158
   Munzner T. M., 2000, Interactive visualization of large graphs and networks
   Noack Andreas, 2007, Journal of Graph Algorithms and Applications, V11, P453, DOI 10.7155/jgaa.00154
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Peng N., 2017, T ASSOC COMPUT LING, V5, P101, DOI [10.1162/tacla00049, DOI 10.1162/TACL_A_00049]
   Pope PE, 2019, PROC CVPR IEEE, P10764, DOI 10.1109/CVPR.2019.01103
   Rao Susie Xi, 2020, ARXIV201112193
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Rodrigues E. M., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P354, DOI 10.1109/PASSAT/SocialCom.2011.139
   Smilkov Daniel, 2016, ARXIV161105469
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Tang J., 2008, P 14 ACM SIGKDD INT, P990, DOI [DOI 10.1145/1401890.1402008, 10.1145/1401890.1402008]
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Veli ~ckovic P., 2017, ARXIV171010903
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Yang CR, 2022, IEEE T KNOWL DATA EN, V34, P4854, DOI [10.1109/tkde.2020.3045924, 10.1109/TKDE.2020.3045924]
   Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yuan Hao, 2020, arXiv preprint arXiv:2012.15445
   Zhou H, 2013, TSINGHUA SCI TECHNOL, V18, P145, DOI 10.1109/TST.2013.6509098
NR 47
TC 6
Z9 6
U1 0
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2500
EP 2516
DI 10.1109/TVCG.2022.3148197
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100019
PM 35120005
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Yeh, CK
   Liu, ZP
   Lin, IH
   Zhang, E
   Lee, TY
AF Yeh, Chih-Kuo
   Liu, Zhanping
   Lin, I-Hsuan
   Zhang, Eugene
   Lee, Tong-Yee
TI WYSIWYG Design of Hypnotic Line Art
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Non-photorealistic rendering (NPR); hypnotic line art; tensor field
   design; streamline placement; vector field visualization
AB Hypnotic line art is a modern form in which white narrow curved ribbons, with the width and direction varying along each path over a black background, provide a keen sense of 3D objects regarding surface shapes and topological contours. However, the procedure of manually creating such line art work can be quite tedious and time-consuming. In this article, we present an interactive system that offers a What-You-See-Is-What-You-Get (WYSIWYG) scheme for producing hypnotic line art images by integrating and placing evenly-spaced streamlines in tensor fields. With an input picture segmented, the user just needs to sketch a few illustrative strokes to guide the construction of a tensor field for each part of the objects therein. Specifically, we propose a new method which controls, with great precision, the aesthetic layout and artistic drawing of an array of streamlines in each tensor field to emulate the style of hypnotic line art. Given several parameters for streamlines such as density, thickness, and sharpness, our system is capable of generating professional-level hypnotic line art work. With great ease of use, it allows art designers to explore a wide variety of possibilities to obtain hypnotic line art results of their own preferences.
C1 [Yeh, Chih-Kuo] Zhaoqing Univ, Sch Comp Sci & Software, Zhaoqing 526061, Peoples R China.
   [Liu, Zhanping] Old Dominion Univ, Dept Modeling Simulat & Visualizat Engn, Norfolk, VA 23529 USA.
   [Lin, I-Hsuan; Lee, Tong-Yee] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
   [Zhang, Eugene] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
C3 Zhaoqing University; Old Dominion University; National Cheng Kung
   University; Oregon State University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
EM simpson.ycg@gmail.com; zhanpingliu@hotmail.com;
   sherrygottalent@hotmail.com; zhange@eecs.oregonstate.edu;
   tonylee@mail.ncku.edu.tw
RI Yeh, Chih-Kuo/JBS-2228-2023
FU Ministry of Science and Technology, Taiwan [107-2221-E-006-196-MY3,
   108-2221-E-006-038-MY3]; NSF [1619383]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [1619383] Funding
   Source: National Science Foundation
FX The authors would like to thank the reviewers for many constructive
   comments that help improve the article. This work was supported in part
   by the Ministry of Science and Technology (contracts
   107-2221-E-006-196-MY3 and 108-2221-E-006-038-MY3), Taiwan, and NSF
   award #1619383.
CR Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Cappelli R, 2000, INT C PATT RECOG, P471, DOI 10.1109/ICPR.2000.903586
   Chen Guoning, 2008, ACM Transaction on Graphics. SIGGRAPH'08, DOI [DOI 10.1145/1360612.1360702, 10. 1145/1399504.1360702, DOI 10.1145/1399504.1360702]
   Delmarcelle T., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P140, DOI 10.1109/VISUAL.1994.346326
   Elber G, 1996, ACM T GRAPHIC, V15, P249, DOI 10.1145/231731.231736
   Elber G, 2001, IEEE COMPUT GRAPH, V21, P44, DOI 10.1109/38.920626
   Etienne J, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384522
   Gerl M, 2013, COMPUT GRAPH-UK, V37, P65, DOI 10.1016/j.cag.2012.11.003
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Jobard B, 2001, WSCG '2001: SHORT COMMUNICATIONS AND POSTERS, pP34
   Jobard B, 2000, COMPUT GRAPH FORUM, V19, pC31, DOI 10.1111/1467-8659.00395
   Jobard Bruno., 1997, VISUALIZATION SCI CO, P43
   Johnston S.F., 2002, Proceedings of the Symposium on Non-photorealistic animation and rendering, P45
   Kalnins RD, 2002, ACM T GRAPHIC, V21, P755, DOI 10.1145/566570.566648
   Kim Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409109
   LEISTER W, 1994, COMPUT GRAPH FORUM, V13, P69, DOI 10.1111/1467-8659.1310069
   Li LY, 2007, IEEE T VIS COMPUT GR, V13, P630, DOI 10.1109/TVCG.2007.1009
   Liu ZP, 2006, IEEE T VIS COMPUT GR, V12, P965, DOI 10.1109/TVCG.2006.116
   Maharik R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964995
   Mattausch O., 2003, P SPRING C COMPUTER, P213
   McLoughlin T, 2010, COMPUT GRAPH FORUM, V29, P1807, DOI 10.1111/j.1467-8659.2010.01650.x
   Mebarki A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P479
   Ostromoukhov V, 1999, COMP GRAPH, P417, DOI 10.1145/311535.311604
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Rivest RL, 2009, Introduction to Algorithms
   Rosanwo O, 2009, IEEE PAC VIS SYMP, P9, DOI 10.1109/PACIFICVIS.2009.4906832
   Rössl C, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P87, DOI 10.1109/PCCGA.2000.883890
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Saputra RA., 2017, Proceedings of the 43rd Graphics Interface Conference, P8
   Seymour P, ABOUT BEHANCE
   Spencer B, 2009, COMPUT GRAPH FORUM, V28, P1618, DOI 10.1111/j.1467-8659.2009.01352.x
   Turk G., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P453, DOI 10.1145/237170.237285
   Verma V, 2000, IEEE VISUAL, P163, DOI 10.1109/VISUAL.2000.885690
   Wu KQ, 2010, IEEE T VIS COMPUT GR, V16, P791, DOI 10.1109/TVCG.2009.206
   Xu J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239480
   Yao CY, 2012, IEEE T VIS COMPUT GR, V18, P902, DOI 10.1109/TVCG.2011.112
   Ye XH, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P471
   Zander J, 2004, COMPUT GRAPH FORUM, V23, P421, DOI 10.1111/j.1467-8659.2004.00773.x
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
   Zhang E, 2009, IEEE T VIS COMPUT GR, V15, P106, DOI 10.1109/TVCG.2008.68
   Zhanping Liu, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6809, p68090A, DOI 10.1117/12.765736
NR 41
TC 0
Z9 0
U1 2
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2517
EP 2529
DI 10.1109/TVCG.2020.3032734
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100020
PM 33085618
DA 2024-11-06
ER

PT J
AU Sereno, M
   Wang, XY
   Besancon, L
   Mcguffin, MJ
   Isenberg, T
AF Sereno, Mickael
   Wang, Xiyao
   Besancon, Lonni
   Mcguffin, Michael J.
   Isenberg, Tobias
TI Collaborative Work in Augmented Reality: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Introductory and survey; computer-supported cooperative work; virtual
   and augmented reality; immersive analytics
ID MIXED REALITY; VISUALIZATION; TECHNOLOGY; ENVIRONMENT; CHALLENGES;
   ANALYTICS; AWARENESS; DESIGN
AB In Augmented Reality (AR), users perceive virtual content anchored in the real world. It is used in medicine, education, games, navigation, maintenance, product design, and visualization, in both single-user and multi-user scenarios. Multi-user AR has received limited attention from researchers, even though AR has been in development for more than two decades. We present the state of existing work at the intersection of AR and Computer-Supported Collaborative Work (AR-CSCW), by combining a systematic survey approach with an exploratory, opportunistic literature search. We categorize 65 papers along the dimensions of space, time, role symmetry (whether the roles of users are symmetric), technology symmetry (whether the hardware platforms of users are symmetric), and output and input modalities. We derive design considerations for collaborative AR environments, and identify under-explored research topics. These include the use of heterogeneous hardware considerations and 3D data exploration research areas. This survey is useful for newcomers to the field, readers interested in an overview of CSCW in AR applications, and domain experts seeking up-to-date information.
C1 [Sereno, Mickael; Wang, Xiyao; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LRI, F-91190 St Aubin, France.
   [Besancon, Lonni] Linkoping Univ, S-58183 Linkoping, Sweden.
   [Mcguffin, Michael J.] Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
C3 Inria; Universite Paris Cite; Universite Paris Saclay; Centre National
   de la Recherche Scientifique (CNRS); Linkoping University; University of
   Quebec; Ecole de Technologie Superieure - Canada
RP Sereno, M (corresponding author), Univ Paris Saclay, CNRS, Inria, LRI, F-91190 St Aubin, France.
EM mickael.sereno@inria.fr; xiyao.wang@inria.fr; lonni.besancon@gmail.com;
   michael.mcguffin@etsmtl.ca; tobias.isenberg@inria.fr
RI Wang, Xiyao/AFN-9739-2022; Besançon, Lonni/N-1856-2017; Isenberg,
   Tobias/A-7575-2008; Sereno, Mickael/H-2447-2019
OI Isenberg, Tobias/0000-0001-7953-8644; Sereno,
   Mickael/0000-0003-1298-0774
CR ADAMS MJ, 1995, HUM FACTORS, V37, P85, DOI 10.1518/001872095779049462
   Adcock M., 2013, P S SPAT US INT, P18
   Agrawala M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P327, DOI 10.1145/258734.258875
   Albinsson P.A., 2003, Proceedings of CHI 2003, P105, DOI [DOI 10.1145/642611.642631, 10.1145/642611.642631]
   Alem L., 2011, RECENT TRENDS MOBILE
   Attfield Simon, 2011, WSDM WORKSH US MOD W, P9
   AYIR MA, 2017, EDUC RES REV-NETH, V20, P1
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Baecker R.M., 1993, Readings in Groupware and Computer Cooperative Supported Work, Assisting Human-Human Collaboration
   Ballagas Rafael, 2013, P 2013 C COMP SUPP C, P225, DOI DOI 10.1145/2441776.2441803
   Barber J, 2018, PHOTOSYNTHESIS AND BIOENERGETICS, P1
   Barsom EZ, 2016, SURG ENDOSC, V30, P4174, DOI 10.1007/s00464-016-4800-6
   Belcher D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P84, DOI 10.1109/ISMAR.2003.1240691
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Benko H, 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI '12, P199, DOI [DOI 10.1145/2207676.2207704, 10.1145/2207676.2207704]
   Benko Hrvoje, 2014, P 27 ANN ACM S US IN, P645, DOI DOI 10.1145/2642918.2647402
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Bhattacharyya P., 2019, PROC SIGCHI C HUM FA
   Billinghurst M, 1999, MIXED REALITY, P261
   Billinghurst M, 2001, COMPUT GRAPH-UK, V25, P745, DOI 10.1016/S0097-8493(01)00117-0
   Billinghurst M., 1998, P COLL VIRT ENV, P123
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Billinghurst M, 2011, RECENT TRENDS OF MOBILE COLLABORATIVE AUGMENTED REALITY SYSTEMS, P1, DOI 10.1007/978-1-4419-9845-3_1
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bruckner S, 2019, IEEE T VIS COMPUT GR, V25, P2514, DOI 10.1109/TVCG.2018.2848906
   Büschel W, 2019, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'19), DOI 10.1145/3338286.3340113
   Butz A., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P35, DOI 10.1109/IWAR.1999.803804
   Chan LW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2625
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/GLOCOM.2015.7417476, 10.1109/ICSENS.2015.7370446]
   Chen M., 1988, Computer Graphics, V22, P121, DOI 10.1145/378456.378497
   Chenechal M.L., 2015, ICAT EGVE 2015 INT C, P4, DOI [10.2312/EGVE.20151322, DOI 10.2312/EGVE.20151322]
   Clergeaud D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139165
   Csikszentmihalyi M., 1975, Beyond boredom and anxiety, V1st Edn
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Dedual N. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2011.6092391
   DeVincenzi Anthony., 2011, P ACM 2011 C COMPUTE, P621, DOI DOI 10.1145/1958824.1958929
   Dolata M., 2019, ACM T COMPUT-HUM INT, V3
   Dong SY, 2013, ADV ENG SOFTW, V55, P45, DOI 10.1016/j.advengsoft.2012.09.001
   Dunleavy M, 2009, J SCI EDUC TECHNOL, V18, P7, DOI 10.1007/s10956-008-9119-1
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Eivazi S, 2015, ACTA NEUROCHIR, V157, P1147, DOI 10.1007/s00701-015-2433-5
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Elvezio Carmine, 2017, ACM SIGGRAPH 2017 VR, DOI [10.1145/3089269.3089281, DOI 10.1145/3089269.3089281]
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Ens Barrett., 2014, Proceedings of the 2nd ACM symposium on Spatial user interaction (SUI'14), P2, DOI DOI 10.1145/2659766.2659769
   Feiner S., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P145, DOI 10.1145/168642.168657
   Fitzmaurice G. W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P442
   Fitzmaurice G. W., 1996, THESIS U TORONTO CAN
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fontaine G., 1992, PRESENCE, V1, P482, DOI DOI 10.1162/pres.1992.1.4.482
   Forlines C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P647
   Forsberg AS, 2009, IEEE T VIS COMPUT GR, V15, P1219, DOI 10.1109/TVCG.2009.126
   Franz, 2019, ACM T COMPUT-HUM INT, V3
   Gauglitz S., 2014, P 27 ANN ACM S US IN, P449
   Gauglitz Steffen, 2014, P 20 ACM S VIRT REAL, P197, DOI 10.1145/2671015.2671016
   Gauglitz Steffen, 2012, P 14 INT C HUM COMP, DOI [10.1145/2371574.2371610, DOI 10.1145/2371574.2371610]
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gutwin C., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P411, DOI 10.1023/A:1021271517844
   Heeter C., 1992, PRESENCE-TELEOP VIRT, V1, P262, DOI [10.1162/pres.1992.1.2.262, DOI 10.1162/PRES.1992.1.2.262]
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson Steven J., 2008, P 2008 ACM S VIRT RE, P211, DOI DOI 10.1145/1450579.1450625
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley K., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P1, DOI 10.1145/263407.263408
   Hong S, 2014, PR IEEE COMP DESIGN, P83, DOI 10.1109/ICCD.2014.6974666
   Huang WD, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P396, DOI 10.1145/3292147.3292177
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Huynh D., 2009, SIGGRAPH S VIDEO GAM, P135, DOI DOI 10.1145/1581073.1581095
   Irlitti A., 2014, 20 ACM S VIRT REAL S, P161
   Irlitti A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P31, DOI [10.1109/ISMAR-Adjunct.2016.25, 10.1109/ISMAR-Adjunct.2016.0032]
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Isenberg T., 2012, P CHI WORKSH 3 DIM C, P53
   Ishii Hiroshi, 1997, Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/258549.258715
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Kan P., 2014, CHALLENGING PRESENCE, P223
   Kasahara S, 2012, SIGGRAPH ASIA 2012 E, P1, DOI DOI 10.1145/2407707.2407727
   Keefe DF, 2013, COMPUTER, V46, P51, DOI 10.1109/MC.2013.178
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kirner C, 2006, IEEE SYS MAN CYBERN, P97, DOI 10.1109/ICSMC.2006.384365
   Kiyokawa K., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P48, DOI 10.1109/ICSMC.1999.816444
   Komiyama Ryohei, 2017, P 8 AUGM HUM INT C S, DOI [10.1145/3041164.3041183, DOI 10.1145/3041164.3041183]
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Lee G. A., 2017, P SIGGRAPH AS MOB GR
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1093/ct/14.1.27
   Lee S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P309
   Lehment NH, 2014, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2014.6948428
   Lien KC, 2016, INT SYM MIX AUGMENT, P77, DOI 10.1109/ISMAR.2016.21
   Lincoln P, 2009, INT SYM MIX AUGMENT, P27, DOI 10.1109/ISMAR.2009.5336503
   Liu S, 2008, INT SYM MIX AUGMENT, P33, DOI 10.1109/ISMAR.2008.4637321
   López D, 2016, IEEE T VIS COMPUT GR, V22, P1616, DOI 10.1109/TVCG.2015.2440233
   Lukosch S, 2015, COMPUT SUPP COOP W J, V24, P515, DOI 10.1007/s10606-015-9239-0
   MacWilliams A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P123, DOI 10.1109/ISMAR.2003.1240695
   Mahmood T, 2019, INT SYM MIX AUGMENT, P236, DOI 10.1109/ISMAR.2019.00021
   Maimone A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P137, DOI 10.1109/ISMAR.2011.6092379
   Marai GE, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P54, DOI 10.1109/IMMERSIVE.2016.7932384
   Marriott K., 2018, IMMERSIVE ANAL, V11190, DOI 10/kt9x
   Marshall P, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2149
   Matsutomo S, 2012, IEEE T MAGN, V48, P531, DOI 10.1109/TMAG.2011.2174208
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mora S, 2012, INT J MOB HUM COMPUT, V4, P88, DOI 10.4018/jmhci.2012040107
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   O'Hara K, 2014, COMMUN ACM, V57, P70, DOI 10.1145/2541883.2541899
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Oda O, 2009, INT SYM MIX AUGMENT, P13, DOI 10.1109/ISMAR.2009.5336507
   OLSON IC, 2011, P 5 INT C TANG EMB E, P29
   ON LB, 2019, COMPUT GRAPH FORUM, V38, P553
   ON LB, 2017, P SIGCHI C HUM FACT, P4727
   Ong SK, 2008, INT J PROD RES, V46, P2707, DOI 10.1080/00207540601064773
   Ong SK, 2009, CIRP ANN-MANUF TECHN, V58, P139, DOI 10.1016/j.cirp.2009.03.020
   Ou J., 2003, Proceedings of the 5th International Conference on Multimodal interfaces (ICMI), P242
   Park K. S., 2000, CVE 2000. Proceedings of the Third International Conference on Collaborative Virtual Environments, P73, DOI 10.1145/351006.351015
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Piekarski W, 2002, COMMUN ACM, V45, P36, DOI 10.1145/502269.502291
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Piper B., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P355, DOI 10.1145/503376.503439
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Poelman R., 2012, P ACM 2012 C COMP SU, P1267, DOI [10.1145/2145204.2145394, DOI 10.1145/2145204.2145394]
   Poretski Lev, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274411
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Prytz E., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P119, DOI 10.1109/ISMAR.2010.5643559
   Raskar R, 1999, AUGMENTED REALITY, P63
   REKIMOTO J, 1996, P VIRT SYST MULT, P85
   Roo JS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P787, DOI 10.1145/3126594.3126638
   Roo JS, 2017, IEEE SYMP 3D USER, P195, DOI 10.1109/3DUI.2017.7893339
   Roo JS, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P570, DOI 10.1145/2839462.2856532
   Sambrooks L., 2013, P 25 AUSTR COMP HUM, DOI [10.1145/2541016.2541066, DOI 10.1145/2541016.2541066, https://doi.org/10.1145/2541016.2541066]
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Schmalstieg D., 1996, P COLL VIRT ENV
   Sereno Mickael, 2019, EUROVIS 2019 POSTERS, P21, DOI [DOI 10.2312/EURP.20191136, 10.2312/EURP.20191136]
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith G., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P139, DOI 10.1145/261135.261161
   Sodhi Rajinder S., 2013, P SIGCHI C HUM FACT, P179
   Song P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1333
   Stafford Aaron, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P165, DOI 10.1109/ISMAR.2006.297809
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Sutherland I. E., 1968, P DEC 9 11 1968 FA 1, P757, DOI [https://doi.org/10.1145/1476589.1476686, DOI 10.1145/1476589.1476686]
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Szalavari Z., 1998, P ACM S VIRT REAL SO, P195, DOI DOI 10.1145/293701.293740
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Teo T, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P406, DOI 10.1145/3292147.3292200
   Thanyadit S, 2019, INT SYM MIX AUGMENT, P258, DOI 10.1109/ISMAR.2019.00023
   Thomas J. J., 2005, Illuminating the path: The research and development agenda for visual analytics
   Thomas PC, 1992, ACM SIGCHI B, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   ULLER JM, 2017, P SIGCHI C HUM FACT, P6481
   Wang X, 2019, P CHI WORKSH IMM AN
   Wang XY, 2008, AUTOMAT CONSTR, V17, P399, DOI 10.1016/j.autcon.2007.07.002
   Wang XY, 2014, COMPUT IND, V65, P314, DOI 10.1016/j.compind.2013.11.012
   Wang XY, 2009, IEEE SYS MAN CYBERN, P3569, DOI 10.1109/ICSMC.2009.5346691
   Wang Xiaoyang., 2020, IEEE INT SYMP CIRC S, P1, DOI [10.1109/ISCAS45731.2020.9180667, DOI 10.1109/iscas45731.2020.9180667, DOI 10.1109/JIOT.2020.2982699.]
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Wilson A.D., 2010, Proc. UIST, P273
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Xia HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P853, DOI 10.1145/3242587.3242597
   Xie L., 2008, TEI'08 Proceedings, P191, DOI [DOI 10.1145/1347390.1347433, 10.1145/1347390.1347433]
   Yuill N., ACM T COMPUT-HUM INT, V19
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 179
TC 91
Z9 95
U1 4
U2 131
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2022
VL 28
IS 6
BP 2530
EP 2549
DI 10.1109/TVCG.2020.3032761
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 0Z1CH
UT WOS:000790817100021
PM 33085619
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Sun, YC
   Ouyang, WQ
   Liu, ZY
   Ni, N
   Savoye, Y
   Song, P
   Liu, LG
AF Sun, Yucheng
   Ouyang, Wenqing
   Liu, Zhongyuan
   Ni, Ning
   Savoye, Yann
   Song, Peng
   Liu, Ligang
TI Computational Design of Self-Actuated Deformable Solids via Shape Memory
   Material
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Switched mode power supplies; Strain; Solids; Deformable models;
   Three-dimensional displays; Solid modeling; Computational design;
   deformable solid; shape memory material; constitutive model; 4D printing
AB The emerging 4D printing techniques open new horizons for fabricating self-actuated deformable objects by combing strength of 3D printing and stimuli-responsive shape memory materials. This article focuses on designing self-actuated deformable solids for 4D printing such that a solid can be programmed into a temporary shape and later recovers to its original shape after heating. To avoid a high material cost, we choose a dual-material strategy that mixes an expensive thermo-responsive shape memory polymer (SMP) material with a common elastic material, which however leads to undesired deformation at the shape programming stage. We model this shape programming process as two elastic models with different parameters linked by a median shape based on customizing a constitutive model of thermo-responsive SMPs. Taking this material modeling as a foundation, we formulate our design problem as a nonconvex optimization to find the distribution of SMP materials over the whole object as well as the median shape, and develop an efficient and parallelizable method to solve it. We show that our proposed approach is able to design self-actuated deformable objects that cannot be achieved by state of the art approaches, and demonstrate their usefulness with three example applications.
C1 [Sun, Yucheng; Ouyang, Wenqing; Ni, Ning; Liu, Ligang] Univ Sci & Technol China, Hefei 230052, Peoples R China.
   [Sun, Yucheng; Song, Peng] Singapore Univ Technol & Design, Singapore 487372, Singapore.
   [Savoye, Yann] Liverpool John Moores Univ, Liverpool L2 2QP, Merseyside, England.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Singapore University of Technology & Design; Liverpool John
   Moores University
RP Liu, LG (corresponding author), Univ Sci & Technol China, Hefei 230052, Peoples R China.
EM syc1011@ustc.edu.cn; wq8809@mail.ustc.edu.cn; zyliu28@mail.ustc.edu.cn;
   nining@mail.ustc.edu.cn; ysavoye@siggraph.org; peng_song@sutd.edu.sg;
   lgliu@ustc.edu.cn
RI Liu, Ligang/IZQ-5817-2023; Song, Peng/ABH-5214-2020
OI Sun, Yucheng/0000-0002-1373-0905; Song, Peng/0000-0003-2734-2783
FU National Natural Science Foundation of China [61672482, 62025207]; SUTD
   Start-up Research [SRG ISTD 2019 148]; Zhejiang Lab [2019NB0AB03]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61672482 and 62025207, the Zhejiang Lab under Grant
   2019NB0AB03, and the SUTD Start-up Research under Grant SRG ISTD 2019
   148.
CR An B., 2018, P 2018 C HUM FACT CO, DOI [DOI 10.1145/3173574, DOI 10.1145/3173574.3173834]
   Bickel B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778800
   Boatti E, 2016, INT J PLASTICITY, V83, P153, DOI 10.1016/j.ijplas.2016.04.008
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chen T, 2018, 3D PRINT ADDIT MANUF, V5, P91, DOI 10.1089/3dp.2017.0118
   Chen X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601189
   Deimel R, 2016, INT J ROBOT RES, V35, P161, DOI 10.1177/0278364915592961
   Ge Q, 2016, SCI REP-UK, V6, DOI 10.1038/srep31110
   Ge Q, 2014, SMART MATER STRUCT, V23, DOI 10.1088/0964-1726/23/9/094007
   Guseinov R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073709
   Hou Y, 2012, IEEE T NEUR NET LEAR, V23, P1003, DOI 10.1109/TNNLS.2012.2194793
   Hsiao JH, 2019, ADV ROBOTICS, V33, P1099, DOI 10.1080/01691864.2019.1679251
   Hu JL, 2012, PROG POLYM SCI, V37, P1720, DOI 10.1016/j.progpolymsci.2012.06.001
   Jani JM, 2014, MATER DESIGN, V56, P1078, DOI 10.1016/j.matdes.2013.11.084
   Jiang B, 2019, COMPUT OPTIM APPL, V72, P115, DOI 10.1007/s10589-018-0034-y
   Lendlein A, 2010, ADV POLYM SCI, V226, P1, DOI 10.1007/978-3-642-12359-7
   Li GY, 2015, SIAM J OPTIMIZ, V25, P2434, DOI 10.1137/140998135
   Ma LK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130850
   Martínez J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073638
   Martínez J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201343
   Martínez J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925922
   Momeni F, 2017, MATER DESIGN, V122, P42, DOI 10.1016/j.matdes.2017.02.068
   Panetta J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766937
   Pérez J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073695
   Pérez J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766998
   Schumacher C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766926
   Sifakis Eftychios, 2012, ACM SIGGRAPH 2012 Courses. SIGGRAPH '12, DOI DOI 10.1145/2343483.2343501
   Skouras M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461979
   Song P, 2018, VISUAL COMPUT, V34, P257, DOI 10.1007/s00371-016-1333-x
   Sun L, 2012, MATER DESIGN, V33, P577, DOI 10.1016/j.matdes.2011.04.065
   Tibbits S, 2014, ARCHIT DESIGN, V84, P116, DOI 10.1002/ad.1710
   Wang GY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P623, DOI 10.1145/3242587.3242625
   Wang Y, 2019, J SCI COMPUT, V78, P29, DOI 10.1007/s10915-018-0757-z
   Zehnder J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130881
   Zhang XT, 2016, COMPUT GRAPH FORUM, V35, P157, DOI 10.1111/cgf.12972
NR 35
TC 3
Z9 3
U1 1
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2577
EP 2588
DI 10.1109/TVCG.2020.3039613
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400003
PM 33226949
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Morse, PE
   Reading, AM
   Stal, T
AF Morse, Peter E.
   Reading, Anya M.
   Stal, Tobias
TI Exploratory Volumetric Deep Earth Visualization by 2.5D Interactive
   Compositing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Earth; Three-dimensional displays; Two dimensional
   displays; Rendering (computer graphics); Image color analysis; Solid
   modeling; Color mapping; interactive visualization; seismic tomography;
   solid earth geophysics; volume visualization
ID OF-THE-ART; GOOGLE EARTH; 3D; MODELS; MANTLE; TIME; TECHNOLOGIES;
   SCIENCE; DESIGN; IMAGES
AB In this contribution we consider the visualization of global, deep Earth volume datasets for display and researcher interaction. While the algorithms and data analysis techniques that produce such volumetric results have become more sophisticated, the manner of visualizing these findings can be improved. We address the challenge of making an illustrative, exploratory visualization of a global geoscience dataset using a combined seismic tomography result, the primary means by which geoscientists infer structure and process in the deep Earth. We present a novel, interactive graphical application suite and associated workflow that uses an intuitive 2.5D layer compositing approach. This allows the user to adjust the separation between data-slices, control graphics variables such as color mapping, opacity and compositing, and facilitate exploration and annotation of the architecture of the lithosphere. Graphics outputs from our applications are enabled for immersive systems such as dome displays. In a case study we visualize the deep Earth structure beneath the Indian Ocean region. We anticipate that the application methodology will find use in the visualization of multiple datasets representing aspects of the Earth's deep interior and atmosphere, and in the interaction with the increasing number of rich datasets from missions to our neighboring planets.
C1 [Morse, Peter E.; Stal, Tobias] Univ Tasmania, Dept Earth Sci, Private Bag 79, Hobart, Tas 7001, Australia.
   [Reading, Anya M.] Univ Tasmania, Dept Phys, Private Bag 37, Hobart, Tas 7001, Australia.
   [Stal, Tobias] Univ Tasmania, Inst Marine & Antarctic Studies, Private Bag 79, Hobart, Tas 7001, Australia.
C3 University of Tasmania; University of Tasmania; University of Tasmania
RP Morse, PE (corresponding author), Univ Tasmania, Dept Earth Sci, Private Bag 79, Hobart, Tas 7001, Australia.
EM peter.morse@utas.edu.au; anya.reading@utas.edu.au;
   tobias.staal@utas.edu.au
RI Stål, Tobias/AAI-9302-2021; Reading, Anya/E-6728-2012; Morse,
   Peter/C-6810-2013
OI Reading, Anya/0000-0002-9316-7605; Morse, Peter/0000-0001-9315-1374;
   Stal, Tobias/0000-0002-4323-6748
FU University of Tasmania; Australian Research Council's Special Research
   Initiative for Antarctic Gateway Partnership [SR140300001]; ARC Research
   Hub for Transforming the Mining Value Chain [IH130200004]
FX PM co-designed the study, developed the visualization software and wrote
   the text. AR co-designed the study and contributed to the text. TS
   carried out data pre-processing and contributed to the text. The authors
   would like to thank Stephen J. Walters for constructive feedback. PM
   acknowledges an RTP Scholarship from the University of Tasmania. TS
   acknowledges support under Australian Research Council's Special
   Research Initiative for Antarctic Gateway Partnership (Project ID
   SR140300001). This work was supported inpart by the ARC Research Hub for
   Transforming the Mining Value Chain (project number IH130200004).
CR Adobe Systems Incorporated, 2006, PDF REFERENCE 17
   Ahern S., 2013, ARXIV13091796
   Andrienko G, 2011, J VISUAL LANG COMPUT, V22, P251, DOI 10.1016/j.jvlc.2011.04.001
   [Anonymous], 2012, Expanding the frontiers of visual analytics and visualization, DOI DOI 10.1016/j.pbiomolbio.2015.07.004
   Auer L, 2014, J GEOPHYS RES-SOL EA, V119, P3006, DOI 10.1002/2013JB010773
   Ayachit U, 2020, PARAVIEW GUIDE PARAL, V5.8
   Bailey JE, 2011, COMPUT GEOSCI-UK, V37, P1, DOI 10.1016/j.cageo.2010.06.001
   Ballagh LM, 2011, COMPUT GEOSCI-UK, V37, P57, DOI 10.1016/j.cageo.2010.05.004
   Becker T. W, 2016, CHAIR GEOPHYS SEISMI
   Becker TW, 2002, GEOCHEM GEOPHY GEOSY, V3, DOI 10.1029/2001GC000168
   Bell David G., 2007, 2007 IEEE Aerospace Conference, P1, DOI 10.1109/AERO.2007.352954
   Bernardin T, 2011, COMPUT GEOSCI-UK, V37, P75, DOI 10.1016/j.cageo.2010.02.006
   Bladin K, 2018, IEEE T VIS COMPUT GR, V24, P802, DOI 10.1109/TVCG.2017.2743958
   Bock A, 2020, IEEE T VIS COMPUT GR, V26, P633, DOI 10.1109/TVCG.2019.2934259
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bourke P. D, 2012, P BOURKE PERSONA JUL
   Bourke Paul, 2009, P COMP GAM ALL TECHN, V1, P265
   Brooks S, 2008, COMPUT ENVIRON URBAN, V32, P278, DOI 10.1016/j.compenvurbsys.2007.11.001
   Brovelli MA, 2017, INT J DIGIT EARTH, V10, P386, DOI 10.1080/17538947.2016.1196505
   Butterworth T., 2018, SYPHON FRAMEWORK
   Chang Kang-TSUNG., 2018, INTRO GEOGRAPHIC INF, V9th
   Chen QY, 2018, EARTH SCI INFORM, V11, P591, DOI 10.1007/s12145-018-0350-x
   Cho I., 2014, PROC STEREOSCOPIC DI, DOI [10.1117/12.2037942, DOI 10.1117/12.2037942]
   Coltekin A., 2017, INT J CARTOGR, V3, P115, DOI [10.1080/23729333.2017.1302910, DOI 10.1080/23729333.2017.1302910]
   Connors M. G., 2009, AGU FALL M ABSTR, V54
   Cozzi Patrick., 2011, 3D engine design for virtual globes
   Davies DR, 2012, EARTH PLANET SC LETT, V353, P253, DOI 10.1016/j.epsl.2012.08.016
   De Paor DG, 2011, COMPUT GEOSCI-UK, V37, P100, DOI 10.1016/j.cageo.2010.05.003
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Duncombe J., 2019, Eos, DOI [10.1029/2019EO117193, DOI 10.1029/2019EO117193]
   DZIEWONSKI AM, 1987, SCIENCE, V236, P37, DOI 10.1126/science.236.4797.37
   DZIEWONSKI AM, 1981, PHYS EARTH PLANET IN, V25, P297, DOI 10.1016/0031-9201(81)90046-7
   Elwood S, 2009, PROG HUM GEOG, V33, P256, DOI 10.1177/0309132508094076
   Engel K, 2006, Real-Time Volume Graphics
   Englund R, 2018, COMPUT GRAPH FORUM, V37, P174, DOI 10.1111/cgf.13320
   ESRI, 2019, ARCGIS EARTH
   Fowler C. M. R., 2008, SOLID EARTH INTRO GL, V2nd
   Frey Steffen, 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P123, DOI 10.1109/SIBGRAPI.2013.26
   Gavrilescu M, 2011, ENVIRON ENG MANAG J, V10, P567, DOI 10.30638/eemj.2011.079
   Graciano A, 2018, ADV ENG SOFTW, V115, P314, DOI 10.1016/j.advengsoft.2017.10.002
   Haklay M. M, 2010, INTERACTING GEOSPATI
   Hansen C. D., 2005, VISUALIZATION HDB
   Hibbard William., 1989, Proceedings of the 1989Chapel Hill Workshop on Volume Visualization, VVS '89, P39, DOI DOI 10.1145/329129.329356
   Hosseini K, 2018, GEOCHEM GEOPHY GEOSY, V19, P1464, DOI 10.1029/2018GC007431
   Huang Q, COMPUT GEOSCI, V59, P41
   Jadamec MA, 2018, EARTH SPACE SCI, V5, P240, DOI 10.1002/2017EA000349
   Kaufman A.E., 2005, Vis. Handb, V7, P127, DOI DOI 10.1016/B978-012387582-2/50009-5
   Li S, 2014, P 2014 VIRT REAL INT, P8
   Liang JM, 2018, ISPRS J PHOTOGRAMM, V146, P91, DOI 10.1016/j.isprsjprs.2018.08.019
   Limaye A, 2012, PROC SPIE, V8506, DOI 10.1117/12.935640
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   MacEachren Alan M, 2001, Cartography and geographic information science, V28, P3, DOI [10.1559/152304001782173970., DOI 10.1559/152304001782173970, 10.1559/152304001782173970]
   MARRIOTT K, 2018, CHAP IMMERSIVE ANAL, P25
   McCann M.P., 2004, Web3D'04: Proceedings of the ninth international conference on 3D Web technology, P15
   Mobeen MM, 2012, IEEE I C EMBED SOFTW, P381, DOI 10.1109/HPCC.2012.58
   Montelli R, 2006, GEOCHEM GEOPHY GEOSY, V7, DOI 10.1029/2006GC001248
   Morse P. E., 2020, **DATA OBJECT**, DOI 10.5281/zenodo.3264036
   Morse PE, 2019, FRONT EARTH SC-SWITZ, V7, DOI 10.3389/feart.2019.00274
   Müller RD, 2018, GEOCHEM GEOPHY GEOSY, V19, P2243, DOI 10.1029/2018GC007584
   Müller RD, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150883
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murray D., 2009, PROC 25 C INT INTERA, V7
   Mwalongo F, 2016, COMPUT GRAPH FORUM, V35, P553, DOI 10.1111/cgf.12929
   Natali M., 2012, P EUR 2013 STAT ART, P155, DOI DOI 10.2312/CONF/EG2013/STARS/155-173
   Nöllenburg M, 2007, LECT NOTES COMPUT SC, V4417, P257
   Plesch A, 2015, WEB3D 2015, P31, DOI 10.1145/2775292.2775315
   Raman S, 2008, PROC EUROGRAPHICSIEE
   Ranalli G., 1995, Rheology of the Earth
   Rautek P, 2007, IEEE T VIS COMPUT GR, V13, P1336, DOI 10.1109/TVCG.2007.70591
   Rawlinson N, 2010, PHYS EARTH PLANET IN, V178, P101, DOI 10.1016/j.pepi.2009.10.002
   Ritsema J, 2011, GEOPHYS J INT, V184, P1223, DOI 10.1111/j.1365-246X.2010.04884.x
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Simmons NA, 2010, J GEOPHYS RES-SOL EA, V115, DOI 10.1029/2010JB007631
   Smit N, 2019, ADV EXP MED BIOL, V1156, P85, DOI 10.1007/978-3-030-19385-0_6
   Sokol J, 2020, QUANTA MAGAZINE JAN
   Stl T., 2020, Journal of Open Research Software, V8, P1, DOI [10.5334/JORS.287, DOI 10.5334/JORS.287]
   Stoecker J. W, 2011, THESIS U MIAMI
   Svakhine N, 2005, IEEE COMPUT GRAPH, V25, P31, DOI 10.1109/MCG.2005.60
   TELEA A., 2007, DATA VISUALIZATION P
   Tikhonova A, 2010, IEEE PAC VIS SYMP, P177, DOI 10.1109/PACIFICVIS.2010.5429595
   Turner AK, 2006, B ENG GEOL ENVIRON, V65, P109, DOI 10.1007/s10064-005-0015-0
   Van Krevelen D., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10.20870/ijvr.2010.9.2.2767
   Wang L., 2008, VOLUME GRAPHICS, P33
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Ward M.O., 2015, INTERACTIVE DATA VIS
   Wawrzyniec TF, 2007, GEOSPHERE, V3, P406, DOI 10.1130/GES00156.1
   Westermann R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P169, DOI 10.1145/280814.280860
   Wilford J, 1999, AGSO RES NEWSLETT, V31
   Yamagishi Y, 2010, COMPUT GEOSCI-UK, V36, P373, DOI 10.1016/j.cageo.2009.08.007
   Yu L, 2012, INT J REMOTE SENS, V33, P3966, DOI 10.1080/01431161.2011.636081
   Zhu LF, 2014, FRONT EARTH SCI-PRC, V8, P524, DOI 10.1007/s11707-014-0438-7
   Ziolkowska JR, 2016, COMPUT GEOSCI-UK, V94, P31, DOI 10.1016/j.cageo.2016.06.003
   Zotti G., 2020, STELLARIUM USER GUID
NR 93
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2641
EP 2653
DI 10.1109/TVCG.2020.3037226
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400008
PM 33170779
DA 2024-11-06
ER

PT J
AU Qian, L
   Song, TY
   Unberath, M
   Kazanzides, P
AF Qian, Long
   Song, Tianyu
   Unberath, Mathias
   Kazanzides, Peter
TI AR-Loupe: Magnified Augmented Reality by Combining an Optical
   See-Through Head-Mounted Display and a Loupe
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; vision augmentation; optical see-through head-mounted
   display; calibration
ID ENHANCED STEREOSCOPIC VISION; CALIBRATION; COMPENSATION; OCCLUSION
AB Head-mounted loupes can increase the user's visual acuity to observe the details of an object. On the other hand, optical see-through head-mounted displays (OST-HMD) are able to provide virtual augmentations registered with real objects. In this article, we propose AR-Loupe, combining the advantages of loupes and OST-HMDs, to offer augmented reality in the user's magnified field-of-vision. Specifically, AR-Loupe integrates a commercial OST-HMD, Magic Leap One, and binocular Galilean magnifying loupes, with customized 3D-printed attachments. We model the combination of user's eye, screen of OST-HMD, and the optical loupe as a pinhole camera. The calibration of AR-Loupe involves interactive view segmentation and an adapted version of stereo single point active alignment method (Stereo-SPAAM). We conducted a two-phase multi-user study to evaluate AR-Loupe. The users were able to achieve sub-millimeter accuracy (0'82 mm) on average, which is significantly (p < 0.001) smaller compared to normal AR guidance (1.49 mm). The mean calibration time was 268.46 s. With the increased size of real objects through optical magnification and the registered augmentation, AR-Loupe can aid users in high-precision tasks with better visual acuity and higher accuracy.
C1 [Qian, Long; Song, Tianyu; Kazanzides, Peter] Johns Hopkins Univ, Baltimore, MD 21218 USA.
   [Unberath, Mathias] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.
   [Kazanzides, Peter] Johns Hopkins Univ, Comp Sci, Baltimore, MD 21218 USA.
C3 Johns Hopkins University; Johns Hopkins University; Johns Hopkins
   University
RP Qian, L (corresponding author), Johns Hopkins Univ, Baltimore, MD 21218 USA.
EM long.qian@jhu.edu; tsong11@jhu.edu; unberath@jhu.edu; pkaz@jhu.edu
RI Kazanzides, Peter/A-3358-2010
OI Qian, Long/0000-0002-5509-0379; Song, Tianyu/0000-0002-8428-9651
FU JHU Internal Funds
FX The authors would like to thank Magic Leap Inc., for loaning the Magic
   Leap One device for two months. This work was supported by JHU Internal
   Funds.
CR Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   Ardouin J., 2012, P ACM S VIRTUAL REAL, P41
   Bakshi AM, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811556
   Birkfellner W, 2003, PHYS MED BIOL, V48, pN49, DOI 10.1088/0031-9155/48/3/402
   Birkfellner W, 2000, LECT NOTES COMPUT SC, V1935, P869
   Birkfellner W, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P54, DOI 10.1109/ISAR.2000.880923
   Deemer AD, 2018, OPTOMETRY VISION SCI, V95, P694, DOI 10.1097/OPX.0000000000001278
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Fan K., 2014, PROC AH, DOI [10.1145/2582051.2582100, DOI 10.1145/2582051.2582100]
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   Figl M, 2005, IEEE T MED IMAGING, V24, P1492, DOI 10.1109/TMI.2005.856746
   Genc Y, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P169, DOI 10.1109/ISMAR.2002.1115086
   Genc Y, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P165, DOI 10.1109/ISAR.2000.880940
   Grubert J, 2018, IEEE T VIS COMPUT GR, V24, P2649, DOI 10.1109/TVCG.2017.2754257
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   HART S G, 1988, P139
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hecht E., 2001, Optics, V1
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Itoh Y, 2017, IEEE T VIS COMPUT GR, V23, P2463, DOI 10.1109/TVCG.2017.2734427
   Itoh Y, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P75, DOI 10.1109/3DUI.2014.6798846
   James Theresa, 2010, Dent Update, V37, P633
   Langlotz T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173964
   Langlotz T, 2016, IEEE T VIS COMPUT GR, V22, P2385, DOI 10.1109/TVCG.2016.2593781
   Liu C, 2018, INT SYM MIX AUGMENT, P98, DOI 10.1109/ISMAR.2018.00037
   Mamoun J., 2013, TECHNICAL ASPECTS CL
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Martin-Gonzalez A, 2009, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2009.5336459
   MASSOF RW, 1992, OPTOMETRY VISION SCI, V69, P32, DOI 10.1097/00006324-199201000-00005
   Miyaki T., 2016, PROC ACM SIGGRAPH EM
   Moser K, 2015, IEEE T VIS COMPUT GR, V21, P491, DOI 10.1109/TVCG.2015.2391856
   OGLE KN, 1952, AMA ARCH OPHTHALMOL, V48, P50
   Orlosky J., 2014, P ACM S SPATIAL USER, P54, DOI DOI 10.1145/2659766.2659771
   Orlosky J, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P22, DOI 10.1109/ISMAR.2017.19
   Orlosky J, 2015, IEEE T VIS COMPUT GR, V21, P1259, DOI 10.1109/TVCG.2015.2459852
   Owen CB, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P70, DOI 10.1109/ISMAR.2004.28
   Peli E, 2001, OPTOMETRY VISION SCI, V78, P304, DOI 10.1097/00006324-200105000-00014
   Peli E., 1994, OPTOMETRY VIS SCI, V71, P21
   Peli E., 1994, P 2 INT C VIRT REAL, P115
   Perrin Philippe, 2016, Swiss Dent J, V126, P222
   Plopski A, 2015, IEEE T VIS COMPUT GR, V21, P481, DOI 10.1109/TVCG.2015.2391857
   Qian L, 2018, IEEE T VIS COMPUT GR, V24, P2936, DOI 10.1109/TVCG.2018.2868559
   Qian L, 2017, INT J COMPUT ASS RAD, V12, P901, DOI 10.1007/s11548-017-1564-y
   Qian L, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P154, DOI [10.1109/ISMAR-Adjunct.2016.57, 10.1109/ISMAR-Adjunct.2016.0065]
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   ROSEN E, 1956, J Hist Med Allied Sci, V11, P13
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Stearns L, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P28, DOI 10.1145/3234695.3236361
   Sutherland I. E., 1968, P DEC 9 11 1968 FA 1, P757, DOI [https://doi.org/10.1145/1476589.1476686, DOI 10.1145/1476589.1476686]
   Sutton J, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P438, DOI 10.1109/ISMAR-Adjunct.2019.00050
   Tuceryan M, 2002, PRESENCE-TELEOP VIRT, V11, P259, DOI 10.1162/105474602317473213
   Urlic I, 2016, ACTA STOMATOL CROAT, V50, P235, DOI 10.15644/asc50/3/6
   Vargas-Martín F, 2002, OPTOMETRY VISION SCI, V79, P715, DOI 10.1097/00006324-200211000-00009
   Wanschitz F, 2002, CLIN ORAL IMPLAN RES, V13, P610, DOI 10.1034/j.1600-0501.2002.130606.x
   Wei C, 2018, CAN J OPHTHALMOL, V53, P139, DOI 10.1016/j.jcjo.2017.08.011
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28
NR 57
TC 17
Z9 21
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2550
EP 2562
DI 10.1109/TVCG.2020.3037284
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400001
PM 33170780
DA 2024-11-06
ER

PT J
AU Bok, J
   Kim, B
   Seo, J
AF Bok, Jinwook
   Kim, Bohyoung
   Seo, Jinwook
TI Augmenting Parallel Coordinates Plots With Color-Coded Stacked
   Histograms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Histograms; Image color analysis; Visualization; Bars; Data
   visualization; Correlation; Layout; Parallel coordinates plots; parallel
   histogram plots; color-coded stacked histogram
ID VISUAL ANALYSIS; VISUALIZATION; EXPLORATION
AB We introduce Parallel Histogram Plot (PHP), a technique that overcomes the innate limitations of parallel coordinates plot (PCP) by attaching stacked-bar histograms with discrete color schemes to PCP. The color-coded histograms enable users to see an overview of the whole data without cluttering or scalability issues. Each rectangle in the PHP histograms is color coded according to the data ranking by a selected attribute. This color-coding scheme allows users to visually examine relationships between attributes, even between those that are displayed far apart, without repositioning or reordering axes. We adopt the Visual Information Seeking Mantra so that the polylines of the original PCP can be used to show details of a small number of selected items when the cluttering problem subsides. We also design interactions, such as a focus+context technique, to help users investigate small regions of interest in a space-efficient manner. We provide a real-world example in which PHP is effectively utilized compared with other visualizations, and we perform a controlled user study to evaluate the performance of PHP in helping users estimate the correlation between attributes. The results demonstrate that the performance of PHP was consistent in the estimation of correlations between two attributes regardless of the distance between them.
C1 [Bok, Jinwook; Seo, Jinwook] Seoul Natl Univ, Seoul 08826, South Korea.
   [Kim, Bohyoung] Hankuk Univ Foreign Studies, Seoul 08826, South Korea.
C3 Seoul National University (SNU); Hankuk University Foreign Studies
RP Seo, J (corresponding author), Seoul Natl Univ, Seoul 08826, South Korea.; Kim, B (corresponding author), Hankuk Univ Foreign Studies, Seoul 08826, South Korea.
EM bok@hcil.snu.ac.kr; bkim@hufs.ac.kr; jseo@snu.ac.kr
OI Bok, Jinwook/0000-0001-6912-6101
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1A2C2089062, NRF-2019R1A2C1088900]; ICT at Seoul National
   University
FX This work was supported by the National Research Foundation of Korea
   (NRF) grants funded by the Korea government (MSIT) under Grant Nos.
   NRF-2019R1A2C2089062 and NRF-2019R1A2C1088900). The research facilities
   for this study was provided by ICT at Seoul National University. The
   authors would like to thank all the participants of the experiments.
CR [Anonymous], 1987, COMPUTER GRAPHICS 19
   [Anonymous], 2018, FANGRAPHS BASEBALL
   [Anonymous], 2018, COLORBREWER
   [Anonymous], 2018, UCI MACHINE LEARNING
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P81, DOI 10.1109/INFVIS.2004.68
   Bok J., 2020, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2020.3038446
   Claessen JHT, 2011, IEEE T VIS COMPUT GR, V17, P2310, DOI 10.1109/TVCG.2011.201
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Dasgupta A, 2010, IEEE T VIS COMPUT GR, V16, P1017, DOI 10.1109/TVCG.2010.184
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Fanea E, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P149, DOI 10.1109/INFVIS.2005.1532141
   Geng Z, 2011, IEEE T VIS COMPUT GR, V17, P2572, DOI 10.1109/TVCG.2011.166
   Guo HQ, 2012, IEEE T VIS COMPUT GR, V18, P1397, DOI 10.1109/TVCG.2012.80
   Hauser H, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P127, DOI 10.1109/INFVIS.2002.1173157
   Heinrich Julian, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P594
   Heinrich J., 2013, EUROGRAPHICS STATE A, P95, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/CONF/EG2013/STARS/095-116]
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Itoh T, 2017, J VISUAL LANG COMPUT, V43, P1, DOI 10.1016/j.jvlc.2017.03.001
   Janetzko H., 2016, Electron. Imag., V28, P1, DOI [10.2352/ISSN.2470-1173.2016.1.VDA-486, DOI 10.2352/ISSN.2470-1173.2016.1.VDA-486]
   Johansson J., 2006, Information Visualization, V5, P125, DOI 10.1057/palgrave.ivs.9500117
   Johansson J, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P188, DOI 10.1109/IV.2005.1
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Keim DA, 2007, IEEE T VIS COMPUT GR, V13, P822, DOI 10.1109/TVCG.2007.1023
   Kobayashi H., 2014, PROC 18 INT C INF VI
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Lu LF, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 2, P252, DOI 10.1109/ICMLA.2012.148
   McDonnell KT, 2008, COMPUT GRAPH FORUM, V27, P1031, DOI 10.1111/j.1467-8659.2008.01239.x
   Nguyen Hoa, 2018, IEEE Trans Vis Comput Graph, V24, P1301, DOI 10.1109/TVCG.2017.2661309
   Nohno K, 2014, IEEE INT CONF INF VI, P7, DOI 10.1109/IV.2014.60
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Peng W, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P89
   Qu H, 2007, IEEE T VIS COMPUT GR, V13, P1408, DOI 10.1109/TVCG.2007.70523
   Raidou RG, 2016, IEEE T VIS COMPUT GR, V22, P589, DOI 10.1109/TVCG.2015.2467872
   RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776
   Roberts RC, 2019, IEEE T VIS COMPUT GR, V25, P1575, DOI 10.1109/TVCG.2018.2808969
   Seo J, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P65
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Long TV, 2015, PROC INT CONF ADV, P297, DOI 10.1109/ATC.2015.7388338
   Tweedie L., 1995, C COMPANION HUMAN FA, P129, DOI DOI 10.1145/223355.223464
   Tweedie Lisa., 1994, C COMPANION HUMAN FA, P435, DOI DOI 10.1145/259963.260433
   Walker J.C.F., 2012, Primary Wood Processing: Principles and Practice, V2nd, P43
   Walker Rick, 2013, 2013 17th International Conference on Information Visualisation, P36, DOI 10.1109/IV.2013.101
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105
   Ying-Huey Fua, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P43, DOI 10.1109/VISUAL.1999.809866
   Yuan XR, 2009, IEEE T VIS COMPUT GR, V15, P1001, DOI 10.1109/TVCG.2009.179
   Zhang ZY, 2012, IEEE PAC VIS SYMP, P17
NR 48
TC 3
Z9 3
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2563
EP 2576
DI 10.1109/TVCG.2020.3038446
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400002
PM 33201820
OA hybrid
DA 2024-11-06
ER

PT J
AU Berton, F
   Grzeskowiak, F
   Bonneau, A
   Jovane, A
   Aggravi, M
   Hoyet, L
   Olivier, AH
   Pacchierotti, C
   Pettré, J
AF Berton, Florian
   Grzeskowiak, Fabien
   Bonneau, Alexandre
   Jovane, Alberto
   Aggravi, Marco
   Hoyet, Ludovic
   Olivier, Anne-Helene
   Pacchierotti, Claudio
   Pettre, Julien
TI Crowd Navigation in VR: Exploring Haptic Rendering of Collisions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Rendering (computer graphics); Navigation; Task
   analysis; Solid modeling; Virtual environments; Trajectory; Crowd; human
   interaction; haptic rendering; virtual reality
ID VISUALLY CONTROLLED LOCOMOTION; AVOIDANCE BEHAVIOR
AB Virtual reality (VR) is a valuable experimental tool for studying human movement, including the analysis of interactions during locomotion tasks for developing crowd simulation algorithms. However, these studies are generally limited to distant interactions in crowds, due to the difficulty of rendering realistic sensations of collisions in VR. In this article, we explore the use of wearable haptics to render contacts during virtual crowd navigation. We focus on the behavioral changes occurring with or without haptic rendering during a navigation task in a dense crowd, as well as on potential after-effects introduced by the use haptic rendering. Our objective is to provide recommendations for designing VR setup to study crowd navigation behavior. To the end, we designed an experiment (N=23) where participants navigated in a crowded virtual train station without, then with, and then again without haptic feedback of their collisions with virtual characters. Results show that providing haptic feedback improved the overall realism of the interaction, as participants more actively avoided collisions. We also noticed a significant after-effect in the users' behavior when haptic rendering was once again disabled in the third part of the experiment. Nonetheless, haptic feedback did not have any significant impact on the users' sense of presence and embodiment.
C1 [Berton, Florian; Grzeskowiak, Fabien; Bonneau, Alexandre; Jovane, Alberto; Aggravi, Marco; Hoyet, Ludovic; Olivier, Anne-Helene; Pacchierotti, Claudio; Pettre, Julien] Univ Rennes, CNRS, INRIA, M2S,IRISA, F-35000 Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Inria
RP Berton, F (corresponding author), Univ Rennes, CNRS, INRIA, M2S,IRISA, F-35000 Rennes, France.
EM florian.berton@inria.fr; fabien.grzeskowiak@inria.fr;
   alexandre.bonneau@ens-rennes.fr; alberto.jovane@inria.fr;
   marco.aggravi@irisa.fr; ludovic.hoyet@inria.fr;
   anne-helene.olivier@univ-rennes2.fr; claudio.pacchierotti@irisa.fr;
   julien.pettre@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023; Olivier, Anne-Hélène/AAH-7378-2020;
   Jovane, Alberto/JDV-6916-2023; Pettré, Julien/AAB-2590-2022; Aggravi,
   Marco/ABB-7474-2020; Pacchierotti, Claudio/G-7304-2011
OI Pettre, Julien/0000-0003-1812-1436; Aggravi, Marco/0000-0001-7911-426X;
   Olivier, Anne-Helene/0000-0002-2833-020X; Pacchierotti,
   Claudio/0000-0002-8006-9168; Jovane, Alberto/0000-0002-3880-3656; Hoyet,
   Ludovic/0000-0002-7373-6049
FU European Union [779942, 856879]; ANR OPMoPS Project [ANR-16-SEBM-0004];
   Agence Nationale de la Recherche (ANR) [ANR-16-SEBM-0004] Funding
   Source: Agence Nationale de la Recherche (ANR)
FX This project has received funding from the European Union's Horizon 2020
   research and innovation programme under Grant 779942 Crowdbot and Grant
   856879 PRESENT, as well as from the ANR OPMoPS Project
   (ANR-16-SEBM-0004).
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Aggravi Marco, 2018, IEEE Robotics and Automation Letters, V3, P2166, DOI 10.1109/LRA.2018.2810887
   Benjamin S, 2017, IEEE T HAPTICS, V10, P418, DOI 10.1109/TOH.2017.2672969
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Bimbo J, 2017, IEEE INT C INT ROBOT, P3401, DOI 10.1109/IROS.2017.8206180
   Bönsch A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P199
   Bonneaud S., 2012, Trans. Edutainment, V7, P1, DOI DOI 10.1007/978-3-642-29050-3_1
   Bourgaize SM, 2021, J MOTOR BEHAV, V53, P166, DOI 10.1080/00222895.2020.1742083
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Chattaraj U, 2009, ADV COMPLEX SYST, V12, P393, DOI 10.1142/S0219525909002209
   CHEW LP, 1989, ALGORITHMICA, V4, P97, DOI 10.1007/BF01553881
   Chinello F, 2020, IEEE T IND ELECTRON, V67, P706, DOI 10.1109/TIE.2019.2899551
   Chinello F, 2018, IEEE T HAPTICS, V11, P39, DOI 10.1109/TOH.2017.2755015
   Chinello F, 2018, IEEE ROBOT AUTOM LET, V3, P524, DOI 10.1109/LRA.2017.2766244
   Cho SH, 2004, CLIN BIOMECH, V19, P145, DOI 10.1016/j.clinbiomech.2003.10.003
   Cirio G, 2013, IEEE T VIS COMPUT GR, V19, P671, DOI 10.1109/TVCG.2013.34
   Croft JL, 2018, J MOTOR BEHAV, V50, P353, DOI 10.1080/00222895.2017.1363695
   Devigne L, 2020, IEEE T HAPTICS, V13, P52, DOI 10.1109/TOH.2019.2963831
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Faure C., 2019, THESIS U LAVAL CANAD
   GIBSON JJ, 1958, BRIT J PSYCHOL, V49, P182, DOI 10.1111/j.2044-8295.1958.tb00656.x
   Hessels RS, 2020, ATTEN PERCEPT PSYCHO, V82, P2482, DOI 10.3758/s13414-019-01952-9
   Huang PH, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1818
   Huber M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089589
   Knorr AG, 2016, J EXP PSYCHOL HUMAN, V42, P1332, DOI 10.1037/xhp0000223
   Krogmeier C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1032, DOI [10.1109/VR.2019.8798139, 10.1109/vr.2019.8798139]
   Krum DM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P223, DOI 10.1109/VR.2018.8446235
   Lindeman R. W., 2006, Virtual Reality, V9, P203, DOI DOI 10.1007/S10055-005-0010-6
   Lindeman R.W., 2004, ACM Symposium on Virtual Reality Software and Technology, P146, DOI DOI 10.1145/1077534.1077562
   Louison C, 2018, INT J HUM-COMPUT INT, V34, P1015, DOI 10.1080/10447318.2017.1411665
   Lynch SD, 2018, IEEE T VIS COMPUT GR, V24, P2078, DOI 10.1109/TVCG.2017.2718514
   Mestre Daniel R., 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P222, DOI 10.1007/978-3-319-39516-6_21
   Olivier AH, 2018, IEEE T VIS COMPUT GR, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Olivier AH, 2013, GAIT POSTURE, V38, P751, DOI 10.1016/j.gaitpost.2013.03.017
   Olivier AH, 2012, GAIT POSTURE, V36, P399, DOI 10.1016/j.gaitpost.2012.03.021
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Patla AE, 1997, GAIT POSTURE, V5, P54, DOI 10.1016/S0966-6362(96)01109-5
   Rio K, 2014, TRANSP RES PROC, V2, P132, DOI 10.1016/j.trpro.2014.09.017
   Rio KW, 2018, P ROY SOC B-BIOL SCI, V285, DOI 10.1098/rspb.2018.0611
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salazar SV, 2020, IEEE T HAPTICS, V13, P167, DOI 10.1109/TOH.2020.2967389
   Scheggi S, 2017, IEEE T HUM-MACH SYST, V47, P462, DOI 10.1109/THMS.2016.2608936
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Silva WS, 2018, GAIT POSTURE, V61, P294, DOI 10.1016/j.gaitpost.2018.01.028
   Slater M, 2003, Presence Conn, V3, P1
   So rensen T., 1948, Kong Dan Vidensk Selsk Biol. Skr, V5, P1
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Warren WH Jr, 1998, ECOL PSYCHOL, V10, P177, DOI 10.1207/s15326969eco103&4_3
   Wilmut K, 2010, HUM MOVEMENT SCI, V29, P289, DOI 10.1016/j.humov.2010.01.001
NR 51
TC 17
Z9 17
U1 2
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2589
EP 2601
DI 10.1109/TVCG.2020.3041341
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400004
PM 33253117
OA Green Published
DA 2024-11-06
ER

PT J
AU Jönsson, D
   Kronander, J
   Unger, J
   Schön, TB
   Wrenninge, M
AF Jonsson, Daniel
   Kronander, Joel
   Unger, Jonas
   Schon, Thomas B.
   Wrenninge, Magnus
TI Direct Transmittance Estimation in Heterogeneous Participating Media
   Using Approximated Taylor Expansions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Media; Taylor series; Rendering (computer graphics); Estimation; Upper
   bound; Monte Carlo methods; Path tracing; rendering; computer graphics;
   scientific visualization
AB Evaluating the transmittance between two points along a ray is a key component in solving the light transport through heterogeneous participating media and entails computing an intractable exponential of the integrated medium's extinction coefficient. While algorithms for estimating this transmittance exist, there is a lack of theoretical knowledge about their behaviour, which also prevent new theoretically sound algorithms from being developed. For this purpose, we introduce a new class of unbiased transmittance estimators based on random sampling or truncation of a Taylor expansion of the exponential function. In contrast to classical tracking algorithms, these estimators are non-analogous to the physical light transport process and directly sample the underlying extinction function without performing incremental advancement. We present several versions of the new class of estimators, based on either importance sampling or Russian roulette to provide finite unbiased estimators of the infinite Taylor series expansion. We also show that the well known ratio tracking algorithm can be seen as a special case of the new class of estimators. Lastly, we conduct performance evaluations on both the central processing unit (CPU) and the graphics processing unit (GPU), and the results demonstrate that the new algorithms outperform traditional algorithms for heterogeneous mediums.
C1 [Jonsson, Daniel; Kronander, Joel; Unger, Jonas] Linkoping Univ, S-58183 Linkoping, Sweden.
   [Schon, Thomas B.] Uppsala Univ, S-75236 Uppsala, Sweden.
   [Wrenninge, Magnus] Pixar Animat Studios, Emeryville, CA 94608 USA.
C3 Linkoping University; Uppsala University
RP Jönsson, D (corresponding author), Linkoping Univ, S-58183 Linkoping, Sweden.
EM daniel.jonsson@liu.se; joelkronander@gmail.com; jonas.unger@liu.se;
   thomas.schon@it.uu.se; magnus.wrenninge@gmail.com
RI Ribeiro, Antônio/AAE-1948-2019; Schon, Thomas/D-4169-2009
OI Jonsson, Daniel/0000-0002-5220-633X; Unger, Jonas/0000-0002-7765-1747;
   Schon, Thomas/0000-0001-5183-234X
FU Knut and Alice Wallenberg Foundation (KAW) [2013-0076]; SeRC (Swedish
   e-Science Research Center); Wallenberg AI, Autonomous Systems and
   Software Program (WASP); Swedish Foundation for Strategic Research (SSF)
   via the project ASSEMBLE [RIT15-0012]; ELLIIT environment for strategic
   research in Sweden; Swedish Foundation for Strategic Research (SSF)
   [RIT15-0012] Funding Source: Swedish Foundation for Strategic Research
   (SSF)
FX The authors would like to thank Ryusuke Villemin for providing valuable
   input to the work. This work was supported through grants 'Seeing Organ
   Function' from the Knut and Alice Wallenberg Foundation (KAW) under
   grant 2013-0076, the SeRC (Swedish e-Science Research Center),
   Wallenberg AI, Autonomous Systems and Software Program (WASP), the
   Swedish Foundation for Strategic Research (SSF) via the project ASSEMBLE
   (contract number: RIT15-0012) and the ELLIIT environment for strategic
   research in Sweden.
CR ANDREO P, 1991, PHYS MED BIOL, V36, P861, DOI 10.1088/0031-9155/36/7/001
   Beskos A, 2006, J R STAT SOC B, V68, P333, DOI 10.1111/j.1467-9868.2006.00552.x
   Brown F.B., 2003, P ANS MATH COMP TOP
   Carter L. L., 1975, Particle transport simulation with the Monte Carlo method
   COLEMAN WA, 1968, NUCL SCI ENG, V32, P76, DOI 10.13182/NSE68-1
   Fearnhead P, 2008, J R STAT SOC B, V70, P755, DOI 10.1111/j.1467-9868.2008.00661.x
   Fong J., 2017, P ACM SIGGRAPH COURS
   Gallager R. G., 2013, Stochastic Processes: Theory for Applications
   Georgiev I, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356559
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Kutz P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073665
   Lyne AM, 2015, STAT SCI, V30, P443, DOI 10.1214/15-STS523
   McLeish D., 2010, ARXIV10052228
   Morgan LWG, 2015, ANN NUCL ENERGY, V85, P1184, DOI 10.1016/j.anucene.2015.07.038
   Novák J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661292
   Owen Art B., 2013, Monte Carlo theory, methods and examples
   Pharr M., 2016, Physically based rendering: From theory to implementation
   Salvat F, 2006, PENELOPE CODE SYSTEM
   SKULLERUD HR, 1968, J PHYS D APPL PHYS, V1, P1567, DOI 10.1088/0022-3727/1/11/423
   SPANIER J., 2008, MONTE CARLO PRINCIPL
   Studios P. A, 2018, J COMPUT GRAPH TECHN, V7, P50
   Szirmay-Kalos L, 2017, COMPUT GRAPH FORUM, V36, P9, DOI 10.1111/cgf.13102
   Szirmay-Kalos L, 2011, COMPUT GRAPH FORUM, V30, P85, DOI 10.1111/j.1467-8659.2010.01831.x
   Woodcock E., 1965, P C APPL COMP METH R, P557
   Yue YH, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866199
NR 26
TC 5
Z9 5
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2602
EP 2614
DI 10.1109/TVCG.2020.3035516
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400005
PM 33141672
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hu, JB
   Wang, SF
   Li, BJ
   Li, FQ
   Luo, ZX
   Liu, LG
AF Hu, Jiangbei
   Wang, Shengfa
   Li, Baojun
   Li, Fengqi
   Luo, Zhongxuan
   Liu, Ligang
TI Efficient Representation and Optimization for TPMS-Based Porous
   Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Topology; Periodic structures; Geometry; Three-dimensional
   printing; Solid modeling; Three-dimensional displays; Porous
   optimization; function description; triply periodic minimal surface
ID SCAFFOLD DESIGN; SHAPE; STIFFNESS; DENSITY
AB In this approach, we present an efficient topology and geometry optimization of triply periodic minimal surfaces (TPMS) based porous shell structures, which can be represented, analyzed, optimized and stored directly using functions. The proposed framework is directly executed on functions instead of remeshing (tetrahedral/hexahedral), and this framework substantially improves the controllability and efficiency. Specifically, a valid TPMS-based porous shell structure is first constructed by function expressions. The porous shell permits continuous and smooth changes of geometry (shell thickness) and topology (porous period). The porous structures also inherit several of the advantageous properties of TPMS, such as smoothness, full connectivity (no closed hollows), and high controllability. Then, the problem of filling an object's interior region with porous shell can be formulated into a constraint optimization problem with two control parameter functions. Finally, an efficient topology and geometry optimization scheme is presented to obtain optimized scale-varying porous shell structures. In contrast to traditional heuristic methods for TPMS, our work directly optimize both the topology and geometry of TPMS-based structures. Various experiments have shown that our proposed porous structures have obvious advantages in terms of efficiency and effectiveness.
C1 [Hu, Jiangbei] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Liaoning, Peoples R China.
   [Wang, Shengfa] Dalian Univ Technol, DUT RU Int Sch Informat & Software Engn, Dalian 116024, Liaoning, Peoples R China.
   [Wang, Shengfa] Dalian Univ Technol, Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116024, Liaoning, Peoples R China.
   [Li, Baojun] Dalian Univ Technol, Inst Automot Digitalizat, Dalian 116024, Liaoning, Peoples R China.
   [Li, Fengqi; Luo, Zhongxuan] Dalian Univ Technol, Sch Software Technol, Dalian 116024, Liaoning, Peoples R China.
   [Luo, Zhongxuan] Guilin Univ Elect Technol, Inst Artificial Intelligence, Guilin 541004, Guangxi, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology; Dalian University of Technology; Dalian
   University of Technology; Guilin University of Electronic Technology;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Wang, SF (corresponding author), Dalian Univ Technol, DUT RU Int Sch Informat & Software Engn, Dalian 116024, Liaoning, Peoples R China.; Wang, SF (corresponding author), Dalian Univ Technol, Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116024, Liaoning, Peoples R China.
EM 915642014@qq.com; sfwang@dlut.edu.cn; bjli@dlut.edu.cn;
   lifengqi@dlut.edu.cn; zxluo@dlut.edu.cn; lgliu@ustc.edu.cn
RI Li, FengQi/HLQ-1543-2023; Liu, Ligang/IZQ-5817-2023; Li,
   Baojun/H-6254-2018
OI li, fengqi/0000-0003-4056-548X
FU National Natural Science Foundation of China [61772104, 61720 106005,
   2017YF1103700]; Fundamental Research Funds for the Central Universities
   [DUT20JC32, DUT20TD107]
FX This work was partially supported by the National Natural Science
   Foundation of China under Grants 61772104, 61720 106005, 2017YF1103700,
   the Fundamental Research Funds for the Central Universities under Grants
   DUT20JC32, DUT20TD107.
CR Abueidda DW, 2016, MECH MATER, V95, P102, DOI 10.1016/j.mechmat.2016.01.004
   Allaire G, 1997, NUMER MATH, V76, P27, DOI 10.1007/s002110050253
   Andreassen E, 2014, COMP MATER SCI, V83, P488, DOI 10.1016/j.commatsci.2013.09.006
   Bächer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601157
   Bang B., 1999, Applications of Mathematics, V44, P309, DOI 10.1023/A:1023084614058
   Chai SM, 2018, GRAPH MODELS, V97, P80, DOI 10.1016/j.gmod.2018.04.002
   Coros S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461953
   CVIJOVIC D, 1992, J PHYS I, V2, P137, DOI 10.1051/jp1:1992129
   Feng JW, 2018, COMPUT METHOD APPL M, V336, P333, DOI 10.1016/j.cma.2018.03.007
   Groen JP, 2019, COMPUT METHOD APPL M, V349, P722, DOI 10.1016/j.cma.2019.02.031
   Guest JK, 2006, INT J SOLIDS STRUCT, V43, P7028, DOI 10.1016/j.ijsolstr.2006.03.001
   Guo X, 2005, CONTROL CYBERN, V34, P255
   Guo X, 2014, J APPL MECH-T ASME, V81, DOI 10.1115/1.4027609
   Hollister SJ, 2005, NAT MATER, V4, P518, DOI 10.1038/nmat1421
   Hornus S., 2018, P 39 ANN EUR ASS COM, P41
   Hu JB, 2019, VISUAL COMPUT, V35, P949, DOI 10.1007/s00371-019-01672-z
   Hu KL, 2015, COMPUT AIDED DESIGN, V65, P1, DOI 10.1016/j.cad.2015.03.001
   Kapfer SC, 2011, BIOMATERIALS, V32, P6875, DOI 10.1016/j.biomaterials.2011.06.012
   Kuipers T, 2019, COMPUT AIDED DESIGN, V114, P37, DOI 10.1016/j.cad.2019.05.003
   Lee M, 2018, COMPUT AIDED DESIGN, V101, P23, DOI 10.1016/j.cad.2018.03.007
   Li DW, 2019, J MECH DESIGN, V141, DOI 10.1115/1.4042617
   Li DW, 2016, INT J ADV MANUF TECH, V83, P1627, DOI 10.1007/s00170-015-7704-z
   Liu C, 2018, STRUCT MULTIDISCIP O, V58, P2455, DOI 10.1007/s00158-018-2114-0
   Lu L, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601168
   Martínez J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201343
   Martínez J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925922
   Melchels FPW, 2010, BIOMATERIALS, V31, P6909, DOI 10.1016/j.biomaterials.2010.05.068
   Nguyen TH, 2010, STRUCT MULTIDISCIP O, V41, P525, DOI 10.1007/s00158-009-0443-8
   Préost R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461957
   Rajagopalan S, 2005, LECT NOTES COMPUT SC, V3749, P794
   Rodrigues H, 2002, STRUCT MULTIDISCIP O, V24, P1, DOI 10.1007/s00158-002-0209-z
   Rosen D., 2006, Rapid Manuf. Conf, P1
   Savio G, 2019, PROG ADDIT MANUF, V4, P281, DOI 10.1007/s40964-019-00073-x
   Schroeder C, 2005, COMPUT AIDED DESIGN, V37, P339, DOI 10.1016/j.cad.2004.03.008
   Schumacher C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275085
   Shi JP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25750-9
   Sigmund O, 2016, STRUCT MULTIDISCIP O, V54, P361, DOI 10.1007/s00158-016-1420-7
   Skouras M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461979
   Stava O, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185544
   SVANBERG K, 1987, INT J NUMER METH ENG, V24, P359, DOI 10.1002/nme.1620240207
   Tricard T, 2020, COMPUT GRAPH FORUM, V39, P147, DOI 10.1111/cgf.13750
   Ulu E, 2019, COMPUT GRAPH FORUM, V38, P85, DOI 10.1111/cgf.13791
   Ulu E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073626
   Wang HQ, 2005, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2005, VOL 3, PTS A AND B, P421
   Wang L., 2016, Computer Graphics Forum, V35, P49, DOI 10.1111/cgf.12810
   Wang MY, 2003, COMPUT METHOD APPL M, V192, P227, DOI 10.1016/S0045-7825(02)00559-5
   Wang T. Y., 2016, J COMPUTER GRAPHICS, V5, P18
   Wang WM, 2018, IEEE T VIS COMPUT GR, V24, P2787, DOI 10.1109/TVCG.2017.2764462
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wang Y, 2007, COMPUT AIDED DESIGN, V39, P179, DOI 10.1016/j.cad.2006.09.005
   Wu J, 2018, IEEE T VIS COMPUT GR, V24, P1127, DOI 10.1109/TVCG.2017.2655523
   Wu J, 2016, COMPUT AIDED DESIGN, V80, P32, DOI 10.1016/j.cad.2016.07.006
   Wu J, 2016, IEEE T VIS COMPUT GR, V22, P1195, DOI 10.1109/TVCG.2015.2502588
   XIE YM, 1993, COMPUT STRUCT, V49, P885, DOI 10.1016/0045-7949(93)90035-C
   Yan X, 2020, IEEE T VIS COMPUT GR, V26, P3037, DOI 10.1109/TVCG.2019.2914044
   Yang N, 2014, MAT SCI ENG C-MATER, V43, P502, DOI 10.1016/j.msec.2014.07.052
   Yoo DJ, 2015, INT J PRECIS ENG MAN, V16, P2021, DOI 10.1007/s12541-015-0263-2
   Yoo DJ, 2009, INT J PRECIS ENG MAN, V10, P131, DOI 10.1007/s12541-009-0081-5
   Zhang H, 2017, COMPUT AIDED GEOM D, V52-53, P285, DOI 10.1016/j.cagd.2017.03.015
   Zhang WS, 2016, STRUCT MULTIDISCIP O, V53, P1243, DOI 10.1007/s00158-015-1372-3
   Zhang XL, 2015, COMPUT AIDED GEOM D, V35-36, P149, DOI 10.1016/j.cagd.2015.03.012
   Zhang XT, 2016, COMPUT GRAPH FORUM, V35, P157, DOI 10.1111/cgf.12972
   Zhou QN, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461967
   Zhu B, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3095815
NR 64
TC 17
Z9 21
U1 23
U2 111
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2615
EP 2627
DI 10.1109/TVCG.2020.3037697
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400006
PM 33180728
DA 2024-11-06
ER

PT J
AU Lu, M
   Fish, N
   Wang, SQ
   Lanir, J
   Cohen-Or, D
   Huang, H
AF Lu, Min
   Fish, Noa
   Wang, Shuaiqi
   Lanir, Joel
   Cohen-Or, Daniel
   Huang, Hui
TI Enhancing Static Charts With Data-Driven Animations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Animation; Data visualization; Encoding; Image color
   analysis; Visual effects; Task analysis; Visual encoding; data-driven;
   animated effects; charts
ID VISUAL EXPLORATION; MOTION
AB Static visual attributes such as color and shape are used with great success in visual charts designed to be displayed in static, hard-copy form. However, nowadays digital displays become ubiquitous in the visualization of any form of data, lifting the confines of static presentations. In this article, we propose incorporating data-driven animations to bring static charts to life, with the purpose of encoding and emphasizing certain attributes of the data. We lay out a design space for data-driven animated effects and experiment with three versatile effects, marching ants, geometry deformation and gradual appearance. For each, we provide practical details regarding their mode of operation and extent of interaction with existing visual encodings. We examine the impact and effectiveness of our enhancements through an empirical user study to assess preference as well as gauge the influence of animated effects on human perception in terms of speed and accuracy of visual understanding.
C1 [Lu, Min; Wang, Shuaiqi; Cohen-Or, Daniel; Huang, Hui] Shenzhen Univ, Shenzhen 518060, Peoples R China.
   [Lanir, Joel] Univ Haifa, IL-3498838 Haifa, Israel.
   [Fish, Noa] Tel Aviv Univ, IL-6997801 Tel Aviv, Israel.
C3 Shenzhen University; University of Haifa; Tel Aviv University
RP Huang, H (corresponding author), Shenzhen Univ, Shenzhen 518060, Peoples R China.
EM lumin.vis@gmail.com; noafish@gmail.com; shuaiqiwang@gmail.com;
   ylanir@is.haifa.il; cohenor@gmail.com; hhzhiyan@gmail.com
RI Huang, Hui/JGB-1049-2023; lu, min/E-5407-2014
OI Lanir, Joel/0000-0002-9838-5142; Huang, Hui/0000-0003-3212-0544
FU NSFC [61802265, 41671387]; GD Science and Technology Program
   [2018A030310426, 2020A0505100064, 2015A030312015]; Guangdong Laboratory
   of Artificial Intelligence and Digital Economy; GD Talent Program
   [2019JC05X328]; DEGP Key Project [2018KZDXM058, LHTD 20170003]; National
   Engineering Laboratory for Big Data System Computing Technology
FX The authors would like to thank the reviewers for their valuable
   comments. This work was supported in parts by NSFC under Grants
   61802265, 41671387, GD Talent Program 2019JC05X328, GD Science and
   Technology Program 2018A030310426, 2020A0505100064, 2015A030312015, DEGP
   Key Project 2018KZDXM058, LHTD 20170003, National Engineering Laboratory
   for Big Data System Computing Technology, and Guangdong Laboratory of
   Artificial Intelligence and Digital Economy (SZ).
CR Albo Y., 2016, Proceedings of the International Working Conference on Advanced Visual Interfaces, P264, DOI [10.1145/2909132.2909250, DOI 10.1145/2909132.2909250]
   [Anonymous], 1994, ACM Transactions on Computer-Human Interaction (TOCHI), DOI [10.1145/180171.180173, DOI 10.1145/180171.180173]
   [Anonymous], 2004, ACM Transactions on Applied Perception (TAP), DOI 10.1145/1008722.1008724
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Bartram L., 2002, Information Visualization, V1, P66, DOI 10.1057/palgrave/ivs/9500005
   Bartram L, 2003, INT J HUM-COMPUT ST, V58, P515, DOI 10.1016/S1071-5819(03)00021-1
   Bartram L., 1997, P WORKSH NEW PAR INF, P3
   Bartram L. R., 2001, PhD thesis
   Baudisch Patrick, 2006, P 19 ANN ACM S US IN, P169, DOI [10.1145, 10.1145/1166253.1166280]
   Bertin J., 2010, Graphische semiologie: diagramme, netze, karten
   Blaas J, 2009, IEEE T VIS COMPUT GR, V15, P969, DOI 10.1109/TVCG.2009.181
   Buschmann S, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P174, DOI 10.1109/CW.2014.32
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Carenini G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1835, DOI 10.1145/2556288.2557141
   Chevalier F., 2016, P INT WORK C ADY VIS, P280, DOI DOI 10.1145/2909132.2909255
   DRIVER J, 1992, PERCEPT PSYCHOPHYS, V51, P79, DOI 10.3758/BF03205076
   Fisher D., 2010, Beautiful Visualization - Looking at Data Through the Eyes of Experts, P329
   Furnas G. W., 1986, SIGCHI Bull, V17, P16, DOI DOI 10.1145/22339.22342
   Gibson J.J., 1979, 9 EUR MICR C BRIGHT
   Grossman Tovi, 2016, Interactions, V23, P52, DOI [10.1145/2949762, DOI 10.1145/2949762]
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Heiser J, 2006, COGNITIVE SCI, V30, P581, DOI 10.1207/s15516709cog0000_70
   Hoffman DM, 2011, J SOC INF DISPLAY, V19, P271, DOI 10.1889/JSID19.3.271
   Huber DE, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P527
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Kazi RH, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4599, DOI 10.1145/2858036.2858386
   Kazi RH, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P351, DOI 10.1145/2556288.2556987
   Klassen R. V., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P148, DOI 10.1109/VISUAL.1991.175792
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Laurel Brenda., 1990, ART HUMAN COMPUTER I
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   McLoughlin T, 2010, COMPUT GRAPH FORUM, V29, P1807, DOI 10.1111/j.1467-8659.2010.01650.x
   Milliez A, 2014, P WORKSH NONPH AN RE, P71, DOI [10.1145/2630397.2630402, DOI 10.1145/2630397.2630402]
   NAKAYAMA K, 1986, NATURE, V320, P264, DOI 10.1038/320264a0
   RAYMOND JE, 1992, J EXP PSYCHOL HUMAN, V18, P849, DOI 10.1037/0096-1523.18.3.849
   Reed B., 2006, PROC ACM S SOFTW VIS, P181
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Rind A, 2011, LECT NOTES COMPUT SC, V6779, P139, DOI 10.1007/978-3-642-21716-6_15
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Romat H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173761
   SARKAR M, 1994, COMMUN ACM, V37, P73, DOI 10.1145/198366.198384
   Scheepens R, 2016, IEEE T VIS COMPUT GR, V22, P379, DOI 10.1109/TVCG.2015.2467112
   Torre-Arenas I. D. L., 2017, PROC S NONPHOTOREALI
   TREISMAN A, 1986, SCI AM, V255, pB114
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646
   visualcapitalist, ANIMATION VISUALIZIN
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P2487, DOI 10.1109/TVCG.2017.2750689
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Ware Colin., 2006, P 3 S APPL PERC GRAP, P107
   Willett NS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/3126594.3126641
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Yu H., 2007, Supercomputing, P1
NR 55
TC 4
Z9 4
U1 3
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2628
EP 2640
DI 10.1109/TVCG.2020.3037300
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400007
PM 33175679
DA 2024-11-06
ER

PT J
AU Weiss, S
   Isk, M
   Thies, J
   Westermann, R
AF Weiss, Sebastian
   Isk, Mustafa
   Thies, Justus
   Westermann, Rudiger
TI Learning Adaptive Sampling and Reconstruction for Volume Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Data visualization; Pipelines; Image resolution;
   Visualization; Rendering (computer graphics); Neural networks; Volume
   visualization; adaptive sampling; deep learning
ID CONVOLUTIONAL NETWORK; IMAGE
AB A central challenge in data visualization is to understand which data samples are required to generate an image of a data set in which the relevant information is encoded. In this article, we make a first step towards answering the question of whether an artificial neural network can predict where to sample the data with higher or lower density, by learning of correspondences between the data, the sampling patterns and the generated images. We introduce a novel neural rendering pipeline, which is trained end-to-end to generate a sparse adaptive sampling structure from a given low-resolution input image, and reconstructs a high-resolution image from the sparse set of samples. For the first time, to the best of our knowledge, we demonstrate that the selection of structures that are relevant for the final visual representation can be jointly learned together with the reconstruction of this representation from these structures. Therefore, we introduce differentiable sampling and reconstruction stages, which can leverage back-propagation based on supervised losses solely on the final image. We shed light on the adaptive sampling patterns generated by the network pipeline and analyze its use for volume visualization including isosurface and direct volume rendering.
C1 [Weiss, Sebastian; Isk, Mustafa; Thies, Justus; Westermann, Rudiger] Tech Univ Munich, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Weiss, S (corresponding author), Tech Univ Munich, D-80333 Munich, Germany.
EM sebastian13.weiss@tum.de; m.isik@tum.de; justus.thies@tum.de;
   westermann@tum.de
OI Westermann, Rudiger/0000-0002-3394-0731; Weiss,
   Sebastian/0000-0003-4399-3180; Isik, Mustafa/0000-0002-3086-8922
CR Bashford-Rogers T, 2014, IEEE T VIS COMPUT GR, V20, P907, DOI 10.1109/TVCG.2013.258
   Belyaev Sergey, 2018, [Journal of Electronic Science and Technology, 电子科技学刊(英文版)], V16, P222
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bolin M. R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P299, DOI 10.1145/280814.280924
   Campagnolo LQ, 2015, SIBGRAPI, P17, DOI 10.1109/SIBGRAPI.2015.27
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Danskin J., 1992, Proceedings of the 1992 workshop on volume visualization, P91, DOI 10.1145/147130.147155
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Frey S, 2014, IEEE T VIS COMPUT GR, V20, P2397, DOI 10.1109/TVCG.2014.2346319
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi
   Görtler J, 2019, IEEE T VIS COMPUT GR, V25, P2193, DOI 10.1109/TVCG.2019.2903945
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   HALTON JH, 1964, COMMUN ACM, V7, P701, DOI 10.1145/355588.365104
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2019, IEEE COMPUT GRAPH, V39, P54, DOI 10.1109/MCG.2018.2881523
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Igehy H, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P186, DOI 10.1109/ICIP.1997.632049
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   King DB, 2015, ACS SYM SER, V1214, P1
   Kratz A, 2011, ZIB TAKUSTR
   Kraus M, 2009, P GRAPP
   Krizhevsky A., 2014, ABS14045997 CORR, V1404, P5997
   Kuznetsov A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13473
   Lawrence J., 2005, EGSR 2005, P11
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levoy M., 1990, Visual Computer, V6, P2, DOI 10.1007/BF01902624
   Lindholm S., 2013, SIGRAD, P55
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Longhurst P., 2006, P 4 INT C COMPUTER G, P21
   Mara M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105774
   Myszkowski K., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P223
   Novins Kevin., 1992, Proceedings of the 1992 Workshop on Volume Visualization, VVS '92, P83
   Painter J., 1989, Computer Graphics, V23, P281, DOI 10.1145/74334.74362
   Paszke A, 2019, ADV NEUR IN, V32
   Prantl Martin, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: GRAPP 2016, P151
   Ramasubramanian M, 1999, COMP GRAPH, P73, DOI 10.1145/311535.311543
   Rigau J., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P260
   Roberts M., 2020, The unreasonable effectiveness of quasirandom sequences
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Tursun OT, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322985
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Xu Q, 2005, LECT NOTES ARTIF INT, V3802, P989
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
NR 62
TC 13
Z9 13
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2654
EP 2667
DI 10.1109/TVCG.2020.3039340
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400009
PM 33211659
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yazdanpour, M
   Fan, GL
   Sheng, WH
AF Yazdanpour, Mahdi
   Fan, Guoliang
   Sheng, Weihua
TI ManhattanFusion: Online Dense Reconstruction of Indoor Scenes From Depth
   Sequences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Image reconstruction; Solid modeling;
   Optimization; Trajectory; Computational modeling; Real-time systems;
   Manhattan frame; volumetric reconstruction; planar alignment; local pose
   optimization
AB We present a new framework for online dense 3D reconstruction of indoor scenes by using only depth sequences. This research is particularly useful in cases with a poor light condition or in a nearly featureless indoor environment. The lack of RGB information makes long-range camera pose estimation difficult in a large indoor environment. The key idea of our research is to take advantage of the geometric prior of Manhattan scenes in each stage of the reconstruction pipeline with the specific aim to reduce the cumulative registration error and overall odometry drift in a long sequence. This idea is further boosted by local Manhattan frame growing and the local-to-global strategy that leads to implicit loop closure handling for a large indoor scene. Our proposed pipeline, namely ManhattanFusion, starts with planar alignment and local pose optimization where the Manhattan constraints are imposed to create detailed local segments. These segments preserve intrinsic scene geometry by minimizing the odometry drift even under complex and long trajectories. The final model is generated by integrating all local segments into a global volumetric representation under the constraint of Manhattan frame-based registration across segments. Our algorithm outperforms others that use depth data only in terms of both the mean distance error and the absolute trajectory error, and it is also very competitive compared with RGB-D based reconstruction algorithms. Moreover, our algorithm outperforms the state-of-the-art in terms of the surface area coverage by 10-40 percent, largely due to the usefulness and effectiveness of the Manhattan assumption through the reconstruction pipeline.
C1 [Yazdanpour, Mahdi] Northern Kentucky Univ, Dept Phys Geol & Engn Technol, Highland Hts, KY 41099 USA.
   [Fan, Guoliang; Sheng, Weihua] Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74075 USA.
C3 Northern Kentucky University; Oklahoma State University System; Oklahoma
   State University - Stillwater
RP Fan, GL (corresponding author), Oklahoma State Univ, Sch Elect & Comp Engn, Stillwater, OK 74075 USA.
EM yazdanpoum1@nku.edu; guoliang.fan@okstate.edu; weihua.sheng@okstate.edu
RI Fan, Guoliang/G-2893-2011
OI Fan, Guoliang/0000-0002-8584-9040
FU US National Science Foundation (NSF) [IIS-1427345, IIS-1910993]; US
   National Institutes of Health (NIH) [R15 AG061833]; Oklahoma Center for
   the Advancement of Science and Technology (OCAST) Health Research Grant
   [HR18-069]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions that are very helpful to improve this
   paper. This work was supported in part by the US National Science
   Foundation (NSF) Grants IIS-1427345 and IIS-1910993, the US National
   Institutes of Health (NIH) Grant R15 AG061833 and the Oklahoma Center
   for the Advancement of Science and Technology (OCAST) Health Research
   Grant HR18-069.
CR Agarwal S., 2013, Ceres solver
   Chen JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461940
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12
   Coughlan J. M., 1999, P 7 IEEE INT C COMP, V2, P941, DOI [10.1109/ICCV.1999.790349, DOI 10.1109/ICCV.1999.790349]
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Dong W, 2018, LECT NOTES COMPUT SC, V11213, P714, DOI 10.1007/978-3-030-01240-3_43
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Ghanem B, 2015, PROC CVPR IEEE, P3772, DOI 10.1109/CVPR.2015.7299001
   Girardeau-Montaut D., 2015, Open Source Project, P197
   Golodetz S, 2018, IEEE T VIS COMPUT GR, V24, P2895, DOI 10.1109/TVCG.2018.2868533
   Halber M, 2017, PROC CVPR IEEE, P6660, DOI 10.1109/CVPR.2017.705
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Henry P, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P398, DOI 10.1109/3DV.2013.59
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Heredia Francisco, 2012, USING KINFU LARGE SC
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824
   Joo K, 2016, PROC CVPR IEEE, P1763, DOI 10.1109/CVPR.2016.195
   Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Maier R, 2014, LECT NOTES COMPUT SC, V8753, P54, DOI 10.1007/978-3-319-11752-2_5
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Roth H, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.112
   Steinbrücker F, 2013, IEEE I CONF COMP VIS, P3264, DOI 10.1109/ICCV.2013.405
   Stückler J, 2014, J VIS COMMUN IMAGE R, V25, P137, DOI 10.1016/j.jvcir.2013.02.008
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wang H, 2016, PROC CVPR IEEE, P3271, DOI 10.1109/CVPR.2016.356
   Wang L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051050
   Whelan Thomas, 2013, 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2013), P548, DOI 10.1109/IROS.2013.6696405
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008
   Whelan T, 2013, IEEE INT CONF ROBOT, P5724, DOI 10.1109/ICRA.2013.6631400
   Whelan Thomas, 2012, MIT CSAIL TR
   Wolters Dominik, 2014, P GCPR
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yaguchi H, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P759, DOI 10.1109/SII.2013.6776686
   Yang S, 2020, IEEE T VIS COMPUT GR, V26, P3217, DOI 10.1109/TVCG.2019.2919619
   Yazdanpour M., 2017, PROC IEEE VIS COMMUN, P1
   Yazdanpour M, 2019, IEEE COMPUT SOC CONF, P964, DOI 10.1109/CVPRW.2019.00127
   Yazdi M. A., 2019, P 1 INT C PROCESS MI, P1
   Zhang H, 2018, IEEE T VIS COMPUT GR, V24, P3137, DOI 10.1109/TVCG.2017.2786233
   Zhou QY, 2014, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2014.65
   Zhou QY, 2013, IEEE I CONF COMP VIS, P473, DOI 10.1109/ICCV.2013.65
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
NR 53
TC 2
Z9 2
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2668
EP 2681
DI 10.1109/TVCG.2020.3036868
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400010
PM 33170778
OA Green Accepted, Bronze
DA 2024-11-06
ER

PT J
AU Wu, HY
   Nollenburg, M
   Viola, I
AF Wu, Hsiang-Yun
   Nollenburg, Martin
   Viola, Ivan
TI Multi-Level Area Balancing of Clustered Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Visualization; Clustering algorithms; Data visualization; Shape;
   Partitioning algorithms; Chemical elements; Graph drawing; Voronoi
   tessellation; multi-level; spatially-efficient layout
ID OF-THE-ART; VISUALIZING GRAPHS; ALGORITHM; DESIGN; LAYOUT; MAPS
AB We present a multi-level area balancing technique for laying out clustered graphs to facilitate a comprehensive understanding of the complex relationships that exist in various fields, such as life sciences and sociology. Clustered graphs are often used to model relationships that are accompanied by attribute-based grouping information. Such information is essential for robust data analysis, such as for the study of biological taxonomies or educational backgrounds. Hence, the ability to smartly arrange textual labels and packing graphs within a certain screen space is therefore desired to successfully convey the attribute data . Here we propose to hierarchically partition the input screen space using Voronoi tessellations in multiple levels of detail. In our method, the position of textual labels is guided by the blending of constrained forces and the forces derived from centroidal Voronoi cells. The proposed algorithm considers three main factors: (1) area balancing, (2) schematized space partitioning, and (3) hairball management. We primarily focus on area balancing, which aims to allocate a uniform area for each textual label in the diagram. We achieve this by first untangling a general graph to a clustered graph through textual label duplication, and then coupling with spanning-tree-like visual integration. We illustrate the feasibility of our approach with examples and then evaluate our method by comparing it with well-known conventional approaches and collecting feedback from domain experts.
C1 [Wu, Hsiang-Yun; Nollenburg, Martin] TU Wien, A-1040 Vienna, Austria.
   [Viola, Ivan] King Abdullah Univ Sci & Technol KAUST, Thuwal 23955, Saudi Arabia.
C3 Technische Universitat Wien; King Abdullah University of Science &
   Technology
RP Wu, HY (corresponding author), TU Wien, A-1040 Vienna, Austria.
EM hsiang.yun.wu@acm.org; noellenburg@ac.tuwien.ac.at;
   ivan.viola@kaust.edu.sa
RI Viola, Ivan/O-8944-2014; WU, Hsiang-Yun/T-8434-2018
OI Viola, Ivan/0000-0003-4248-6574; Nollenburg, Martin/0000-0003-0454-3937;
   WU, Hsiang-Yun/0000-0003-1028-0010
FU European Union [747985]; Vienna Science and Technology Fund (WWTF)
   [VRG11-010]; Austrian Science Fund (FWF) [P31119]; King Abdullah
   University of Science and Technology (KAUST) [BAS/1/1680-01-01]; Marie
   Curie Actions (MSCA) [747985] Funding Source: Marie Curie Actions
   (MSCA); Austrian Science Fund (FWF) [P31119] Funding Source: Austrian
   Science Fund (FWF)
FX The project has received funding from the European Union Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie Grant
   agreement No. 747985, from the Vienna Science and Technology Fund (WWTF)
   through projects VRG11-010, from the Austrian Science Fund (FWF) through
   project P31119, and from King Abdullah University of Science and
   Technology (KAUST) through award BAS/1/1680-01-01. The authors would
   like to thank Michael Cusack from Research Communication and Publication
   Services at KAUST for proofreading.
CR Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   [Anonymous], 2019, BOOST C LIB VERSION
   [Anonymous], 2019, The Computational Geometry Algorithms Library
   [Anonymous], 2019, GRAPH DRAWING CONTES
   [Anonymous], 2018, Eigen - a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms
   [Anonymous], 2017, QT 5 8 CROSS PLATFOR
   Auer S., 2018, P 8 INT C WEB INT MI, DOI [DOI 10.1145/3227609.3227689, 10.1145/3227609, DOI 10.1145/3227609, 10.1145/3227609.3227689]
   Balzer M, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P49, DOI 10.1109/INFVIS.2005.1532128
   Bertault F, 1999, LECT NOTES COMPUT SC, V1731, P197
   Borgatti SP, 2009, SCIENCE, V323, P892, DOI 10.1126/science.1165821
   Brivio P, 2010, IEEE T VIS COMPUT GR, V16, P1261, DOI 10.1109/TVCG.2010.136
   Buchin K., 2011, P 19 ACM SIGSPATIAL, P261, DOI DOI 10.1145/2093973.2094009
   Chaikin GM., 1974, Comput Graph Image Process, V3, P346, DOI [10.1016/0146-664X(74)90028-8, DOI 10.1016/0146-664X(74)90028-8]
   Chaturvedi S, 2014, COMPUT GRAPH FORUM, V33, P52, DOI 10.1111/cgf.12400
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Cui WW, 2010, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2010.5429600
   Delling D, 2014, COMP GEOM-THEOR APPL, V47, P381, DOI 10.1016/j.comgeo.2013.10.002
   Dongen S., 2000, Technical Report INS-R0010
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Eades Peter, 2018, Graph Drawing and Network Visualization. 25th International Symposium, GD 2017. Revised Selected Papers: LNCS 10692, P272, DOI 10.1007/978-3-319-73915-1_22
   Eades P., 1997, Graph Drawing. Symposium on Graph Drawing, GD '96. Proceedings, P101
   Efrat A, 2014, LECT NOTES COMPUT SC, V8871, P452, DOI 10.1007/978-3-662-45803-7_38
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Frati F, 2016, CLUSTERED GRAPH DRAW, P326
   Fried D, 2014, IEEE PAC VIS SYMP, P113, DOI 10.1109/PacificVis.2014.47
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gansner ER, 2010, IEEE PAC VIS SYMP, P201, DOI 10.1109/PACIFICVIS.2010.5429590
   Gansner ER, 2010, IEEE COMPUT GRAPH, V30, P54, DOI 10.1109/MCG.2010.101
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Gronemann Martin, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P426, DOI 10.1007/978-3-642-36763-2_38
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Henry N, 2008, IEEE T VIS COMPUT GR, V14, P1317, DOI 10.1109/TVCG.2008.141
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Hsiang-Yun Wu, 2013, 2013 17th International Conference on Information Visualisation, P96, DOI 10.1109/IV.2013.11
   Huang ML, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P920, DOI 10.1109/ICIG.2007.10
   K. Laboratories, 2018, KEGG PATHW DAT MET P
   Keiro, 2020, PACK VIS GRAPHS
   Kindermann P, 2019, LECT NOTES COMPUT SC, V11904, P575, DOI 10.1007/978-3-030-35802-0_43
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Klein R:., 1989, Concrete and Abstract Voronoi Diagrams
   Kobourov S.G., 2014, EUROVIS SHORT PAPERS
   KOU L, 1981, ACTA INFORM, V15, P141, DOI 10.1007/BF00288961
   Lin CC, 2012, J VISUAL LANG COMPUT, V23, P29, DOI 10.1016/j.jvlc.2011.12.001
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   MCL, 2008, CLUST ALG GRAPHS
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Meulemans W, 2010, LECT NOTES COMPUT SC, V6292, P160, DOI 10.1007/978-3-642-15300-6_12
   Nachmanson L, 2015, LECT NOTES COMPUT SC, V9411, P3, DOI 10.1007/978-3-319-27261-0_1
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Nielsen SS, 2021, IEEE ACM T COMPUT BI, V18, P1130, DOI 10.1109/TCBB.2019.2938501
   Noronha A, 2019, NUCLEIC ACIDS RES, V47, pD614, DOI 10.1093/nar/gky992
   Noronha A, 2017, BIOINFORMATICS, V33, P605, DOI 10.1093/bioinformatics/btw667
   Nusrat S, 2016, COMPUT GRAPH FORUM, V35, P619, DOI 10.1111/cgf.12932
   Roberts MJ, 2017, INT J HUM-COMPUT ST, V98, P109, DOI 10.1016/j.ijhcs.2016.06.003
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Shneiderman B, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P73, DOI 10.1109/INFVIS.2001.963283
   Siegel RL, 2018, CA-CANCER J CLIN, V68, P7, DOI [10.3322/caac.21442, 10.3322/caac.21551]
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   VERLET L, 1967, PHYS REV, V159, P98, DOI 10.1103/PhysRev.159.98
   Wang YS, 2011, IEEE T VIS COMPUT GR, V17, P2528, DOI 10.1109/TVCG.2011.205
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu HY, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2779-4
   Wu HY, 2018, J VISUAL LANG COMPUT, V44, P106, DOI 10.1016/j.jvlc.2017.09.008
   Yao ZH, 2017, INT CONF SOFTW ENG, P422, DOI 10.1109/ICSESS.2017.8342946
   YEAP KH, 1993, SIAM J COMPUT, V22, P500, DOI 10.1137/0222035
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Yoghourdjian V, 2016, IEEE T VIS COMPUT GR, V22, P339, DOI 10.1109/TVCG.2015.2467251
NR 70
TC 6
Z9 6
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2682
EP 2696
DI 10.1109/TVCG.2020.3038154
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400011
PM 33201819
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Kreskowski, A
   Beck, S
   Froehlich, B
AF Kreskowski, Adrian
   Beck, Stephan
   Froehlich, Bernd
TI Output-Sensitive Avatar Representations for Immersive Telepresence
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Avatars; Telepresence; Rendering (computer
   graphics); Streaming media; Geometry; Image reconstruction; Immersive
   telepresence; avatars; output-sensitive rendering; distributed virtual
   environments
ID REAL-TIME; MESH COMPRESSION; 3D VIDEO
AB In this article, we propose a system design and implementation for output-sensitive reconstruction, transmission and rendering of 3D video avatars in distributed virtual environments. In our immersive telepresence system, users are captured by multiple RGBD sensors connected to a server that performs geometry reconstruction based on viewing feedback from remote telepresence parties. This feedback and reconstruction loop enables visibility-aware level-of-detail reconstruction of video avatars regarding geometry and texture data, and considers individual and groups of collocated users. Our evaluation reveals that our approach leads to a significant reduction of reconstruction times, network bandwidth requirements and round-trip times as well as rendering costs in many situations.
C1 [Kreskowski, Adrian; Beck, Stephan; Froehlich, Bernd] Bauhaus Univ Weimar, Virtual Real & Visualizat Res Grp, D-99423 Weimar, Germany.
C3 Bauhaus-Universitat Weimar
RP Kreskowski, A (corresponding author), Bauhaus Univ Weimar, Virtual Real & Visualizat Res Grp, D-99423 Weimar, Germany.
EM adrian.kreskowski@uni-weimar.de; stephan.beck@uni-weimar.de;
   bernd.froehlich@uni-weimar.de
OI Kreskowski, Adrian/0000-0002-5032-7613; Froehlich,
   Bernd/0000-0002-9439-1959
FU Thuringian Ministry for Economic Affairs, Science and Digital Society
   [5575/10-5]
FX This research received funding from the Thuringian Ministry for Economic
   Affairs, Science and Digital Society under grant 5575/10-5 (MetaReal).
   The authors would like to thank the members of the Virtual Reality and
   Visualization Research Group at Bauhaus-Universitat Weimar
   (http://www.uni-weimar.de/vr) for their support and the reviewers of
   this article for their constructive feedback that helped to improve the
   article significantly.
CR Alexiadis D, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P278, DOI 10.1109/VCIP.2014.7051558
   Alexiadis DS, 2013, 2013 IEEE 11TH IVMSP WORKSHOP: 3D IMAGE/VIDEO TECHNOLOGIES AND APPLICATIONS (IVMSP 2013)
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   [Anonymous], 2013, P 19 ACM S VIRT REAL
   Beacco A, 2011, COMPUT GRAPH FORUM, V30, P2328, DOI 10.1111/j.1467-8659.2011.02065.x
   Beck S, 2017, P IEEE VIRT REAL ANN, P167, DOI 10.1109/VR.2017.7892244
   Beck S, 2013, IEEE T VIS COMPUT GR, V19, P616, DOI 10.1109/TVCG.2013.33
   Carr NA, 2002, ACM T GRAPHIC, V21, P106, DOI 10.1145/508357.508360
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Collet Yann, 2013, LZ4 - Extremely fast compression
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Fairchild AJ, 2017, IEEE T CIRC SYST VID, V27, P814, DOI 10.1109/TCSVT.2016.2580425
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Goswami P, 2013, VISUAL COMPUT, V29, P69, DOI 10.1007/s00371-012-0675-2
   Greene N., 1993, Computer Graphics Proceedings, P231, DOI 10.1145/166117.166147
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Kulik A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024222
   Lamboray E, 2004, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2004.1310060
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Liu YP, 2015, LECT NOTES COMPUT SC, V9314, P442, DOI 10.1007/978-3-319-24075-6_43
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Maimone A, 2011, INT SYM MIX AUGMENT
   Mamou K, 2009, COMPUT ANIMAT VIRT W, V20, P343, DOI 10.1002/cav.319
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Mekuria R, 2014, IEEE T MULTIMEDIA, V16, P1809, DOI 10.1109/TMM.2014.2331919
   Mekuria R, 2013, IEEE INT CONF MULTI
   Niski K, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P153
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pece F., 2011, EGVE EUROVR, P59
   Pluss C., 2016, P INT C COMP AN SOC, P89
   Purnomo B., 2005, P ACM SIGGRAPH EUROG, P53, DOI DOI 10.1145/1071866.1071876
   Roberts DJ, 2015, IEEE J-STSP, V9, P562, DOI 10.1109/JSTSP.2015.2402635
   Schneegans S, 2014, WORK SOFTW ENG, P35, DOI 10.1109/SEARIS.2014.7152799
   Tang D., 2018, ACM T GRAPHIC, V37, P1
   Tang DH, 2020, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR42600.2020.00137
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang XQ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Willert M., 2012, P 11 ACM SIGGRAPH IN, P247
   Würmlin S, 2004, COMPUT GRAPH-UK, V28, P3, DOI 10.1016/j.cag.2003.10.015
   Yoon SE, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P131, DOI 10.1109/VISUAL.2004.86
NR 43
TC 4
Z9 4
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2697
EP 2709
DI 10.1109/TVCG.2020.3037360
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400012
PM 33175680
DA 2024-11-06
ER

PT J
AU Mallett, I
   Seiler, L
   Yuksel, C
AF Mallett, Ian
   Seiler, Larry
   Yuksel, Cem
TI Patch Textures: Hardware Support for Mesh Colors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Hardware; Two dimensional displays; Standards;
   Rendering (computer graphics); Graphics processing units; Faces;
   Textures; Mesh Colors; Ptex; GPU hardware; texture filtering;
   barycentric filtering; anisotropic filtering
AB Mesh Colors provide an effective alternative to standard texture mapping. They significantly simplify the asset production pipeline by removing the need for defining a mapping and eliminate rendering artifacts due to seams. This article addresses the problem that using Mesh Colors for real-time rendering has not been practical, due to the absence of hardware support. We show that it is possible to provide full hardware texture filtering support for Mesh Colors with minimal changes to existing GPUs by introducing a hardware-friendly representation for Mesh Colors that we call Patch Textures, which can have quadrilateral or triangular topology. We discuss the hardware modifications needed for storing and filtering Patch Textures, including anisotropic filtering. This article extends our previous work by discussing and comparing patch edge-handling approaches, including an option for sampling the textures of neighboring patches using an adjacency map. We also provide extensive discussions regarding data duplication, a partial implementation present in existing hardware, and the difficulties with providing a similar hardware support for Ptex.
C1 [Mallett, Ian; Yuksel, Cem] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
   [Seiler, Larry] Facebook Real Labs, Pittsburgh, PA 15213 USA.
C3 Utah System of Higher Education; University of Utah; Facebook Inc
RP Mallett, I (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM imallett@cs.utah.edu; larryseiler@fb.com; cem@cemyuksel.com
OI Mallett, Ian/0000-0002-2505-3649; Yuksel, Cem/0000-0002-0122-4159; ,
   Jeka_L/0009-0009-6596-7822
FU Facebook Reality Labs
FX The authors would like to thank Christer Sveen for use of the alien
   character, Murat Afs ar for the lizard model, Lee Perry-Smith for the
   head model, and Paul Tosca for the Nyra model. This project was
   supported in part by a Grant from Facebook Reality Labs.
CR [Anonymous], 2004, SHADERX3 ADV RENDERI
   Benson D, 2002, ACM T GRAPHIC, V21, P785, DOI 10.1145/566570.566652
   Burley B, 2008, COMPUT GRAPH FORUM, V27, P1155, DOI 10.1111/j.1467-8659.2008.01253.x
   Christensen P.H., 2004, Proc. Eurographics Symposium on Rendering, P133, DOI [10.2312/EGWR/EGSR04/133-141, DOI 10.2312/EGWR/EGSR04/133-141]
   Kim S., 2011, PROC SIGGRAPH ASIA S, P12
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P579, DOI 10.1145/1141911.1141926
   Lefebvre S, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P25
   Liu SR, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130897
   Mallett I., 2019, PROC HIGH PERFORM GR
   May khronos, 2018, ABOUT AS
   McDonald J., 2013, GDC
   McDonald John, 2011, ACM SIGGRAPH 2011 TA, DOI [10.1145/2037826.2037840, DOI 10.1145/2037826.2037840]
   PURNOMO B., 2004, EUROGRAPHICSACM SIGG, P65
   Ray N, 2010, COMPUT GRAPH FORUM, V29, P1489, DOI 10.1111/j.1467-8659.2010.01746.x
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Tarini M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925898
   Tatarchuk Natalya, 2015, PROC ACM SIGGRAPH CO
   Toth Robert, 2013, J COMPUTER GRAPHICS, V2, P91
   Wiki O, 2019, BINDLESS TEXTURE OPE
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
   Yuksel C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105780
   Yuksel C, 2019, COMPUT GRAPH FORUM, V38, P535, DOI 10.1111/cgf.13656
   Yuksel C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731053
NR 23
TC 4
Z9 4
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2710
EP 2721
DI 10.1109/TVCG.2020.3039777
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400013
PM 33226950
DA 2024-11-06
ER

PT J
AU Golebiowska, IM
   Coltekin, A
AF Golebiowska, Izabela M.
   Coltekin, Arzu
TI Rainbow Dash: Intuitiveness, Interpretability and Memorability of the
   Rainbow Color Scheme in Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Task analysis; Data visualization; Remote sensing;
   Visualization; Licenses; Anomaly detection; Color; visualization;
   colormap; color perception; visual design
ID MAPS
AB After demonstrating that rainbow colors are still commonly used in scientific publications, we comparatively evaluate the rainbow and sequential color schemes on choropleth and isarithmic maps in an empirical user study with 544 participants to examine if a) people intuitively associate order for the colors in these schemes, b) they can successfully conduct perceptual and semantic map reading and recall tasks with quantitative data where order may have implicit or explicit importance. We find that there is little to no agreement in ordering of rainbow colors while sequential colors are indeed intuitively ordered by the participants with a strong dark is more bias. Sequential colors facilitate most quantitative map reading tasks better than the rainbow colors, whereas rainbow colors competitively facilitate extracting specific values from a map, and may support hue recall better than sequential. We thus contribute to dark- versus light is more bias debate, demonstrate why and when rainbow colors may impair performance, and add further nuance to our understanding of this highly popular, yet highly criticized color scheme.
C1 [Golebiowska, Izabela M.] Univ Warsaw, Fac Geog & Reg Studies, Krakowskie Przedmiescie 30, PL-00927 Warsaw, Poland.
   [Coltekin, Arzu] Univ Appl Sci & Arts Northwestern Switzerland, Inst Interact Technol, Bahnhofstr 5, CH-5201 Brugg, Switzerland.
C3 University of Warsaw; FHNW University of Applied Sciences & Arts
   Northwestern Switzerland
RP Golebiowska, IM (corresponding author), Univ Warsaw, Fac Geog & Reg Studies, Krakowskie Przedmiescie 30, PL-00927 Warsaw, Poland.
EM i.golebiowska@uw.edu.pl; arzu.coltekin@fhnw.ch
RI Golebiowska, Izabela/ABB-6549-2020; Çöltekin, Arzu/ACY-8666-2022;
   Coltekin, Arzu/C-7705-2018
OI Golebiowska, Izabela/0000-0002-4307-7054; Coltekin,
   Arzu/0000-0002-3178-3509
FU National Science Centre, Poland [UMO-2016/23/B/HS6/03846]
FX The authors would like to thank Izabela Karsznia, Jolanta
   Korycka-Skorupa, Tomasz Nowacki, Tomasz Panecki, and Katarzyna Slomska
   for their help with data collection. This work was supported by the
   National Science Centre, Poland Grant UMO-2016/23/B/HS6/03846.
CR Aisch G., 2020, CHROMAJS COLOR PALET
   [Anonymous], 1991, LIE MAPS
   [Anonymous], 2015, MODERN TRENDS CARTOG, DOI DOI 10.1007/978-3-319-0W7926-4_3
   [Anonymous], 2015, P 1 ICA EUROPEAN S C
   [Anonymous], 2015, Int. J. Cartography
   [Anonymous], 2016, J VISUAL-JAPAN, DOI DOI 10.1167/16.12.628
   [Anonymous], 1961, VISUAL COMP ISOPLETH
   [Anonymous], 1990, CARTOGR INT J GEOGR
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Brewer C., 1997, Cartography Geographic Informat. Syst., V24, P203, DOI 10.1559/152304097782439231
   Brewer C., 2013, COLORBREWER 2 0
   Brewer C. A., 2003, Cartography Geographic Inf. Sci., V30, P5, DOI 10.1559/152304003100010929
   Brewer CA, 1997, ANN ASSOC AM GEOGR, V87, P411, DOI 10.1111/1467-8306.00061
   Brewer CA, 1996, CARTOGR J, V33, P79
   Brychtov ~a A., 2015, SEQUENTIAL SCHEME GE
   Brychtová A, 2017, CARTOGR GEOGR INF SC, V44, P229, DOI 10.1080/15230406.2016.1140074
   Brychtova A, 2016, CARTOGR J, V53, P202, DOI 10.1179/1743277414Y.0000000103
   Bujack R, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P32, DOI 10.1109/SciVis.2018.8823772
   Bujack R, 2018, IEEE T VIS COMPUT GR, V24, P923, DOI 10.1109/TVCG.2017.2743978
   C oltekin A., 2019, PROC ABSTRACTION SCA, P1
   Çöltekin A, 2017, INT J DIGIT EARTH, V10, P560, DOI 10.1080/17538947.2016.1234007
   Coltekin A., 2017, INT J CARTOGR, V3, P115, DOI [10.1080/23729333.2017.1302910, DOI 10.1080/23729333.2017.1302910]
   Cuff D. J., 1972, THESIS PENNSYLVANIA
   Gramazio C. C., 2017, COLORGORICAL
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Green M., 1998, ERGO/GERO Human Factors Science, V8, P1
   Hegarty M., 2009, CARTOGRAPHICA, V44, P171, DOI DOI 10.3138/CARTO.44.3.171
   Hyslop M. D., 2007, THESIS MICHIGAN STAT
   Jenny B., 2006, COLOR ORACLE
   Jenny B., 2007, Cartographic Perspectives, P61, DOI [DOI 10.14714/CP58.270, 10.14714/CP58.270]
   Knapp L., 1995, Cognitive aspects of human-computer interaction for Geographic Information Systems, P355
   KUMLER MP, 1990, CARTOGR GEOGR INFORM, V17, P279, DOI 10.1559/152304090783805681
   LENNENBERG ERIC H., 1961, PERCEPT MOT SKILLS, V12, P375
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   MACEACHREN A. M., 1995, How Maps Work: Representation, Visualization, and Design, V1st, DOI DOI 10.1002/esp.1383
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Moreland K., 2016, HUMAN VISION ELECT I, P262, DOI [10.2352/ISSN.2470-1173.2016.16HVEI-133, DOI 10.2352/ISSN.2470-1173.2016.16HVEI-133]
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Munzner T., 2014, AK Peters Visualization Series
   Olson JM, 1997, ANN ASSOC AM GEOGR, V87, P103, DOI 10.1111/0004-5608.00043
   OLSON JM, 1981, ANN ASSOC AM GEOGR, V71, P259, DOI 10.1111/j.1467-8306.1981.tb01352.x
   Quinan PS, 2019, COMPUT GRAPH FORUM, V38, P363, DOI 10.1111/cgf.13695
   Reda K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173846
   Robinson A.H., 1967, International Yearbook of Cartography, V7, P50
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Smallman HS, 2005, ERGON DES, V13, P6, DOI 10.1177/106480460501300303
   Stauffer R, 2015, B AM METEOROL SOC, V96, P203, DOI 10.1175/BAMS-D-13-00155.1
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   TRUMBO BE, 1981, AM STAT, V35, P220, DOI 10.2307/2683294
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Ware C., 2017, PROC WORKSHOP REPROD
   Ware C., 2019, Information Visualization: Perception for Design
   Ware C, 2019, IEEE T VIS COMPUT GR, V25, P2777, DOI 10.1109/TVCG.2018.2855742
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 57
TC 12
Z9 12
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2722
EP 2733
DI 10.1109/TVCG.2020.3035823
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400014
PM 33151882
OA hybrid
DA 2024-11-06
ER

PT J
AU Iglesias-Guitian, JA
   Mane, P
   Moon, B
AF Iglesias-Guitian, Jose A.
   Mane, Prajita
   Moon, Bochang
TI Real-Time Denoising of Volumetric Path Tracing for Direct Volume
   Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Noise reduction; Real-time systems;
   Photonics; Media; Lighting; Transfer functions; Volume rendering; global
   illumination; path-tracing; participating media; image-space filtering;
   real-time denoising
ID INTERACTIVE GLOBAL ILLUMINATION; MULTIPLE-SCATTERING; MODELS; DIFFUSION
AB Direct volume rendering (DVR) using volumetric path tracing (VPT) is a scientific visualization technique that simulates light transport with objects' matter using physically-based lighting models. Monte Carlo (MC) path tracing is often used with surface models, yet its application for volumetric models is difficult due to the complexity of integrating MC light-paths in volumetric media with none or smooth material boundaries. Moreover, auxiliary geometry-buffers (G-buffers) produced for volumes are typically very noisy, failing to guide image denoisers relying on that information to preserve image details. This makes existing real-time denoisers, which take noise-free G-buffers as their input, less effective when denoising VPT images. We propose the necessary modifications to an image-based denoiser previously used when rendering surface models, and demonstrate effective denoising of VPT images. In particular, our denoising exploits temporal coherence between frames, without relying on noise-free G-buffers, which has been a common assumption of existing denoisers for surface-models. Our technique preserves high-frequency details through a weighted recursive least squares that handles heterogeneous noise for volumetric models. We show for various real data sets that our method improves the visual fidelity and temporal stability of VPT during classic DVR operations such as camera movements, modifications of the light sources, and editions to the volume transfer function.
C1 [Iglesias-Guitian, Jose A.] Univ Autonoma Barcelona, Comp Vis Ctr, Bellaterra 08193, Spain.
   [Iglesias-Guitian, Jose A.] Univ A Coruna, CITIC Ctr ICT Res, La Coruna 15071, Spain.
   [Mane, Prajita; Moon, Bochang] Gwangju Inst Sci & Technol, Gwangju 61005, South Korea.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Universidade da Coruna; Gwangju Institute of Science & Technology
   (GIST)
RP Moon, B (corresponding author), Gwangju Inst Sci & Technol, Gwangju 61005, South Korea.
EM j.iglesias.guitian@udc.es; prajitamane@gist.ac.kr; bmoon@gist.ac.kr
OI Iglesias-Guitian, Jose A./0000-0002-0817-1010; Moon,
   Bochang/0000-0003-3142-0115
FU European Union [665919]; Spanish Ministry project (MCIU/AEI/FEDER, EU)
   [TIN2017-88709-R, RYC2018-025385-I]; FEDER Galicia [ED431G 2019/01];
   Cross-Ministry Giga KOREA Project - Korea government (MSIT) [GK20P0300]
FX The authors would like to thank reviewers for their insightful feedback.
   They also thank S. Oh, F. Llumbreras and J. Serrat for their help with
   Tensorflow, and T. Kroes for Exposure Render. The datasets are courtesy
   of the OsiriX Foundation (MANIX), University of Texas (CHAMELEON),
   University of Arizona (HELODERMA) and XYZ RGB Inc. (DRAGON). This work
   was supported by the European Union's Horizon 2020 research and
   innovation programme under the Marie Sklodowska-Curie g.a. No 665919.
   J.A. Iglesias-Guitian acknowledges the UDC-Inditex InTalent programme,
   the Spanish Ministry project TIN2017-88709-R, RYC2018-025385-I
   (MCIU/AEI/FEDER, EU), FEDER Galicia ED431G 2019/01 and the Nvidia GPU
   Grant Program. B. Moon was supported by The Cross-Ministry Giga KOREA
   Project grant funded by the Korea government (MSIT) (No. GK20P0300).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2008, P ACM SIGGRAPH AS CO
   Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073708, 10.1145/3072959.3073703]
   Bitterli B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275103
   Bitterli B, 2016, COMPUT GRAPH FORUM, V35, P107, DOI 10.1111/cgf.12954
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Chandrasekhar S., 1960, Radiative Transfer
   COLEMAN WA, 1968, NUCL SCI ENG, V32, P76, DOI 10.13182/NSE68-1
   Dappa E, 2016, INSIGHTS IMAGING, V7, P849, DOI 10.1007/s13244-016-0518-1
   Díaz J, 2017, VISUAL COMPUT, V33, P47, DOI 10.1007/s00371-015-1151-6
   Engel K., 2016, GPU Technology Conference, P4
   Engelhardt T., 2010, INSTANT MULTIPLE SCA
   Englund R., 2016, P SIGGRAPH AS S VIS
   Etiene T, 2014, IEEE T VIS COMPUT GR, V20, P140, DOI 10.1109/TVCG.2013.90
   Gharbi M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322954
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409083
   Iglesias-Guitian JA, 2016, COMPUT GRAPH FORUM, V35, P363, DOI 10.1111/cgf.13033
   Jarosz W, 2008, COMPUT GRAPH FORUM, V27, P557, DOI 10.1111/j.1467-8659.2008.01153.x
   Jarosz W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024215
   Jarosz W, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330518
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Jönsson D, 2014, COMPUT GRAPH FORUM, V33, P27, DOI 10.1111/cgf.12252
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Karis Brian., 2014, High Quality Temporal Supersampling
   Kharlamov Alexander., 2007, IMAGE DENOISING
   Khlebnikov R, 2014, COMPUT GRAPH FORUM, V33, P61, DOI 10.1111/cgf.12362
   Koerner D, 2014, COMPUT GRAPH FORUM, V33, P178, DOI 10.1111/cgf.12342
   Krivánek J, 2005, IEEE T VIS COMPUT GR, V11, P550, DOI 10.1109/TVCG.2005.83
   Krivanek Jaroslav, 2009, Practical Global Illumination with Irradiance Caching
   Krivanek Jaroslav, 2006, Rendering Techniques, V2006, P127
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Kronander J, 2012, IEEE T VIS COMPUT GR, V18, P447, DOI 10.1109/TVCG.2011.35
   Kulla C, 2012, COMPUT GRAPH FORUM, V31, P1519, DOI 10.1111/j.1467-8659.2012.03148.x
   Kutz P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073665
   Lafortune E. P., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P91
   Lindemann F, 2011, IEEE T VIS COMPUT GR, V17, P1922, DOI 10.1109/TVCG.2011.161
   Liu N, 2016, COMPUT ANIMAT VIRT W, V27, P394, DOI 10.1002/cav.1706
   Ljung L., 1987, THEORY PRACTICE RECU
   Magnus JG, 2018, IEEE T VIS COMPUT GR, V24, P984, DOI 10.1109/TVCG.2017.2744438
   Mara M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105774
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Max Nelson, 2010, Dagstuhl Follow-Ups, V1, P259
   Moon B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766992
   Nov~ak J., 2018, PROC ACM SIGGRAPH CO
   Novák J, 2018, COMPUT GRAPH FORUM, V37, P551, DOI 10.1111/cgf.13383
   Novák J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661292
   Paladini G., 2015, PROC EUROGRAPHICS C
   Pharr M., 2016, Physically based rendering: From theory to implementation
   Rowe SP, 2018, BRIT J RADIOL, V91, DOI 10.1259/bjr.20170558
   Salama CR, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P411, DOI 10.1109/PG.2007.27
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Stam J, 1995, SPRING COMP SCI, P41
   Szirmay-Kalos L, 2017, COMPUT GRAPH FORUM, V36, P9, DOI 10.1111/cgf.13102
   Weber C., 2013, P INT WORKSH VIS MOD, P195, DOI [10.2312/PE.VMV.VMV13.195-202, DOI 10.2312/PE.VMV.VMV13.195-202]
   Yang H, 2008, IEEE IMAGE PROC, P2868, DOI 10.1109/ICIP.2008.4712393
   Yue YH, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866199
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P1317, DOI 10.1109/TVCG.2013.17
   Zwicker M, 2015, COMPUT GRAPH FORUM, V34, P667, DOI 10.1111/cgf.12592
NR 62
TC 8
Z9 8
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2734
EP 2747
DI 10.1109/TVCG.2020.3037680
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400015
PM 33180727
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, YL
   Zou, XM
   Xu, SH
   Xing, GY
   Wei, HS
   Zhang, YC
AF Liu, Yanli
   Zou, Xingming
   Xu, Songhua
   Xing, Guanyu
   Wei, Housheng
   Zhang, Yanci
TI Real-Time Shadow Detection From Live Outdoor Videos for Augmented
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shadow boundary detection under moving viewpoints; optical tracking;
   shadow interaction for augmented reality
ID GENERATION; TRACKING; IMAGE
AB Simulating shadow interactions between real and virtual objects is important for augmented reality (AR), in which accurately and efficiently detecting real shadows from live videos is a crucial step. Most of the existing methods are capable of processing only scenes captured under a fixed viewpoint. In contrast, this article proposes a new framework for shadow detection in live outdoor videos captured under moving viewpoints. The framework splits each frame into a tracked region, which is the region tracked from the previous video frame through optical flow analysis, and an emerging region, which is newly introduced into the scene due to the moving viewpoint. The framework subsequently extracts features based on the intensity profiles surrounding the boundaries of candidate shadow regions. These features are then utilized to both correct erroneous shadow boundaries for the tracked region and to detect shadow boundaries for the emerging region by a Bayesian learning module. To remove spurious shadows, spatial layout constraints are further considered for emerging regions. The experimental results demonstrate that the proposed framework outperforms the state-of-the-art shadow tracking and detection algorithms on a variety of challenging cases in real time, including shadows on backgrounds with complex textures, nonplanar shadows, fast-moving shadows with changing typologies, and shadows cast by nonrigid objects. The quantitative experiments show that our method outperforms the best existing method, achieving a 33.3% increase in the average F-measure on a self-collected database. Coupled with an image-based shadow-casting method, the proposed framework generates realistic shadow interaction results. This capability will be particularly beneficial for supporting AR applications.
C1 [Liu, Yanli; Zou, Xingming; Xing, Guanyu; Wei, Housheng; Zhang, Yanci] Sichuan Univ, Coll Comp Sci, Chengdu 610017, Peoples R China.
   [Xu, Songhua] Univ South Carolina, Columbia, SC 29201 USA.
C3 Sichuan University; University of South Carolina System; University of
   South Carolina Columbia
RP Xing, GY (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610017, Peoples R China.
EM yanliliu@scu.edu.cn; zzxxmm414@outlook.com; xus1@cec.sc.edu;
   xingguanyu@scu.edu.cn; willson.wei.hou@qq.com; yczhang@scu.edu.cn
RI Wei, Housheng/X-9733-2019
OI Liu, Yanli/0000-0002-3181-2699; wei, housheng/0000-0002-1139-9788;
   Zhang, Yanci/0000-0001-7045-185X
FU National Natural Science Foundation of China [61972271, 61572333]
FX We thank all the anonymous reviewers for their insightful comments and
   constructive suggestions. This research is supported by National Natural
   Science Foundation of China (Grant No.61972271, 61572333). Guanyu Xing
   is the corresponding author.
CR Andalibi M., 2016, ARTIF INTELL RES, V5, P144
   Barreira J, 2018, IEEE T VIS COMPUT GR, V24, P1223, DOI 10.1109/TVCG.2017.2676777
   Dong Q, 2014, COMPUT GRAPH-UK, V38, P310, DOI 10.1016/j.cag.2013.11.005
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Huang X, 2011, IEEE I CONF COMP VIS, P898, DOI 10.1109/ICCV.2011.6126331
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jacobs K, 2006, COMPUT GRAPH FORUM, V25, P29, DOI 10.1111/j.1467-8659.2006.00816.x
   Jacobs K., 2005, Proceedings of Graphics Interface 2005, P113
   Jiddi S, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P192, DOI 10.1109/ISMAR-Adjunct.2017.63
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Khare M., 2017, MULTIMEDIA TOOLS APP, V77, P1
   Kolivand H, 2015, IETE TECH REV, V32, P3, DOI 10.1080/02564602.2014.906860
   Kolivand H, 2014, MULTIMED TOOLS APPL, V73, P1225, DOI 10.1007/s11042-013-1630-6
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Le HE, 2018, LECT NOTES COMPUT SC, V11206, P680, DOI 10.1007/978-3-030-01216-8_41
   Lee JT, 2016, LECT NOTES COMPUT SC, V9555, P299, DOI 10.1007/978-3-319-30285-0_24
   Liu YL, 2012, IEEE T VIS COMPUT GR, V18, P573, DOI 10.1109/TVCG.2012.53
   Liu YL, 2009, VISUAL COMPUT, V25, P637, DOI 10.1007/s00371-009-0342-4
   Murali S, 2018, INF TECHNOL CONTROL, V47, P75, DOI 10.5755/j01.itc.47.1.15012
   Qin X, 2017, IEEE INT C INT ROBOT, P4284, DOI 10.1109/IROS.2017.8206291
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Russell M., 2016, Comput. Vis. Media, V2, P195, DOI [DOI 10.1007/S41095-016-0058-0, 10.1007/s41095-016-0058-0]
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Sun X, 2015, IEEE T IMAGE PROCESS, V24, P3386, DOI 10.1109/TIP.2015.2447213
   Tian JD, 2016, PATTERN RECOGN, V51, P85, DOI 10.1016/j.patcog.2015.09.006
   Vicente TFY, 2018, IEEE T PATTERN ANAL, V40, P682, DOI 10.1109/TPAMI.2017.2691703
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wei HS, 2019, IEEE ACCESS, V7, P75292, DOI 10.1109/ACCESS.2019.2920950
   Xing GY, 2013, COMPUT GRAPH FORUM, V32, P101, DOI 10.1111/cgf.12217
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
NR 37
TC 0
Z9 0
U1 14
U2 33
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2748
EP 2763
DI 10.1109/TVCG.2020.3041100
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400016
PM 33245695
DA 2024-11-06
ER

PT J
AU Cha, IH
   Ko, HS
AF Cha, Ick-Hoon
   Ko, Hyeong-Seok
TI Tanglement Resolution in Clothing Simulation With Explicit Convergence
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Clothing; Charge coupled devices; Linear systems; Computational
   modeling; Color; Jacobian matrices; Force; Computer graphics; clothing
   simulation; self-collisions; tanglement resolution; re-meshing
ID CONTINUOUS COLLISION DETECTION
AB This article proposes a new discrete collision handling method (DCH method) that can be used for resolving tanglements in clothing simulation, based on the existing continuous collision handling methods (CCH methods). The proposed method performs intersection analysis of the clothing mesh at every time step, and stores the result in the form of coloring the vertices, edges, and triangles. Referring to the coloring, the method resolves the tanglements in the out-to-in manner by applying the proposed operations, the triangle shrinkage and vertex pull, to the triangles and vertices around the intersection path. We take note of the CCH methods that use some small tolerance value to defend the round-off errors for the purpose of preventing false negatives. This work gives a second thought to that tolerance value, and proposes a new DCH method which uses the tolerance value for the resolution purpose. Under certain conditions, the method turns out to guarantee resolution of the tanglements in a finite number of time steps.
C1 [Cha, Ick-Hoon; Ko, Hyeong-Seok] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 08826, South Korea.
C3 Seoul National University (SNU)
RP Cha, IH (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul 08826, South Korea.
EM picklepie@graphics.snu.ac.kr; hsko@graphics.snu.ac.kr
OI Cha, Ick-Hoon/0000-0002-0497-2486
FU R&D program for Advanced Integrated-intelligence for IDentification
   (AIID) through the National Research Foundation of Korea(NRF) - Ministry
   of Science and ICT [2018M3E3A1057288]; Brain of Korea 21 Project in
   2020; ASRI (Automation and Systems Research Institute at Seoul National
   University)
FX This work was supported by R&D program for Advanced
   Integrated-intelligence for IDentification (AIID) through the National
   Research Foundation of Korea(NRF) funded by Ministry of Science and ICT
   under Grant 2018M3E3A1057288, the Brain of Korea 21 Project in 2020, and
   ASRI (Automation and Systems Research Institute at Seoul National
   University).
CR Baraff D, 2003, ACM T GRAPHIC, V22, P862, DOI 10.1145/882262.882357
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Brochu T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185592
   Buffet T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323010
   Choi KJ, 2002, ACM T GRAPHIC, V21, P604, DOI 10.1145/566570.566624
   Curtis S, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P61
   Provot Xavier., 1997, COMPUTER ANIMATION S, P177
   Tang M., 2010, P ACM SIGGRAPH S INT, P7
   Tang M., 2014, ACM T GRAPHIC, V33
   Tang M, 2009, IEEE T VIS COMPUT GR, V15, P544, DOI 10.1109/TVCG.2009.12
   Volino P, 2006, ACM T GRAPHIC, V25, P1154, DOI 10.1145/1141911.1142007
   Wang T., 2017, COMPUT GRAPH FORUM
   Wang ZD, 2015, COMPUT GRAPH FORUM, V34, P289, DOI 10.1111/cgf.12767
   Wicke Martin., 2006, PROC VISION MODELING, P349
   Ye J., 2014, ARXIV14092081
   Ye JT, 2017, COMPUT GRAPH FORUM, V36, P217, DOI 10.1111/cgf.13287
   Ye Juntao, 2012, P ACM SIGGRAPH EUR S, P311
NR 18
TC 2
Z9 2
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2764
EP 2775
DI 10.1109/TVCG.2020.3039566
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400017
PM 33226948
DA 2024-11-06
ER

PT J
AU Wang, XM
   Bryan, C
   Li, YR
   Pan, RS
   Liu, YL
   Chen, W
   Ma, KL
AF Wang, Xumeng
   Bryan, Chris
   Li, Yiran
   Pan, Rusheng
   Liu, Yanling
   Chen, Wei
   Ma, Kwan-Liu
TI Umbra: A Visual Analysis Approach for Defense Construction Against
   Inference Attacks on Sensitive Information
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data privacy; Privacy; Bayes methods; Visualization; Task analysis; Data
   visualization; Data models; Privacy; inference attack; bayesian network;
   visual analytics
ID VISUALIZATION; PRIVACY; PARALLEL; UTILITY
AB Collecting and analyzing anonymous personal information is required as a part of data analysis processes, such as medical diagnosis and restaurant recommendation. Such data should ostensibly be stored so that specific individual information cannot be disclosed. Unfortunately, inference attacks-integrating background knowledge and intelligent models-hinder classic sanitization techniques like syntactic anonymity and differential privacy from exhaustively protecting sensitive information. As a solution, we introduce a three-stage approach empowered within a visual interface, which depicts underlying inference behaviors via a Bayesian Network and supports a customized defense against inference attacks from unknown adversaries. In particular, our approach visually explains the process details of the underlying privacy preserving models, allowing users to verify if the results sufficiently satisfy the requirements of privacy preservation. We demonstrate the effectiveness of our approach through two case studies and expert reviews.
C1 [Wang, Xumeng; Pan, Rusheng; Liu, Yanling; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Bryan, Chris] Arizona State Univ, Phoenix, AZ 85004 USA.
   [Liu, Yanling; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 Zhejiang University; Arizona State University; Arizona State
   University-Downtown Phoenix; University of California System; University
   of California Davis
RP Wang, XM (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM wangxumeng@zju.edu.cn; cbryan16@asu.edu; ranli@ucdavis.edu;
   panrusheng@zju.edu.cn; 3150104312@zju.edu.cn; chenwei@cad.zju.edu.cn;
   ma@cs.ucdavis.edu
RI Chen, Wei/AAR-9817-2020; 王, 叙萌/GZK-9445-2022; Pan, Rusheng/AAA-7007-2020
OI Chen, Wei/0000-0002-8365-4741; Ma, Kwan-Liu/0000-0001-8086-0366; Bryan,
   Christopher/0000-0003-2430-815X
FU National Natural Science Foundation of China [61772456, 61761136020]
FX The authors would like to thank the experts whom they
   consulted/interviewed for this work. Xumeng Wang and Wei Chen was
   supported by National Natural Science Foundation of China under Grants
   61772456, 61761136020.
CR Aljarah I, 2016, STUDENTS ACAD PERFOR
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Cai ZP, 2018, IEEE T DEPEND SECURE, V15, P577, DOI 10.1109/TDSC.2016.2613521
   Canario Y, 2017, HOME INSURANCE
   Chen JY, 2020, IEEE T DEPEND SECURE, V17, P1173, DOI 10.1109/TDSC.2018.2861403
   Chou J.-K., 2016, PROC SIGGRAPH ASIA S
   Chou JK, 2018, IEEE SYM VIS CYB SEC
   Chou JK, 2017, IEEE PAC VIS SYMP, P11, DOI 10.1109/PACIFICVIS.2017.8031573
   Cormode G., 2011, P 17 ACM SIGKDD INT, P1253
   Dasgupta A., 2019, IEEE S VIS CYBER SEC, V9
   Dasgupta A, 2013, COMPUT GRAPH FORUM, V32, P35, DOI 10.1111/cgf.12142
   Dasgupta A, 2011, IEEE T VIS COMPUT GR, V17, P2241, DOI 10.1109/TVCG.2011.163
   Dautrich Jr J.L., 2013, P 16 INT C EXT DAT T, P155
   Duncan GT, 2012, Chance, V17, P16, DOI 10.1080/09332480.2004.10554908
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Hamm J, 2017, J MACH LEARN RES, V18
   He JP, 2018, IEEE T INFORM THEORY, V64, P5677, DOI 10.1109/TIT.2018.2842221
   Heatherly R, 2013, IEEE T KNOWL DATA EN, V25, P1849, DOI 10.1109/TKDE.2012.120
   Islam M. S., 2012, 19 ANN NETW DISTR SY
   Ji SL, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P303
   Kang Ruogu, 2015, S US PRIV SEC SOUPS, P39
   Kao CH, 2017, J SYST ARCHITECT, V80, P85, DOI 10.1016/j.sysarc.2017.09.009
   Keith MJ, 2013, INT J HUM-COMPUT ST, V71, P1163, DOI 10.1016/j.ijhcs.2013.08.016
   Li C, 2007, LECT NOTES COMPUT SC, V4443, P422
   Li G, 2011, RENEW ENERG, V36, P352, DOI 10.1016/j.renene.2010.06.049
   Li N, 2007, INT CONF NANO MICRO, P692, DOI 10.1109/icde.2007.367856
   Li TC, 2009, PROC INT CONF DATA, P6, DOI 10.1109/ICDE.2009.86
   Li ZD, 2006, LECT NOTES COMPUT SC, V4080, P883
   Liu Changchang, 2016, Proceedings of the Network and Distributed System Security (NDSS) Symposium, V16, P21
   Liu H, 2015, EUR J PREV CARDIOL, V22, P1531, DOI 10.1177/2047487314551547
   Maltese A., 2015, Journal of College Science Teaching, V45, P84, DOI [DOI 10.2505/4/JCST150450184, DOI 10.2505/4/JCST15_045_01_84, 10.2505/4/jcst15_045_01_84]
   McVicar D, 2002, J ROY STAT SOC A STA, V165, P317, DOI 10.1111/1467-985X.00641
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Oksanen J, 2015, J TRANSP GEOGR, V48, P135, DOI 10.1016/j.jtrangeo.2015.09.001
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Rao A., 2016, 12 S US PRIV SEC SOU, P77
   Salamatian S, 2015, IEEE J-STSP, V9, P1240, DOI 10.1109/JSTSP.2015.2442227
   Sathiyapriya K., 2013, Int J Data Min Knowl Manage Process, V3, P119, DOI DOI 10.5121/IJDKP.2013.3208
   Shneiderman B, 2020, INT J HUM-COMPUT INT, V36, P495, DOI 10.1080/10447318.2020.1741118
   Sun Y, 2014, PERS UBIQUIT COMPUT, V18, P1871, DOI 10.1007/s00779-014-0787-y
   Timmer S.T., 2013, 25 BEN C ART INT BNA, P199
   Vandenbroucke JP, 2016, INT J EPIDEMIOL, V45, P1776, DOI 10.1093/ije/dyv341
   Voigt Paul, 2017, The eu general data protection regulation (gdpr).A practical guide, V1st, DOI DOI 10.1007/978-3-319-57959-7.PDF
   Wang XM, 2019, IEEE T INTELL TRANSP, V20, P3375, DOI 10.1109/TITS.2018.2875021
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wang XM, 2018, IEEE T VIS COMPUT GR, V24, P351, DOI 10.1109/TVCG.2017.2745139
   Warren S. D., 1890, Harv. L. Rev, V4, P193, DOI [https://doi.org/10.2307/1321160, DOI 10.2307/1321160]
   Witten IH, 2011, MOR KAUF D, P1
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang B, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P747, DOI 10.1145/2723372.2747643
   Yet B, 2016, EXPERT SYST APPL, V60, P141, DOI 10.1016/j.eswa.2016.05.005
   Yue K, 2015, IEEE T CYBERNETICS, V45, P2890, DOI 10.1109/TCYB.2015.2388791
   Zhang S., 2011, J INFORM SECURITY, V2, P8
   Zhao P, 2019, IEEE INTERNET THINGS, V6, P808, DOI 10.1109/JIOT.2018.2858240
NR 55
TC 3
Z9 3
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2776
EP 2790
DI 10.1109/TVCG.2020.3037670
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400018
PM 33180726
DA 2024-11-06
ER

PT J
AU Ghosh, A
   Nashaat, M
   Miller, J
   Quader, S
AF Ghosh, Aindrila
   Nashaat, Mona
   Miller, James
   Quader, Shaikh
TI VisExPreS: A Visual Interactive Toolkit for User-Driven Evaluations of
   Embeddings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Visualization; Quality assessment; Data visualization;
   Stress; Distortion; Linear programming; Data and knowledge
   visualization; interactive data exploration and discovery; knowledge and
   data engineering tools and techniques
ID REPRESENTATIVE SUBSET
AB Although popularly used in big-data analytics, dimensionality reduction is a complex, black-box technique whose outcome is difficult to interpret and evaluate. In recent years, a number of quantitative and visual methods have been proposed for analyzing low-dimensional embeddings. On the one hand, quantitative methods associate numeric identifiers to qualitative characteristics of these embeddings; and, on the other hand, visual techniques allow users to interactively explore these embeddings and make decisions. However, in the former case, users do not have control over the analysis, while in the latter case. assessment decisions are entirely dependent on the user's perception and expertise. In order to bridge the gap between the two, in this article, we present VisExPreS, a visual interactive toolkit that enables a user-driven assessment of low-dimensional embeddings. VisExPreS is based on three novel techniques namely PG-LAPS, PG-GAPS, and RepSubset, that generate interpretable explanations of the preserved local and global structures in embeddings. In the first two techniques, the VisExPreS system proactively guides users during every step of the analysis. We demonstrate the utility of VisExPreS in interpreting, analyzing, and evaluating embeddings from different dimensionality reduction algorithms using multiple case studies and an extensive user study.
C1 [Ghosh, Aindrila; Nashaat, Mona; Miller, James] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2R3, Canada.
   [Quader, Shaikh] IBM Toronto Software Lab, Toronto, ON L6G 1C7, Canada.
C3 University of Alberta; International Business Machines (IBM)
RP Ghosh, A (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2R3, Canada.
EM aindrila@ualberta.ca; nashaata@ualberta.ca; jimm@ualberta.ca;
   shaikhq@ca.ibm.com
RI Ghosh, Aindrila/KFA-4845-2024; Nashaat, Mona/KPY-0439-2024
OI Ghosh, Aindrila/0000-0003-4908-9491; Nashaat, Mona/0000-0002-7580-5757;
   Miller, James/0000-0001-5095-3000
CR Amid E., 2018, ARXIV180300854
   Angulo C, 2003, NEUROCOMPUTING, V55, P57, DOI 10.1016/S0925-2312(03)00435-1
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   Bibal A., 2019, Safe Machine Learning Workshop at ICLR
   Boyd JP, 2001, APPL MATH LETT, V14, P477, DOI 10.1016/S0893-9659(00)00180-4
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI [10.1371/journal.pone.0170531, DOI 10.1371/JOURNAL.PONE.0170531]
   Bunte K., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P349, DOI 10.1109/CIDM.2011.5949443
   Cavallo M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174209
   CHAUDHURI BB, 1994, PATTERN RECOGN LETT, V15, P893, DOI 10.1016/0167-8655(94)90151-1
   CHAUDHURI D, 1994, IEEE T SYST MAN CYB, V24, P1416, DOI 10.1109/21.310520
   Clark RD, 1997, J CHEM INF COMP SCI, V37, P1181, DOI 10.1021/ci970282v
   Cutura R, 2018, PROC 26 EUR S ARTIFL
   da Silva R. R., 2015, InEuroVA@ EuroVis, P31
   Daszykowski M, 2002, ANAL CHIM ACTA, V468, P91, DOI 10.1016/S0003-2670(02)00651-7
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   France S. L., 2019, ARXIV190208571
   Gani W, 2016, J STAT COMPUT SIM, V86, P135, DOI 10.1080/00949655.2014.996758
   Georgsson M, 2016, J AM MED INFORM ASSN, V23, P5, DOI 10.1093/jamia/ocv099
   Ghosh A, 2022, IEEE T KNOWL DATA EN, V34, P2227, DOI 10.1109/TKDE.2020.3005878
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   Guidotti R., 2018, CoRR abs/1805.10820, V1805, P10820
   HAFTKA RT, 1991, AIAA J, V29, P1523, DOI 10.2514/3.10768
   Heimerl F., 2019, ARXIV191101542
   Johannemann J., 2019, ARXIV190701974
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   KENNARD RW, 1969, TECHNOMETRICS, V11, P137, DOI 10.2307/1266770
   Lai CF, 2018, J VISUAL LANG COMPUT, V48, P144, DOI 10.1016/j.jvlc.2018.08.006
   Lee JA, 2010, PATTERN RECOGN LETT, V31, P2248, DOI 10.1016/j.patrec.2010.04.013
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Lespinats S, 2011, COMPUT GRAPH FORUM, V30, P113, DOI 10.1111/j.1467-8659.2010.01835.x
   Levina E., 2004, NIPS, P777
   Lewis J. M., 2012, PROC ANN M COGN SCI, V34, P7
   Mahmood S, 2020, IEEE T VIS COMPUT GR, V26, P2875, DOI 10.1109/TVCG.2019.2895642
   Mall R, 2013, SOC NETW ANAL MIN, V3, P1075, DOI 10.1007/s13278-013-0144-6
   Martins RM, 2014, COMPUT GRAPH-UK, V41, P26, DOI 10.1016/j.cag.2014.01.006
   Motta R, 2015, NEUROCOMPUTING, V150, P583, DOI 10.1016/j.neucom.2014.09.063
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pagliosa L, 2016, SIBGRAPI, P297, DOI [10.1109/SIBGRAPI.2016.048, 10.1109/SIBGRAPI.2016.45]
   Plumb G., 2019, ARXIV 180702910
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rieck B., 2017, Topological Methods in Data Analysis and Visualization IV: Theory, Algorithms, and Applications VI, P103
   Schreck T, 2010, INFORM VISUAL, V9, P181, DOI 10.1057/ivs.2010.2
   Sedlmair M., 2012, Tech. Rep. TR-2012-03
   Self J. Z., 2015, ANDROMEDA OBSERVATIO
   Smilkov Daniel, 2016, ARXIV161105469
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Tominaga Y, 1998, CHEMOMETR INTELL LAB, V43, P157, DOI 10.1016/S0169-7439(98)00085-9
   van der Maaten L., 2008, J MACH LEARN RES 10, V66, P13
   Wang HY, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/695720
   Xia JZ, 2018, IEEE T VIS COMPUT GR, V24, P236, DOI 10.1109/TVCG.2017.2744098
NR 52
TC 3
Z9 3
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2791
EP 2807
DI 10.1109/TVCG.2020.3039106
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400019
PM 33211658
DA 2024-11-06
ER

PT J
AU Williams, AS
   Garcia, J
   Ortega, F
AF Williams, Adam S.
   Garcia, Jason
   Ortega, Francisco
TI Understanding Multimodal User Gesture and Speech Behavior for Object
   Manipulation in Augmented Reality Using Elicitation (vol 26, pg 3479,
   2020)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Correction
DE Behavioral sciences; Augmented reality
C1 [Williams, Adam S.; Garcia, Jason; Ortega, Francisco] Colorado State Univ, Ft Collins, CO 80523 USA.
C3 Colorado State University
RP Williams, AS (corresponding author), Colorado State Univ, Ft Collins, CO 80523 USA.
EM adamwil@colostate.edu; j.s.garcia@colostate.edu; f.ortega@colostate.edu
CR Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
NR 1
TC 0
Z9 0
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2022
VL 28
IS 7
BP 2808
EP 2808
DI 10.1109/TVCG.2022.3164438
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P2OA
UT WOS:000801853400020
PM 35617166
OA Bronze
DA 2024-11-06
ER

PT J
AU Ye, H
   Kwan, KC
   Fu, HB
AF Ye, Hui
   Kwan, Kin Chung
   Fu, Hongbo
TI 3D Curve Creation on and Around Physical Objects With Mobile AR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Mobile handsets; Two dimensional displays;
   Tracking; Visualization; Cameras; Tools; Mobile augmented reality;
   In-situ 3D drawing; interactive system; curve refinement; optimization
ID SLAM
AB The recent advance in motion tracking (e.g., Visual Inertial Odometry) allows the use of a mobile phone as a 3D pen, thus significantly benefiting various mobile Augmented Reality (AR) applications based on 3D curve creation. However, when creating 3D curves on and around physical objects with mobile AR, tracking might be less robust or even lost due to camera occlusion or textureless scenes. This motivates us to study how to achieve natural interaction with minimum tracking errors during close interaction between a mobile phone and physical objects. To this end, we contribute an elicitation study on input point and phone grip, and a quantitative study on tracking errors. Based on the results, we present a system for direct 3D drawing with an AR-enabled mobile phone as a 3D pen, and interactive correction of 3D curves with tracking errors in mobile AR. We demonstrate the usefulness and effectiveness of our system for two applications: in-situ 3D drawing, and direct 3D measurement.
C1 [Ye, Hui; Kwan, Kin Chung; Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
   [Kwan, Kin Chung] Univ Konstanz, D-78464 Constance, Germany.
C3 City University of Hong Kong; University of Konstanz
RP Fu, HB (corresponding author), City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
EM huiye4-c@my.cityu.edu.hk; kinckwan@cityu.edu.hk; hongbofu@cityu.edu.hk
OI FU, Hongbo/0000-0002-0284-726X; Ye, Hui/0000-0001-9539-9920
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CityU 11212119]; City University of Hong Kong [7005590, 7005176];
   Centre for Applied Computing and Interactive Media (ACIM) of School of
   Creative Media, CityU
FX The authors would like to thank the anonymous reviewers for the
   constructive comments. This work was supported by an unrestricted gift
   from Adobe and grants from the Research Grants Council of the Hong Kong
   Special Administrative Region, China (Project No. CityU 11212119), City
   University of Hong Kong under Grants No. 7005590 and No. 7005176, and
   the Centre for Applied Computing and Interactive Media (ACIM) of School
   of Creative Media, CityU.
CR Agrawal S., 2011, Proceedings of the 9th International Conference on Mobile Systems, Applications, P15, DOI DOI 10.1145/1999995.1999998
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514
   [Anonymous], 2018, ASHRAE Handbook: Refrigeration
   Arora R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173759
   Babic T, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P2, DOI 10.1145/3267782.3267785
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Botsch M, 2008, IEEE T VIS COMPUT GR, V14, P213, DOI 10.1109/TVCG.2007.1054
   Choi B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925970
   Cohen J. M., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P17, DOI 10.1145/300523.300655
   Darbar R., 2015, PROC IEEE INT C ELEC, P1
   Deering M. F., 1995, ACM T COMPUT-HUM INT, V2, P220
   Deselaers T, 2015, IEEE T HUM-MACH SYST, V45, P263, DOI 10.1109/THMS.2014.2365723
   European Commission/EACEA/Eurydice, 2018, NATL STUDENT FEE SUP
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321
   Grey J., 2002, BADWATER HOTLICKS
   Grey J., 2003, CENTAUR
   Grimm C., 2012, P INT S SKETCH BAS I, P121
   Grossman T., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P121, DOI 10.1145/503376.503398
   GRYMALA, 2019, AR PLAN 3D
   GRYMALA,, 2017, AR RUL
   Guay M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766893
   Huo K, 2017, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'17), P37, DOI 10.1145/3024969.3024995
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Karpenko Olga., 2004, Proc. Eurographics Symposium on Sketch-Based Interfaces and Modeling, P167, DOI DOI 10.2312/SBM/SBM04/167-173
   Keefe D.F., 2001, P S INT 3D GRAPH NEW, P85
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Kim Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173812
   Kim Y, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P797, DOI 10.1145/2984511.2984567
   Krs V, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073603
   Kwan KC, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300406
   L. Labs, 2017, AIRM
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251
   M. A. Corporation,, 1982, MOT AN
   Mohanty RR, 2018, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2018, VOL 1B
   NaturalPoint I, 1996, OPT
   Nerurkar E., 2020, U.S. Patent, Patent No. 10802147
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   SAUL G., 2010, P 7 SKETCH BAS INT M, P17
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Schmidt R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618495
   Siek KA, 2005, LECT NOTES COMPUT SC, V3585, P267, DOI 10.1007/11555261_24
   Su QK, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601202
   Taketomi T., 2017, IPSJ Trans Comput Vis Appl, V9, P16, DOI 10.1186/s41074-017-0027-2
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Ventura J, 2014, IEEE T VIS COMPUT GR, V20, P531, DOI 10.1109/TVCG.2014.27
   Wacker P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300849
   Xin Min, 2008, P 2008 ACM S VIRT RE, P223, DOI DOI 10.1145/1450579.1450627
   Xu BX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601128
   Xu PF, 2019, IEEE T VIS COMPUT GR, V25, P2927, DOI 10.1109/TVCG.2018.2860016
   Yan ZX, 2017, IEEE T VIS COMPUT GR, V23, P2389, DOI 10.1109/TVCG.2017.2734458
   Ye H, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392404
   Yue YT, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3693, DOI 10.1145/3025453.3025792
NR 53
TC 8
Z9 8
U1 2
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2809
EP 2821
DI 10.1109/TVCG.2020.3049006
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600001
PM 33400650
DA 2024-11-06
ER

PT J
AU Bletterer, A
   Payan, F
   Antonini, M
AF Bletterer, Arnaud
   Payan, Frederic
   Antonini, Marc
TI A Local Graph-Based Structure for Processing Gigantic Aggregated 3D
   Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Surface morphology; Random access memory;
   Surface treatment; Solid modeling; Sensors; Two dimensional displays;
   Computational geometry and object modeling; three-dimensional graphics
   and realism; 3D point clouds; data structure; graphs; out-of-core
   algorithms; poisson-disk sampling
ID OCTREE
AB We present an original workflow for structuring a point cloud generated from several scans. Our representation is based on a set of local graphs. Each graph is constructed from the depth map provided by each scan. The graphs are then connected together via the overlapping areas, and careful consideration of the redundant points in these regions leads to a piecewise and globally consistent structure for the underlying surface sampled by the point cloud. The proposed workflow allows structuring aggregated point clouds, scan after scan, whatever the number of acquisitions and the number of points per acquisition, even on computers with very limited memory capacities. To show that our structure can be highly relevant for the community, where the gigantic amount of data represents a real scientific challenge per se, we present an algorithm based on this structure capable of resampling billions of points on standard computers. This application is particularly attractive for simplifying and visualizing gigantic point clouds representing very large-scale scenes (buildings, urban scenes, historical sites...), which often require a prohibitive number of points to describe them accurately.
C1 [Bletterer, Arnaud; Payan, Frederic; Antonini, Marc] Univ Cote dAzur, I3S CNRS, Nice, France.
C3 Universite Cote d'Azur; Centre National de la Recherche Scientifique
   (CNRS)
RP Payan, F (corresponding author), Univ Cote dAzur, I3S CNRS, Nice, France.
EM bletterer@i3s.unice.fr; fpayan@i3s.unice.fr; am@i3s.unice.fr
OI Antonini, Marc/0000-0002-7012-1735; Payan, Frederic/0000-0001-9885-6445;
   Bletterer, Arnaud/0000-0002-0573-9141
FU Region Sud (France)
FX TEMPLO MAYOR, MEETING HOUSE, ANANDA OAK KYAUNG, WAT PHRA SI SANPHET, EIM
   YA KYAUNG and KHAYMINGHA are courtesy of the CyArk/Google Open Heritage
   Program [29]. PALAIS (EXT.) and PALAIS (INT.) are courtesy of Art
   Graphique et Patrimoine. FERTILITY and VENUS are courtesy of
   AIM@SHAPE-VISIONAIR Shape Repository [30]. ARMADILLO and DRAGON are
   courtesy of the Stanford Computer Graphics Laboratory [31]. This work
   was supported by a grant from Region Sud (France). This work was partly
   presented in [1] and [2].
CR AIM@SHAPE-VISIONAIR, AIM SHAP VIS SHAP RE
   [Anonymous], 2014, AMBIENT 2014 4 INT C
   [Anonymous], 2007, ACM SIGGRAPH 2007 CO
   Biasutti P, 2019, VISAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 4, P27, DOI 10.5220/0007308600270035
   Bletterer A., 2018, PROC 16 EURO GRAPHIC, P1
   Bletterer A., 2018, PROC S GEOMETRY PROC, DOI [10.2312/sgp20181178, DOI 10.2312/SGP20181178]
   Boltcheva D, 2017, COMPUT AIDED DESIGN, V90, P123, DOI 10.1016/j.cad.2017.05.011
   Bowers J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866188
   Chen SH, 2018, IEEE T SIGNAL PROCES, V66, P666, DOI 10.1109/TSP.2017.2771730
   Cignoni P., 2008, P 6 EUR IT CHAPT C E, P129
   Cline D, 2009, COMPUT GRAPH FORUM, V28, P1217, DOI 10.1111/j.1467-8659.2009.01499.x
   COOK RL, 1986, ACM T GRAPHIC, V5, P51, DOI 10.1145/7529.8927
   Corsini M, 2012, IEEE T VIS COMPUT GR, V18, P914, DOI 10.1109/TVCG.2012.34
   Dachsbacher C, 2003, ACM T GRAPHIC, V22, P657, DOI 10.1145/882262.882321
   Dijkstra E. W., 1959, Numer. Math, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/BF01386390]
   Elseberg J, 2013, ISPRS J PHOTOGRAMM, V76, P76, DOI 10.1016/j.isprsjprs.2012.10.004
   Fu Y, 2008, SPM 2008: PROCEEDINGS OF THE ACM SOLID AND PHYSICAL MODELING SYMPOSIUM, P115
   Google/CyArk, OP HER
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0
   Levoy M., The stanford 3d scanning repository
   Loop C., 2013, P 5 HIGH PERF GRAPH, P73
   Peng JL, 2005, ACM T GRAPHIC, V24, P609, DOI 10.1145/1073204.1073237
   Peyrot JL, 2015, VISUAL COMPUT, V31, P1365, DOI 10.1007/s00371-014-1019-1
   Pietroni N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024183
   Rivest J.-F., 1993, Journal of Electronic Imaging, V2, P326, DOI 10.1117/12.159642
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Ryde J, 2010, AUTON ROBOT, V28, P169, DOI 10.1007/s10514-009-9158-3
   Schnabel R., 2006, P PBG SIGGRAPH, V3, P1
   Thanou D, 2016, IEEE T IMAGE PROCESS, V25, P1765, DOI 10.1109/TIP.2016.2529506
   Wei LY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964945
   Xu Y, 2012, COMPUT GRAPH-UK, V36, P232, DOI 10.1016/j.cag.2012.02.005
NR 31
TC 3
Z9 3
U1 1
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2822
EP 2833
DI 10.1109/TVCG.2020.3042588
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600002
PM 33275583
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gabbard, JL
   Smith, M
   Merenda, C
   Burnett, G
   Large, DR
AF Gabbard, Joseph L.
   Smith, Missie
   Merenda, Coleman
   Burnett, Gary
   Large, David R.
TI A Perceptual Color-Matching Method for Examining Color Blending in
   Augmented Reality Head-Up Display Graphics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Color; Optical distortion; Graphics; Lighting;
   Visualization; Distortion; D; 2; 14; a user interfaces; H; 1; 2; a human
   factors; H; 5; 1; b artificial; augmented; and virtual realities; I; 4;
   8; a color
ID TEXT DRAWING STYLES; BACKGROUND TEXTURES; LEGIBILITY; EYE
AB Augmented reality (AR) offers new ways to visualize information on-the-go. As noted in related work, AR graphics presented via optical see-through AR displays are particularly prone to color blending, whereby intended graphic colors may be perceptually altered by real-world backgrounds, ultimately degrading usability. This work adds to this body of knowledge by presenting a methodology for assessing AR interface color robustness, as quantitatively measured via shifts in the CIE color space, and qualitatively assessed in terms of users' perceived color name. We conducted a human factors study where twelve participants examined eight AR colors atop three real-world backgrounds as viewed through an in-vehicle AR head-up display (HUD); a type of optical see-through display used to project driving-related information atop the forward-looking road scene. Participants completed visual search tasks, matched the perceived AR HUD color against the WCS color palette, and verbally named the perceived color. We present analysis that suggests blue, green, and yellow AR colors are relatively robust, while red and brown are not, and discuss the impact of chromaticity shift and dispersion on outdoor AR interface design. While this work presents a case study in transportation, the methodology is applicable to a wide range of AR displays in many application domains and settings.
C1 [Gabbard, Joseph L.; Merenda, Coleman] Virginia Tech, Grad Dept Ind & Syst Engn, Blacksburg, VA 24061 USA.
   [Smith, Missie] Oakland Univ, Ind & Syst Engn Dept, Rochester, MI 48309 USA.
   [Burnett, Gary; Large, David R.] Univ Nottingham, Human Factors Res Grp, Nottingham NG7 2RD, England.
C3 Virginia Polytechnic Institute & State University; Oakland University;
   University of Nottingham
RP Smith, M (corresponding author), Oakland Univ, Ind & Syst Engn Dept, Rochester, MI 48309 USA.
EM jbabbard@vt.edu; mismith@oakland.edu; cjm120@vt.edu;
   gary.burnett@nottingham.ac.uk; david.r.large@nottingham.ac.uk
OI Smith, Missie/0000-0001-9594-7640
FU NSF [1261162, 1816721]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1816721] Funding Source: National
   Science Foundation; Office Of Internatl Science &Engineering; Office Of
   The Director [1261162] Funding Source: National Science Foundation
FX The authors would like to thank Nicole Sanderlin, Jack Lesko, Valerie
   Kane, Catherine Harvey, Elizabeth Crundall, Ayse Eren, and Claire
   Merenda. This work was supported in part by a grants from the NSF under
   Grant 1261162 & 1816721.
CR [Anonymous], 1929, T OPT SOC, DOI DOI 10.1088/1475-4878/30/4/301
   Berlin B., 1991, Basic Color Terms: Their Universality and Evolution
   Boyce P.R., 1997, Handbook of Human Factors and Ergonomics, VFourth, P673
   Cook R. S., 2005, Handbook of categorization in cognitive science, P223, DOI DOI 10.1016/B978-008044612-7/50064-0
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Di Donato M, 2015, COMPUT IND, V70, P70, DOI 10.1016/j.compind.2015.02.008
   Flatla DR, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P195
   Flatla DR, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2563
   Foley J. D., 1994, Introduction to computer graphics, V55
   Fukiage T, 2014, INT SYM MIX AUGMENT, P63, DOI 10.1109/ISMAR.2014.6948410
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2005, P IEEE VIRT REAL ANN, P11
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gabbard JL, 2013, P IEEE VIRT REAL ANN, P157, DOI 10.1109/VR.2013.6549410
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Gattullo M, 2015, IEEE T VIS COMPUT GR, V21, P638, DOI 10.1109/TVCG.2014.2385056
   Gattullo M, 2015, IEEE COMPUT GRAPH, V35, P52, DOI 10.1109/MCG.2015.36
   Grundhöfer A, 2008, IEEE T VIS COMPUT GR, V14, P97, DOI 10.1109/TVCG.2007.1052
   Guild J, 1932, PHILOS T R SOC LOND, V230, P149, DOI 10.1098/rsta.1932.0005
   Harrison B. L., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P391, DOI 10.1145/238386.238583
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hincapié-Ramos JD, 2015, IEEE T VIS COMPUT GR, V21, P1336, DOI 10.1109/TVCG.2015.2450745
   Itoh Y, 2019, IEEE T VIS COMPUT GR, V25, P1951, DOI 10.1109/TVCG.2019.2899229
   Itoh Y, 2015, IEEE T VIS COMPUT GR, V21, P1269, DOI 10.1109/TVCG.2015.2459892
   Joblove G. H., 1978, P 5 ANN C COMPUTER G, V12, P20, DOI [10.1145/800248.807362, 10.1145/965139.807362]
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kerr D. A., 2003, INTERNET
   Kim K, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357584
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Langlotz T, 2016, IEEE T VIS COMPUT GR, V22, P2385, DOI 10.1109/TVCG.2016.2593781
   Large D., 2016, HUM FACT COMPL SYST
   Lee JW, 2015, INT CONF ADV COMMUN, P263, DOI 10.1109/ICACT.2015.7224799
   Lenneberg EricH., 1956, LANGUAGE EXPERIENCE
   Lisle L, 2019, INT J MOB HUM COMPUT, V11, P1, DOI 10.4018/IJMHCI.2019040101
   Livingston Mark A., 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P3, DOI 10.1109/ISMAR.2006.297788
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P115, DOI 10.1109/VR.2009.4811009
   MacAdam DL, 1942, J OPT SOC AM, V32, P247, DOI 10.1364/JOSA.32.000247
   Medenica Zeljko, 2011, P 13 INT C HUM COMP, P265, DOI [10.1145/2037373.2037414, DOI 10.1145/2037373.2037414]
   Mollon JD., 2003, The science of color, P1, DOI [10.1016/B978-044451251-2/50002-7, DOI 10.1016/B978-044451251-2/50002-7]
   Mori S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI 10.1109/VR.2018.8446441
   Narzt W., 2006, Universal Access in the Information Society, V4, P177, DOI 10.1007/s10209-005-0017-5
   Nickerson D, 1940, J OPT SOC AM, V30, P575, DOI 10.1364/JOSA.30.000575
   Ohta N, 2005, COLORIMETRY: FUNDAMENTALS AND APPLICATIONS, P1, DOI 10.1002/0470094745
   Paley W. B., 2003, UIST 03, P57
   Park BJ, 2015, INT CONF ADV COMMUN, P593, DOI 10.1109/ICACT.2015.7224865
   Reinecke K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2693, DOI 10.1145/2858036.2858077
   Sanches S. R. R., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P49, DOI 10.1109/WACV.2012.6163037
   Seo S, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0357-8
   Sridharan SrikanthKirshnamachari., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P231
   STURGES J, 1995, COLOR RES APPL, V20, P364, DOI 10.1002/col.5080200605
   Tang A., 2003, COMP EFFECTIVENESS A, P73
   Thomas B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P139, DOI 10.1109/ISWC.2000.888480
   Thomas B, 2002, PERS UBIQUIT COMPUT, V6, P75, DOI 10.1007/s007790200007
   Tkalcic M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P304
   Van Krevelen D., 2010, INT J VIRT REAL, V9, P1, DOI [DOI 10.20870/IJVR.2010.9.2.2767, https://doi.org/10.20870/IJVR.2010.9.2.2767]
   Veas E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1471
   Vigier M, 2020, MIDWEST SYMP CIRCUIT, P876, DOI [10.1109/MWSCAS48704.2020.9184480, 10.1109/mwscas48704.2020.9184480]
   Zhang L., 2018, COLOR IMAGING C, P102
NR 60
TC 21
Z9 21
U1 12
U2 83
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2834
EP 2851
DI 10.1109/TVCG.2020.3044715
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600003
PM 33315569
OA Green Accepted, Bronze
DA 2024-11-06
ER

PT J
AU Morrical, N
   Wald, I
   Usher, W
   Pascucci, V
AF Morrical, Nate
   Wald, Ingo
   Usher, Will
   Pascucci, Valerio
TI Accelerating Unstructured Mesh Point Location With RT Cores
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scientific ray tracing; unstructured scalar data; GPGPU; simulation;
   volume rendering
ID VOLUME; VISUALIZATION; SIMULATION; TREES
AB We present a technique that leverages ray tracing hardware available in recent Nvidia RTX GPUs to solve a problem other than classical ray tracing. Specifically, we demonstrate how to use these units to accelerate the point location of general unstructured elements consisting of both planar and bilinear faces. This unstructured mesh point location problem has previously been challenging to accelerate on GPU architectures; yet, the performance of these queries is crucial to many unstructured volume rendering and compute applications. Starting with a CUDA reference method, we describe and evaluate three approaches that reformulate these point queries to incrementally map algorithmic complexity to these new hardware ray tracing units. Each variant replaces the simpler problem of point queries with a more complex one of ray queries. Initial variants exploit ray tracing cores for accelerated BVH traversal, and subsequent variants use ray-triangle intersections and per-face metadata to detect point-in-element intersections. Although these later variants are more algorithmically complex, they are significantly faster than the reference method thanks to hardware acceleration. Using our approach, we improve the performance of an unstructured volume renderer by up to 4x for tetrahedral meshes and up to 15x for general bilinear element meshes, matching, or out-performing state-of-the-art solutions while simultaneously improving on robustness and ease-of-implementation.
C1 [Morrical, Nate; Usher, Will; Pascucci, Valerio] Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.
   [Wald, Ingo] NVIDIA, Santa Clara, CA 95051 USA.
C3 Utah System of Higher Education; University of Utah; Nvidia Corporation
RP Morrical, N (corresponding author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.
EM natemorrical@gmail.com; ingowald@gmail.com; will@sci.utah.edu;
   pascucci@sci.utah.edu
RI pascucci, Valerio/GXF-0616-2022
OI Morrical, Nathan/0000-0002-2262-6974; pascucci,
   valerio/0000-0002-8877-2042; Usher, Will/0000-0001-5008-8280
FU NSF [1314896, 1602127, 1649923, 1842042]; DOE [DE-SC0007446,
   DE-NA0002375]; U.S. Department of Energy (DOE) [DE-SC0007446] Funding
   Source: U.S. Department of Energy (DOE); Direct For Computer & Info Scie
   & Enginr; Div Of Information & Intelligent Systems [1314896] Funding
   Source: National Science Foundation; Directorate For Engineering; Div Of
   Industrial Innovation & Partnersh [1602127] Funding Source: National
   Science Foundation; Office of Advanced Cyberinfrastructure (OAC); Direct
   For Computer & Info Scie & Enginr [1649923, 1842042] Funding Source:
   National Science Foundation
FX The Agulhas data set is courtesy of Dr. Niklas Rober (DKRZ); the Japan
   Earthquake data set is courtesy of Carsten Burstedde, Omar Ghattas,
   James R. Martin, Georg Stadler, and Lucas C. Wilcox (ICES, the
   University of Texas at Austin) and Paul Navratil and Greg Abram (TACC).
   Hardware for development and testing was graciously provided by Nvidia
   Corp. This work was supported in part by NSF: CGV Award: 1314896,
   NSF:IIP Award: 1602127, NSF:ACI Award: 1649923, DOE/SciDAC DESC0007446,
   CCMSC DE-NA0002375, and NSF:OAC Award: 1842042.
CR [Anonymous], 2001, P 2001 ACMIEEE C SUP
   [Anonymous], 2018, CUDA C PROGRAMMING G
   Biedron R. T., 2019, FUN3D Manual: 13.6
   Childs H., 2012, HIGH PERFORMANCE VIS, P357
   Ganter D, 2019, COMPUT GRAPH FORUM, V38, P13, DOI 10.1111/cgf.13756
   Glassner A.S., 1989, An Introduction to Ray Tracing M
   Green Simon., 2003, NVIDIA CLOTH SAMPLE
   Gribble C., 2019, RAY TRACING GEMS HIG
   Haidar A., 2018, P INT C HIGH PERF
   Haines Eric., 2019, RAY TRACING GEMS HIG
   Howard MP, 2016, COMPUT PHYS COMMUN, V203, P45, DOI 10.1016/j.cpc.2016.02.003
   Kim D., 2019, PROC 21 EUROGRAPHICS, P77
   Kim T., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P86
   Knoll A., 2019, Ray Tracing Gems, Chapter 29: Efficient Particle Volume Splatting in a Ray Tracer, P533, DOI [10.1007/978-1-4842-4427-2_29, DOI 10.1007/978-1-4842-4427-2_29]
   Krüger J, 2005, COMPUT GRAPH FORUM, V24, P685, DOI 10.1111/j.1467-8659.2005.00893.x
   Maximo A, 2010, COMPUT GRAPH FORUM, V29, P903, DOI 10.1111/j.1467-8659.2009.01673.x
   Moreland K, 2003, P ACM SIGGRAPH EUROG, V112, P112, DOI DOI 10.2312/EGGH.EGGH03.112-119
   Morrical Nate, 2019, 2019 IEEE Visualization Conference (VIS), P256, DOI 10.1109/VISUAL.2019.8933539
   Muigg P, 2007, IEEE T VIS COMPUT GR, V13, P1592, DOI 10.1109/TVCG.2007.70588
   Muigg P, 2011, IEEE T VIS COMPUT GR, V17, P2115, DOI 10.1109/TVCG.2011.216
   Nelson B, 2012, IEEE T VIS COMPUT GR, V18, P2325, DOI 10.1109/TVCG.2012.218
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   NVIDIA, 2018, Technical Report WP -09183-001 v01
   Olliff J, 2018, COMPUT MECH, V62, P1461, DOI 10.1007/s00466-018-1574-9
   Owens JD, 2007, COMPUT GRAPH FORUM, V26, P80, DOI 10.1111/j.1467-8659.2007.01012.x
   Parker SG, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778803
   Pineda J., 1988, Computer Graphics, V22, P17, DOI 10.1145/378456.378457
   Rathke B., 2015, P EUR S PAR GRAPH VI, P33
   Reshetov A, 2019, Cool Patches: A Geometric Approach to Ray/ Bilinear Patch Intersections, P95
   Rumpf M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1103, DOI 10.1109/ICIP.2001.958320
   Rumpf M., 2001, Visualization, Imaging, and Image Processing. Proceedings of the IASTED International Conference, P193
   Salmon JL, 2019, PROCEEDINGS OF 2019 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2019), P19, DOI 10.1109/PMBS49563.2019.00008
   Sawhney R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392374
   Shirley P., 1990, Computer Graphics, V24, P63, DOI 10.1145/99308.99322
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Ulmstedt M., 2019, GPU accelerated ray-tracing for simulating sound propagation in water
   Vinkler M, 2016, COMPUT GRAPH FORUM, V35, P68, DOI 10.1111/cgf.12776
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Wald I., 2019, High Performance Graphics (Short Papers), P7, DOI DOI 10.2312/HPG.20191189
   Wald I, 2021, IEEE T VIS COMPUT GR, V27, P625, DOI 10.1109/TVCG.2020.3030470
   Wald I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601199
   Yang B, 2008, COMPUT MECH, V41, P189, DOI 10.1007/s00466-006-0116-z
   Zellmann S., 2020, ARXIV200811235
NR 43
TC 7
Z9 9
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2852
EP 2866
DI 10.1109/TVCG.2020.3042930
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600004
PM 33290224
OA Bronze
DA 2024-11-06
ER

PT J
AU Anderson, CL
   Robinson, AC
AF Anderson, Cary L.
   Robinson, Anthony C.
TI Affective Congruence in Visualization Design: Influences on Reading
   Categorical Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Data visualization; Visualization; Task analysis;
   Automobiles; Tools; Sports; Color; visualization; emotion; design;
   cartography
ID COLOR; OPTIMIZATION; PERCEPTION; SCALES
AB Recent work in data visualization has demonstrated that small, perceptually-distinct color palettes-such as those used in categorical mapping-can connote significant affective qualities. Data that are mapped or otherwise visualized are also often emotive in nature, either inherently (e.g., climate change, disease mortality rates), or by design, such as can be found in visual storytelling. However, little is known about how the affective qualities of color interact with those of data context in visualization design. This article describes the results of a crowdsourced study on the influence of affectively congruent versus incongruent color schemes on categorical map-reading response. We report both objective (pattern detection; area comparison) and subjective (affective quality; appropriateness; preference) measures of map-reader response. Our results suggest that affectively congruent colors amplify perceptions of the affective qualities of maps with emotive topics, affective incongruence may cause confusion, and that affective congruence is particularly influential in maps of positive-leaning data topics. Finally, we offer preliminary design recommendations for balancing color congruence with other design factors, and for synthesizing color and affective context in thematic map design.
C1 [Anderson, Cary L.] Univ Pittsburgh, Katz Grad Sch Business, Mkt & Business Econ Area, Pittsburgh, PA 15260 USA.
   [Robinson, Anthony C.] Penn State Univ, GeoVISTA Ctr, Dept Geog, University Pk, PA 16803 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); Pennsylvania State University; Pennsylvania State University -
   University Park
RP Anderson, CL (corresponding author), Univ Pittsburgh, Katz Grad Sch Business, Mkt & Business Econ Area, Pittsburgh, PA 15260 USA.
EM cla77@pitt.edu; acr181@psu.edu
RI Robinson, Anthony/AAZ-3051-2020
OI Anderson, Cary/0000-0003-1702-9590; Robinson,
   Anthony/0000-0002-5249-8010
CR [Anonymous], 2018, AMAZON MECH TURK
   [Anonymous], 2018, MOCKAROO
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Bemis D, 1989, COLOR TEMPERATURE MA
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bradley M.M., 1999, PSYCHOLOGY
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [DOI 10.1016/B978-0-08-042415-6.50014-4, 10.1016/b978-0-08-042415-6.50014-4]
   Brewer CA, 1997, ANN ASSOC AM GEOGR, V87, P411, DOI 10.1111/1467-8306.00061
   Brewer CA, 2002, ANN ASSOC AM GEOGR, V92, P662, DOI 10.1111/1467-8306.00310
   Brewer CynthiaA., 2012, COLORBREWER
   Cuff D. J., 1973, The Cartographic Journal, V10, P17
   Dawn Shaikh A., 2006, Usability News, V8, P1
   De Houwer J, 2002, COGNITION EMOTION, V16, P643, DOI 10.1080/02699930143000419
   Dillman D.A., 2009, Internet, Mail, and Mix-Mode Surveys: The Taylored Design Method
   Doyle JR, 2006, J CONSUM PSYCHOL, V16, P112, DOI 10.1207/s15327663jcp1602_2
   Edsall R. M, 2010, PROC SPECIAL JOINT S
   Fabrikant S. I, 2012, PROC 7 INT C GEOGRAP
   Fang H, 2017, IEEE T VIS COMPUT GR, V23, P871, DOI 10.1109/TVCG.2016.2599214
   FAZIO RH, 1986, J PERS SOC PSYCHOL, V50, P229, DOI 10.1037/0022-3514.50.2.229
   Funke F, 2016, SOC SCI COMPUT REV, V34, P244, DOI 10.1177/0894439315575477
   Gorn GJ, 1997, MANAGE SCI, V43, P1387, DOI 10.1287/mnsc.43.10.1387
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Griffin A., 2012, Kartographische Nachrichten, V62, P291
   Griffin AL., 2017, Cartographic J, V3, P90, DOI [10.1080/23729333.2017.1315988, DOI 10.1080/23729333.2017.1315988.3, DOI 10.1080/23729333.2017.1315988]
   Griffin AL, 2006, ANN ASSOC AM GEOGR, V96, P740, DOI 10.1111/j.1467-8306.2006.00514.x
   Guidero ElaineMeredith., 2016, Where cartography meets typography: Choosing typefaces and semantic effects for maps using microaesthetics
   Hanss D, 2012, J CONSUM BEHAV, V11, P368, DOI 10.1002/cb.1380
   Harrison L, 2012, IEEE CONF VIS ANAL, P227, DOI 10.1109/VAST.2012.6400540
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Ishihara S, 1972, ISHIHARAS TESTS COLO
   Jamieson Susan, 2004, Med Educ, V38, P1217, DOI 10.1111/j.1365-2929.2004.02012.x
   Jiang YW, 2016, J CONSUM RES, V42, P709, DOI 10.1093/jcr/ucv049
   Klauer K.C., 1997, EUR REV SOC PSYCHOL, V8, P67, DOI [DOI 10.1080/14792779643000083, 10.1080/14792779643000083]
   Knapp L., 1995, Cognitive aspects of human-computer interaction for Geographic Information Systems, P355
   Kulahcioglu T, 2019, PROCEEDINGS OF IUI 2019, P132, DOI 10.1145/3301275.3302327
   Labrecque LI, 2013, PSYCHOL MARKET, V30, P187, DOI 10.1002/mar.20597
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   MACEACHREN A. M., 1995, How Maps Work: Representation, Visualization, and Design, V1st, DOI DOI 10.1002/esp.1383
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, V12
   Naor-Raz G, 2003, PERCEPTION, V32, P667, DOI 10.1068/p5050
   ROBERTSON PK, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P114, DOI 10.1109/VISUAL.1990.146372
   Robinson A.C., 2017, INT J CARTOGRAPHY, V3, P32, DOI [10.1080/23729333.2016.1278151, DOI 10.1080/23729333.2016.1278151]
   Robinson AC, 2011, J HOMEL SECUR EMERG, V8, DOI 10.2202/1547-7355.1811
   Robinson Arthur., 1976, NATURE MAPS
   Rod J.K., 2001, Cartographic Perspectives, P7
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   Samsel F., 2017, P WORKSHOP VISUALISA, P55, DOI DOI 10.2312/ENVIRVIS.20171105
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Schloss KB, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0090-y
   Schloss KB, 2011, ATTEN PERCEPT PSYCHO, V73, P551, DOI 10.3758/s13414-010-0027-0
   Schmitt BH, 1995, COLUMBIA J WORLD BUS, V30, P28, DOI 10.1016/0022-5428(95)90003-9
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Stroop JR, 1935, J EXP PSYCHOL, V18, P643, DOI 10.1037/h0054651
   Suk HJ, 2010, COLOR RES APPL, V35, P64, DOI 10.1002/col.20554
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   WELLER L, 1988, J GEN PSYCHOL, V115, P433, DOI 10.1080/00221309.1988.9710580
   Zadra JR, 2011, WIRES COGN SCI, V2, P676, DOI 10.1002/wcs.147
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 63
TC 13
Z9 16
U1 8
U2 37
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2867
EP 2878
DI 10.1109/TVCG.2021.3050118
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600005
PM 33417558
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, L
   Guo, JW
   Xiao, J
   Zhang, XP
   Yan, DM
AF Zhang, Long
   Guo, Jianwei
   Xiao, Jun
   Zhang, Xiaopeng
   Yan, Dong-Ming
TI Blending Surface Segmentation and Editing for 3D Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Shape; Surface morphology;
   Clustering algorithms; Trajectory; Partitioning algorithms; Mesh
   segmentation; structure recovery; superfacets; rolling-ball blending
   surface; Markov random field
ID MESH SEGMENTATION; STRUCTURE RECOVERY; RECONSTRUCTION; EXTRACTION
AB Recognizing and fitting shape primitives from underlying 3D models are key components of many computer graphics and computer vision applications. Although a vast number of structural recovery methods are available, they usually fail to identify blending surfaces, which corresponds to small transitional regions among relatively large primary patches. To address this issue, we present a novel approach for automatic segmentation and surface fitting with accurate geometric parameters from 3D models, especially mechanical parts. Overall, we formulate the structural segmentation as a Markov random field (MRF) labeling problem. In contrast to existing techniques, we first propose a new clustering algorithm to build superfacets by incorporating 3D local geometric information. This algorithm extracts the general quadric and rolling-ball blending regions, and improves the robustness of further segmentation. Next, we apply a specially designed MRF framework to efficiently partition the original model into different meaningful patches of known surface types by defining the multilabel energy function on the superfacets. Furthermore, we present an iterative optimization algorithm based on skeleton extraction to fit rolling-ball blending patches by recovering the parameters of the rolling center trajectories and ball radius. Experiments on different complex models demonstrate the effectiveness and robustness of the proposed method, and the superiority of our method is also verified through comparisons with state-of-the-art approaches. We further apply our algorithm in applications such as mesh editing by changing the radius of the rolling balls.
C1 [Zhang, Long; Guo, Jianwei; Xiao, Jun; Zhang, Xiaopeng; Yan, Dong-Ming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Guo, Jianwei; Zhang, Xiaopeng; Yan, Dong-Ming] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Xiao, J (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
EM zzlzlzl001@gmail.com; jianwei.guo@nlpr.ia.ac.cn; xiaojun@ucas.ac.cn;
   Xiaopeng.Zhang@ia.ac.cn; yandongming@gmail.com
OI Guo, Jianwei/0000-0002-3376-1725; ZHANG, Xiaopeng/0000-0002-0092-6474;
   Yan, Dong-Ming/0000-0003-2209-2404; Zhang, Long/0000-0003-0096-403X;
   Xiao, Jun/0000-0002-1799-3948
FU National Key RD Program [2018YFB2100602]; National Natural Science
   Foundation of China [61802406, 61772523, U2003109]; Beijing Natural
   Science Foundation [L182059]; Key Research Program of Frontier Sciences
   CAS [QYZDY-SSW-SYS004]; Strategic Priority Research Program of CAS
   [XDA23090304]; Youth Innovation Promotion Association of CAS [Y201935];
   Open Project Programof State Key Laboratory of Virtual Reality
   Technology and Systems Beihang University [VRLAB2019B02]; Alibaba Group
   through Alibaba Innovative Research Program; Fundamental Research Funds
   for the Central Universities
FX The authors would like to thank anonymous reviewer for their valuable
   comments. This work was supported in part by the National Key R&D
   Program under Grant 2018YFB2100602, the National Natural Science
   Foundation of China under Grants 61802406, 61772523, U2003109, Beijing
   Natural Science Foundation under Grant L182059, the Key Research Program
   of Frontier Sciences CAS under Grant QYZDY-SSW-SYS004, the Strategic
   Priority Research Program of CAS under Grant XDA23090304, the Youth
   Innovation Promotion Association of CAS under Grant Y201935, Open
   Project Programof State Key Laboratory of Virtual Reality Technology and
   Systems Beihang University under Grant VRLAB2019B02, the Alibaba Group
   through Alibaba Innovative Research Program, and the Fundamental
   Research Funds for the Central Universities. Long Zhang and Jianwei Guo
   are joint first authors with equal contribution
CR Ahn SJ, 2002, IEEE T PATTERN ANAL, V24, P620, DOI 10.1109/34.1000237
   [Anonymous], 2005, Graphics Interface
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   Attene M, 2005, IEEE T VIS COMPUT GR, V11, P181, DOI 10.1109/TVCG.2005.34
   Attene M, 2010, COMPUT GRAPH FORUM, V29, P1905, DOI 10.1111/j.1467-8659.2010.01658.x
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Cazals F, 2005, COMPUT AIDED GEOM D, V22, P121, DOI 10.1016/j.cagd.2004.09.004
   CGAL, Computational Geometry Algorithms Library
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Chen YH, 1999, COMPUT AIDED DESIGN, V31, P101, DOI 10.1016/S0010-4485(98)00083-9
   CHOI BK, 1989, COMPUT AIDED DESIGN, V21, P213, DOI 10.1016/0010-4485(89)90046-8
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Du Q, 2010, NUMER MATH-THEORY ME, V3, P119, DOI 10.4208/nmtma.2010.32s.1
   Du T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275006
   Edwards John, 2013, P 21 INT MESH ROUNDT, P403
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Fang H, 2018, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2018.00313
   Fei Y, 2014, COMPUT GRAPH-UK, V40, P1, DOI 10.1016/j.cag.2014.01.002
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Hu SM, 2020, IEEE T VIS COMPUT GR, V26, P2485, DOI 10.1109/TVCG.2018.2889944
   Huang L, 2000, HZTMSURFHUANG04 BEIJ
   Jagannathan A, 2007, IEEE T PATTERN ANAL, V29, P2195, DOI 10.1109/TPAMI.2007.1125
   Julius D, 2005, COMPUT GRAPH FORUM, V24, P581, DOI 10.1111/j.1467-8659.2005.00883.x
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Kanai T, 2006, PROC S GEOMETRY PROC, P21
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kim DH, 2006, PATTERN RECOGN, V39, P827, DOI 10.1016/j.patcog.2005.11.022
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   Kós G, 2000, COMPUT AIDED GEOM D, V17, P127, DOI 10.1016/S0167-8396(99)00043-6
   Lafarge F., 2009, PROC BRIT MACH VIS C
   Lafarge F, 2010, IEEE T IMAGE PROCESS, V19, P1683, DOI 10.1109/TIP.2010.2045695
   Lai Yu-Kun, 2006, Proceedings of the 2006 ACM symposium on Solid and physical modeling, SPM '06, P3
   Lavoué G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001
   Li B, 2009, COMPUT GRAPH FORUM, V28, P1985, DOI 10.1111/j.1467-8659.2009.01577.x
   Li LX, 2019, PROC CVPR IEEE, P2647, DOI 10.1109/CVPR.2019.00276
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Liu JB, 2015, IEEE I CONF COMP VIS, P2093, DOI 10.1109/ICCV.2015.242
   Liu Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559758
   Liu YS, 2005, VISUAL COMPUT, V21, P915, DOI 10.1007/s00371-005-0306-2
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Oesau S, 2016, COMPUT GRAPH FORUM, V35, P203, DOI 10.1111/cgf.12720
   Pan X, 2017, IEEE T VIS COMPUT GR, V23, P2342, DOI 10.1109/TVCG.2016.2621763
   Papaioannou G, 2000, INT C PATT RECOG, P734, DOI 10.1109/ICPR.2000.905491
   Petitjean S, 2002, ACM COMPUT SURV, V34, P211, DOI 10.1145/508352.508354
   Qi CR, 2017, ADV NEUR IN, V30
   Rocchini C, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P296, DOI 10.1109/SMA.2001.923401
   Rodrigues RSV, 2018, COMPUT GRAPH FORUM, V37, P235, DOI 10.1111/cgf.13323
   Rong GD, 2011, IEEE T VIS COMPUT GR, V17, P345, DOI 10.1109/TVCG.2010.53
   Rossignac J. R., 1984, Computers in Mechanical Engineering, V3, P65
   Sander P. V., 2003, Symposium on Geometry Processing, P146
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Sharma G., 2020, COMPUTER VISION ECCV, P261, DOI DOI 10.1007/978-3-030-58571-6_16
   Simari P, 2014, COMPUT GRAPH FORUM, V33, P181, DOI 10.1111/cgf.12486
   Theologou P, 2015, COMPUT VIS IMAGE UND, V135, P49, DOI 10.1016/j.cviu.2014.12.008
   Le T, 2017, COMPUT AIDED GEOM D, V52-53, P231, DOI 10.1016/j.cagd.2017.02.009
   Tran TT, 2015, COMPUT GRAPH-UK, V46, P345, DOI 10.1016/j.cag.2014.09.027
   Varady T., 1988, PROC IMA C MATH SURF, P171
   Verdie Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2732527
   VIDA J, 1994, COMPUT AIDED DESIGN, V26, P341, DOI 10.1016/0010-4485(94)90023-X
   Wang J, 2012, COMPUT IND ENG, V63, P1189, DOI 10.1016/j.cie.2012.07.009
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu JH, 2005, COMPUT GRAPH FORUM, V24, P277, DOI 10.1111/j.1467-8659.2005.00852.x
   Xu K., 2016, SIGGRAPH ASIA 2016 Courses, P4
   Yan DM, 2012, COMPUT AIDED DESIGN, V44, P1072, DOI 10.1016/j.cad.2012.04.005
   Yang XL, 2020, COMPUT VIS MEDIA, V6, P431, DOI 10.1007/s41095-020-0192-6
   Yu FG, 2019, PROC CVPR IEEE, P9483, DOI 10.1109/CVPR.2019.00972
   Zhang HJ, 2015, COMPUT GRAPH-UK, V51, P136, DOI 10.1016/j.cag.2015.05.012
   Zhang Long, About us
   Zhou Qingnan, 2016, arXiv preprint arXiv:1605.04797
   Zhuang Yixin, 2017, [Computational Visual Media, 计算可视媒体], V3, P147
NR 75
TC 9
Z9 9
U1 3
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2879
EP 2894
DI 10.1109/TVCG.2020.3045450
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600006
PM 33332272
DA 2024-11-06
ER

PT J
AU Lin, JC
   Xiao, PT
   Fu, YA
   Shi, YB
   Wang, HR
   Guo, SH
   He, Y
   Lee, TY
AF Lin, Juncong
   Xiao, Pintong
   Fu, Yinan
   Shi, Yubin
   Wang, Hongran
   Guo, Shihui
   He, Ying
   Lee, Tong-Yee
TI C<SUP>3</SUP> Assignment: Camera Cubemap Color Assignment for Creative
   Interior Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Creative interior colorization; harmony; mood
ID EVOLUTIONARY COMPUTATION; PREFERENCE; EMOTIONS
AB Color design for 3D indoor scenes is a challenging problem due to many factors that need to be balanced. Although learning from images is a commonly adopted strategy, this strategy may be more suitable for natural scenes in which objects tend to have relatively fixed colors. For interior scenes consisting mostly of man-made objects, creative yet reasonable color assignments are expected. We propose C-3 Assignment, a system providing diverse suggestions for interior color design while satisfying general global and local rules including color compatibility, color mood, contrast, and user preference. We extend these constraints from the image domain to R-3, and formulate 3D interior color design as an optimization problem. The design is accomplished in an omnidirectional manner to ensure a comfortable experience when the inhabitant observes the interior scene from possible positions and directions. We design a surrogate-assisted evolutionary algorithm to efficiently solve the highly nonlinear optimization problem for interactive applications, and investigate the system performance concerning problem complexity, solver convergence, and suggestion diversity. Preliminary user studies have been conducted to validate the rule extension from 2D to 3D and to verify system usability.
C1 [Lin, Juncong; Xiao, Pintong; Fu, Yinan; Shi, Yubin; Wang, Hongran; Guo, Shihui] Xiamen Univ, Sch Informat, Xiamen 361005, Fujian, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Lee, Tong-Yee] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
C3 Xiamen University; Nanyang Technological University; National Cheng Kung
   University
RP Guo, SH (corresponding author), Xiamen Univ, Sch Informat, Xiamen 361005, Fujian, Peoples R China.
EM jclin@xmu.edu.cn; xpt_solferino@qq.com; yinan.fu1202@gmail.com;
   tens444@163.com; 24320162202914@stu.xmu.edu.cn; guoshihui@xmu.edu.cn;
   yhe@ntu.edu.sg; tonylee@mail.ncku.edu.tw
RI He, Ying/A-3708-2011
OI He, Ying/0000-0002-6749-4485; Shi, Yubin/0000-0003-1862-966X
FU National Natural Science Foundation of China [62077039, 62072383,
   61702433]; Fundamental Research Funds for the Central Universities China
   [20720190006]; Ministry of Science and Technology Taiwan
   [108-2221-E-006-038-MY3]; Singapore Ministry of Education [RG20/20]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was supported in part by the National
   Natural Science Foundation of China under Grants 62077039, 62072383,
   61702433, the Fundamental Research Funds for the Central Universities
   China under Grant 20720190006, Ministry of Science and Technology
   108-2221-E-006-038-MY3 Taiwan and Singapore Ministry of Education Tier 1
   Grant RG20/20.
CR [Anonymous], 1961, ART COLOR SUBJECTIVE
   [Anonymous], 2009, P INT C SMART CIT AP, DOI DOI 10.1145/1599470.1599478
   [Anonymous], ADV COLOR SCI TECHNO
   BLINN J, 1988, IEEE COMPUT GRAPH, V8, P76, DOI 10.1109/38.7751
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen GM, 2016, COMPUT GRAPH-UK, V60, P34, DOI 10.1016/j.cag.2016.08.009
   Chen K, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818096
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chia AYS, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024190
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Haubenwallner K, 2017, COMPUT GRAPH FORUM, V36, P213, DOI 10.1111/cgf.13120
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Jain A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366162
   Jin YC, 2011, SWARM EVOL COMPUT, V1, P61, DOI 10.1016/j.swevo.2011.05.001
   Joubert N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818106
   Krause J., 2010, COLOR INDEX
   KRIGE DG, 1994, J S AFR I MIN METALL, V94, P95
   Kuhnt S, 2010, ASTA-ADV STAT ANAL, V94, P307, DOI 10.1007/s10182-010-0143-0
   Lamming D, 1991, CONTRAST SENSITIVITY, V5
   LCL, 2010, ACM SIGGRAPH EUROGRA, P139, DOI [DOI 10.2312/SCA/SCA10/139-148, 10.2312/SCA/SCA10/139-148]
   Leifman G, 2012, COMPUT GRAPH FORUM, V31, P421, DOI 10.1111/j.1467-8659.2012.03021.x
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Li-Wei He, 1996, Computer Graphics Proceedings. SIGGRAPH '96, P217
   Lin S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461988
   Lino C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766965
   Liu XP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409105
   Luan Q., 2007, P 18 EUR C REND TECH, P309
   Ma Y.-F., 2003, Proc. eleventh ACM Int. Conf. Multimedia, P374, DOI [10.1145/957013.957094, DOI 10.1145/957013.957094]
   Matsuda Y., 1995, COLOR DESIGN
   Mitchell SA, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3194657
   NEMCSICS A, 1980, COLOR RES APPL, V5, P113, DOI 10.1002/col.5080050214
   Nguyen CH, 2012, COMPUT GRAPH FORUM, V31, P431, DOI 10.1111/j.1467-8659.2012.03022.x
   Nielsen HB., 2002, INFORM MATH MODELLIN
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Olivier P., 2009, P ACM SIGGRAPH ASIA
   Ong YS, 2006, IEEE C EVOL COMPUTAT, P2913
   Ou LC, 2004, COLOR RES APPL, V29, P292, DOI 10.1002/col.20024
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Pilat ML, 2008, IEEE C EVOL COMPUTAT, P3289, DOI 10.1109/CEC.2008.4631243
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Ranon R, 2014, IEEE T VIS COMPUT GR, V20, P795, DOI 10.1109/TVCG.2013.2297932
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Savva M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661230
   Shugrina M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392461
   Sims K., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P15, DOI 10.1145/192161.192167
   SIMS K, 1991, COMP GRAPH, V25, P319, DOI 10.1145/127719.122752
   Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485
   Tokumaru M, PROC IEEE INT C FUZZ, P378
   Wang BY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866172
   Xie K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201284
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185553
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhu J, 2018, IEEE T VIS COMPUT GR, V24, P2473, DOI 10.1109/TVCG.2017.2753255
NR 56
TC 5
Z9 7
U1 1
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2895
EP 2908
DI 10.1109/TVCG.2020.3041728
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600007
PM 33259303
DA 2024-11-06
ER

PT J
AU Abramov, D
   Burchett, JN
   Elek, O
   Hummels, C
   Prochaska, JX
   Forbes, AG
AF Abramov, David
   Burchett, Joseph N.
   Elek, Oskar
   Hummels, Cameron
   Prochaska, J. Xavier
   Forbes, Angus G.
TI CosmoVis: An Interactive Visual Analysis Tool for Exploring Hydrodynamic
   Cosmological Simulations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Analytical models; Computational modeling; Hydrodynamics; Data models;
   Software; Data visualization; Absorption; Astrovis; astrographics;
   cosmological simulations; astronomy; astrophysics; virtual spectrography
ID STAR-FORMATION; CIRCUMGALACTIC MEDIUM; ILLUSTRIS PROJECT;
   ABSORPTION-LINES; GALAXY FORMATION; COSMIC WEB; ORIGIN; EVOLUTION;
   VISUALIZATION; FILAMENTS
AB We introduce CosmoVis, an open source web-based visualization tool for the interactive analysis of massive hydrodynamic cosmological simulation data. CosmoVis was designed in close collaboration with astrophysicists to enable researchers and citizen scientists to share and explore these datasets, and to use them to investigate a range of scientific questions. CosmoVis visualizes many key gas, dark matter, and stellar attributes extracted from the source simulations, which typically consist of complex data structures multiple terabytes in size, often requiring extensive data wrangling. CosmoVis introduces a range of features to facilitate real-time analysis of these simulations, including the use of "virtual skewers," simulated analogues of absorption line spectroscopy that act as spectral probes piercing the volume of gaseous cosmic medium. We explain how such synthetic spectra can be used to gain insight into the source datasets and to make functional comparisons with observational data. Furthermore, we identify the main analysis tasks that CosmoVis enables and present implementation details of the software interface and the client-server architecture. We conclude by providing details of three contemporary scientific use cases that were conducted by domain experts using the software and by documenting expert feedback from astrophysicists at different career levels.
C1 [Abramov, David; Elek, Oskar; Prochaska, J. Xavier; Forbes, Angus G.] Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
   [Burchett, Joseph N.] New Mexico State Univ, Las Cruces, NM 88003 USA.
   [Hummels, Cameron] CALTECH, Pasadena, CA 91125 USA.
C3 University of California System; University of California Santa Cruz;
   New Mexico State University; California Institute of Technology
RP Forbes, AG (corresponding author), Univ Calif Santa Cruz, Santa Cruz, CA 95064 USA.
EM dabramov@ucsc.edu; jnb@nmsu.edu; oelek@ucsc.edu; chummels@gmail.com;
   xavier@ucolick.org; angus@ucsc.edu
OI Hummels, Cameron/0000-0002-3817-8133; Elek, Oskar/0000-0003-0549-3302;
   Forbes, Angus/0000-0002-8700-7795; Abramov, David/0000-0003-0356-3637
FU Hubble Space Telescope Archival Research awards from the Space Telescope
   Science Institute through Hubble Space Telescope Archival Research Award
   [15790]; National Science Foundation Award [1748958]; NSF [CNS-1730158,
   ACI-1540112, ACI-1541349, OAC-1826967, OAC-2112167, CNS-2120019]
FX This work was supported in part by Hubble Space Telescope Archival
   Research awards from the Space Telescope Science Institute through
   Hubble Space Telescope Archival Research Award under Grant HST-AR #15790
   and in part by National Science Foundation Award under Grant NSF-PHY
   #1748958. The Pacific Research Platform's Nautilus HyperCluster was
   supported in part by NSF awards under Grants CNS-1730158, ACI-1540112,
   ACI-1541349, OAC-1826967, OAC-2112167, and CNS-2120019.
CR Aguirre A, 2001, ASTROPHYS J, V561, P521, DOI 10.1086/323370
   Ahrens James, 2005, VISUALIZATION HDB, V717, P8
   Altintas I, 2019, IEEE SYM PARA DISTR, P865, DOI 10.1109/IPDPSW.2019.00142
   Ayachit U., 2015, PARAVIEW GUIDE PARAL
   BAHCALL JN, 1969, ASTROPHYS J, V156, pL63, DOI 10.1086/180350
   Balogh ML, 2000, ASTROPHYS J, V540, P113, DOI 10.1086/309323
   BERGER MJ, 1984, J COMPUT PHYS, V53, P484, DOI 10.1016/0021-9991(84)90073-1
   BERGERON J, 1991, ASTRON ASTROPHYS, V243, P344
   Bock A, 2020, IEEE T VIS COMPUT GR, V26, P633, DOI 10.1109/TVCG.2019.2934259
   BOKSENBERG A, 1978, ASTROPHYS J, V220, P42, DOI 10.1086/155880
   Bond JR, 1996, NATURE, V380, P603, DOI 10.1038/380603a0
   Bowen DV, 2016, ASTROPHYS J, V826, DOI 10.3847/0004-637X/826/1/50
   Bunn EF, 2009, AM J PHYS, V77, P688, DOI 10.1119/1.3129103
   Burchett JN, 2019, COMPUT GRAPH FORUM, V38, P491, DOI 10.1111/cgf.13705
   Burchett J. N, 2019, HST PROPOSAL
   Burchett J. N, 2020, PROC IEEEVISWORKSHOP, P1
   Burchett JN, 2021, ASTROPHYS J, V909, DOI 10.3847/1538-4357/abd4e0
   Burchett JN, 2020, ASTROPHYS J LETT, V891, DOI 10.3847/2041-8213/ab700c
   Burchett JN, 2016, ASTROPHYS J, V832, DOI 10.3847/0004-637X/832/2/124
   CEN RY, 1994, ASTROPHYS J, V437, pL9, DOI 10.1086/187670
   Chen HW, 2001, ASTROPHYS J, V556, P158, DOI 10.1086/321537
   Davé R, 2011, MON NOT R ASTRON SOC, V415, P11, DOI 10.1111/j.1365-2966.2011.18680.x
   Donnari M, 2021, MON NOT R ASTRON SOC, V506, P4760, DOI 10.1093/mnras/stab1950
   Doroshkevich A. G., 1970, Ap, V6, P320, DOI [10.1007/BF01001625, DOI 10.1007/BF01001625]
   Elek O, 2021, IEEE T VIS COMPUT GR, V27, P806, DOI 10.1109/TVCG.2020.3030407
   Fritschi Lea, 2019, 2019 IEEE Scientific Visualization Conference (SciVis), P1, DOI 10.1109/SciVis47405.2019.8968943
   Geller A., FIREFLY AWEBGL TOOL
   Genel S, 2014, MON NOT R ASTRON SOC, V445, P175, DOI 10.1093/mnras/stu1654
   Guedes J, 2011, ASTROPHYS J, V742, DOI 10.1088/0004-637X/742/2/76
   Habib S, 2016, NEW ASTRON, V42, P49, DOI 10.1016/j.newast.2015.06.003
   Hesse-Edenfeld Clemens, 2019, 2019 IEEE Scientific Visualization Conference (SciVis), P12, DOI 10.1109/SciVis47405.2019.8968917
   Hopkins PF, 2018, MON NOT R ASTRON SOC, V480, P800, DOI 10.1093/mnras/sty1690
   Hopkins PF, 2015, MON NOT R ASTRON SOC, V450, P53, DOI 10.1093/mnras/stv195
   Hubble E, 1929, P NATL ACAD SCI USA, V15, P168, DOI 10.1073/pnas.15.3.168
   Hummels CB, 2019, ASTROPHYS J, V882, DOI 10.3847/1538-4357/ab378f
   Hummels CB, 2017, ASTROPHYS J, V847, DOI 10.3847/1538-4357/aa7e2d
   ICKE V, 1973, ASTRON ASTROPHYS, V27, P1
   Johnson SD, 2015, MON NOT R ASTRON SOC, V449, P3263, DOI 10.1093/mnras/stv553
   Kacprzak G. G., 2019, ASTROPHYS J, V870, P1
   Lan FF, 2021, COMPUT GRAPH FORUM, V40, P635, DOI 10.1111/cgf.14332
   Leitner SN, 2011, ASTROPHYS J, V734, DOI 10.1088/0004-637X/734/1/48
   Libeskind NI, 2018, MON NOT R ASTRON SOC, V473, P1195, DOI 10.1093/mnras/stx1976
   Lopez S, 2018, NATURE, V554, P493, DOI 10.1038/nature25436
   Man A, 2018, NAT ASTRON, V2, P695, DOI 10.1038/s41550-018-0558-1
   Mandelker N., 2021, ASTROPHYS J, V923, P1
   Mandelker N, 2019, ASTROPHYS J LETT, V881, DOI 10.3847/2041-8213/ab30cb
   Martizzi D, 2019, MON NOT R ASTRON SOC, V486, P3766, DOI 10.1093/mnras/stz1106
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   McAlpine S, 2016, ASTRON COMPUT, V15, P72, DOI 10.1016/j.ascom.2016.02.004
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Naiman JP, 2016, ASTRON COMPUT, V15, P50, DOI 10.1016/j.ascom.2016.02.002
   Nelson D, 2019, MON NOT R ASTRON SOC, V490, P3234, DOI 10.1093/mnras/stz2306
   Nelson D, 2018, MON NOT R ASTRON SOC, V477, P450, DOI 10.1093/mnras/sty656
   Nguyen Bao D., 2019, 2019 IEEE Scientific Visualization Conference (SciVis), P31, DOI 10.1109/SciVis47405.2019.8968854
   Odekon MC, 2018, ASTROPHYS J, V852, DOI 10.3847/1538-4357/aaa1e8
   Oppenheimer B. D, 2019, MONTHLY NOTICES ROY, V491, P2939
   Peebles P. J. E., 1993, Principles of Physical Cosmology
   Peeples MS, 2019, ASTROPHYS J, V873, DOI 10.3847/1538-4357/ab0654
   Pillepich A, 2018, MON NOT R ASTRON SOC, V473, P4077, DOI 10.1093/mnras/stx2656
   Pontzen A., 2013, pynbody: N-Body/SPH analysis for python, Astrophysics Source Code Library
   Prochaska JX, 2011, ASTROPHYS J, V740, DOI 10.1088/0004-637X/740/2/91
   Rahmati A, 2016, MON NOT R ASTRON SOC, V459, P310, DOI 10.1093/mnras/stw453
   Rahmati A, 2013, MON NOT R ASTRON SOC, V430, P2427, DOI 10.1093/mnras/stt066
   Rasmussen J, 2009, ASTROPHYS J, V697, P79, DOI 10.1088/0004-637X/697/1/79
   Rupke DSN, 2019, NATURE, V574, P643, DOI 10.1038/s41586-019-1686-1
   Schatz K, 2016, SYMP LARG DATA ANAL, P56, DOI 10.1109/LDAV.2016.7874310
   Schaye J., 2015, MNRAS, V446, P521, DOI DOI 10.1093/MNRAS/STU2058
   Scherzinger A, 2017, IEEE COMPUT GRAPH, V37, P80, DOI 10.1109/MCG.2017.20
   Segers MC, 2016, MON NOT R ASTRON SOC, V456, P1235, DOI 10.1093/mnras/stv2562
   Sijacki D, 2015, MON NOT R ASTRON SOC, V452, P575, DOI 10.1093/mnras/stv1340
   Skillman S. W., 2014, ARXIV14072600
   Smit NoeskaN., 2014, VCBM, P145
   Sofroniew N., NAPARI MULTIDIMENSIO
   Sukumar N, 2003, INT J NUMER METH ENG, V57, P1, DOI 10.1002/nme.664
   Tumlinson J, 2011, SCIENCE, V334, P948, DOI 10.1126/science.1209840
   Tumlinson J, 2017, ANNU REV ASTRON ASTR, V55, P389, DOI 10.1146/annurev-astro-091916-055240
   Tumlinson J, 2013, ASTROPHYS J, V777, DOI 10.1088/0004-637X/777/1/59
   Turk MJ, 2011, ASTROPHYS J SUPPL S, V192, DOI 10.1088/0067-0049/192/1/9
   van de Sande J, 2019, MON NOT R ASTRON SOC, V484, P869, DOI 10.1093/mnras/sty3506
   Veilleux S, 2005, ANNU REV ASTRON ASTR, V43, P769, DOI 10.1146/annurev.astro.43.072103.150610
   Vogelsberger M, 2014, NATURE, V509, P177, DOI 10.1038/nature13316
   Vogelsberger M, 2014, MON NOT R ASTRON SOC, V444, P1518, DOI 10.1093/mnras/stu1536
   Woodring J, 2011, ASTROPHYS J SUPPL S, V195, DOI 10.1088/0067-0049/195/1/11
   ZELDOVICH YB, 1970, ASTRON ASTROPHYS, V5, P84
   Zinger E, 2018, MON NOT R ASTRON SOC, V475, P3654, DOI 10.1093/mnras/stx3329
NR 85
TC 1
Z9 2
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2909
EP 2925
DI 10.1109/TVCG.2022.3159630
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600008
PM 35294350
OA Bronze
DA 2024-11-06
ER

PT J
AU Zhang, M
   Liao, J
   Yu, JH
AF Zhang, Mohan
   Liao, Jing
   Yu, Jinhui
TI Deep Exemplar-Based Color Transfer for 3D Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Three-dimensional displays; Solid modeling;
   Semantics; Optimization; Task analysis; Histograms; 3D model texture;
   color transfer; deep learning
AB Recoloring 3D models is a challenging task that often requires professional knowledge and tedious manual efforts. In this article, we present the first deep-learning framework for exemplar-based 3D model recolor, which can automatically transfer the colors from a reference image to the 3D model texture. Our framework consists of two modules to solve two major challenges in the 3D color transfer. First, we propose a new feed-forward Color Transfer Network to achieve high-quality semantic-level color transfer by finding dense semantic correspondences between images. Second, considering 3D model constraints such as UV mapping, we design a novel 3D Texture Optimization Module which can generate a seamless and coherent texture by combining color transferred results rendered in multiple views. Experiments show that our method performs robustly and generalizes well to various kinds of models.
C1 [Zhang, Mohan; Yu, Jinhui] Zhejiang Univ, Sate Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
   [Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Yu, Jinhui] Harbin Finance Univ, Dept Comp Sci, Harbin 150020, Peoples R China.
C3 Zhejiang University; City University of Hong Kong; Harbin Finance
   University
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM zhangmohan@zju.edu.cn; jingliao@cityu.edu.hk; jhyu@cad.zju.edu.cn
OI LIAO, Jing/0000-0001-7014-5377
FU Natural Science Foundation of China [61772463]; Hong Kong Research
   Grants Council (RGC) Early Career Scheme [9048148, CityU 21209119];
   CityU of Hong Kong under APRC Grant [9610488]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant No. 61772463, the Hong Kong Research Grants Council
   (RGC) Early Career Scheme under Grant 9048148 (CityU 21209119) and the
   CityU of Hong Kong under APRC Grant 9610488.
CR An XB, 2010, COMPUT GRAPH FORUM, V29, P263, DOI 10.1111/j.1467-8659.2009.01595.x
   Arbelot B, 2017, COMPUT GRAPH-UK, V62, P15, DOI 10.1016/j.cag.2016.12.005
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Fiser J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925948
   Freedman D, 2010, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2010.5540201
   Gardner J. R, 2015, ARXIV 151106421
   Gatys L. A., 2016, PRESERVING COLOR NEU
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   He MM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292482
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Laffont PY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601101
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li YJ, 2018, LECT NOTES COMPUT SC, V11207, P468, DOI 10.1007/978-3-030-01219-9_28
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu HTD, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275047
   Liu J., 2017, PROC SIGGRAPH ASIA T
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mechrez R, 2017, PROC BRIT MACH VIS C
   Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47
   Mordvintsev A., 2018, Distill, V3, P12
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Shih YC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508419
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Tai YW, 2005, PROC CVPR IEEE, P747
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Yoo JD, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033003
   Yoo J, 2019, IEEE I CONF COMP VIS, P9035, DOI 10.1109/ICCV.2019.00913
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 43
TC 4
Z9 4
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2926
EP 2937
DI 10.1109/TVCG.2020.3041487
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600009
PM 33259302
DA 2024-11-06
ER

PT J
AU Li, XY
   Zhang, B
   Liao, J
   Sander, P
AF Li, Xiaoyu
   Zhang, Bo
   Liao, Jing
   Sander, Pedro, V
TI Deep Sketch-Guided Cartoon Video Inbetweening
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Interpolation; Image color analysis; Two dimensional
   displays; Estimation; Streaming media; Semantics; 2D cartoon animation;
   sketch-guided synthesis; frame interpolation
ID FLOW
AB We propose a novel framework to produce cartoon videos by fetching the color information from two input keyframes while following the animated motion guided by a user sketch. The key idea of the proposed approach is to estimate the dense cross-domain correspondence between the sketch and cartoon video frames, and employ a blending module with occlusion estimation to synthesize the middle frame guided by the sketch. After that, the input frames and the synthetic frame equipped with established correspondence are fed into an arbitrary-time frame interpolation pipeline to generate and refine additional inbetween frames. Finally, a module to preserve temporal consistency is employed. Compared to common frame interpolation methods, our approach can address frames with relatively large motion and also has the flexibility to enable users to control the generated video sequences by editing the sketch guidance. By explicitly considering the correspondence between frames and the sketch, we can achieve higher quality results than other image synthesis methods. Our results show that our system generalizes well to different movie frames, achieving better results than existing solutions.
C1 [Li, Xiaoyu] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Peoples R China.
   [Zhang, Bo] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Sander, Pedro, V] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Microsoft; Microsoft
   Research Asia; City University of Hong Kong; Hong Kong University of
   Science & Technology
RP Sander, P (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
EM xliea@connect.ust.hk; Tony.Zhang@microsoft.com; jingliao@cityu.edu.hk
RI Zhang, Bo/AAN-7181-2020
OI LIAO, Jing/0000-0001-7014-5377; Li, Xiaoyu/0000-0003-2588-1687
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [CityU
   21209119]; CityU of Hong Kong under APRC [9610488]; HKUST [FSGRF1 6EG08,
   DAG06/07.EG07]
FX This work was supported in part by the Hong Kong Research Grants Council
   (RGC) Early Career Scheme under Grant CityU 21209119, the CityU of Hong
   Kong under APRC Grant 9610488, and at HKUST under Grants FSGRF1 6EG08
   and DAG06/07.EG07.
CR Aberman K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201332
   [Anonymous], P INT WORKSH EN MIN
   Bansal Aayush, 2019, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P2317
   Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   Bao WB, 2021, IEEE T PATTERN ANAL, V43, P933, DOI 10.1109/TPAMI.2019.2941941
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Ben-Zvi N, 2016, COMPUT GRAPH FORUM, V35, P18, DOI 10.1111/cgf.12729
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chen T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618470
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Choi J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3363550
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Dvoroznák M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201326
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Eitz M, 2011, IEEE COMPUT GRAPH, V31, P56, DOI 10.1109/MCG.2011.67
   Gonzalez-Garcia A, 2018, ADV NEUR IN, V31
   Gucluturk Yagmur, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P810, DOI 10.1007/978-3-319-46604-0_56
   Huang X, 2012, SIGNAL PROCESS-IMAGE, V27, P16, DOI 10.1016/j.image.2011.06.008
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Kingma DP., 2015, P 3 INT C LEARN REPR
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu AH, 2018, ADV NEUR IN, V31
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu MY, 2017, ADV NEUR IN, V30
   Liu YF, 2018, NEUROCOMPUTING, V311, P78, DOI 10.1016/j.neucom.2018.05.045
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Long GC, 2016, LECT NOTES COMPUT SC, V9910, P434, DOI 10.1007/978-3-319-46466-4_26
   Mahajan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531348
   Niklaus S, 2018, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2018.00183
   Niklaus S, 2017, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2017.37
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Paszke A, 2019, ADV NEUR IN, V32
   Peleg T, 2019, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2019.00250
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Selinger P, 2015, PORTRACE
   Simo-Serra E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3132703
   Simo-Serra E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925972
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Whited B, 2010, COMPUT GRAPH FORUM, V29, P605, DOI 10.1111/j.1467-8659.2009.01630.x
   Wu JY, 2016, IEEE T WIREL COMMUN, V15, P2713, DOI 10.1109/TWC.2015.2509063
   Xia MH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275080
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xing J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818079
   Yang HS, 2014, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2014.435
   Yang WW, 2018, COMPUT GRAPH FORUM, V37, P125, DOI 10.1111/cgf.13518
   Yi R, 2019, PROC IEEE C COMPUT V, p10 743
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhu HC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925872
NR 60
TC 12
Z9 14
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2938
EP 2952
DI 10.1109/TVCG.2021.3049419
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600010
PM 33400651
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Heimerl, F
   Kralj, C
   Möller, T
   Gleicher, M
AF Heimerl, Florian
   Kralj, Christoph
   Moeller, Torsten
   Gleicher, Michael
TI <i>embComp</i>: Visual Interactive Comparison of Vector Embeddings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Visualization; Dimensionality reduction; Task analysis; Two
   dimensional displays; Stress; Object recognition; Visual analytics;
   visual comparison; machine learning; vector embeddings
ID DIMENSIONALITY REDUCTION; EXPLORATION; VISUALIZATION
AB This article introduces embComp, a novel approach for comparing two embeddings that capture the similarity between objects, such as word and document embeddings. We survey scenarios where comparing these embedding spaces is useful. From those scenarios, we derive common tasks, introduce visual analysis methods that support these tasks, and combine them into a comprehensive system. One of embComp's central features are overview visualizations that are based on metrics for measuring differences in the local structure around objects. Summarizing these local metrics over the embeddings provides global overviews of similarities and differences. Detail views allow comparison of the local structure around selected objects and relating this local information to the global views. Integrating and connecting all of these components, embComp supports a range of analysis workflows that help understand similarities and differences between embedding spaces. We assess our approach by applying it in several use cases, including understanding corpora differences via word vector embeddings, and understanding algorithmic differences in generating embeddings.
C1 [Heimerl, Florian; Gleicher, Michael] Univ Wisconsin Madison UW Madison, Dept Comp Sci, Madison, WI 53718 USA.
   [Kralj, Christoph; Moeller, Torsten] Univ Vienna, Fac Comp Sci & Data Sci, Uni Vienna Sensengasse 6, A-1090 Vienna, Austria.
C3 University of Vienna
RP Heimerl, F (corresponding author), Univ Wisconsin Madison UW Madison, Dept Comp Sci, Madison, WI 53718 USA.
EM heimerl@cs.wisc.edu; christoph.kralj@univie.ac.at;
   torsten.moeller@univie.ac.at; gleicher@cs.wisc.edu
RI Heimerl, Florian/AAY-9917-2020
OI Moller, Torsten/0000-0003-1192-0710; Gleicher,
   Michael/0000-0003-3295-4071
FU US National Science Foundation [1841349]; DARPA Award [FA8750-17-20107];
   Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [1841349] Funding Source: National Science Foundation
FX This work was funded in part by US National Science Foundation Award
   1841349 and DARPA Award FA8750-17-20107. The authors would like to thank
   our domain collaborators including Michael Witmore, Jonathan Hope, and
   Gary Lupyan.
CR Alaux J., 2019, 7 INT C LEARNING REP
   Alexander E, 2016, IEEE T VIS COMPUT GR, V22, P320, DOI 10.1109/TVCG.2015.2467618
   Arendt DL, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P259, DOI 10.1145/3377325.3377514
   Bagrow JP, 2008, EPL-EUROPHYS LETT, V81, DOI 10.1209/0295-5075/81/68004
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Chen JT, 2018, J VISUAL LANG COMPUT, V48, P178, DOI 10.1016/j.jvlc.2018.08.008
   Choi E, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1495, DOI 10.1145/2939672.2939823
   Chuang Jason, 2012, P SIGCHI C HUM FACT, P443, DOI DOI 10.1145/2207676.2207738
   Crossno PJ, 2011, PROC INT C TOOLS ART, P936, DOI 10.1109/ICTAI.2011.162
   Cutura R., 2018, P EUR S ART NEUR NET, P1
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Grave Edouard, 2019, PR MACH LEARN RES, V89
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hamilton WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1489
   Heimerl F, 2018, COMPUT GRAPH FORUM, V37, P253, DOI 10.1111/cgf.13417
   Heimerl F, 2018, ARXIV 181002445
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hristov Yordan., 2018, C ROB LEARN, P957
   Ingram S., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P3, DOI 10.1109/VAST.2010.5652392
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jatowt A, 2014, ACM-IEEE J CONF DIG, P229, DOI 10.1109/JCDL.2014.6970173
   Kairam S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P498, DOI 10.1145/2254556.2254651
   Köper M, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1202
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Lee H, 2012, COMPUT GRAPH FORUM, V31, P1155, DOI 10.1111/j.1467-8659.2012.03108.x
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Liu SS, 2018, IEEE T VIS COMPUT GR, V24, P553, DOI 10.1109/TVCG.2017.2745141
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Mikolov T, 2013, 1 INT C LEARN REPR M, DOI DOI 10.48550/ARXIV.1301.3781
   Mikolov T, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P52
   Mokbel B, 2013, NEUROCOMPUTING, V112, P109, DOI 10.1016/j.neucom.2012.11.046
   Molino P, 2019, PROC 57 ANN M ASS CO, P1
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Munzner T., 2014, AK Peters Visualization Series
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Piringer H, 2012, COMPUT GRAPH FORUM, V31, P1195, DOI 10.1111/j.1467-8659.2012.03112.x
   Radford Alec., 2018, Improving language understanding by generative pre-training
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sarikaya A, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13408
   Smilkov D., 2016, ARXIV PREPRINT ARXIV, P1
   Sopan A., 2010, HCIL201001 U MAR COL
   Sra Suvrit, 2006, Advances in Neural Information Processing Systems 18, P283
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Text Creation Partnership, 2015, EEBO TCP EARL ENGL B
   Thompson B., 2018, PROC 40 ANN C COGN S, P1
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Venna J, 2001, LECT NOTES COMPUT SC, V2130, P485
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Yuan Y, 2017, IEEE DATA MINING, P1159, DOI 10.1109/ICDM.2017.155
   Zhong GQ, 2013, PROC INT CONF DOC, P1315, DOI 10.1109/ICDAR.2013.266
NR 63
TC 16
Z9 16
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2953
EP 2969
DI 10.1109/TVCG.2020.3045918
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600011
PM 33347410
OA Green Submitted, Bronze
DA 2024-11-06
ER

PT J
AU Tsai, WL
   Pan, TY
   Hu, MC
AF Tsai, Wan-Lun
   Pan, Tse-Yu
   Hu, Min-Chun
TI Feasibility Study on Virtual Reality Based Basketball Tactic Training
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Sports; Videos; Three-dimensional displays; Visualization; Two
   dimensional displays; Trajectory; Virtual reality; visualization;
   basketball training; trajectory analysis
ID SPORT
AB In this article, a VR-based basketball training system comprising a standalone VR device and a tablet is proposed. The system is intended to improve the ability of players to understand offensive tactics and practice these tactics correctly. We compare the training effectiveness of various degrees of immersion, including a conventional basketball tactic board, a 2D monitor, and virtual reality. A multi-camera-based human tracking system was designed and built around a real-world basketball court to record and analyze the running trajectory of each player during tactical execution. The accuracy of the running path and hesitation time at each tactical step were evaluated for each participant. Furthermore, we assessed several subjective measurements, including simulator sickness, presence, and sport imagery ability, to conduct a more comprehensive exploration of the feasibility of the proposed VR framework for basketball tactics training. The results indicate that the proposed system is useful for learning complex tactics. Furthermore, high VR immersion training improves athletes' abilities with regards to strategic imagery.
C1 [Tsai, Wan-Lun] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Multimedia Informat Syst Lab, Tainan 701, Taiwan.
   [Pan, Tse-Yu] Natl Tsing Hua Univ, Hsinchu 300, Taiwan.
   [Hu, Min-Chun] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Cheng Kung University; National Tsing Hua University; National
   Tsing Hua University
RP Tsai, WL (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Multimedia Informat Syst Lab, Tainan 701, Taiwan.; Hu, MC (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM lookoutking@gmail.com; typan@mx.nthu.edu.tw; anitahu@cs.nthu.edu.tw
RI Hu, Min-Chun/AAX-1721-2020
FU Ministry of Science and Technology, Taiwan [MOST-107-2811E-006-541,
   MOST-108-2218-E-007-055, MOST-108-2221-E-007-106-MY3,
   MOST-109-2218E-006-019, MOST-109-2221-E-007-095-MY3]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Contract MOST-107-2811E-006-541, Contract
   MOST-108-2218-E-007-055, Contract MOST-108-2221-E-007-106-MY3, Contract
   MOST-109-2218E-006-019, and Contract MOST-109-2221-E-007-095-MY3.
CR Appelbaum LG, 2018, INT REV SPORT EXER P, V11, P160, DOI 10.1080/1750984X.2016.1266376
   Berndt D. J., 1994, P KDD WORKSH SEATTL, P359, DOI DOI 10.5555/3000850.3000887
   Bideau B., 2004, Proceedings of the 2004 ACM SIGGRAPH international conference on Virtual Reality continuum and its applications in industry, P210
   BORST C, 1982, AM J PHYSIOL, V243, pH676, DOI 10.1152/ajpheart.1982.243.5.H676
   BRAULT S, 2015, MOV SPORT SCI SCI MO, V3, P79, DOI DOI 10.3917/SM.089.0079
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Craig C., 2013, Sports Technology, V6, P161, DOI [10.1080/19346182.2013.855224, DOI 10.1080/19346182.2013.855224]
   Dai W, 2013, IEEE INT C INT ROBOT, P3507, DOI 10.1109/IROS.2013.6696856
   Demsar U, 2015, MOV ECOL, V3, DOI 10.1186/s40462-015-0032-y
   Fadde P.J., 2006, TECHNOLOGY INSTRUCTI, V4, P265
   Gulec U, 2019, COMPUT STAND INTER, V64, P1, DOI 10.1016/j.csi.2018.11.004
   Hohmann T, 2016, J SPORT SCI, V34, P746, DOI 10.1080/02640414.2015.1069380
   Hopwood MJ, 2011, INT J SPORTS SCI COA, V6, P523, DOI 10.1260/1747-9541.6.4.523
   Huang Y., 2015, P 2015 VIRT REAL INT, DOI [10.1145/2806173.2806178, DOI 10.1145/2806173.2806178]
   Isogawa M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P587, DOI 10.1109/VR.2018.8446073
   Kimura T., 2018, MULTIDISCIPLINARY DI, V2, P299, DOI [10.3390/proceedings2060299, DOI 10.3390/PROCEEDINGS2060299]
   Lindsay R.-S., J SPORT SCI, V6, P20
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Munroe-Chandler K.J., 2005, European Journal of Sport Science, V5, P41, DOI [10.1080/17461390500076592, DOI 10.1080/17461390500076592]
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   NeuroTracker, 2018, NEUR
   Nicol F, 2013, PROC INT C INTERDISC, P1
   Ramsay J. O., 2006, Encyclopedia of Statistical Sciences, DOI [10.1002/0471667196.ess3138, DOI 10.1002/0471667196.ESS3138]
   Reyna J, 2018, INTED PROC, P1448
   S. Labs, 2016, STRIVR IMM TRAIN SOL
   Sampaio J, 2014, SCI SPORT, V29, pE23, DOI 10.1016/j.scispo.2013.05.004
   Silverman B.W., 2018, DENSITY ESTIMATION S, DOI DOI 10.1201/9781315140919
   Sports E., 2016, EON SPORTS VR N D
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Tcha-Tokey K., 2017, ACM International Conference Proceeding Series, Part, VF1311, P1, DOI DOI 10.1145/3121283.3121284
   Tsai W.-L., 2017, P 2017 ACM WORKSH MU, P3
   Tsai WL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1193, DOI [10.1109/VR.2019.8798309, 10.1109/vr.2019.8798309]
   Ullah S, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-43
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vignais N, 2015, HUM MOVEMENT SCI, V39, P12, DOI 10.1016/j.humov.2014.10.006
   Wellner M, 2010, P I MECH ENG P-J SPO, V224, P117, DOI 10.1243/17543371JSET33
   Williams SE, 2011, J SPORT EXERCISE PSY, V33, P416, DOI 10.1123/jsep.33.3.416
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu KH, 2019, IEEE INT CONF BIG DA, P5094, DOI 10.1109/BigData47090.2019.9005551
   Zinchenko YP, 2011, PSYCHOL RUSS, V4, P129
NR 40
TC 18
Z9 19
U1 14
U2 93
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2970
EP 2982
DI 10.1109/TVCG.2020.3046326
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600012
PM 33351762
DA 2024-11-06
ER

PT J
AU Chung, H
   Nandhakumar, S
   Yang, S
AF Chung, Haeyong
   Nandhakumar, Santhosh
   Yang, Seungwon
TI GridSet: Visualizing Individual Elements and Attributes for Analysis of
   Set-Typed Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Layout; Motion pictures; Image color
   analysis; Complexity theory; Aggregates; Set visualization; sets;
   intersections; elements; attributes; glyphs; visual links; treemap;
   set-typed data
ID VISUALIZATIONS; EXPLORATION
AB We present GridSet, a novel set visualization for exploring elements, their attributes, intersections, as well as entire sets. In this set visualization, each set representation is composed of glyphs, which represent individual elements and their attributes utilizing different visual encodings. In each set, elements are organized within a grid treemap layout that can provide space-efficient overviews of the elements structured by set intersections across multiple sets. These intersecting elements can be connected among sets through visual links. These visual representations for the individual set, elements, and intersection in GridSet facilitate novel interaction approaches for undertaking analysis tasks by utilizing both macroscopic views of sets, as well as microscopic views of elements and attribute details. In order to perform multiple set operations, GridSet supports a simple and straightforward process for set operations through dragging and dropping set objects. Our use cases involving two large set-typed datasets demonstrate that GridSet facilitates the exploration and identification of meaningful patterns and distributions of elements with respect to attributes and set intersections for solving complex analysis problems in set-typed data.
C1 [Chung, Haeyong; Nandhakumar, Santhosh] Univ Alabama Huntsville, Dept Comp Sci, Huntsville, AL 35899 USA.
   [Yang, Seungwon] Louisiana State Univ, Sch Informat Studies, Baton Rouge, LA 70803 USA.
   [Yang, Seungwon] Louisiana State Univ, Ctr Computat & Technol, Baton Rouge, LA 70803 USA.
C3 University of Alabama System; University of Alabama Huntsville;
   Louisiana State University System; Louisiana State University; Louisiana
   State University System; Louisiana State University
RP Chung, H (corresponding author), Univ Alabama Huntsville, Dept Comp Sci, Huntsville, AL 35899 USA.
EM hc0021@uah.edu; sn0026@uah.edu; seungwonyang@lsu.edu
OI Nandhakumar, Santhosh/0000-0002-7674-6138
CR Academy ofMotion Picture Arts and Sciences, 2019, OFFICIAL ACAD AWARDS
   Ahlberg C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P619, DOI 10.1145/142750.143054
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B, 2017, IEEE T VIS COMPUT GR, V23, P361, DOI 10.1109/TVCG.2016.2598496
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chambers John M, 1983, GRAPHICAL METHODS DA
   Chung HY, 2018, PERS UBIQUIT COMPUT, V22, P409, DOI 10.1007/s00779-017-1091-4
   Chung H, 2012, IEEE CONF VIS ANAL, P289
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   D'Hont A, 2012, NATURE, V488, P213, DOI 10.1038/nature11241
   Dinkla K, 2012, COMPUT GRAPH FORUM, V31, P875, DOI 10.1111/j.1467-8659.2012.03080.x
   Drucker S., 2015, MSRTR201565 MICR RES
   EICK SG, 1992, IEEE T SOFTWARE ENG, V18, P957, DOI 10.1109/32.177365
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Fekete JD, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P117, DOI 10.1109/INFVIS.2002.1173156
   Fisher D., 2018, SANDDANCE
   Freiler W, 2008, IEEE T VIS COMPUT GR, V14, P1340, DOI 10.1109/TVCG.2008.144
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hutchins EL., 1985, HUMAN COMPUTER INTER, V1, P311, DOI DOI 10.1207/S15327051HCI0104_2
   Jones DM, 1996, CONFLICT MANAG PEACE, V15, P163, DOI 10.1177/073889429601500203
   Keim D. A., 2002, Information Visualization, V1, P20, DOI 10.1057/palgrave/ivs/9500003
   Keim D.A., 1996, J COMPUT GRAPH STAT, V5, P58, DOI DOI 10.1080/10618600.1996.10474695
   Keim DA, 2000, IEEE T VIS COMPUT GR, V6, P59, DOI 10.1109/2945.841121
   Kim B, 2007, INTERACT COMPUT, V19, P630, DOI 10.1016/j.intcom.2007.05.004
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Misue K, 2006, PROC ASIA PACIFIC S, P169
   Neale DB, 2014, GENOME BIOL, V15, DOI 10.1186/gb-2014-15-3-r59
   Oelke D, 2014, COMPUT GRAPH FORUM, V33, P201, DOI 10.1111/cgf.12376
   Oelke D, 2011, COMPUT GRAPH FORUM, V30, P871, DOI 10.1111/j.1467-8659.2011.01936.x
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Schreck T., 2006, P 22 SPRING C COMPUT, P184, DOI [10.1145/2602161.2602183, DOI 10.1145/2602161.2602183]
   Shen Zeqian, 2006, P 2006 AS PAC S INF, P93
   Shneiderman B., 1997, IUI97. 1997 International Conference on Intelligent User Interfaces, P33, DOI 10.1145/238218.238281
   Simonetto P, 2009, COMPUT GRAPH FORUM, V28, P967, DOI 10.1111/j.1467-8659.2009.01452.x
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   Vihrovs Jevgenijs, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P29
   Waldner Manuela, 2010, P C GRAPH INT GI 10, P129
   Ward M. O., 2002, Information Visualization, V1, P194, DOI 10.1057/palgrave.ivs.9500025
   Wickens C.D., 2015, ENG PSYCHOL HUMAN PE, DOI DOI 10.4324/9781315665177
   Wickham H, 2012, ENVIRONMETRICS, V23, P382, DOI 10.1002/env.2152
   Wilkinson L, 1999, AM PSYCHOL, V54, P594, DOI 10.1037/0003-066X.54.8.594
   Wilkinson L, 2012, IEEE T VIS COMPUT GR, V18, P321, DOI 10.1109/TVCG.2011.56
   Yalçin MA, 2016, IEEE T VIS COMPUT GR, V22, P688, DOI 10.1109/TVCG.2015.2467051
NR 52
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2983
EP 2998
DI 10.1109/TVCG.2020.3047111
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600013
PM 33360996
DA 2024-11-06
ER

PT J
AU Armando, M
   Franco, JS
   Boyer, E
AF Armando, Matthieu
   Franco, Jean-Sebastien
   Boyer, Edmond
TI Mesh Denoising With Facet Graph Convolutions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Noise reduction; Faces; Shape; Noise measurement; Three-dimensional
   displays; Surface treatment; Optimization; Mesh denoising; normal
   filtering; graph convolution; feature preserving; geometric deep
   learning
AB We examine the problem of mesh denoising, which consists of removing noise from corrupted 3D meshes while preserving existing geometric features. Most mesh denoising methods require a lot of mesh-specific parameter fine-tuning, to account for specific features and noise types. In recent years, data-driven methods have demonstrated their robustness and effectiveness with respect to noise and feature properties on a wide variety of geometry and image problems. Most existing mesh denoising methods still use hand-crafted features, and locally denoise facets rather than examine the mesh globally. In this work, we propose the use of a fully end-to-end learning strategy based on graph convolutions, where meaningful features are learned directly by our network. It operates on a graph of facets, directly on the existing topology of the mesh, without resampling, and follows a multi-scale design to extract geometric features at different resolution levels. Similar to most recent pipelines, given a noisy mesh, we first denoise face normals with our novel approach, then update vertex positions accordingly. Our method performs significantly better than the current state-of-the-art learning-based methods. Additionally, we show that it can be trained on noisy data, without explicit correspondence between noisy and ground-truth facets. We also propose a multi-scale denoising strategy, better suited to correct noise with a low spatial frequency.
C1 [Armando, Matthieu; Franco, Jean-Sebastien; Boyer, Edmond] Univ Grenoble Alpes, LJK, Grenoble INP, Inria,CNRS, F-38000 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA);
   Institut National Polytechnique de Grenoble; Inria; Centre National de
   la Recherche Scientifique (CNRS)
RP Armando, M (corresponding author), Univ Grenoble Alpes, LJK, Grenoble INP, Inria,CNRS, F-38000 Grenoble, France.
EM matthieu.armando@inria.fr; jean-sebastien.franco@inria.fr;
   edmond.boyer@inria.fr
OI Armando, Matthieu/0000-0002-5118-4757
FU MSR-Inria Joint Center
FX The work of Matthieu Armando was funded by the MSR-Inria Joint Center.
CR Aanæs H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   [Anonymous], 2001, Res. Rep. RC2213 IBM
   [Anonymous], 2014, KINOVIS INRIA PLATFO
   Arvanitis G, 2019, IEEE T VIS COMPUT GR, V25, P1513, DOI 10.1109/TVCG.2018.2802926
   Boscaini D, 2016, ADV NEUR IN, V29
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Clarenz U., 2002, PROC VIS, P397
   Defferrard M, 2016, ADV NEUR IN, V29
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI [10.1109/TPAMI.2007.1115, 10.1109/TP'AMI.2007.1115]
   Diebel JR, 2006, ACM T GRAPHIC, V25, P39, DOI 10.1145/1122501.1122504
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Kingma D. P., 2017, P INT C LEARNING REP, P1
   Leroy V, 2018, LECT NOTES COMPUT SC, V11213, P796, DOI 10.1007/978-3-030-01240-3_48
   Li XZ, 2018, COMPUT GRAPH FORUM, V37, P155, DOI 10.1111/cgf.13556
   Li ZQ, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102861
   Liu B, 2018, COMPUT GRAPH-UK, V74, P119, DOI 10.1016/j.cag.2018.05.003
   Liu D, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P842
   Maas A. L., 2013, ICML WORKSH DEEP LEA
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Tasdizen T, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P125, DOI 10.1109/VISUAL.2002.1183766
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Vollmer J, 1999, COMPUT GRAPH FORUM, V18, pC131, DOI 10.1111/1467-8659.00334
   Wang J, 2019, COMPUT AIDED DESIGN, V114, P133, DOI 10.1016/j.cad.2019.05.027
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P2910, DOI 10.1109/TVCG.2018.2865363
   Yadav SK, 2019, IEEE T VIS COMPUT GR, V25, P2304, DOI 10.1109/TVCG.2018.2828818
   Yadav SK, 2018, IEEE T VIS COMPUT GR, V24, P2366, DOI 10.1109/TVCG.2017.2740384
   Yagou H, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P28, DOI 10.1109/CGI.2003.1214444
   Yagou H, 2002, GEOMETRIC MODELING AND PROCESSING: THEORY AND APPLICATIONS, PROCEEDINGS, P124, DOI 10.1109/GMAP.2002.1027503
   Yoshizawa S, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P38
   Zhang H, 2010, COMPUT GRAPH FORUM, V29, P1865, DOI 10.1111/j.1467-8659.2010.01655.x
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zhao W., 2019, NORMALNET LEARNING B
   Zhao Y, 2018, COMPUT AIDED DESIGN, V101, P82, DOI 10.1016/j.cad.2018.04.001
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
NR 45
TC 14
Z9 14
U1 0
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 2999
EP 3012
DI 10.1109/TVCG.2020.3045490
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600014
PM 33332273
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Rahimi, FB
   Boyd, JE
   Levy, RM
   Eiserman, J
AF Rahimi, Farzan Baradaran
   Boyd, Jeffrey E.
   Levy, Richard M.
   Eiserman, Jennifer
TI New Media and Space: An Empirical Study of Learning and Enjoyment
   Through Museum Hybrid Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Games; Media; Time measurement; Statistics; Augmented reality; Next
   generation networking; Virtual reality; Evaluation; methodology; games
   and infotainment; new media and museum hybrid space; virtual reality
ID PERCEPTION; TIME; GAME
AB A museum hybrid space combines physical artifacts co-located with virtual and augmented reality displays. Although the technology exists to provide museums with hybrid space, there are no empirical studies on effectiveness of the museum hybrid space in terms of learning and enjoyment. This article takes an experimental approach and measures the enjoyment and learning (dependent variables) of participants in response to selected environments (independent variables) including a traditional environment (based on photos and labels), a video-enhanced environment (based on projected video clips), and a VR-enhanced environment (based on video game). The main outcome of this article is demonstrating that the use of VR technology and the resulting hybrid space (i.e., VR-enhanced environment) results in novel museum experiences that provide greater impacts on audience in terms of learning and enjoyment.
C1 [Rahimi, Farzan Baradaran] Univ Calgary, Computat Media Design CMD Program, Calgary, AB T2N 1N4, Canada.
   [Boyd, Jeffrey E.] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
   [Levy, Richard M.] Univ Calgary, Sch Architecture Planning & Landscape, Calgary, AB T2N 1N4, Canada.
   [Eiserman, Jennifer] Univ Calgary, Dept Art, Calgary, AB T2N 1N4, Canada.
C3 University of Calgary; University of Calgary; University of Calgary;
   University of Calgary
RP Rahimi, FB (corresponding author), Univ Calgary, Computat Media Design CMD Program, Calgary, AB T2N 1N4, Canada.
EM farzan.baradaran@ucalgary.ca; jboyd@ucalgary.ca; rmlevy@ucalgary.ca;
   jreiserman@ucalgary.ca
OI Baradaran Rahimi, Farzan/0000-0001-5938-0181
CR Rahimi FB, 2021, SPACE CULT, V24, P83, DOI 10.1177/1206331218793065
   Brengman M., 2002, THESIS GHENT U BRUSS
   Campbell D. T., 1963, EXPT QUASIEXPERIMENT
   Carrozzino M, 2010, J CULT HERIT, V11, P452, DOI 10.1016/j.culher.2010.04.001
   Castells M., 2010, The Rise of the Network Society, V2, DOI DOI 10.1002/9781444319514.CH6
   Chinchanachokchai S, 2015, COMPUT HUM BEHAV, V45, P185, DOI 10.1016/j.chb.2014.11.087
   Connolly TM, 2012, COMPUT EDUC, V59, P661, DOI 10.1016/j.compedu.2012.03.004
   Daniel W.W., 1999, Biostatics: A Foundation for Analysis in Health Sciences, Vseventh
   de Souzae Silva., 2006, Space and Culture, V9, P261, DOI [10.1177/1206331206289022, DOI 10.1177/1206331206289022, 10.1177/]
   DONOVAN RJ, 1982, J RETAILING, V58, P34
   Falk J.H., 2002, Lessons without limit: How free-choice learning is transforming education
   Gagne R.M., 1979, PRINCIPLES INSTRUCTI, V2nd
   GRAHAM RJ, 1981, J CONSUM RES, V7, P335, DOI 10.1086/208823
   Hooper-Greenhill E., 2004, INT J HERIT STUD, V10, P151, DOI [10.1080/13527250410001692877, DOI 10.1080/13527250410001692877]
   Hooper-Greenhill E., 2003, MEASURING OUTCOMES I
   Janes RR, 2009, MUS MEAN, P1
   Lepouras G., 2004, Virtual Reality, V8, P927, DOI [https://doi.org/10.1007/s10055-004-0141-1, DOI 10.1007/S10055-004-0141-1]
   Ma J, 2020, IEEE T VIS COMPUT GR, V26, P472, DOI 10.1109/TVCG.2019.2934401
   Mitchell W., 1999, e-topia: Urban Life, Jim--but not as we know it
   Murre JMJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120644
   Naing L, 2006, ARCH OROFAC SCI, V1, P9
   Rahimi FB, 2020, IEEE T GAMES, V12, P312, DOI 10.1109/TG.2019.2954880
   Sadler GR, 2010, NURS HEALTH SCI, V12, P369, DOI 10.1111/j.1442-2018.2010.00541.x
   Smith PatriciaL., 1993, INSTRUCTIONAL DESIGN, VThird
   Teddlie C, 2007, J MIX METHOD RES, V1, P77, DOI 10.1177/2345678906292430
   Watson WR, 2011, COMPUT EDUC, V56, P466, DOI 10.1016/j.compedu.2010.09.007
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Yildirim Z, 2001, J EDUC RES, V94, P207, DOI 10.1080/00220670109598754
   Zar J.H., 2013, Ecology, DOI DOI 10.2307/2265725
NR 29
TC 10
Z9 11
U1 7
U2 51
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 3013
EP 3021
DI 10.1109/TVCG.2020.3043324
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600015
PM 33290225
DA 2024-11-06
ER

PT J
AU Sui, XJ
   Ma, KD
   Yao, YR
   Fang, YM
AF Sui, Xiangjie
   Ma, Kede
   Yao, Yiru
   Fang, Yuming
TI Perceptual Quality Assessment of Omnidirectional Images as Moving Camera
   Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Omnidirectional images; perceptual quality assessment; virtual reality
AB Omnidirectional images (also referred to as static 360 degrees panoramas) impose viewing conditions much different from those of regular 2D images. How do humans perceive image distortions in immersive virtual reality (VR) environments is an important problem which receives less attention. We argue that, apart from the distorted panorama itself, two types of VR viewing conditions are crucial in determining the viewing behaviors of users and the perceived quality of the panorama: the starting point and the exploration time. We first carry out a psychophysical experiment to investigate the interplay among the VR viewing conditions, the user viewing behaviors, and the perceived quality of 360 degrees images. Then, we provide a thorough analysis of the collected human data, leading to several interesting findings. Moreover, we propose a computational framework for objective quality assessment of 360 degrees images, embodying viewing conditions and behaviors in a delightful way. Specifically, we first transform an omnidirectional image to several video representations using different user viewing behaviors under different viewing conditions. We then leverage advanced 2D full-reference video quality models to compute the perceived quality. We construct a set of specific quality measures within the proposed framework, and demonstrate their promises on three VR quality databases.
C1 [Sui, Xiangjie; Yao, Yiru; Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330032, Jiangxi, Peoples R China.
   [Ma, Kede] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Jiangxi University of Finance & Economics; City University of Hong Kong
RP Fang, YM (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang 330032, Jiangxi, Peoples R China.
EM suixiangjie2017@163.com; kede.ma@cityu.edu.hk; 2848444870@qq.com;
   fa0001ng@e.ntu.edu.sg
OI Ma, Kede/0000-0001-8608-1128
FU National Key R&D Program of China [2018AAA0100601]; National Natural
   Science Foundation of China [62071407, 61822109]; Fok Ying Tung
   Education Foundation [161061]; Jiangxi Natural Science Foundation of
   China [20202ACB202007]; CityU APRC [9610487]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018AAA0100601, the National Natural Science Foundation of
   China under Grants 62071407 and 61822109, the Fok Ying Tung Education
   Foundation under Grant 161061, the Jiangxi Natural Science Foundation of
   China under Grant 20202ACB202007, and the CityU APRC under Grant
   9610487.
CR [Anonymous], 2020, VR PHOTOGRAPHY
   [Anonymous], 2017, JVETG1003
   Antkowiak J., 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment
   Balle Johannes, 2018, INT C LEARN REPR
   Besharse J., 2011, The retina and its disorders
   Channappayya SS, 2008, INT CONF ACOUST SPEE, P765, DOI 10.1109/ICASSP.2008.4517722
   Chen MX, 2020, IEEE J-STSP, V14, P89, DOI 10.1109/JSTSP.2019.2956408
   Chen SJ, 2018, IEEE INT CON MULTI
   Ding K., 2020, COMP IMAGE QUALITY M
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Duan HY, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351786
   Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785
   Hands DS, 2001, APPL COGNITIVE PSYCH, V15, P639, DOI 10.1002/acp.731
   Huang MK, 2018, IEEE T IMAGE PROCESS, V27, P6039, DOI 10.1109/TIP.2018.2865089
   Jabar F., 2020, IEEE INT C MULTIMEDI, P1
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14
   Laparra V, 2017, J OPT SOC AM A, V34, P1511, DOI 10.1364/JOSAA.34.001511
   Li Z, 2016, SCI REP-UK, V6, DOI 10.1038/srep30338
   Lopes F, 2018, PROC SPIE, V10752, DOI 10.1117/12.2321679
   Luz G., 2017, P IEEE 19 INT WORKSH, P1
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989
   NOTON D, 1971, VISION RES, V11, P929, DOI 10.1016/0042-6989(71)90213-6
   Series B., 2012, Recommendation ITU-R BT
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Snell J, 2017, IEEE IMAGE PROC, P4277, DOI 10.1109/ICIP.2017.8297089
   Sun W., 2018, 2018 IEEE International Conference on Communications (ICC), P1, DOI 10.1109/MMSP.2018.8547102
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Tabachnick B.G., 2007, USING MULTIVARIATE S, P117
   Tu ZZ, 2020, IEEE IMAGE PROC, P141, DOI 10.1109/ICIP40778.2020.9191169
   Upenik E, 2016, PICT COD SYMP
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, MODERN IMAGE QUALITY
   Xu J., 2019, PROC PICTURE CODING, P1
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1080/17445302.2018.1558727, 10.1109/TCSVT.2018.2886277]
   Xu MN, 2020, INT CONF ACOUST SPEE, P4447, DOI [10.1109/icassp40776.2020.9053031, 10.1109/ICASSP40776.2020.9053031]
   Yu M, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P31, DOI 10.1109/ISMAR.2015.12
   Zakharchenko V, 2016, PROC SPIE, V9970, DOI 10.1117/12.2235885
   Zeng K, 2012, IEEE IMAGE PROC, P621, DOI 10.1109/ICIP.2012.6466936
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YX, 2018, IEEE T BROADCAST, V64, P461, DOI 10.1109/TBC.2018.2811627
NR 49
TC 28
Z9 29
U1 1
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 3022
EP 3034
DI 10.1109/TVCG.2021.3050888
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600016
PM 33434131
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, S
   Gu, X
   Yi, KR
   Yang, YL
   Wang, GP
   Manocha, D
AF Li, Sheng
   Gu, Xiang
   Yi, Kangrui
   Yang, Yanlin
   Wang, Guoping
   Manocha, Dinesh
TI Self-Illusion: A Study on Cognition of Role-Playing in Immersive Virtual
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cats; Psychology; Cognition; Virtual environments; Particle
   measurements; Atmospheric measurements; Physiology; Presence;
   self-illusion; plausibility illusion; place illusion; sense of
   embodiment; virtual body ownership; non-human role; dissociation;
   virtual reality
ID REALITY; APPEARANCE; EXPERIENCE; SENSE; REPRESENTATION; CHARACTERS;
   OWNERSHIP; AGENCY; FEEL
AB We present the design and results of an experiment investigating the occurrence of self-illusion and its contribution to realistic behavior consistent with a virtual role in virtual environments. Self-illusion is a generalized illusion about one's self in cognition, eliciting a sense of being associated with a role in a virtual world, despite sure knowledge that this role is not the actual self in the real world. We validate and measure self-illusion through an experiment where each participant occupies a non-human perspective and plays a non-human role using this role's behavior patterns. 77 participants were enrolled for the user study according to the priori power analysis. In the mixed-design experiment with different levels of manipulations, we asked the participants to play a cat (a non-human role) within an immersive VE and captured their different kinds of responses, finding that the participants with higher self-illusion can connect themselves to the virtual role more easily. Based on statistical analysis of questionnaires and behavior data, there is some evidence that self-illusion can be considered a novel psychological component of presence because it is dissociated from sense of embodiment (SoE), plausibility illusion (Psi), and place illusion (PI). Moreover, self-illusion has the potential to be an effective evaluation metric for user experience in a virtual reality system for certain applications.
C1 [Li, Sheng; Gu, Xiang; Yi, Kangrui; Yang, Yanlin; Wang, Guoping] Peking Univ, Beijing 100871, Peoples R China.
   [Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
C3 Peking University; University System of Maryland; University of Maryland
   College Park
RP Li, S (corresponding author), Peking Univ, Beijing 100871, Peoples R China.
EM lisheng@pku.edu.cn; xgu@pku.edu.cn; yikangrui@pku.edu.cn;
   yangyl@pku.edu.cn; wgp@pku.edu.cn; dm@cs.umd.edu
RI wang, guoping/KQU-3394-2024
OI Gu, Xiang/0000-0002-8527-9113; Li, Sheng/0000-0002-8901-2184
FU National Key R&D Program of China [2017 YFB0203002, 2017YFB1002700];
   National Natural Science Foundation of China [61632003, 61631001]
FX The authors would like to thank anonymous reviewers for their helpful
   comments. This work was supported by the National Key R&D Program of
   China under Grants No.2017 YFB0203002, No.2017YFB1002700 and National
   Natural Science Foundation of China under Grants No.61632003,
   No.61631001.
CR Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Aymerich-Franch L, 2016, NEUROSCI RES, V104, P31, DOI 10.1016/j.neures.2015.11.001
   Banakou D, 2014, P NATL ACAD SCI USA, V111, P17678, DOI 10.1073/pnas.1414936111
   Baumeister R. F., 1999, The self in social psychology
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Domna B, 2013, P NATL ACAD SCI USA, V110
   Egeberg MCS, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927940
   Foreman N., 2010, THEMES SCI TECHNOLOG, V2, P225
   Giumetti GW, 2007, J RES PERS, V41, P1234, DOI 10.1016/j.jrp.2007.02.005
   Gonzalez-Franco M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01125
   HIGGINS ET, 1987, PSYCHOL REV, V94, P319, DOI 10.1037/0033-295X.94.3.319
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hood BruceM., 2012, The Self Illusion: How the Social Brain Creates Identity
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Huettel, 2004, FUNCTIONAL MAGNETIC, V1
   Ijsselsteijn W, 2003, EMERG COMMUNICAT, V5, P3
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Jung S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI 10.1109/VR.2018.8447562
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kong GQ, 2017, CONSCIOUS COGN, V52, P115, DOI 10.1016/j.concog.2017.04.018
   Laha B, 2016, PRESENCE-VIRTUAL AUG, V25, P129, DOI 10.1162/PRES_a_00251
   Lakoff G., 1999, Concepts: Core Readings, P391
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1093/ct/14.1.27
   Lewis-Beck M, 2003, SAGE ENCY SOCIAL SCI
   Lombard M., 2015, Immersed in Media, P13, DOI [10.1007/978-3-319-10190-3_2, DOI 10.1007/978-3-319-10190-3_2]
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Markus H., 1987, SELF IDENTITY, P157
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   Muender T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300903
   Murata A, 2004, INT J HUM-COMPUT INT, V17, P463, DOI 10.1207/s15327590ijhc1704_2
   O'Regan JK, 2001, BEHAV BRAIN SCI, V24, P939, DOI 10.1017/S0140525X01000115
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   PIERS EV, 1964, J EDUC PSYCHOL, V55, P91, DOI 10.1037/h0044453
   Ratan R, 2010, PSYCHNOLOGY J, V8, P11
   Ratan Rabindra, 2013, HDB RES TECHNOSELF I, P322, DOI [10.4018/978-1-4666-2211-1.ch018, DOI 10.4018/978-1-4666-2211-1.CH018]
   Rehm IC, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00186
   Roth D., 2017, P 2017 CHI C EXT ABS, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Rovira A, 2009, FRONT BEHAV NEUROSCI, V3, DOI 10.3389/neuro.08.059.2009
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert TW, 2009, COMMUN THEOR, V19, P161, DOI 10.1111/j.1468-2885.2009.01340.x
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Sears P. S., 1963, OE873 USOE
   Singh AK, 2018, IEEE ACCESS, V6, P24617, DOI 10.1109/ACCESS.2018.2832089
   Skarbez R., 2016, PhD thesis, DOI 10.17615/2mg3-gh93
   Skarbez R., 2015, IEEE VIRT REAL VR DO
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2004, CYBERPSYCHOL BEHAV, V7, P121, DOI 10.1089/109493104322820200
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Steed A, 1996, P IEEE VIRT REAL ANN, P163, DOI 10.1109/VRAIS.1996.490524
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Turner P, 2014, AI SOC, V29, P497, DOI 10.1007/s00146-013-0491-x
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Won AS, 2015, PRESENCE-TELEOP VIRT, V24, P335, DOI 10.1162/PRES_a_00238
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 70
TC 6
Z9 6
U1 4
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 3035
EP 3049
DI 10.1109/TVCG.2020.3044563
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600017
PM 33315568
DA 2024-11-06
ER

PT J
AU Yeshchenko, A
   Di Ciccio, C
   Mendling, J
   Polyvyanyy, A
AF Yeshchenko, Anton
   Di Ciccio, Claudio
   Mendling, Jan
   Polyvyanyy, Artem
TI Visual Drift Detection for Event Sequence Data of Business Processes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Business; Data visualization; Data mining; Visualization; Erbium;
   Antibiotics; Guidelines; Sequence data; visualization; temporal data;
   process mining; process drifts; declarative process models
ID USER ACCEPTANCE; PROCESS MODELS; DESIGN
AB Event sequence data is increasingly available in various application domains, such as business process management, software engineering, or medical pathways. Processes in these domains are typically represented as process diagrams or flow charts. So far, various techniques have been developed for automatically generating such diagrams from event sequence data. An open challenge is the visual analysis of drift phenomena when processes change over time. In this article, we address this research gap. Our contribution is a system for fine-granular process drift detection and corresponding visualizations for event logs of executed business processes. We evaluated our system both on synthetic and real-world data. On synthetic logs, we achieved an average F-score of 0.96 and outperformed all the state-of-the-art methods. On real-world logs, we identified all types of process drifts in a comprehensive manner. Finally, we conducted a user study highlighting that our visualizations are easy to use and useful as perceived by process mining experts. In this way, our work contributes to research on process mining, event sequence analysis, and visualization of temporal data.
C1 [Yeshchenko, Anton; Mendling, Jan] Vienna Univ Econ & Business, A-1020 Vienna, Austria.
   [Di Ciccio, Claudio] Sapienza Univ Rome, I-00185 Rome, Italy.
   [Polyvyanyy, Artem] Univ Melbourne, Parkville, Vic 3010, Australia.
C3 Vienna University of Economics & Business; Sapienza University Rome;
   University of Melbourne
RP Yeshchenko, A (corresponding author), Vienna Univ Econ & Business, A-1020 Vienna, Austria.
EM anton.yeshchenko@wu.ac.at; claudio.diciccio@uniroma1.it;
   jan.mendling@wu.ac.at; artem.polyvyanyy@unimelb.edu.au
RI Polyvyanyy, Artem/AAR-9578-2020; Di Ciccio, Claudio/H-8898-2018
OI Mendling, Jan/0000-0002-7260-524X; Di Ciccio,
   Claudio/0000-0001-5570-0475
FU EU [645751]; Australian Research Council [DP180102839]; MUR
FX This work was supported in part by the EU H2020 program under MSCA-RISE
   agreement 645751 (RISE_BPM). The work of A. Polyvyanyy was supported in
   part by the Australian Research Council Discovery Project DP180102839.
   The work of C. Di Ciccio was supported in part by the MUR under Grant
   "Dipartimenti di eccellenza 2018-2022" of the Department of Computer
   Science at Sapienza University of Rome.
CR Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Aigner W, 2008, IEEE T VIS COMPUT GR, V14, P47, DOI 10.1109/TVCG.2007.70415
   Albers D, 2011, IEEE T VIS COMPUT GR, V17, P2392, DOI 10.1109/TVCG.2011.232
   [Anonymous], 2018, VIZSEC
   [Anonymous], 2018, Fundamentals of BPM, DOI DOI 10.1007/978-3-642-33143-5.PDF
   [Anonymous], 2012, INFORM VISUAL
   Bauer M, 2018, LECT NOTES COMPUT SC, V10816, P239, DOI 10.1007/978-3-319-91563-0_15
   Berti A., 2019, Process Mining for Python (PM4Py): Bridging the Gap Between Process and Data Science
   Cao, 2020, SURVEY VISUAL ANAL E
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Cecconi A, 2020, 2020 2ND INTERNATIONAL CONFERENCE ON PROCESS MINING (ICPM 2020), P113, DOI 10.1109/ICPM49681.2020.00026
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   CHEUNG YW, 1995, J BUS ECON STAT, V13, P277, DOI 10.2307/1392187
   Cousins S. B., 1991, Artificial Intelligence in Medicine, V3, P341, DOI 10.1016/0933-3657(91)90005-V
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   De Smedt J, 2018, INFORM SYST, V74, P40, DOI 10.1016/j.is.2018.01.001
   Deutch D, 2012, J COMPUT SYST SCI, V78, P583, DOI 10.1016/j.jcss.2011.09.004
   Di Ciccio Claudio, 2015, ACM Transactions on Management Information Systems, V5, DOI 10.1145/2629447
   Di Ciccio C, 2017, INFORM SYST, V64, P425, DOI 10.1016/j.is.2016.09.005
   Fahland, 2018, BPI CHALLENGE
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Garcia CD, 2019, EXPERT SYST APPL, V133, P260, DOI 10.1016/j.eswa.2019.05.003
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Guo SN, 2019, IEEE INT CONF BIG DA, P1125, DOI 10.1109/BigData47090.2019.9005687
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Hompes B., 2015, SIMPDA, V2015, P95
   Killick R, 2012, J AM STAT ASSOC, V107, P1590, DOI 10.1080/01621459.2012.737745
   Kim N. W., 2010, Proceedings of the International Conference on Advanced Visual Interfaces, P241, DOI 10.1145/1842993.1843035
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P396, DOI 10.1109/TVCG.2018.2864886
   Leemans S. J. J., 2015, PROC INT WORKSHOP BU, P85
   Leemans SJJ, 2019, 2019 INTERNATIONAL CONFERENCE ON PROCESS MINING (ICPM 2019), P25, DOI 10.1109/ICPM.2019.00015
   Liu HC, 2017, MINER ENG, V106, P22, DOI 10.1016/j.mineng.2017.01.013
   Maaradji A, 2017, IEEE T KNOWL DATA EN, V29, P2140, DOI 10.1109/TKDE.2017.2720601
   Maggi F. M., 2011, Proceedings 2011 IEEE Symposium on Computational Intelligence and Data Mining (CIDM 2011), P192, DOI 10.1109/CIDM.2011.5949297
   Maggi FM, 2018, INFORM SYST, V74, P136, DOI 10.1016/j.is.2017.12.002
   Malik S., 2015, P 20 INT C INT US IN, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10.1145/2678025.2701407]
   Mannhardt F., 2017, CEUR WORKSHOP P, V1859, P72
   Mendling J, 2008, LECT NOTES BUS INF P, V6, P1
   Meyer M, 2015, INFORM VISUAL, V14, P234, DOI 10.1177/1473871613510429
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Ostovar A, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3375398
   Ostovar A, 2016, LECT NOTES COMPUT SC, V9974, P330, DOI 10.1007/978-3-319-46397-1_26
   Polyvyanyy Artem, 2014, Application and Theory of Petri Nets and Concurrency. 35th International Conference, PETRI NETS 2014. Proceedings: LNCS 8489, P210, DOI 10.1007/978-3-319-07734-5_12
   Polyvyanyy A, 2016, FORM ASP COMPUT, V28, P597, DOI 10.1007/s00165-016-0372-4
   Prescher J., 2014, SIMPDA, V1293, P162
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Seeliger A., 2017, P 9 C SUBJ OR BUS PR, P6, DOI 10.1145/3040565.3040566
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Truong C, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107299
   Tsymbal A., 2004, The Problem of Concept Drift: Definitions and Related Work
   van der Aalst W, 2004, IEEE T KNOWL DATA EN, V16, P1128, DOI 10.1109/TKDE.2004.47
   van der Aalst WMP, 2009, COMPUT SCI-RES DEV, V23, P99, DOI 10.1007/s00450-009-0057-9
   van der Aalst Wil, 2016, Process Mining: Data Science in Action, V2nd, DOI [10.1007/978-3-662-49851-4_1, DOI 10.1007/978-3-662-49851-4]
   Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540
   Viegas Fernanda B., 2004, P SIGCHI C HUM FACT, P575, DOI [DOI 10.1038/455022a, 10.1145/985692.985765, DOI 10.1145/985692.985765]
   Wang X., 2020, CONCEPTEXPLORER VISU
   Weijters A., 2006, Technische Universiteit Eindhoven, Tech. Rep. WP, V166, P1
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   YESHCHENKO A, 2019, P 38 INT C CONC MOD, P119
   Yeshchenko A., 2020, CEUR WORKSHOP P, P31
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
NR 66
TC 16
Z9 17
U1 4
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 3050
EP 3068
DI 10.1109/TVCG.2021.3050071
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600018
PM 33417557
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ferrari, V
   Cattari, N
   Fontana, U
   Cutolo, F
AF Ferrari, Vincenzo
   Cattari, Nadia
   Fontana, Umberto
   Cutolo, Fabrizio
TI Parallax Free Registration for Augmented Reality Optical See-Through
   Displays in the Peripersonal Space (vol 28, pg 1608, 2022)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Correction
DE Augmented reality; Augmented reality; optical see-through; registration
AB In the original article, there was a mistake in the content of Table 2 page 8 column 1 as published. The values of the mean and standard deviation of the virtual-to-real overlay error in visual angles, which are reported for different checkerboard distances, are to be corrected. Due to a typing error within the data analysis code, we mistakenly considered an erroneous value of the average angular resolution for the eye-replacement camera. This scale factor is used to pass from the original registration errors (expressed in pixel) to the angular registration errors (in arcmin). The value of the average angular resolution is $\approx 2.67$approximate to 2.67 arcmin/pixel. The corrected Table 2 appears below.
C1 [Ferrari, Vincenzo; Fontana, Umberto; Cutolo, Fabrizio] Univ Pisa, Dept Informat Engn, I-56122 Pisa, Italy.
   [Ferrari, Vincenzo; Cattari, Nadia; Cutolo, Fabrizio] Univ Pisa, Dept Translat Res & New Technol Med & Surg, EndoCAS Ctr, I-56124 Pisa, Italy.
C3 University of Pisa; University of Pisa
RP Ferrari, V (corresponding author), Univ Pisa, Dept Informat Engn, I-56122 Pisa, Italy.; Ferrari, V (corresponding author), Univ Pisa, Dept Translat Res & New Technol Med & Surg, EndoCAS Ctr, I-56124 Pisa, Italy.
EM vincenzo.ferrari@unipi.it; nadia.cattari@endocas.unipi.it;
   umbertofontana93@gmail.com; fabrizio.cutolo@unipi.it
RI Cattari, Nadia/AAC-3748-2022; Ferrari, Vincenzo/H-9908-2015; Cutolo,
   Fabrizio/K-2408-2018
OI Ferrari, Vincenzo/0000-0001-9294-2828; Cattari,
   Nadia/0000-0002-7091-2908; Cutolo, Fabrizio/0000-0001-6773-3741
CR Ferrari V, 2022, IEEE T VIS COMPUT GR, V28, P1608, DOI 10.1109/TVCG.2020.3021534
NR 1
TC 0
Z9 1
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2022
VL 28
IS 8
BP 3069
EP 3069
DI 10.1109/TVCG.2022.3176417
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6BI
UT WOS:000819823600019
PM 35771835
OA Bronze
DA 2024-11-06
ER

PT J
AU Ruddle, RA
   Bernard, J
   Lucke-Tieke, H
   May, T
   Kohlhammer, J
AF Ruddle, Roy A.
   Bernard, Juergen
   Lucke-Tieke, Hendrik
   May, Thorsten
   Kohlhammer, Jorn
TI The Effect of Alignment on People's Ability to Judge Event Sequence
   Similarity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Biology; Visualization; Shape; Task analysis;
   Pattern analysis; Proteins; Event sequence visualization; sequence
   alignment; evaluation; user study
ID VISUALIZATION; PATTERNS; DATABASE; DESIGN
AB Event sequences are central to the analysis of data in domains that range from biology and health, to logfile analysis and people's everyday behavior. Many visualization tools have been created for such data, but people are error-prone when asked to judge the similarity of event sequences with basic presentation methods. This article describes an experiment that investigates whether local and global alignment techniques improve people's performance when judging sequence similarity. Participants were divided into three groups (basic versus local versus global alignment), and each participant judged the similarity of 180 sets of pseudo-randomly generated sequences. Each set comprised a target, a correct choice and a wrong choice. After training, the global alignment group was more accurate than the local alignment group (98 versus 93 percent correct), with the basic group getting 95 percent correct. Participants' response times were primarily affected by the number of event types, the similarity of sequences (measured by the Levenshtein distance) and the edit types (nine combinations of deletion, insertion and substitution). In summary, global alignment is superior and people's performance could be further improved by choosing alignment parameters that explicitly penalize sequence mismatches.
C1 [Ruddle, Roy A.] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
   [Bernard, Juergen] Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.
   [Bernard, Juergen] Univ Zurich, CH-8006 Zrich, Switzerland.
   [Lucke-Tieke, Hendrik; May, Thorsten; Kohlhammer, Jorn] Fraunhofer IGD, D-64283 Darmstadt, Germany.
C3 University of Leeds; University of British Columbia
RP Ruddle, RA (corresponding author), Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
EM R.A.Ruddle@leeds.ac.uk; jubernar@cs.ubc.ca;
   hendrik.luecke-tieke@igd.fraunhofer.de; thorsten.may@igd.fraunhofer.de;
   Joern.Kohlhammer@igd.fraunhofer.de
RI Bernard, Jürgen/AAK-5732-2021
OI Lucke-Tieke, Hendrik/0000-0002-0934-6820; May,
   Thorsten/0000-0001-8027-2687; Kohlhammer, Jorn/0000-0003-1706-8979
FU Alexander von Humboldt Foundation; Engineering and Physical Sciences
   Research Council [EP/N013980/1]; Alan Turing Institute Fellowship; EPSRC
   [EP/N013980/1] Funding Source: UKRI
FX This work was supported by the Alexander von Humboldt Foundation, the
   Engineering and Physical Sciences Research Council under Grant
   EP/N013980/1, and an Alan Turing Institute Fellowship awarded to R.A.R.
   Data associated with this article is available from the University of
   Leeds at https://doi.org/10.5518/934 [52].
CR Albers D, 2011, IEEE T VIS COMPUT GR, V17, P2392, DOI 10.1109/TVCG.2011.232
   Anderson CL, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-184
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Bernard J, 2015, PROC SPIE, V9397, DOI 10.1117/12.2079841
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Chappidi S, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P15, DOI 10.1145/3191801.3191808
   Darling ACE, 2004, GENOME RES, V14, P1394, DOI 10.1101/gr.2289704
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Du F, 2017, IEEE T VIS COMPUT GR, V23, P1636, DOI 10.1109/TVCG.2016.2539960
   Fails JA, 2006, IEEE CONF VIS ANAL, P167
   Goodstein DM, 2012, NUCLEIC ACIDS RES, V40, pD1178, DOI 10.1093/nar/gkr944
   Gotz D, 2014, J BIOMED INFORM, V48, P148, DOI 10.1016/j.jbi.2014.01.007
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Gusfield Dan, 1997, Algorithms on strings, trees and sequences: computer science and computational biology
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Heb M. P., 2018, THESIS TECHNISCHE U
   Hess M., 2016, PROC EUROGRAPHICS WO, P31
   Hess M, 2014, LECT NOTES COMPUT SC, V8395, P175, DOI 10.1007/978-3-319-05972-3_18
   Jentner W, 2018, VISUAL COMPUT, V34, P1225, DOI 10.1007/s00371-018-1483-0
   Katoh K, 2013, MOL BIOL EVOL, V30, P772, DOI 10.1093/molbev/mst010
   Krane D. E., 2003, FUNDAMENTAL CONCEPTS
   Larkin MA, 2007, BIOINFORMATICS, V23, P2947, DOI 10.1093/bioinformatics/btm404
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Liu Z., 2016, PROC IEEE VIS WORKSH
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Lu X, 2016, BPM DEMOS, P44
   Lücke-Tieke H, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P60, DOI 10.1109/BELIV.2018.8634201
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mahmood S, 2020, IEEE T VIS COMPUT GR, V26, P2875, DOI 10.1109/TVCG.2019.2895642
   Malik S., 2015, P 20 INT C INT US IN, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10.1145/2678025.2701407]
   Munzner T., 2014, AK Peters Visualization Series
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Nguyen PH, 2020, IEEE T VIS COMPUT GR, V26, P77, DOI 10.1109/TVCG.2019.2934609
   Nguyen PH, 2019, IEEE T VIS COMPUT GR, V25, P2838, DOI 10.1109/TVCG.2018.2859969
   Ovcharenko I, 2005, GENOME RES, V15, P184, DOI 10.1101/gr.3007205
   Perer A., 2016, PROC IEEE WORKSHOP T
   Robert X, 2014, NUCLEIC ACIDS RES, V42, pW320, DOI 10.1093/nar/gku316
   Ruddle R. A., 2020, EFFECT ALIGNMENT PEO, DOI [10.5518/934, DOI 10.5518/934]
   Ruddle R.A., 2016, P IEEE VIS 2016 WORK
   Sakai H, 2013, PLANT CELL PHYSIOL, V54, pE6, DOI 10.1093/pcp/pcs183
   Shneiderman B., 2016, P IEEE VIS WORKSH TE
   Sigrist CJA, 2010, NUCLEIC ACIDS RES, V38, pD161, DOI 10.1093/nar/gkp885
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Snowden R., 2012, Basic vision: An introduction to visual perception
   Vrotsou K, 2019, IEEE T VIS COMPUT GR, V25, P2597, DOI 10.1109/TVCG.2018.2848247
   Waterhouse AM, 2009, BIOINFORMATICS, V25, P1189, DOI 10.1093/bioinformatics/btp033
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat K, 2012, INTERACT COMPUT, V24, P55, DOI 10.1016/j.intcom.2012.01.003
   Zhang YX, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P206, DOI [10.1109/VISUAL.2019.8933584, 10.1109/visual.2019.8933584]
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 52
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3070
EP 3081
DI 10.1109/TVCG.2021.3050497
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700001
PM 33434130
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Zhang, SH
   Zhang, SK
   Xie, WY
   Luo, CY
   Yang, YL
   Fu, HB
AF Zhang, Song-Hai
   Zhang, Shao-Kui
   Xie, Wei-Yu
   Luo, Cheng-Yang
   Yang, Yong-Liang
   Fu, Hongbo
TI Fast 3D Indoor Scene Synthesis by Learning Spatial Relation Priors of
   Objects
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Three-dimensional displays; Computational modeling;
   Optimization; Mathematical model; Task analysis; Semantics; 3D indoor
   scene synthesis; furniture objects arrangement; complete spatial
   randomness
ID FAST SEARCH; RANDOMNESS; FIND
AB We present a framework for fast synthesizing indoor scenes, given a room geometry and a list of objects with learnt priors. Unlike existing data-driven solutions, which often learn priors by co-occurrence analysis and statistical model fitting, our method measures the strengths of spatial relations by tests for complete spatial randomness (CSR), and learns discrete priors based on samples with the ability to accurately represent exact layout patterns. With the learnt priors, our method achieves both acceleration and plausibility by partitioning the input objects into disjoint groups, followed by layout optimization using position-based dynamics (PBD) based on the Hausdorff metric. Experiments show that our framework is capable of measuring more reasonable relations among objects and simultaneously generating varied arrangements in seconds compared with the state-of-the-art works.
C1 [Zhang, Song-Hai; Zhang, Shao-Kui; Xie, Wei-Yu] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Zhang, Song-Hai] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.
   [Luo, Cheng-Yang] Tsinghua Univ, Dept Math Sci, Beijing 100084, Peoples R China.
   [Yang, Yong-Liang] Univ Bath, Dept Comp Sci, Bath BA2 7AY, Avon, England.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Tsinghua University; Tsinghua University; Tsinghua University;
   University of Bath; City University of Hong Kong
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM shz@tsinghua.edu.cn; zhangsk18@mails.tsinghua.edu.cn; ervinxie@qq.com;
   luocy16@mails.tsinghua.edu.cn; y.yang@cs.bath.ac.uk;
   hongbofu@cityu.edu.hk
OI Zhang, Shao-Kui/0000-0003-0353-1977; Xie, Weiyu/0000-0003-0173-1027;
   Yang, Yong-Liang/0000-0002-8071-5756; FU, Hongbo/0000-0002-0284-726X
FU National Key Technology RD Program [2017YFB1002604]; National Natural
   Science Foundation of China [61521002, 61772298]; Research Grant of
   Beijing Higher Institution Engineering Research Center; Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology; RCUK Grant CAMERA
   [EP/M023281/1, EP/T014865/1]; EPSRC [EP/T022523/1, EP/M023281/1] Funding
   Source: UKRI
FX The authors would like to thank all reviewers for their thoughtful
   comments. This work was supported by the National Key Technology R&D
   Program (Project Number 2017YFB1002604), the National Natural Science
   Foundation of China (Project Numbers 61521002, 61772298), Research Grant
   of Beijing Higher Institution Engineering Research Center, and
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology.
   The work of Yong-Liang Yang was supported in part by RCUK Grant CAMERA
   (EP/M023281/1, EP/T014865/1).
CR ASSUNCAO R, 1994, BIOMETRICS, V50, P531, DOI 10.2307/2533397
   Assuncao R., 2000, BRAZ J PROBAB STAT, V14, P71
   Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Besag J.E., 1973, Bulletin of the International Statistical Institute, V45, P153
   Chang A., 2014, P 2014 C EMP METH NA, P2028, DOI [10.3115/v1/D14-1217, DOI 10.3115/V1/D14-1217, 10.3115/v1/D14-1217.]
   Chang A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P53
   Chen K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661239
   De Berg M., 2000, Computational geometry: Algorithms and applications
   Diggle P.J., 1983, Statistical analysis of spatial point patterns
   DIGGLE PJ, 1976, BIOMETRICS, V32, P659, DOI 10.2307/2529754
   DIGGLE PJ, 1979, BIOMETRICS, V35, P87, DOI 10.2307/2529938
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Fisher M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818057
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Fu H., 2020, arXiv
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Germer T, 2009, COMPUT GRAPH FORUM, V28, P2068, DOI 10.1111/j.1467-8659.2009.01351.x
   Gignoux J, 1999, BIOMETRICS, V55, P156, DOI 10.1111/j.0006-341X.1999.00156.x
   Graham R. L., 1972, Information Processing Letters, V1, P132, DOI 10.1016/0020-0190(72)90045-2
   Handa A, 2016, PROC CVPR IEEE, P4077, DOI 10.1109/CVPR.2016.442
   He Y., ARXIV 200304187, V2020
   Henderson P, 2019, Arxiv, DOI arXiv:1711.10939
   HINES WGS, 1979, BIOMETRIKA, V66, P73, DOI 10.1093/biomet/66.1.73
   Ho LP, 2006, J STAT COMPUT SIM, V76, P585, DOI 10.1080/00949650412331321043
   Hu RZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392391
   Huang SS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461954
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Kleiman Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818116
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   Li WB, 2018, COMM COM INF SC, V779, P77, DOI 10.1007/978-3-319-71734-0_7
   Li YB, 2018, AAAI CONF ARTIF INTE, P7041
   Liu MM, 2020, IEEE T VIS COMPUT GR, V26, P1702, DOI 10.1109/TVCG.2018.2880737
   Liu RH, 2019, NEUROCOMPUTING, V330, P223, DOI 10.1016/j.neucom.2018.06.058
   Lyons G. H., 2008, 10 COMMON HOME DECOR
   Ma R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275035
   Ma R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980223
   Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Ritchie D, 2019, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2019.00634
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Satkin S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.128
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Tong B., 2019, P 3 INT C MECH ENG I
   Wang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322941
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Weiss T, 2019, IEEE T VIS COMPUT GR, V25, P3231, DOI 10.1109/TVCG.2018.2866436
   Wu WM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356556
   Xie H., 2013, Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry, P191
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461968
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2016, IEEE T VIS COMPUT GR, V22, P1138, DOI 10.1109/TVCG.2015.2417575
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Yuan Liang, 2018, Computational Visual Media, V4, P123, DOI 10.1007/s41095-018-0110-3
   Yuan Liang, 2017, Next Generation Computer Animation Techniques. Third International Workshop, AniNex 2017. Revised Selected Papers: LNCS 10582, P133, DOI 10.1007/978-3-319-69487-0_10
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
NR 59
TC 15
Z9 17
U1 0
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3082
EP 3092
DI 10.1109/TVCG.2021.3050143
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700002
PM 33434129
OA Green Published
DA 2024-11-06
ER

PT J
AU Procopio, M
   Mosca, A
   Scheidegger, C
   Wu, E
   Chang, R
AF Procopio, Marianne
   Mosca, Ab
   Scheidegger, Carlos
   Wu, Eugene
   Chang, Remco
TI Impact of Cognitive Biases on Progressive Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Uncertainty; Bars; Task analysis; Real-time systems;
   Query processing; Data analysis; Progressive visualization; cognitive
   bias
ID VISUAL ANALYTICS; ENCODINGS
AB Progressive visualization is fast becoming a technique in the visualization community to help users interact with large amounts of data. With progressive visualization, users can examine intermediate results of complex or long running computations, without waiting for the computation to complete. While this has shown to be beneficial to users, recent research has identified potential risks. For example, users may misjudge the uncertainty in the intermediate results and draw incorrect conclusions or see patterns that are not present in the final results. In this article, we conduct a comprehensive set of studies to quantify the advantages and limitations of progressive visualization. Based on a recent report by Micallef et al., we examine four types of cognitive biases that can occur with progressive visualization: uncertainty bias, illusion bias, control bias, and anchoring bias. The results of the studies suggest a cautious but promising use of progressive visualization - while there can be significant savings in task completion time, accuracy can be negatively affected in certain conditions. These findings confirm earlier reports of the benefits and drawbacks of progressive visualization and that continued research into mitigating the effects of cognitive biases is necessary.
C1 [Procopio, Marianne; Mosca, Ab; Chang, Remco] Tufts Univ, Medford, MA 02155 USA.
   [Scheidegger, Carlos] Univ Arizona, Tucson, AZ 85721 USA.
   [Wu, Eugene] Columbia Univ, New York, NY 10027 USA.
C3 Tufts University; University of Arizona; Columbia University
RP Procopio, M (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM procopio@cs.tuts.edu; amosca01@cs.tuts.edu; cscheid@email.arizona.edu;
   ewu@cs.columbia.edu; remcol@cs.tufts.edu
OI Chang, Remco/0000-0002-6484-6430; Procopio,
   Marianne/0000-0002-9518-1259; Mosca, Ab/0000-0002-9008-5516
FU US National Science Foundation [1527765, 1564049, 1513651, 1452977,
   1845638]; DARPA [FA8750-17-2-0107]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1527765, 1452977,
   1513651, 1564049] Funding Source: National Science Foundation
FX The authors would like to thank Shannon Robinson and Brian Montambault
   for their help in preparing this manuscript, as well as the organizers
   and participants of Dagstuhl Seminar 18411 "Progressive Data Analysis
   and Visualization" whose discussions laid the foundation for this work.
   This work was supported in part by US National Science Foundation under
   Grants 1527765, 1564049, 1513651, 1452977, 1845638, and DARPA
   FA8750-17-2-0107.
CR Agarwal Sameer, 2013, 8 EUR C 2013 EUROSYS, P29
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Badam SK, 2017, COMPUT GRAPH FORUM, V36, P491, DOI 10.1111/cgf.13205
   Bedek MichaelA., 2018, COGNITIVE BIASES VIS, P61
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Cohen M. F., 1988, Computer Graphics, V22, P75, DOI 10.1145/378456.378487
   Cormode G, 2011, FOUND TRENDS DATABAS, V4, P1, DOI 10.1561/1900000004
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Crouser RJ, 2017, IEEE INTERNET COMPUT, V21, P72, DOI 10.1109/MIC.2017.2911428
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Ding BL, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P679, DOI 10.1145/2882903.2915249
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Ferreira N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P571, DOI 10.1145/2556288.2557131
   Fisher D., 2012, P SIGCHI C HUM FACT, P1673, DOI DOI 10.1145/2207676.2208294
   Fisher D, 2012, IEEE COMPUT GRAPH, V32, P55, DOI 10.1109/MCG.2012.48
   Glueck M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P561, DOI 10.1145/2556288.2557195
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Haas PJ, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P287, DOI 10.1145/304181.304208
   Hellerstein J. M., 1997, SIGMOD Record, V26, P171, DOI 10.1145/253262.253291
   Hetzler EG, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P89, DOI 10.1109/INFVIS.2005.1532133
   Hoppe H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P189, DOI 10.1145/258734.258843
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Jermaine C, 2008, ACM T DATABASE SYST, V33, DOI 10.1145/1412331.1412335
   Johnson DR, 2012, TEACH PSYCHOL, V39, P245, DOI 10.1177/0098628312456615
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kim A, 2015, PROC VLDB ENDOW, V8, P521, DOI 10.14778/2735479.2735485
   LAUR D, 1991, COMP GRAPH, V25, P285, DOI 10.1145/127719.122748
   Li FF, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P615, DOI 10.1145/2882903.2915235
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   McInnis B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2271, DOI 10.1145/2858036.2858539
   Micallef Luana, 2019, IN PRESS, P19, DOI [10.2312/evs.20191164, DOI 10.2312/EVS.20191164]
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Mühlbacher T, 2014, IEEE T VIS COMPUT GR, V20, P1643, DOI 10.1109/TVCG.2014.2346578
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Procopio M, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6010014
   Rahman S, 2017, PROC VLDB ENDOW, V10, P1262, DOI 10.14778/3137628.3137637
   Rosenbaum Rene, 2009, Proceedings of the SPIE - The International Society for Optical Engineering, V7243, DOI 10.1117/12.810501
   Schulz HJ, 2016, IEEE T VIS COMPUT GR, V22, P1830, DOI 10.1109/TVCG.2015.2462356
   SHNEIDERMAN B, 1984, COMPUT SURV, V16, P265, DOI 10.1145/2514.2517
   Smith AR, 2011, JUDGM DECIS MAK, V6, P139
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Turkay C, 2017, IEEE T VIS COMPUT GR, V23, P131, DOI 10.1109/TVCG.2016.2598470
   Valdez AC, 2018, IEEE T VIS COMPUT GR, V24, P584, DOI 10.1109/TVCG.2017.2744138
   Wall E., 2018, COGNITIVE BIASES VIS, P29, DOI [10.1007/978-3-319-95831-63, DOI 10.1007/978-3-319-95831-6_3, 10.1007/978-3-319-95831-6_3, DOI 10.1007/978-3-319-95831-63]
   Wall E, 2019, LECT NOTES COMPUT SC, V11747, P555, DOI 10.1007/978-3-030-29384-0_34
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Wesslen R, 2019, COMPUT GRAPH FORUM, V38, P161, DOI 10.1111/cgf.13679
   Wickham H, 2011, J COMPUT GRAPH STAT, V20, P281, DOI 10.1198/jcgs.2011.1de
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Zgraggen E, 2017, IEEE T VIS COMPUT GR, V23, P1977, DOI 10.1109/TVCG.2016.2607714
NR 52
TC 10
Z9 10
U1 4
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3093
EP 3112
DI 10.1109/TVCG.2021.3051013
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700003
PM 33434132
OA Bronze
DA 2024-11-06
ER

PT J
AU Deng, QX
   Ma, LM
   Jin, AB
   Bi, HK
   Le, BH
   Deng, ZG
AF Deng, Qixin
   Ma, Luming
   Jin, Aobo
   Bi, Huikun
   Le, Binh Huy
   Deng, Zhigang
TI Plausible 3D Face Wrinkle Generation Using Variational Autoencoders
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Three-dimensional displays; Solid modeling; Shape; Computational
   modeling; Pipelines; Data models; Face modeling; wrinkle synthesis; deep
   generative models; variational autoencoders
ID RECONSTRUCTION; MODEL; SKIN
AB Realistic 3D facial modeling and animation have been increasingly used in many graphics, animation, and virtual reality applications. However, generating realistic fine-scale wrinkles on 3D faces, in particular, on animated 3D faces, is still a challenging problem that is far away from being resolved. In this article we propose an end-to-end system to automatically augment coarse-scale 3D faces with synthesized fine-scale geometric wrinkles. By formulating the wrinkle generation problem as a supervised generation task, we implicitly model the continuous space of face wrinkles via a compact generative model, such that plausible face wrinkles can be generated through effective sampling and interpolation in the space. We also introduce a complete pipeline to transfer the synthesized wrinkles between faces with different shapes and topologies. Through many experiments, we demonstrate our method can robustly synthesize plausible fine-scale wrinkles on a variety of coarse-scale 3D faces with different shapes and expressions.
C1 [Deng, Qixin; Ma, Luming; Jin, Aobo; Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
   [Bi, Huikun] Chinese Acad Sci, Inst Comp Technol, Beijing 100864, Peoples R China.
   [Le, Binh Huy] Elect Arts Inc, SEED Lab, Search Extraordinary Experience Div, Ashburn, VA 20147 USA.
C3 University of Houston System; University of Houston; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS
RP Deng, ZG (corresponding author), Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
EM qxdeng1991@gmail.com; balokume@gmail.com; jinaobo1103@gmail.com;
   xiaobi361@gmail.com; bbinh85@gmail.com; zdeng4@uh.edu
RI Deng, Qixin/JEF-1654-2023; Aobo, Jin/ITT-6622-2023
OI Deng, Zhigang/0000-0002-0452-8676; Deng, Zhigang/0000-0003-2571-5865
FU US NSF [IIS-1524782, IIS-2005430]; National Natural Science Foundation
   of China [62002345]
FX This work was supported in part by US NSF IIS-1524782 and NSF
   IIS-2005430. Huikun Bi was supported in part by the National Natural
   Science Foundation of China under Grant 62002345.
CR [Anonymous], 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'09, DOI DOI 10.1145/1599470.1599472
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970
   Bickel B, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276419, 10.1145/1239451.1239484]
   Boissieux L, 2000, SPRING COMP SCI, P15
   Bradley D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778778
   Brock A, 2016, Arxiv, DOI [arXiv:1608.04236, 10.48550/arXiv.1608.04236]
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cutler LD, 2007, GRAPH MODELS, V69, P219, DOI 10.1016/j.gmod.2006.09.003
   Deng Zhigang., 2008, Data-driven 3D facial animation, P1
   Fyffe G, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2638549
   Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Garrido P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508380
   Gotardo P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275073
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Huang HD, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964969
   Huber Patrik, 2016, VISIGRAPP 2016. 11th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications. Proceedings: VISAPP 2016, P79
   Kim HJ, 2015, COMPUT GRAPH FORUM, V34, P179, DOI 10.1111/cgf.12551
   Lewis John P, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li Pengbo., 2014, Proceedings of the Seventh International Conference on Motion in Games, P171
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Ma LM, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317016
   Ma WC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409074
   Mo KC, 2019, Arxiv, DOI arXiv:1908.00575
   Nash C, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13240
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Saito S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275019
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Shi FH, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661290
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Suwajanakorn S, 2015, IEEE I CONF COMP VIS, P3952, DOI 10.1109/ICCV.2015.450
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Valgaerts L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366206
   Venkataraman K, 2005, COMPUT GRAPH-UK, V29, P756, DOI 10.1016/j.cag.2005.08.024
   Wang Y, 2006, COMPUT GRAPH-UK, V30, P111, DOI 10.1016/j.cag.2005.10.010
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang Y, 2006, J VISUAL LANG COMPUT, V17, P126, DOI 10.1016/j.jvlc.2005.10.002
   Zhang Y, 2004, IEEE T VIS COMPUT GR, V10, P339, DOI 10.1109/TVCG.2004.1272733
   Zhang Y, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P347, DOI 10.1109/CGI.2001.934696
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 55
TC 10
Z9 10
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3113
EP 3125
DI 10.1109/TVCG.2021.3051251
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700004
PM 33439847
OA Bronze
DA 2024-11-06
ER

PT J
AU Skanberg, R
   Falk, M
   Linares, M
   Ynnerman, A
   Hotz, I
AF Skanberg, Robin
   Falk, Martin
   Linares, Mathieu
   Ynnerman, Anders
   Hotz, Ingrid
TI Tracking Internal Frames of Reference for Consistent Molecular
   Distribution Functions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Distribution functions; Trajectory; Visualization; Graphical models;
   Numerical models; Shape; Periodic structures; Molecule visualization;
   molecular dynamics; interactive exploration
ID RELATE 2 SETS; VECTOR OBSERVATIONS; DYNAMICS; BINDING; ROTATION; MOLDEN
AB In molecular analysis, spatial distribution functions (SDF) are fundamental instruments in answering questions related to spatial occurrences and relations of atomic structures over time. Given a molecular trajectory, SDFs can, for example, reveal the occurrence of water in relation to particular structures and hence provide clues of hydrophobic and hydrophilic regions. For the computation of meaningful distribution functions, the definition of molecular reference structures is essential. Therefore we introduce the concept of an internal frame of reference (IFR) for labeled point sets that represent selected molecular structures, and we propose an algorithm for tracking the IFR over time and space using a variant of Kabsch's algorithm. This approach lets us generate a consistent space for the aggregation of the SDF for molecular trajectories and molecular ensembles. We demonstrate the usefulness of the technique by applying it to temporal molecular trajectories as well as ensemble datasets. The examples include different docking scenarios with DNA, insulin, and aspirin.
C1 [Skanberg, Robin; Falk, Martin; Linares, Mathieu; Ynnerman, Anders; Hotz, Ingrid] Linkoping Univ, Sci Visualizat Grp, S-58183 Linkoping, Sweden.
   [Skanberg, Robin; Falk, Martin; Linares, Mathieu; Ynnerman, Anders; Hotz, Ingrid] Swedish E Sci Res Ctr SeRC, S-11428 Stockholm, Sweden.
   [Linares, Mathieu] Linkoping Univ, Lab Organ Elect, S-58183 Linkoping, Sweden.
C3 Linkoping University; Linkoping University
RP Skanberg, R (corresponding author), Linkoping Univ, Sci Visualizat Grp, S-58183 Linkoping, Sweden.; Skanberg, R (corresponding author), Swedish E Sci Res Ctr SeRC, S-11428 Stockholm, Sweden.
EM robin.skanberg@liu.se; martin.falk@liu.se; mathieu.linares@liu.se;
   Anders.Ynnerman@liu.se; ingrid.hotz@liu.se
RI ; linares, mathieu/C-5791-2008
OI Ynnerman, Anders/0000-0002-9466-9826; linares,
   mathieu/0000-0002-9720-5429; Hotz, Ingrid/0000-0001-7285-0483; Falk,
   Martin/0000-0003-1511-5006
FU Excellence Center at Linkoping and Lund in Information Technology
   (ELLIIT); Swedish e-Science Research Centre (SeRC)
FX This work was supported through grants from the Excellence Center at
   Link_oping and Lund in Information Technology (ELLIIT) and the Swedish
   e-Science Research Centre (SeRC). The authors would like to thank the
   Swedish National Infrastructure for Computing (SNIC) for providing
   computing resources.
CR Abraham Mark James, 2015, SoftwareX, V1-2, P19, DOI 10.1016/j.softx.2015.06.001
   Alexander AL, 2000, MAGNET RESON MED, V44, P283, DOI 10.1002/1522-2594(200008)44:2<283::AID-MRM16>3.0.CO;2-V
   Brehm M, 2011, J CHEM INF MODEL, V51, P2007, DOI 10.1021/ci200217w
   Case D.A., 2010, AMBER 11
   Chevrot G, 2011, J CHEM PHYS, V135, DOI 10.1063/1.3626275
   Correa CarlosD., 2007, Sixth Eurographics / IEEE VGTC Workshop on Volume Graphics, P91
   Davenport P., 1968, VECTOR APPROACH ALGE
   FARRELL JL, 1966, SIAM REV, V8, P384, DOI 10.1137/1008080
   Hanwell MD, 2012, J CHEMINFORMATICS, V4, DOI 10.1186/1758-2946-4-17
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873
   KABSCH W, 1978, ACTA CRYSTALLOGR A, V34, P827, DOI 10.1107/S0567739478001680
   König C, 2018, CHEM COMMUN, V54, P3030, DOI 10.1039/c8cc00105g
   Li X, 2012, J CHEM THEORY COMPUT, V8, P4766, DOI 10.1021/ct300606q
   Linares M, 2019, PHYS CHEM CHEM PHYS, V21, P3637, DOI 10.1039/c8cp05326j
   Lindow N, 2019, IEEE T VIS COMPUT GR, V25, P967, DOI 10.1109/TVCG.2018.2864507
   MARKLEY FL, 1988, J ASTRONAUT SCI, V36, P245
   MARKLEY FL, 1993, J ASTRONAUT SCI, V41, P261
   Markley FL, 2000, J ASTRONAUT SCI, V48, P359
   Mortari D, 1997, J ASTRONAUT SCI, V45, P195
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Phillips JC, 2005, J COMPUT CHEM, V26, P1781, DOI 10.1002/jcc.20289
   PLIMPTON S, 1995, J COMPUT PHYS, V117, P1, DOI 10.1006/jcph.1995.1039
   Ponder J.W., 2004, TINKER SOFTWARE TOOL
   Schaftenaar G, 2000, J COMPUT AID MOL DES, V14, P123, DOI 10.1023/A:1008193805436
   Schaftenaar G, 2017, J COMPUT AID MOL DES, V31, P789, DOI 10.1007/s10822-017-0042-5
   Schmid N, 2011, EUR BIOPHYS J BIOPHY, V40, P843, DOI 10.1007/s00249-011-0700-9
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Shuster M.D., 1978, Guidance and Control Conference, page, P1249
   Singh RK, 2005, J DRUG TARGET, V13, P113, DOI 10.1080/10611860400024078
   Ska ~nberg R., 2019, PROC WORKSHOP MOL GR, P17
   Skanberg R., 2018, P EG WORKSH MOL GRAP, P19, DOI [10.2312/molva.20181102, DOI 10.2312/MOLVA.20181102]
   SVISHCHEV IM, 1993, J CHEM PHYS, V99, P3049, DOI 10.1063/1.465158
   Vad V., 2017, VCBM 17: Eurographics Workshop on Visual Computing forBiology and Medicine, DOI [10.2312/vcbm.20171235, DOI 10.2312/VCBM.2017123]
   Wahba G., 1965, SIAM review, V7, P409, DOI [10.1137/1008080, DOI 10.1137/1008080]
NR 35
TC 8
Z9 8
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3126
EP 3137
DI 10.1109/TVCG.2021.3051632
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700005
PM 33444141
OA Green Published
DA 2024-11-06
ER

PT J
AU Friston, S
   Griffith, E
   Swapp, D
   Julier, S
   Irondi, C
   Jjunju, F
   Ward, R
   Marshall, A
   Steed, A
AF Friston, Sebastian
   Griffith, Elias
   Swapp, David
   Julier, Simon
   Irondi, Caleb
   Jjunju, Fred
   Ward, Ryan
   Marshall, Alan
   Steed, Anthony
TI Consensus Based Networking of Distributed Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Synchronization; Collaboration; Servers; Kalman filters; Haptic
   interfaces; Task analysis; Solid modeling; C; 2; 4; b distributed
   applications; I; 6; 8; e distributed simulations; H; 5; 1; b artificial;
   augmented; and virtual realities
ID SCENE-GRAPH; INTERACTIVE APPLICATIONS; BILATERAL TELEOPERATION; LATENCY;
   CONSISTENCY; AGENTS
AB Distributed virtual environments (DVEs) are challenging to create as the goals of consistency and responsiveness become contradictory under increasing latency. DVEs have been considered as both distributed transactional databases and force-reflection systems. Both are good approaches, but they do have drawbacks. Transactional systems do not support Level 3 (L3) collaboration: manipulating the same degree-of-freedom at the same time. Force-reflection requires a client-server architecture and stabilisation techniques. With Consensus Based Networking (CBN), we suggest DVEs be considered as a distributed data-fusion problem. Many simulations run in parallel and exchange their states, with remote states integrated with continous authority. Over time the exchanges average out local differences, performing a distribued-average of a consistent, shared state. CBN aims to build simulations that are highly responsive, but consistent enough for use cases such as the piano-movers problem. CBN's support for heterogeneous nodes can transparently couple different input methods, avoid the requirement of determinism, and provide more options for personal control over the shared experience. Our work is early, however we demonstrate many successes, including L3 collaboration in room-scale VR, 1000's of interacting objects, complex configurations such as stacking, and transparent coupling of haptic devices. These have been shown before, but each with a different technique; CBN supports them all within a single, unified system.
C1 [Friston, Sebastian; Swapp, David; Julier, Simon; Steed, Anthony] UCL, Dept Comp Sci, London WC1E 6BT, England.
   [Griffith, Elias; Irondi, Caleb; Jjunju, Fred; Ward, Ryan; Marshall, Alan] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3BX, Merseyside, England.
C3 University of London; University College London; University of Liverpool
RP Friston, S (corresponding author), UCL, Dept Comp Sci, London WC1E 6BT, England.
EM sebastian.friston@cs.ucl.ac.uk; e.griffith@liverpool.ac.uk;
   d.swapp@cs.ucl.ac.uk; sjulier@cs.ucl.ac.uk;
   caleb.irondi@liverpool.ac.uk; fjjunju@liverpool.ac.uk;
   Ryan.Ward@liverpool.ac.uk; Alan.Marshall@liverpool.ac.uk;
   a.steed@cs.ucl.ac.uk
RI Ward, Ryan/AAX-9762-2021; Ward, Ryan/ACC-9367-2022
OI Swapp, David/0000-0002-9335-8663; Steed, Anthony/0000-0001-9034-3020;
   Ward, Ryan/0000-0002-9850-5191; Jjunju, Fred Paul
   Mark/0000-0001-6257-434X; Marshall, Alan/0000-0002-8058-5242; Friston,
   Sebastian/0000-0002-0061-8519; Griffith, Elias/0000-0001-9360-381X
FU EPSRC [EP/P004040/1, EP/P004016/1]; EPSRC [EP/P004016/1, EP/P004040/1,
   EP/S028854/1] Funding Source: UKRI
FX The authors would like to thank FSMLabs, NDFIS and JISC. This work was
   supported by EPSRC under Grants EP/P004040/1 and EP/P004016/1.
CR Allard J, 2004, LECT NOTES COMPUT SC, V3149, P497
   Allison R.S., 2004, P 2004 ACM SIGGRAPH, P375
   Anthes C., 2006, Advances in Multimedia Modeling. 13th International Multimedia Modeling Conference, MMM 2007. Proceedings (Lecture Notes in Computer Science Vol.4351), P722
   Arioui H, 2002, IEEE ROMAN 2002, PROCEEDINGS, P134, DOI 10.1109/ROMAN.2002.1045611
   Berestesky P, 2004, IEEE INT CONF ROBOT, P4557, DOI 10.1109/ROBOT.2004.1302436
   Bernier Y.W., 2001, Latency Compensating Methods in Client/Server in-Game Protocol Design and Optimization
   Boukerche A, 2007, INT J COMPUT APPL T, V29, P81, DOI 10.1504/IJCAT.2007.014063
   Brandi F, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC AUDIO-VISUAL ENVIRONMENTS AND GAMES (HAVE 2013), P63, DOI 10.1109/HAVE.2013.6679612
   Broll W., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P148, DOI 10.1109/VRAIS.1995.512490
   Buttolo P, 1997, COMPUT GRAPH-UK, V21, P421, DOI 10.1016/S0097-8493(97)00019-8
   Chardavoine F, 2005, PRESENCE-TELEOP VIRT, V14, P20, DOI 10.1162/1054746053890297
   Chatterjee A, 2013, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2013.70
   Cheong J, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P277
   Chitimalla D, 2017, J OPT COMMUN NETW, V9, P172, DOI 10.1364/JOCN.9.000172
   Choukair Z, 2000, SEVENTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P111, DOI 10.1109/ICPADS.2000.857689
   Coelho EM, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P6, DOI 10.1109/ISMAR.2004.44
   Cronin E, 2004, MULTIMED TOOLS APPL, V23, P7, DOI 10.1023/B:MTAP.0000026839.31028.9f
   Delaney D, 2006, PRESENCE-TELEOP VIRT, V15, P465, DOI 10.1162/pres.15.4.465
   Dellaney D, 2006, PRESENCE-VIRTUAL AUG, V15, P218, DOI 10.1162/pres.2006.15.2.218
   Drolet F, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P271, DOI 10.1109/VR.2009.4811050
   Exit Games, PUN INTR
   Fiedler G, 2018, ABOUT US
   Fujimoto RM, 2001, WSC'01: PROCEEDINGS OF THE 2001 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P147, DOI 10.1109/WSC.2001.977259
   Garin F, 2010, LECT NOTES CONTR INF, V406, P75
   Ghapani S, 2019, IEEE T AUTOMAT CONTR, V64, P1178, DOI 10.1109/TAC.2018.2840452
   Greenhalgh C., 1995, ACM Trans. Comput.-Human Interact., V2, P239, DOI DOI 10.1145/210079.210088
   Grimstead IJ, 2005, IEEE ACM DIS SIM, P61, DOI 10.1109/DISTRA.2005.12
   Gunn C, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P481
   Gunn C, 2005, PRESENCE-TELEOP VIRT, V14, P313, DOI 10.1162/105474605323384663
   Gutwin Carl., 2003, Proceedings of the 2003 International ACM SIGGROUP Conference on Supporting Group Work, P294
   Hanawa D., 2005, MODEL OPTIM, V7, P85
   Hanawa D, 2006, 2006 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P107, DOI 10.1109/CW.2006.10
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Hatanaka T, 2015, COMMUN CONTROL ENG, P1, DOI 10.1007/978-3-319-15171-7
   Hesina Gerd, 1999, P ACM S VIRT REAL SO, P74, DOI [10.1145/323663.323675, DOI 10.1145/323663.323675]
   Hinterseer P., 2006, PROC IEEE INTCONF AC, V5, pV, DOI DOI 10.1109/ICASSP.2006.1661315
   Hokayem PF, 2006, AUTOMATICA, V42, P2035, DOI 10.1016/j.automatica.2006.06.027
   Hoskinson R., 2017, DETERMINISM NI LEAGU
   Jorissen P, 2005, IEEE T VIS COMPUT GR, V11, P649, DOI 10.1109/TVCG.2005.100
   Jung J.Y., 2000, Proc. Hum. Factors Ergon. Soc. Annu. Meet., V44, P499, DOI [10.1177/154193120004400504, DOI 10.1177/154193120004400504]
   Lake D, 2010, ANN WORK NETW
   Lambeth B. M., 2009, PROC 47 ANN SE REGIO, P1
   Latoschik Marc Erich, 2006, The International Journal of Virtual Reality, V5, P47
   LAWRENCE DA, 1993, IEEE T ROBOTIC AUTOM, V9, P624, DOI 10.1109/70.258054
   Lozano R., 2002, P 8 MECHATRONICS FOR, P954
   Lysenko M., 2014, REPLICATION NETWORKE
   MacIntyre B., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P361, DOI 10.1145/280814.280935
   Margellos K, 2018, IEEE T AUTOMAT CONTR, V63, P1372, DOI 10.1109/TAC.2017.2747505
   Margery D., 1999, Virtual Environments '99 Proceedings of the Eurographics Workshop. Eurographics, P169
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Naef M, 2003, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2003.1191157
   NIEMEYER G, 1991, IEEE J OCEANIC ENG, V16, P152, DOI 10.1109/48.64895
   Niemeyer G, 2004, INT J ROBOT RES, V23, P873, DOI 10.1177/0278364904045563
   NTT, 2019, IP NETW SERV LEV AGR
   Nuño E, 2011, IEEE T AUTOMAT CONTR, V56, P935, DOI 10.1109/TAC.2010.2103415
   Olfati-Saber R, 2004, IEEE T AUTOMAT CONTR, V49, P1520, DOI 10.1109/TAC.2004.834113
   Olfati-Saber R, 2007, P IEEE, V95, P215, DOI 10.1109/JPROC.2006.887293
   Pantel Lothar., 2002, NETGAMES 02 P 1 WORK, P79
   Park KS, 1999, P IEEE VIRT REAL ANN, P104, DOI 10.1109/VR.1999.756940
   Pusch R., 2019, EXPLAINING FIGHTING
   Qin J, 2013, PRESENCE-TELEOP VIRT, V22, P36, DOI 10.1162/PRES_a_00132
   Roberts D, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P46, DOI 10.1109/DS-RT.2004.13
   Roberts DJ, 1997, IEEE SYS MAN CYBERN, P4492, DOI 10.1109/ICSMC.1997.637574
   Rodríguez-Seda EJ, 2009, IEEE T ROBOT, V25, P1304, DOI 10.1109/TRO.2009.2032964
   Roth M, 2004, COMPUT GRAPH-UK, V28, P63, DOI 10.1016/j.cag.2003.10.004
   Ruddle R. A., 2002, ACM Transactions on Computer-Human Interaction, V9, P285, DOI 10.1145/586081.586084
   Ryan M. D., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P75, DOI 10.1109/ICSMC.1999.816458
   Ryan M. D., 1998, Virtual Worlds. First International Conference, VW'98. Proceedings, P42
   Ryan MD, 1997, IEEE SYS MAN CYBERN, P1067, DOI 10.1109/ICSMC.1997.638090
   Sandoz P., 1996, VR WORLD, V96
   Sankaranarayanan G., 2006, 1 IEEERAS EMBS INT C, P853
   Sarlette Alain., 2007, Decision and Control, 2007 46th IEEE Conference on, P2566
   Savery C., 2014, P 1 ACM SIGCHI ANN S, P237
   Schiefer A., 2010, P WEB3D S, P55
   Schuwerk C, 2014, IEEE HAPTICS SYM, P371, DOI 10.1109/HAPTICS.2014.6775484
   Sharkey PM, 1998, P IEEE VIRT REAL ANN, P242, DOI 10.1109/VRAIS.1998.658502
   SINGHAL SK, 1995, PRESENCE-TELEOP VIRT, V4, P169, DOI 10.1162/pres.1995.4.2.169
   Steed A., 2010, NETWORKED GRAPHICS
   Sweeney T., 2019, ACM SIGGRAPH 2019 TA, P1
   Tavakoli M, 2006, SURG ENDOSC, V20, P1570, DOI 10.1007/s00464-005-0582-y
   Terrano M., 2001, 1500 ARCHERS 288 NET
   Tumanov A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P123
   Valadares A., 2012, 2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012), P142, DOI 10.1109/HAVE.2012.6374453
   Verizon, 2019, IP LAT STAT
   Voss G., 2002, Fourth Eurographics Workshop on Parallel Graphics and Visualization, P33
   Wang GP, 2009, SCI CHINA SER F, V52, P457, DOI 10.1007/s11432-009-0071-3
   Watt ST, 2015, 2015 SAUDI ARABIA SMART GRID CONFERENCE (SASG)
   Wolff R, 2004, PRESENCE-TELEOP VIRT, V13, P251, DOI 10.1162/1054746041422280
   Xiao L, 2007, J PARALLEL DISTR COM, V67, P33, DOI 10.1016/j.jpdc.2006.08.010
   Zaeh MF, 2006, INFORMATION VISUALIZATION-BOOK, P597
   Zeleznik B, 2000, COMPUT GRAPH FORUM, V19, pC91, DOI 10.1111/1467-8659.00401
   Zhang Y, 2010, IEEE T AUTOMAT CONTR, V55, P939, DOI 10.1109/TAC.2010.2041612
NR 92
TC 0
Z9 0
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3138
EP 3153
DI 10.1109/TVCG.2021.3052580
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700006
PM 33465027
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wu, J
   Wang, LL
   Zhang, H
   Popescu, V
AF Wu, Jian
   Wang, Lili
   Zhang, Hui
   Popescu, Voicu
TI Quantifiable Fine-Grain Occlusion Removal Assistance for Efficient VR
   Exploration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Legged locomotion; Geometry; Teleportation; Cameras;
   Navigation; Virtual environments; VR exploration; fine grain
   disocclusion; multiperspective visualization; graph camera; occlusion
   quantification
ID REAL
AB This article presents an occlusion management approach that handles fine-grain occlusions, and that quantifies and localizes occlusions as a user explores a virtual environment (VE). Fine-grain occlusions are handled by finding the VE region where they occur, and by constructing a multiperspective visualization that lets the user explore the region from the current location, with intuitive head motions, without first having to walk to the region. VE geometry close to the user is rendered conventionally, from the user's viewpoint, to anchor the user, avoiding disorientation and simulator sickness. Given a viewpoint, residual occlusions are quantified and localized as VE voxels that cannot be seen from the given viewpoint but that can be seen from nearby viewpoints. This residual occlusion quantification and localization helps the user ascertain that a VE region has been explored exhaustively. The occlusion management approach was tested in three controlled studies, which confirmed the exploration efficiency benefit of the approach, and in perceptual experiments, which confirmed that exploration efficiency does not come at the cost of reducing spatial awareness and sense of presence, or of increasing simulator sickness.
C1 [Wu, Jian; Wang, Lili; Zhang, Hui] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 518000, Peoples R China.
   [Wu, Jian; Wang, Lili; Zhang, Hui] Peng Cheng Lab, Shenzhen 518000, Guangdong, Peoples R China.
   [Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Beihang University; Peng Cheng Laboratory; Purdue University System;
   Purdue University
RP Wang, LL (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 518000, Peoples R China.
EM lanayawj@buaa.edu.cn; wanglily@buaa.edu.cn; popescu@purdue.edu
RI wang, lili/HJP-8047-2023
FU National Natural Science Foundation of China [61932003, 61772051];
   National Key RD plan [2019YFC1521102]; Beijing Natural Science
   Foundation [L182016]; Beijing Program for International S&T Cooperation
   Project [Z191100001619003]; Shenzhen Research Institute of Big Data
   under Grant Shenzhen
FX The authors would like to thank Meng-Lin Wu for his inspiring work on
   occlusion removal for HMD visualization for VR and AR. This work was
   supported in part by the National Natural Science Foundation of China
   through Projects 61932003 and 61772051, by National Key R&D plan
   2019YFC1521102, by the Beijing Natural Science Foundation L182016, by
   the Beijing Program for International S&T Cooperation Project
   Z191100001619003, by the funding of Shenzhen Research Institute of Big
   Data under Grant Shenzhen 518000.
CR [Anonymous], 1908, BIOMETRIKA, V6, P1
   [Anonymous], 2011, PROC INT C ARTIF REA
   [Anonymous], 1988, Statistical Power Analysis for the Behavioral Sciences
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1077, DOI 10.1109/TVCG.2006.140
   Cirio G, 2012, IEEE T VIS COMPUT GR, V18, P546, DOI 10.1109/TVCG.2012.60
   Coffin C, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P25, DOI 10.1109/TRIDUI.2006.1618266
   Cui JA, 2010, IEEE T VIS COMPUT GR, V16, P1235, DOI 10.1109/TVCG.2010.127
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   El Makssoud H, 2009, IEEE ENG MED BIO, P2384, DOI 10.1109/IEMBS.2009.5334973
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Fung J, 2006, CYBERPSYCHOL BEHAV, V9, P157, DOI 10.1089/cpb.2006.9.157
   Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446
   Guy Emilie, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2015.7131725
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lorenz H, 2009, LECT NOTES GEOINF CA, P301
   MacQuarrie A, 2018, IEEE T VIS COMPUT GR, V24, P1564, DOI 10.1109/TVCG.2018.2793561
   Mei CH, 2005, COMPUT GRAPH FORUM, V24, P335, DOI 10.1111/j.1467-8659.2005.00858.x
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Nakatani R, 2012, J ADV COMPUT INTELL, V16, P696, DOI 10.20965/jaciii.2012.p0696
   Pasewaldt S., 2011, 19 INT C CENTRAL EUR, P111
   Popescu V, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618504
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Sandor C, 2010, P IEEE VIRT REAL ANN, P47, DOI 10.1109/VR.2010.5444815
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert Thomas W., 2003, Zeitschrift fur Medienpsychologie, V15, P69
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Teshima T, 2006, INT C PATT RECOG, P626
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Wang LL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P708, DOI [10.1109/VR.2019.8798025, 10.1109/vr.2019.8798025]
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   Wu ML, 2018, LECT NOTES COMPUT SC, V11162, P240, DOI 10.1007/978-3-030-01790-3_15
   Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14
   Zimmerman DW, 1997, J EDUC BEHAV STAT, V22, P349, DOI 10.2307/1165289
NR 39
TC 2
Z9 2
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3154
EP 3167
DI 10.1109/TVCG.2021.3053287
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700007
PM 33476271
DA 2024-11-06
ER

PT J
AU Liu, SS
   He, XW
   Wang, WC
   Wu, EH
AF Liu, Shusen
   He, Xiaowei
   Wang, Wencheng
   Wu, Enhua
TI Adapted SIMPLE Algorithm for Incompressible SPH Fluids With a Broad
   Range Viscosity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Viscosity; Mathematical model; Couplings; Interference; Computational
   modeling; Software; Force; Smoothed particle hydrodynamics (SPH); SIMPLE
   algorithm; fluid simulation; incompressibility; viscosity
ID FORMULATION; FLOWS; SOLVER
AB In simulating viscous incompressible SPH fluids, incompressibility and viscosity are typically solved in two separate stages. However, the interference between pressure and shear forces could cause the missing of behaviors that include preservation of sharp surface details and remarkable viscous behaviors such as buckling and rope coiling. To alleviate this problem, we introduce for the first time the semi-implicit method for pressure linked equations (SIMPLE) into SPH to solve incompressible fluids with a broad range viscosity. We propose to link incompressibility and viscosity solvers, and impose incompressibility and viscosity constraints iteratively to gradually remove the interference between pressure and shear forces. We will also discuss how to solve the particle deficiency problem for both incompressibility and viscosity solvers. Our method is stable at simulating incompressible fluids whose viscosity can range from zero to an extremely high value. Compared to state-of-the-art methods, our method not only produces realistic viscous behaviors, but is also better at preserving sharp surface details.
C1 [Liu, Shusen; Wang, Wencheng; Wu, Enhua] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100864, Peoples R China.
   [Liu, Shusen; Wang, Wencheng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [He, Xiaowei] Chinese Acad Sci, Inst Software, Key Lab Human Comp Interact, Beijing 100864, Peoples R China.
   [Wu, Enhua] Univ Macau, Taipa 999078, Macau, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Chinese
   Academy of Sciences; Institute of Software, CAS; University of Macau
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100864, Peoples R China.; He, XW (corresponding author), Chinese Acad Sci, Inst Software, Key Lab Human Comp Interact, Beijing 100864, Peoples R China.
EM liuss@ios.ac.cn; xiaowei@iscas.ac.cn; whn@ios.ac.cn; ehwu@umac.mo
RI Wang, Wencheng/A-3828-2009
OI wang, wen cheng/0000-0001-5094-4606; he, xiao wei/0000-0002-8870-2482;
   Liu, Shusen/0000-0002-7416-5110; wu, en hua/0000-0002-2174-1428
FU National Key R&D Program of China [2017YFB1002701]; National Natural
   Science Foundation of China [62072446, 61872345, 61672502, 62072449,
   61632003]; Youth Innovation Promotion Association, CAS [2019109];
   Strategic Priority Research Program, CAS [19080102]; University of Macau
   [MYRG2019-00006-FST]
FX The authors would like to thank anonymous reviewers for their valuable
   comments. The work was supported by the National Key R&D Program of
   China under Grant 2017YFB1002701, the National Natural Science
   Foundation of China under Grants 62072446, 61872345, 61672502, 62072449,
   61632003, the Youth Innovation Promotion Association, CAS under Grant
   2019109, the Strategic Priority Research Program, CAS under Grant
   19080102, and the University of Macau under Grant MYRG2019-00006-FST.
CR Aanjaneya M, 2013, J COMPUT PHYS, V247, P17, DOI 10.1016/j.jcp.2013.03.048
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Batty C, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239551, 10.1145/1276377.1276502]
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J., 2015, ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P147
   Bhatacharya H., 2011, Symp. Comp. Anim, P17
   Bodin K, 2012, IEEE T VIS COMPUT GR, V18, P516, DOI 10.1109/TVCG.2011.29
   Cornelis J, 2019, VISUAL COMPUT, V35, P579, DOI 10.1007/s00371-018-1488-8
   CROSS MM, 1965, J COLL SCI IMP U TOK, V20, P417, DOI 10.1016/0095-8522(65)90022-X
   CRUICKSHANK JO, 1981, J FLUID MECH, V113, P221, DOI 10.1017/S0022112081003467
   Cummins SJ, 1999, J COMPUT PHYS, V152, P584, DOI 10.1006/jcph.1999.6246
   F_urstenau J.-P., 2017, P 12 INT SPHER WORKS, P1
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Gotoh H., 2016, J OCEAN ENG MAR ENER, V2, P251, DOI DOI 10.1007/S40722-016-0049-3
   Habibi M, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.066306
   He XW, 2020, Arxiv, DOI arXiv:2001.09421
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   He XW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366168
   He XW, 2012, COMPUT GRAPH FORUM, V31, P1948, DOI 10.1111/j.1467-8659.2012.03074.x
   Ihmsen M., 2014, EUROGRAPHICS STATE A
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Jones B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2560795
   Khayyer A, 2011, J COMPUT PHYS, V230, P3093, DOI 10.1016/j.jcp.2011.01.009
   Koschier Dan, 2019, Eurographics 2019 Tutorials
   Larionov E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073628
   Liu MB, 2010, ARCH COMPUT METHOD E, V17, P25, DOI 10.1007/s11831-010-9040-7
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Monaghan JJ, 2005, REP PROG PHYS, V68, P1703, DOI 10.1088/0034-4885/68/8/R01
   MONAGHAN JJ, 1989, J COMPUT PHYS, V82, P1, DOI 10.1016/0021-9991(89)90032-6
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Morris JP, 1997, J COMPUT PHYS, V136, P214, DOI 10.1006/jcph.1997.5776
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Nair P, 2014, COMPUT FLUIDS, V102, P304, DOI 10.1016/j.compfluid.2014.07.006
   Patankar S., 2018, Numerical Heat Transfer and Fluid Flow
   Peer A, 2017, IEEE T VIS COMPUT GR, V23, P2656, DOI 10.1109/TVCG.2016.2636144
   Peer A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766925
   Robinson-Mosher A, 2011, J COMPUT PHYS, V230, P1547, DOI 10.1016/j.jcp.2010.11.021
   Robinson-Mosher A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360645
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shao SD, 2003, ADV WATER RESOUR, V26, P787, DOI 10.1016/S0309-1708(03)00030-7
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B., 2008, P 2008 ACM SIGGRAPH, P211
   Takahashi T, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13292
   Takahashi T, 2015, COMPUT GRAPH FORUM, V34, P493, DOI 10.1111/cgf.12578
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Winchenbach R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073713
   Yang S., 2016, S COMP ANIM, P29
NR 49
TC 5
Z9 5
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3168
EP 3179
DI 10.1109/TVCG.2021.3055789
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700008
PM 33523813
DA 2024-11-06
ER

PT J
AU Wu, K
   Tarini, M
   Yuksel, C
   McCann, J
   Gao, XF
AF Wu, Kui
   Tarini, Marco
   Yuksel, Cem
   McCann, James
   Gao, Xifeng
TI Wearable 3D Machine Knitting: Automatic Generation of Shaped Knit Sheets
   to Cover Real-World Objects
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Clothing; Pipelines; Solid modeling; Surface
   treatment; Fabrication; Yarn; Knitting; fabrication; stitch meshes
ID OPTIMIZATION; GEOMETRY; DESIGN
AB Knitting can efficiently fabricate stretchable and durable soft surfaces. These surfaces are often designed to be worn on solid objects as covers, garments, and accessories. Given a 3D model, we consider a knit for it wearable if the knit not only reproduces the shape of the 3D model but also can be put on and taken off from the model without deforming the model. This "wearability" places additional constraints on surface design and fabrication, which existing machine knitting approaches do not take into account. We introduce the first practical automatic pipeline to generate knit designs that are both wearable and machine knittable. Our pipeline handles knittability and wearability with two separate modules that run in parallel. Specifically, given a 3D object and its corresponding 3D garment surface, our approach first converts the garment surface into a topological disc by introducing a set of cuts. The resulting cut surface is then fed into a physically-based unclothing simulation module to ensure the garment's wearability over the object. The unclothing simulation determines which of the previously introduced cuts could be sewn permanently without impacting wearability. Concurrently, the cut surface is converted into an anisotropic stitch mesh. Then, our novel, stochastic, any-time flat-knitting scheduler generates fabrication instructions for an industrial knitting machine. Finally, we fabricate the garment and manually assemble it into one complete covering worn by the target object. We demonstrate our method's robustness and knitting efficiency by fabricating models with various topological and geometric complexities. Further, we show that our method can be incorporated into a knitting design tool for creating knitted garments with customized patterns.
C1 [Wu, Kui] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Tarini, Marco] Univ Milan, I-20122 Milan, Italy.
   [Yuksel, Cem] Univ Utah, Salt Lake City, UT 84112 USA.
   [McCann, James] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Gao, Xifeng] Florida State Univ, Tallahassee, FL 32306 USA.
C3 Massachusetts Institute of Technology (MIT); University of Milan; Utah
   System of Higher Education; University of Utah; Carnegie Mellon
   University; State University System of Florida; Florida State University
RP Gao, XF (corresponding author), Florida State Univ, Tallahassee, FL 32306 USA.
EM walker.kui.wu@gmail.com; marco.tarini@isti.cnr.it; cem@cemyuksel.com;
   jmccann@cs.cmu.edu; gxf.xisha@gmail.com
RI McCann, James/JBS-2149-2023; Tarini, Marco/H-1562-2012
OI Gao, Xifeng/0000-0003-0829-7075; Yuksel, Cem/0000-0002-0122-4159
FU University of Utah Graduate Research Fellowship [NSF-IIS-1910486]
FX The authors would like to thank Professor Wojciech Matusik for offering
   all the resources needed and giving his full support for Kui Wu in this
   article. They also thank Zhiyuan Zhang and Ella Moore for 3D printing
   and Alexandre Kaspar for the insightful discussions. This work was
   supported in part by NSF-IIS-1910486. Kui Wu was supported in part by
   the University of Utah Graduate Research Fellowship.
CR Albaugh L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300414, 10.1145/3290607.3311767]
   Bartle A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925896
   Belcastro SM, 2009, J MATH ARTS, V3, P67, DOI 10.1080/17513470902896561
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   Campen M, 2014, COMPUT GRAPH FORUM, V33, P69, DOI 10.1111/cgf.12401
   Clegg A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275048
   Eppstein D, 2008, COMPUT GRAPH FORUM, V27, P1477, DOI 10.1111/j.1467-8659.2008.01288.x
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gao XF, 2016, IEEE T VIS COMPUT GR, V22, P1899, DOI 10.1109/TVCG.2015.2473835
   Garg A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601106
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hofmann M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P5, DOI 10.1145/3332165.3347886
   Igarashi Y, 2009, COMPUT GRAPH FORUM, V28, P1965, DOI 10.1111/j.1467-8659.2009.01575.x
   Igarashi Y, 2008, COMPUT GRAPH FORUM, V27, P1737, DOI 10.1111/j.1467-8659.2008.01318.x
   Igarashi Yuki., 2008, EUROGRAPHICS SHORT P, P17
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Kaldor JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360664
   Kaspar A, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P53, DOI 10.1145/3332165.3347879
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275042
   Lin J, 2018, ACM SYMPOSIUM ON COMPUTATIONAL FABRICATION (SCF 2018), DOI 10.1145/3213512.3213515
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   Mahdavi-Amiri Ali., 2015, P 41 GRAPHICS INTERF, P73, DOI DOI 10.20380/GI2015.10
   Malomo L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982397
   McCann J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925940
   McCann James, 2017, The "Knitout"(.k) File Format
   Meissner M, 1998, COMPUT GRAPH FORUM, V17, pC355, DOI 10.1111/1467-8659.00282
   Mori Y, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239496
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Narayanan V, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322995
   Narayanan V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3186265
   Pérez J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073695
   Pietroni N, 2016, COMPUT GRAPH FORUM, V35, P485, DOI 10.1111/cgf.13045
   Popescu M., 2018, Automated Generation of Knit Patterns for Non-developable Surfaces, P271, DOI DOI 10.1007/978-981-10-6611-524
   Poranne R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130845
   Poranne R, 2013, COMPUT GRAPH FORUM, V32, P152, DOI 10.1111/cgf.12005
   Pottmann H, 2007, LECT NOTES COMPUT SC, V4647, P341
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Ray N, 2006, ACM T GRAPHIC, V25, P1460, DOI 10.1145/1183287.1183297
   Schertler N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201389
   Schüller C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201347
   Sharp N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201356
   Shen HX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323012
   Shima Seiki, 2011, SDS ONE APEX3 DESIGN
   Skouras M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601166
   Smith J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766947
   Soft Byte Ltd, 1999, DES
   Stoll, 2011, M1PLUS PATT SOFTW
   Tarini M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024176
   Tutte W.T., 1963, Proc. Lond. Math. Soc, Vs3-13, P743, DOI DOI 10.1112/PLMS/S3-13.1.743
   Umetani N, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964985
   Underwood Jenny, 2009, DESIGN 3D SHAPE KNIT
   Usai F, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2809785
   Wang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2503177
   Wang HM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964966
   Wu J, 2021, IEEE T VIS COMPUT GR, V27, P43, DOI 10.1109/TVCG.2019.2938946
   Wu K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292481
   Wu K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201360
   Yuksel C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185533
   Zhang XT, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322988
NR 63
TC 10
Z9 11
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3180
EP 3192
DI 10.1109/TVCG.2021.3056101
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700009
PM 33539299
OA Bronze, Green Published
DA 2024-11-06
ER

PT J
AU Porssut, T
   Hou, YW
   Blanke, O
   Herbelin, B
   Boulic, R
AF Porssut, Thibault
   Hou, Yawen
   Blanke, Olaf
   Herbelin, Bruno
   Boulic, Ronan
TI Adapting Virtual Embodiment Through Reinforcement Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Distortion; Avatars; Reinforcement learning; Task analysis; Haptic
   interfaces; Visualization; Training; Virtual reality; embodiment;
   machine learning; reinforcement learning; motion capture; movement
   distortion
ID PSYCHOPHYSICAL PROCEDURES; PSYCHOMETRIC PROCEDURES; REALITY; STROKE;
   REHABILITATION; THRESHOLD; STAIRCASE; FEEDBACK; ERROR; HAND
AB In Virtual Reality, having a virtual body opens a wide range of possibilities as the participant's avatar can appear to be quite different from oneself for the sake of the targeted application (e.g., for perspective-taking). In addition, the system can partially manipulate the displayed avatar movement through some distortion to make the overall experience more enjoyable and effective (e.g., training, exercising, rehabilitation). Despite its potential, an excessive distortion may become noticeable and break the feeling of being embodied into the avatar. Past researches have shown that individuals have a relatively high tolerance to movement distortions and a great variability of individual sensitivities to distortions. In this article, we propose a method taking advantage of Reinforcement Learning (RL) to efficiently identify the magnitude of the maximum distortion that does not get noticed by an individual (further noted the detection threshold). We show through a controlled experiment with subjects that the RL method finds a more robust detection threshold compared to the adaptive staircase method, i.e., it is more able to prevent subjects from detecting the distortion when its amplitude is equal or below the threshold. Finally, the associated majority voting system makes the RL method able to handle more noise within the forced choices input than adaptive staircase. This last feature is essential for future use with physiological signals as these latter are even more susceptible to noise. It would then allow to calibrate embodiment individually to increase the effectiveness of the proposed interactions.
C1 [Porssut, Thibault; Hou, Yawen; Boulic, Ronan] Ecole Polytech Fed Lausanne EPFL, Immers Interact Res Grp, CH-1015 Lausanne, Switzerland.
   [Blanke, Olaf; Herbelin, Bruno] Ecole Polytech Fed Lausanne EPFL, Brain Mind Inst, Lab Cognit Neurosci, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Swiss Federal Institutes of Technology Domain;
   Ecole Polytechnique Federale de Lausanne
RP Porssut, T (corresponding author), Ecole Polytech Fed Lausanne EPFL, Immers Interact Res Grp, CH-1015 Lausanne, Switzerland.
EM thibault.porssut@epfl.ch; yawen.hou@epfl.ch; olaf.blanke@epfl.ch;
   bruno.herbelin@epfl.ch; ronan.boulic@epfl.ch
OI Porssut, Thibault/0000-0002-6691-1427
FU SNFS project 'Immersive Embodied Interactions' [200020_178790]; Swiss
   National Science Foundation (SNF) [200020_178790] Funding Source: Swiss
   National Science Foundation (SNF)
FX The authors would like to thank Ms. Francesca Gieruc and M. Mathias
   Delahaye for their invaluable contributions. This work was supported by
   the SNFS project 'Immersive Embodied Interactions' under Grant
   200020_178790.
CR Adamovich SV, 2009, NEUROREHABILITATION, V25, P29, DOI 10.3233/NRE-2009-0497
   Altintas E, 2019, PSYCHIAT RES, V273, P487, DOI 10.1016/j.psychres.2019.01.030
   Amitay S, 2006, J ACOUST SOC AM, V119, P1616, DOI 10.1121/1.2164988
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Brand T, 2002, J ACOUST SOC AM, V111, P2801, DOI 10.1121/1.1479152
   Bréchet L, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0197763
   Brewer BR, 2008, BRAIN RES BULL, V75, P804, DOI 10.1016/j.brainresbull.2008.01.006
   Burns E, 2006, PRESENCE-TELEOP VIRT, V15, P1, DOI 10.1162/pres.2006.15.1.1
   Burns E., 2007, Int. J. Vet. Res., V6, P11
   Chavarriaga R, 2010, IEEE ENG MED BIO, P4226, DOI 10.1109/IEMBS.2010.5627376
   Cameirao MDS, 2011, RESTOR NEUROL NEUROS, V29, P287, DOI 10.3233/RNN-2011-0599
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P341, DOI 10.1109/VR.2018.8448285
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Emken JL, 2005, IEEE T NEUR SYS REH, V13, P33, DOI 10.1109/TNSRE.2004.843173
   Esmaeili S., DETECTION SCALED HAN
   Fasola J, 2019, IEEE ENG MED BIO, P1529, DOI [10.1109/embc.2019.8857523, 10.1109/EMBC.2019.8857523]
   Grüsser SM, 2007, CYBERPSYCHOL BEHAV, V10, P290, DOI 10.1089/cpb.2006.9956
   HALL JL, 1983, J ACOUST SOC AM, V73, P663, DOI 10.1121/1.388958
   Henderson A, 2007, TOP STROKE REHABIL, V14, P52, DOI 10.1310/tsr1402-52
   Iturrate I, 2010, IEEE INT CONF ROBOT, P4822, DOI 10.1109/ROBOT.2010.5509734
   Iturrate I., 2013, P 2 WORKSH MACH LEA, P45
   Jones PR, 2015, J VISION, V15, DOI 10.1167/15.11.2
   Kannape OA, 2010, NEUROPSYCHOLOGIA, V48, P1628, DOI 10.1016/j.neuropsychologia.2010.02.005
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim SK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17682-7
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   KOLLMEIER B, 1988, J ACOUST SOC AM, V83, P1852, DOI 10.1121/1.396521
   Leek MR, 2001, PERCEPT PSYCHOPHYS, V63, P1279, DOI 10.3758/BF03194543
   Luo TJ, 2018, IEEE INT C BIOINFORM, P697, DOI 10.1109/BIBM.2018.8621183
   MADIGAN R, 1987, PERCEPT PSYCHOPHYS, V42, P240, DOI 10.3758/BF03203075
   Marvit P, 2003, J ACOUST SOC AM, V113, P3348, DOI 10.1121/1.1570445
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   MEESE TS, 1995, PERCEPT PSYCHOPHYS, V57, P267, DOI 10.3758/BF03213053
   Molla E, 2018, IEEE T VIS COMPUT GR, V24, P2089, DOI 10.1109/TVCG.2017.2708083
   NIELSEN TI, 1963, SCAND J PSYCHOL, V4, P225, DOI 10.1111/j.1467-9450.1963.tb01326.x
   O'Brien K, 2017, GAIT POSTURE, V54, P178, DOI 10.1016/j.gaitpost.2017.03.003
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Patton JL, 2006, EXP BRAIN RES, V168, P368, DOI 10.1007/s00221-005-0097-8
   Patton JL, 2004, IEEE T BIO-MED ENG, V51, P636, DOI 10.1109/TBME.2003.821035
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/VR.2019.8797716, 10.1109/vr.2019.8797716]
   Pozeg P, 2017, NEUROLOGY, V89, P1894, DOI 10.1212/WNL.0000000000004585
   Remus JJ, 2008, J ACOUST SOC AM, V123, P315, DOI 10.1121/1.2816567
   Salazar-Gomez Andres F., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6570, DOI 10.1109/ICRA.2017.7989777
   Sawant A., 2004, MEASUREMENT JOINT MO, V3rd
   SHELTON BR, 1982, J ACOUST SOC AM, V71, P1527, DOI 10.1121/1.387806
   Sigrist R, 2013, PSYCHON B REV, V20, P21, DOI 10.3758/s13423-012-0333-8
   STILLMAN JA, 1989, PERCEPT PSYCHOPHYS, V46, P345, DOI 10.3758/BF03204988
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Takahashi CD, 2003, EXP BRAIN RES, V149, P131, DOI 10.1007/s00221-002-1340-1
   Wang JK, 2020, AAAI CONF ARTIF INTE, V34, P6202
   Wei Y, 2005, INT C REHAB ROBOT, P505
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
NR 57
TC 8
Z9 8
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3193
EP 3205
DI 10.1109/TVCG.2021.3057797
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700010
PM 33556011
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Ye, SQ
   Chen, DD
   Han, SF
   Wan, ZY
   Liao, J
AF Ye, Shuquan
   Chen, Dongdong
   Han, Songfang
   Wan, Ziyu
   Liao, Jing
TI Meta-PU: An Arbitrary-Scale Upsampling Network for Point Cloud
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Feature extraction; Task analysis;
   Convolution; Neural networks; Deep learning; Computational modeling;
   Point cloud; upsampling; meta-learning; deep learning
AB Point cloud upsampling is vital for the quality of the mesh in three-dimensional reconstruction. Recent research on point cloud upsampling has achieved great success due to the development of deep learning. However, the existing methods regard point cloud upsampling of different scale factors as independent tasks. Thus, the methods need to train a specific model for each scale factor, which is both inefficient and impractical for storage and computation in real applications. To address this limitation, in this article, we propose a novel method called "Meta-PU" to first support point cloud upsampling of arbitrary scale factors with a single model. In the Meta-PU method, besides the backbone network consisting of residual graph convolution (RGC) blocks, a meta-subnetwork is learned to adjust the weights of the RGC blocks dynamically, and a farthest sampling block is adopted to sample different numbers of points. Together, these two blocks enable our Meta-PU to continuously upsample the point cloud with arbitrary scale factors by using only a single model. In addition, the experiments reveal that training on multiple scales simultaneously is beneficial to each other. Thus, Meta-PU even outperforms the existing methods trained for a specific scale factor only.
C1 [Ye, Shuquan; Wan, Ziyu; Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Chen, Dongdong] Microsoft Res, Redmond, WA 98052 USA.
   [Han, Songfang] Univ Calif San Diego, La Jolla, CA 92093 USA.
C3 City University of Hong Kong; Microsoft; University of California
   System; University of California San Diego
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM shuquan2-c@my.cityu.edu.hk; cddlyf@gmail.com; hansongfang@gmail.com;
   ziyuwan2-c@my.cityu.edu.hk; jingliao@my.cityu.edu.hk
RI Chen, Dongdong/AAR-4481-2020; Han, Songfang/AAA-5781-2020
OI Han, Songfang/0000-0002-6432-8764; Chen, Dongdong/0000-0002-4642-4373;
   LIAO, Jing/0000-0001-7014-5377; Ye, Shuquan/0000-0001-5121-8040
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [9048148
   (CityU 21209119)]; Shenzhen Basic Research General Program
   [JCYJ20190814112007258]
FX This work was supported in part by the Hong Kong Research Grants Council
   (RGC) Early Career Scheme under Grant 9048148 (CityU 21209119), and in
   part by the Shenzhen Basic Research General Program under Grant
   JCYJ20190814112007258.
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Andrychowicz M, 2016, ADV NEUR IN, V29
   [Anonymous], 2019, PR MACH LEARN RES
   Arnold SMR, 2020, Arxiv, DOI arXiv:2008.12284
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Chen DD, 2020, IEEE T IMAGE PROCESS, V29, P8043, DOI 10.1109/TIP.2020.3009844
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Fan QN, 2018, LECT NOTES COMPUT SC, V11217, P455, DOI 10.1007/978-3-030-01261-8_27
   Fan QN, 2021, IEEE T PATTERN ANAL, V43, P33, DOI 10.1109/TPAMI.2019.2925793
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hu R, 2018, PROC CVPR IEEE, P4233, DOI 10.1109/CVPR.2018.00445
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Kipf T., 2017, P 5 INT C LEARNING
   Lemke C, 2015, ARTIF INTELL REV, V44, P117, DOI 10.1007/s10462-013-9406-y
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339D\, 10.1109/ICCV.2019.00339]
   Pickup D, 2016, INT J COMPUT VISION, V120, P169, DOI 10.1007/s11263-016-0903-8
   Qi C.R., 2017, ArXiv, P5099
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ravi S, 2017, P 5 INT C LEARN REPR, P1
   Shu ZY, 2019, IEEE T VIS COMPUT GR, V25, P2583, DOI 10.1109/TVCG.2018.2848628
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wu HK, 2019, Arxiv, DOI arXiv:1908.02111
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Yang T., 2018, P 32 INT C NEURAL IN, P320
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
NR 33
TC 44
Z9 50
U1 4
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3206
EP 3218
DI 10.1109/TVCG.2021.3058311
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700011
PM 33560989
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Schwab, M
   Saffo, D
   Bond, N
   Sinha, S
   Dunne, C
   Huang, J
   Tompkin, J
   Borkin, MA
AF Schwab, Michail
   Saffo, David
   Bond, Nicholas
   Sinha, Shash
   Dunne, Cody
   Huang, Jeff
   Tompkin, James
   Borkin, Michelle A.
TI Scalable Scalable Vector Graphics: Automatic Translation of Interactive
   SVGs to a Multithread VDOM for Fast Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Rendering (computer graphics); Browsers; Cascading
   style sheets; Layout; Tools; Instruction sets; Visualization systems;
   SVG; performance; virtual DOM; rendering; D3; js
AB The dominant markup language for Web visualizations-Scalable Vector Graphics (SVG)-is comparatively easy to learn, and is open, accessible, customizable via CSS, and searchable via the DOM, with easy interaction handling and debugging. Because these attributes allow visualization creators to focus on design on implementation details, tools built on top of SVG, such as D3.js, are essential to the visualization community. However, slow SVG rendering can limit designs by effectively capping the number of on-screen data points, and this can force visualization creators to switch to Canvas or WebGL. These are less flexible (e.g., no search or styling via CSS), and harder to learn. We introduce Scalable Scalable Vector Graphics (SSVG) to reduce these limitations and allow complex and smooth visualizations to be created with SVG. SSVG automatically translates interactive SVG visualizations into a dynamic virtual DOM (VDOM) to bypass the browser's slow 'to specification' rendering by intercepting JavaScript function calls. De-coupling the SVG visualization specification from SVG rendering, and obtaining a dynamic VDOM, creates flexibility and opportunity for visualization system research. SSVG uses this flexibility to free up the main thread for more interactivity and renders the visualization with Canvas or WebGL on a web worker. Together, these concepts create a drop-in JavaScript library which can improve rendering performance by 3-9x with only one line of code added. To demonstrate applicability, we describe the use of SSVG on multiple example visualizations including published visualization research. A free copy of this article, collected data, and source code are available as open science at osf.io/ge8wp.
C1 [Schwab, Michail; Saffo, David; Bond, Nicholas; Dunne, Cody; Borkin, Michelle A.] Northeastern Univ, Boston, MA 02115 USA.
   [Sinha, Shash; Huang, Jeff; Tompkin, James] Brown Univ, Providence, RI 02912 USA.
C3 Northeastern University; Brown University
RP Schwab, M (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM schwab.m@northeastern.edu; saffo.d@northeastern.edu;
   bond.n@northeastern.edu; ssinha11@brown.edu; c.dunne@northeastern.edu;
   jeff_huang@brown.edu; james_tompkini@brown.edu;
   m.borkin@northeastern.edu
RI Schwab, Michail/GWC-3548-2022; Dunne, Cody/M-4444-2019
OI Saffo, David/0000-0001-9515-048X; Dunne, Cody/0000-0002-1609-9776;
   Borkin, Michelle/0000-0002-8016-355X; Schwab,
   Michail/0000-0003-4427-3353; Tompkin, James/0000-0003-2218-2899
FU Khoury College of Computer Sciences, Northeastern University
FX The authors would like to thank Alex Ahmed, Sara Di Bartolomeo, Aditeya
   Pandey, Lulu Liu, and Laura South for experimenting with SSVG and
   providing useful feedback and advice. This work was supported by the
   Khoury College of Computer Sciences, Northeastern University.
CR Almende B. V., 2018, VIS JS DYNAMIC BROWS
   Anderson D., 2017, MOZILLA GFX TEAM BLO
   Bakaus P., 2014, ILLUSION MOTION
   Ballard DH, 1997, BEHAV BRAIN SCI, V20, P723, DOI 10.1017/S0140525X97001611
   Baxter K., 2018, WORKERDOM JAVASCRIPT
   Bostock M., 2012, FORCE DIRECTED GRAPH
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandel J., 2012, TWO JS RENDERER AGNO
   Cabello Ricardo, 2010, three.js-JavaScript 3D library
   Card S., 1983, The Psychology of Human-Computer Interaction
   Claypool M, 2006, PROC SPIE, V6071, DOI 10.1117/12.648609
   Cytoscape Consortium, 2001, CYT NETW DAT INT AN
   Facebook, 2013, REACT
   Goodboy Digital Ltd, 2013, PIX HTML5 CREAT ENG
   Google, 2015, WEB FUND MEAS PERF R
   Google, 2020, WEB FUND REND PERF
   Google, 2010, ANG
   Gray WD, 2000, J EXP PSYCHOL-APPL, V6, P322, DOI 10.1037//1076-898X.6.4.322
   Gueziri HE, 2018, IEEE T BIO-MED ENG, V65, P1140, DOI 10.1109/TBME.2017.2777742
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jie A., 2016, PROTON JAVASCRIPT PA
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Klamka K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376199
   Lehni J., 2011, PAPER JS SWISS ARMY
   Lerner G., 2014, CANVG JAVASCRIPT SVG
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   Miller R., 1968, AFIPS Fall Joint Computer Conference, P267, DOI 10.1145/1476589.1476628
   Mozilla, 2013, MDN WEB DOCS BLOB
   Mozilla, 2016, MDN WEB DOCS SHAREDA
   Mozilla Developer Network, 2016, OFFSCREENCANVAS EL
   Ren DH, 2017, COMPUT GRAPH FORUM, V36, P179, DOI 10.1111/cgf.13178
   Ritter W, 2015, LECT NOTES COMPUT SC, V9176, P139, DOI 10.1007/978-3-319-20681-3_13
   Saffo D., 2019, PROC IEEE VIS C, DOI [10.31219/osf.io/ykwah, DOI 10.31219/OSF.IO/YKWAH]
   Satyanarayan A., 2014, P 27 ANN ACM S US IN, P669, DOI DOI 10.1145/2642918.2647360
   Schulz C, 2017, IEEE T VIS COMPUT GR, V23, P531, DOI 10.1109/TVCG.2016.2598919
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   Smus B., 2009, PERFORMANCE CANVAS V
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P2487, DOI 10.1109/TVCG.2017.2750689
   Wattenberg M., 2012, WIND MAP
   World Wide Web Consortium, 2016, HTML LIVING STANDARD
   You E., 2016, VUE JS
NR 41
TC 6
Z9 6
U1 2
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3219
EP 3234
DI 10.1109/TVCG.2021.3059294
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700012
PM 33587700
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, YX
   Li, W
   Fan, R
   Liu, XP
AF Chen, Yixin
   Li, Wei
   Fan, Rui
   Liu, Xiaopei
TI GPU Optimization for High-Quality Kinetic Fluid Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Kinetic theory; Mathematical model; Graphics processing units;
   Computational modeling; Solids; Optimization; Adaptation models; GPU
   optimization; parallel computing; fluid simulation; lattice Boltzmann
   method; immersed boundary method
ID LATTICE BOLTZMANN METHOD; NAVIER-STOKES SOLVER; IMMERSED-BOUNDARY;
   IMPLEMENTATION; ALGORITHM; EFFICIENT
AB Fluid simulations are often performed using the incompressible Navier-Stokes equations (INSE), leading to sparse linear systems which are difficult to solve efficiently in parallel. Recently, kinetic methods based on the adaptive-central-moment multiple-relaxation-time (ACM-MRT) model [1], [2] have demonstrated impressive capabilities to simulate both laminar and turbulent flows, with quality matching or surpassing that of state-of-the-art INSE solvers. Furthermore, due to its local formulation, this method presents the opportunity for highly scalable implementations on parallel systems such as GPUs. However, an efficient ACM-MRT-based kinetic solver needs to overcome a number of computational challenges, especially when dealing with complex solids inside the fluid domain. In this article, we present multiple novel GPU optimization techniques to efficiently implement high-quality ACM-MRT-based kinetic fluid simulations in domains containing complex solids. Our techniques include a new communication-efficient data layout, a load-balanced immersed-boundary method, a multi-kernel launch method using a simplified formulation of ACM-MRT calculations to enable greater parallelism, and the integration of these techniques into a parametric cost model to enable automated prameter search to achieve optimal execution performance. We also extended our method to multi-GPU systems to enable large-scale simulations. To demonstrate the state-of-the-art performance and high visual quality of our solver, we present extensive experimental results and comparisons to other solvers.
C1 [Chen, Yixin; Li, Wei; Fan, Rui; Liu, Xiaopei] ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
C3 ShanghaiTech University
RP Liu, XP (corresponding author), ShanghaiTech Univ, Shanghai Engn Res Ctr Intelligent Vis & Imaging, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
EM chenyx2@shanghaitech.edu.cn; liwei@shanghaitech.edu.cn;
   fanrui@shanghaitech.edu.cn; liuxp@shanghaitech.edu.cn
OI Chen, Yixin/0000-0001-7547-9587
FU ShanghaiTech University; National Natural Science Foundation of China
   [61976138]
FX The authors would like to thank all the reviewers for their constructive
   comments. They also thank Yihui Ma, Chenqi Luo, and Chaoyang Lyu from
   the FLARE Lab at ShanghaiTech University for helping with video
   preparations. They are grateful to YOKE Intelligence for providing the
   3D reconstruction in Fig. 1 for our large scale simulation. This work
   was supported by the startup fund of ShanghaiTech University and the
   National Natural Science Foundation of China under Grant 61976138.
CR Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Александрова Мария Викторовна Aleksandrova M.], 2010, [Проблемы Дальнего Востока, Problemy Dal'nego Vostoka], P65
   Alfonsi G, 2011, LECT NOTES COMPUT SC, V6873, P404, DOI 10.1007/978-3-642-23178-0_35
   Ando R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461982
   [Anonymous], 2005, Natural Phenomena 2005, DOI DOI 10.2312/NPH/NPH05/051-056
   Bai K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3412360
   Bailey Peter, 2009, Proceedings of the 2009 International Conference on Parallel Processing (ICPP 2009), P550, DOI 10.1109/ICPP.2009.38
   Band S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180486
   Band Stefan, 2017, P 13 WORKSH VIRT REA, P21
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bernaschi M, 2010, CONCURR COMP-PRACT E, V22, P1, DOI 10.1002/cpe.1466
   Brandvik T, 2008, 46 AIAA AER SCI M EX, P607
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Brochu Tyson, 2012, S COMPUTER ANIMATION, P87
   Calore E, 2019, INT J HIGH PERFORM C, V33, P124, DOI 10.1177/1094342017703771
   Chen S, 1998, ANNU REV FLUID MECH, V30, P329, DOI 10.1146/annurev.fluid.30.1.329
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Clausen P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451243
   CUDA, 2021, PAR COMP PLATF
   Cui QD, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201352
   cuSPARSE, 2021, SPARS LIN ALG
   d'Humières D, 2002, PHILOS T ROY SOC A, V360, P437, DOI 10.1098/rsta.2001.0955
   de Goes F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766901
   De Rosis A, 2017, PHYS REV E, V95, DOI 10.1103/PhysRevE.95.013310
   Delbosc N, 2014, COMPUT MATH APPL, V67, P462, DOI 10.1016/j.camwa.2013.10.002
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Feng ZG, 2004, J COMPUT PHYS, V195, P602, DOI 10.1016/j.jcp.2003.10.013
   Fu CY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130878
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275044
   Geier M, 2009, EUR PHYS J-SPEC TOP, V171, P55, DOI 10.1140/epjst/e2009-01011-1
   Geier M, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.066705
   Golas A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366167
   Griebel M, 2010, COMPUT SCI-RES DEV, V25, P65, DOI 10.1007/s00450-010-0111-7
   Guo XH, 2015, COMPUT FLUIDS, V110, P227, DOI 10.1016/j.compfluid.2014.09.007
   Guo YL, 2017, IEEE T VIS COMPUT GR, V23, P1479, DOI 10.1109/TVCG.2016.2532335
   Habich J, 2011, ADV ENG SOFTW, V42, P266, DOI 10.1016/j.advengsoft.2010.10.007
   Harris S., 2004, An introduction to the theory of the Boltzmann equation
   Helfenstein R, 2012, J COMPUT APPL MATH, V236, P3584, DOI 10.1016/j.cam.2011.04.025
   Henniger R, 2010, J COMPUT PHYS, V229, P3543, DOI 10.1016/j.jcp.2010.01.015
   HERON A, 1989, J COMPUT PHYS, V85, P284, DOI 10.1016/0021-9991(89)90152-6
   Herschlag G, 2018, INT PARALL DISTRIB P, P825, DOI 10.1109/IPDPS.2018.00092
   Hu YM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356506
   Ihmsen M., 2014, SPH FLUIDS COMPUTER
   Jakob Wenzel, 2010, Mitsuba Renderer
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Krüger T, 2011, COMPUT MATH APPL, V61, P3485, DOI 10.1016/j.camwa.2010.03.057
   Krüger J, 2003, ACM T GRAPHIC, V22, P908, DOI 10.1145/882262.882363
   Ladicky L, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818129
   Li W, 2003, VISUAL COMPUT, V19, P444, DOI 10.1007/s00371-003-0210-6
   Li W, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392400
   Li W, 2019, IEEE T VIS COMPUT GR, V25, P2694, DOI 10.1109/TVCG.2018.2859931
   Liu X, 2014, IEEE T VIS COMPUT GR, V20, P289, DOI 10.1109/TVCG.2012.303
   Liu Y, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P247
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Lycett-Brown D, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4866146
   Mashayekhi O, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3173551
   Mattila K, 2008, COMPUT MATH APPL, V55, P1514, DOI 10.1016/j.camwa.2007.08.001
   Mattila K, 2007, COMPUT PHYS COMMUN, V176, P200, DOI 10.1016/j.cpc.2006.09.005
   Mei RW, 1999, J COMPUT PHYS, V155, P307, DOI 10.1006/jcph.1999.6334
   Mohammed A. A., 2012, LATTICE BOLTZMANN ME, DOI [10.2514/1.J051744, DOI 10.2514/1.J051744]
   Morton GM, 1966, COMPUTER ORIENTED GE
   Mullen P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531344
   Myre J, 2011, CONCURR COMP-PRACT E, V23, P332, DOI 10.1002/cpe.1645
   Obrecht C, 2013, COMPUT MATH APPL, V65, P252, DOI 10.1016/j.camwa.2011.02.020
   Park Sang Il, 2005, S COMPUTER ANIMATION, P261
   PESKIN CS, 1972, J COMPUT PHYS, V10, P252, DOI 10.1016/0021-9991(72)90065-4
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Posey S., 2013, PROCEDIA ENG, V61, P388
   Qu ZY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322945
   Rohde M, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.066703
   Sato Y, 2013, COMPUT FLUIDS, V88, P496, DOI 10.1016/j.compfluid.2013.10.008
   Sbragaglia M, 2005, PHYS FLUIDS, V17, DOI 10.1063/1.2044829
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Setaluri R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661269
   Shan XW, 2019, PHYS REV E, V100, DOI 10.1103/PhysRevE.100.043308
   Shan XW, 2006, J FLUID MECH, V550, P413, DOI 10.1017/S0022112005008153
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Suga K, 2015, COMPUT MATH APPL, V69, P518, DOI 10.1016/j.camwa.2015.01.010
   Thibault J., 2009, P 47 AIAA AER SCI M
   Thuerey N., 2006, PROC VIS MODEL VIS, V2006, P193
   Thürey N, 2009, COMPUT VIS SCI, V12, P247, DOI 10.1007/s00791-008-0090-4
   Tölke J, 2008, INT J COMPUT FLUID D, V22, P443, DOI 10.1080/10618560802238275
   Tölke J, 2010, COMPUT VIS SCI, V13, P29, DOI 10.1007/s00791-008-0120-2
   Valero-Lara P, 2015, J COMPUT SCI-NETH, V10, P249, DOI 10.1016/j.jocs.2015.07.002
   Verschaeve JCG, 2010, J COMPUT PHYS, V229, P6781, DOI 10.1016/j.jcp.2010.05.022
   Wang R, 2008, APPL MATH COMPUT, V196, P433, DOI 10.1016/j.amc.2007.06.024
   Wang Y., 2014, P HIGH PERF COMP S
   Wei XM, 2004, IEEE T VIS COMPUT GR, V10, P719, DOI 10.1109/TVCG.2004.48
   Weissmann S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778852
   Wellein G, 2006, COMPUT FLUIDS, V35, P910, DOI 10.1016/j.compfluid.2005.02.008
   Winchenbach R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073713
   Wu J, 2010, J COMPUT PHYS, V229, P5022, DOI 10.1016/j.jcp.2010.03.024
   Wu K, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13350
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Xinxin Zhang, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2661229.2661261
   Yuksel C, 2015, COMPUT GRAPH FORUM, V34, P25, DOI 10.1111/cgf.12538
   Zehnder J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201324
   Zhang XX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925910
   Zhang XX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766982
   Zhao Y, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P181
   Zhu B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461999
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 105
TC 9
Z9 11
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3235
EP 3251
DI 10.1109/TVCG.2021.3059753
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700013
PM 33591918
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wagner, J
   Stuerzlinger, W
   Nedel, L
AF Wagner, Jorge
   Stuerzlinger, Wolfgang
   Nedel, Luciana
TI The Effect of Exploration Mode and Frame of Reference in Immersive
   Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Navigation; Task analysis; Data visualization; Legged locomotion;
   Three-dimensional displays; Inspection; Affordances; Navigation
   techniques; frame of reference; immersive analytics; space-time cube
ID 3D VISUALIZATIONS; NAVIGATION; MOVEMENT
AB The design space for user interfaces for Immersive Analytics applications is vast. Designers can combine navigation and manipulation to enable data exploration with ego- or exocentric views, have the user operate at different scales, or use different forms of navigation with varying levels of physical movement. This freedom results in a multitude of different viable approaches. Yet, there is no clear understanding of the advantages and disadvantages of each choice. Our goal is to investigate the affordances of several major design choices, to enable both application designers and users to make better decisions. In this article, we assess two main factors, exploration mode and frame of reference, consequently also varying visualization scale and physical movement demand. To isolate each factor, we implemented nine different conditions in a Space-Time Cube visualization use case and asked 36 participants to perform multiple tasks. We analyzed the results in terms of performance and qualitative measures and correlated them with participants' spatial abilities. While egocentric room-scale exploration significantly reduced mental workload, exocentric exploration improved performance in some tasks. Combining navigation and manipulation made tasks easier by reducing workload, temporal demand, and physical effort.
C1 [Wagner, Jorge; Nedel, Luciana] Univ Fed Rio Grande do Sul, BR-90040 Porto Alegre, RS, Brazil.
   [Stuerzlinger, Wolfgang] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
C3 Universidade Federal do Rio Grande do Sul; Simon Fraser University
RP Wagner, J (corresponding author), Univ Fed Rio Grande do Sul, BR-90040 Porto Alegre, RS, Brazil.
EM jawfilho@inf.ufrgs.br; w.s@sfu.ca; nedel@inf.ufrgs.br
RI Wagner, Jorge/AAV-7597-2020; Nedel, Luciana/G-3506-2012
OI Nedel, Luciana/0000-0002-2390-1392; Stuerzlinger,
   Wolfgang/0000-0002-7110-5024; Wagner Filho, Jorge
   Alberto/0000-0002-7016-3142
FU CNPq-Brazil; Global Affairs Canada; NSERC; Coordenacao de
   Aperfeicoamento de Pessoal de Ni'vel Superior -Brasil (CAPES) [001]
FX The authors thank the study participants for their feedback and the
   reviewers for their insightful comments. They acknowledge financial
   support from CNPq-Brazil, Global Affairs Canada, and NSERC. This study
   was financed in part by the Coordenacao de Aperfeicoamento de Pessoal de
   Ni ' vel Superior -Brasil (CAPES) -Finance Code 001.
CR Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   [Anonymous], 1988, Statistical Power Analysis for the Behavioral Sciences
   [Anonymous], 1992, PROC S INTERACTIVE 3
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Bellec Matthieu, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087804
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Breheny P, 2017, R J, V9, P56, DOI 10.32614/RJ-2017-046
   Büschel W, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P62, DOI 10.1145/3132272.3134125
   Butterworth J., 1992, Proceeding of the Symposium on Interactive 3D Graphics, P135, DOI DOI 10.1145/147156.147182
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Chen X, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P32
   Cliquet G., 2017, PROC WORKSHOP IMMERS, P1
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Drogemuller A., 2018, 2018 International Symposium on Big Data Visual and Immersive Analytics (BDVA), P1, DOI DOI 10.1109/BDVA.2018.8533895
   Ekstrom R.B., 1976, KIT FACTORREFERENCED
   Fabroyir H, 2018, COMPUT HUM BEHAV, V80, P331, DOI 10.1016/j.chb.2017.11.033
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fonnet A., 2018, PROC STUDENT INTERAC
   Fonnet A., 2018, 2018 International Symposium on Big Data Visual and Immersive Analytics (BDVA), P1, DOI [DOI 10.1109/BDVA.2018.8533892, 10.1109/bdva.2018.8533892]
   Gonçalves T, 2015, J LOCAT BASED SERV, V9, P138, DOI 10.1080/17489725.2015.1074736
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hedley NR, 2002, PRESENCE-VIRTUAL AUG, V11, P119, DOI 10.1162/105474602317396002
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jordan Patrick W, 1996, Industry
   Kapler T, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P25, DOI 10.1109/INFVIS.2004.27
   Käser DP, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085094
   Kennedy RS, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P247
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kristensson PO, 2009, IEEE T VIS COMPUT GR, V15, P696, DOI 10.1109/TVCG.2008.194
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lages W. S., 2018, Frontiers in ICT, V5, P15, DOI DOI 10.3389/FICT.2018.00015
   Marriott K., 2018, IMMERSIVE ANAL, V11190, DOI 10/kt9x
   McCormick EP, 1998, HUM FACTORS, V40, P443, DOI 10.1518/001872098779591403
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Okada K, 2018, IEEE INT CON INF VIS, P91, DOI 10.1109/iV.2018.00026
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Risch JS, 1996, IEEE COMPUT GRAPH, V16, P33, DOI 10.1109/38.544070
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sauro J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1599
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Simpson M., 2017, Proceeedings of workshop on immersive analytics at IEEE VIS 2017, P1
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Ssin SY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P210, DOI [10.1109/VR.2019.8797812, 10.1109/vr.2019.8797812]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vinson N.G., 1999, CHI 99, P278
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wagner JA, 2019, IEEE COMPUT GRAPH, V39, P41, DOI 10.1109/MCG.2019.2898856
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
NR 59
TC 14
Z9 14
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3252
EP 3264
DI 10.1109/TVCG.2021.3060666
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700014
PM 33606632
DA 2024-11-06
ER

PT J
AU Li, YQ
   Wang, CA
   Hong, J
   Zhu, J
   Guo, J
   Wang, J
   Guo, YW
   Wang, WP
AF Li, Yuanqi
   Wang, Chuan
   Hong, Jing
   Zhu, Jie
   Guo, Jie
   Wang, Jue
   Guo, Yanwen
   Wang, Wenping
TI Video Vectorization via Bipartite Diffusion Curves Propagation and
   Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Optimization; Image resolution; Geometry; Image
   reconstruction; Spatial coherence; Feature extraction; Video;
   vectorization; diffusion curve
ID IMAGE VECTORIZATION; ROBUST; COLOR
AB We propose a new video vectorization approach for converting videos in the raster format to vector representation with the benefits of resolution independence and compact storage. Through classifying extracted curves in each video frame into salient ones and non-salient ones, we introduce a novel bipartite diffusion curves (BDCs) representation in order to preserve both important image features such as sharp boundaries and regions with smooth color variation. This bipartite representation allows us to propagate non-salient curves across frames such that the propagation, in conjunction with geometry optimization and color optimization of salient curves, ensures the preservation of fine details within each frame and across different frames, and meanwhile, achieves good spatial-temporal coherence. Thorough experiments on a variety of videos show that our method is capable of converting videos to the vector representation with low reconstruction errors, low computational cost, and fine details, demonstrating our superior performance over the state of the art. We also show that, when used for video upsampling, our method produces results comparable to video super-resolution.
C1 [Li, Yuanqi; Wang, Chuan; Hong, Jing; Zhu, Jie; Guo, Jie; Guo, Yanwen] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210000, Jiangsu, Peoples R China.
   [Wang, Jue] Megvii Technol, Beijing 100000, Peoples R China.
   [Wang, Wenping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Nanjing University; University of Hong Kong
RP Guo, J; Guo, YW (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing 210000, Jiangsu, Peoples R China.
EM yuanqili@smail.nju.edu.cn; wangchuan@megvii.com;
   hongjing@smail.nju.edu.cn; magickuang@126.com; guojie@nju.edu.cn;
   wangjue@megvii.com; ywguo@nju.edu.cn; wenping@cs.hku.hk
RI Wang, Jue/GVU-0480-2022
OI Wang, Jue/0000-0002-3641-3136; Li, Yuanqi/0000-0003-4100-7471
FU National Natural Science Foundation of China [62032011, 61772257,
   61972194]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62032011, 61772257, and 61972194. J.
   Guo and Y. Guo are the co-corresponding authors.
CR Bartolo A, 2007, SKETCH-BASED INTERFACES AND MODELING 2007, P123
   Ben-Zvi N, 2016, COMPUT GRAPH FORUM, V35, P18, DOI 10.1111/cgf.12729
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bessmeltsev M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3202661
   Bowers JC, 2011, COMPUT GRAPH FORUM, V30, P1345, DOI 10.1111/j.1467-8659.2011.01994.x
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Favreau JD, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130888
   Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946
   Finch M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024200
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127
   Hongwei Lin, 2018, Computational Visual Media, V4, P149, DOI 10.1007/s41095-018-0109-9
   Hoshyari S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201312
   Hou F, 2020, IEEE T VIS COMPUT GR, V26, P1361, DOI 10.1109/TVCG.2018.2867478
   Ilbery P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508426
   Janssen RDT, 1997, COMPUT VIS IMAGE UND, V65, P38, DOI 10.1006/cviu.1996.0484
   Jeschke S, 2011, COMPUT GRAPH FORUM, V30, P523, DOI 10.1111/j.1467-8659.2011.01877.x
   Jeschke S, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12812
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618462
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618463
   Kopf J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964994
   Lai WS, 2018, LECT NOTES COMPUT SC, V11219, P179, DOI 10.1007/978-3-030-01267-0_11
   Lai YK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531391
   Lecot G., 2006, P 17 EUR C REND TECH, P349
   Li YJ, 2021, IEEE T VIS COMPUT GR, V27, P228, DOI 10.1109/TVCG.2019.2929808
   Liao ZC, 2012, IEEE T VIS COMPUT GR, V18, P1858, DOI 10.1109/TVCG.2012.76
   Lu SF, 2019, VISUAL COMPUT, V35, P1027, DOI 10.1007/s00371-019-01671-0
   Lucas B. D., 1981, P IJCAI, P674
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640
   Orzan A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360691
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Sun X, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185570
   Sykora D, 2005, LECT NOTES COMPUT SC, V3804, P43
   Takayama K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866202
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang CA, 2017, IEEE T IMAGE PROCESS, V26, P1833, DOI 10.1109/TIP.2017.2666742
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Xia T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618461
   Xie GF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661275
   Yao CY, 2017, IEEE T VIS COMPUT GR, V23, P1070, DOI 10.1109/TVCG.2016.2525774
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
   Zhao S, 2018, IEEE T VIS COMPUT GR, V24, P2153, DOI 10.1109/TVCG.2017.2721400
   Zou JJ, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P225, DOI 10.1109/CGI.2001.934678
NR 47
TC 2
Z9 2
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3265
EP 3276
DI 10.1109/TVCG.2021.3061131
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700015
PM 33621178
DA 2024-11-06
ER

PT J
AU Isenberg, T
   Salazar, Z
   Blanco, R
   Plaisant, C
AF Isenberg, Tobias
   Salazar, Zujany
   Blanco, Rafael
   Plaisant, Catherine
TI Do You Believe Your (Social Media) Data? A Personal Story on Location
   Data Biases, Errors, and Plausibility as Well as Their Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Social networking (online); Data visualization; Data collection; Data
   mining; Multimedia Web sites; Image databases; Data integrity; Social
   media data; Flickr; Panoramio; iNaturalist; data bias; data error; data
   plausibility; data obfuscation; citizen science
ID DATA QUALITY; MAPS
AB We present a case study on a journey about a personal data collection of carnivorous plant species habitats, and the resulting scientific exploration of location data biases, data errors, location hiding, and data plausibility. While initially driven by personal interest, our work led to the analysis and development of various means for visualizing threats to insight from geo-tagged social media data. In the course of this endeavor we analyzed local and global geographic distributions and their inaccuracies. We also contribute Motion Plausibility Profiles-a new means for visualizing how believable a specific contributor's location data is or if it was likely manipulated. We then compared our own repurposed social media dataset with data from a dedicated citizen science project. Compared to biases and errors in the literature on traditional citizen science data, with our visualizations we could also identify some new types or show new aspects for known ones. Moreover, we demonstrate several types of errors and biases for repurposed social media data. Please note that people with color impairments may consider our alternative paper version.
C1 [Isenberg, Tobias] Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 Gif Sur Yvette, France.
   [Salazar, Zujany; Blanco, Rafael] Telecom SudParis, 9 Rue Charles Fourier, F-91000 Evry, France.
   [Plaisant, Catherine] Univ Maryland, College Pk, MD 20742 USA.
   [Plaisant, Catherine] INRIA, F-78150 Le Chesnay, France.
C3 Universite Paris Saclay; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS); Inria; IMT - Institut Mines-Telecom;
   Institut Mines-Telecom Business School; Institut Polytechnique de Paris;
   Telecom SudParis; University System of Maryland; University of Maryland
   College Park; Inria
RP Isenberg, T (corresponding author), Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 Gif Sur Yvette, France.
EM tobias.isenberg@inria.fr; zujany@gmail.com; rblancog25@gmail.com;
   plaisant@cs.umd.edu
RI ; Isenberg, Tobias/A-7575-2008
OI Plaisant, Catherine/0000-0003-4049-5848; Salazar,
   Zujany/0000-0002-8655-0585; Isenberg, Tobias/0000-0001-7953-8644
CR Adlassing W, 2010, PHYTON-ANN REI BOT A, V49, P279
   Alstott J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085777
   Amano T, 2016, BIOSCIENCE, V66, P393, DOI 10.1093/biosci/biw022
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P213, DOI 10.1109/VAST.2009.5333472
   [Anonymous], 2017, GEO HDB BIODIVERSITY, DOI DOI 10.1007/978-3-319-27288-7_9
   Anthony L, 2018, IEEE T PROF COMMUN, V61, P428, DOI 10.1109/TPC.2018.2870681
   Arnold ND, 2017, INT J GEOGR INF SCI, V31, P2524, DOI 10.1080/13658816.2017.1359747
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Beck J, 2014, ECOL INFORM, V19, P10, DOI 10.1016/j.ecoinf.2013.11.002
   Blanco R., 2019, PROC IEEE VIS POSTER
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bowser A., 2014, Interaction, V21, P70, DOI DOI 10.1145/2540032
   Bright J, 2018, GEOJOURNAL, V83, P427, DOI 10.1007/s10708-017-9778-7
   Callaghan CT, 2019, PLOS BIOL, V17, DOI 10.1371/journal.pbio.3000357
   Campbell DL, 2020, PEERJ, V8, DOI 10.7717/peerj.9219
   Chapman A.D, 2005, PRINCIPLES DATA QUAL, DOI [10.15468/doc.jrgg-a190, DOI 10.15468/DOC.JRGG-A190]
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Crandall D., 2009, P 18 INT C WORLD WID, P761, DOI 10.1145/1526709.1526812
   DARWIN CR, 1875, Insectivorous Plants
   Das MPA, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING & COMMUNICATION ENGINEERING (ICACCE-2019), DOI [10.1145/3290605.3300793, 10.1109/icacce46606.2019.9079984]
   Dennis RLH, 2000, J INSECT CONSERV, V4, P73, DOI 10.1023/A:1009690919835
   Dickinson JL, 2010, ANNU REV ECOL EVOL S, V41, P149, DOI 10.1146/annurev-ecolsys-102209-144636
   Eaton C, 2005, LECT NOTES COMPUT SC, V3585, P861, DOI 10.1007/11555261_68
   Eaton Cyntrica., 2003, Proceedings of the 14th IEEE Visualization 2003 (VIS'03), P100, DOI DOI 10.1109/VIS.2003.10029
   Fisher D, 2007, IEEE T VIS COMPUT GR, V13, P1184, DOI 10.1109/TVCG.2007.70561
   Gardner Z, 2020, GEOJOURNAL, V85, P1603, DOI 10.1007/s10708-019-10035-z
   Global biodiversity information facility, 2017, MAGN DAT, DOI [10.15468/dl.wquvxb, DOI 10.15468/DL.WQUVXB]
   Gschwandtner Theresia, 2012, Multidisciplinary Research and Practice for Information Systems. International Cross-Domain Conference and Workshop on Availability, Reliability and Security (CD-ARES 2012). Proceedings, P58, DOI 10.1007/978-3-642-32498-7_5
   Gschwandtner T., 2014, Proceedings of the 14th international conference on knowledge technologies and data-driven business, DOI [10.1145/2637748.2638423, DOI 10.1145/2637748.2638423]
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Isenberg T., 2004, CARNIV PLANT NEWSL, V33, P36
   Jackson LA, 2013, COMPUT HUM BEHAV, V29, P910, DOI 10.1016/j.chb.2012.11.024
   Jennings DE, 2011, BIOL CONSERV, V144, P1356, DOI 10.1016/j.biocon.2011.03.013
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kim S, 2013, IEEE T VIS COMPUT GR, V19, P1438, DOI 10.1109/TVCG.2013.66
   Kisilevich S, 2010, IEEE INT CONF INF VI, P289, DOI 10.1109/IV.2010.94
   Kiszka J., 2020, The IUCN Red List of Threatened Species 2020
   Kosmala M, 2016, FRONT ECOL ENVIRON, V14, P551, DOI 10.1002/fee.1436
   Krueger R, 2016, IEEE PAC VIS SYMP, P176, DOI 10.1109/PACIFICVIS.2016.7465266
   Laitinen H, 2001, IEEE VTS VEH TECHNOL, P2504, DOI 10.1109/VETECS.2001.944052
   Lewis JS, 2007, J APPL ECOL, V44, P663, DOI 10.1111/j.1365-2664.2007.01286.x
   Ma D, 2015, ISPRS INT J GEO-INF, V4, P535, DOI 10.3390/ijgi4020535
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   MacEachren A. M., 1992, Cartographic Perspectives, V13, P10, DOI [10.14714/CP13.1000 10.14714/CP13.1000, DOI 10.14714/CP13.1000]
   Mair L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147796
   Maldonado C, 2015, GLOBAL ECOL BIOGEOGR, V24, P973, DOI 10.1111/geb.12326
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Morstatter Fred, 2017, Online Social Networks and Media, V1, P1, DOI 10.1016/j.osnem.2017.01.001
   Muchnik L, 2013, SCI REP-UK, V3, DOI 10.1038/srep01783
   Naczi Robert F. C., 1999, SIDA Contributions to Botany, V18, P1183
   Olteanu A., 2016, THESIS ECOLE POLYTEC, DOI [10.5075/epfl-thesis-6892, DOI 10.5075/EPFL-THESIS-6892]
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Padilla L., 2022, Computational Statistics in Data Science, P405, DOI 10.31234/osf.io/ebd6r
   Page R., 2012, BLOG POST JUN
   Page R., 2012, FLICKR
   Parisod C, 2005, ANN BOT-LONDON, V95, P277, DOI 10.1093/aob/mci023
   Pick J, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8090424
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Prandi C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P402, DOI 10.1109/PERCOMW.2015.7134071
   Preece J, 2016, INT J HUM-COMPUT INT, V32, P585, DOI 10.1080/10447318.2016.1194153
   Renfro B. A., 2019, TRSGL1902 U TEX AUST
   Robertson MP, 2016, ECOGRAPHY, V39, P394, DOI 10.1111/ecog.02118
   Roy H., UNDERSTANDING CITIZE
   Royer F, 2008, J EXP MAR BIOL ECOL, V359, P1, DOI 10.1016/j.jembe.2008.01.026
   Sharp H., 2007, INTERACTION DESIGN H
   van Diggelen F, 2015, I NAVIG SAT DIV INT, P361
   Waller J., 2019, BIODIVERSITY INF SCI, V3, DOI [10.3897/biss.3.35829, DOI 10.3897/BISS.3.35829]
   Wang YZ, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P59, DOI 10.1109/ICCI-CC.2017.8109730
   Wiggins A., 2011, Proceedings of the 2011 IEEE Seventh International Conference on e-Science Workshops (eScienceW 2011), P14, DOI 10.1109/eScienceW.2011.27
   Wu YC, 2016, IEEE T MULTIMEDIA, V18, P2135, DOI 10.1109/TMM.2016.2614220
   Ytow N, 2001, BIOL J LINN SOC, V73, P81, DOI 10.1111/j.1095-8312.2001.tb01348.x
   Zizka A, 2019, METHODS ECOL EVOL, V10, P744, DOI 10.1111/2041-210X.13152
NR 76
TC 0
Z9 0
U1 3
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3277
EP 3291
DI 10.1109/TVCG.2022.3141605
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700016
PM 35015642
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yang, WK
   Ye, X
   Zhang, XX
   Xiao, LX
   Xia, JZ
   Wang, ZY
   Zhu, J
   Pfister, H
   Liu, SX
AF Yang, Weikai
   Ye, Xi
   Zhang, Xingxing
   Xiao, Lanxi
   Xia, Jiazhi
   Wang, Zhongyuan
   Zhu, Jun
   Pfister, Hanspeter
   Liu, Shixia
TI Diagnosing Ensemble Few-Shot Classifiers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Feature extraction; Predictive models; Training;
   Analytical models; Data models; Behavioral sciences; Few-shot learning;
   ensemble model; subset selection; matrix visualization; scatterplot
AB The base learners and labeled samples (shots) in an ensemble few-shot classifier greatly affect the model performance. When the performance is not satisfactory, it is usually difficult to understand the underlying causes and make improvements. To tackle this issue, we propose a visual analysis method, FSLDiagnotor. Given a set of base learners and a collection of samples with a few shots, we consider two problems: 1) finding a subset of base learners that well predict the sample collections; and 2) replacing the low-quality shots with more representative ones to adequately represent the sample collections. We formulate both problems as sparse subset selection and develop two selection algorithms to recommend appropriate learners and shots, respectively. A matrix visualization and a scatterplot are combined to explain the recommended learners and shots in context and facilitate users in adjusting them. Based on the adjustment, the algorithm updates the recommendation results for another round of improvement. Two case studies are conducted to demonstrate that FSLDiagnotor helps build a few-shot classifier efficiently and increases the accuracy by 12% and 21%, respectively.
C1 [Yang, Weikai; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Ye, Xi] Univ Texas Austin, Austin, TX 78712 USA.
   [Zhang, Xingxing; Zhu, Jun] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
   [Xiao, Lanxi] Tsinghua Univ, Acad Arts & Design, Beijing 100084, Peoples R China.
   [Xia, Jiazhi] Cent South Univ, Changsha 410017, Hunan, Peoples R China.
   [Wang, Zhongyuan] Kuaishou Technol Co Ltd, Beijing 100085, Peoples R China.
   [Pfister, Hanspeter] Harvard Univ, Cambridge, MA 02138 USA.
C3 Tsinghua University; University of Texas System; University of Texas
   Austin; Tsinghua University; Tsinghua University; Central South
   University; Harvard University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM ywk19@mails.tsinghua.edu.cn; xiye@cs.utexas.edu;
   xxzhang2020@mail.tsinghua.edu.cn; xlq20@mails.tsinghua.edu.cn;
   xiajiazhi@csu.edu.cn; wzhy@outlook.com; dcszj@tsinghua.edu.cn;
   pfister@g.harvard.edu; shixia@tsinghua.edu.cn
RI Liu, Shi-Xia/C-5574-2016; ye, xi/KTH-8756-2024; Zhang,
   Xingxing/HGE-4445-2022
OI Xiao, Lanxi/0009-0001-5385-1453; yang, wei kai/0000-0002-6520-1642;
   Pfister, Hanspeter/0000-0002-3620-2582
FU National Key R&D Program of China [2020YFB2104100]; National Natural
   Science Foundation of China [U21A20469, 61936002]; Institute Guo Qiang;
   THUIBCS; BLBCI; Tsinghua-Kuaishou Institute of Future Media Data
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020YFB2104100, in part by the National Natural Science
   Foundation of China under Grants U21A20469, 61936002, in part by
   Institute Guo Qiang, THUIBCS, and BLBCI, and in part by the
   Tsinghua-Kuaishou Institute of Future Media Data.
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   [Anonymous], 2019, HUMPBACK WHALE IDENT
   [Anonymous], 2019, CROSS DOMAIN FEW SHO
   [Anonymous], 2011, P 44 HAW INT C SYST, DOI DOI 10.1109/HICSS.2011.339
   [Anonymous], 1998, THEORY LINEAR INTEGE
   Behrisch M, 2014, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2014.7042480
   Bertinetto L., 2019, PROC INT C LEARN REP
   Boudiaf M., 2020, ADV NEURAL INFORM PR, V33, P2445, DOI DOI 10.5555/3495724.3495930
   Bruneau Pierrick, 2013, 2013 17th International Conference on Information Visualisation, P168, DOI 10.1109/IV.2013.21
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dinkla K, 2012, IEEE T VIS COMPUT GR, V18, P2457, DOI 10.1109/TVCG.2012.208
   Dvornik Nikita, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P769, DOI 10.1007/978-3-030-58607-2_45
   Dvornik N, 2019, IEEE I CONF COMP VIS, P3722, DOI 10.1109/ICCV.2019.00382
   Elhamifar E, 2016, IEEE T PATTERN ANAL, V38, P2182, DOI 10.1109/TPAMI.2015.2511748
   Endert A, 2016, SYNTH LECT VISUALIZA, V4, P1
   Fekete J.D., 2015, P 1 WORKSH DAT SYST, P5
   Fekete JD, 2016, Arxiv, DOI arXiv:1607.05162
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   Meng Y, 2015, IEEE PAC VIS SYMP, P207, DOI 10.1109/PACIFICVIS.2015.7156379
   Mengshi Qi, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P3007, DOI 10.1145/3394171.3416269
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ng A., 2021, A Chat with Andrew on MLOps: From model-centric to data-centric AI
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Popolin Neto M, 2021, IEEE T VIS COMPUT GR, V27, P1427, DOI 10.1109/TVCG.2020.3030354
   Ren M., 2018, PROC INT C LEARN REP, P1
   Renggli C., 2021, IEEE Data Engineering Bulletin, V44, P11
   Schneider B, 2021, IEEE T BIG DATA, V7, P483, DOI 10.1109/TBDATA.2018.2877350
   Settles B., 2009, ACTIVE LEARING LIT S
   Sneath P. H., 1973, NUMERICAL TAXONOMY P
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   van Eck NJ, 2009, J AM SOC INF SCI TEC, V60, P1635, DOI 10.1002/asi.21075
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Williams M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2004.60
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zhou Z.-H, 2012, Ensemble Methods, DOI DOI 10.1201/B12207
   Zhu Xiaojin, 2009, Introduction to semi-supervised learning
NR 64
TC 12
Z9 14
U1 0
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3292
EP 3306
DI 10.1109/TVCG.2022.3182488
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700017
PM 35696465
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Streeb, D
   Metz, Y
   Schlegel, U
   Schneider, B
   El-Assady, M
   Neth, H
   Chen, M
   Keim, DA
AF Streeb, Dirk
   Metz, Yannick
   Schlegel, Udo
   Schneider, Bruno
   El-Assady, Mennatallah
   Neth, Hansjoerg
   Chen, Min
   Keim, Daniel A.
TI Task-Based Visual Interactive Modeling: Decision Trees and Rule-Based
   Classifiers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision trees; Task analysis; Visual analytics; Machine learning;
   Analytical models; Data visualization; Libraries; Decision trees;
   rule-based classification; visual analytics; interactive machine
   learning; interactive model analysis; survey; visualization
ID VISUALIZATION SUPPORT; PARAMETER SPACE; BLACK-BOX; MACHINE;
   CLASSIFICATION; ANALYTICS; EXPLORATION; SYSTEM; USERS
AB Visual analytics enables the coupling of machine learning models and humans in a tightly integrated workflow, addressing various analysis tasks. Each task poses distinct demands to analysts and decision-makers. In this survey, we focus on one canonical technique for rule-based classification, namely decision tree classifiers. We provide an overview of available visualizations for decision trees with a focus on how visualizations differ with respect to 16 tasks. Further, we investigate the types of visual designs employed, and the quality measures presented. We find that (i) interactive visual analytics systems for classifier development offer a variety of visual designs, (ii) utilization tasks are sparsely covered, (iii) beyond classifier development, node-link diagrams are omnipresent, (iv) even systems designed for machine learning experts rarely feature visual representations of quality measures other than accuracy. In conclusion, we see a potential for integrating algorithmic techniques, mathematical quality measures, and tailored interactive visualizations to enable human experts to utilize their knowledge more effectively.
C1 [Streeb, Dirk; Metz, Yannick; Schlegel, Udo; Schneider, Bruno; El-Assady, Mennatallah; Neth, Hansjoerg; Keim, Daniel A.] Univ Konstanz, D-78464 Constance, Germany.
   [Chen, Min] Univ Oxford, Oxford OX1 2JD, England.
C3 University of Konstanz; University of Oxford
RP Streeb, D (corresponding author), Univ Konstanz, D-78464 Constance, Germany.
EM dirk.streeb@uni-konstanz.de; yannick.metz@uni-konstanz.de;
   udo.3.schlegel@uni-konstanz.de; bruno.schneider@uni-konstanz.de;
   Mennatallah.El-Assady@uni-konstanz.de; h.neth@uni-konstanz.de;
   min.chen@oerc.ox.ac.uk; keim@uni-konstanz.de
RI Schlegel, Udo/AAI-9385-2021; Keim, Daniel/X-7749-2019
OI Schlegel, Udo/0000-0002-8266-0162; Metz, Yannick/0000-0001-5955-4487;
   El-Assady, Mennatallah/0000-0001-8526-2613; Neth,
   Hansjorg/0000-0001-5427-3141
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [251654672, 350399414]
FX This work was supported by the Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation) within the projects A03 of TRR 161
   Project-ID 251654672 and Knowledge Generation in Visual Analytics
   Project-ID 350399414.
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Ankerst M., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P179, DOI 10.1145/347090.347124
   [Anonymous], 1999, P 5 ACM SIGKDD INT C, DOI DOI 10.1145/312129.312298
   [Anonymous], 2004, J STATIST EDU
   [Anonymous], 2001, START FLOWCHART
   [Anonymous], 2007, SIMPLE EASY UNDERSTA
   [Anonymous], 1996, MATH TEACHER
   [Anonymous], 2003, THINKING PSYCHOL PER
   Aupetit M., 2016, P IEEE S VIS CYB SEC, P1, DOI 10.1109/VIZSEC.2016.7739577
   Balestriero R, 2017, Arxiv, DOI arXiv:1702.07360
   Barlow T, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P149, DOI 10.1109/INFVIS.2001.963292
   Barlow T, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P131, DOI 10.1109/INFVIS.2001.963290
   Benson M, 1996, Prehosp Disaster Med, V11, P117
   Bertsimas D., 2011, 38611 MIT
   Bhatnagar V, 2010, LECT NOTES COMPUT SC, V5999, P225
   Bishop C., 2006, Pattern Recognition and Machine Learning
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Breiman L., 2001, MACH LEARN, V45, P5
   Breslow LA, 1997, KNOWL ENG REV, V12, P1, DOI 10.1017/S0269888997000015
   Brown ET, 2014, IEEE T VIS COMPUT GR, V20, P1663, DOI 10.1109/TVCG.2014.2346575
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Rojas WC, 2015, PROCEDIA COMPUT SCI, V55, P650, DOI 10.1016/j.procs.2015.07.063
   Castillo-Rojas Wilson, 2013, Human-Computer Interaction. 6th Latin American Conference, CLIHC 2013. Proceedings: LNCS 8278, P148, DOI 10.1007/978-3-319-03068-5_24
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Chen CM, 2006, IEEE CONF VIS ANAL, P59
   Cong B, 1991, J COMPUT SCI COLL, V7, P1
   Dang T, 2017, VOILA ISWC
   Dhami MK, 2001, J BEHAV DECIS MAKING, V14, P141, DOI 10.1002/bdm.371
   Dhami MK, 2003, PSYCHOL SCI, V14, P175, DOI 10.1111/1467-9280.01438
   Di Castro F., 2019, CEUR WORKSHOP PROC, V2327
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Fonarow GC, 2005, JAMA-J AM MED ASSOC, V293, P572, DOI 10.1001/jama.293.5.572
   Forberg J, 2019, PROC HUMCENTEREDMACH
   Furnkranz J., 2012, Foundations of rule learning
   Giarratano J.C., 2005, EXPERT SYSTEMS PRINC
   GIGERENZER G, 1995, PSYCHOL REV, V102, P684, DOI 10.1037/0033-295X.102.4.684
   Gilbreth FrankB., 1921, Process Charts: First Steps in Finding the One Best Way to Do Work
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Guerra-Gómez JA, 2013, IEEE T VIS COMPUT GR, V19, P2566, DOI 10.1109/TVCG.2013.231
   Welling SH, 2016, Arxiv, DOI arXiv:1605.09196
   Handa H, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114555
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holten D, 2008, COMPUT GRAPH FORUM, V27, P759, DOI 10.1111/j.1467-8659.2008.01205.x
   Hornbaek K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5040, DOI 10.1145/3025453.3025765
   Hostettler IC, 2018, J NEUROSURG, V129, P1499, DOI 10.3171/2017.7.JNS17677
   Hu XY, 2019, ADV NEUR IN, V32
   Huang YF, 2019, J VISUAL-JAPAN, V22, P125, DOI 10.1007/s12650-018-0514-2
   Ilczuk G, 2007, LECT NOTES ARTIF INT, V4482, P371
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Jia SC, 2020, J VISUAL-JAPAN, V23, P141, DOI 10.1007/s12650-019-00607-z
   Jianchao Han, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P244
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Kagan R, 2020, ACTA ORTHOP, V91, P171, DOI 10.1080/17453674.2020.1716295
   Kandogan E., 2000, P IEEE S INF VIS LAT, P9
   Ke GL, 2017, ADV NEUR IN, V30
   Keefer D.L., 2002, SUMMARY DECISION ANA
   Keim D. A., 2010, MASTERING INFORM AGE
   KEIM DA, 1994, IEEE COMPUT GRAPH, V14, P40, DOI 10.1109/38.310723
   Kingsford C, 2008, NAT BIOTECHNOL, V26, P1011, DOI 10.1038/nbt0908-1011
   Kotsiantis SB, 2013, ARTIF INTELL REV, V39, P261, DOI 10.1007/s10462-011-9272-4
   Kreiser J, 2018, IEEE T VIS COMPUT GR, V24, P873, DOI 10.1109/TVCG.2017.2744299
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Leake D.B., 2001, INT ENCY SOCIAL BEHA, P12117, DOI [DOI 10.1016/B0-08-043076-7/00545-3, 10.1016/B0-08-043076-7/00545-3]
   Lee T, 2016, Arxiv, DOI arXiv:1610.05463
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li KQ, 2015, Arxiv, DOI arXiv:1503.00202
   Liu B, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P615
   Liu DY, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA'04), P280
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu Y, 2007, LECT NOTES COMPUT SC, V4551, P92
   Liu Y, 2007, INT J HUM-COMPUT ST, V65, P95, DOI 10.1016/j.ijhcs.2006.07.005
   Liu Y, 2007, THEOR ISS ERGON SCI, V8, P63, DOI 10.1080/14639220500284371
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Luan SH, 2011, PSYCHOL REV, V118, P316, DOI 10.1037/a0022684
   May T, 2008, COMPUT GRAPH FORUM, V27, P911, DOI 10.1111/j.1467-8659.2008.01224.x
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Moreno-Torres JG, 2012, PATTERN RECOGN, V45, P521, DOI 10.1016/j.patcog.2011.06.019
   Mott D, 2019, Arxiv, DOI arXiv:1909.05644
   Moussaïd M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078433
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Muller N.H., 2017, Int. J. Adv. Softw, V10, P385
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Neth H, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.567817
   Neumann J. V., 1944, Theory of Games and Economic Behavior
   Nguyen TD, 2000, PROC INT C TOOLS ART, P28, DOI 10.1109/TAI.2000.889842
   Niemann U, 2014, EXPERT SYST APPL, V41, P5405, DOI 10.1016/j.eswa.2014.02.040
   Padua L, 2014, COMPUT GRAPH-UK, V41, P99, DOI 10.1016/j.cag.2014.02.004
   Park Yubin, 2016, P INT C MACH LEARN
   Parr T, VISUALIZE DECISION T
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pham K. N, 2008, PROC INT S APPL STOC, P152
   Phillips ND, 2017, JUDGM DECIS MAK, V12, P344
   Podgorelec Vili, 2002, J Med Syst, V26, P445, DOI 10.1023/A:1016409317640
   POULET F, 2002, P VDM ECML PKDD 2002, P67
   Provost F., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P43
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   QuinoneroCandela J, 2009, NEURAL INF PROCESS S, P1
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L., 2015, Data Mining With Decision Trees, V2
   Rudin C, 2019, TUTS OPERAT RES, DOI DOI 10.1287/EDUC.2019.0200
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Rudin C, 2018, MATH PROGRAM COMPUT, V10, P659, DOI 10.1007/s12532-018-0143-8
   Sacha D., 2016, 2016 European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN), P641
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sakurai D, 2016, IEEE T VIS COMPUT GR, V22, P945, DOI 10.1109/TVCG.2015.2467433
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Stasko J, 2000, INT J HUM-COMPUT ST, V53, P663, DOI 10.1006/ijhc.2000.0420
   Steele K., 2016, STANFORD ENCY PHILOS
   Stiglic G, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033812
   Sydow JF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100736
   Szücs D, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P190, DOI 10.1109/SNAMS.2018.8554961
   Tam GKL, 2011, COMPUT GRAPH FORUM, V30, P901, DOI 10.1111/j.1467-8659.2011.01939.x
   Tam GKL, 2017, IEEE T VIS COMPUT GR, V23, P71, DOI 10.1109/TVCG.2016.2598829
   Tan J. H., 2018, EVOLUTIONARY BEHAV S, DOI [10.1037/ebs0000114, DOI 10.1037/EBS0000114]
   Tan JH, 2017, EVOL HUM BEHAV, V38, P27, DOI 10.1016/j.evolhumbehav.2016.06.004
   Tanner L, 2008, PLOS NEGLECT TROP D, V2, DOI 10.1371/journal.pntd.0000196
   Teoh S.T., 2003, 9 ACM SIGKDD INT C K, P667
   Teoh ST, 2003, SIAM PROC S, P178
   Tukey J. W., 1977, EXPLORATORY DATA ANA, V2
   Urbanek S., 2003, Proceedings of the Joint Statistical Meetings
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Wang J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P697, DOI 10.1109/ICDM.2002.1184032
   Wang T, 2017, J MACH LEARN RES, V18, P1
   Ward M.O., 2015, INTERACTIVE DATA VIS
   Ware M, 2001, INT J HUM-COMPUT ST, V55, P281, DOI 10.1006/ijhc.2001.0499
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Wlodyka A, 2008, COMPUTERS IN CARDIOLOGY 2008, VOLS 1 AND 2, P645, DOI 10.1109/CIC.2008.4749124
   Xie C, 2014, IEEE T VIS COMPUT GR, V20, P1743, DOI 10.1109/TVCG.2014.2346913
   Xu YH, 2007, LECT NOTES ARTIF INT, V4682, P1172
   Zhang JT, 2009, COMPUT GEOSCI-UK, V35, P1827, DOI 10.1016/j.cageo.2009.02.006
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 143
TC 10
Z9 10
U1 4
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2022
VL 28
IS 9
BP 3307
EP 3323
DI 10.1109/TVCG.2020.3045560
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3K0HP
UT WOS:000833767700018
PM 33439846
OA Green Published
DA 2024-11-06
ER

PT J
AU Krishnamurthy, VR
   Akleman, E
   Subramanian, SG
   Ebert, M
   Cui, JQ
   Fu, CA
   Starrett, C
AF Krishnamurthy, Vinayak R.
   Akleman, Ergun
   Subramanian, Sai Ganesh
   Ebert, Matthew
   Cui, Jiaqi
   Fu, Chia-An
   Starrett, Courtney
TI Geometrically Interlocking Space-Filling Tiling Based on Fabric Weaves
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Fabrics; Weaving; Shape; Yarn; Three-dimensional displays; Fabrication;
   Visualization; Space-filling shapes; 3D tile design; geometric
   interlocking; fabric weave; 3D printing; computational fabrication
ID REGULAR MAPS; CATALOG; DESIGN
AB In this article, we introduce a framework for the geometric design and fabrication of a family of geometrically interlocking space-filling shapes, which we call woven tiles. Our framework is based on a unique combination of (1) Voronoi partitioning of space using curve segments as the Voronoi sites and (2) the design of these curve segments based on weave patterns closed under symmetry operations. The underlying weave geometry provides an interlocking property to the tiles and the closure property under symmetry operations ensure single tile can fill space. In order to demonstrate this general framework, we focus on specific symmetry operations induced by fabric weaving patterns. We specifically showcase the design and fabrication of woven tiles on flat and curved domains by using the most common 2-fold fabrics, namely, plain, twill, and satin weaves. We further evaluate and compare the mechanical behavior of the so created woven tiles through finite element analysis.
C1 [Krishnamurthy, Vinayak R.; Subramanian, Sai Ganesh; Ebert, Matthew] Texas A&M Univ, J Mike Walker 66 Dept Mech Engn, College Stn, TX 77843 USA.
   [Krishnamurthy, Vinayak R.; Akleman, Ergun] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.
   [Akleman, Ergun; Cui, Jiaqi; Fu, Chia-An; Starrett, Courtney] Texas A&M Univ, Dept Visualizat, College Stn, TX 77843 USA.
C3 Texas A&M University System; Texas A&M University College Station; Texas
   A&M University System; Texas A&M University College Station; Texas A&M
   University System; Texas A&M University College Station
RP Krishnamurthy, VR (corresponding author), Texas A&M Univ, J Mike Walker 66 Dept Mech Engn, College Stn, TX 77843 USA.; Krishnamurthy, VR (corresponding author), Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX 77843 USA.
EM vinayak@tamu.edu; ergun.akleman@gmail.com; sai3097ganesh@tamu.edu;
   matt_ebert@tamu.edu; giaqi96@tamu.edu; sqree@tamu.edu;
   cstarrett@tamu.edu
RI cui, jiaqi/HLX-3700-2023; Ebert, Matthew/G-3964-2015
OI Akleman, Ergun/0000-0003-3618-4166; Krishnamurthy,
   Vinayak/0000-0001-6434-2577
FU Texas A&M Engineering Experiment Station
FX This work was supported in part by the Texas A&M Engineering Experiment
   Station and the J. Mike Walker '66 Department of Mechanical Engineering
   at Texas A&M University, College Station. The authors would like to
   thank the reviewers for their valuable feedback. They would also like to
   thank Dr. Matt Pharr and Dr. Yuri Estrin for their advise on FEA-based
   failure analysis.
CR Adriaenssens S., 2014, Shell Structures for Architecture: Form Finding and Optimization, V1
   Akleman E, 2005, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P44, DOI 10.1109/SMI.2005.40
   Akleman E., 2009, ACM T GRAPHIC, V28
   Akleman E, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P171
   Akleman E, 2020, COMPUT GRAPH-UK, V89, P156, DOI 10.1016/j.cag.2020.05.016
   Akleman E, 2015, DISCRETE APPL MATH, V193, P61, DOI 10.1016/j.dam.2015.04.015
   Akleman E, 2015, COMPUT GRAPH-UK, V46, P306, DOI 10.1016/j.cag.2014.09.020
   Akleman E, 2011, COMPUT GRAPH-UK, V35, P623, DOI 10.1016/j.cag.2011.03.003
   Baverel O., 2000, Ph.D. Thesis
   Baverel O., 2000, INT J SPACE STRUCT, V15, P155, DOI DOI 10.1260/0266351001495053
   Bjorner A., 1999, Oriented Matroids
   Carlesso M, 2012, SCRIPTA MATER, V66, P483, DOI 10.1016/j.scriptamat.2011.12.022
   Conder M, 2001, J COMB THEORY B, V81, P224, DOI 10.1006/jctb.2000.2008
   Delaunay BN, 1961, Tr Mat Inst Steklova, V64, P28
   Douthe C, 2009, COMPUT STRUCT, V87, P1296, DOI 10.1016/j.compstruc.2009.06.011
   Dyskin AV, 2001, SCRIPTA MATER, V44, P2689, DOI 10.1016/S1359-6462(01)00968-X
   Estrin Y, 2011, MAT SCI ENG C-MATER, V31, P1189, DOI 10.1016/j.msec.2010.11.011
   Evans Robin., 2000, The Projective Cast
   Fallacara Giuseppe., 2009, Proceedings of the Third International Congress on Construction History, P553
   Fernando S., 2015, P FUT ARCH RES C
   Fleury F., 2009, P 3 INT C CONSTR HIS, P1
   Fu CW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766892
   GRUNBAUM B, 1986, DISCRETE MATH, V60, P155, DOI 10.1016/0012-365X(86)90010-5
   GRUNBAUM B, 1985, ANN NY ACAD SCI, V440, P279, DOI 10.1111/j.1749-6632.1985.tb14560.x
   GRUNBAUM B, 1988, AM MATH MON, V95, P5, DOI 10.2307/2323440
   Grunbaum B., 1987, Tilings and patterns
   Grunbaum B, 1980, Math Mag, V53, P139
   Hu SY, 2012, COMPUT GRAPH-UK, V36, P455, DOI 10.1016/j.cag.2012.03.025
   Kita N, 2021, VISUAL COMPUT, V37, P777, DOI 10.1007/s00371-020-01968-5
   Krishnamurthy VR, 2020, Graphics interface, P286
   Loeb A.L., 1991, Space Struct, P127, DOI [10.1007/978-1-4612-0437-416, DOI 10.1007/978-1-4612-0437-416]
   Ng SP, 2000, COMPOS PART B-ENG, V31, P113, DOI 10.1016/S1359-8368(99)00078-5
   PENNE R, 1993, GEOMETRIAE DEDICATA, V45, P49, DOI 10.1007/BF01667403
   Qing Xing, 2010, Proceedings of the Shape Modeling International (SMI 2010), P90, DOI 10.1109/SMI.2010.13
   RICHTERGEBERT J, 1993, DISCRETE COMPUT GEOM, V10, P287, DOI 10.1007/BF02573982
   Roelofs Rinus, 2007, International Journal of Space Structures, V22, P191, DOI 10.1260/026635107782218840
   Schmitt MW, 2016, Ph.D. thesis]
   Skouras M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818128
   Song P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130803
   Song P, 2015, COMPUT AIDED GEOM D, V35-36, P137, DOI 10.1016/j.cagd.2015.03.020
   Song P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461915
   Song P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366147
   Subramanian SG, 2019, COMPUT GRAPH-UK, V82, P73, DOI 10.1016/j.cag.2019.05.021
   Tessmann O, 2013, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2013), P469
   van Wijk JJ, 2014, IEEE T VIS COMPUT GR, V20, P2614, DOI 10.1109/TVCG.2014.2352952
   van Wijk JJ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531355
   Wang ZQ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356489
   Wang ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275034
   Weizmann M, 2016, AUTOMAT CONSTR, V72, P18, DOI 10.1016/j.autcon.2016.05.014
   Xin SQ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964992
NR 50
TC 5
Z9 6
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3391
EP 3404
DI 10.1109/TVCG.2021.3065457
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100006
PM 33705320
DA 2024-11-06
ER

PT J
AU Nabata, K
   Iwasaki, K
AF Nabata, Kosuke
   Iwasaki, Kei
TI Adaptive Irradiance Sampling for Many-Light Rendering of Subsurface
   Scattering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Scattering; Three-dimensional displays;
   Monte Carlo methods; Sampling methods; Error analysis; Tuning;
   Subsurface scattering; BSSRDF; adaptive sampling; many-lights
ID DIFFUSION
AB Rendering a translucent material involves integrating the product of the transmittance-weighted irradiance and the BSSRDF over the surface of it. In previous methods, this spatial integral was computed by creating a dense distribution of discrete points over the surface or by importance-sampling based on the BSSRDF. Both of these approaches necessitate specifying the number of samples, which affects both the quality and the computation time for rendering. An insufficient number of samples leads to noise and artifacts in the rendered image and an excessive number results in a prohibitively long rendering time. In this article, we propose an error estimation method for translucent materials in a many-light rendering framework. Our adaptive sampling can automatically determine the number of samples so that the estimated relative error of each pixel intensity is less than a user-specified threshold. We also propose an efficient method to generate the sampling points that make large contributions to the pixel intensity taking into account the BSSRDF. This enables us to use a simple uniform sampling, instead of costly importance sampling based on the BSSRDF. The experimental results show that our method can accurately estimate the error. In addition, in comparison with the previous methods, our sampling method achieves better estimation accuracy in equal-time.
C1 [Nabata, Kosuke; Iwasaki, Kei] Wakayama Univ, Dept Syst Engn, Wakayama 6408510, Japan.
   [Iwasaki, Kei] Prometech CG Res, Tokyo 1130033, Japan.
C3 Wakayama University
RP Iwasaki, K (corresponding author), Wakayama Univ, Dept Syst Engn, Wakayama 6408510, Japan.
EM s141044@gmail.com; iwasaki@wakayama-u.ac.jp
RI Iwasaki, Kei/GNH-6504-2022
OI Iwasaki, Kei/0000-0002-5235-536X
FU JSPS KAKENHI [15H05924, 18H03348]; Grants-in-Aid for Scientific Research
   [21H05826] Funding Source: KAKEN
FX The authors would like to thank the anonymous reviewers for their
   constructive suggestions and comments. This work was supported in part
   by JSPS KAKENHI under Grants 15H05924 and 18H03348.
CR Arbree A, 2008, COMPUT GRAPH FORUM, V27, P507, DOI 10.1111/j.1467-8659.2008.01148.x
   Bus N, 2015, COMPUT GRAPH FORUM, V34, P561, DOI 10.1111/cgf.12584
   Chaitanya C.R. A., 2018, Proceedings of the Eurographics Symposium on Rendering: Experimental Ideas Implementations, SR'18, P23, DOI DOI 10.2312/SRE.20181169
   d'Eon E, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964951
   Dachsbacher C, 2014, COMPUT GRAPH FORUM, V33, P88, DOI 10.1111/cgf.12256
   Donner C, 2005, ACM T GRAPHIC, V24, P1032, DOI 10.1145/1073204.1073308
   Frederickx R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073681
   Frisvad JR, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682629
   Grinstead C.M., 1997, Introduction to probability
   Habel R, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/cgf.12148
   Hasan M, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239477
   Huo YC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818120
   Jensen HW, 2001, COMP GRAPH, P511, DOI 10.1145/383259.383319
   Jensen HW, 2002, ACM T GRAPHIC, V21, P576, DOI 10.1145/566570.566619
   K ~riv ~anek J., 2013, PROC ACM SIGGRAPH CO
   Keller A., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P49, DOI 10.1145/258734.258769
   King A., 2013, P ACM SIGGRAPH TALKS, P48
   Milaenen D., 2019, PROC 45 GRAPH INTERF
   Nabata K, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.13040
   Ou JW, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024213
   Sakai H, 2019, COMPUT VIS MEDIA, V5, P151, DOI 10.1007/s41095-019-0137-0
   Tokuyoshi Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323018
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   Walter B, 2006, ACM T GRAPHIC, V25, P1081, DOI 10.1145/1141911.1141997
   Walter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185555
   Wu YT, 2015, IEEE T VIS COMPUT GR, V21, P363, DOI 10.1109/TVCG.2014.2385059
   Wu YT, 2013, IEEE T VIS COMPUT GR, V19, P1566, DOI 10.1109/TVCG.2013.21
NR 27
TC 2
Z9 2
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3324
EP 3335
DI 10.1109/TVCG.2021.3066640
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100001
PM 33729941
DA 2024-11-06
ER

PT J
AU Sakano, Y
   Ando, H
AF Sakano, Yuichi
   Ando, Hiroshi
TI Conditions of a Multi-View 3D Display for Accurate Reproduction of
   Perceived Glossiness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Two dimensional displays; Head; Crosstalk;
   Tracking; Visualization; Visual systems; Autostereoscopic display; head
   motion; stereopsis; material perception; perceptual validation; human
   factors
ID MOTION IN-DEPTH; 3-DIMENSIONAL SHAPE; STILL IMAGES; CROSS-TALK;
   PERCEPTION; ILLUMINATION; HIGHLIGHTS; INFORMATION; TELEVISION;
   SMOOTHNESS
AB Visualizing objects as they are perceived in the real world is often critical in our daily experiences. We previously focused on objects' surface glossiness visualized with a 3D display and found that a multi-view 3D display reproduces perceived glossiness more accurately than a 2D display. This improvement of glossiness reproduction can be explained by the fact that a glossy surface visualized by a multi-view 3D display appropriately provides luminance differences between the two eyes and luminance changes accompanying the viewer's lateral head motion. In the present study, to determine the requirements of a multi-view 3D display for the accurate reproduction of perceived glossiness, we developed a simulator of a multi-view 3D display to independently and simultaneously manipulate the viewpoint interval and the magnitude of the optical inter-view crosstalk. Using the simulator, we conducted a psychophysical experiment and found that glossiness reproduction is most accurate when the viewpoint interval is small and there is just a small (but not too small) amount of crosstalk. We proposed a simple yet perceptually valid model that quantitatively predicts the reproduction accuracy of perceived glossiness.
C1 [Sakano, Yuichi] Natl Inst Informat & Commun Technol, Ctr Informat & Neural Networks CiNet, Suita, Osaka 5650871, Japan.
   [Sakano, Yuichi] Osaka Univ, Suita, Osaka 5650871, Japan.
   [Ando, Hiroshi] Natl Inst Informat & Commun Technol, Ctr Informat & Neural Networks CiNet, Kyoto 6190289, Japan.
   [Ando, Hiroshi] Osaka Univ, Kyoto 6190289, Japan.
C3 National Institute of Information & Communications Technology (NICT) -
   Japan; Osaka University; National Institute of Information &
   Communications Technology (NICT) - Japan; Osaka University
RP Sakano, Y (corresponding author), Natl Inst Informat & Commun Technol, Ctr Informat & Neural Networks CiNet, Suita, Osaka 5650871, Japan.; Sakano, Y (corresponding author), Osaka Univ, Suita, Osaka 5650871, Japan.
EM yuichi@nict.go.jp; h-ando@nict.go.jp
RI Sakano, Yuichi/D-1955-2011; Ando, Hiroshi/A-8570-2015
OI Sakano, Yuichi/0000-0002-4106-6386
CR Akao Y, 2004, J IMAGING SCI TECHN, V48, P227
   Allison RS, 2007, J IMAGING SCI TECHN, V51, P317, DOI 10.2352/J.ImagingSci.Technol.(2007)51:4(317)
   Anderson BL, 2009, J VISION, V9, DOI 10.1167/9.11.10
   Ando H, 2014, 2014 IEEE 3RD GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P252, DOI 10.1109/GCCE.2014.7031269
   Banks MS, 2016, ANNU REV VIS SCI, V2, P397, DOI 10.1146/annurev-vision-082114-035800
   Banks MS, 2012, SMPTE MOTION IMAG J, V121, P24, DOI 10.5594/j18173
   BECK J, 1981, PERCEPT PSYCHOPHYS, V30, P407, DOI 10.3758/BF03206160
   Berzhanskaya J, 2005, PERCEPTION, V34, P565, DOI 10.1068/p5401
   BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0
   Blinn J.F., 1977, P 4 ANN C COMPUTER G, P192, DOI [DOI 10.1145/965141.563893, 10.1145/563858.563893]
   Boev A., 2007, 3DTV Conference, 2007, P1
   Boev A, 2010, J SOC INF DISPLAY, V18, P686, DOI 10.1889/JSID18.9.686
   Braspenning Ralph, 2005, 2005 13th European Signal Processing Conference, P1
   Chen WL, 2010, J SOC INF DISPLAY, V18, P647, DOI 10.1889/JSID18.9.647
   Cheng-Hao Ko A., 2015, 2015 11th Conference on Lasers and Electro-Optics Pacific Rim (CLEO-PR). Proceedings, P1, DOI 10.1109/CLEOPR.2015.7375875
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Doerschner K, 2011, CURR BIOL, V21, P2010, DOI 10.1016/j.cub.2011.10.036
   Dumont-Bcle Patricia., 2001, Proceedings of the Driving Simulation Conference, P123
   Ferwerda JA, 2015, VISION RES, V109, P166, DOI 10.1016/j.visres.2014.10.016
   Fleming RW, 2015, VISION RES, V115, P157, DOI 10.1016/j.visres.2015.08.006
   Fleming RW, 2003, J VISION, V3, P347, DOI 10.1167/3.5.3
   Georgieva SS, 2008, CEREB CORTEX, V18, P2416, DOI 10.1093/cercor/bhn002
   Howard IP., 1995, Binocular vision and stereopsis
   Howarth PA, 2011, OPHTHAL PHYSL OPT, V31, P111, DOI 10.1111/j.1475-1313.2011.00822.x
   Iwasawa S., 2012, PROC INT C 3D SYS AP, P105
   JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x
   Kaptein R, 2007, SID INT SYMP DIG TEC, V38, P1220, DOI 10.1889/1.2785530
   Kawakita Masahiro, 2010, Journal of the National Institute of Information and Communications Technology, V57, P47
   Kawakita M, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.6.061610
   Kersten MA, 2006, IEEE T VIS COMPUT GR, V12, P1117, DOI 10.1109/TVCG.2006.139
   Kersten-Oertel M, 2014, IEEE T VIS COMPUT GR, V20, P391, DOI 10.1109/TVCG.2013.240
   Kim D., 2015, OPT ENG, V54, P1
   Kim J, 2017, IEEE T IMAGE PROCESS, V26, P4885, DOI 10.1109/TIP.2017.2717180
   Kim J, 2012, NAT NEUROSCI, V15, P1590, DOI 10.1038/nn.3221
   Komatsu H, 2018, NEUROSCIENCE, V392, P329, DOI 10.1016/j.neuroscience.2018.09.001
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Kooima, 2009, GEN PERSP PROJ, P1
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Maloney LT, 2010, J VISION, V10, DOI 10.1167/10.9.19
   Marlow PJ, 2016, J VISION, V16, DOI 10.1167/16.1.5
   Marlow PJ, 2015, VISION RES, V115, P199, DOI 10.1016/j.visres.2015.05.003
   Marlow PJ, 2012, CURR BIOL, V22, P1909, DOI 10.1016/j.cub.2012.08.009
   Mausfeld R, 2014, I-PERCEPTION, V5, P1, DOI 10.1068/i0603
   Mingolla E, 2001, P SOC PHOTO-OPT INS, V4299, P302, DOI 10.1117/12.429499
   Mizushina H, 2016, J SOC INF DISPLAY, V24, P747, DOI 10.1002/jsid.520
   Motoyoshi I, 2007, NATURE, V447, P206, DOI 10.1038/nature05724
   Nefs HT, 2008, J VISION, V8, DOI 10.1167/8.11.11
   Nefs HT, 2006, ACTA PSYCHOL, V121, P297, DOI 10.1016/j.actpsy.2005.08.001
   Nishida S, 1998, J OPT SOC AM A, V15, P2951, DOI 10.1364/JOSAA.15.002951
   Norman JF, 2004, PSYCHOL SCI, V15, P565, DOI 10.1111/j.0956-7976.2004.00720.x
   Obein G, 2004, J VISION, V4, P711, DOI 10.1167/4.9.4
   Oguma M., 2008, P IDW, V15, P1087
   Palmisano S, 2002, PERCEPTION, V31, P463, DOI 10.1068/p3321
   Palmisano S, 1996, PERCEPT PSYCHOPHYS, V58, P1168, DOI 10.3758/BF03207550
   Pastoor S., 1989, Proceedings of the S.I.D., V30, P217
   Read JCA, 2014, ERGONOMICS, V57, P1140, DOI 10.1080/00140139.2014.914581
   Ribeiro FML, 2018, IEEE T MULTIMEDIA, V20, P1, DOI 10.1109/TMM.2017.2714425
   ROGERS B, 1979, PERCEPTION, V8, P125, DOI 10.1068/p080125
   Runde D, 2000, IEEE T CIRC SYST VID, V10, P376, DOI 10.1109/76.836282
   Sakano Y., 2013, P PS 18 OECC, P1
   Sakano Y, 2018, INT J MODEL SIMUL SC, V9, DOI 10.1142/S1793962318400093
   Sakano Y, 2014, J VISION, V14, DOI 10.1167/14.8.21
   Sakano Y, 2012, J SOC INF DISPLAY, V20, P286, DOI 10.1889/JSID20.5.286
   Sakano Y, 2012, J VISION, V12, DOI 10.1167/12.1.11
   Sakano Y, 2010, J VISION, V10, DOI 10.1167/10.9.15
   Salmimaa M., 2014, P SID S DIG TECH PAP, V45, P801
   Salmimaa M, 2009, J SOC INF DISPLAY, V17, P449, DOI 10.1889/JSID17.5.449
   Seuntiëns PJH, 2005, DISPLAYS, V26, P177, DOI 10.1016/j.displa.2005.06.005
   Shioiri S, 2000, VISION RES, V40, P2565, DOI 10.1016/S0042-6989(00)00130-9
   Speranza F, 2005, P SOC PHOTO-OPT INS, V5664, P72, DOI 10.1117/12.587170
   Sugawara M., 2004, BROADCAST TECHNOL, P5
   Sugawara M, 2013, ITE TRANS MEDIA TECH, V1, P27, DOI 10.3169/mta.1.27
   Sun HC, 2016, J NEUROPHYSIOL, V115, P2779, DOI 10.1152/jn.00829.2015
   Sun HC, 2015, VISION RES, V109, P149, DOI 10.1016/j.visres.2014.11.012
   Takaki Y, 2005, IDW/AD '05: PROCEEDINGS OF THE 12TH INTERNATIONAL DISPLAY WORKSHOPS IN CONJUNCTION WITH ASIA DISPLAY 2005, VOLS 1 AND 2, P1777
   Takaki Y, 2012, OPT EXPRESS, V20, P27180, DOI 10.1364/OE.20.027180
   Tam WJ, 2011, IEEE T BROADCAST, V57, P335, DOI 10.1109/TBC.2011.2125070
   Todd JT, 2004, PSYCHOL SCI, V15, P33, DOI 10.1111/j.0963-7214.2004.01501006.x
   TODD JT, 1983, J EXP PSYCHOL HUMAN, V9, P583, DOI 10.1037/0096-1523.9.4.583
   Tsirlin I, 2012, PROC SPIE, V8288, DOI 10.1117/12.906751
   Tsirlin I, 2011, IEEE T BROADCAST, V57, P445, DOI 10.1109/TBC.2011.2105630
   Tsuchida M, 2001, OPT REV, V8, P444, DOI 10.1007/BF02931733
   Wada A, 2014, NEUROIMAGE, V98, P243, DOI 10.1016/j.neuroimage.2014.05.001
   Wang LL, 2010, J SOC INF DISPLAY, V18, P405, DOI 10.1889/JSID18.6.405
   Wang PC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013032
   Wendt G, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519846133
   Wendt G, 2010, J VISION, V10, DOI 10.1167/10.9.7
   Wendt G, 2008, J VISION, V8, DOI 10.1167/8.1.14
   Wijntjes MWA, 2010, J VISION, V10, DOI 10.1167/10.9.13
   Woods AJ, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.4.040902
   Xu R., 2015, PROC SIGGRAPH ASIA 2, P1
   Yamamoto S, 2012, J SOC INF DISPLAY, V20, P94, DOI 10.1889/JSID20.2.94
   Yuuki A, 2010, J SOC INF DISPLAY, V18, P483, DOI 10.1889/JSID18.7.483
NR 95
TC 3
Z9 3
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3336
EP 3350
DI 10.1109/TVCG.2021.3063182
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100002
PM 33651695
OA hybrid
DA 2024-11-06
ER

PT J
AU Ajani, K
   Lee, E
   Xiong, C
   Knaflic, CN
   Kemper, W
   Franconeri, S
AF Ajani, Kiran
   Lee, Elsie
   Xiong, Cindy
   Knaflic, Cole Nussbaumer
   Kemper, William
   Franconeri, Steven
TI Declutter and Focus: Empirically Evaluating Design Guidelines for
   Effective Data Communication
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Guidelines; Image color analysis; Clutter; Task
   analysis; Bars; Visualization; Data visualization; data communication;
   data storytelling; empirical evaluation; visualization aesthetics
ID DATA-INK RATIO; VISUALIZATION
AB Data visualization design has a powerful effect on which patterns we see as salient and how quickly we see them. The visualization practitioner community prescribes two popular guidelines for creating clear and efficient visualizations: declutter and focus. The declutter guidelines suggest removing non-critical gridlines, excessive labeling of data values, and color variability to improve aesthetics and to maximize the emphasis on the data relative to the design itself. The focus guidelines for explanatory communication recommend including a clear headline that describes the relevant data pattern, highlighting a subset of relevant data values with a unique color, and connecting those values to written annotations that contextualize them in a broader argument. We evaluated how these recommendations impact recall of the depicted information across cluttered, decluttered, and decluttered+focused designs of six graph topics. Undergraduate students were asked to redraw previously seen visualizations, to recall their topics and main conclusions, and to rate the varied designs on aesthetics, clarity, professionalism, and trustworthiness. Decluttering designs led to higher ratings on professionalism, and adding focus to the design led to higher ratings on aesthetics and clarity. They also showed better memory for the highlighted pattern in the data, as reflected across redrawings of the original visualization and typed free-response conclusions, though we do not know whether these results would generalize beyond our memory-based tasks. The results largely empirically validate the intuitions of visualization designers and practitioners. The stimuli, data, analysis code, and Supplementary Materials are available at https://osf.io/wes9u/.
C1 [Ajani, Kiran] Case Western Reserve Univ, Sch Med, Cleveland, OH 44106 USA.
   [Lee, Elsie] Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA.
   [Xiong, Cindy] UMass Amherst, CICS, Amherst, MA 01003 USA.
   [Knaflic, Cole Nussbaumer] Storytelling Data, Milwaukee, WI 53202 USA.
   [Kemper, William; Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
C3 University System of Ohio; Case Western Reserve University; University
   of Michigan System; University of Michigan; University of Massachusetts
   System; University of Massachusetts Amherst; Northwestern University
RP Ajani, K (corresponding author), Case Western Reserve Univ, Sch Med, Cleveland, OH 44106 USA.
EM kiran.ajani@case.edu; elsie.lee@umich.edu; cxiong@u.northwestern.edu;
   cole@storytellingwithdata.com; wlkemper@gmail.com;
   franconeri@northwestern.edu
RI Lee-Robbins, Elsie/IUP-2028-2023
OI Ajani, Kiran/0000-0001-6087-5325; Franconeri,
   Steven/0000-0001-5244-9764; Xiong Bearfield, Cindy/0000-0002-1451-4083
FU National Science Foundation [IIS-1901485]
FX The authors would like to thank Evan Anderson for assisting with blind
   qualitative coding, Evan Lee for digitizing redrawn graphs, and Caitlyn
   McColeman and Miriam Novack for assisting on the inter-rater reliability
   analysis. The authors would also like to thank Nicole Jardine and
   Cristina Ceja for their helpful comments on this article. This work was
   supported by the National Science Foundation under Grant IIS-1901485.
CR Andrews R., 2019, Info We Trust: How to Inspire the World With Data
   [Anonymous], YOU PROBABLY NEED GR
   [Anonymous], 1985, APPL OPTICS
   [Anonymous], STORYTELLING DATA
   [Anonymous], 1990, Envisioning information
   [Anonymous], 2014, P 2014 9 INT MASONRY
   [Anonymous], 2010, LME4 MIXED EFFECTS M
   Bartram L, 2011, IEEE T VIS COMPUT GR, V17, P1942, DOI 10.1109/TVCG.2011.242
   Bartram L, 2011, IEEE T VIS COMPUT GR, V17, P1444, DOI 10.1109/TVCG.2010.237
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bates D, 2005, FITTING LINEAR MIXED, V5, P27, DOI DOI 10.1159/000323281
   Berinato S., 2016, Good charts: The HBR guide to making smarter, more persuasive data visualizations
   Blasio AJ, 2002, INT J IND ERGONOM, V30, P89, DOI 10.1016/S0169-8141(02)00074-4
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Cairo A., 2012, The Functional Art: An Introduction to Information Graph. and Visualization
   Cairo A., 2016, The truthful art: Data, charts, and maps for communication, New Riders
   Cam oes J., 2016, DATA WORK BEST PRACT
   Doumont Jean-luc., 2009, Trees, Maps, and Theorems: Effective Communication for Rational Minds
   Duarte N., 2019, Data Story. Explain Data and Inspire Action through Story
   Duarte Nancy., 2008, Slide: ology: The art and science of creating great presentations
   Dykes B., 2019, Effective data storytelling
   Evergreen S.D., 2018, Presenting data effectiviely: Communicating your findings for maximum impact, V2nd
   Evergreen S. DH, 2019, EFFECTIVE DATA VIS R
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Few S., 2013, Information Dashboard Design: The Effective Visual Communication of Data
   Few S, 2009, ANALYTICS, Patent No. 9780970601988
   Few Stephen, 2004, SHOW ME NUMBERS
   Gabrielle B.R., 2010, Speaking PowerPoint the new language of business: The business leader's guide to boardroom-style slides
   GILLAN DJ, 1994, HUM FACTORS, V36, P619, DOI 10.1177/001872089403600405
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Helgeson R.D., 1993, ADA276274 AFB AIF FO
   Hill S., 2018, J INFORM SYSTEMS APP, V11, P34
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Inbar O., 2007, P ACM EUR C COGN ERG, P185, DOI DOI 10.1145/1362550.1362587
   Jones B., 2014, Communicating Data with Tableau: Designing, Developing, and Delivering Data Visualizations
   Jones B., 2019, Avoiding data pitfalls: how to steer clear of common blunders when working with data and presenting analysis and visualizations
   Kale A, 2020, Arxiv, DOI arXiv:2007.14516
   KELLY JD, 1989, JOURNALISM QUART, V66, P632, DOI 10.1177/107769908906600315
   Kirk A., 2012, Data Visualization: a successful design process
   KIRK A., 2016, DATA VISUALISATION H
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kosslyn S., 2010, BETTER POWERPOINT R
   Kriebel A., 2018, MAKEOVERMONDAY IMPRO
   Lima M., 2014, The Book of Trees: Visualizing Branches of Knowledge
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Meirelles Isabel, 2013, DESIGN INFORM INTRO
   Munzner T., 2014, VIS ANAL DESIGN
   Murray DG., 2013, Tableau your data!: fast and easy visual analysis with tableau software
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Nussbaumer Knaflic C., 2020, STORYTELLING DATA LE
   Parker I., 2001, The New Yorker, V28, P76
   Rougier NP, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003833
   RVAideMemoire, US
   Schwabish J.A., 2020, ELEVATE DEBATE MULTI
   Schwabish Jonathan., 2016, BETTER PRESENTATIONS
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Strauss A., 1994, HDB QUALITATIVE RES, P273, DOI DOI 10.1007/BF00988593
   Su YS, 2008, COMPUT STAT DATA AN, V52, P4594, DOI 10.1016/j.csda.2008.03.007
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tufte E.R., 2006, Visual Explanations
   VANESSEN DC, 1992, SCIENCE, V255, P419, DOI 10.1126/science.1734518
   Vora S., 2019, The Power of Data Storytelling
   Ware C, 2010, Visual thinking for design
   Ware C., 2019, Information Visualization: Perception for Design
   Wexler S., 2017, BIG BOOK DASHBOARDS
   Wong D., 2010, The Wall Street Journal Guide to Information Graphics
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yau N., 2013, DATA POINTS VISUALIZ
   [No title captured]
NR 74
TC 18
Z9 18
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3351
EP 3364
DI 10.1109/TVCG.2021.3068337
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100003
PM 33760737
OA Bronze
DA 2024-11-06
ER

PT J
AU Zheng, CW
   Xu, F
AF Zheng, Chengwei
   Xu, Feng
TI DTexFusion: Dynamic Texture Fusion Using a Consumer RGBD Sensor
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Geometry; Three-dimensional displays;
   Optimization; Dynamics; Image color analysis; Faces; Texture
   reconstruction; dynamic texture; novel view synthesis; 3D dynamic
   reconstruction
ID REGISTRATION; RECONSTRUCTION; SUPERRESOLUTION; GEOMETRY
AB In addition to 3D geometry, accurate representation of texture is important when digitizing real objects in virtual worlds. Based on a single consumer RGBD sensor, accurate texture representation for static objects can be realized by fusing multi-frame information; however, extending the process to dynamic objects, which typically have time-varying textures, is difficult. Thus, to address this problem, we propose a compact keyframe-based representation that decouples a dynamic texture into a basic static texture and a set of multiplicative changing maps. With this representation, the proposed method first aligns textures recorded from multiple keyframes with the reconstructed dynamic geometry of the object. Errors in the alignment and geometry are then compensated in an innovative iterative linear optimization framework. With the reconstructed texture, we then employ a scheme to synthesize the dynamic object from arbitrary viewpoints. By considering temporal and local pose similarities jointly, dynamic textures in all keyframes are fused to guarantee high-quality image generation. Experimental results demonstrate that the proposed method handles various dynamic objects, including faces, bodies, cloth, and toys. In addition, qualitative and quantitative comparisons demonstrate that the proposed method outperforms state-of-the-art solutions.
C1 [Zheng, Chengwei; Xu, Feng] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Xu, F (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM zhengcw18@gmail.com; xufeng2003@gmail.com
RI Zheng, Chengwei/HPC-8073-2023
OI Zheng, Chengwei/0000-0002-3657-0297
FU National Key R&D Program of China [2018YFA0704000]; NSFC [61822111,
   61727808]; Beijing Natural Science Foundation [JQ19015]
FX This work was supported by the National Key R&D Program of China under
   Grant 2018YFA0704000, the NSFC under Grants 61822111, 61727808 and
   Beijing Natural Science Foundation under Grant JQ19015.
CR Aganj Ehsan, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P468
   Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   [Anonymous], 2017, ACM Transactions on Graphics (TOG)
   [Anonymous], ACM SIGGRAPH
   Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346
   Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Boukhayma A, 2016, LECT NOTES COMPUT SC, V9905, P230, DOI 10.1007/978-3-319-46448-0_14
   Bozic A, 2020, PROC CVPR IEEE, P7000, DOI 10.1109/CVPR42600.2020.00703
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Callieri M, 2008, COMPUT GRAPH-UK, V32, P464, DOI 10.1016/j.cag.2008.05.004
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Casas D, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12296
   Chuang M, 2009, COMPUT GRAPH FORUM, V28, P1475, DOI 10.1111/j.1467-8659.2009.01524.x
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Corsini M, 2013, INT J COMPUT VISION, V102, P91, DOI 10.1007/s11263-012-0552-5
   Corsini M, 2009, COMPUT GRAPH FORUM, V28, P1755, DOI 10.1111/j.1467-8659.2009.01552.x
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Debevec P., 1996, P SIGGRAPH 96, P11, DOI DOI 10.1145/237170.237191
   Dellepiane M, 2012, IEEE T VIS COMPUT GR, V18, P463, DOI 10.1109/TVCG.2011.75
   Dou MS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130801
   Du RF, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190843
   Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x
   Franken T, 2005, VISUAL COMPUT, V21, P619, DOI 10.1007/s00371-005-0309-z
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x
   Goldlücke B, 2014, INT J COMPUT VISION, V106, P172, DOI 10.1007/s11263-013-0654-8
   Gotardo P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275073
   Hedman P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982420
   Johnson AE, 1999, IMAGE VISION COMPUT, V17, P135, DOI 10.1016/S0262-8856(98)00117-6
   Kim J, 2019, COMPUT GRAPH FORUM, V38, P697, DOI 10.1111/cgf.13872
   Lempitsky V, 2007, PROC CVPR IEEE, P829
   Lensch HPA, 2001, GRAPH MODELS, V63, P245, DOI 10.1006/gmod.2001.0554
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508407
   Li W, 2019, IEEE T VIS COMPUT GR, V25, P2296, DOI 10.1109/TVCG.2018.2831220
   Liu LY, 2012, COMPUT VIS IMAGE UND, V116, P25, DOI 10.1016/j.cviu.2011.07.009
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Martin-Brualla R, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275099
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ofek E, 1997, IEEE COMPUT GRAPH, V17, P18, DOI 10.1109/38.574667
   Pandey R, 2019, PROC CVPR IEEE, P9701, DOI 10.1109/CVPR.2019.00994
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Prada F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925967
   Pulli K, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P531, DOI 10.1109/3DIM.2005.65
   Pulli K, 2000, GRAPH MODELS, V62, P165, DOI 10.1006/gmod.1999.0519
   Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250
   Sinha SN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409112
   Stamos I, 2002, COMPUT VIS IMAGE UND, V88, P94, DOI 10.1006/cviu.2002.0963
   Tsiminaki V, 2014, PROC CVPR IEEE, P1502, DOI 10.1109/CVPR.2014.195
   Tung T, 2008, PROC CVPR IEEE, P2814
   Velho L, 2007, VISUAL COMPUT, V23, P621, DOI 10.1007/s00371-007-0150-7
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
   Wen Q, 2017, IEEE T VIS COMPUT GR, V23, P2586, DOI 10.1109/TVCG.2016.2641442
   Wu CL, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275101
   Wu HZ, 2016, IEEE T VIS COMPUT GR, V22, P2012, DOI 10.1109/TVCG.2015.2498617
   Zhang H, 2018, IEEE T VIS COMPUT GR, V24, P3137, DOI 10.1109/TVCG.2017.2786233
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
NR 62
TC 5
Z9 5
U1 2
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3365
EP 3375
DI 10.1109/TVCG.2021.3064846
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100004
PM 33687843
DA 2024-11-06
ER

PT J
AU Shu, YZ
   Yi, R
   Xia, MF
   Ye, ZP
   Zhao, W
   Chen, Y
   Lai, YK
   Liu, YJ
AF Shu, Yezhi
   Yi, Ran
   Xia, Mengfei
   Ye, Zipeng
   Zhao, Wang
   Chen, Yang
   Lai, Yu-Kun
   Liu, Yong-Jin
TI GAN-Based Multi-Style Photo Cartoonization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Generative adversarial networks; Semantics; Image edge
   detection; Training data; Generators; Computer architecture; Style
   transfer; cartoon styles; multi-style transfer; generative adversarial
   network
AB Cartoon is a common form of art in our daily life and automatic generation of cartoon images from photos is highly desirable. However, state-of-the-art single-style methods can only generate one style of cartoon images from photos and existing multi-style image style transfer methods still struggle to produce high-quality cartoon images due to their highly simplified and abstract nature. In this article, we propose a novel multi-style generative adversarial network (GAN) architecture, called MS-CartoonGAN, which can transform photos into multiple cartoon styles. MS-CartoonGAN uses only unpaired photos and cartoon images of multiple styles for training. To achieve this, we propose to use (1) a hierarchical semantic loss with sparse regularization to retain semantic content and recover flat shading in different abstract levels, (2) a new edge-promoting adversarial loss for producing fine edges, and (3) a style loss to enhance the difference between output cartoon styles and make training process more stable. We also develop a multi-domain architecture, where the generator consists of a shared encoder and multiple decoders for different cartoon styles, along with multiple discriminators for individual styles. By observing that cartoon images drawn by different artists have their unique styles while sharing some common characteristics, our shared network architecture exploits the common characteristics of cartoon styles, achieving better cartoonization and being more efficient than single-style cartoonization. We show that our multi-domain architecture can theoretically guarantee to output desired multiple cartoon styles. Through extensive experiments including a user study, we demonstrate the superiority of the proposed method, outperforming state-of-the-art single-style and multi-style image style transfer methods.
C1 [Shu, Yezhi; Yi, Ran; Xia, Mengfei; Ye, Zipeng; Zhao, Wang; Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, BNRist, Beijing 100084, Peoples R China.
   [Chen, Yang] Tencent, Shenzhen 518057, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Tsinghua University; Tencent; Cardiff University
RP Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, BNRist, Beijing 100084, Peoples R China.
EM shuyz19@mails.tsinghua.edu.cn; yr16@mails.tsinghua.edu.cn;
   xiamfl6@mails.tsinghua.edu.cn; yezp17@mails.tsinghua.edu.cn;
   zhao-w19@mails.tsinghua.edu.cn; cylily93@gmail.com; laiy4@cardiff.ac.uk;
   liuyongjin@tsinghua.edu.cn
RI Yi, Ran/AAU-6636-2021; Lai, Yu-Kun/D-2343-2010
OI Ye, Zipeng/0000-0002-4322-7550; Lai, Yukun/0000-0002-2094-5680; Yi,
   Ran/0000-0003-1858-3358
FU Natural Science Foundation of China [61725204]
FX This work was supported by the Natural Science Foundation of China under
   Grant 61725204. Y. Shu and R. Yi are joint first authors.
CR [Anonymous], 2013, COMPUTATIONAL IMAGIN
   [Anonymous], 2016, P ICLR
   Anoosheh A, 2018, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2018.00122
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen Y, 2018, PROC CVPR IEEE, P9465, DOI 10.1109/CVPR.2018.00986
   Chen Y, 2017, IEEE IMAGE PROC, P2010, DOI 10.1109/ICIP.2017.8296634
   Cho W, 2019, PROC CVPR IEEE, P10631, DOI 10.1109/CVPR.2019.01089
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Dumoulin V., 2017, PROC INT C LEARN REP
   Gatys LA, 2015, ADV NEUR IN, V28
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gomez R, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3164, DOI 10.1145/3394171.3413785
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hensel M, 2017, ADV NEUR IN, V30
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang SS, 2014, VISUAL COMPUT, V30, P673, DOI 10.1007/s00371-014-0973-y
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karacan Levent, 2016, Learning to generate images of outdoor scenes from attributes and semantic layouts. arXiv preprint arXiv:1612.00215
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu MY, 2017, ADV NEUR IN, V30
   Maas A. L., 2013, P ICML ATL GEORG US
   Rosin PaulL., 2015, Proceedings of the Workshop on Computational Aesthetics, P159
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Simonyan K., 2015, P INT C LEARN REPR I, P1
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Wu JJ, 2016, ADV NEUR IN, V29
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang M, 2010, IEEE IMAGE PROC, P1805, DOI 10.1109/ICIP.2010.5651715
   Yang XW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P374, DOI 10.1145/3240508.3240716
   Zhang JC, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P392, DOI 10.1145/3240508.3240594
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 39
TC 18
Z9 19
U1 2
U2 56
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3376
EP 3390
DI 10.1109/TVCG.2021.3067201
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100005
PM 33750692
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Dy, B
   Ibrahim, N
   Poorthuis, A
   Joyce, S
AF Dy, Bianchi
   Ibrahim, Nazim
   Poorthuis, Ate
   Joyce, Sam
TI Improving Visualization Design for Effective Multi-Objective Decision
   Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Decision making; Tools; Radar;
   Heating systems; Radar scattering; Multi-objective decision-making;
   multidimensional visualization; parallel coordinates; scatter plot
   matrix; heat map; radar chart; evaluation
ID VISUAL ANALYSIS; PERFORMANCE
AB Decision-makers across many professions are often required to make multi-objective decisions over increasingly larger volumes of data with several competing criteria. Data visualization is a powerful tool for exploring these complex 'solution spaces', but there is limited research on its ability to support multi-objective decisions. In this article, we explore the effects of chart complexity and data volume on decision quality in multi-objective scenarios with complex trade-offs. We look at the impact of four common multidimensional chart types (scatter plot matrices, parallel coordinates plots, heat maps, radar charts), the number of options and dimensions and participant chart usage experience on decision time and accuracy when selecting the 'optimal option'. As objectively evaluating the quality of multi-objective decisions and the trade-offs involved is challenging, we employ rank- and score-based accuracy metrics. While heat maps demonstrate a time advantage, our findings show no strong performance benefit for one chart type over another for accuracy. We find mixed evidence for the impact of chart complexity on performance, with our results suggesting the existence of a 'ceiling' in the number of dimensions considered by participants. This points to a potential limit to data complexity that is useful for decision making. Lastly, participants who use charts frequently performed better, suggesting that users can potentially be trained to effectively use complex visualizations in their decision-making.
C1 [Dy, Bianchi; Ibrahim, Nazim; Joyce, Sam] Singapore Univ Technol & Design SUTD, Singapore 487372, Singapore.
   [Poorthuis, Ate] Katholieke Univ Leuven, B-3000 Leuven, Belgium.
C3 Singapore University of Technology & Design; KU Leuven
RP Dy, B (corresponding author), Singapore Univ Technol & Design SUTD, Singapore 487372, Singapore.
EM bianchi_dy@sutd.edu.sg; nazim_ibrahim@sutd.edu.sg;
   ate.poorthuis@kuleuven.be; sam_joyce@sutd.edu.sg
RI Poorthuis, Ate/S-2675-2018
OI Poorthuis, Ate/0000-0002-3808-7493; Dy, Bianchi/0000-0001-8469-4385;
   Conrad Joyce, Sam/0000-0001-6637-4193; Nazim,
   Ibrahim/0000-0003-1971-2254
FU SUTD-MIT International Design Centre (IDC)
FX This work was supported by the SUTD-MIT International Design Centre
   (IDC). Any findings, conclusions, recommendations, or opinions expressed
   in this document are those of the author(s) and do not necessary reflect
   the views of the IDC.
CR Abdul-Rahman A, 2019, Arxiv, DOI arXiv:1909.03786
   Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   Andrienko G., 2003, J DECIS SYST, V12, P193, DOI [DOI 10.3166/JDS.12.193-208, 10.3166/jds.12.193-208]
   [Anonymous], 1997, HDB EVOLUTIONARY COM
   [Anonymous], 2014, MOTORCYCLE CONSUMER, P27
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Brown N., 2016, EARLY STAGE INTEGRAT
   Brown N., 2017, Designing With Data: Moving Beyond Design Space Catalog
   Card SK., 1999, READINGS INFORM VISU
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Conati C, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12393
   CORE, 2016, DES EXPL
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   Cristiani V., 2019, CARDIS
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Engelke Ulrich., 2016, Electronic Imaging, V2016, P1
   Evins R, 2012, P I CIVIL ENG-CIV EN, V165, P5, DOI [10.1680/cien.11.00014, 10.1680/cien.11.20014]
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guo G., 2020, PROC EUROGRAPHICS C
   Holten D, 2010, COMPUT GRAPH FORUM, V29, P793, DOI 10.1111/j.1467-8659.2009.01666.x
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Joyce S. C., 2019, PROC IASS ANN S, P1
   Kahneman D, 2015, FORTUNE, V172, P20
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Khan A, 2015, INT J HUM-COMPUT ST, V83, P94, DOI 10.1016/j.ijhcs.2015.07.001
   KOTTEMANN JE, 1991, DECISION SCI, V22, P918, DOI 10.1111/j.1540-5915.1991.tb00371.x
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Li J, 2010, INFORM VISUAL, V9, P13, DOI 10.1057/ivs.2008.13
   Marler RT, 2004, STRUCT MULTIDISCIP O, V26, P369, DOI 10.1007/s00158-003-0368-6
   Matejka J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173943
   McFadden D., 1974, Frontiers in econometrics, DOI DOI 10.1108/EB028592
   Mueller CT, 2015, AUTOMAT CONSTR, V52, P70, DOI 10.1016/j.autcon.2015.02.011
   Oulasvirta A, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P516, DOI 10.1145/1571941.1572030
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Perin C, 2014, IEEE T VIS COMPUT GR, V20, P2082, DOI 10.1109/TVCG.2014.2346279
   Raseman WJ, 2019, ENVIRON MODELL SOFTW, V116, P153, DOI 10.1016/j.envsoft.2019.03.005
   Riehmann P, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P423, DOI 10.1145/2254556.2254638
   RITTEL HWJ, 1973, POLICY SCI, V4, P155, DOI 10.1007/BF01405730
   Seabold S., 2010, STATSMODELS ECONOMET, V57, P10
   Simon H.A., 1997, Models of Bounded Rationality: Empirically Grounded Economic Reason, V3
   Turkay C, 2011, IEEE T VIS COMPUT GR, V17, P2591, DOI 10.1109/TVCG.2011.178
   von Buelow P., 2012, Journal of the International Association for Shell and Spatial Structures, V53, P271
   Wilkinson L, 2009, AM STAT, V63, P179, DOI 10.1198/tas.2009.0033
   Yi J. S., 2005, Information Visualization, V4, P239, DOI 10.1057/palgrave.ivs.9500099
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
NR 50
TC 9
Z9 9
U1 0
U2 31
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3405
EP 3416
DI 10.1109/TVCG.2021.3065126
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100007
PM 33690120
DA 2024-11-06
ER

PT J
AU Ren, B
   He, W
   Li, CF
   Chen, X
AF Ren, Bo
   He, Wei
   Li, Chen-Feng
   Chen, Xu
TI Incompressibility Enforcement for Multiple-Fluid SPH Using Deformation
   Gradient
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Strain; Computational modeling; Mathematical model; Visualization;
   Solids; Volume measurement; Tensors; Compressible and incompressible
   fluids; multiple-fluid simulation; smoothed particle hydrodynamics;
   deformation gradient
ID PARTICLE; SIMULATION
AB To maintain incompressibility in SPH fluid simulations is important for visual plausibility. However, it remains an outstanding challenge to enforce incompressibility in such recent multiple-fluid simulators as the mixture-model SPH framework. To tackle this problem, we propose a novel incompressible SPH solver, where the compressibility of fluid is directly measured by the deformation gradient. By disconnecting the incompressibility of fluid from the conditions of constant density and divergence-free velocity, the new incompressible SPH solver is applicable to both single- and multiple-fluid simulations. The proposed algorithm can be readily integrated into existing incompressible SPH frameworks developed for single-fluid, and is fully parallelizable on GPU. Applied to multiple-fluid simulations, the new incompressible SPH scheme significantly improves the visual effects of the mixture-model simulation, and it also allows exploitation for artistic controlling.
C1 [Ren, Bo; He, Wei; Chen, Xu] Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China.
   [Li, Chen-Feng] Swansea Univ, Swansea SA2 8PP, W Glam, Wales.
C3 Nankai University; Swansea University
RP Ren, B (corresponding author), Nankai Univ, Coll Comp Sci, Tianjin 300071, Peoples R China.
EM rb@nankai.edu.cn; 2120190362@mail.nankai.edu.cn; c.f.li@swansea.ac.uk;
   cnarutox@mail.nankai.edu.cn
RI Li, Chenfeng/AFQ-6554-2022; ren, bo/IST-0814-2023; He, Wei/ADP-7281-2022
OI Chen, Xu/0000-0002-2632-7576; Li, Chenfeng/0000-0003-0441-211X
FU National Key R&D Program of China [2017YFB1002701]
FX This work was supported by the National Key R&D Program of China under
   Grant 2017YFB1002701. The authors would also like to thank all the
   anonymous reviewers for the inspiring suggestions.
CR Aboudi J, 2013, MICROMECHANICS OF COMPOSITE MATERIALS: A GENERALIZED MULTISCALE ANALYSIS APPROACH, P1
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   [Anonymous], 2011, COMPUTATIONAL METHOD
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   Bodin K, 2012, IEEE T VIS COMPUT GR, V18, P516, DOI 10.1109/TVCG.2011.29
   Cummins SJ, 1999, J COMPUT PHYS, V152, P584, DOI 10.1006/jcph.1999.6246
   Fulk DA, 1995, INT J IMPACT ENG, V17, P329, DOI 10.1016/0734-743X(95)99859-P
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201309
   Gao Y, 2009, COMPUT GRAPH FORUM, V28, P1845, DOI 10.1111/j.1467-8659.2009.01562.x
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   HARADA T., 2007, Smoothed Particle Hydrodynamics on GPUs
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Kang N, 2014, COMPUT GRAPH FORUM, V33, P219, DOI 10.1111/cgf.12490
   Lee CH, 2017, COMPUT METHOD APPL M, V318, P514, DOI 10.1016/j.cma.2017.02.002
   Losasso F, 2008, IEEE T VIS COMPUT GR, V14, P797, DOI 10.1109/TVCG.2008.37
   Macklin M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461984
   MONAGHAN JJ, 1994, J COMPUT PHYS, V110, P399, DOI 10.1006/jcph.1994.1034
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Ren B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2645703
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Tampubolon AP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073651
   Yan X, 2018, COMPUT GRAPH FORUM, V37, P183, DOI 10.1111/cgf.13523
   Yan X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925897
   Yang T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130882
   Yang T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818117
NR 27
TC 4
Z9 5
U1 5
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3417
EP 3427
DI 10.1109/TVCG.2021.3062643
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100008
PM 33646953
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Arleo, A
   Didimo, W
   Liotta, G
   Miksch, S
   Montecchiani, F
AF Arleo, Alessio
   Didimo, Walter
   Liotta, Giuseppe
   Miksch, Silvia
   Montecchiani, Fabrizio
TI Influence Maximization With Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information visualization; visualization systems and software; influence
   maximization; visual analytics; information diffusion
ID SOCIAL NETWORKS; INFORMATION DIFFUSION; VISUALIZATION
AB In social networks, individuals' decisions are strongly influenced by recommendations from their friends, acquaintances, and favorite renowned personalities. The popularity of online social networking platforms makes them the prime venues to advertise products and promote opinions. The Influence Maximization (IM) problem entails selecting a seed set of users that maximizes the influence spread, i.e., the expected number of users positively influenced by a stochastic diffusion process triggered by the seeds. Engineering and analyzing IM algorithms remains a difficult and demanding task due to the NP-hardness of the problem and the stochastic nature of the diffusion processes. Despite several heuristics being introduced, they often fail in providing enough information on how the network topology affects the diffusion process, precious insights that could help researchers improve their seed set selection. In this paper, we present VAIM, a visual analytics system that supports users in analyzing, evaluating, and comparing information diffusion processes determined by different IM algorithms. Furthermore, VAIM provides useful insights that the analyst can use to modify the seed set of an IM algorithm, so to improve its influence spread. We assess our system by: (i) a qualitative evaluation based on a guided experiment with two domain experts on two different data sets; (ii) a quantitative estimation of the value of the proposed visualization through the ICE-T methodology by Wall et al. (IEEE TVCG - 2018). The twofold assessment indicates that VAIM effectively supports our target users in the visual analysis of the performance of IM algorithms.
C1 [Arleo, Alessio; Miksch, Silvia] TU Wien, Ctr Visual Analyt Sci & Technol, A-1040 Vienna, Austria.
   [Didimo, Walter; Liotta, Giuseppe; Montecchiani, Fabrizio] Univ Perugia, Engn Dept, I-06123 Perugia, Italy.
C3 Technische Universitat Wien; University of Perugia
RP Arleo, A (corresponding author), TU Wien, Ctr Visual Analyt Sci & Technol, A-1040 Vienna, Austria.
EM alessio.arleo@tuwien.ac.at; walter.didimo@unipg.it;
   giuseppe.liotta@unipg.it; silvia.miksch@tuwien.ac.at;
   fabrizio.montecchiani@unipg.it
RI ; Arleo, Alessio/IRZ-8036-2023; Liotta, Giuseppe/I-4638-2015
OI Miksch, Silvia/0000-0003-4427-5703; Montecchiani,
   Fabrizio/0000-0002-0543-8912; Arleo, Alessio/0000-0003-2008-3651;
   Liotta, Giuseppe/0000-0002-2886-9694
FU Smart CT Research Cluster at Vienna University of Technology; MIUR
   [20174LF3T8]; University of Perugia [RICBA19FM, RICBA20ED]; TU Wien
   Bibliothek
FX This work was supported in part by the Smart CT Research Cluster at
   Vienna University of Technology, in part by MIUR under Grant 20174LF3T8
   "AHeAD: Efficient Algorithms for HArnessing networked Data" in part by
   the University of Perugia under Grants RICBA19FM and RICBA20ED and in
   part by TU Wien Bibliothek through its Open Access Funding Programme.
CR Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Afzal S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P86, DOI 10.1109/VIS47514.2020.00024
   Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   Angori L, 2022, IEEE T VIS COMPUT GR, V28, P1288, DOI 10.1109/TVCG.2020.3016055
   [Anonymous], 2016, CITEVIS CITATION DAT
   [Anonymous], P 2008 EUR C MACH LE
   [Anonymous], REACT JAVASCRIPT LIB
   [Anonymous], Neo4j Graph Platform - The Leader in Graph Databases
   [Anonymous], VAIM GIT REPOSITORY
   Arleo Alessio, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P115, DOI 10.1007/978-3-030-68766-3_9
   Arleo A, 2019, IEEE T PARALL DISTR, V30, P754, DOI 10.1109/TPDS.2018.2869805
   Arleo A, 2017, INFORM SCIENCES, V381, P124, DOI 10.1016/j.ins.2016.11.012
   Arora A, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P651, DOI 10.1145/3035918.3035924
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bryan C, 2015, IEEE CONF VIS ANAL, P17, DOI 10.1109/VAST.2015.7347626
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen, 2020, VISUAL DATA ANAL SIM
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Chen SM, 2016, IEEE CONF VIS ANAL, P41, DOI 10.1109/VAST.2016.7883510
   Chen W., 2010, P 16 ACM SIGKDD INT, P1029
   Chen W, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P199, DOI 10.1145/1557019.1557047
   Domingos P., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P57, DOI 10.1145/502512.502525
   Eubank S, 2004, NATURE, V429, P180, DOI 10.1038/nature02541
   Gansner ER, 2000, SOFTWARE PRACT EXPER, V30, P1203, DOI 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.0.CO;2-N
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gonzalez Joseph E., 2014, USENIX OSDI 2014, P599
   Guille A, 2013, SIGMOD REC, V42, P17
   Guo D, 2007, INT J GEOGR INF SCI, V21, P859, DOI 10.1080/13658810701349037
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Henry N, 2008, IEEE T VIS COMPUT GR, V14, P1317, DOI 10.1109/TVCG.2008.141
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hu Yifan, 2005, Mathematica J., V10, P37
   Huang XD, 2018, IEEE T BIG DATA, V4, P381, DOI 10.1109/TBDATA.2016.2555319
   Jia YT, 2008, IEEE T VIS COMPUT GR, V14, P1285, DOI 10.1109/TVCG.2008.151
   Kempe D., 2003, P 9 ACM SIGKDD INT C, DOI [10.1145/956750.956769, DOI 10.1145/956750.956769]
   Kobourov S. G., 2013, Handbook of Graph Drawing and Visualization, P383
   Kumar S, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P333, DOI 10.1145/3159652.3159729
   Kumar S, 2016, IEEE DATA MINING, P221, DOI [10.1109/ICDM.2016.175, 10.1109/ICDM.2016.0033]
   Li YC, 2018, IEEE T KNOWL DATA EN, V30, P1852, DOI 10.1109/TKDE.2018.2807843
   Long Cheng, 2014, INT C DATA MINING WO, P1223
   Maciejewski R, 2011, IEEE T VIS COMPUT GR, V17, P440, DOI 10.1109/TVCG.2010.82
   Marcus A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P227
   Marcus A, 2011, SIGMOD REC, V40, P21, DOI 10.1145/2094114.2094120
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   NEMHAUSER GL, 1978, MATH PROGRAM, V14, P265, DOI 10.1007/BF01588971
   Pinaud B, 2020, VIS INFORM, V4, P23, DOI 10.1016/j.visinf.2020.09.005
   RICHARDSON M, 2003, P 2 INT SEM WEB C, P351
   Rossetti G, 2018, INT J DATA SCI ANAL, V5, P61, DOI 10.1007/s41060-017-0086-6
   Skianis K, 2016, INT CONF DAT MIN WOR, P1324, DOI [10.1109/ICDMW.2016.0195, 10.1109/ICDMW.2016.181]
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.2669579, 10.1145/2669557.26695792,9, DOI 10.1145/2669557.26695792,9]
   Sun GD, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3106775
   Szor P., 2004, P 13 USENIX SEC S
   VALLET J, 2015, P GRAPHS MOD WORKSH, P65
   Van den Broeck W, 2011, BMC INFECT DIS, V11, DOI [10.1186/1471-2334-11-37, 10.1186/1471-2458-11-575]
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang P, 2013, INT J INF SECUR, V12, P383, DOI 10.1007/s10207-013-0203-z
   Wu YC, 2014, IEEE T VIS COMPUT GR, V20, P1763, DOI 10.1109/TVCG.2014.2346920
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
NR 62
TC 3
Z9 4
U1 2
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3428
EP 3440
DI 10.1109/TVCG.2022.3190623
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100009
PM 35830402
OA hybrid
DA 2024-11-06
ER

PT J
AU Wang, YF
   Liang, HY
   Shu, XH
   Wang, JC
   Xu, K
   Deng, ZK
   Campbell, C
   Chen, BJ
   Wu, YC
   Qu, HM
AF Wang, Yifang
   Liang, Hongye
   Shu, Xinhuan
   Wang, Jiachen
   Xu, Ke
   Deng, Zikun
   Campbell, Cameron
   Chen, Bijia
   Wu, Yingcai
   Qu, Huamin
TI Interactive Visual Exploration of Longitudinal Historical Career
   Mobility Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Engineering profession; Data visualization; History; Visual analytics;
   Social groups; Trajectory; Government; Digital humanities; quantitative
   history; career mobility; visual analytics
ID EVENT; PATTERNS
AB The increased availability of quantitative historical datasets has provided new research opportunities for multiple disciplines in social science. In this article, we work closely with the constructors of a new dataset, CGED-Q (China Government Employee Database-Qing), that records the career trajectories of over 340,000 government officials in the Qing bureaucracy in China from 1760 to 1912. We use these data to study career mobility from a historical perspective and understand social mobility and inequality. However, existing statistical approaches are inadequate for analyzing career mobility in this historical dataset with its fine-grained attributes and long time span, since they are mostly hypothesis-driven and require substantial effort. We propose CareerLens, an interactive visual analytics system for assisting experts in exploring, understanding, and reasoning from historical career data. With CareerLens, experts examine mobility patterns in three levels-of-detail, namely, the macro-level providing a summary of overall mobility, the meso-level extracting latent group mobility patterns, and the micro-level revealing social relationships of individuals. We demonstrate the effectiveness and usability of CareerLens through two case studies and receive encouraging feedback from follow-up interviews with domain experts.
C1 [Wang, Yifang; Liang, Hongye; Wang, Jiachen; Deng, Zikun; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Wang, Yifang; Liang, Hongye; Wang, Jiachen; Deng, Zikun] Zhejiang Lab, Hangzhou 311121, Peoples R China.
   [Shu, Xinhuan; Campbell, Cameron; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Xu, Ke] NYU, New York, NY 10003 USA.
   [Campbell, Cameron] Cent China Normal Univ, Wuhan 430079, Peoples R China.
   [Chen, Bijia] Renmin Univ China, Beijing 100872, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory; Hong Kong University of
   Science & Technology; New York University; Central China Normal
   University; Renmin University of China
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM yifang.wang@connect.ust.hk; 21821087@zju.edu.cn;
   xinhuan.shu@connect.ust.hk; wangjiachen@zju.edu.cn; kexu@nyu.edu;
   zikun_rain@zju.edu.cn; camcam@ust.hk; bjchen@ruc.edu.cn;
   ycwu@zju.edu.cn; huamin@cse.ust.hk
RI Deng, Zikun/IQT-3106-2023; , kk/AAH-8764-2020; Wang,
   Jiachen/KIK-8161-2024; Campbell, Cameron/AAK-3419-2020; Wang,
   Yifang/GXH-9767-2022; wang, yixuan/JGM-3893-2023
OI Shu, Xinhuan/0000-0002-9736-4454; Deng, Zikun/0000-0002-4477-5292; Chen,
   Bijia/0000-0002-9332-4172; Wang, Yifang/0000-0001-6267-9440; Zhang,
   Xiaofeng/0000-0003-2738-3286; Campbell, Cameron
   Dougall/0000-0001-6277-1941; Wang, Jiachen/0000-0001-9630-9958
FU Hong Kong Research Grants Council (RGC) General Research Fund (GRF)
   [16213317]; National Natural Science Foundation of China [62072400];
   Zhejiang Provincial Natural Science Foundation [LR18F020001]; 100
   Talents Program of Zhejiang University; Hong Kong RGC GRF [16601718]
FX The work was supported in part by the Hong Kong Research Grants Council
   (RGC) General Research Fund (GRF) under Grant 16213317, in part by the
   National Natural Science Foundation of China under Grant 62072400, in
   part by the Zhejiang Provincial Natural Science Foundation under Grant
   LR18F020001, and in part by the 100 Talents Program of Zhejiang
   University. The construction of the CGED-Q was supported by the Hong
   Kong RGC GRF under Grant 16601718. The work of Yifang Wang was done when
   she was a visiting student supervised by YingcaiWu at Zhejiang
   University.
CR [Anonymous], HIST SAMPLE NETHERLA
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chen BJ, 2020, J CHINESE HIST, V4, P431, DOI 10.1017/jch.2020.15
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   D'Unger AV, 1998, AM J SOCIOL, V103, P1593, DOI 10.1086/231402
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Filipov Velitchko Andreev., 2018, Proceedings of the Eurographics Conference on Visualization, Posters, P1
   Fischer F., 2012, Proc. EuroVis Short Papers, P97, DOI DOI 10.2312/PE/EUROVISSHORT/EUROVISSHORT2012/097-101
   Fung TL, 2016, IEEE PAC VIS SYMP, P244, DOI 10.1109/PACIFICVIS.2016.7465279
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Grnwald PD., 2007, The Minimum Description Length Principle
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Guo Y, 2020, Arxiv, DOI arXiv:2006.14291
   Jaenicke S, 2016, IEEE T VIS COMPUT GR, V22, P200, DOI 10.1109/TVCG.2015.2467620
   Jarvis BF, 2017, AM SOCIOL REV, V82, P568, DOI 10.1177/0003122417706391
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Liao TF, 2020, AM BEHAV SCI, V64, P740, DOI 10.1177/0002764220910229
   Lin N., 2017, Social capital: Theory and research
   Lipset SeymourMartin Reinhard Bendix., 1959, SOCIAL MOBILITY IND
   Liu ZC, 2017, COMPUT GRAPH FORUM, V36, P527, DOI 10.1111/cgf.13208
   Manson S., IPUMS National Historical Geographic Information System. In, V15.0
   Meng QX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P14, DOI 10.1145/3292500.3330969
   Monroe M, 2014, Molecular Weight Calculator
   Munzner T., 2014, AK Peters Visualization Series
   Nagin DS, 2016, J RES CRIME DELINQ, V53, P356, DOI 10.1177/0022427815611710
   Plaisant Catherine, 2003, The craft of information visualization, P308, DOI DOI 10.1016/B978-155860915-0/50038-X
   Qu HY, 2016, IEEE TRUST BIG, P1668, DOI [10.1109/TrustCom.2016.254, 10.1109/TrustCom.2016.0256]
   ROSENBAUM JE, 1979, ADMIN SCI QUART, V24, P220, DOI 10.2307/2392495
   SICHERMAN N, 1990, J POLIT ECON, V98, P169, DOI 10.1086/261674
   Sorokin PitirimAleksandrovich., 1998, Social mobility, V3
   STONE L, 1971, DAEDALUS-US, V100, P46
   TZINER A, 1983, SOC BEHAV PERSONAL, V11, P119, DOI 10.2224/sbp.1983.11.1.119
   Voth H.-J., DP13963 CTR EC POL R
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Wu J, 2020, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST50239.2020.00009
   Wu MQY, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P785
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Xu H, 2015, IEEE DATA MINING, P1057, DOI 10.1109/ICDM.2015.122
   Xu Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1945
   Yuxue Ren., 2019, China Government Employee Dataset-Qing Dynasty Jinshenlu 1900-1912 Public Release User Guide
   Zhang C, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3230707
   US
NR 50
TC 8
Z9 9
U1 1
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3441
EP 3455
DI 10.1109/TVCG.2021.3067200
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100010
PM 33750691
OA hybrid
DA 2024-11-06
ER

PT J
AU Halladjian, S
   Kouril, D
   Miao, HC
   Gröller, ME
   Viola, I
   Isenberg, T
AF Halladjian, Sarkis
   Kouril, David
   Miao, Haichao
   Groeller, M. Eduard
   Viola, Ivan
   Isenberg, Tobias
TI Multiscale Unfolding: Illustratively Visualizing the Whole Genome at a
   Glance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; DNA; Genomics; Bioinformatics; Visualization;
   Three-dimensional displays; Navigation; Multiscale visualization;
   spatially-controlled scale transition; visual abstraction; illustrative
   visualization; genome; DNA
ID ABSTRACTION
AB We present Multiscale Unfolding, an interactive technique for illustratively visualizing multiple hierarchical scales of DNA in a single view, showing the genome at different scales and demonstrating how one scale spatially folds into the next. The DNA's extremely long sequential structure-arranged differently on several distinct scale levels-is often lost in traditional 3D depictions, mainly due to its multiple levels of dense spatial packing and the resulting occlusion. Furthermore, interactive exploration of this complex structure is cumbersome, requiring visibility management like cut-aways. In contrast to existing temporally controlled multiscale data exploration, we allow viewers to always see and interact with any of the involved scales. For this purpose we separate the depiction into constant-scale and scale transition zones. Constant-scale zones maintain a single-scale representation, while still linearly unfolding the DNA. Inspired by illustration, scale transition zones connect adjacent constant-scale zones via level unfolding, scaling, and transparency. We thus represent the spatial structure of the whole DNA macro-molecule, maintain its local organizational characteristics, linearize its higher-level organization, and use spatially controlled, understandable interpolation between neighboring scales. We also contribute interaction techniques that provide viewers with a coarse-to-fine control for navigating within our all-scales-in-one-view representations and visual aids to illustrate the size differences. Overall, Multiscale Unfolding allows viewers to grasp the DNA's structural composition from chromosomes to the atoms, with increasing levels of "unfoldedness," and can be applied in data-driven illustration and communication.
C1 [Halladjian, Sarkis; Isenberg, Tobias] Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 St Aubin, France.
   [Kouril, David; Miao, Haichao; Groeller, M. Eduard] TU Wien, A-1040 Vienna, Austria.
   [Groeller, M. Eduard] VRV Res Ctr, A-1220 Vienna, Austria.
   [Viola, Ivan] King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
C3 Inria; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); Universite Paris Cite; Technische Universitat Wien;
   King Abdullah University of Science & Technology
RP Isenberg, T (corresponding author), Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 St Aubin, France.
EM sarkis.halladjian@inria.fr; dvdkouril@cg.tuwien.ac.at;
   miao@cg.tuwien.ac.at; groeller@cg.tuwieri.ac.at;
   ivan.viola@kaust.edu.sa; tobias.isenberg@inria.fr
RI Miao, Haichao/HNJ-6239-2023; Isenberg, Tobias/A-7575-2008; Viola,
   Ivan/O-8944-2014
OI Isenberg, Tobias/0000-0001-7953-8644; Kouril, David/0000-0003-4043-3487;
   Viola, Ivan/0000-0003-4248-6574
FU Austrian Science Fund (FWF) [I 2953-N31]; French National Research
   Agency (ANR) [ANR-16-CE91-0011-01]; King Abdullah University of Science
   and Technology (KAUST) [BAS/1/1680-01-01]; ILLVISATION grant by WWTF
   [VRG11-010]; BMVIT; Vienna Business Agency [854174]; BMWFW, Styria; SFG;
   Agence Nationale de la Recherche (ANR) [ANR-16-CE91-0011] Funding
   Source: Agence Nationale de la Recherche (ANR)
FX The authors would like to thank all experts who provided their feedback
   and were available for interviews. Part of this work was funded under
   the ILLUSTRARE grant by both the Austrian Science Fund (FWF): I 2953-N31
   and the French National Research Agency (ANR): ANR-16-CE91-0011-01. This
   work was further supported by funding from King Abdullah University of
   Science and Technology (KAUST), under award number BAS/1/1680-01-01 and
   by funding from the ILLVISATION grant by WWTF (VRG11-010). The authors
   also thank Nanographics GmbH (nanographics.at) for providing the Marion
   Software Framework. This article was partly written in collaboration
   with the VRVis Competence Center. VRVis is funded by BMVIT, BMWFW,
   Styria, SFG and Vienna Business Agency in the scope of COMET -Competence
   Centers for Excellent Technologies (854174), which is managed by FFG.
CR Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286
   Alberts B, 2015, MOLECULAR BIOLOGY OF THE CELL, SIXTH EDITION, P1035
   Annunziato A., 2008, NAT ED, V1, P26
   Asbury TM, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-444
   Axelsson E, 2017, COMPUT GRAPH FORUM, V36, P459, DOI 10.1111/cgf.13202
   BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Biga LM., 2019, Anatomy Physiology
   Bladin K, 2018, IEEE T VIS COMPUT GR, V24, P802, DOI 10.1109/TVCG.2017.2743958
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brosz J., 2013, P 26 ANN ACM S USER, P97
   Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P156, DOI 10.1109/VISUAL.1991.175794
   Card S. K., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P181, DOI 10.1145/108844.108874
   COQUILLART S, 1991, COMP GRAPH, V25, P23, DOI 10.1145/127719.122720
   Coquillart S., 1990, J. Computer Graphics, V24, P187, DOI DOI 10.1145/97880.97900
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P468, DOI 10.1109/TVCG.2009.86
   Everts MH, 2015, IEEE T VIS COMPUT GR, V21, P808, DOI 10.1109/TVCG.2015.2403323
   Finkelstein A., 1994, P SIGGRAPH, P261, DOI DOI 10.1145/192161.192223
   Fu CW, 2007, IEEE T VIS COMPUT GR, V13, P108, DOI 10.1109/TVCG.2007.2
   Furnas G. W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P234
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Glueck Michael, 2009, P 2009 S INT 3D GRAP, P225, DOI [DOI 10.1145/1507149.1507186, 10.1145/1507149.1507186]
   Halladjian S, 2020, IEEE T VIS COMPUT GR, V26, P654, DOI 10.1109/TVCG.2019.2934334
   Hauser H., 2006, Scientific Visualization: The Visual Extraction of Knowledge from Data, P305, DOI [DOI 10.1007/3-540-30790-7_18, 10/dh5vbj]
   Hsu WH, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024165
   Irobalieva RN, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9440
   Javed W., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI '12, P287, DOI DOI 10.1145/2207676.2207716
   Johnson A.J., 1862, Johnson's New Illustrated Steel Plate Family Atlas, With Descriptions, Geographical, Statistical, and Historical
   Keefe DF, 2013, COMPUTER, V46, P51, DOI 10.1109/MC.2013.178
   Keefe DF, 2010, IEEE COMPUT GRAPH, V30, P8, DOI 10.1109/MCG.2010.30
   Klashed S., 2010, P EUR 2010 AR
   Kouril D, 2021, IEEE T VIS COMPUT GR, V27, P3493, DOI 10.1109/TVCG.2020.2975583
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Kozlikova B.a. K., 2015, Eurographics Conference on Visualization (EuroVis)-STARs, P061, DOI DOI 10.2312/EUROVISSTAR.20151112
   Kreiser J, 2018, COMPUT GRAPH FORUM, V37, P597, DOI 10.1111/cgf.13445
   LAZARUS F, 1994, COMPUT AIDED DESIGN, V26, P607, DOI 10.1016/0010-4485(94)90103-1
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Lekschas F, 2020, IEEE T VIS COMPUT GR, V26, P611, DOI 10.1109/TVCG.2019.2934555
   Lerios A., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P449, DOI 10.1145/218380.218502
   Lindow N, 2012, COMPUT GRAPH FORUM, V31, P1325, DOI 10.1111/j.1467-8659.2012.03128.x
   Lueks W., 2011, PROC ABSTRACTS 1 IEE
   MACKENZIE IS, 1994, BEHAV INFORM TECHNOL, V13, P328, DOI 10.1080/01449299408914613
   McCrae James., 2009, P 2009 S INT 3D GRAP, P7, DOI [10.1145/1507149.1507151, DOI 10.1145/1507149.1507151]
   Miao H, 2018, COMPUT GRAPH FORUM, V37, P403, DOI 10.1111/cgf.13429
   Miao HC, 2019, J MOL BIOL, V431, P1049, DOI 10.1016/j.jmb.2018.09.004
   Miao HC, 2018, IEEE T VIS COMPUT GR, V24, P1014, DOI 10.1109/TVCG.2017.2743981
   Miller Robert B., 1968, P DEC 9 11 1968 FA 1, P267, DOI DOI 10.1145/1476589.1476628
   Mindek P, 2018, IEEE T VIS COMPUT GR, V24, P883, DOI 10.1109/TVCG.2017.2744518
   Mistelbauer G, 2012, IEEE PAC VIS SYMP, P233, DOI 10.1109/PacificVis.2012.6183596
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Nowotny J, 2016, SCI REP-UK, V6, DOI 10.1038/srep20802
   Nusrat S, 2019, COMPUT GRAPH FORUM, V38, P781, DOI 10.1111/cgf.13727
   Parulek J, 2014, COMPUT GRAPH FORUM, V33, P276, DOI 10.1111/cgf.12349
   Pennisi E, 2001, SCIENCE, V291, P1177, DOI 10.1126/science.291.5507.1177
   Ramos G., 2005, Proceedings of the UIST '05 Symposium on User Interface Software and Technology, P143, DOI DOI 10.1145/1095034.1095059
   Ramos G., 2003, Proceedings of the UIST '03 Symposium on User Interface Software and Technology, P105, DOI DOI 10.1145/964696.964708
   Schatz K, 2016, SYMP LARG DATA ANAL, P56, DOI 10.1109/LDAV.2016.7874310
   Schneider VA, 2017, GENOME RES, V27, P849, DOI 10.1101/gr.213611.116
   Szerlong HJ, 2011, BIOCHEM CELL BIOL, V89, P24, DOI 10.1139/O10-139
   Termeer M, 2007, IEEE T VIS COMPUT GR, V13, P1632, DOI 10.1109/TVCG.2007.70550
   Tonna S, 2010, NAT REV NEPHROL, V6, P332, DOI 10.1038/nrneph.2010.55
   Tufte E.R., 1990, Envisioning Information
   van der Zwan M, 2011, COMPUT GRAPH FORUM, V30, P683, DOI 10.1111/j.1467-8659.2011.01917.x
   Viola I., 2020, Foundations of Data Visualization, P15, DOI [DOI 10.1007/978-3-030-34444-3_2, 10/gk874c, DOI 10.1007/978-3-030-34444-32, 10.1007/978-3-030-34444-3_2]
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wikipedia, 2021, LINK DNA
   Wills G., 2008, Handbook of Data Vi- sualization, P217, DOI [DOI 10.1007/978-3-540-33037-0_10, 10.1007/978-3-540-33037-0_10]
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhang XL, 2005, THIRD INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P109
NR 72
TC 5
Z9 5
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3456
EP 3470
DI 10.1109/TVCG.2021.3065443
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100011
PM 33705319
OA Green Published, hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Carr, HA
   Rübel, O
   Weber, GH
   Ahrens, JP
AF Carr, Hamish A.
   Ruebel, Oliver
   Weber, Gunther H.
   Ahrens, James P.
TI Optimization and Augmentation for Data Parallel Contour Trees
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Vegetation; Topology; Task analysis; Data analysis; Tools; Level set;
   Parallel algorithms; Computational topology; contour tree; parallel
   algorithms
ID TOPOLOGY
AB Contour trees are used for topological data analysis in scientific visualization. While originally computed with serial algorithms, recent work has introduced a vector-parallel algorithm. However, this algorithm is relatively slow for fully augmented contour trees which are needed for many practical data analysis tasks. We therefore introduce a representation called the hyperstructure that enables efficient searches through the contour tree and use it to construct a fully augmented contour tree in data parallel, with performance on average 6 times faster than the state-of-the-art parallel algorithm in the TTK topological toolkit.
C1 [Carr, Hamish A.] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
   [Ruebel, Oliver; Weber, Gunther H.] Lawrence Berkeley Natl Lab, Computat Res Div, Berkeley, CA 94720 USA.
   [Weber, Gunther H.] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Ahrens, James P.] Los Alamos Natl Lab, Livermore, NM 87545 USA.
C3 University of Leeds; United States Department of Energy (DOE); Lawrence
   Berkeley National Laboratory; University of California System;
   University of California Davis; United States Department of Energy
   (DOE); Los Alamos National Laboratory
RP Carr, HA (corresponding author), Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
EM H.Carr@leeds.ac.uk; ORuebel@lbl.gov; ghweber@lbl.gov; ahrens@lanl.gov
RI Weber, Gunther/AAA-9678-2019
OI Weber, Gunther H./0000-0002-1794-1398; Ahrens, James/0000-0001-9378-282X
FU EPSRC [EP/J013072/1]; Exascale Computing Project, a U.S. Department of
   Energy Office of Science [17-SC-20-SC]; National Nuclear Security
   Administration [DE-AC02-05CH11231, 14-017566, 7452335]; U.S. Department
   of Energy Office of Science User Facility [DE-AC02-05CH11231]; EPSRC
   [EP/J013072/1] Funding Source: UKRI
FX We acknowledge EPSRC Grant EP/J013072/1 and the University of Leeds for
   the first author's study leave at Los Alamos National Laboratory. This
   research was supported by the Exascale Computing Project (17-SC-20-SC),
   a collaborative effort of the U.S. Department of Energy Office of
   Science and the National Nuclear Security Administration under Contract
   No. DE-AC02-05CH11231 to the Lawrence Berkeley National Laboratory and
   under Award Number 14-017566 to the Los Alamos National Laboratory, and
   subcontract 7452335 to the University of Leeds. This research used
   resources of the University of Leeds Advanced Research Computing
   facility and of the National Energy Research Scientific Computing Center
   (NERSC), a U.S. Department of Energy Office of Science User Facility
   operated under Contract No. DE-AC02-05CH11231. We thank Jean-Luc Vay and
   Maxence Thevenet for making the WarpX dataset available to us. We would
   also like to thank Julien Tierny for his assistance in setting up the
   TTK runs for comparison.
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Blelloch GE., 1990, VECTOR MODELS DATA P
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H., 2020, Topological Methods in Data Analysis and Visualization V, P103, DOI [10.1007/978-3-030-43036-8_7, DOI 10.1007/978-3-030-43036-8_7]
   Carr H, 2010, COMP GEOM-THEOR APPL, V43, P42, DOI 10.1016/j.comgeo.2006.05.009
   Carr H, 2009, MATH VIS, P59, DOI 10.1007/978-3-540-88606-8_5
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Chiang YJ, 2005, COMP GEOM-THEOR APPL, V30, P165, DOI 10.1016/j.comgeo.2004.05.002
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   GIBBONS J, 1994, SCI COMPUT PROGRAM, V23, P1, DOI 10.1016/0167-6423(94)00013-1
   Gueunet C, 2017, SYMP LARG DATA ANAL, P6, DOI 10.1109/LDAV.2017.8231846
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Guo F, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.155005
   Heitmann K, 2015, ASTROPHYS J SUPPL S, V219, DOI 10.1088/0067-0049/219/2/34
   Hristov P., 2021, IN PRESS, V6
   Hristov P, 2020, SYMP LARG DATA ANAL, P12, DOI 10.1109/LDAV51489.2020.00008
   Kanitsar A, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P489, DOI 10.1109/VISUAL.2002.1183812
   Klacansky P, 2020, IEEE T VIS COMPUT GR, V26, P173, DOI 10.1109/TVCG.2019.2934257
   Landge AG, 2014, INT CONF HIGH PERFOR, P1020, DOI 10.1109/SC.2014.88
   Lo L.-t., 2012, PISTON PORTABLE CROS, P11
   Maadasamy S, 2012, INT C HIGH PERFORM
   Miller Gary L., 1989, Advances in Computing Research, V5, P47
   Moreland K, 2016, IEEE COMPUT GRAPH, V36, P48, DOI 10.1109/MCG.2016.48
   Morozov D., 2014, Topological methods in data analysis and visualization, III: Theory, algorithms, and applications, P89, DOI DOI 10.1007/978-3-319-04099-86
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Pascucci V, 2004, ALGORITHMICA, V38, P249, DOI 10.1007/s00453-003-1052-3
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Patchett J, 2017, LAUR1721595 LOS AL N
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Schroeder W., 2006, VISUALIZATION TOOLKI
   Sewell Christopher, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P25, DOI 10.1109/LDAV.2013.6675155
   Smirnov D., 2020, Topological Methods in Data Analysis and Visualization V: Theory, Algorithms, and Applications, V7, P19
   TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   U.S. Geological Survey, 1996, GTOPO30 COURT US GEO
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P330, DOI 10.1109/TVCG.2007.47
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
NR 41
TC 4
Z9 4
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3471
EP 3485
DI 10.1109/TVCG.2021.3064385
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100012
PM 33684039
OA Green Submitted, Green Accepted, Bronze
DA 2024-11-06
ER

PT J
AU Zhang, YJ
   Wang, R
   Huo, YC
   Hua, W
   Bao, HJ
AF Zhang, Yunjin
   Wang, Rui
   Huo, Yuchi
   Hua, Wei
   Bao, Hujun
TI PowerNet: Learning-Based Real-Time Power-Budget Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Power demand; Real-time systems;
   Predictive models; Neural networks; Integrated circuit modeling;
   Computational modeling; Power-budget rendering; rendering system; neural
   network
AB With the prevalence of embedded GPUs on mobile devices, power-efficient rendering has become a widespread concern for graphics applications. Reducing the power consumption of rendering applications is critical for extending battery life. In this paper, we present a new real-time power-budget rendering system to meet this need by selecting the optimal rendering settings that maximize visual quality for each frame under a given power budget. Our method utilizes two independent neural networks trained entirely by synthesized datasets to predict power consumption and image quality under various workloads. This approach spares time-consuming precomputation or runtime periodic refitting and additional error computation. We evaluate the performance of the proposed framework on different platforms, two desktop PCs and two smartphones. Results show that compared to the previous state of the art, our system has less overhead and better flexibility. Existing rendering engines can integrate our system with negligible costs.
C1 [Zhang, Yunjin; Wang, Rui; Huo, Yuchi; Hua, Wei; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, R (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM zhangyunjin@zju.edu.cn; rwang@cad.zju.edu.cn; huo.yuchi.sc@gmail.com;
   huawei@cad.zju.edu.cn; bao@cad.zju.edu.cn
OI Bao, Hujun/0000-0002-2662-0334; Zhang, Yunjin/0000-0003-3582-8900
FU NSFC [61872319]; Zhejiang Provincial NSFC [LR18F020002]; National Key
   R&D Programof China [2017YFB1002605]
FX The authors would like to thank all reviewers and editors for their
   insightful comments. This work was partially funded by NSFC under Grant
   No. 61872319, Zhejiang Provincial NSFC under Grant No. LR18F020002, and
   the National Key R&D Programof China under Grant No. 2017YFB1002605.
CR [Anonymous], 1996, Mobile Computing
   Belcour L, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073620
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Chen HL, 2015, ADV SOC BEHAV SCI, V9, P105, DOI 10.1109/ICDSP.2015.7251839
   Chen WF, 2016, COMPUT GRAPH-UK, V54, P57, DOI 10.1016/j.cag.2015.07.015
   Clarberg P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601214
   Davidovic T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602144
   Dong MA, 2012, IEEE T MOBILE COMPUT, V11, P1587, DOI 10.1109/TMC.2011.167
   Dugas C, 2001, ADV NEUR IN, V13, P472
   Dupuy J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073694
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gharbi M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322954
   He ST, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P27, DOI 10.1145/2789168.2790117
   He Y, 2014, ACM T GRAPHIC, V33, P1
   Heitz E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925895
   Huo YC, 2020, COMPUT GRAPH FORUM, V39, P192, DOI 10.1111/cgf.14011
   Huo YC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3368313
   Huo YC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980244
   Huo YC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818120
   Hwang C, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P422, DOI 10.1145/3117811.3117841
   Jimenez J., 2011, ACM SIGGRAPH 2011 Courses, SIGGRAPH'11, p6:1
   Jimenez J, 2012, COMPUT GRAPH FORUM, V31, P355, DOI 10.1111/j.1467-8659.2012.03014.x
   Kim S, 2018, COMPUT GRAPH-UK, V70, P198, DOI 10.1016/j.cag.2017.07.017
   Le Sueur E., 2010, P INT C POW AW COMP, P1, DOI DOI 10.5555/1924920.1924921
   Lecocq P, 2017, IEEE T VIS COMPUT GR, V23, P1428, DOI 10.1109/TVCG.2017.2656889
   Mathias P., 2016, ARM MALI GPU MIDGARD
   McGuire M, 2017, IEEE T VIS COMPUT GR, V23, P1465, DOI 10.1109/TVCG.2017.2656082
   Moon B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766992
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Nixon K.L., 2014, Purdue E-Pubs, P1
   NVML, 2019, NV MAN LIBR
   Pool Jeff., 2011, Proceedings of the ACM SIGGRAPH Symposium on High Performance Graphics. HPG'11, P159, DOI DOI 10.1145/2018323.2018349
   PowerVR, 2012, MAST CLASS GRAPH TEC
   Ragan-Kelley J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966396
   Ren PR, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462009
   Silvennoinen A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130852
   Stachowiak T., 2015, PROC ACM SIGGRAPH 20, P1
   Vatjus-Anttila Jarkko M., 2013, 2013 Seventh International Conference on Next-Generation Mobile Apps, Services and Technologies (NGMAST), P210, DOI 10.1109/NGMAST.2013.45
   Vicini D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322974
   Vogels T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201388
   Wang R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925889
   Wang R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508413
   Wyman C., 2018, ACM SIGGRAPH 2018 CO
   Xu B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356547
   Xu K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508386
   Yan LQ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130802
   Yang LC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356511
   Zhang YJ, 2018, COMPUT GRAPH FORUM, V37, P155, DOI 10.1111/cgf.13483
   Zsolnai-Fehér K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201307
NR 50
TC 2
Z9 3
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3486
EP 3498
DI 10.1109/TVCG.2021.3064367
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100013
PM 33684038
DA 2024-11-06
ER

PT J
AU Li, YS
   Baciu, G
AF Li, Yushi
   Baciu, George
TI SG-GAN: Adversarial Self-Attention GCN for Point Cloud Topological Parts
   Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Gallium nitride; Training; Shape; Generative
   adversarial networks; Solid modeling; Convolution; Generative
   adversarial network; graph convolution network; binary tree;
   self-attention; 3D shape generation; point cloud learning; gradient
   penalty
AB Point clouds are fundamental in the representation of 3D objects. However, they can also be highly unstructured and irregular. This makes it difficult to directly extend 2D generative models to three-dimensional space. In this article, we cast the problem of point cloud generation as a topological representation learning problem. In order to capture the representative features of 3D shapes in the latent space, we propose a hierarchical mixture model that integrates self-attention with an inference tree structure for constructing a point cloud generator. Based on this, we design a novel Generative Adversarial Network (GAN) architecture that is capable of generating recognizable point clouds in an unsupervised manner. The proposed adversarial framework (SG-GAN) relies on self-attention mechanism and Graph Convolution Network (GCN) to hierarchically infer the latent topology of 3D shapes. Embedding and transferring the global topology information in a tree framework allows our model to capture and enhance the structural connectivity. Furthermore, the proposed architecture endows our model with partially generating 3D structures. Finally, we propose two gradient penalty methods to stabilize the training of SG-GAN and overcome the possible mode collapse of GAN networks. To demonstrate the performance of our model, we present both quantitative and qualitative evaluations and show that SG-GAN is more efficient in training and it exceeds the state-of-the-art in 3D point cloud generation.
C1 [Li, Yushi; Baciu, George] Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Li, YS (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hung Hom, Hong Kong, Peoples R China.
EM csysli@comp.polyu.edu.hk; csgeorge@polyu.edu.hk
RI Baciu, George/AAU-7143-2021
OI BACIU, George/0000-0002-1766-6357; li, yushi/0000-0001-7164-5605
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Chen C, 2019, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR.2019.00513
   Defferrard M, 2016, ADV NEUR IN, V29
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Henaff M, 2015, Arxiv, DOI arXiv:1506.05163
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Gulrajani I, 2017, ADV NEUR IN, V30
   Joseph-Rivlin M, 2019, IEEE INT CONF COMP V, P4085, DOI 10.1109/ICCVW.2019.00503
   Kodali N, 2017, Arxiv, DOI arXiv:1705.07215
   LeCun Y, 2013, P INT C LEARN REPR I
   Lee J, 2019, PR MACH LEARN RES, V97
   Lei H, 2019, PROC CVPR IEEE, P9623, DOI 10.1109/CVPR.2019.00986
   Li CL, 2018, Arxiv, DOI arXiv:1810.05795
   Li YY, 2018, ADV NEUR IN, V31
   Lin HX, 2019, IEEE INT CON MULTI, P326, DOI 10.1109/ICME.2019.00064
   Liu YC, 2019, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2019.00534
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, 10.48550/arXiv.1609.02907]
   Pumarola A, 2020, PROC CVPR IEEE, P7946, DOI 10.1109/CVPR42600.2020.00797
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Shu DW, 2019, IEEE I CONF COMP VIS, P3858, DOI 10.1109/ICCV.2019.00396
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Sun YB, 2020, IEEE WINT CONF APPL, P61, DOI [10.1109/WACV45572.2020.9093430, 10.1109/wacv45572.2020.9093430]
   Te GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P746, DOI 10.1145/3240508.3240621
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Valsesia D., 2018, INT C LEARNING REPRE
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yang JC, 2019, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2019.00344
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
NR 43
TC 12
Z9 12
U1 9
U2 45
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3499
EP 3512
DI 10.1109/TVCG.2021.3069195
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100014
PM 33769934
DA 2024-11-06
ER

PT J
AU Fernstad, SJ
   Westberg, JJ
AF Fernstad, Sara Johansson
   Westberg, Jimmy Johansson
TI To Explore What Isn't There-Glyph-Based Visualization for Analysis of
   Missing Values
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Image color analysis; Statistical
   analysis; Heating systems; Decision making; Uncertainty; Missing data;
   information visualization; glyphs
ID VISUAL ANALYSIS; INFERENCE
AB This article contributes a novel visualization method, Missingness Glyph, for analysis and exploration of missing values in data. Missing values are a common challenge in most data generating domains and may cause a range of analysis issues. Missingness in data may indicate potential problems in data collection and pre-processing, or highlight important data characteristics. While the development and improvement of statistical methods for dealing with missing data is a research area in its own right, mainly focussing on replacing missing values with estimated values, considerably less focus has been put on visualization of missing values. Nonetheless, visualization and explorative analysis has great potential to support understanding of missingness in data, and to enable gaining of novel insights into patterns of missingness in a way that statistical methods are unable to. The Missingness Glyph supports identification of relevant missingness patterns in data, and is evaluated and compared to two other visualization methods in context of the missingness patterns. The results are promising and confirms that the Missingness Glyph in several cases perform better than the alternative visualization methods.
C1 [Fernstad, Sara Johansson] Newcastle Univ, Newcastle Upon Tyne, Tyne & Wear, England.
   [Westberg, Jimmy Johansson] Linkoping Univ, S-58183 Linkoping, Sweden.
C3 Newcastle University - UK; Linkoping University
RP Fernstad, SJ (corresponding author), Newcastle Univ, Newcastle Upon Tyne, Tyne & Wear, England.
EM sara.fernstad@newcastle.ac.uk; jimmy.johansson@liu.se
OI Johansson Fernstad, Sara/0000-0003-4518-5144
CR Triana JA, 2019, INFORM VISUAL, V18, P384, DOI 10.1177/1473871618821255
   Andreasson R, 2014, IEEE INT CONF INF VI, P132, DOI 10.1109/IV.2014.77
   [Anonymous], 2012, MIP MULTIPLE IMPUTAT
   [Anonymous], 1996, Journal of Computational and Graphical Statistics, DOI [10.1080/106 18600.1996.10474700., DOI 10.1080/10618600.1996.10474700, DOI 10.2307/1390776]
   Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x
   Arbesser C, 2017, IEEE T VIS COMPUT GR, V23, P641, DOI 10.1109/TVCG.2016.2598592
   Armstrong RA, 2014, OPHTHAL PHYSL OPT, V34, P502, DOI 10.1111/opo.12131
   Asuncion A., 2007, School of Information and Computer Sciences
   BEDDOW J, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P238, DOI 10.1109/VISUAL.1990.146387
   Borgo R., 2013, P EUR, P39, DOI [DOI 10.2312/CONF/EG2013/STARS/039-063, 10.2312/conf/EG2013/stars/039-063]
   Carpenter JR, 2013, Multiple imputation and its application, V1st
   Cedilnik A, 2000, IEEE VISUAL, P77, DOI 10.1109/VISUAL.2000.885679
   Cheng XY, 2015, J STAT SOFTW, V68, P1, DOI 10.18637/jss.v068.i06
   Chung DHS, 2015, INFORM VISUAL, V14, P76, DOI 10.1177/1473871613511959
   Cumming G, 2005, AM PSYCHOL, V60, P170, DOI 10.1037/0003-066X.60.2.170
   DAYAL BS, 1994, PULP PAP-CANADA, V95, P26
   Djurcilov S, 2000, IEEE COMPUT GRAPH, V20, P52, DOI 10.1109/38.865880
   Eaton C, 2005, LECT NOTES COMPUT SC, V3585, P861, DOI 10.1007/11555261_68
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fernstad SJ, 2019, INFORM VISUAL, V18, P230, DOI 10.1177/1473871618785387
   Fernstad SJ, 2014, IEEE CONF VIS ANAL, P249, DOI 10.1109/VAST.2014.7042514
   Fielding S, 2009, HEALTH QUAL LIFE OUT, V7, DOI 10.1186/1477-7525-7-57
   Graziano A.M., 1997, Research Methods, A Process of Inquiry
   Gschwandtner T, 2018, IEEE PAC VIS SYMP, P205, DOI 10.1109/PacificVis.2018.00034
   Honaker J, 2011, J STAT SOFTW, V45, P1
   Johansson J, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P188, DOI 10.1109/IV.2005.1
   Kahraman HT, 2013, KNOWL-BASED SYST, V37, P283, DOI 10.1016/j.knosys.2012.08.009
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kirk A., 2014, VISUALIZING ZERO SHO
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lichman M., 2013, UCI MACHINE LEARNING
   Little MA, 2007, BIOMED ENG ONLINE, V6, DOI 10.1186/1475-925X-6-23
   Maguire E, 2012, IEEE T VIS COMPUT GR, V18, P2603, DOI 10.1109/TVCG.2012.271
   Pilhöfer A, 2013, J STAT SOFTW, V53, P1
   QUINLAN PT, 1987, PERCEPT PSYCHOPHYS, V41, P455, DOI 10.3758/BF03203039
   RUBIN DB, 1976, BIOMETRIKA, V63, P581, DOI 10.2307/2335739
   Schulz HJ, 2017, INFORM VISUAL, V16, P232, DOI 10.1177/1473871616667767
   Song H, 2019, IEEE T VIS COMPUT GR, V25, P914, DOI 10.1109/TVCG.2018.2864914
   Swayne DF, 2003, COMPUT STAT DATA AN, V43, P423, DOI 10.1016/S0167-9473(02)00286-4
   Swayne DF, 1998, COMPUTATION STAT, V13, P15
   Templ M, 2012, ADV DATA ANAL CLASSI, V6, P29, DOI 10.1007/s11634-011-0102-y
   Theus M, 1997, NEW TECHNIQUES AND TECHNOLOGIES FOR STATISTICS II, P247
   Tierney NJ, 2018, ARXIV
   Twiddy R., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P212, DOI 10.1109/VISUAL.1994.346317
   Unwin A, 2015, R SERIES, P1
   WANG H, 2007, P INT C ADV VIS INF, P267
   Wang H., 2008, DATA WAREHOUSING MIN, P3027
   Wong BL William., 2012, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V56, P287
   Xie ZX, 2006, IEEE CONF VIS ANAL, P183
   Yeh IC, 1998, CEMENT CONCRETE RES, V28, P1797, DOI 10.1016/S0008-8846(98)00165-3
NR 51
TC 2
Z9 2
U1 3
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3513
EP 3529
DI 10.1109/TVCG.2021.3065124
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100015
PM 33690119
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kumpf, A
   Stumpfegger, J
   Härtl, PF
   Westermann, R
AF Kumpf, Alexander
   Stumpfegger, Josef
   Haertl, Patrick Fabian
   Westermann, Ruediger
TI Visual Analysis of Multi-Parameter Distributions Across Ensembles of 3D
   Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Uncertainty; Rendering
   (computer graphics); Visual analytics; Market research; Isosurfaces;
   Ensemble visualization; multi-parameter visualization; 3D rendering;
   distribution comparison; parallel coordinates
ID VISUALIZATION; UNCERTAINTY; EXPLORATION
AB For an ensemble of 3D multi-parameter fields, we present a visual analytics workflow to analyse whether and which parts of a selected multi-parameter distribution is present in all ensemble members. Supported by a parallel coordinate plot, a multi-parameter brush is applied to all ensemble members to select data points with similar multi-parameter distribution. By a combination of spatial sub-division and a covariance analysis of partitioned sub-sets of data points, a tight partition in multi-parameter space with reduced number of selected data points is obtained. To assess the representativeness of the selected multi-parameter distribution across the ensemble, we propose a novel extension of violin plots that can show multiple parameter distributions simultaneously. We investigate the visual design that effectively conveys (dis-)similarities in multi-parameter distributions, and demonstrate that users can quickly comprehend parameter-specific differences regarding distribution shape and representativeness from a side-by-side view of these plots. In a 3D spatial view, users can analyse and compare the spatial distribution of selected data points in different ensemble members via interval-based isosurface raycasting. In two real-world application cases we show how our approach is used to analyse the multi-parameter distributions across an ensemble of 3D fields.
C1 [Kumpf, Alexander; Stumpfegger, Josef; Haertl, Patrick Fabian; Westermann, Ruediger] Tech Univ Munich TUM, Comp Graph & Visualizat Grp, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Kumpf, A (corresponding author), Tech Univ Munich TUM, Comp Graph & Visualizat Grp, D-80333 Munich, Germany.
EM alexander.kumpf@tum.de; josefStumpfegger@outlook.de;
   patrick.haertl@tum.de; westermann@tum.de
OI Stumpfegger, Josef/0000-0002-2553-184X; Westermann,
   Rudiger/0000-0002-3394-0731
FU Transregional Collaborative Research Center SFB/TRR 165 Waves - German
   Research Foundation (DFG)
FX This research has been done within the subproject B5 of the
   Transregional Collaborative Research Center SFB/TRR 165 Waves to Weather
   funded by the German Research Foundation (DFG).
CR [Anonymous], 2010, PRINCIPAL COMPONENT
   [Anonymous], 2017, GRAPHICAL METHODS DA
   Baumgartner C, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P11, DOI 10.1109/ICDM.2004.10112
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Blumenschein M, 2020, COMPUT GRAPH FORUM, V39, P537, DOI 10.1111/cgf.14000
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Bunte K, 2012, NEUROCOMPUTING, V90, P23, DOI 10.1016/j.neucom.2012.02.034
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chambers John M, 1983, GRAPHICAL METHODS DA
   Cheng C.-H., 1999, P INT C KNOWL DISC D, P84, DOI [10.1145/312129.312199, DOI 10.1145/312129.312199]
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   Demir I., 2016, PROC SIGGRAPH ASIA S
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Doleisch H., 2004, P 2004 EUROGRAPHICSI, P91, DOI 10.2312/VisSym/VisSym04/091-096
   Dutta S, 2016, IEEE T VIS COMPUT GR, V22, P837, DOI 10.1109/TVCG.2015.2467436
   Ferdosi BJ, 2011, COMPUT GRAPH FORUM, V30, P1121, DOI 10.1111/j.1467-8659.2011.01961.x
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Fofonov A, 2016, IEEE T VIS COMPUT GR, V22, P2037, DOI 10.1109/TVCG.2015.2498554
   Gama S., 2014, EUROVIS SHORT PAPERS, DOI [10.2312/eurovisshort.20141168, DOI 10.2312/EUROVISSHORT.20141168]
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hauser H., 2004, IEEE VIS CONTEST
   Hazarika S, 2019, IEEE T VIS COMPUT GR, V25, P1214, DOI 10.1109/TVCG.2018.2864801
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   He WB, 2020, VIS INFORM, V4, P109, DOI 10.1016/j.visinf.2020.04.004
   Heinrich J., 2013, EUROGRAPHICS STATE A, P95, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/CONF/EG2013/STARS/095-116]
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   Höllt T, 2014, IEEE T VIS COMPUT GR, V20, P1114, DOI 10.1109/TVCG.2014.2307892
   Höllt T, 2013, IEEE PAC VIS SYMP, P185, DOI 10.1109/PacificVis.2013.6596144
   Inselberg A., 1991, HUMAN MACHINE INTERA, P199
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Jarema M, 2015, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2015.7347634
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kumpf A., 2019, PROC 24 INT S VIS MO, DOI 10.2312/vmv.20191320
   Lex A, 2010, IEEE T VIS COMPUT GR, V16, P1027, DOI 10.1109/TVCG.2010.138
   Linsen L, 2008, IEEE T VIS COMPUT GR, V14, P1483, DOI 10.1109/TVCG.2008.167
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Love AL, 2005, IEEE COMPUT GRAPH, V25, P69, DOI 10.1109/MCG.2005.71
   MacDonald J. D., 1990, Visual Computer, V6, P153, DOI 10.1007/BF01911006
   Molchanov V, 2018, VISIGRAPP 2018: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS / INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS (IVAPP), VOL 3, P29, DOI 10.5220/0006541900290039
   Morrison A, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P152, DOI 10.1109/INFVIS.2002.1173161
   Nam JE, 2013, IEEE T VIS COMPUT GR, V19, P291, DOI 10.1109/TVCG.2012.65
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Potter K, 2010, COMPUT GRAPH FORUM, V29, P823, DOI 10.1111/j.1467-8659.2009.01677.x
   Raidou RG, 2016, IEEE T VIS COMPUT GR, V22, P589, DOI 10.1109/TVCG.2015.2467872
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Roberts RC, 2019, IEEE T VIS COMPUT GR, V25, P1575, DOI 10.1109/TVCG.2018.2808969
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shusen Liu, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P73, DOI 10.1109/LDAV.2012.6378978
   Swinbank R, 2016, B AM METEOROL SOC, V97, P49, DOI 10.1175/BAMS-D-13-00191.1
   Thompson D., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P23, DOI 10.1109/LDAV.2011.6092313
   Torsney-Weir T, 2011, IEEE T VIS COMPUT GR, V17, P1892, DOI 10.1109/TVCG.2011.248
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Long T, 2009, COMPUT GRAPH FORUM, V28, P823, DOI 10.1111/j.1467-8659.2009.01468.x
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang KC, 2017, IEEE PAC VIS SYMP, P161, DOI 10.1109/PACIFICVIS.2017.8031590
   Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P326, DOI 10.1109/VISUAL.1994.346302
   Wellmann C, 2018, J ADV MODEL EARTH SY, V10, P3103, DOI 10.1029/2018MS001465
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Williams M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2004.60
   Ying-Huey Fua, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P43, DOI 10.1109/VISUAL.1999.809866
   Ying-Huey Fua, 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P58, DOI 10.1109/INFVIS.1999.801858
NR 69
TC 3
Z9 3
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3530
EP 3545
DI 10.1109/TVCG.2021.3061925
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100016
PM 33625986
DA 2024-11-06
ER

PT J
AU Yao, LJ
   Bezerianos, A
   Vuillemot, R
   Isenberg, P
AF Yao, Lijie
   Bezerianos, Anastasia
   Vuillemot, Romain
   Isenberg, Petra
TI Visualization in Motion: A Research Agenda and Two Evaluations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Sports; Games; Visualization; Trajectory; Animation;
   Complexity theory; Visualization; visualization in motion; perception;
   research agenda; movement; motion
ID DYNAMIC VISUAL-ACUITY; MOVING TEST OBJECTS; INFORMATION VISUALIZATION;
   ANIMATED TRANSITIONS; AUGMENTED REALITY; OCULAR PURSUIT; EYE-MOVEMENTS;
   PERCEPTION; EXPLORATION; PERFORMANCE
AB We contribute a research agenda for visualization in motion and two experiments to understand how well viewers can read data from moving visualizations. We define visualizations in motion as visual data representations that are used in contexts that exhibit relative motion between a viewer and an entire visualization. Sports analytics, video games, wearable devices, or data physicalizations are example contexts that involve different types of relative motion between a viewer and a visualization. To analyze the opportunities and challenges for designing visualization in motion, we show example scenarios and outline a first research agenda. Motivated primarily by the prevalence of and opportunities for visualizations in sports and video games we started to investigate a small aspect of our research agenda: the impact of two important characteristics of motion-speed and trajectory on a stationary viewer's ability to read data from moving donut and bar charts. We found that increasing speed and trajectory complexity did negatively affect the accuracy of reading values from the charts and that bar charts were more negatively impacted. In practice, however, this impact was small: both charts were still read fairly accurately.
C1 [Yao, Lijie; Bezerianos, Anastasia; Isenberg, Petra] Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 Gif Sur Yvette, France.
   [Vuillemot, Romain] Univ Lyon, Ecole Cent Lyon, UMR5205, CNRS,LIRIS, F-69134 Lyon, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   Paris Cite; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); Institut National des Sciences Appliquees de Lyon -
   INSA Lyon; Ecole Centrale de Lyon
RP Yao, LJ (corresponding author), Univ Paris Saclay, LISN, INRIA, CNRS, F-91190 Gif Sur Yvette, France.
EM lijie.yao@inria.fr; anastasia.bezerianos@lri.fr;
   romain.vuillemot@ec-lyon.fr; petra.isenberg@inria.fr
RI Yao, Lijie/ISS-7925-2023; Vuillemot, Romain/ABE-5719-2020
OI Bezerianos, Anastasia/0000-0002-7142-2548; Isenberg,
   Petra/0000-0002-2948-6417; Yao, Lijie/0000-0002-4208-5140; Vuillemot,
   Romain/0000-0003-1447-6926
CR Afonso AP, 2019, MULTIMED TOOLS APPL, V78, P33069, DOI 10.1007/s11042-019-07952-z
   Afsari Z, 2016, J VISION, V16, DOI 10.1167/16.11.8
   Amini Fereshteh, 2017, P 11 EAI INT C PERV, P163, DOI [10.1145/3154862.3154879, DOI 10.1145/3154862.3154879]
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bach B, 2014, IEEE T VIS COMPUT GR, V20, P740, DOI 10.1109/TVCG.2013.254
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Bezerianos A, 2012, IEEE T VIS COMPUT GR, V18, P2516, DOI 10.1109/TVCG.2012.251
   Bladh T, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P297, DOI 10.1109/IV.2005.122
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P630, DOI 10.1109/TVCG.2018.2865142
   Bowman B, 2012, IEEE T VIS COMPUT GR, V18, P1956, DOI 10.1109/TVCG.2012.77
   Bressa N, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P173, DOI 10.1145/3322276.3322326
   BROWN B, 1972, VISION RES, V12, P305, DOI 10.1016/0042-6989(72)90120-4
   Buschel Wolfgang, 2021, P 2021 CHI C HUM FAC, P1, DOI [DOI 10.1145/3411764.3445651, 10.1145/3411764.3445651]
   Cai X, 2018, COMPUT GRAPH FORUM, V37, P300, DOI 10.1111/cgf.13325
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chevalier F, 2014, IEEE T VIS COMPUT GR, V20, P2241, DOI 10.1109/TVCG.2014.2346424
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Croxton FE, 1927, J AM STAT ASSOC, V22, P473, DOI 10.2307/2276829
   Cumming G, 2005, AM PSYCHOL, V60, P170, DOI 10.1037/0003-066X.60.2.170
   Di Bartolomeo S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376237
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Díaz J, 2018, IEEE INT CON INF VIS, P159, DOI 10.1109/iV.2018.00037
   Dragicevic P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2009
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Eells WC, 1926, J AM STAT ASSOC, V21, P119, DOI 10.2307/2277140
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Fagard J, 2003, LATERALITY, V8, P39, DOI 10.1080/713754473
   FC Barcelone, BARCA MALLORCA 20192
   FootoVision, About us
   Gonçalves T, 2018, IEEE INT CON INF VIS, P103, DOI 10.1109/iV.2018.00028
   GRANAAS MM, 1984, HUM FACTORS, V26, P97, DOI 10.1177/001872088402600109
   Greene MR, 2009, PSYCHOL SCI, V20, P464, DOI 10.1111/j.1467-9280.2009.02316.x
   GROSSMAN GE, 1989, J NEUROPHYSIOL, V62, P264, DOI 10.1152/jn.1989.62.1.264
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hernandez MD, 2017, J CONSUM MARK, V34, P1, DOI 10.1108/JCM-02-2016-1710
   Higgins JJ., 2004, Introduction to modern nonparametric statistics
   Hillman EJ, 1999, J VESTIBUL RES-EQUIL, V9, P49
   Hollands JG, 1998, APPL COGNITIVE PSYCH, V12, P173, DOI 10.1002/(SICI)1099-0720(199804)12:2<173::AID-ACP499>3.0.CO;2-K
   Hornbaek K., 2002, ACM Transactions on Computer-Human Interaction, V9, P362, DOI 10.1145/586081.586086
   Isenberg P, 2013, IEEE T VIS COMPUT GR, V19, P2346, DOI 10.1109/TVCG.2013.163
   Jakobsen MR, 2013, IEEE T VIS COMPUT GR, V19, P2386, DOI 10.1109/TVCG.2013.166
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jetter HC, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P83, DOI 10.1145/2254556.2254575
   KANG TJ, 1989, BEHAV INFORM TECHNOL, V8, P33, DOI 10.1080/01449298908914536
   Kaplan O, 2016, IEEE SYS MAN CYBERN, P994, DOI 10.1109/SMC.2016.7844371
   Karduni A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376365
   Kong N, 2010, IEEE T VIS COMPUT GR, V16, P990, DOI 10.1109/TVCG.2010.186
   Krzywinski M, 2013, NAT METHODS, V10, P921, DOI 10.1038/nmeth.2659
   Langner Ricardo, 2021, MOBILE DATA VISUALIZ, P1
   Li D, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND ARTIFICIAL INTELLIGENCE (ISAI 2016), P1, DOI [10.1109/ISAI.2016.59, 10.1109/ISAI.2016.0010]
   Li Q, 2017, IEEE T VIS COMPUT GR, V23, P211, DOI 10.1109/TVCG.2016.2598415
   Lin T., 2021, P ACM C HUM FACT COM, P13, DOI [DOI 10.1145/3411764.34456492, 10.1145/3411764.34456492,9, DOI 10.1145/3411764.34456492,9, 10.1145/3411764.3445649, DOI 10.1145/3411764.3445649]
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   LUDVIGH E, 1958, J OPT SOC AM, V48, P799, DOI 10.1364/JOSA.48.000799
   Ludvigh E., 1953, SCH AVIAT MED JOINT
   Ludvigh E., 1953, A study of Dynamic Visual Acuity
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   Madsen JB, 2016, IEEE T VIS COMPUT GR, V22, P1415, DOI 10.1109/TVCG.2016.2518318
   Makita K, 2009, IEEE INT CON MULTI, P982, DOI 10.1109/ICME.2009.5202661
   Mashat A. A, 2017, THESIS OLD DOMINION, DOI [10.25777/VAWY-5Q63, DOI 10.25777/VAWY-5Q63]
   Mengtian Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P473, DOI 10.1007/978-3-030-58536-5_28
   MILLER JW, 1958, J OPT SOC AM, V48, P803, DOI 10.1364/JOSA.48.000803
   Mustonen T., 2004, Extended abstracts of the 2004 conference on Human factors and computing systems - CHI '04, P1243, DOI DOI 10.1145/985921.986034
   Neshati Ali, 2019, Stud Health Technol Inform, V257, P325
   Neshati Ali, 2019, P GRAPHICS INTERFACE, P1, DOI [10.20380/GI2019.23, DOI 10.20380/GI2019.23]
   Peters BT, 2005, ACTA OTO-LARYNGOL, V125, P353, DOI 10.1080/00016480410024631
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Prolific, About us
   Redmond S, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P106, DOI [10.1109/visual.2019.8933718, 10.1109/VISUAL.2019.8933718]
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Ripoll P., ODDATA SPATIAL FILTE
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Rodighiero D., 2018, PROC TRANSDISCIPLINA, P58, DOI DOI 10.6084/M9.FIGSHARE.6104693.V2
   RODIGHIERO D, 2021, MAPPING AFFINITIES D
   Roth RE, 2015, ISPRS INT J GEO-INF, V4, P262, DOI 10.3390/ijgi4010262
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Schiewe Alexander, 2020, 19 INT C MOB UB MULT, P18, DOI [DOI 10.1145/3428361.34284092, 10.1145/3428361.3428409, DOI 10.1145/3428361.3428409]
   Schildbach Bastian, 2010, P 12 INT C HUM COMP, P93, DOI [DOI 10.1145/1851600.18516192, 10.1145/1851600.1851619, DOI 10.1145/1851600.1851619]
   Shanmugasundaram Maruthappan, 2007, Proceedings Graphics Interface 2007, P71, DOI 10.1145/1268517.1268531
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   Skau D, 2015, COMPUT GRAPH FORUM, V34, P221, DOI 10.1111/cgf.12634
   Skau Drew., 2017, EuroVis Short Papers, P91, DOI DOI 10.2312/EUROVISSHORT.20171139
   Smith AK, 2020, LATERALITY, V25, P5, DOI 10.1080/1357650X.2019.1577433
   Spering M, 2011, J NEUROPHYSIOL, V105, P1756, DOI 10.1152/jn.00344.2010
   SportBuzzBusiness, US
   SportsDynamics, US
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Thomas LE, 2010, COGNITION, V117, P80, DOI 10.1016/j.cognition.2010.07.002
   Tica L., 2020, PROC 4 WORKSHOP IMME
   Vadas K., 2006, P 8 C HUMAN COMPUTER, P219, DOI DOI 10.1145/1152215.1152262
   Veras R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300771
   Tran VH, 2021, IEEE COMPUT SOC CONF, P4223, DOI 10.1109/CVPRW53098.2021.00478
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   WEISSMAN S, 1965, J EXP PSYCHOL, V70, P141, DOI 10.1037/h0022214
   Wikipedia, HLTH GAME TERMINOLOG
   Wikipedia, HLTH BAR VIDEO GAMES
   Wikipedia, 7810ID1 ISO IEC
   Wikipedia, MOTION DEFINITION
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wu E, 2021, IEEE T VIS COMPUT GR, V27, P2566, DOI 10.1109/TVCG.2021.3067761
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Yao L., 2020, PROC POSTERS IEEE VI
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zhao MQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300462
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
   Ziemkiewicz C, 2010, IEEE COMPUT GRAPH, V30, P7, DOI 10.1109/MCG.2010.83
   Ziemkiewicz Caroline, 2010, P ADV VISUAL INTERFA, P215, DOI [10.1145/1842993.1843031, DOI 10.1145/1842993.1843031]
NR 116
TC 9
Z9 9
U1 2
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3546
EP 3562
DI 10.1109/TVCG.2022.3184993
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100017
PM 35727779
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Pandey, A
   Syeda, UH
   Shah, C
   Guerra-Gomez, JA
   Borkin, MA
AF Pandey, Aditeya
   Syeda, Uzma Haque
   Shah, Chaitya
   Guerra-Gomez, John A.
   Borkin, Michelle A.
TI A State-of-the-Art Survey of Tasks for Tree Design and Evaluation With a
   Curated Task Dataset
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Vegetation; Data visualization; Visualization;
   Terminology; Encoding; Taxonomy; STAR; tree; tasks; task abstraction;
   theory; datasets
ID INFORMATION VISUALIZATION; INTERACTIVE TREE; SPACE; MAPS; LIFE
AB In the field of information visualization, the concept of "tasks" is an essential component of theories and methodologies for how a visualization researcher or a practitioner understands what tasks a user needs to perform and how to approach the creation of a new design. In this article, we focus on the collection of tasks for tree visualizations, a common visual encoding in many domains ranging from biology to computer science to geography. In spite of their commonality, no prior efforts exist to collect and abstractly define tree visualization tasks. We present a literature review of tree visualization articles and generate a curated dataset of over 200 tasks. To enable effective task abstraction for trees, we also contribute a novel extension of the Multi-Level Task Typology to include more specificity to support tree-specific tasks as well as a systematic procedure to conduct task abstractions for tree visualizations. All tasks in the dataset were abstracted with the novel typology extension and analyzed to gain a better understanding of the state of tree visualizations. These abstracted tasks can benefit visualization researchers and practitioners as they design evaluation studies or compare their analytical tasks with ones previously studied in the literature to make informed decisions about their design. We also reflect on our novel methodology and advocate more broadly for the creation of task-based knowledge repositories for different types of visualizations. The Supplemental Material, which can be found on the Computer Society Digital Library at http://doi.ieeecomputersociety.org/10.1109/TVCG.2021.3064037, will be maintained on OSF: https://osf.io/u5ehs/.
C1 [Pandey, Aditeya; Syeda, Uzma Haque; Shah, Chaitya; Guerra-Gomez, John A.; Borkin, Michelle A.] Northeastern Univ, Boston, MA 02115 USA.
C3 Northeastern University
RP Pandey, A (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM pandey.ad@northeastern.edu; syeda.u@northeastern.edu;
   shah.cha@northeastern.edu; j.guerragomez@northeastern.edu;
   m.borkin@northeastern.edu
RI Guerra Gomez, John Alexis/AAT-1678-2020
OI Borkin, Michelle/0000-0002-8016-355X; Guerra-Gomez, John
   Alexis/0000-0001-7943-0000
FU NSF CISE CRII Award [1657466]
FX The authors would like to thank Hans-Jorg Schulz for initial feedback on
   the project idea. They are also thankful to Yixuan "Janice" Zhang, Cody
   Dunne, Micha Schwab, David Saffo, Sara Di Bartolomeo, Laura South and
   other members of visualization lab at Northeastern University for their
   feedback on the article. This manuscript benefited greatly from the
   comments of anonymous reviewers. They are grateful to Amriteya Pandey
   for contributing to our website development. Finally, they thank Jane
   Kokernak for her help with editing of the article. This work was
   supported by NSF CISE CRII Award no. 1657466.
CR Alsallakh B., 2014, PROC EUROGRAPH C VIS, DOI [10.2312/eurovisstar.20141170.001-021, DOI 10.2312/EUROVISSTAR.20141170.001-021]
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Andrews K., 2002, Information Visualization, V1, P166, DOI 10.1057/palgrave.ivs.9500023
   Andrews K, 2007, IEEE INT CONF INF VI, P81
   Andrienko G, 2011, J VISUAL LANG COMPUT, V22, P213, DOI 10.1016/j.jvlc.2011.02.003
   [Anonymous], 2017, P 10 INT S VISUAL IN, DOI DOI 10.1145/3105971.3105976
   [Anonymous], 2006, P 8 JOINT EUR IEEE V
   Auber D, 2013, IEEE T VIS COMPUT GR, V19, P1820, DOI 10.1109/TVCG.2013.91
   Band Z., 2006, CHI 06 EXTENDED ABST, P514
   Barlow T, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P131, DOI 10.1109/INFVIS.2001.963290
   Beheshti J., 2010, P AM SOC INFORM SCI, V46, P1
   Bladh T, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P297, DOI 10.1109/IV.2005.122
   Bladh T, 2004, LECT NOTES COMPUT SC, V3101, P50
   Blanch R, 2015, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2015.7156353
   Block F, 2012, IEEE T VIS COMPUT GR, V18, P2789, DOI 10.1109/TVCG.2012.272
   Borgo Rita, 2017, Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments. Revised Contributions: LNCS 10264, P96, DOI 10.1007/978-3-319-66435-4_5
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2440, DOI 10.1109/TVCG.2011.193
   Burch M, 2010, LECT NOTES COMPUT SC, V6453, P338
   Card SK, 2006, IEEE CONF VIS ANAL, P3
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   Chen Y, 2015, J VISUAL-JAPAN, V18, P237, DOI 10.1007/s12650-014-0269-3
   Cockburn A, 2000, BCS CONFERENCE S, P425
   Dang T, 2017, VOILA ISWC
   Dang T, 2017, IEEE PAC VIS SYMP, P210, DOI 10.1109/PACIFICVIS.2017.8031596
   Fekete J.-D., 2002, GEN TASKS APPL MOST
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   Görtler J, 2018, IEEE T VIS COMPUT GR, V24, P719, DOI 10.1109/TVCG.2017.2743959
   Golemati M, 2007, IEEE INT CONF INF VI, P93
   Gomez SR, 2017, IEEE T VIS COMPUT GR, V23, P1042, DOI 10.1109/TVCG.2016.2532331
   Gong LW, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P185, DOI 10.1109/ICVRV.2013.36
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Guerra-Gómez JA, 2013, IEEE T VIS COMPUT GR, V19, P2566, DOI 10.1109/TVCG.2013.231
   Hall LO, 1998, IEEE SYS MAN CYBERN, P2579, DOI 10.1109/ICSMC.1998.725047
   Harrigan M, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P53
   Heath H, 2004, INT J NURS STUD, V41, P141, DOI 10.1016/S0020-7489(03)00113-5
   Heinicke A, 2015, PROCEDIA MANUF, V3, P5427, DOI 10.1016/j.promfg.2015.07.669
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Holten D, 2008, COMPUT GRAPH FORUM, V27, P759, DOI 10.1111/j.1467-8659.2008.01205.x
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   JOHNSON B, 1991, VISUALIZATION 91, P284
   Kerracher N, 2015, IEEE T VIS COMPUT GR, V21, P1160, DOI 10.1109/TVCG.2015.2424889
   Kim NW, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3131275
   Kleiberg E, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P87, DOI 10.1109/INFVIS.2001.963285
   Kobsa A, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P9, DOI 10.1109/INFVIS.2004.70
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Letunic I, 2007, BIOINFORMATICS, V23, P127, DOI 10.1093/bioinformatics/btl529
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   LIANG J., 2012, 2012 16th International Conference on Information Visualisation, P74
   Lima M., 2014, The Book of Trees: Visualizing Branches of Knowledge
   Linsen L, 2011, COMPUTATION STAT, V26, P679, DOI 10.1007/s00180-011-0272-2
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P2482, DOI 10.1109/TVCG.2018.2834341
   Long LK, 2017, PROCEDIA COMPUT SCI, V124, P108, DOI 10.1016/j.procs.2017.12.136
   Mahyar N., 2015, WORKSHOP PERSONAL VI, V3, P2
   Soares AGM, 2018, IEEE INT CON INF VIS, P58, DOI 10.1109/iV.2018.00021
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Müller NH, 2017, ACHI 2017: THE TENTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER-HUMAN INTERACTIONS, P93
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Munzner T., 2000, THESIS STANFORD U
   Muramalla S, 2017, IADIS-INT J COMPUT S, V12, P17
   Neumann P., 2005, P 7 JOINT EUROGRAPHI, P53, DOI [DOI 10.2312/VISSYM/EUROVIS05/053-060, 10.1.1.73.1055&rep]
   Novick LR, 2012, BIOSCIENCE, V62, P757, DOI 10.1525/bio.2012.62.8.8
   Nusrat S, 2019, COMPUT GRAPH FORUM, V38, P781, DOI 10.1111/cgf.13727
   Nusrat S., 2015, EUR C VIS EUROVIS TH, DOI [10.2312/eurovisshort.20151126, DOI 10.2312/EUROVISSHORT.20151126]
   Ottley A, 2015, INFORM VISUAL, V14, P223, DOI 10.1177/1473871613513227
   Pandey A., 2020, DIGITAL COLLAB AUGME
   Plaisant C, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P57, DOI 10.1109/INFVIS.2002.1173148
   REINGOLD EM, 1981, IEEE T SOFTWARE ENG, V7, P223, DOI 10.1109/TSE.1981.234519
   Rosindell J, 2012, PLOS BIOL, V10, DOI 10.1371/journal.pbio.1001406
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Sallaberry A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149324
   Santos J. M., 2013, 2013 17 INT C INFORM, P422, DOI [10.1109/IV.2013.56, DOI 10.1109/IV.2013.56]
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shin H, 2011, COMPUT GRAPH FORUM, V30, P1131, DOI 10.1111/j.1467-8659.2011.01962.x
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Song H, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P223
   Stasko J, 2000, INT J HUM-COMPUT ST, V53, P663, DOI 10.1006/ijhc.2000.0420
   Tan DS, 2007, IEEE T VIS COMPUT GR, V13, P1113, DOI 10.1109/TVCG.2007.70537
   Therón R, 2006, LECT NOTES COMPUT SC, V4073, P70
   Tuttle C, 2010, IEEE T VIS COMPUT GR, V16, P1063, DOI 10.1109/TVCG.2010.185
   van de Wetering H, 2020, IEEE PAC VIS SYMP, P121, DOI 10.1109/PacificVis48177.2020.4908
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   van Ham F, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P93, DOI 10.1109/INFVIS.2002.1173153
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Viegas F., 2013, P 22 INT C WORLD WID, P1389
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wang TWD, 2006, LECT NOTES COMPUT SC, V4273, P695
   Wattenberg M, 2008, IEEE T VIS COMPUT GR, V14, P1221, DOI 10.1109/TVCG.2008.172
   Wiss U, 1998, IEEE INFOR VIS, P137, DOI 10.1109/IV.1998.694211
   Wiss U., 1999, 1999 IEEE International Conference on Information Visualization (Cat. No. PR00210), P392, DOI 10.1109/IV.1999.781587
   Woodburn L, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P96, DOI [10.1109/visual.2019.8933545, 10.1109/VISUAL.2019.8933545]
   Yu LY, 2010, IEEE T VIS COMPUT GR, V16, P1613, DOI 10.1109/TVCG.2010.157
   Zhao SD, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2005.1532129
   Ziemkiewicz C, 2008, IEEE T VIS COMPUT GR, V14, P1269, DOI 10.1109/TVCG.2008.171
NR 103
TC 8
Z9 9
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2022
VL 28
IS 10
BP 3563
EP 3584
DI 10.1109/TVCG.2021.3064037
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4G5UL
UT WOS:000849261100018
PM 33667165
OA Bronze, Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, JS
   Tversky, B
   Feiner, S
AF Liu, Jen-Shuo
   Tversky, Barbara
   Feiner, Steven
TI Precueing Object Placement and Orientation for Manual Tasks in Augmented
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Copper; Training; Manuals; Computer
   science; Collaboration; Augmented reality; precueing; cueing; manual
   tasks
ID SEE
AB When a user is performing a manual task, AR or VR can provide information about the current subtask (cueing) and upcoming subtasks (precueing) that makes them easier and faster to complete. Previous research on cueing and precueing in AR and VR has focused on path-following tasks requiring simple actions at each of a series of locations, such as pushing a button or just visiting. We consider a more complex task, whose subtasks involve moving to and picking up an item, moving that item to a designated place while rotating it to a specific angle, and depositing it. We conducted two user studies to examine how people accomplish this task while wearing an AR headset, guided by different visualizations that cue and precue movement and rotation. Participants performed best when given movement information for two successive subtasks and rotation information for a single subtask. In addition, participants performed best when the rotation visualization was split across the manipulated object and its destination.
C1 [Liu, Jen-Shuo; Feiner, Steven] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
   [Tversky, Barbara] Columbia Univ, Teachers Coll, Dept Human Dev, New York, NY 10027 USA.
C3 Columbia University; Columbia University Teachers College; Columbia
   University
RP Liu, JS (corresponding author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
EM jl5004@columbia.edu; bt2158@tc.columbia.edu; feiner@cs.columbia.edu
RI Tversky, Barbara/KWT-7222-2024
OI Liu, Jen-Shuo/0000-0002-4109-5769
FU National Science Foundation [CMMI-2037101]
FX This research was funded in part by National Science Foundation Grant
   CMMI-2037101. We thank Portia Wang for her assistance in making the
   video.
CR Alvarez GA, 2007, J VISION, V7, DOI 10.1167/7.13.14
   Andrist S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2571, DOI 10.1145/3025453.3026033
   [Anonymous], UN
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Chen L, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3485297
   Cowan N., 2007, TALL TALES BRAIN THI, P45, DOI DOI 10.1093/ACPROF:OSO/9780198568773.003.0005
   Ellis SR, 1997, P IEEE VIRT REAL ANN, P138, DOI 10.1109/VRAIS.1997.583063
   Elvezio C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174162
   Gilbreth Frank., 1919, Applied Motion Study: A Collection of Papers on the Efficient Method to Industrial Preparedness
   Herbert Dean, HOME
   Hertzum M, 2013, INT J HUM-COMPUT INT, V29, P338, DOI 10.1080/10447318.2012.711704
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   HOLM S, 1979, SCAND J STAT, V6, P65
   Ishihara S, 1972, ISHIHARAS TESTS COLO
   Jeanne F, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139144
   Jing ALS, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.697367
   Klinker G, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P124, DOI 10.1109/ISAR.2001.970522
   Kosmalla F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P270, DOI 10.1145/3132272.3134119
   Lashley KS, 1951, CEREBRAL MECH BEHAV, P112
   Liu JS, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P531, DOI 10.1109/VRW55335.2022.00121
   Liu JS, 2021, IEEE T VIS COMPUT GR, V27, P4311, DOI 10.1109/TVCG.2021.3106476
   Mathworks Inc, MATL STAT MACH LEARN
   Mendes D, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P3, DOI 10.1109/3DUI.2014.6798833
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Narzt W., 2006, Universal Access in the Information Society, V4, P177, DOI 10.1007/s10209-005-0017-5
   NASA, 1986, TASK LOAD IND TLX V
   NOVICK LR, 1987, J EXP PSYCHOL GEN, V116, P50, DOI 10.1037/0096-3445.116.1.50
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Pierno AC, 2006, J COGNITIVE NEUROSCI, V18, P2130, DOI 10.1162/jocn.2006.18.12.2130
   PYLYSHYN Z W, 1988, Spatial Vision, V3, P179, DOI 10.1163/156856888X00122
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Sadasivan S., 2005, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, Portland, Oregon, P141, DOI DOI 10.1145/1054972.1054993
   Stereo Optical Co. Inc, OR STER FLY STER
   Sukan M., 2014, P 27 ANN ACM S USER, P331, DOI DOI 10.1145/2642918.2647417
   Sukan M, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P89, DOI 10.1145/2983310.2985764
   Team17 and Ghost Town Games, OV 2
   Thomas B, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P168, DOI 10.1109/ISWC.1998.729549
   Tukey J.W., 1977, Exploratory Data Analysis, V2
   varjo, Varjo XR-3
   Volmer B, 2018, IEEE T VIS COMPUT GR, V24, P2846, DOI 10.1109/TVCG.2018.2868587
   Vuibert V., 2015, P 3 ACM S SPATIAL US, P44, DOI [10.1145/2788940.2788950, DOI 10.1145/2788940.2788950]
   Wilson Andrew, 2012, P SIGCHI C HUM FACT, P179, DOI [DOI 10.1145/2207676.2207702, 10.1145/2207676.2207702]
   Wolf J, 2021, 2021 IEEE INT S MIXE
   Zhou B, 2020, IEEE T VIS COMPUT GR, V26, P3514, DOI 10.1109/TVCG.2020.3023635
NR 45
TC 8
Z9 8
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3799
EP 3809
DI 10.1109/TVCG.2022.3203111
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5T5BH
UT WOS:000875881300001
PM 36049002
DA 2024-11-06
ER

PT J
AU Mueller, K
   Bowman, D
AF Mueller, Klaus
   Bowman, Doug
TI Message from the Editor-in-Chief and from the Associate Editor-in-Chief
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Mueller, Klaus] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Bowman, Doug] Virginia Tech, Blacksburg, VA USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   Virginia Polytechnic Institute & State University
RP Mueller, K (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
OI Mueller, Klaus/0000-0002-0996-8590
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP IV
EP IV
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200001
DA 2024-11-06
ER

PT J
AU Iwai, D
   Gabbard, JL
   Moreau, G
   Wang, LL
AF Iwai, Daisuke
   Gabbard, Joseph L.
   Moreau, Guillaume
   Wang, Lili
TI Message from the ISMAR 2022 Science and Technology Journal Program
   Chairs and TVCG Guest Editors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Iwai, Daisuke] Osaka Univ, Suita, Osaka, Japan.
   [Gabbard, Joseph L.] Virginia Tech, Blacksburg, VA USA.
   [Moreau, Guillaume] IMT Atlantique, Nantes, France.
   [Wang, Lili] Beihang Univ, Beijing, Peoples R China.
C3 Osaka University; Virginia Polytechnic Institute & State University; IMT
   - Institut Mines-Telecom; IMT Atlantique; Beihang University
RP Iwai, D (corresponding author), Osaka Univ, Suita, Osaka, Japan.
RI Iwai, Daisuke/R-8174-2019; wang, lili/HJP-8047-2023; Moreau,
   Guillaume/I-3153-2013
OI Iwai, Daisuke/0000-0002-3493-5635
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP V
EP V
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200002
DA 2024-11-06
ER

PT J
AU Sidenmark, L
   Parent, M
   Wu, CH
   Chan, J
   Glueck, M
   Wigdor, D
   Grossman, T
   Giordano, M
AF Sidenmark, Ludwig
   Parent, Mark
   Wu, Chi-Hao
   Chan, Joannes
   Glueck, Michael
   Wigdor, Daniel
   Grossman, Tovi
   Giordano, Marcello
TI Weighted Pointer: Error-aware Gaze-based Interaction through Fallback
   Modalities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Eye tracking; Gaze interaction; Virtual Reality; Adaptive interfaces;
   Accessibility
ID EYE-GAZE; SELECTION
AB Gaze-based interaction is a fast and ergonomic type of hands-free interaction that is often used with augmented and virtual reality when pointing at targets. Such interaction, however, can be cumbersome whenever user, tracking, or environmental factors cause eye tracking errors. Recent research has suggested that fallback modalities could be leveraged to ensure stable interaction irrespective of the current level of eye tracking error. This work thus presents Weighted Pointer interaction, a collection of error-aware pointing techniques that determine whether pointing should be performed by gaze, a fallback modality, or a combination of the two, depending on the level of eye tracking error that is present. These techniques enable users to accurately point at targets when eye tracking is accurate and inaccurate. A virtual reality target selection study demonstrated that Weighted Pointer techniques were more performant and preferred over techniques that required the use of manual modality switching.
C1 [Sidenmark, Ludwig] Real Labs, Lancaster, England.
   [Sidenmark, Ludwig] Univ Lancaster, Lancaster, England.
   [Parent, Mark; Wu, Chi-Hao; Chan, Joannes; Glueck, Michael; Wigdor, Daniel; Giordano, Marcello] Real Labs Res, Lancaster, England.
   [Grossman, Tovi] Univ Toronto, Toronto, ON, Canada.
C3 Lancaster University; University of Toronto
RP Sidenmark, L (corresponding author), Real Labs, Lancaster, England.; Sidenmark, L (corresponding author), Univ Lancaster, Lancaster, England.
EM l.sidenmark@lancaster.ac.uk; mrkprnt@fb.com; eddywu@fb.com;
   joanneschan@fb.com; mglueck@fb.com; dwigdor@fb.com;
   tovi@dgp.toronto.edu; giordanoml@fb.com
RI Wu, chihao/G-3512-2011; Glueck, Michael/AAK-3015-2020
CR Adhanom IB, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391374
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Bækgaard P, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319831
   Balogun MB, 2019, AFRICON, DOI [10.1109/africon46755.2019.9133906, 10.1145/3290605.3300331]
   Barz M, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204536
   Barz M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P275, DOI 10.1145/2857491.2857493
   Bates R., 2003, Universal Access in the Information Society, V2, P280, DOI 10.1007/s10209-003-0053-y
   Bernhard M, 2014, ACM T APPL PERCEPT, V11, DOI 10.1145/2644812
   Casiez G., 2012, P SIGCHI C HUM FACT, P2527, DOI DOI 10.1145/2207676.2208639
   Chatterjee I, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P131, DOI 10.1145/2818346.2820752
   Choi Myungguen, 2020, ACM S EYE TRACK RES, DOI [10.1145/3379155.3391322, DOI 10.1145/3379155.3391322]
   David-John Brendan, 2021, EYE TRACKING RES APP, DOI 10.1145/3448018.3458008
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI [10.2312/EGVE/IPT_EGVE2005/201-209, DOI 10.2312/EGVE/IPT_EGVE2005/201-209]
   Deng Shujie, 2017, 2017 3 IEEE INT C CY, P1, DOI 10.1109/CYBConf.2017.7985779
   Drewes H, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P139, DOI 10.1145/3282894.3282913
   Drewes J., 2012, P S EYE TRACK RES AP, P209, DOI [DOI 10.1145/2168556.2168596, 10.1145/2168556.2168596]
   Erickson A, 2020, IEEE T VIS COMPUT GR, V26, P1934, DOI 10.1109/TVCG.2020.2973054
   Fares Ribel., 2013, P SIGCHI C HUMAN FAC, P1387
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Flatla D., 2011, Proc. of ACM UIST 2011, P403, DOI [10.1145/2047196.2047248, DOI 10.1145/2047196.2047248, 10.1145/2047196.20472482, DOI 10.1145/2047196.20472482]
   Gomez AR, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204585
   Grossman Tovi, 2006, P 19 ANN ACM S US IN, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Grossman Tovi., 2005, CHI 05, P281, DOI DOI 10.1145/1054972.1055012
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley K., 1994, UIST '94. Seventh Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P213, DOI 10.1145/192426.192501
   Holmqvist K., 2012, P S EYE TRACK RES AP, P45, DOI [DOI 10.1145/2168556.2168563, 10.1145/2168556.2168563]
   Holmqvist Kenneth, 2011, Eye Tracking: A Comprehensive Guide to Methods and Measures
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   Jacob R. J. K., 1990, SIGCHI Bulletin, P11
   Jalaliniya S, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P155, DOI 10.1145/2802083.2802094
   Kaiser E., 2003, ICMI 03, P12, DOI DOI 10.1145/958432.958438
   Kalaganis FP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31425-2
   Koelle M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376162
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Kurauchi A, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769550
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935
   Lankford Chris., 2000, P 2000 S EYE TRACKIN, P23, DOI DOI 10.1145/355017.355021
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Li Zhi, 2021, Proc (Graph Interface), V2021, P231, DOI 10.20380/GI2021.35
   Lutteroth C, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P385, DOI 10.1145/2807442.2807461
   Mankoff J., 2000, UIST. Proceedings of the 13th Annual ACM Symposium on User Interface Software and Technology, P11, DOI 10.1145/354401.354407
   Mankoff Jennifer., 2000, CHI '00: CHI '00 extended abstracts on Human factors in computing systems, P77, DOI DOI 10.1145/633292.633339
   Mardanbegi D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300842
   Mughrabi MH, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P301, DOI 10.1109/VRW55335.2022.00070
   Niehorster DC, 2020, BEHAV RES METHODS, V52, P1140, DOI 10.3758/s13428-019-01307-0
   Norouzi N, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357587
   Olwal A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P300, DOI 10.1109/ISMAR.2003.1240730
   Orquin JL, 2018, BEHAV RES METHODS, V50, P1645, DOI 10.3758/s13428-017-0998-z
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   pakov O. S., 2011, P 1 C NOVEL GAZE CON, DOI [10.1145/1983302.1983308, DOI 10.1145/1983302.1983308]
   pakov O. S., 2014, P S EYE TRACKING RES, P291, DOI [10.1145/2578153.2578200, DOI 10.1145/2578153.2578200]
   Palmer C, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P65, DOI 10.1145/2857491.2857544
   Pathmanathan N, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391829
   Pfeuffer K., 2013, P 26 ANN ACM S US IN, P261, DOI [DOI 10.1145/2501988.2501998, 10.1145/2501988.2501998]
   Pfeuffer K, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P301, DOI 10.1145/2984511.2984514
   Porta M., 2010, Proceedings of the 2010 Symposium on Eye-Tracking Research #38; Applications, ETRA'10, (New York, NY, USA), P331, DOI DOI 10.1145/1743666.1743741
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Salvucci Dario D, 2000, P 2000 S EYE TRACK R, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Santini T, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319835
   Schmidt G, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P87, DOI 10.1109/TRIDUI.2006.1618277
   Schwarz Julia, 2010, P 23 ANN ACM S US IN, P47, DOI DOI 10.1145/1866029.1866039
   Sidenmark L, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391312
   Sidenmark L, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376438
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319815
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Spakov O., 2012, P S EYE TRACK RES AP, P281, DOI [DOI 10.1145/2168556.2168616, 10.1145/2168556.21686162,5, DOI 10.1145/2168556.21686162,5]
   Spakov O., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, ETRA'14, P35, DOI DOI 10.1145/2578153.2578157
   Spakov O, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P705
   Steinicke F, 2006, COMPUT IMAGING VIS, V32, P320, DOI 10.1007/1-4020-4179-9_46
   Stellmach S., 2012, Proc. CHI, P2981, DOI DOI 10.1145/2207676.2208709
   Sunggeun Ahn, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382908
   Ware C., 1987, SIGCHI Bulletin, P183, DOI 10.1145/1165387.275627
   Williamson JR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300310
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zeleznik RC, 2005, LOOK THAT THERE EXPL
   Zhai S., 1999, P SIGCHI C HUM FACT, P246, DOI [10.1145/302979.303053, DOI 10.1145/302979.303053, DOI 10.1145/302979.3030532]
   Zhang XY, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P525
NR 80
TC 15
Z9 15
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3585
EP 3595
DI 10.1109/TVCG.2022.3203096
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200004
PM 36048981
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Moullec, Y
   Saint-Aubert, J
   Manson, J
   Cogne, M
   Lecuyer, A
AF Moullec, Yann
   Saint-Aubert, Justine
   Manson, Julien
   Cogne, Melanie
   Lecuyer, Anatole
TI Multi-sensory display of self-avatar's physiological state: virtual
   breathing and heart beating can increase sensation of effort in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Avatar; multi-sensory display; haptic; physiological computing; effort
   sensation; embodiment; cardiac; respiration
ID BODY; INDEX; SENSE; MEN
AB In this paper we explore the multi-sensory display of self-avatars' physiological state in Virtual Reality (VR), as a means to enhance the connection between the users and their avatar. Our approach consists in designing and combining a coherent set of visual, auditory and haptic cues to represent the avatar's cardiac and respiratory activity. These sensory cues are modulated depending on the avatar's simulated physical exertion. We notably introduce a novel haptic technique to represent respiratory activity using a compression belt simulating abdominal movements that occur during a breathing cycle. A series of experiments was conducted to evaluate the influence of our multi-sensory rendering techniques on various aspects of the VR user experience, including the sense of virtual embodiment and the sensation of effort during a walking simulation. A first study (N=30) that focused on displaying cardiac activity showed that combining sensory modalities significantly enhances the sensation of effort. A second study (N=20) that focused on respiratory activity showed that combining sensory modalities significantly enhances the sensation of effort as well as two sub-components of the sense of embodiment. Interestingly, the user's actual breathing tended to synchronize with the simulated breathing, especially with the multi-sensory and haptic displays. A third study (N=18) that focused on the combination of cardiac and respiratory activity showed that combining both rendering techniques significantly enhances the sensation of effort. Taken together, our results promote the use of our novel breathing display technique and multi-sensory rendering of physiological parameters in VR applications where effort sensations are prominent, such as for rehabilitation, sport training, or exergames.
C1 [Moullec, Yann; Saint-Aubert, Justine; Manson, Julien; Lecuyer, Anatole] Univ Rennes, INRIA, CNRS, IRISA, Rennes, France.
   [Cogne, Melanie] Univ Rennes, INRIA, CNRS, IRISA,CHU Rennes, Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Inria; Universite de Rennes; CHU Rennes; Inria; Centre National
   de la Recherche Scientifique (CNRS)
RP Moullec, Y (corresponding author), Univ Rennes, INRIA, CNRS, IRISA, Rennes, France.
EM yann.moullec@inria.fr
RI Cogne, Melanie/JVN-4300-2024
OI Moullec, Yann/0000-0002-1604-8864; Saint-Aubert,
   Justine/0000-0001-8412-653X
FU European Union [101017884]; Research and Innovation Department of the
   University Hospital of Rennes
FX The research leading to these results has been partially funded from the
   European Union Horizon 2020 research and innovation program under grant
   agreement No. 101017884 -GuestXR project.. The authors also wish to
   thank the Research and Innovation Department of the University Hospital
   of Rennes for promoting and supporting our study.
CR Adler D, 2014, RESP PHYSIOL NEUROBI, V203, P68, DOI 10.1016/j.resp.2014.08.003
   Allard E, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11045-y
   Amemiya T, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P605
   Aspell JE, 2013, PSYCHOL SCI, V24, P2445, DOI 10.1177/0956797613498395
   Ban Y, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275492
   Blum J, 2020, APPL PSYCHOPHYS BIOF, V45, P153, DOI 10.1007/s10484-020-09468-x
   BRANSFORD DR, 1977, MED SCI SPORT EXER, V9, P41
   Byrne NM, 2005, J APPL PHYSIOL, V99, P1112, DOI 10.1152/japplphysiol.00023.2004
   Campbell J, 2019, PROCEEDINGS OF THE 31ST EUROPEAN CONFERENCE ON COGNITIVE ERGONOMICS: DESIGN FOR COGNITION (ECCE 2019), P177, DOI 10.1145/3335082.3335087
   Chen H., 2017, Proceedings of the 29th Australian conference on computer-human interaction, P108, DOI DOI 10.1145/3152771.3152783
   Chittaro L, 2014, INTERACT COMPUT, V26, P528, DOI 10.1093/iwc/iwt049
   Choi KY, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P17, DOI 10.1145/3374920.3374938
   Costa J, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P758, DOI 10.1145/2971648.2971752
   Czub M, 2019, CYBERPSYCH BEH SOC N, V22, P494, DOI 10.1089/cyber.2018.0700
   Derrickson B., 2014, Principles of anatomy and physiology
   Dey A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P101, DOI 10.1145/3242671.3242676
   Dey A, 2019, INT SYM MIX AUGMENT, P248, DOI 10.1109/ISMAR.2019.00022
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Ghandeharioun A., 2017, BrightBeat: Effortlessly Influencing Breathing for Cultivating Calmness and Focus. pages, P1624, DOI DOI 10.1145/3027063.3053164
   Gradl S, 2018, INT CONF WEARAB IMPL, P152, DOI 10.1109/BSN.2018.8329681
   Hirao Y, 2018, J IMAGING SCI TECHN, V62, DOI 10.2352/J.ImagingSci.Technol.2018.62.6.060402
   Hood VL, 2002, ARCH PHYS MED REHAB, V83, P1266, DOI 10.1053/apmr.2002.34598
   Houzangbe Samory, 2018, P 13 INT C FDN DIG G, P1
   Iodice P, 2019, P NATL ACAD SCI USA, V116, P13897, DOI 10.1073/pnas.1821032116
   Jackson AS, 2002, INT J OBESITY, V26, P789, DOI 10.1038/sj.ijo.0802006
   Jain Dhruv., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P1563
   Jarvela Simo, 2021, ACM Transactions on Social Computing, V4, DOI 10.1145/3449358
   Jones LA, 2008, HUM FACTORS, V50, P90, DOI 10.1518/001872008X250638
   Katch V.L., 2011, Essentials of Exercise Physiology
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kraemer W., 2011, EXERCISE PHYSL INTEG
   Leslie AM., 2001, International Encyclopedia of the Social Behavioral Sciences, P15652, DOI DOI 10.1016/B0-08-043076-7/01640-5
   Marsh Suzanne, 2006, N Z Med J, V119, pU2281
   Matsuda Y., 2021, FRONTIERS VIRTUAL RE, V2
   MENYHART JA, 1986, AUST J PSYCHOL, V38, P133, DOI 10.1080/00049538608256424
   Monti A, 2020, J NEUROPHYSIOL, V123, P420, DOI 10.1152/jn.00617.2019
   Neder JA, 2003, EUR RESPIR J, V21, P530, DOI 10.1183/09031936.03.00045402
   Ondobaka S, 2017, BRAIN COGNITION, V112, P64, DOI 10.1016/j.bandc.2015.08.002
   Peck T. C., 2021, FRONTIERS VIRTUAL RE, V1
   Pescara E, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P97, DOI 10.1145/3152832.3152863
   PIVARNIK JM, 1990, MED SCI SPORT EXER, V22, P127
   Rockstroh C, 2021, VIRTUAL REAL-LONDON, V25, P539, DOI 10.1007/s10055-020-00471-5
   Roo JS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1459, DOI 10.1145/3025453.3025743
   Saint-Aubert J, 2023, IEEE T VIS COMPUT GR, V29, P3507, DOI 10.1109/TVCG.2022.3161130
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Strath SJ, 2000, MED SCI SPORT EXER, V32, pS465, DOI 10.1097/00005768-200009001-00005
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Tinga AM, 2019, APPL PSYCHOPHYS BIOF, V44, P51, DOI 10.1007/s10484-018-9421-5
   Ueoka R, 2018, LECT NOTES COMPUT SC, V10904, P436, DOI 10.1007/978-3-319-92043-6_37
   VALINS S, 1966, J PERS SOC PSYCHOL, V4, P400, DOI 10.1037/h0023791
   Watanabe T, 2004, INT J HUM-COMPUT INT, V17, P89, DOI 10.1207/s15327590ijhc1701_7
NR 54
TC 5
Z9 5
U1 1
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3596
EP 3606
DI 10.1109/TVCG.2022.3203120
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200005
PM 36048993
OA Green Published
DA 2024-11-06
ER

PT J
AU Kurth, P
   Leuschner, M
   Stamminger, M
   Bauer, F
AF Kurth, Philipp
   Leuschner, Markus
   Stamminger, Marc
   Bauer, Frank
TI Content-Aware Brightness Solving and Error Mitigation in Large-Scale
   Multi-Projection Mapping
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Projection mapping; content-aware; robust; distributed; scalable
AB Projection mapping with inexpensive hardware often suffers from calibration errors that lead to visually compromised results. In this paper, we classify common errors that lead to typical visual artifacts. Based on this classification, we present the first content-aware brightness solver. It is tailored for high GPU performance, yet efficiently hides the most common calibration artifacts. Moreover, it is specifically designed to handle both single and larger networked projection mapping setups with minimal latency.
C1 [Kurth, Philipp; Leuschner, Markus; Stamminger, Marc; Bauer, Frank] Friedrich Alexander Univ Erlangen Nurnberg, Visual Comp Grp, Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Kurth, P (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Visual Comp Grp, Erlangen, Germany.
EM philipp.kurth@fau.de; markus.leuschner@fau.de; marc.stamminger@fau.de;
   frank.bauer@fau.de
OI Stamminger, Marc/0000-0001-8699-3442
CR Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bimber O., 2005, SPATIAL AUGMENTED RE, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Brown M, 2005, IEEE T VIS COMPUT GR, V11, P193, DOI 10.1109/TVCG.2005.27
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Jones B., 2013, P SIGCHI C HUM FACT, P869, DOI DOI 10.1145/2470654.2466112
   Jones Brett, 2014, P 27 ANN ACM S US IN, P637, DOI [10.1145/2642918.2647383, DOI 10.1145/2642918.2647383]
   Kurth Philipp, 2020, 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), P174, DOI 10.1109/ISMAR50242.2020.00039
   Kurth P, 2018, IEEE T VIS COMPUT GR, V24, P2886, DOI 10.1109/TVCG.2018.2868530
   Lange V., 2017, Proceedings of the European Association for Computer Graphics: Short Papers, page, P1
   Lincoln P, 2011, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2011.5759447
   Majumder Aditi., 2007, Practical multi-projector display design
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nomoto T., 2020, SIGGRAPH Asia 2020 Emerging Technologies, P1
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Nomoto T, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3407297
   Pjanic P, 2018, IEEE T VIS COMPUT GR, V24, P2963, DOI 10.1109/TVCG.2018.2868597
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Raskar R, 2001, SPRING EUROGRAP, P89
   Rong G., 2006, Jump flooding in GPU with applications to Voronoi diagram and distance transform, P109, DOI DOI 10.1145/1111411.1111431
   Shimazu S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2011.6092393
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl Christian, 2017, [Computational Visual Media, 计算可视媒体], V3, P263
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Simonyan K., 2015, P INT C LEARN REPR I, P1
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   Watanabe Y., 2015, HIGH SPEED 8 BIT IMA
   Watanabe Y., 2019, 26 INT DISPLAY WORKS, P1350
   Watanabe Y, 2016, ADV OPT TECHNOL, V5, P367, DOI 10.1515/aot-2016-0047
NR 30
TC 5
Z9 6
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3607
EP 3617
DI 10.1109/TVCG.2022.3203085
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200006
PM 36048983
DA 2024-11-06
ER

PT J
AU Shen, JX
   Dudley, J
   Mo, G
   Kristensson, PO
AF Shen, Junxiao
   Dudley, John
   Mo, George
   Kristensson, Per Ola
TI Gesture Spotter: A Rapid Prototyping Tool for Key Gesture Spotting in
   Virtual and Augmented Reality Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Gesture interaction; prototyping tools; machine learning; augmented
   reality; virtual reality
AB In this paper we examine the task of key gesture spotting: accurate and timely online recognition of hand gestures. We specifically seek to address two key challenges faced by developers when integrating key gesture spotting functionality into their applications. These are: i) achieving high accuracy and zero or negative activation lag with single-time activation; and ii) avoiding the requirement for deep domain expertise in machine learning. We address the first challenge by proposing a key gesture spotting architecture consisting of a novel gesture classifier model and a novel single-time activation algorithm. This key gesture spotting architecture was evaluated on four separate hand skeleton gesture datasets, and achieved high recognition accuracy with early detection. We address the second challenge by encapsulating different data processing and augmentation strategies, as well as the proposed key gesture spotting architecture, into a graphical user interface and an application programming interface. Two user studies demonstrate that developers are able to efficiently construct custom recognizers using both the graphical user interface and the application programming interface.
C1 [Shen, Junxiao; Dudley, John; Mo, George; Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Shen, JX (corresponding author), Univ Cambridge, Cambridge, England.
EM js2283@cam.ac.uk; jjd50@cam.ac.uk; gm621@cam.ac.uk; pok21@cam.ac.uk
OI Shen, Junxiao/0000-0002-1552-4689; Kristensson, Per
   Ola/0000-0002-7139-871X
FU EPSRC [EP/S027432/1]; EPSRC [EP/S027432/1] Funding Source: UKRI
FX John Dudley and Per Ola Kristensson were supported by EPSRC (grant
   EP/S027432/1).
CR Anthony Lisa, 2010, Proceedings_of_Graphics_Interface_2010, P245
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Boulahia SY, 2017, INT CONF IMAG PROC
   Caputo A., 2021, ARXIV, DOI [10.48550/ARXIV.2106.10980, DOI 10.48550/ARXIV.2106.10980]
   Chalasani T, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P109, DOI 10.1109/ISMAR-Adjunct.2018.00045
   Chen YX, 2019, Arxiv, DOI [arXiv:1907.08871, 10.48550/arXiv.1907.08871, DOI 10.48550/ARXIV.1907.08871]
   Cirean D.C., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence - Volume Volume Two, P1237, DOI [10.5555/ 2283516.2283603, DOI 10.5555/2283516.2283603]
   De Smedt Q., 2017, P 3DOR 10 EUR WORKSH, P1, DOI DOI 10.2312/3DOR.20171049
   developer, OCULUS SET HAND TRAC
   edu, IMPACT S FAMILY
   Finn C, 2017, PR MACH LEARN RES, V70
   Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde S, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P262, DOI [10.1109/ISMAR-Adjunct.2016.0090, 10.1109/ISMAR-Adjunct.2016.81]
   Hochreiter S, 1997, ADV NEUR IN, V9, P473
   Kaneko T, 2017, INTERSPEECH, P3389, DOI 10.21437/Interspeech.2017-962
   Kawakami K., 2008, THESIS
   Köpüklü O, 2019, IEEE INT CONF AUTOMA, P407, DOI 10.1109/fg.2019.8756576
   Lai K, 2018, INT C PATT RECOG, P3451, DOI 10.1109/ICPR.2018.8545718
   Leiva LA, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2799648
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Liu JB, 2020, PROC CVPR IEEE, P5750, DOI 10.1109/CVPR42600.2020.00579
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lu H., 2012, CHI, P2875
   Lü H, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1685, DOI 10.1145/2556288.2557263
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Mikolov T, 2011, INT CONF ACOUST SPEE, P5528
   Min YC, 2020, PROC CVPR IEEE, P5760, DOI 10.1109/CVPR42600.2020.00580
   Hoai M, 2012, PROC CVPR IEEE, P2863, DOI 10.1109/CVPR.2012.6248012
   Mo G. B, 2021, CHI 21
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Nguyen XS, 2019, PROC CVPR IEEE, P12028, DOI 10.1109/CVPR.2019.01231
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Park G, 2020, INT SYM MIX AUGMENT, P588, DOI 10.1109/ISMAR50242.2020.00086
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shen J., 2021, P 2021 16 IEEE INT C, P1, DOI [10.1109/FG52635.2021.9666999, DOI 10.1109/FG52635.2021.9666999]
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Shi XY, 2019, INT SYM MIX AUGMENT, P178, DOI [10.1109/ISMAR.2019.000-6, 10.1109/ISMAR.2019.00-6]
   Taigman Y., 2016, arXiv
   Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27
   Taranta EM, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P873, DOI 10.1145/2984511.2984525
   Vatavu RD, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P273
   Wang JY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P289, DOI 10.1109/ISMAR-Adjunct.2019.00-26
   Wobbrock JO, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P159
   Xie HW, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P274, DOI 10.1109/ISMAR-Adjunct.2019.00-30
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
NR 51
TC 5
Z9 5
U1 2
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3618
EP 3628
DI 10.1109/TVCG.2022.3203004
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200007
PM 36048982
OA Green Published
DA 2024-11-06
ER

PT J
AU Pintore, G
   Agus, M
   Almansa, E
   Gobbetti, E
AF Pintore, Giovanni
   Agus, Marco
   Almansa, Eva
   Gobbetti, Enrico
TI Instant Automatic Emptying of Panoramic Indoor Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Mediated and diminished reality; Omnidirectional; 360; Real-time
   performance issues; AR/MR/VR for architecture; Computer vision; Machine
   learning
ID OF-THE-ART; DIMINISHED REALITY
AB Nowadays 360 degrees cameras, capable to capture full environments in a single shot, are increasingly being used in a variety of Extended Reality (XR) applications that require specific Diminished Reality (DR) techniques to conceal selected classes of objects. In this work, we present a new data-driven approach that, from an input 360 degrees image of a furnished indoor space automatically returns, with very low latency, an omnidirectional photorealistic view and architecturally plausible depth of the same scene emptied of all clutter. Contrary to recent data-driven inpainting methods that remove single user-defined objects based on their semantics, our approach is holistically applied to the entire scene, and is capable to separate the clutter from the architectural structure in a single step. By exploiting peculiar geometric features of the indoor environment, we shift the major computational load on the training phase and having an extremely lightweight network at prediction time. Our end-to-end approach starts by calculating an attention mask of the clutter in the image based on the geometric difference between full and empty scene. This mask is then propagated through gated convolutions that drive the generation of the output image and its depth. Returning the depth of the resulting structure allows us to exploit, during supervised training, geometric losses of different orders, including robust pixel-wise geometric losses and high-order 3D constraints typical of indoor structures. The experimental results demonstrate that our method provides interactive performance and outperforms current state-of-the-art solutions in prediction accuracy on available commonly used indoor panoramic benchmarks. In addition, our method presents consistent quality results even for scenes captured in the wild and for data for which there is no ground truth to support supervised training.
C1 [Pintore, Giovanni; Almansa, Eva; Gobbetti, Enrico] CRS4, Milan, Italy.
   [Agus, Marco] HBKU, Doha, Qatar.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar
RP Pintore, G (corresponding author), CRS4, Milan, Italy.
EM giovanni.pintore@crs4.it; MAgus@hbku.edu.qa; eva.almansa@crs4.it;
   enrico.gobbetti@crs4.it
RI Agus, Marco/AAM-5898-2020; Gobbetti, Enrico/O-2188-2015; Pintore,
   Giovanni/AFV-0023-2022; Almansa, Eva/M-9086-2015
OI Agus, Marco/0000-0003-2752-3525; Almansa, Eva/0000-0002-7288-0989
FU European Union [813170]; Sardinian Regional Authorities under project
   VDIC; Marie Curie Actions (MSCA) [813170] Funding Source: Marie Curie
   Actions (MSCA)
FX The project received funding from the European Union's H2020 research
   and innovation programme under grant 813170 (EVOCATION), and from
   Sardinian Regional Authorities under project VDIC.
CR Bertel T, 2019, IEEE T VIS COMPUT GR, V25, P1828, DOI 10.1109/TVCG.2019.2898799
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gkitsas V, 2021, IEEE COMPUT SOC CONF, P3711, DOI 10.1109/CVPRW53098.2021.00412
   Gupta V., 2019, International journal of computational systems engineering, V5, P53, DOI 10.1504/IJCSYSE.2019.098418
   Hongyu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P725, DOI 10.1007/978-3-030-58536-5_43
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Jin L, 2020, PROC CVPR IEEE, P886, DOI 10.1109/CVPR42600.2020.00097
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jokela T, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365645
   Kawai N, 2016, IEEE T VIS COMPUT GR, V22, P1236, DOI 10.1109/TVCG.2015.2462368
   Kim Hanseob, 2020, 26 ACM S VIRTUAL REA, DOI [10.1145/3385956.3418948, DOI 10.1145/3385956.3418948, 10.1145/3385956]
   Kingma DP, 2014, ADV NEUR IN, V27
   Lambert-Lacroix S, 2016, J NONPARAMETR STAT, V28, P487, DOI 10.1080/10485252.2016.1190359
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li JY, 2020, PROC CVPR IEEE, P7757, DOI 10.1109/CVPR42600.2020.00778
   Li JY, 2019, IEEE I CONF COMP VIS, P5961, DOI 10.1109/ICCV.2019.00606
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Matterport, 2017, MATTERPORT3D
   Matzen K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073645
   Meerits S, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY WORKSHOPS, P53, DOI 10.1109/ISMARW.2015.19
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Mori S, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY WORKSHOPS, P32, DOI 10.1109/ISMARW.2015.16
   Namboku Y, 2020, PROC SPIE, V11515, DOI 10.1117/12.2566248
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Paszke A., 2017, P 31 C NEUR INF PROC, P4
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pintore G, 2021, PROC CVPR IEEE, P11531, DOI 10.1109/CVPR46437.2021.01137
   Pintore G, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480480
   Pintore G, 2020, COMPUT GRAPH FORUM, V39, P667, DOI 10.1111/cgf.14021
   Pintore G, 2019, COMPUT GRAPH FORUM, V38, P347, DOI 10.1111/cgf.13842
   Pintore G, 2018, COMPUT GRAPH-UK, V77, P16, DOI 10.1016/j.cag.2018.09.013
   Queguiner G, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P226, DOI 10.1109/ISMAR-Adjunct.2018.00073
   Roberto G. d. A., 2019, PROC IEEE MMSP, P1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sasanuma H, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P117, DOI [10.1109/ISMAR-Adjunct.2016.48, 10.1109/ISMAR-Adjunct.2016.0055]
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Siltanen S., 2014, PROC ISMAR, P371, DOI [10.1109/ISMAR.2014.6948494, DOI 10.1109/ISMAR.2014.6948494]
   Siltanen S, 2017, VISUAL COMPUT, V33, P193, DOI 10.1007/s00371-015-1174-z
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sulaiman M.Z., 2020, IMDES, P221, DOI [DOI 10.2991/ASSEHR.K.201202.079, 10.2991/assehr.k.201202.079]
   Sun C, 2021, PROC CVPR IEEE, P2573, DOI 10.1109/CVPR46437.2021.00260
   Takeuchi Y., 2012, Proceedings of the 2012ACM annual conference on Human Factors in Computing Systems (CHI '12), P2411, DOI [DOI 10.1145/2207676.2208404, 10.1145/2207676.2208404]
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Yi ZL, 2020, PROC CVPR IEEE, P7505, DOI 10.1109/CVPR42600.2020.00753
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Yu F., 2015, ARXIV
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982432
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
   Zou CH, 2021, INT J COMPUT VISION, V129, P1410, DOI 10.1007/s11263-020-01426-8
NR 65
TC 6
Z9 7
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3629
EP 3639
DI 10.1109/TVCG.2022.3202999
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200008
PM 36067097
DA 2024-11-06
ER

PT J
AU Medeiros, D
   McGill, M
   Ng, A
   McDermid, R
   Pantidi, N
   Williamson, J
   Brewster, S
AF Medeiros, Daniel
   McGill, Mark
   Ng, Alexander
   McDermid, Robert
   Pantidi, Nadia
   Williamson, Julie
   Brewster, Stephen
TI From Shielding to Avoidance: Passenger Augmented Reality and the Layout
   of Virtual Displays for Productivity in Shared Transit
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Augmented Reality; Productivity; Virtual Workspaces; Mixed Reality;
   Extended Reality; Passengers; Transport; Transit; Airplanes; Cars;
   Trains; Subway; Mobility
ID PERSONAL-SPACE INVASION
AB Passengers spend considerable periods of time in shared transit spaces, relying on smartphones and laptops for work. However, these displays are limited in size and ergonomics compared to typical multi-monitor setups used in the office, impairing productivity. Augmented Reality (AR) headsets could provide large, flexible virtual workspaces during travel, enabling passengers to work more efficiently. This paper investigates the factors affecting how passengers choose to layout virtual displays in car, train, subway and plane environments, studying the affordances of each mode of transport and the presence of others. Results from our experiment showed: significant usage of the physical environment to align displays; strong social effects meant avoiding placing displays over other passengers or their belongings; and use of displays for shielding oneself from others. Our findings show the unique challenges posed by the mode of transport and presence of others on the use of AR for mobile productivity in the future.
C1 [Medeiros, Daniel; McGill, Mark; Ng, Alexander; McDermid, Robert; Williamson, Julie; Brewster, Stephen] Univ Glasgow, Glasgow, Lanark, Scotland.
   [Pantidi, Nadia] Victoria Univ Wellington, Wellington, New Zealand.
C3 University of Glasgow; Victoria University Wellington
RP Medeiros, D (corresponding author), Univ Glasgow, Glasgow, Lanark, Scotland.
EM daniel.piresdesamedeiros@glasgow.ac.uk; mark.mcgill@glasgow.ac.uk;
   alexander.ng@glasgow.ac.uk; nadia.pantidi@vuw.ac.nz;
   julie.williamson@glasgow.ac.uk; stephen.brewster@glasgow.ac.uk
RI Brewster, Stephen/J-9003-2017
FU European Research Council (ERC) under the European Union [835197];
   European Research Council (ERC) [835197] Funding Source: European
   Research Council (ERC)
FX This research received funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme (#835197, ViAjeRo).
CR Ahmadpour N, 2016, WORK, V54, P981, DOI 10.3233/WOR-162346
   Ahmadpour N, 2014, ERGONOMICS, V57, P801, DOI 10.1080/00140139.2014.899632
   Alallah F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281541
   Anderson J.A.:., 2007, Productivity, screens, and aspect ratios
   [Anonymous], 2014, P 2 ACM S SPAT US IN, DOI DOI 10.1145/2659766.2659769
   Bajorunaite L, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P432, DOI 10.1109/VRW52623.2021.00098
   Barrett Ens, 2016, COLLABORATION MEETS, P153, DOI [10.1007/978-3-319-45853- 3_8, DOI 10.1007/978-3-319-45853-3_8]
   Bi XJ, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1005
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Czerwinski Mary, 2003, Interact, V3, P9
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Dumur E., 2004, Designing for comfort
   Endert A, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P58, DOI 10.1145/2254556.2254570
   Ens B, 2017, IEEE COMPUT GRAPH, V37, P66, DOI 10.1109/MCG.2016.38
   Ens B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3171
   eurostat, 2019, AIR TRANSP STAT
   eurostat, 2021, RAILW PASS TRANSP ST
   Evans GW, 2007, J ENVIRON PSYCHOL, V27, P90, DOI 10.1016/j.jenvp.2006.10.002
   Fiorillo I, 2021, INT J IND ERGONOM, V83, DOI 10.1016/j.ergon.2021.103131
   Garcia-Sanjuan F., 2016, FRONTIERS ICT, V20
   Garland-Thomson R, 2006, J VIS CULT, V5, P173, DOI 10.1177/1470412906066907
   Gerber M. A., 2022, User Experience Design in the Era of Automated Driving, P477
   Goffman E., 1963, STIGMA NOTES MANAGEM
   Groening Stephen, 2016, Film History: An International Journal
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Grudin J., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P458, DOI 10.1145/365024.365312
   Gugenheimer J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299028
   Haeuslschmid R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5076, DOI 10.1145/2858036.2858336
   Hall ET, 1966, The hidden dimension, V609
   House C, 2017, PUBLICATION TITLE HA
   Jacobsen M.H., 2015, The social thought of Erving Goffman
   Krings Sarah, 2020, EICS 20, V9, P1
   Lewis L, 2017, ERGONOMICS, V60, P1461, DOI 10.1080/00140139.2017.1313456
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Lischke L., 2016, P 5 ACM INT S PERV D, P228
   Liu J., 2021, 2021 17 INT C INTELL, P1
   Lokhandwala M, 2018, TRANSPORT RES C-EMER, V97, P45, DOI 10.1016/j.trc.2018.10.007
   Mai C, 2018, PROCEEDINGS PERVASIVE DISPLAYS 2018: THE 7TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, DOI 10.1145/3205873.3205879
   Mäkelä V, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376796
   Mathis F., 2021, IEEE C VIRTUAL REALI
   Mathis F., 2021, P CHI 2021 WORKSHOP
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2020, VIRTUAL REAL-LONDON, V24, P583, DOI 10.1007/s10055-019-00420-x
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Ng A., 2021, P 2021 IEEE INT S MI
   Ofek E., 2020, arXiv
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Osmers N., 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445633, DOI 10.1145/3411764.3445633]
   Oulasvirta A, 2020, P IEEE, V108, P434, DOI 10.1109/JPROC.2020.2969687
   Patel H, 2018, TRANSPORT REV, V38, P252, DOI 10.1080/01441647.2017.1307877
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Riegler Andreas, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P119, DOI 10.1145/3428361.3428390
   Schmelter T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P279, DOI [10.1109/VRW50115.2020.0-218, 10.1109/VRW50115.2020.00058]
   Smith M, 2015, P IEEE VIRT REAL ANN, P401, DOI 10.1109/VR.2015.7223465
   Statistics N, 2020, TRANSP STAT GREAT BR, P6
   Steed A., 2020, Interaction, V27, P62, DOI [DOI 10.1145/3406098, 10.1145/3406098]
   Thomas J. A. P. K., 2009, SOCIAL ENV PUBLIC TR
   Vergari M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P695, DOI 10.1109/VR50410.2021.00096
   Williamson JR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300310
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yang KT, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P499, DOI 10.1145/3242587.3242630
NR 63
TC 19
Z9 20
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3640
EP 3650
DI 10.1109/TVCG.2022.3203002
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200009
PM 36048986
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Joos, L
   Jaeger-Honz, S
   Schreiber, F
   Keim, DA
   Klein, K
AF Joos, Lucas
   Jaeger-Honz, Sabrina
   Schreiber, Falk
   Keim, Daniel A.
   Klein, Karsten
TI Visual Comparison of Networks in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Network comparison; virtual reality; weighted graphs; immersive
   analytics
ID PERCEPTION
AB Networks are an important means for the representation and analysis of data in a variety of research and application areas. While there are many efficient methods to create layouts for networks to support their visual analysis, approaches for the comparison of networks are still underexplored. Especially when it comes to the comparison of weighted networks, which is an important task in several areas, such as biology and biomedicine, there is a lack of efficient visualization approaches. With the availability of affordable high-quality virtual reality (VR) devices, such as head-mounted displays (HMDs), the research field of immersive analytics emerged and showed great potential for using the new technology for visual data exploration. However, the use of immersive technology for the comparison of networks is still underexplored. With this work, we explore how weighted networks can be visually compared in an immersive VR environment and investigate how visual representations can benefit from the extended 3D design space. For this purpose, we develop different encodings for 3D node-link diagrams supporting the visualization of two networks within a single representation and evaluate them in a pilot user study. We incorporate the results into a more extensive user study comparing node-link representations with matrix representations encoding two networks simultaneously. The data and tasks designed for our experiments are similar to those occurring in real-world scenarios. Our evaluation shows significantly better results for the node-link representations, which is contrary to comparable 2D experiments and indicates a high potential for using VR for the visual comparison of networks.
C1 [Joos, Lucas; Jaeger-Honz, Sabrina; Schreiber, Falk; Keim, Daniel A.; Klein, Karsten] Univ Konstanz, Constance, Germany.
   [Schreiber, Falk] Monash Univ, Clayton, Vic, Australia.
C3 University of Konstanz; Monash University
RP Joos, L (corresponding author), Univ Konstanz, Constance, Germany.
EM lucas.joos@uni-konstanz.de; sabring.jaeger@uni-konstanz.de;
   falk.schreiber@uni-konstanz.de; keim@uni-konstanz.de;
   karsten.klein@uni-konstanz.de
RI Keim, Daniel/X-7749-2019
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [251654672 -TRR 161]
FX Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) -Project-ID 251654672 -TRR 161.
CR Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   [Anonymous], 2004, J INTEGR BIOINFORMAT, DOI DOI 10.1515/JIB-2004-2
   Archambault Daniel, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P475, DOI 10.1007/978-3-642-36763-2_42
   Archambault D, 2011, LECT NOTES COMPUT SC, V6502, P50, DOI 10.1007/978-3-642-18469-7_5
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bach B., 2014, EuroVis-STARs, DOI [10.2312/eurovisstar.20141171, DOI 10.2312/EUROVISSTAR.20141171, 10.2312/EUROVISSTAR.20141171]
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Bach B, 2014, IEEE T VIS COMPUT GR, V20, P740, DOI 10.1109/TVCG.2013.254
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Büschel W, 2019, IEEE COMPUT GRAPH, V39, P29, DOI 10.1109/MCG.2019.2897927
   Chen H, 2021, IEEE T VIS COMPUT GR, V27, P2056, DOI 10.1109/TVCG.2019.2946558
   Chimani Markus., 2011, Handbook of graph drawing and visualization, P543
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cui WW, 2014, IEEE PAC VIS SYMP, P121, DOI 10.1109/PacificVis.2014.48
   De Vico Fallani Fabrizio, 2017, PLoS Comput Biol, V13, pe1005305, DOI 10.1371/journal.pcbi.1005305
   Di Battista G., 2021, Journal of Graph Algorithms and Applications, V25, P311, DOI [DOI 10.7155/JGAA.00560, 10.7155/jgaa.00560]
   Diersch N, 2019, J EXP BIOL, V222, DOI 10.1242/jeb.187252
   Dinkla K, 2012, IEEE T VIS COMPUT GR, V18, P2457, DOI 10.1109/TVCG.2012.208
   Drogemuller A, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100937
   Fallani FD, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0521
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Greffard N, 2012, LECT NOTES COMPUT SC, V7034, P215
   HAGERSTRAND T, 1982, TIJDSCHR ECON SOC GE, V73, P323, DOI 10.1111/j.1467-9663.1982.tb01647.x
   HART S G, 1988, P139
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hess RF, 2015, I-PERCEPTION, V6, DOI 10.1177/2041669515593028
   Jaeger S, 2019, IEEE PAC VIS SYMP, P42, DOI 10.1109/PacificVis.2019.00013
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jin ZC, 2021, J VISUAL-JAPAN, V24, P365, DOI 10.1007/s12650-020-00706-2
   John M, 2019, IEEE PAC VIS SYMP, P247, DOI 10.1109/PacificVis.2019.00037
   Kairam S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P498, DOI 10.1145/2254556.2254651
   Kotlarek J, 2020, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis48177.2020.4722
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Kypridemou E., 2020, EuroVis 2020 - Short Papers, DOI DOI 10.2312/EVS.20201039
   Macindoe Owen, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P193, DOI 10.1109/SocialCom.2010.35
   Marriott Kim, 2018, Immersive Analytics, V11190, DOI DOI 10.1007/978-3-030-01388-2
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   Murugesan S, 2020, INFORM VISUAL, V19, P96, DOI 10.1177/1473871619882019
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Pester B., 2021, EUROVIS WORKSHOP VIS, DOI [10.2312/eurova.20211091, DOI 10.2312/EUROVA.20211091]
   Ren D, 2019, NETW SCI, V7, P242, DOI 10.1017/nws.2019.6
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Sancho-Chavarría L, 2020, COMM COM INF SC, V1087, P423, DOI 10.1007/978-3-030-41005-6_29
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Schreiber F., 2003, Proc. APBC, Australian Computer Society, P105
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sharan R, 2005, P NATL ACAD SCI USA, V102, P1974, DOI 10.1073/pnas.0409522102
   Skarbez R, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00082
   Soni U, 2018, COMPUT GRAPH FORUM, V37, P169, DOI 10.1111/cgf.13410
   Sorger J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P144, DOI 10.1109/AIVR46125.2019.00030
   Tamassia R., 2013, Handbook of graph drawing and visualization
   Ware C, 1996, ACM T GRAPHIC, V15, P121, DOI 10.1145/234972.234975
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Xu R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P186, DOI [10.1109/visual.2019.8933544, 10.1109/VISUAL.2019.8933544]
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
NR 67
TC 12
Z9 14
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3651
EP 3661
DI 10.1109/TVCG.2022.3203001
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200010
PM 36048995
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Leng, JY
   Wang, LL
   Liu, XL
   Shi, XH
   Wang, M
AF Leng, Jiaye
   Wang, Lili
   Liu, Xiaolong
   Shi, Xuehuai
   Wang, Miao
TI Efficient Flower Text Entry in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Virtual reality; text entry; keyboard layout; hand interaction;
   controller
AB Text entry is a frequently used task in virtual reality (VA) applications, and controller is the most common interactive device in current VR systems. However, in terms of typing speed, there is still a gap between the existing controller-based text entry techniques and using a physical keyboard in reality, so it is important to improve the efficiency of the controller-based text entry. In this paper, we introduce Flower Text Entry, a single-controller text entry method based on a newly designed flower-shaped keyboard using hand 3D translation interaction for letters selection. We conduct user studies to optimize the keyboard design and the mapping between the interaction and selection, so as to evaluate our method. The results show that our method has high typing speed, lower error rate, and is very friendly to novices compared with the state-of-the-art controller-based text entry methods. After a short training, the novice group can type at 17.65 words per minute (WPM), and the potential expert group can type at 22.97 WPM. The highest typing speed is up to 30.80 WPM achieved by a potential expert participant.
C1 [Leng, Jiaye; Wang, Lili; Liu, Xiaolong; Shi, Xuehuai; Wang, Miao] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Wang, Lili] Peng Cheng Lab, Shengzhen, Peoples R China.
   [Wang, Lili] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Wang, LL (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Wang, LL (corresponding author), Peng Cheng Lab, Shengzhen, Peoples R China.; Wang, LL (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing, Peoples R China.
EM lengjiaye@buaa.edu.cn; wanglily@buaa.edu.cn; liuxiaolong186@buaa.edu.cn;
   shixuehuaireal@buaa.edu.cn; miaow@buaa.edu.cn
RI li, bai/JNE-1502-2023; Shi, Xuehuai/ISB-5757-2023; Wang,
   Lily/HJY-9269-2023; Leng, Jiaye/GSE-0384-2022
OI Leng, Jiaye/0000-0001-6772-4124
FU National Key RD plan [2019YFC1521102]; National Natural Science
   Foundation of China [61932003, 61772051]
FX This work was supported by National Key R&D plan 2019YFC1521102, by the
   National Natural Science Foundation of China through Projects 61932003
   and 61772051.
CR Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   Benligiray B, 2019, J MULTIMODAL USER IN, V13, P321, DOI 10.1007/s12193-018-0285-z
   Boletsis C, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020031
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Cechanowicz J., 2006, P WORKING C ADV VISU, P163
   Evans F., 1999, International Journal of Human-Computer Studies
   Foy Conor R, 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1
   Garbe W., 2012, SYMSPELL, V6
   Gong J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173755
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P49, DOI 10.1145/2984511.2984576
   Gupta A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300244
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Huckauf A, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P51, DOI 10.1145/1344471.1344483
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Jiang HY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143063
   Jiang HY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P132, DOI 10.1109/ISMAR-Adjunct.2018.00051
   Kim Junhyeok, 2018, GRAPHICS INTERFACE
   Kim YR, 2017, IEEE ICCE, DOI 10.1109/ICCE.2017.7889285
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   LEE L, IEEE PERCOM 20, DOI [DOI 10.1109/PERCOM45495.2020.9127378, 10.1109/PerCom45495.2020.9127378]
   Lin Jia-Wei., 2017, ACM SIGGRAPH 2017 Posters on - SIGGRAPH'17, P1, DOI DOI 10.1145/3102163
   MacKenzie I.S., 2002, A note on calculating text entry speed
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   MacKenzie IS, 2002, LECT NOTES COMPUT SC, V2411, P195
   Mankoff J., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P213, DOI 10.1145/288392.288611
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364265
   Pick S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P109, DOI 10.1109/3DUI.2016.7460039
   Prätorius M, 2015, IEEE COMPUT GRAPH, V35, P42, DOI 10.1109/MCG.2015.106
   Proschowsky M., 2006, Proceedings of the SIGCHI conference on Human Factors in computing systems, P467, DOI DOI 10.1145/1124772.1124842
   Qin R, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P137, DOI 10.1145/3279778.3279786
   Shneiderman B, 2000, COMMUN ACM, V43, P63, DOI 10.1145/348941.348990
   Soukoreff R. William, 2003, P SIGCHI C HUM FACT, P113
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   VENOLIA D, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P265, DOI 10.1145/191666.191761
   Vertanen K., 2009, Efficient correction interfaces for speech recognition
   Walker J., 2016, CHI 16 EXTENDED ABST
   Walker J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5457, DOI 10.1145/3025453.3025783
   Whitmire E., 2017, P ACM INTERACTIVE MO, V1, P113, DOI [DOI 10.1145/3130978, 10.1145/3130978]
   Wikipedia contributors, 2021, LETT FREQ WIK FREE E
   Wong PC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI [10.1145/3173574.3173752, 10.1109/ICOPS35962.2018.9575596]
   Xu WG, 2019, IEEE T VIS COMPUT GR, V25, P1991, DOI 10.1109/TVCG.2019.2898736
   Xu ZE, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P883, DOI 10.1145/3332165.3347865
   Yi X, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P705, DOI 10.1145/3025453.3025454
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yiqin Lu, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090083
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Yu DF, 2018, IEEE T VIS COMPUT GR, V24, P2927, DOI 10.1109/TVCG.2018.2868581
   Zhenyu Gu, 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P35, DOI 10.1007/978-3-319-20916-6_4
   Zhu SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174013
NR 50
TC 6
Z9 6
U1 3
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3662
EP 3672
DI 10.1109/TVCG.2022.3203101
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200011
PM 36049000
DA 2024-11-06
ER

PT J
AU Li, C
   Kon, ALL
   Shing, HH
AF Li, Chen
   Kon, Angel Lo Lo
   Shing, Horace Ho
TI Use Virtual Reality to Enhance Intercultural Sensitivity: A Randomised
   Parallel Longitudinal Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Virtual reality; presence; intercultural sensitivity; emotional empathy
ID EMPATHY; COMPETENCE; EXPERIENCE; TECHNOLOGY; BEHAVIOR; PROGRAM; IMPACT
AB Prior studies suggest that emotional empathy is one of the components of intercultural sensitivity - the affective dimension under the concept of intercultural communication competence. Based on existing theories and findings, this paper reports a randomised parallel longitudinal study investigating the use of virtual reality (VR) exposure to enhance intercultural sensitivity. A total of 80 participants (36 females and 44 males) joined the study and were included in the data analysis. The participants were randomly assigned to the VR group, the video group, and the control group. Their intercultural sensitivity was measured three times: one week before the exposure (T-1), right after the exposure (T-2), and three weeks after the exposure (T-3). The results suggested that (1) the intercultural sensitivity of the VR group was significantly enhanced in both within-subject comparisons and between-subject comparisons, (2) there were no significant differences in intercultural sensitivity between the VR group and the video group at T-2, but the VR group retained the enhancement better at T-3, and (3) the sense of presence and emotional empathy well predicted the change in intercultural sensitivity of the VR group. The results, together with the participants' feedback and comments, provide new insights into the practice of using VR for intercultural sensitivity training and encourage future research on exploring the contributing factors of the results.
C1 [Li, Chen] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Kon, Angel Lo Lo; Shing, Horace Ho] City Univ Hong Kong, Ctr Innovat Applicat Internet & Multimedia Techno, Hong Kong, Peoples R China.
   [Shing, Horace Ho] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; City University of Hong Kong; City
   University of Hong Kong
RP Li, C (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
EM richard-chen.li@polyu.edu.hk; angelluluk@gmail.com;
   horace.ip@cityu.edu.hk
OI Li, Chen/0000-0002-3782-0737
FU Hong Kong Polytechnic University [P0035264]; Centre for Innovative
   Applications of Internet and Multimedia Technologies (AIMtech Centre),
   City University of Hong Kong
FX This project is supported by The Hong Kong Polytechnic University
   (project no.: P0035264) and the Centre for Innovative Applications of
   Internet and Multimedia Technologies (AIMtech Centre), City University
   of Hong Kong.
CR Akdere M, 2021, INT J INTERCULT REL, V82, P109, DOI 10.1016/j.ijintrel.2021.03.009
   Bachen CM, 2016, COMPUT HUM BEHAV, V64, P77, DOI 10.1016/j.chb.2016.06.043
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Barbot B, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106431
   Bennett M., 2017, International encyclopedia of intercultural communication, DOI DOI 10.1002/9781118783665.IEICC0182
   Bennett M.J., 2013, Basic concepts of intercultural communication: Paradigms, principles, practices
   BENNETT MJ, 1986, INT J INTERCULT REL, V10, P179, DOI 10.1016/0147-1767(86)90005-2
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   BHAWUK DPS, 1992, INT J INTERCULT REL, V16, P413, DOI 10.1016/0147-1767(92)90031-O
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Census and Statistics Department The Government of Hong Kong SAR, HONG KONG 2016 POP C
   Chen G.M., 1996, Communication yearbook 19, P353, DOI [DOI 10.1080/23808985.1996.11678935, 10.1080/23808985.1996.11678935]
   Chen G.M., 1997, BIENNIAL CONVENTION
   Chen G.M., 2000, HUMAN COMMUNICATION, V3, P1, DOI DOI 10.1037/T61546-000
   CLARK RE, 1983, REV EDUC RES, V53, P445, DOI 10.2307/1170217
   Coffey AJ, 2017, ETR&D-EDUC TECH RES, V65, P455, DOI 10.1007/s11423-017-9510-9
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Decety J, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0077
   Dziedziewicz D, 2014, THINK SKILLS CREAT, V13, P32, DOI 10.1016/j.tsc.2014.02.006
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Findlay LC, 2006, EARLY CHILD RES Q, V21, P347, DOI 10.1016/j.ecresq.2006.07.009
   Gerling KM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3413, DOI 10.1145/2556288.2556962
   Gorini A, 2011, CYBERPSYCH BEH SOC N, V14, P99, DOI 10.1089/cyber.2010.0100
   Greitemeyer T, 2010, EMOTION, V10, P796, DOI 10.1037/a0020194
   Ho JCF, 2022, BEHAV INFORM TECHNOL, V41, P1185, DOI 10.1080/0144929X.2020.1864018
   Hoffman M.L., 1984, EMOTION COGNITION BE, P103
   Huang W., 2020, Investigating the Novelty Effect in Virtual Reality on STEM Learning
   Jain Sachin, 2013, J Cult Divers, V20, P15
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Korsi MJL, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P91, DOI 10.1145/2967934.2968110
   Lambert A, 2020, INT J HUM-COMPUT INT, V36, P1804, DOI 10.1080/10447318.2020.1801172
   Leung K, 2014, ANNU REV ORGAN PSYCH, V1, P489, DOI 10.1146/annurev-orgpsych-031413-091229
   Li C, 2020, J COMPUT ASSIST LEAR, V36, P625, DOI 10.1111/jcal.12432
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Luck M, 2000, APPL ARTIF INTELL, V14, P3, DOI 10.1080/088395100117142
   Lussier D., 2007, J APPL LINGUISTICS, V4, P309, DOI DOI 10.1558/japl.v4i3.309
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Martingano Alison Jane., 2021, Technology, Mind, and Behavior, V2, DOI DOI 10.1037/TMB0000034
   MEHRABIAN A, 1972, J PERS, V40, P525, DOI 10.1111/j.1467-6494.1972.tb00078.x
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Norouzi N, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P17, DOI 10.1145/3267851.3267901
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Penbek Sebnem, 2012, International Journal of Logistics Systems and Management, V11, P232, DOI 10.1504/IJLSM.2012.045425
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Sahin M, 2012, CHILD YOUTH SERV REV, V34, P1325, DOI 10.1016/j.childyouth.2012.03.013
   Sarwari AQ, 2017, COGENT SOC SCI, V3, DOI 10.1080/23311886.2017.1310479
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Serafin G., 2004, P ICAD 04 10 M INT C
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Silton N. R, 2019, SCI CONCEPTS HAPPINE, DOI [10.4018/978-1-5225-5918-4.ch010, DOI 10.4018/978-1-5225-5918-4.CH010]
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2018, BRIT J PSYCHOL, V109, P431, DOI 10.1111/bjop.12305
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Straffon DA, 2003, INT J INTERCULT REL, V27, P487, DOI 10.1016/S0147-1767(03)00035-X
   Tamim RM, 2011, REV EDUC RES, V81, P4, DOI 10.3102/0034654310393361
   Tarchi C, 2019, EUR J PSYCHOL EDUC, V34, P873, DOI 10.1007/s10212-019-00417-9
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Vorderer P, 2001, MEDIA PSYCHOL, V3, P343, DOI 10.1207/S1532785XMEP0304_03
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zhang XT, 2019, INT J INTERCULT REL, V71, P31, DOI 10.1016/j.ijintrel.2019.04.006
NR 70
TC 2
Z9 2
U1 2
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3673
EP 3683
DI 10.1109/TVCG.2022.3203091
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200012
PM 36048997
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Shi, XH
   Wang, LL
   Wu, J
   Fan, RZ
   Hao, AM
AF Shi, Xuehuai
   Wang, Lili
   Wu, Jian
   Fan, Runze
   Hao, Aimin
TI Foveated Stochastic Lightcuts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Virtual Reality; Foveated Rendering; Lightcuts; Many-lights Rendering
AB Foveated rendering provides an idea for accelerating rendering algorithms without sacrificing the perceived rendering quality in virtual reality applications. In this paper, we propose a foveated stochastic lightcuts method to render high-quality many-lights illumination effects in high perception-sensitive regions. First, we introduce a spatiotemporal-luminance based lightcuts generation method to generate lightcuts with different accuracy for different visual perception-sensitive regions. Then we propose a multi-resolution light samples selection method to select the light sample for each node in the lightcuts more efficiently. Our method supports full-dynamic scenes containing over 250k dynamic light sources and dynamic diffuse/specular/glossy objects. It provides frame rates up to 110fps for high-quality many-lights illumination effects in high perception-sensitive regions of the HVS in VR HMDs. Compared with the state-of-the-art stochastic lightcuts method using the same rendering time, our method achieves smaller mean squared errors in the fovea and periphery. We also conduct user studies to prove that the perceived quality of our method has a high visual similarity with the results of the ground truth rendered by using the stochastic lightcuts with 2048 light samples per pixel.
C1 [Wang, Lili] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Wang, Lili] Peng Cheng Lab, Shengzhen, Peoples R China.
   [Wang, Lili] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing, Peoples R China.
   [Shi, Xuehuai; Wu, Jian; Fan, Runze; Hao, Aimin] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University; Beihang University; Beihang University
RP Wang, LL (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Wang, LL (corresponding author), Peng Cheng Lab, Shengzhen, Peoples R China.; Wang, LL (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing, Peoples R China.
EM shixuehuaireal@buaa.edu.cn; wanglily@buaa.edu.cn; lanayawj@buaa.edu.cn;
   BY2106131@buaa.edu.cn; ham@buaa.edu.cn
RI wang, lili/HJP-8047-2023; Shi, Xuehuai/ISB-5757-2023; Zhao,
   Mingyu/HHS-0141-2022
FU National Key RD plan [2019YFC1521102]; National Natural Science
   Foundation of China [61932003, 61772051]
FX This work is supported by National Key R&D plan 2019YFC1521102, by the
   National Natural Science Foundation of China through Projects 61932003
   and 61772051.
CR Adelson E., 1984, RCA Eng, V29, P33
   Bastani B., 2020, US Patent, Patent No. [10,546,364, 10546364]
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Davis T, 2012, ASSER INT SPORT LAW, P1, DOI 10.1007/978-90-6704-829-3_1
   Duchowski AT, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498703
   Estevez AC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233305
   Field A., 2002, How to Design and Report Experiments
   Franke L, 2021, COMPUT GRAPH FORUM, V40, P110, DOI 10.1111/cgf.14176
   Friston S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323033
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Lafortune E. P., 1993, EDUGRAPHICS '93. First International Conference on Graphics Education. COMPUGRAPHICS '93. Third International Conference on Computational Graphics and Visualization Techniques. Combined Proceedings, P145
   LIN D, 2020, P ACM COMPUT GRAPH, V1, P1
   Lindeberg, 2016, CONCEALING RENDERING
   Meng XX, 2020, IEEE T VIS COMPUT GR, V26, P1972, DOI 10.1109/TVCG.2020.2973442
   Meng XX, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203199
   Moreau Pierre, 2019, High Performance Graphics, P21, DOI 10.2312/hpg.20191191
   Moreton H., 2018, TURING TEXTURE SPACE
   Nehab D, 2007, GRAPHICS HARDWARE 2007: ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P25
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Potter MC, 2014, ATTEN PERCEPT PSYCHO, V76, P270, DOI 10.3758/s13414-013-0605-z
   Shi XH, 2021, IEEE T VIS COMPUT GR, V27, P4183, DOI 10.1109/TVCG.2021.3106488
   Stafford J. R., 2019, US Patent, Patent No. [10,169,846, 10169846]
   Stengel M, 2016, COMPUT GRAPH FORUM, V35, P129, DOI 10.1111/cgf.12956
   Swafford Nicholas T, 2016, P ACM S APPL PERC, P7, DOI DOI 10.1145/2931002.2931011
   Turner Eric., 2018, 2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P1
   Tursun OT, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322985
   Vincent O. R., 2009, INSITE 2009 INF SCI, P97, DOI DOI 10.28945/3351
   Walter B, 2005, ACM T GRAPHIC, V24, P1098, DOI 10.1145/1073204.1073318
   Walter B, 2006, ACM T GRAPHIC, V25, P1081, DOI 10.1145/1141911.1141997
   Walter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185555
   Wang LS, 2020, IEEE POW ENER SOC GE, DOI 10.1109/pesgm41954.2020.9281769
   Wang R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508413
   Wasserstein RL, 2016, AM STAT, V70, P129
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Weier M, 2016, COMPUT GRAPH FORUM, V35, P289, DOI 10.1111/cgf.13026
   Yang QQ, 2021, COMPUT GRAPH-UK, V97, P200, DOI 10.1016/j.cag.2021.04.021
   Young A., 2019, US Patent, Patent No. [10,192,528, 10192528]
   Yuksel, 2020, IEEE T VIS COMPUT GR
   Yuksel C, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073604
   Yuksel Cem, 2019, High Performance Graphics, P27, DOI [10.2312/hpg.20191192, DOI 10.2312/HPG.20191192]
   Zheng ZP, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281588
   Zhou Dengwen, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1186, DOI 10.1109/CISP.2010.5647190
NR 43
TC 2
Z9 2
U1 11
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3684
EP 3693
DI 10.1109/TVCG.2022.3203089
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200013
PM 36049004
DA 2024-11-06
ER

PT J
AU Yu, K
   Zacharis, K
   Eck, U
   Navab, N
AF Yu, Kevin
   Zacharis, Kostantinos
   Eck, Ulrich
   Navab, Nassir
TI Projective Bisector Mirror (PBM): Concept and Rationale
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Mirror Geometry; Multi-camera system; Augmented Reality
ID AR
AB Our world is full of cameras, whether they are installed in the environment or integrated into mobile devices such as mobile phones or head-mounted displays. Displaying external camera views in our egocentric view with a picture-in-picture approach allows us to understand their view; however, it would not allow us to correlate their viewpoint with our perceived reality. We introduce Projective Bisector Mirrors for visualizing a camera view comprehensibly in the egocentric view of an observer with the metaphor of a virtual mirror. Our concept projects the image of a capturing camera onto the bisecting plane between the capture and the observer camera. We present extensive mathematical descriptions of this novel paradigm for multi-view visualization, discuss the effects of tracking errors and provide concrete implementation for multiple exemplary use-cases.
C1 [Yu, Kevin; Eck, Ulrich; Navab, Nassir] Tech Univ Munich, Comp Aided Med Procedures, Munich, Germany.
   [Zacharis, Kostantinos] Tech Univ Munich, Res Grp MITI, Hosp Rechts Isar, Munich, Germany.
C3 Technical University of Munich; Technical University of Munich
RP Yu, K (corresponding author), Tech Univ Munich, Comp Aided Med Procedures, Munich, Germany.
EM kevin.yu@tum.de
CR Agarwal Sameer, 2022, CERES SOLVER, V3
   Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816
   Barmaki R, 2019, ANAT SCI EDUC, V12, P599, DOI 10.1002/ase.1858
   Bernhard C., 2021, TRANSPORTATION RES I
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Bimber O, 2000, COMPUT GRAPH FORUM, V19, pC161, DOI 10.1111/1467-8659.00408
   BLINN JF, 1992, IEEE COMPUT GRAPH, V12, P89
   Blum T, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P115, DOI 10.1109/VR.2012.6180909
   Bork F, 2019, ANAT SCI EDUC, V12, P585, DOI 10.1002/ase.1864
   Bork F, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P169, DOI 10.1109/ISMAR.2017.33
   Breen D.E., 1995, INTERACTIVE OCCLUSIO
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Dey A, 2012, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2012.6402556
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Eisert P, 2007, IEEE IMAGE PROC, P1121
   Fotouhi J, 2020, IEEE ROBOT AUTOM LET, V5, P2722, DOI 10.1109/LRA.2020.2972831
   Giovanni Stevie, 2012, Motion in Games. 5th International Conference (MIG 2012). Proceedings, P55, DOI 10.1007/978-3-642-34710-8_6
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Greenslade Thomas B., 2011, Physics Teacher, V49, P338, DOI 10.1119/1.3628254
   Hauswiesner Stefan, 2011, P 10 INT C VIRT REAL, P23, DOI DOI 10.1145/2087756.2087759
   Heckbert Paul S, 1989, Fundamentals of texture mapping and image warping
   Hoang T. N., 2010, P ISWC, P1, DOI [DOI 10.1109/ISWC.2010.5665865, 10.1109/ISWC.2010.5665865]
   Hormann K., 2004, Proceedings of the SIGGRAPH/Eurographics Workshop on Graphics Hardware, P7, DOI DOI 10.1145/1058129.1058131
   Kameda Y, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P151, DOI 10.1109/ISMAR.2004.45
   Kim M., 2015, International Journal of Smart Home, V9, P169, DOI DOI 10.14257/IJSH.2015.9.2.16
   Kiyokawa K., 2005, HCI INT
   Kjarside K., 2005, Em: Proceedings of the central european multimedia and virtual reality conference, P511
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P73, DOI 10.1145/2993369.2993399
   Li N, 2022, PSYCHOL HEALTH MED, V27, P2229, DOI 10.1080/13548506.2021.1990363
   Marreiros F., 2005, ATAS 13 ENCONTRO POR, P41
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P217, DOI [10.1109/ISMAR50242.2020.00045, 10.1109/1SMA1R50242.2020.00045]
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P207, DOI [10.1109/1SMA1R50242.2020.00044, 10.1109/ISMAR50242.2020.00044]
   Mazzae E. N., 2018, EXAMINATION PROTOTYP
   Mcmillan L., VIRTUAL SPACE TELECO, P8
   Miyamoto T, 2006, LECT NOTES COMPUT SC, V4282, P302
   Mukhopadhyay K, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P1279, DOI 10.1109/IEMCON.2018.8615072
   Mulder JD, 2005, P IEEE VIRT REAL ANN, P203
   Navab N, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P43
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Portales Cristina, 2018, Virtual and Augmented Reality: Concepts, Methodologies, Tools, and Applications, P18, DOI [DOI 10.4018/978-1, 10.4018/978-1-5225-5469-1.ch002, DOI 10.4018/978-1-5225-5469-1.CH002]
   Reddy ND, 2019, PROC CVPR IEEE, P7318, DOI 10.1109/CVPR.2019.00750
   Roth D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P693, DOI 10.1109/VRW52623.2021.00229
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Sato H, 2009, LECT NOTES COMPUT SC, V5622, P482, DOI 10.1007/978-3-642-02771-0_54
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Schmidt E.A., Handbook of Camera Monitor Systems: The Automotive Mirror- Replacement Technology based on ISO 16505, P369, DOI [10.1007/ 978-3-319-29611-1_12, DOI 10.1007/978-3-319-29611-1_12]
   Shah M. M., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P372
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Stotko P, 2019, IEEE T VIS COMPUT GR, V25, P2102, DOI 10.1109/TVCG.2019.2899231
   Strak R, 2021, MENSCH AND COMPUTER 2021 (MUC 21), P227, DOI 10.1145/3473856.3473883
   Weibel Nadir, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383169
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
   Yuan ML, 2013, IEEE T MULTIMEDIA, V15, P1958, DOI 10.1109/TMM.2013.2280560
   Zhang YQ, 2016, IEEE IMAGE PROC, P1734, DOI 10.1109/ICIP.2016.7532655
   Zhou Y, 2021, RESULTS OPTICS, V5
   Zimmermann C, 2017, 2017 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Zokai S, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P217, DOI 10.1109/ISMAR.2003.1240705
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
NR 60
TC 4
Z9 4
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3694
EP 3704
DI 10.1109/TVCG.2022.3203108
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200014
PM 36048998
DA 2024-11-06
ER

PT J
AU Wang, XY
   Ye, H
   Sandor, C
   Zhang, WZ
   Fu, HB
AF Wang, Xuanyu
   Ye, Hui
   Sandor, Christian
   Zhang, Weizhan
   Fu, Hongbo
TI Predict-and-Drive: Avatar Motion Adaption in Room-Scale Augmented
   Reality Telepresence with Heterogeneous Spaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE AR Telepresence; Avatar Motion Adaption; Heterogeneous Spaces;
   Redirected Walking
ID WALKING
AB Avatar-mediated symmetric Augmented Reality (AR) telepresence has emerged with the ability to empower users located in different remote spaces to interact with each other in 3D through avatars. However, different spaces have heterogeneous structures and features, which bring difficulties in synchronizing avatar motions with real user motions and adapting avatar motions to local scenes. To overcome these issues, existing methods generate mutual movable spaces or retarget the placement of avatars. However, these methods limit the telepresence experience in a small sub-area space, fix the positions of users and avatars, or adjust the beginning/ending positions of avatars without presenting smooth transitions. Moreover, the delay between the avatar retargeting and users' real transitions can break the semantic synchronization between users' verbal conversation and perceived avatar motion. In this paper, we first examine the impact of the aforementioned transition delay and explore the preferred transition style with the existence of such delay through user studies. With the results showing a significant negative effect of avatar transition delay and providing the design choice of the transition style, we propose a Predict-and-Drive controller to diminish the delay and present the smooth transition of the telepresence avatar. We also introduce a grouping component as an upgrade to immediately calculate a coarse virtual target once the user initiates a transition, which could further eliminate the avatar transition delay. Once having the coarse virtual target or an exactly predicted target, we find the corresponding target for the avatar according to the pre-constructed mapping of objects of interest between two spaces. The avatar control component maintains an artificial potential field of the space and drives the avatar towards the target while respecting the obstacles in the physical environment. We further conduct ablation studies to evaluate the effectiveness of our proposed components.
C1 [Wang, Xuanyu; Zhang, Weizhan] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, MOEKLINNS Lab, Xian, Peoples R China.
   [Wang, Xuanyu; Ye, Hui; Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
   [Sandor, Christian] Univ Paris Saclay, CNRS, Lab Intetdisciplinaire Sci Numer LISN, Paris, France.
C3 Xi'an Jiaotong University; City University of Hong Kong; Universite
   Paris Saclay; Centre National de la Recherche Scientifique (CNRS);
   Universite Paris Cite
RP Zhang, WZ (corresponding author), Xi An Jiao Tong Univ, Sch Comp Sci & Technol, MOEKLINNS Lab, Xian, Peoples R China.; Fu, HB (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM xwang2247-c@my.cityu.edu.hk; hui.ye@cityu.edu.hk;
   chris.sandor@gmail.com; zhangwzh@xjtu.edu.cn; hongbofu@cityu.edu.hk
RI ZHAO, YUAN/HCI-5831-2022; Wang, Xuanyu/HGA-5924-2022
OI Wang, Xuanyu/0000-0002-6040-6905; Ye, Hui/0000-0001-9539-9920; Zhang,
   Weizhan/0000-0003-0330-5435; SANDOR, Christian/0000-0002-3990-2728
FU National Key Research and Development Program of China [2020AAA0108800];
   City University of Hong Kong [7005729, 9667234, 7005590, 9229094];
   National Natural Science Foundation of China [62172326, 62137002];
   Innovative Research Group of the National Natural Science Foundation of
   China [61721002]; Innovation Research Team of Ministry of Education [IRT
   17R86]; Project of China Knowledge Centre for Engineering Science and
   Technology; Project of Chinese academy of engineering "The Online and
   Offline Mixed Educational Service System for 'The Belt and Road'
   Training in MOOC China"; RGC Postdoc Fellowship Scheme
FX We thank the anonymous reviewers for their constructive comments, and
   the interview and user study participants for their time. This work was
   supported by grants from National Key Research and Development Program
   of China (No. 2020AAA0108800), the City University of Hong Kong (No.
   7005729, 9667234, 7005590, 9229094), the National Natural Science
   Foundation of China (No. 62172326 and 62137002), Innovative Research
   Group of the National Natural Science Foundation of China (No.
   61721002), Innovation Research Team of Ministry of Education (No. IRT
   17R86), Project of China Knowledge Centre for Engineering Science and
   Technology, Project of Chinese academy of engineering "The Online and
   Offline Mixed Educational Service System for `The Belt and Road'
   Training in MOOC China". Hui Ye was supported by the RGC Postdoc
   Fellowship Scheme.
CR Benda B, 2021, INT SYM MIX AUGMENT, P50, DOI 10.1109/ISMAR52148.2021.00019
   Caine K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P981, DOI 10.1145/2858036.2858498
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Choi Y, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P1, DOI [10.1109/VR46266.2020.1581319786286, 10.1109/VR46266.2020.00-87]
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Gottsacker M, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR52148.2021.00047
   Hirche S, 2003, P AMER CONTR CONF, P168
   Huang YZ, 2016, IEEE T VIS COMPUT GR, V22, P1568, DOI 10.1109/TVCG.2015.2446494
   HWANG YK, 1992, IEEE T ROBOTIC AUTOM, V8, P23, DOI 10.1109/70.127236
   Jo D, 2015, COMPUT ANIMAT VIRT W, V26, P259, DOI 10.1002/cav.1645
   Juyoung Lee, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382867
   Keshavarzi M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P353, DOI [10.1109/VR46266.2020.1581131119600, 10.1109/VR46266.2020.00-49]
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   Kim K, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1771
   Kim Y, 2016, IEEE T VIS COMPUT GR, V22, P2405, DOI 10.1109/TVCG.2016.2593780
   Lang YN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P767, DOI [10.1109/VR.2019.8798018, 10.1109/vr.2019.8798018]
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lehment NH, 2014, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2014.6948428
   Li S., 2008, COMPUTERS ENTERTAINM, V5, P1
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   McHenry N, 2021, AEROSP CONF PROC, DOI 10.1109/AERO50100.2021.9438161
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Samaraweera G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2013.6550192
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Suri S., 1986, 2 S COMPUTATIONAL GE, P14, DOI DOI 10.1145/10515.10517
   Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Valentin J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751556
   Walker Michael E., 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P538, DOI 10.1109/VR.2019.8798152
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Xie Q, 2020, PROC CVPR IEEE, P10444, DOI 10.1109/CVPR42600.2020.01046
   Xu K, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818075
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Yoon L., 2020, IEEE T VIS COMPUT GR
   Yoon L, 2021, Arxiv, DOI arXiv:2103.04380
   Zank M, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P229, DOI 10.1109/CW.2015.20
NR 41
TC 8
Z9 8
U1 4
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3705
EP 3714
DI 10.1109/TVCG.2022.3203109
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200015
PM 36049006
OA Green Published
DA 2024-11-06
ER

PT J
AU Kourtesis, P
   Vizcay, S
   Marchal, M
   Pacchierotti, C
   Argelaguet, F
AF Kourtesis, Panagiotis
   Vizcay, Sebastian
   Marchal, Maud
   Pacchierotti, Claudio
   Argelaguet, Ferran
TI Action-Specific Perception & Performance on a Fitts's Law Task in
   Virtual Reality: The Role of Haptic Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Spatial perception; time perception; accuracy; reaction time;
   electrotactile; vibrotactile; Fitts Law
ID OWNERSHIP; DISPLAYS; BEHAVIOR; SIZE
AB While user's perception and performance are predominantly examined independently in virtual reality, the Action-Specific Perception (ASP) theory postulates that the performance of an individual on a task modulates this individual's spatial and time perception pertinent to the task's components and procedures. This paper examines the association between performance and perception and the potential effects that tactile feedback modalities could generate. This paper reports a user study (N=24), in which participants performed a standardized Fitts's law target acquisition task by using three feedback modalities: visual, visuo-electrotactile, and visuo-vibrotactile. The users completed 3 Target Sizes x 2 Distances x 3 feedback modalities = 18 trials. The size perception, distance perception, and (movement) time perception were assessed at the end of each trial. Performance-wise, the results showed that electrotactile feedback facilitates a significantly better accuracy compared to vibrotactile and visual feedback, while vibrotactile provided the worst accuracy. Electrotactile and visual feedback enabled a comparable reaction time, while the vibrotactile offered a substantially slower reaction time than visual feedback. Although amongst feedback types the pattern of differences in perceptual aspects were comparable to performance differences, none of them was statistically significant. However, performance indeed modulated perception. Significant action-specific effects on spatial and time perception were detected. Changes in accuracy modulate both size perception and time perception, while changes in movement speed modulate distance perception. Also, the index of difficulty was found to modulate all three perceptual aspects. However, individual differences appear to affect the magnitude of action-specific effects. These outcomes highlighted the importance of haptic feedback on performance, and importantly the significance of action-specific effects on spatial and time perception in VR, which should be considered in future VR studies.
C1 [Kourtesis, Panagiotis; Vizcay, Sebastian; Pacchierotti, Claudio; Argelaguet, Ferran] Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
   [Marchal, Maud] Univ Rennes, INSA, IRISA, INRIA,CNRS, F-35042 Rennes, France.
   [Marchal, Maud] Inst Univ France, Paris, France.
C3 Universite de Rennes; Inria; Centre National de la Recherche
   Scientifique (CNRS); Centre National de la Recherche Scientifique
   (CNRS); Universite de Rennes; Inria; Institut Universitaire de France
RP Kourtesis, P (corresponding author), Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
EM panagiotis.kourtesis@inria.fr; sebastian.vizcay@inria.fr;
   ferran.argelaguet@inria.fr
RI Pacchierotti, Claudio/G-7304-2011; Kourtesis, Panagiotis/ABA-9356-2020
OI Pacchierotti, Claudio/0000-0002-8006-9168; Vizcay,
   Sebastian/0000-0002-1837-5607; Kourtesis, Panagiotis/0000-0002-2914-1064
FU European Union [856718]
FX This work was supported by the European Union's Horizon 2020 research
   and innovation program under grant agreement No. 856718 (TACTILITY).
CR Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Ariza O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P327, DOI 10.1109/VR.2018.8446317
   Asjad NS, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225171
   Bækgaard P, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319831
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bao T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219737
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Brickler D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419986
   Burke J. L., 2006, P 8 INT C MULT INT, P108, DOI DOI 10.1145/1180995.1181017
   Cehajic D., 2017, IEEE WORLD HAPTICS 2
   Chinello F, 2020, IEEE T IND ELECTRON, V67, P706, DOI 10.1109/TIE.2019.2899551
   Cholewiak RW, 2006, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2006, PROCEEDINGS, P413
   Chouvardas VG, 2008, DISPLAYS, V29, P185, DOI 10.1016/j.displa.2007.07.003
   Clark LD, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102413
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Devigne L, 2020, IEEE T HAPTICS, V13, P52, DOI 10.1109/TOH.2019.2963831
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Firestone C, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X15000965
   Firestone C, 2014, PSYCHOL SCI, V25, P38, DOI 10.1177/0956797613485092
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gibson J. J., 2014, ECOLOGICAL APPROACH, DOI DOI 10.4324/9781315740218
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hummel J, 2016, P IEEE VIRT REAL ANN, P39, DOI 10.1109/VR.2016.7504686
   Ichihara YG, 2008, PROC SPIE, V6807, DOI 10.1117/12.765420
   Isakovic M, 2022, IEEE T HAPTICS, V15, P255, DOI 10.1109/TOH.2022.3141187
   ISO Central Secretary, 2007, 92414002007 ISO
   Jones JA, 2019, IEEE T VIS COMPUT GR, V25, P2050, DOI 10.1109/TVCG.2019.2898798
   Joyce R. D., 2017, Passive Haptics to Enhance Virtual Reality Simulations, DOI [DOI 10.2514/6.2017-1313, 10.2514/6.2017-1313]
   KACZMAREK KA, 1991, IEEE T BIO-MED ENG, V38, P1, DOI 10.1109/10.68204
   Khenak N, 2020, IEEE T VIS COMPUT GR, V26, P3467, DOI 10.1109/TVCG.2020.3023574
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kourtesis P, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100151
   Kourtesis P, 2022, IEEE T HAPTICS, V15, P479, DOI 10.1109/TOH.2022.3189866
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   Kreimeier J, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P289, DOI 10.1145/3316782.3321536
   Laitin EL, 2019, ATTEN PERCEPT PSYCHO, V81, P778, DOI 10.3758/s13414-018-01652-w
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Li-Te Cheng, 1996, Proceedings ACM Multimedia 96, P243, DOI 10.1145/244130.244220
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   Maisto M, 2017, IEEE T HAPTICS, V10, P511, DOI 10.1109/TOH.2017.2691328
   McGee M, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1259
   Meli L., 2014, P ACM SIGGRAPH POST
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Pamungkas D. S., 2016, International Journal of Computer Theory and Engineering, V8, P465, DOI 10.7763/IJCTE.2016.V8.1090
   Pamungkas D, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P300, DOI 10.1109/ICARA.2015.7081164
   Patil I., 2021, JOSS, V6, P3167, DOI 10.21105/joss.03167
   Peterson RA, 2020, J APPL STAT, V47, P2312, DOI 10.1080/02664763.2019.1630372
   Proffitt DR, 2003, PSYCHOL SCI, V14, P106, DOI 10.1111/1467-9280.t01-1-01427
   Rakkolainen I, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5120081
   Sagardia M, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Schwind V., 2019, P MENSCH COMPUTER 20, DOI [DOI 10.1145/3340764.3340769, 10.1145/3340764.3340769]
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Singmann H., 2021, afex: Analysis of factorial experiments Computer software
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Somrak A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041185
   Sugovic M, 2016, ACTA PSYCHOL, V165, P1, DOI 10.1016/j.actpsy.2016.01.012
   Teather RJ, 2010, P IEEE VIRT REAL ANN, P307, DOI 10.1109/VR.2010.5444753
   Tu HW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300848
   Üzüm B, 2011, LECT NOTES COMPUT SC, V6779, P171, DOI 10.1007/978-3-642-21716-6_18
   van Breda Eric, 2017, BMJ Open Sport Exerc Med, V3, pe000216, DOI 10.1136/bmjsem-2016-000216
   van der Hoort B, 2014, ATTEN PERCEPT PSYCHO, V76, P1414, DOI 10.3758/s13414-014-0664-9
   Vizcay S., 2021, ICAT EGVE 2021, DOI [10.2312/EGVE.20211331, DOI 10.2312/EGVE.20211331]
   Wang BC, 2019, LECT NOTES COMPUT SC, V11576, P291, DOI 10.1007/978-3-030-22577-3_21
   Wilson CJ, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/151702
   Witt J, 2009, EXP BRAIN RES, V192, P145, DOI 10.1007/s00221-008-1594-3
   Witt JK, 2018, PSYCHOL SCI, V29, P139, DOI 10.1177/0956797617730892
   Witt JK, 2011, CURR DIR PSYCHOL SCI, V20, P201, DOI 10.1177/0963721411408770
   Witt JK, 2010, PERCEPTION, V39, P1341, DOI 10.1068/p6699
   Witt JK, 2010, J EXP PSYCHOL HUMAN, V36, P1153, DOI 10.1037/a0019947
   Witt JK, 2005, PSYCHOL SCI, V16, P937, DOI 10.1111/j.1467-9280.2005.01640.x
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zhao L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P239, DOI [10.1109/VR46266.2020.1581066900344, 10.1109/VR46266.2020.00-61]
NR 78
TC 6
Z9 6
U1 3
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3715
EP 3726
DI 10.1109/TVCG.2022.3203003
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200016
PM 36048989
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Ye, ZC
   Li, GL
   Liu, HM
   Cui, ZP
   Bao, HJ
   Zhang, GF
AF Ye, Zhichao
   Li, Guanglin
   Liu, Haomin
   Cui, Zhaopeng
   Bao, Hujun
   Zhang, Guofeng
TI CoLi-BA: Compact Linearization based Solver for Bundle Adjustment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Bundle adjustment; Compact linearization; Schur complement; SLAM;
   Structure-from-Motion
AB Bundle adjustment (BA) is widely used in SLAM and SfM, which are key technologies in Augmented Reality. For real-time SLAM and large-scale SfM, the efficiency of BA is of great importance. This paper proposes CoLi-BA, a novel and efficient BA solver that significantly improves the optimization speed by compact linearization and reordering. Specifically, for each reprojection function, the redundant matrix representation of Jacobian is replaced with a tiny 3D vector, by which the computational complexity, memory storage, and cache missing for Hessian matrix construction and Schur complement are significantly reduced. Besides, we also propose a novel reordering strategy to improve the cache efficiency for Schur complement. Experiments on diverse datasets show that the speed of the proposed CoLi-BA is five times that of Ceres and two times that of g2o without sacrificing accuracy. We further verify the effectiveness by porting CoLi-BA to the open-source SLAM and SfM systems. Even when running the proposed solver in a single thread, the local BA of SLAM only takes about 20ms on a desktop PC, and the reconstruction of SfM with seven thousand photos only takes half an hour. The source code is available on the webpage: https://github.com/zju3dv/CoLi-BA.
C1 [Ye, Zhichao; Li, Guanglin; Cui, Zhaopeng; Bao, Hujun; Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Liu, Haomin] SenseTime Res, Hong Kong, Peoples R China.
C3 Zhejiang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
EM yezhichao_cad@zju.edu.cn; liguanglin@zju.edu.cn;
   liuhaomin@sensetime.com; zhpcui@zju.edu.cn; baohujun@zju.edu.cn;
   zhangguofeng@zju.edu.cn
RI Liu, Haomin/IXW-5373-2023; Zheng, Zhaoyu/IUO-8001-2023; Zhang,
   Ge/K-9118-2019
OI Liu, Haomin/0000-0001-9511-2416
FU National Key Research and Development Program of China [2020YFF0304300];
   National Natural Science Foundation of China [61932003]; ZJU-SenseTime
   Joint Lab of 3D Vision
FX This work was partially supported by the National Key Research and
   Development Program of China under Grant 2020YFF0304300, the National
   Natural Science Foundation of China (No. 61932003), and ZJU-SenseTime
   Joint Lab of 3D Vision.
CR Agarwal S., CERES SOLVER
   Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   BJO A., 1996, Numerical Methods for Least Squares Problems, DOI [DOI 10.1137/1.9781611971484, 10.1137/1.9781611971484]
   Byröd M, 2010, LECT NOTES COMPUT SC, V6312, P114, DOI 10.1007/978-3-642-15552-9_9
   Cai Q, 2023, IEEE T PATTERN ANAL, V45, P73, DOI 10.1109/TPAMI.2021.3139681
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Campos C, 2020, IEEE INT CONF ROBOT, P51, DOI [10.1109/ICRA40945.2020.9197334, 10.1109/icra40945.2020.9197334]
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995
   EISENSTAT SC, 1981, SIAM J SCI STAT COMP, V2, P1, DOI 10.1137/0902001
   Elvira R, 2019, IEEE INT C INT ROBOT, P6253, DOI [10.1109/IROS40897.2019.8967572, 10.1109/iros40897.2019.8967572]
   Eriksson A, 2016, PROC CVPR IEEE, P1754, DOI 10.1109/CVPR.2016.194
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gu M, 1996, SIAM J SCI COMPUT, V17, P848, DOI 10.1137/0917055
   Guan H, 2017, IEEE T IMAGE PROCESS, V26, P711, DOI 10.1109/TIP.2016.2621662
   Ila V, 2017, INT CONF 3D VISION, P175, DOI 10.1109/3DV.2017.00029
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Lindenberger P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5967, DOI 10.1109/ICCV48922.2021.00593
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Moulon P, 2017, LECT NOTES COMPUT SC, V10214, P60, DOI 10.1007/978-3-319-56414-2_5
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Ni K, 2007, IEEE I CONF COMP VIS, P2009
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Pagani A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P375, DOI 10.1109/ICCVW.2011.6130266
   Polok L., 2015, P S HIGH PERF COMP, P33
   Polok L, 2013, IEEE INT CONF ROBOT, P2263, DOI 10.1109/ICRA.2013.6630883
   Powell M.J.D., 1970, NUMERICAL METHODS NO
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Rosen DM, 2012, IEEE INT CONF ROBOT, P1262, DOI 10.1109/ICRA.2012.6224646
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tanaka T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6230, DOI 10.1109/ICCV48922.2021.00619
   Tang C, 2019, 7 INT C LEARNING REP
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Tyagi A, 2021, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR52148.2021.00034
   Ventura J, 2014, IEEE T VIS COMPUT GR, V20, P531, DOI 10.1109/TVCG.2014.27
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Yang XB, 2020, IEEE T VIS COMPUT GR, V26, P3446, DOI 10.1109/TVCG.2020.3023634
   Zhang F., 2006, The Schur complement and its applications, V4
   Zhang RZ, 2017, IEEE I CONF COMP VIS, P29, DOI 10.1109/ICCV.2017.13
   Zhou LP, 2020, INT SYM MIX AUGMENT, P136, DOI 10.1109/ISMAR50242.2020.00035
NR 48
TC 3
Z9 4
U1 0
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3727
EP 3736
DI 10.1109/TVCG.2022.3203119
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200017
PM 36048987
DA 2024-11-06
ER

PT J
AU Weerasinghe, M
   Quigley, A
   Pucihar, KC
   Toniolo, A
   Miguel, A
   Kljun, M
AF Weerasinghe, Maheshya
   Quigley, Aaron
   Pucihar, Klen Copic
   Toniolo, Alice
   Miguel, Angela
   Kljun, Matjaz
TI Arigato: Effects of Adaptive Guidance on Engagement and Performance in
   Augmented Reality Learning Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Experiential learning; instructional guidance; adaptive learning
   systems; augmented reality; engagement; language Learning
ID INSTRUCTION; EXPERIENCE; DRIVERS; SCHOOL
AB Experiential learning (ExL) is the process of learning through experience or more specifically "learning through reflection on doing". In this paper, we propose a simulation of these experiences, in Augmented Reality (AR), addressing the problem of language learning. Such systems provide an excellent setting to support "adaptive guidance", in a digital form, within a real environment. Adaptive guidance allows the instructions and learning content to be customised for the individual learner, thus creating a unique learning experience. We developed an adaptive guidance AR system for language learning, we call Arigato (Augmented Reality Instructional Guidance & Tailored Omniverse), which offers immediate assistance, resources specific to the learner's needs, manipulation of these resources, and relevant feedback. Considering guidance, we employ this prototype to investigate the effect of the amount of guidance (fixed vs. adaptive-amount) and the type of guidance (fixed vs. adaptive-associations) on the engagement and consequently the learning outcomes of language learning in an AR environment. The results for the amount of guidance show that compared to the adaptive-amount, the fixed-amount of guidance group scored better in the immediate and delayed (after 7 days) recall tests. However, this group also invested a significantly higher mental effort to complete the task. The results for the type of guidance show that the adaptive-associations group outperforms the fixed-associations group in the immediate, delayed (after 7 days) recall tests, and learning efficiency. The adaptive-associations group also showed significantly lower mental effort and spent less time to complete the task.
C1 [Weerasinghe, Maheshya; Pucihar, Klen Copic; Kljun, Matjaz] Univ Primorska, Koper, Slovenia.
   [Weerasinghe, Maheshya; Toniolo, Alice; Miguel, Angela] Univ St Andrews, St Andrews, Fife, Scotland.
   [Quigley, Aaron] Univ New South Wales, Sydney, NSW, Australia.
C3 University of Primorska; University of St Andrews; University of New
   South Wales Sydney
RP Weerasinghe, M (corresponding author), Univ Primorska, Koper, Slovenia.; Weerasinghe, M (corresponding author), Univ St Andrews, St Andrews, Fife, Scotland.
EM amw31@st-andrews.ac.uk; a.quigley@unsw.edu.au; klen.copic@famnit.upr.si;
   a.toniolo@st-andrews.ac.uk; arm14@st-andrews.ac.uk;
   matjaz.kljun@famnit.upr.si
RI Kljun, Matjaž/G-6415-2015; Quigley, Aaron/JHS-5032-2023
OI Copic Pucihar, Klen/0000-0002-7784-1356; Quigley,
   Aaron/0000-0002-5274-6889; Weerasinghe, Dr. Maheshya/0000-0003-2691-601X
FU European Commission [739574]; Republic of Slovenia; Republic of Slovenia
   (European Union of the European Regional Development Fund); Slovenian
   research agency ARRS [B1-DE/20-21-002, P1-0383, J1-9186, J1-1715,
   J5-1796, J1-1692]
FX This research was supported by European Commission through the InnoRenew
   CoE project (Grant Agreement 739574) under the Horizon2020
   Widespread-Teaming program and the Republic of Slovenia (investment
   funding of the Republic of Slovenia and the European Union of the
   European Regional Development Fund). We also acknowledge support from
   the Slovenian research agency ARRS (program no. B1-DE/20-21-002,
   P1-0383, J1-9186, J1-1715, J5-1796, and J1-1692).
CR American Institute of Physics, 2008, WHAT LEV GUID PROM E, V1064
   Amiryousefi M., 2011, Journal of Language Teaching and Research, V2, P178
   ANDERSON JR, 1985, SCIENCE, V228, P456, DOI 10.1126/science.228.4698.456
   [Anonymous], 2009, IMPLICIT EMOTIONAL T
   [Anonymous], 2017, AN ADAPTIVE AR TUTOR
   [Anonymous], 2001, A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives
   Appleton JJ, 2008, PSYCHOL SCHOOLS, V45, P369, DOI 10.1002/pits.20303
   Arvanitis P., 2021, Digital Pedagogies and the Transformation of Language Education, P1, DOI [10.4018/978-1-7998-6745-6.ch001, DOI 10.4018/978-1-7998-6745-6.CH001]
   Ary D., 2018, Introduction to Research in Education
   ATKINSON RC, 1975, AM PSYCHOL, V30, P821, DOI 10.1037/h0077029
   Birt J, 2018, INFORMATION, V9, DOI 10.3390/info9020031
   Boud D., 1993, Using experience for learning
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   BRUNER JS, 1961, HARVARD EDUC REV, V31, P21
   Canhoto AI, 2016, J MARKET EDUC, V38, P98, DOI 10.1177/0273475316643746
   Carbonneau KJ, 2015, J EXP EDUC, V83, P495, DOI 10.1080/00220973.2014.989306
   Clark R.E., 2009, Constructivist instruction: Success or failure?, P158
   Clark RC, 2011, E-Learning and the Science of Instruction: Proven Guidelines for Consumers and Designers of Multimedia Learning, 3rd Edition, P1, DOI 10.1002/9781118255971
   Cohen A. D., 1980, System, V8, P221, DOI DOI 10.1016/0346-251X(80)90004-4
   Cronbach L. J., 1977, Aptitudes and Instructional Methods: A Handbook for Research on Interactions
   Dita F.-A, 2016, INFORM EC, V20, P76, DOI 10.12948/issn14531305/20.4.2016.07
   Draxler F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376537
   Dunlosky J, 2013, PSYCHOL SCI PUBL INT, V14, P4, DOI 10.1177/1529100612453266
   Ellis N. C., 1995, Computer Assisted Language Learning, V8, P103, DOI 10.1080/0958822940080202
   Erasmus+, FACTSH STAT ER
   Ferreira J. M., 2003, P TECHNOLOGY ENHANCE
   Ferrero G, 2018, WATER-SUI, V10, DOI 10.3390/w10020227
   Frantzidis CA, 2010, IEEE T INF TECHNOL B, V14, P589, DOI 10.1109/TITB.2010.2041553
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Freund PA, 2011, PERS INDIV DIFFER, V51, P629, DOI 10.1016/j.paid.2011.05.033
   Grantcharov TP, 2004, BRIT J SURG, V91, P146, DOI 10.1002/bjs.4407
   Guan JQ, 2023, INTERACT LEARN ENVIR, V31, P2016, DOI 10.1080/10494820.2021.1871631
   Halabi A. K, 2006, GLOBAL PERSPECTIVES, V3, P6
   Herman P., 2009, TAKING GUIDED LEARNI, P74
   Huang GP, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445283
   Huang TC, 2016, COMPUT EDUC, V96, P72, DOI 10.1016/j.compedu.2016.02.008
   Ibrahim A, 2018, IEEE T VIS COMPUT GR, V24, P2867, DOI 10.1109/TVCG.2018.2868568
   IEEE, 2003, REM EM REC MULT MOD, V2
   Jantjies M, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY MANAGEMENT (ICETM 2018), P42, DOI 10.1145/3300942.3300956
   Jarmon L, 2009, COMPUT EDUC, V53, P169, DOI 10.1016/j.compedu.2009.01.010
   Joplin L., 1981, J EXPERIENT EDUC, V4, P17, DOI DOI 10.1177/105382598100400104
   Joseph S., 2013, PhD dissertation
   Kalyuga S., 2001, EDUC PSYCHOL-UK, V21, P5, DOI [10.1080/ 01443410124681. eprint, DOI 10.1080/01443410124681.EPRINT, https://doi.org/10.1080/01443410124681, DOI 10.1080/01443410124681]
   Katsis CD, 2008, IEEE T SYST MAN CY A, V38, P502, DOI 10.1109/TSMCA.2008.918624
   Kearsley G., 1998, Educational Technology, V38, P20
   Kirschner PA, 2006, EDUC PSYCHOL-US, V41, P75, DOI 10.1207/s15326985ep4102_1
   Koedinger KR, 2007, EDUC PSYCHOL REV, V19, P239, DOI 10.1007/s10648-007-9049-0
   Koelstra R. A. L, 2012, AFFECTIVE IMPLICIT T
   Kolb D.A., 2014, Experiential learning: Experience as the source of learning and development
   Kolb D.A., 1981, ACAD MANAGE REV, V6, P289
   Kolb DA, 2001, EDUC PSYCHO, P227
   Kuder GF, 1937, PSYCHOMETRIKA, V2, P151, DOI 10.1007/BF02288391
   Kuhn D, 2007, EDUC PSYCHOL-US, V42, P109, DOI 10.1080/00461520701263376
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Lazonder AW, 2016, REV EDUC RES, V86, P681, DOI 10.3102/0034654315627366
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Lewis L. H., 1994, NEW DIRECTIONS ADULT, V1994, P5, DOI [DOI 10.1002/ACE.36719946203, 10.1002/ace.36719946203]
   Liono RA, 2021, PROCEDIA COMPUT SCI, V179, P144, DOI 10.1016/j.procs.2021.12.019
   Liu PHE, 2013, BRIT J EDUC TECHNOL, V44, pE1, DOI 10.1111/j.1467-8535.2012.01302.x
   Lu SJ, 2015, ENVIRON EDUC RES, V21, P525, DOI 10.1080/13504622.2014.911247
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   Mastropieri M. A., 1991, Teaching students ways to remember
   Mather C, 2017, STUD HEALTH TECHNOL, V241, P57, DOI 10.3233/978-1-61499-794-8-57
   Mayer R.E., 2009, Constructivist Instruction: Success or Failure?, P184
   Mergel B., 1998, INSTRUCTIONAL DESIGN
   Merrill MD, 2002, ETR&D-EDUC TECH RES, V50, P43, DOI 10.1007/BF02505024
   Moorhouse N., 2017, eReview of Tourism Research
   Moorhouse N, 2019, MUS MANAGE CURATOR, V34, P402, DOI 10.1080/09647775.2019.1578991
   Morrison A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1889
   PAAS FGWC, 1993, HUM FACTORS, V35, P737, DOI 10.1177/001872089303500412
   PAIVIO A, 1981, J EDUC PSYCHOL, V73, P780, DOI 10.1037/0022-0663.73.6.780
   PLACKETT RL, 1983, INT STAT REV, V51, P59, DOI 10.2307/1402731
   PRESSLEY M, 1982, REV EDUC RES, V52, P61, DOI 10.3102/00346543052001061
   Putnam A. L., 2015, TRANSLATIONAL ISSUES, V1, P130, DOI DOI 10.1037/TPS0000023
   RAUGH MR, 1975, J EDUC PSYCHOL, V67, P1, DOI 10.1037/h0078665
   Reeve J, 2011, CONTEMP EDUC PSYCHOL, V36, P257, DOI 10.1016/j.cedpsych.2011.05.002
   Rheinberg F, 2001, DIAGNOSTICA, V47, P57, DOI 10.1026//0012-1924.47.2.57
   Richardson JohnT.E., 1980, MENTAL IMAGERY HUMAN
   Rzayev R., 2020, P 11 NORDIC C HUMAN, P1
   SAGE Publications Sage CA: Los Angeles CA, 2017, ENG COMP VR NON VR E, V61
   Salomon G., 1983, EDUC PSYCHOL-US, V18, P42, DOI DOI 10.1080/00461528309529260
   Schaufeli W.B., 2013, Employee Engagement in Theory and Practice
   Schrepp M, 2019, UEQ USER EXP QUESTIO
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   SCHUMAN H, 1981, PUBLIC OPIN QUART, V45, P216, DOI 10.1086/268652
   Seedhouse P., 2014, Bellaterra journal of teaching and learning language and literature, V7, P0001
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Springer, 2008, TIME FREQUENCY ANAL
   Steffe L.P., 1995, CONSTRUCTIVISM ED
   Sullivan Gail M, 2013, J Grad Med Educ, V5, P541, DOI 10.4300/JGME-5-4-18
   Sullivan L., 2016, InterQuartile Range (IQR)
   Tobias S., 2009, Constructivist instruction: Success or failure?, DOI DOI 10.4324/9780203878842
   Tobias S., 1982, EDUC RES-UK, V11, P4
   toO.enableAlrashidi,usersH, 2016, HUMANFACTORSIN COMPU, V12, P41
   Topu FB, 2019, COMPUT HUM BEHAV, V92, P1, DOI 10.1016/j.chb.2018.10.022
   Vaughan Karen L., 2017, Natural Sciences Education, V46, P160031, DOI 10.4195/nse2016.11.0031
   Vazquez Christian David, 2017, P 2017 CHI C HUM FAC, P2172, DOI [DOI 10.1145/3027063.3053098, 10.1145/3027063, DOI 10.1145/3027063]
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Weber M, 2019, TRANSPORT RES F-TRAF, V65, P107, DOI 10.1016/j.trf.2019.06.001
   Weerasinghe Maheshya, 2019, Educational Augmented Reality Games, P3, DOI [10.1007/978-3-030-15620-6_1, DOI 10.1007/978-3-030-15620-6_1]
   Wei XD, 2016, P IEEE VIRT REAL ANN, P307, DOI 10.1109/VR.2016.7504776
   Westerfield G, 2015, INT J ARTIF INTELL E, V25, P157, DOI 10.1007/s40593-014-0032-x
   WESTON C, 1986, J HIGH EDUC, V57, P259, DOI 10.2307/1981553
   Wickens C.D., 2015, ENG PSYCHOL HUMAN PE, DOI DOI 10.4324/9781315665177
   Wise A F., 2009, Beyond more versus less: A reframing of the debate on instructional guidance
   Worthen JB, 2011, ESSAYS COGN PSYCHOL, P1
   Yang SX, 2018, J EDUC TEACHING, V44, P511, DOI 10.1080/02607476.2018.1450937
NR 107
TC 5
Z9 5
U1 7
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3737
EP 3747
DI 10.1109/TVCG.2022.3203088
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200018
PM 36048999
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Weerasinghe, M
   Biener, V
   Grubert, J
   Quigley, A
   Toniolo, A
   Pucihar, KC
   Kljun, M
AF Weerasinghe, Maheshya
   Biener, Verena
   Grubert, Jens
   Quigley, Aaron
   Toniolo, Alice
   Pucihar, Klen Copic
   Kljun, Matjaz
TI VocabulARy: Learning Vocabulary in AR Supported by Keyword
   Visualisations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Augmented Reality; vocabulary learning; keyword method; contextual
   learning
ID MENTAL EFFORT; MOTIVATION; MNEMONICS
AB Learning vocabulary in a primary or secondary language is enhanced when we encounter words in context. This context can be afforded by the place or activity we are engaged with. Existing learning environments include formal learning, mnemonics, flashcards, use of a dictionary or thesaurus, all leading to practice with new words in context. In this work, we propose an enhancement to the language learning process by providing the user with words and learning tools in context, with VocabulARy. VocabulARy visually annotates objects in AR, in the user's surroundings, with the corresponding English (first language) and Japanese (second language) words to enhance the language learning process. In addition to the written and audio description of each word, we also present the user with a keyword and its visualisation to enhance memory retention. We evaluate our prototype by comparing it to an alternate AR system that does not show an additional visualisation of the keyword, and, also, we compare it to two non-AR systems on a tablet, one with and one without visualising the keyword. Our results indicate that AR outperforms the tablet system regarding immediate recall, mental effort and task-completion time. Additionally, the visualisation approach scored significantly higher than showing only the written keyword with respect to immediate and delayed recall and learning efficiency, mental effort and task-completion time.
C1 [Weerasinghe, Maheshya; Pucihar, Klen Copic; Kljun, Matjaz] Univ Primorska, Koper, Slovenia.
   [Weerasinghe, Maheshya; Toniolo, Alice] Univ St Andrews, St Andrews, Fife, Scotland.
   [Biener, Verena; Grubert, Jens] Coburg Univ Appl Sci, Coburg, Germany.
   [Quigley, Aaron] Univ New South Wales, Sydney, NSW, Australia.
C3 University of Primorska; University of St Andrews; Hochschule Coburg;
   University of New South Wales Sydney
RP Weerasinghe, M (corresponding author), Univ Primorska, Koper, Slovenia.; Weerasinghe, M (corresponding author), Univ St Andrews, St Andrews, Fife, Scotland.
EM amw31@st-andrews.ac.uk; verena.biener@hs-coburg.de;
   jens.gruhert@hs-coburg.de; a.quigley@unsw.edu.au;
   a.toniolo@st-andrews.ac.uk; klen.copic@famnit.upr.si;
   matjaz.kljun@famnit.upr.si
RI Kljun, Matjaž/G-6415-2015; Quigley, Aaron/JHS-5032-2023; Grubert,
   Jens/B-1012-2018
OI Quigley, Aaron/0000-0002-5274-6889; Weerasinghe, Dr.
   Maheshya/0000-0003-2691-601X
FU European Commission [739574]; Republic of Slovenia; Republic of Slovenia
   (European Union of the European Regional Development Fund); Slovenian
   research agency ARRS [BI-DE/20-21-002, P1-0383, J1-9186, J1-1715,
   J5-1796, J1-1692]
FX This research was supported by European Commission through the InnoRenew
   CoE project (Grant Agreement 739574) under the Horizon2020
   Widespread-Teaming program and the Republic of Slovenia (investment
   funding of the Republic of Slovenia and the European Union of the
   European Regional Development Fund). We also acknowledge support from
   the Slovenian research agency ARRS (program no. BI-DE/20-21-002,
   P1-0383, J1-9186, J1-1715, J5-1796, and J1-1692).
CR Amiryousefi M., 2011, Journal of Language Teaching and Research, V2, P178
   Anonthanasap O., 2014, P HUMAN INTERFACE SO, V14
   [Anonymous], Vuforia Developer Portal
   [Anonymous], 2014, P 2 ACM S SPAT US IN
   Ary D., 2018, Introduction to Research in Education
   ATKINSON RC, 1975, AM PSYCHOL, V30, P821, DOI 10.1037/h0077029
   Ibáñez MB, 2014, COMPUT EDUC, V71, P1, DOI 10.1016/j.compedu.2013.09.004
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Brown H.D., 1995, READINGS 2 LANGUAGE
   Castle RO, 2009, INT SYM MIX AUGMENT, P179, DOI 10.1109/ISMAR.2009.5336477
   Chen Y.-C., 2009, WHAMPOA-An Interdisciplinary Journal, V56, P13
   Clark RC, 2011, E-Learning and the Science of Instruction: Proven Guidelines for Consumers and Designers of Multimedia Learning, 3rd Edition, P1, DOI 10.1002/9781118255971
   Cohen A. D., 1980, System, V8, P221, DOI DOI 10.1016/0346-251X(80)90004-4
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   Dalim CSC, 2020, INT J HUM-COMPUT ST, V134, P44, DOI 10.1016/j.ijhcs.2019.10.002
   Draxler F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376537
   Dunlosky J, 2013, PSYCHOL SCI PUBL INT, V14, P4, DOI 10.1177/1529100612453266
   Edge D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3169
   Erasmus+, FACTSH STAT ER
   Freund PA, 2011, PERS INDIV DIFFER, V51, P629, DOI 10.1016/j.paid.2011.05.033
   FUJIMOTO Y, 2012, P 3 AUGM HUM INT C, P1, DOI DOI 10.1145/2160125.2160132
   Georgiev T., 2004, Proceedings of the International Conference on Computer Systems and Technologies (e-Learning), pIV.28
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   Halabi A. K, 2006, GLOBAL PERSPECTIVES, V3, P6
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hautasaari Ari, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3369824
   Hinderks Andreas, 2018, WEBIST, P373
   Ibrahim A, 2018, IEEE T VIS COMPUT GR, V24, P2867, DOI 10.1109/TVCG.2018.2868568
   Jie Guo, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P948, DOI 10.1109/VR.2019.8797972
   Khoshnevisan B., 2021, Designing, Deploying, and Evaluating Virtual and Augmented Reality in Education, P242
   KINGSEARS ME, 1992, REM SPEC EDUC, V13, P22, DOI 10.1177/074193259201300505
   Kuder GF, 1937, PSYCHOMETRIKA, V2, P151, DOI 10.1007/BF02288391
   Kumar Basak S., 2018, E-LEARNING DIGITAL M, V15, P191, DOI [10.1177/2042753018785180, DOI 10.1177/2042753018785180]
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Li SS, 2014, ASEE ANNU CONF EXPO
   Lin MH, 2017, EURASIA J MATH SCI T, V13, P3553, DOI 10.12973/eurasia.2017.00744a
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   Masarwa S, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2119614119
   Mastropieri M. A., 1991, Teaching students ways to remember
   Mayes T., 2007, RETHINKING PEDAGOGY, P13
   McLoughlin C, 2010, AUSTRALAS J EDUC TEC, V26, P28, DOI 10.14742/ajet.1100
   Microsoft, MICR HOL MIX REAL TE
   NASA, 2006, NASA TLX Task Load Index
   Nicholson P, 2007, Computers and Education: E-Learning, From Theory to Practice, P1, DOI 10.1007/978-1-4020-4914-9_1
   Nunan D., 1999, Second Language Teaching and Learning
   PAAS FGWC, 1993, HUM FACTORS, V35, P737, DOI 10.1177/001872089303500412
   PAIVIO A, 1981, J EDUC PSYCHOL, V73, P780, DOI 10.1037/0022-0663.73.6.780
   PEARLMAN I, 1990, B PSYCHONOMIC SOC, V28, P14, DOI 10.3758/BF03337635
   Pintrich PR, 2003, J EDUC PSYCHOL, V95, P667, DOI 10.1037/0022-0663.95.4.667
   PRESSLEY M, 1982, J EDUC PSYCHOL, V74, P693, DOI 10.1037/0022-0663.74.5.693
   PRESSLEY M, 1982, REV EDUC RES, V52, P61, DOI 10.3102/00346543052001061
   Putnam A. L., 2015, TRANSLATIONAL ISSUES, V1, P130, DOI DOI 10.1037/TPS0000023
   RAUGH MR, 1975, J EDUC PSYCHOL, V67, P1, DOI 10.1037/h0078665
   RAUGH MR, 1977, INSTR SCI, V6, P199, DOI 10.1007/BF00120656
   Rheinberg F, 2001, DIAGNOSTICA, V47, P57, DOI 10.1026//0012-1924.47.2.57
   S. E. C. LTD, SAMS GAL OFF SAM GAL
   Sagarra N, 2006, MOD LANG J, V90, P228, DOI 10.1111/j.1540-4781.2006.00394.x
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Salman M, 2018, LECT NOTES ARTIF INT, V10928, P403, DOI 10.1007/978-3-319-95972-6_44
   SALOMON G, 1984, J EDUC PSYCHOL, V76, P647, DOI 10.1037/0022-0663.76.4.647
   Santos Marc Ericson C, 2016, Res Pract Technol Enhanc Learn, V11, P4, DOI 10.1186/s41039-016-0028-2
   Schrepp M, 2019, UEQ USER EXPERIENCE
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   SCHULTZ BB, 1985, SYST ZOOL, V34, P449, DOI 10.2307/2413207
   SCHUMAN H, 1981, PUBLIC OPIN QUART, V45, P216, DOI 10.1086/268652
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7
   Spitzer M, 2015, TRENDS NEUROSCI EDUC, V4, P87, DOI 10.1016/j.tine.2015.11.004
   Strzys MP, 2018, EUR J PHYS, V39, DOI 10.1088/1361-6404/aaa8fb
   Sullivan Gail M, 2013, J Grad Med Educ, V5, P541, DOI 10.4300/JGME-5-4-18
   U. Technologies, UN REAL TIM DEV PLAT
   Vazquez Christian David, 2017, P 2017 CHI C HUM FAC, P2172, DOI [DOI 10.1145/3027063.3053098, 10.1145/3027063, DOI 10.1145/3027063]
   Waters D.L., 2005, LANG TEACH RES, V9, P129, DOI [https://doi.org/10.1191/1362168805lr151oa, DOI 10.1191/1362168805LR151OA, 10.1191/1362168805lr151oa.]
   Wei Z, 2015, LANG TEACH RES, V19, P43, DOI 10.1177/1362168814541734
   Wille Matthias, 2014, P 2014 ACM INT S WEA, P221
   Wu HK, 2013, COMPUT EDUC, V62, P41, DOI 10.1016/j.compedu.2012.10.024
   Yang SX, 2018, J EDUC TEACHING, V44, P511, DOI 10.1080/02607476.2018.1450937
NR 79
TC 9
Z9 9
U1 7
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3748
EP 3758
DI 10.1109/TVCG.2022.3203116
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200019
PM 36044496
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Tong, J
   Wilcox, LM
   Allison, RS
AF Tong, Jonathan
   Wilcox, Laurie M.
   Allison, Robert S.
TI The impacts of lens and stereo camera separation on perceived slant in
   Virtual Reality head-mounted displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Virtual Reality; Interpupillary Distance; Depth Perception
ID ONE-HANDED CATCH; DEPTH; EXPOSURE
AB Stereoscopic AR and VR headsets have displays and lenses that are either fixed or adjustable to match a limited range of user inter-pupillary distances (IPDs). Projective geometry predicts a misperception of depth when either the displays or virtual cameras used to render images are misaligned with the eyes. However, misalignment between the eyes and lenses might also affect binocular convergence, which could further distort perceived depth. This possibility has been largely ignored in previous studies. Here, we evaluated this phenomenon in a VR headset in which the inter-lens and inter-axial camera separations are coupled and adjustable. In a baseline condition, both were matched to observers' IPDs. In two other conditions, the inter-lens and inter-axial camera separations were set to the maximum and minimum allowed by the headset. In each condition, observers were instructed to adjust a fold created by two intersecting, textured surfaces until it appeared to have an angle of 90 degrees. The task was performed at three randomly interleaved viewing distances, monocularly and binocularly. In the monocular condition, observers underestimated the fold angle and there was no effect of viewing distance on their settings. In the binocular conditions, we found that when the lens and camera separation were less than the viewer's IPD, they exhibited compression of perceived slant relative to baseline. The reverse pattern was seen when the lens and camera separation were larger than the viewer's IPD. These results were well explained by a geometric model that considers shifts in convergence due to lens and display misalignment with the eyes, as well as the relative contribution of monocular cues.
C1 [Tong, Jonathan; Wilcox, Laurie M.; Allison, Robert S.] York Univ, Ctr Vis Res, N York, ON, Canada.
C3 York University - Canada
RP Tong, J (corresponding author), York Univ, Ctr Vis Res, N York, ON, Canada.
EM tongj86@yorku.ca; lwilcox@yorku.ca; allison@eecs.yorku.ca
OI Allison, Robert/0000-0002-4485-2665; Wilcox, Laurie/0000-0002-3594-6192
FU NSERC Collaborative Research and Development (CRD) grant; Qualcomm
   Canada Inc; Canada First Research Excellence Fund (CFREF) for the
   Vision: Science to Application (VISTA) program
FX This work was funded by an NSERC Collaborative Research and Development
   (CRD) grant, in partnership with Qualcomm Canada Inc, and the Canada
   First Research Excellence Fund (CFREF) for the Vision: Science to
   Application (VISTA) program.
CR Allison RS, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2770875
   Allison RS, 2004, PROC SPIE, V5291, P167, DOI 10.1117/12.526278
   Bennett S, 1999, EXP BRAIN RES, V129, P362, DOI 10.1007/s002210050904
   Bennett SJ, 2000, EXP BRAIN RES, V135, P341, DOI 10.1007/s002210000520
   Benzeroual K., 2011, SMPTE 2 ANN INT C ST, P1
   Cheng DW, 2022, OPT EXPRESS, V30, P6584, DOI 10.1364/OE.452747
   COOK RD, 1977, TECHNOMETRICS, V19, P15, DOI 10.2307/1268249
   EPSTEIN W, 1968, AM J PSYCHOL, V81, P189, DOI 10.2307/1421263
   Gao ZP, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205032
   Hibbard PB, 2020, INT CONF 3D IMAG, DOI 10.1109/IC3D51119.2020.9376369
   Hillis JM, 2004, J VISION, V4, P967, DOI 10.1167/4.12.1
   Howard I.P., 2012, Perceiving in Depth, Volume 2: Stereoscopic Vision, V2
   Neveu P, 2010, OPHTHAL PHYSL OPT, V30, P806, DOI 10.1111/j.1475-1313.2010.00763.x
   Priot A.E., 2015, INT C 3D IMAGING IC3, P1
   Priot AE, 2018, DISPLAYS, V51, P1, DOI 10.1016/j.displa.2017.11.002
   Robinett W., 1992, Presence: Teleoper. Virtual Environ, V1, P45, DOI DOI 10.1162/pres.1992.1.1.45
   Rosenberg L. B, 1992, EFFECT INTEROCULAR D
   Siegel M, 2000, IEEE T CIRC SYST VID, V10, P387, DOI 10.1109/76.836283
   Spottiswoode R., 1953, The theory of stereoscopic transmission its application to the motion picture
   Stuart G. W., 2007, HEAD AND HELMET MOUN, V6557, P137
   Tong J, 2020, INT SYM MIX AUGMENT, P73, DOI [10.1109/ISMAR50242.2020.00027, 10.1109/1SMA1R50242.2020.00027]
   Tong J, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.6.060409
   Vaissie L, 1999, P SOC PHOTO-OPT INS, V3639, P57, DOI 10.1117/12.349415
   von Helmholtz H., 2013, TREATISE PHYSL OPTIC, V3
   WALLACH H, 1963, AM J PSYCHOL, V76, P191, DOI 10.2307/1419156
   WANN JP, 1995, VISION RES, V35, P2731, DOI 10.1016/0042-6989(95)00018-U
   Ware C, 1998, IEEE T SYST MAN CY A, V28, P56, DOI 10.1109/3468.650322
   Wartell Z, 2002, IEEE T VIS COMPUT GR, V8, P129, DOI 10.1109/2945.998666
   Wheatstone C., 1838, Philosophical Transactions of the Royal Society of London, V128, P371, DOI DOI 10.1098/RSTL.1838.0019
NR 29
TC 1
Z9 1
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3759
EP 3766
DI 10.1109/TVCG.2022.3203098
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200020
PM 36048994
DA 2024-11-06
ER

PT J
AU Jhan, XD
   Wong, SK
   Ebrahimi, E
   Lai, YW
   Huang, WC
   Babu, SV
AF Jhan, Xing-Da
   Wong, Sai-Keung
   Ebrahimi, Elham
   Lai, Yuwen
   Huang, Wei-Chia
   Babu, Sabarish, V
TI Effects of Small Talk With a Crowd of Virtual Humans on Users' Emotional
   and Behavioral Responses
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Virtual Humans; Virtual Crowds; Virtual Reality; Small Talk Modeling;
   Simulated Social Dialogue; User Evaluation
ID EYE GAZE; CONTAGION; GENDER; EXPRESSIONS
AB In this contribution, we empirically investigated the effect of small talk on the users' non-verbal behaviors and emotions when users interacted with a crowd of virtual humans (VHs) with positive behavioral dispositions. Users were tasked with collecting items in a virtual marketplace via natural speech-based dialogue with a crowd of virtual pedestrians and vendors. The users were able to engage in natural speech-based conversation in a predefined corpus of small talk content that covered various commonplace small talk topics such as conversations about the weather, general concerns, and entertainment based on similar real-life situations. For instance, the VHs with the small talk ability would ask the users some simple questions to make small talk or remind the users of their belongings. We conducted a between-subjects empirical evaluation to investigate whether the user behaviors and emotions were different between a small talk condition and a non-small talk condition, and examined gender effects of the participants. We collected objective and subjective measures of the users to analyze users' emotions and social interaction behaviors, when in conversation with VHs that either possessed small-talk capability or not, besides task or goal oriented dialogue capabilities. Our result revealed that the VHs with small talk capability could alter the emotions and non-verbal behaviors of the users. Furthermore, the non-verbal behaviors between female and male participants differed greatly in the presence or absence of small talk.
C1 [Jhan, Xing-Da; Wong, Sai-Keung; Huang, Wei-Chia] Natl Yang Ming Chiao Tung Univ, Comp Sci Dept, New Taipei, Taiwan.
   [Ebrahimi, Elham] Univ North Carolina Wilmington, Comp Sci Dept, Wilmington, NC USA.
   [Lai, Yuwen] Apex Mat Technol Corp, Keelung, Taiwan.
   [Babu, Sabarish, V] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
C3 National Yang Ming Chiao Tung University; University of North Carolina;
   University of North Carolina Wilmington; Clemson University
RP Wong, SK (corresponding author), Natl Yang Ming Chiao Tung Univ, Comp Sci Dept, New Taipei, Taiwan.
EM gg4627942@gmail.com; cswingo@nycu.edu.tw; ebrahimie@uncw.edu;
   yuwen.lai@gmail.com; michae805@gmail.com; sbabu@clemson.edu
OI Ebrahimi, Elham/0000-0001-9431-557X
FU US National Science Foundation [IIS 2007435]; Higher Education Sprout
   Project of the National Yang Ming Chiao Tung University; Ministry of
   Education (MOE), Taiwan;  [MOST 109-2221-E-009121-MY3]; 
   [110-2811-E-009-508];  [111-2811-E-A49-508]
FX This work was partly supported by grant no. MOST 109-2221-E-009121-MY3,
   110-2811-E-009-508, and 111-2811-E-A49-508 (Taiwan), and US National
   Science Foundation grant no. IIS 2007435, as well as the Higher
   Education Sprout Project of the National Yang Ming Chiao Tung University
   and Ministry of Education (MOE), Taiwan. The authors would like to thank
   all the participants.
CR André E, 2010, SPEECH TECHNOLOGY: THEORY AND APPLICATIONS, P123, DOI 10.1007/978-0-387-73819-2_8
   ARON A, 1992, J PERS SOC PSYCHOL, V63, P596, DOI 10.1037/0022-3514.63.4.596
   Aslan E, 2020, CLASSR DISCOURSE, V11, P252, DOI 10.1080/19463014.2019.1585891
   Babel F, 2021, INT J SOC ROBOT, V13, P1485, DOI 10.1007/s12369-020-00730-0
   Babu S, 2005, LECT NOTES ARTIF INT, V3661, P120
   Babu S, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P215
   Babu S, 2006, LECT NOTES ARTIF INT, V4133, P169
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Barsade SG, 2002, ADMIN SCI QUART, V47, P644, DOI 10.2307/3094912
   Baylor AL, 2009, COMPUT HUM BEHAV, V25, P450, DOI 10.1016/j.chb.2008.10.008
   Bickmore T, 2005, TEXT SPEECH LANG TEC, V30, P23
   Cassell J, 2000, COMMUN ACM, V43, P70, DOI 10.1145/332051.332075
   Cassell J, 2000, EMBODIED CONVERSATIONAL AGENTS, P29
   Coupland J, 2003, RES LANG SOC INTERAC, V36, P1, DOI 10.1207/S15327973RLSI3601_1
   COUPLAND J, 1992, LANG SOC, V21, P207, DOI 10.1017/S0047404500015268
   Coviello L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090315
   Crozier W.R., 2010, The development of shyness and social withdrawal, P42
   D'Mello S, 2012, INT J HUM-COMPUT ST, V70, P377, DOI 10.1016/j.ijhcs.2012.01.004
   Ekman P., 2002, The facial action coding system
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Ferrara E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142390
   Ferreira Nuno, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P97, DOI 10.1007/978-3-642-33197-8_10
   Gallace A, 2022, CURR OPIN BEHAV SCI, V43, P249, DOI 10.1016/j.cobeha.2021.11.006
   Guadagno RE, 2007, MEDIA PSYCHOL, V10, P1
   HALL ET, 1968, CURR ANTHROPOL, V9, P83, DOI 10.1086/200975
   HALL ET, 1963, AM ANTHROPOL, V65, P1003, DOI 10.1525/aa.1963.65.5.02a00020
   Hall ET, 1966, The hidden dimension, V609
   Harms C., 2004, INTERNAL CONSISTENCY, P1
   Harper RG., 1978, Nonverbal communication: the state of the art
   Hatfield E., 1993, Current directions in psychological science, V2, P96, DOI 10.1111/1467-8721.ep10770953
   Helbing D, 2002, PEDESTRIAN AND EVACUATION DYNAMICS, P21
   Hess U., 2016, Encyclopedia of mental health, V3, P208, DOI DOI 10.1016/B978-0-12-397045-9.00218-4
   Hessels RS, 2020, PSYCHON B REV, V27, P856, DOI 10.3758/s13423-020-01715-w
   Hoegen R, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P111, DOI 10.1145/3308532.3329473
   Izard C.E., 1993, The Differential Emotions Scale: DES IV-A [A method of measuring the meaning of subjective experience of discrete emotions]
   Johnson SK, 2008, LEADERSHIP QUART, V19, P1, DOI 10.1016/j.leaqua.2007.12.001
   Johnson W.L., 2000, INT J ARTIFICIAL INT, V11, P47
   Kipp M, 2008, LECT NOTES COMPUT SC, V5208, P191
   Kobori T., 2016, P 17 ANN M SPEC INT, P370, DOI DOI 10.18653/V1/W16-3646
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lavoie R, 2021, VIRTUAL REAL-LONDON, V25, P69, DOI 10.1007/s10055-020-00440-y
   Leys C, 2013, J EXP SOC PSYCHOL, V49, P764, DOI 10.1016/j.jesp.2013.03.013
   LUNDQVIST LO, 1995, SCAND J PSYCHOL, V36, P130, DOI 10.1111/j.1467-9450.1995.tb00974.x
   Lynch SD, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI 10.1109/VR.2018.8446180
   MAZUR A, 1980, AM J SOCIOL, V86, P50, DOI 10.1086/227202
   Methot JR, 2021, ACAD MANAGE J, V64, P1445, DOI 10.5465/amj.2018.1474
   Michael-Grigoriou D., 2022, FRONTIERS VIRTUAL RE
   Milek A, 2018, PSYCHOL SCI, V29, P1451, DOI 10.1177/0956797618774252
   Montagne B, 2007, PERCEPT MOTOR SKILL, V104, P589, DOI 10.2466/PMS.104.2.589-598
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   MOSHER D L, 1981, Motivation and Emotion, V5, P61, DOI 10.1007/BF00993662
   Mousas C, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P40, DOI 10.1109/VR50410.2021.00024
   Nakano YI, 2010, IUI 2010, P139
   Niewiadomski R., 2013, P 2013 INT C AUT AG, P619
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Norouzi N, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P17, DOI 10.1145/3267851.3267901
   Omdahl BL, 1999, J ADV NURS, V29, P1351, DOI 10.1046/j.1365-2648.1999.01021.x
   Pejsa T, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2724731
   Pelachaud C., 2005, 13th Annual ACM International Conference on Multimedia, P683, DOI 10.1145/1101149.1101301
   PerezMarin D, 2011, CONVERSATIONAL AGENTS AND NATURAL LANGUAGE INTERACTION: TECHNIQUES AND EFFECTIVE PRACTICES, P1, DOI 10.4018/978-1-60960-617-6
   Podkosova I, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281523
   Pullin P., 2010, Journal of Business Communication, V47, P455, DOI DOI 10.1177/0021943610377307
   RAINES RS, 1990, J NONVERBAL BEHAV, V14, P253, DOI 10.1007/BF00989319
   Reeves B., 1996, CAMBRIDGE UK, V10
   Ren Y, 2021, Arxiv, DOI arXiv:2006.04558
   Rickel J., 2001, Intelligent Virtual Agents. Third International Workshop, IVA 2001. Proceedings (Lecture Notes in Artificial Intelligence Vol.2190), P15
   Robb A, 2013, IEEE T VIS COMPUT GR, V19, P662, DOI 10.1109/TVCG.2013.35
   Rosén J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53971-z
   Rosenbusch H, 2019, SOC PSYCHOL PERS SCI, V10, P1028, DOI 10.1177/1948550618820309
   Ruhland K, 2015, COMPUT GRAPH FORUM, V34, P299, DOI 10.1111/cgf.12603
   Russell James A, 1997, The psychology of facial expression, V10
   Rzayev R., 2019, P MENSCH COMPUTER 20, V2019, P11, DOI [https://doi.org/10.1145/3340764.3340802, DOI 10.1145/3340764.3340802]
   Schoenewolf G., 1990, MODERN PSYCHOANALYSI, V15, P49, DOI DOI 10.4135/9781452283012.N124
   Shi Y, 2021, Arxiv, DOI arXiv:2010.11567
   Singh Archana, 2017, Ind Psychiatry J, V26, P77, DOI 10.4103/ipj.ipj_25_14
   Thayalan X, 2012, PROCD SOC BEHV, V67, P580, DOI 10.1016/j.sbspro.2012.11.363
   Tsai Jason, 2012, Intelligent Virtual Agents. Proceedings 12th International Conference, IVA 2012, P81, DOI 10.1007/978-3-642-33197-8_8
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Uzzell D, 2006, BRIT J SOC PSYCHOL, V45, P579, DOI 10.1348/014466605X58384
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Volonte M, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343118
   Volonte M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P188, DOI 10.1109/VR50410.2021.00040
   Volonte M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P293, DOI [10.1109/VR46266.2020.1581610451331, 10.1109/VR46266.2020.00-55]
   Volonte M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P25, DOI 10.1109/VR.2018.8446364
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wallbott HG, 1998, EUR J SOC PSYCHOL, V28, P879, DOI 10.1002/(SICI)1099-0992(1998110)28:6<879::AID-EJSP901>3.0.CO;2-W
   Wang CC, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P340, DOI [10.1109/VR51125.2022.00053, 10.1109/ISPDS56360.2022.9874172]
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wheeless L. R., 1977, HUMAN COMMUNICATION, V3, P250, DOI DOI 10.1111/J.1468-2958.1977.TB00523.X
   Willis F.N., 1966, PSYCHON SCI, V5, P221, DOI [DOI 10.3758/BF03328362, 10.3758/BF03328362]
   Wu YX, 2014, IEEE T VIS COMPUT GR, V20, P626, DOI 10.1109/TVCG.2014.19
NR 92
TC 4
Z9 4
U1 2
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3767
EP 3777
DI 10.1109/TVCG.2022.3203107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200021
PM 36049003
DA 2024-11-06
ER

PT J
AU Xu, SZ
   Liu, TQ
   Liu, JH
   Zollmann, S
   Zhang, SH
AF Xu, Sen-Zhe
   Liu, Tian-Qi
   Liu, Jia-Hong
   Zollmann, Stefanie
   Zhang, Song-Hai
TI Making Resets away from Targets: POI aware Redirected Walking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH
DE Virtual Reality; redirected walking; reset; POI
AB Rapidly developing Redirected Walking (RDW) technologies have enabled VR applications to immerse users in large virtual environments (VE) while actually walking in relatively small physical environments (PE). When an unavoidable collision emerges in a PE, the RDW controller suspends the user's immersive experience and resets the user to a new direction in PE. Existing RDW methods mainly aim to reduce the number of resets. However, from the perspective of the user experience, when users are about to reach a point of interest (POI) in a VE, reset interruptions are more likely to have an impact on user experience. In this paper, we propose a new RDW method, aiming to keep resets occurring at a longer distance from the virtual target, as well as to reduce the number of resets. Simulation experiments and real user studies demonstrate that our method outperforms state-of-the-art RDW methods in the number of resets and dramatically increases the distance between the reset locations and the virtual targets.
C1 [Xu, Sen-Zhe] Tsinghua Univ, YMSC, Beijing, Peoples R China.
   [Xu, Sen-Zhe] BIMSA, Beijing, Peoples R China.
   [Liu, Tian-Qi; Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Liu, Tian-Qi; Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, BNRist, Beijing, Peoples R China.
   [Zollmann, Stefanie] Univ Otago, Dept Comp Sci, Dunedin, New Zealand.
C3 Tsinghua University; Tsinghua University; Tsinghua University;
   University of Otago
RP Xu, SZ (corresponding author), Tsinghua Univ, YMSC, Beijing, Peoples R China.; Xu, SZ (corresponding author), BIMSA, Beijing, Peoples R China.
EM xsz@tsinghua.edu.cn; liu-tq20@mails.tsinghua.edu.cn;
   liujiaho19@mails.tsinghua.edu.cn; stefanie.zollmann@otago.ac.nz;
   shz@tsinghua.edu.cn
RI liu, jiahong/GXH-6188-2022
OI Liu, JiaHong/0000-0001-9166-9364; Zollmann, Stefanie/0000-0002-4690-5409
FU National Natural Science Foundation of China [62132012];
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology
FX This work was supported by the National Natural Science Foundation of
   China (Project Number 62132012), and Tsinghua-Tencent Joint Laboratory
   for Internet Innovation Technology.
CR Azmandian M., 2022, IEEE T VIS COMPUT GR, P1
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bolte B, 2015, IEEE T VIS COMPUT GR, V21, P545, DOI 10.1109/TVCG.2015.2391851
   Chang Y. L., 2019, ARXIV
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Joshi Y, 2022, ARXIV
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP02012, 10.1207/s15327108ijap02012]
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Miceli Maria, 2014, Expectancy and Emotion
   NGUYEN A, 2018, INT C AUGMENTED REAL, P183
   Peck Tabitha C, 2009, IEEE Trans Vis Comput Graph, V15, P383, DOI 10.1109/TVCG.2008.191
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Peschel AO, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00902
   Razzaque S., 2001, EUR 2001 P
   Razzaque S., 2005, Redirected Walking
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Thomas J., 2020, 26th ACM Symposium on Virtual Reality Software and Technology, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams N. L., 2021, ARXIV
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Yu R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P313, DOI 10.1109/VR.2018.8448288
   Zhang S.-H., 2022, IEEE T VIS COMPUT GR
NR 39
TC 7
Z9 7
U1 3
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3778
EP 3787
DI 10.1109/TVCG.2022.3203095
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200022
PM 36074875
DA 2024-11-06
ER

PT J
AU Kim, YJ
   Kumaran, R
   Sayyad, E
   Milner, A
   Bullock, T
   Giesbrecht, B
   Höllerer, T
AF Kim, You-Jin
   Kumaran, Radha
   Sayyad, Ehsan
   Milner, Anne
   Bullock, Tom
   Giesbrecht, Barry
   Hollerer, Tobias
TI Investigating Search Among Physical and Virtual Objects Under Different
   Lighting Conditions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Mobile augmented reality; wide-area; user study; lighting conditions;
   perception; behavior
ID DIRECTION; SENSE
AB By situating computer-generated content in the physical world, mobile augmented reality (AR) can support many tasks that involve effective search and inspection of physical environments. Currently, there is limited information regarding the viability of using AR in realistic wide-area outdoor environments and how AR experiences affect human behavior in these environments. Here, we conducted a wide-area outdoor AR user study (n=48) using a commercially available AR headset (Microsoft Hololens 2) to compare (1) user interactions with physical and virtual objects in the environment (2) the effects of different lighting conditions on user behavior and AR experience and (3) the impact of varying cognitive load on AR task performance. Participants engaged in a treasure hunt task where they searched for and classified virtual target items (green "gems") in an augmented outdoor courtyard scene populated with physical and virtual objects. Cognitive load was manipulated so that in half the search trials users were required to monitor an audio stream and respond to specific target sounds. Walking paths, head orientation and eye gaze information were measured, and users were queried about their memory of encountered objects and provided feedback on the experience. Key findings included (1) Participants self-reported significantly lower comfort in the ambient natural light condition, with virtual objects more visible and participants more likely to walk into physical objects at night; (2) recall for physical objects was worse than for virtual objects, (3) participants discovered more gems hidden behind virtual objects than physical objects, implying higher attention on virtual objects and (4) dual-tasking modified search behavior. These results suggest there are important technical, perceptual and cognitive factors that must be considered if the full potential of "anywhere and anytime mobile AR" is to be realized.
C1 [Kim, You-Jin; Sayyad, Ehsan; Hollerer, Tobias] Univ Calif Santa Barbara, Media Arts & Technol, Santa Barbara, CA 93106 USA.
   [Kumaran, Radha; Hollerer, Tobias] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
   [Milner, Anne; Bullock, Tom; Giesbrecht, Barry] Univ Calif Santa Barbara, Dept Psychol & Brain Sci, Santa Barbara, CA 93106 USA.
   [Milner, Anne; Bullock, Tom; Giesbrecht, Barry] Univ Calif Santa Barbara, Inst Collaborat Biotechnol, Santa Barbara, CA 93106 USA.
C3 University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara;
   University of California System; University of California Santa Barbara
RP Kim, YJ (corresponding author), Univ Calif Santa Barbara, Media Arts & Technol, Santa Barbara, CA 93106 USA.
EM yujnkm@ucsb.edu; rkumaran@ucsb.edu
RI Kumaran, Radha/LCE-5323-2024
OI Kim, You-Jin/0000-0003-0903-8999; Kumaran, Radha/0000-0001-7161-3048
FU U.S. Army Combat Capabilities Development Command Soldier Center
   Measuring and Advancing Soldier Tactical Readiness and Effectiveness
   (MASTR-E) program [W911NF-19-F-0018, W911NF-19-D-0001]; ONR
   [N00014-19-1-2553, N00174-19-1-0024]; NSF [IIS-1911230]
FX This work was funded by the U.S. Army Combat Capabilities Development
   Command Soldier Center Measuring and Advancing Soldier Tactical
   Readiness and Effectiveness (MASTR-E) program through award
   W911NF-19-F-0018 under contract W911NF-19-D-0001 for the Institute for
   Collaborative Biotechnologies. Additional funding came from ONR awards
   N00014-19-1-2553 and N00174-19-1-0024, as well as NSF award IIS-1911230.
   The authors thank Natalie Juo and Anabel Salimian for their assistance
   with data collection.
CR Alha K, 2019, COMPUT HUM BEHAV, V93, P114, DOI 10.1016/j.chb.2018.12.008
   [Anonymous], 1998, SPATIAL TEMPORAL REA
   Arefin MS, 2022, IEEE T VIS COMPUT GR, V28, P2014, DOI 10.1109/TVCG.2022.3150503
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Cheok AD, 2004, PERS UBIQUIT COMPUT, V8, P71, DOI 10.1007/s00779-004-0267-x
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Erickson Austin, 2020, P INT C ART REAL TEL, P1
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Gabbard JL, 2019, IEEE T VIS COMPUT GR, V25, P2228, DOI 10.1109/TVCG.2018.2832633
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Gattullo M, 2015, IEEE T VIS COMPUT GR, V21, P638, DOI 10.1109/TVCG.2014.2385056
   Gleue T., 2001, P 2001 C VIRTUAL REA, P161
   Hamari J, 2019, INT J HUM-COMPUT INT, V35, P804, DOI 10.1080/10447318.2018.1497115
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Hollerer T., 2004, Mobile augmented reality. Telegeoinformatics: Location-Based Computing and Services
   Hund AM, 2009, J ENVIRON PSYCHOL, V29, P151, DOI 10.1016/j.jenvp.2008.05.009
   Huynh DQ, 2009, J MATH IMAGING VIS, V35, P155, DOI 10.1007/s10851-009-0161-2
   Kahl D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P121, DOI 10.1109/VR51125.2022.00030
   Kim K, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357584
   KOZLOWSKI LT, 1977, J EXP PSYCHOL HUMAN, V3, P590, DOI 10.1037/0096-1523.3.4.590
   Lages WS, 2019, INT SYM MIX AUGMENT, P301, DOI 10.1109/ISMAR.2019.00028
   Lakens D, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00863
   Livingston MarkA., 2013, Human Factors in Augmented Reality Environments, P35, DOI [10.1007/978-1-4614-4205-93, DOI 10.1007/978-1-4614-4205-93]
   Microsoft HoloLens Documentation, MAP PHYS SPAC HOLOLE
   Miller Jr R. G., 1997, ANOVA Beyond Basics of Applied Statistics
   Montello D. R., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT '93 Proceedings, P312
   Morrison A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1889
   Newman J, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P77, DOI 10.1109/ISAR.2001.970517
   PASHLER H, 1989, Q J EXP PSYCHOL-A, V41, P19, DOI 10.1080/14640748908402351
   Richard G, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P186, DOI 10.1109/VR51125.2022.00037
   Rompapas D, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P163, DOI 10.1145/3266037.3271637
   Rompapas DC, 2019, COMPUT GRAPH-UK, V84, P24, DOI 10.1016/j.cag.2019.08.007
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Smith M, 2015, P IEEE VIRT REAL ANN, P401, DOI 10.1109/VR.2015.7223465
   Spence C, 1997, PERCEPT PSYCHOPHYS, V59, P1, DOI 10.3758/BF03206843
   Strayer DL, 2001, PSYCHOL SCI, V12, P462, DOI 10.1111/1467-9280.00386
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Thomas B, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P168, DOI 10.1109/ISWC.1998.729549
   Thomas B, 2002, PERS UBIQUIT COMPUT, V6, P75, DOI 10.1007/s007790200007
   Vlahakis V., 2001, VIRTUAL REALITY ARCH, V9
   Waller D, 2004, PSYCHON B REV, V11, P157, DOI 10.3758/BF03206476
   Wickens C.D., 1984, VARIETIES ATTENTION
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
NR 47
TC 9
Z9 9
U1 5
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3788
EP 3798
DI 10.1109/TVCG.2022.3203093
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200023
PM 36048996
DA 2024-11-06
ER

PT J
AU Biener, V
   Kalamkar, S
   Nouri, N
   Ofek, E
   Pahud, M
   Dudley, JJ
   Hu, JH
   Kristensson, PO
   Weerasinghe, M
   Pucihar, KC
   Kljun, M
   Streuber, S
   Grubert, J
AF Biener, Verena
   Kalamkar, Snehanjali
   Nouri, Negar
   Ofek, Eyal
   Pahud, Michel
   Dudley, John J.
   Hu, Jinghui
   Kristensson, Per Ola
   Weerasinghe, Maheshya
   Pucihar, Klen Copic
   Kljun, Matjaz
   Streuber, Stephan
   Grubert, Jens
TI Quantifying the Effects of Working in VR for One Week
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE virtual reality; long-term; knowledge work; user study
ID PRODUCTIVITY; BENEFITS
AB Virtual Reality (VR) provides new possibilities for modern knowledge work. However, the potential advantages of virtual work environments can only be used if it is feasible to work in them for an extended period of time. Until now, there are limited studies of long-term effects when working in VR. This paper addresses the need for understanding such long-term effects. Specifically, we report on a comparative study (n=16), in which participants were working in VR for an entire week-for five days, eight hours each day-as well as in a baseline physical desktop environment. This study aims to quantify the effects of exchanging a desktop-based work environment with a VR-based environment. Hence, during this study, we do not present the participants with the best possible VR system but rather a setup delivering a comparable experience to working in the physical desktop environment. The study reveals that, as expected, VR results in significantly worse ratings across most measures. Among other results, we found concerning levels of simulator sickness, below average usability ratings and two participants dropped out on the first day using VR, due to migraine, nausea and anxiety. Nevertheless, there is some indication that participants gradually overcame negative first impressions and initial discomfort. Overall, this study helps lay the groundwork for subsequent research, by clearly highlighting current shortcomings and identifying opportunities for improving the experience of working in VR.
C1 [Biener, Verena; Kalamkar, Snehanjali; Nouri, Negar; Streuber, Stephan; Grubert, Jens] Coburg Univ Appl Sci & Arts, Coburg, Germany.
   [Ofek, Eyal; Pahud, Michel] Microsoft Res, Redmond, WA USA.
   [Dudley, John J.; Hu, Jinghui; Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
   [Weerasinghe, Maheshya; Pucihar, Klen Copic; Kljun, Matjaz] Univ Primorska, Primorska, Slovenia.
   [Weerasinghe, Maheshya] Univ St Andrews, St Andrews, Fife, Scotland.
C3 Klinikum Coburg; Microsoft; University of Cambridge; University of
   Primorska; University of St Andrews
RP Biener, V (corresponding author), Coburg Univ Appl Sci & Arts, Coburg, Germany.
EM verena.biener@hs-coburg.de; snehanjali.kalamkar@hs-coburg.de;
   negar.nouri@hs-coburg.de; eyalofek@microsoft.com; mpahud@microsoft.com;
   jjd50@cam.ac.uk; jh2265@cam.ac.uk; pok21@cam.ac.uk;
   amw31@st-andrews.ac.uk; klen.copic@famnit.upr.si;
   matjaz.kljun@famnit.upr.si; stephan.streuber@hs-coburg.de;
   jens.grubert@hs-coburg.de
RI Kljun, Matjaž/G-6415-2015; Grubert, Jens/B-1012-2018; Ofek,
   Eyal/LPP-8746-2024; Hu, Jinghui/ABH-8537-2020
OI Ofek, Eyal/0000-0003-4750-1569; Weerasinghe, Dr.
   Maheshya/0000-0003-2691-601X; Kristensson, Per Ola/0000-0002-7139-871X
CR Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   [Anonymous], 2014, P 2 ACM S SPAT US IN
   [Anonymous], TIME TRACKER MANAGEM
   Benedetto S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083676
   Berman MG, 2008, PSYCHOL SCI, V19, P1207, DOI 10.1111/j.1467-9280.2008.02225.x
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P2069, DOI 10.1109/TVCG.2022.3150474
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.0-178, 10.1109/VRW50115.2020.00098]
   Brunia S, 2009, J CORP REAL ESTATE, V11, P169, DOI 10.1108/14630010910985922
   Buckley S., 2017, 2 PEOPLE SPENT 48 HO
   C. V. C. GmbH, 10FASTFINGERSCOM TYP
   Das Thoondee K, 2017, 2017 COMPUTING CONFERENCE, P492, DOI 10.1109/SAI.2017.8252142
   Drucker P. F., 1966, EFFECTIVE EXECUTIVE
   Ens B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3171
   Funk M, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P222, DOI 10.1145/3056540.3056548
   G. I. Limited, CHROME REMOTE DESKTO
   G. LLC, FACE MESH MEDIAPIPE
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grier RA., 2015, Proc Human Factors Ergonomics Soc Annual Meeting, V59, P1727, DOI DOI 10.1177/1541931215591373
   Grubert J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P229, DOI 10.1109/ISMAR.2010.5643581
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Guo J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P443, DOI [10.1109/VR46266.2020.00-39, 10.1109/VR46266.2020.1581306543750]
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   HART S G, 1988, P139
   HEUER H, 1989, Z EXP ANGEW PSYCHOL, V36, P538
   Jie Guo, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P948, DOI 10.1109/VR.2019.8797972
   Jordan C. J., 2020, VIRTUAL M CRITICAL S
   Jordan P.W., 1996, Usability Evaluation in Industry
   KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim J, 2016, BUILD ENVIRON, V103, P203, DOI 10.1016/j.buildenv.2016.04.015
   Klemens B., 2022, I SPENT 100 HOURS WO
   Knierim P, 2021, IEEE PERVAS COMPUT, V20, P71, DOI 10.1109/MPRV.2021.3119378
   Knierim Pascal, 2020, The Virtual Office of the Future: Are Centralized Workplaces Obsolete
   Lee H., 2019, PERS UBIQUIT COMPUT, P1
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Lu FY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P768, DOI 10.1109/VR50410.2021.00104
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Mezner T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P372, DOI [10.1109/VR46266.2020.00-47, 10.1109/VR46266.2020.1581107639032]
   Mostajeran F, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83277-y
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   Nordahl R., 2019, 2019 IEEE C VIRTUAL
   Ofek E., 2020, arXiv
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364265
   Pretsch J., 2020, EUR J EC BUS STUD, V6, P95, DOI [DOI 10.26417/EJES.V6I1.P95-105, https://doi.org/10.26417/ejes.v6i1.p95-105]
   Rheinberg F., 2003, ERFASSUNG FLOWERLEBE
   Ruvimova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376724
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Schubert Thomas W., 2003, Zeitschrift fur Medienpsychologie, V15, P69
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wille Matthias, 2014, P 2014 ACM INT S WEA, P221
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Zsido AN, 2020, PSYCHIAT RES, V291, DOI 10.1016/j.psychres.2020.113223
NR 61
TC 17
Z9 17
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3810
EP 3820
DI 10.1109/TVCG.2022.3203103
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200024
PM 36044497
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Stanescu, A
   Mohr, P
   Schmalstieg, D
   Kalkofen, D
AF Stanescu, Ana
   Mohr, Peter
   Schmalstieg, Dieter
   Kalkofen, Denis
TI Model-Free Authoring by Demonstration of Assembly Instructions in
   Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Assembly tutorial; assembly instructions; 3D reconstruction; authoring
   by demonstration; augmented reality
ID TRACKING; RECONSTRUCTION; RECOGNITION
AB Among the most compelling applications of Augmented Reality are spatially registered tutorials. The effort of creating such instructions remains one of the obstacles precluding a wider use. We propose a system that is capable of extracting 3D instructions in a completely model-free manner from demonstrations, based on volumetric changes. The instructions are visualised later in an interactive Augmented Reality guidance application, on a mobile head-mounted display. We enable a technology that can be used by anyone in an ad-hoc tabletop setup for assemblies with rigid components.
C1 [Stanescu, Ana; Mohr, Peter; Schmalstieg, Dieter; Kalkofen, Denis] Graz Univ Technol, Graz, Austria.
   [Kalkofen, Denis] Flinders Univ S Australia, Adelaide, SA, Australia.
   [Schmalstieg, Dieter] VRVis GmbH, Vienna, Austria.
C3 Graz University of Technology; Flinders University South Australia
RP Stanescu, A (corresponding author), Graz Univ Technol, Graz, Austria.
EM ana.stanescu@icg.tugraz.at; mohr@icg.tugraz.at; schmalstieg@tugraz.at;
   kalkofen@icg.tugraz.at
OI Stanescu, Ana/0000-0002-6203-1238
FU Austrian Science Fund FWF [P30694, I5912]; Competence Center VRVis -
   Vienna Business Agency in the scope of COMET-Competence Centers for
   Excellent Technologies [879730]; Austrian Science Fund (FWF) [P30694,
   I5912] Funding Source: Austrian Science Fund (FWF)
FX This work was enabled by the Austrian Science Fund FWF (grant no. P30694
   and I5912) and the Competence Center VRVis, which is funded by BMK,
   BMDW, Styria, SFG, Tyrol and Vienna Business Agency in the scope of
   COMET -Competence Centers for Excellent Technologies (879730) which is
   managed by FFG.
CR Alves J, 2019, IEEE INT CONF AUTON, P168
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039
   Bhattacharya B, 2019, COMPUT IND, V105, P61, DOI 10.1016/j.compind.2018.04.021
   Büttner S, 2020, IN SY AP IN WE HC, V12203, P153, DOI 10.1007/978-3-030-50344-4_12
   Chidambaram S, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P234, DOI 10.1145/3461778.3462126
   Ellson J, 2004, MATH VIS, P127
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614
   Finman R, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P178, DOI 10.1109/ECMR.2013.6698839
   Furrer F, 2018, IEEE INT C INT ROBOT, P6835, DOI 10.1109/IROS.2018.8594391
   Golparvar-Fard M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P249, DOI 10.1109/ICCVW.2011.6130250
   Gupta A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P389
   Halber M, 2019, IEEE I CONF COMP VIS, P2541, DOI 10.1109/ICCV.2019.00263
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Huang GP, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445283
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Kaya SG, 2021, INT SYM MIX AUGMENT, P441, DOI 10.1109/ISMAR-Adjunct54149.2021.00101
   Kerbl B, 2015, COMPUT GRAPH FORUM, V34, P287, DOI 10.1111/cgf.12560
   Lambert AJD, 2003, INT J PROD RES, V41, P3721, DOI 10.1080/0020754031000120078
   Langer E, 2020, IEEE INT C INT ROBOT, P8453, DOI 10.1109/IROS45743.2020.9341664
   Makris S, 2013, CIRP ANN-MANUF TECHN, V62, P9, DOI 10.1016/j.cirp.2013.03.095
   Miller A, 2012, IEEE T VIS COMPUT GR, V18, P651, DOI 10.1109/TVCG.2012.48
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Palazzolo E, 2019, IEEE INT C INT ROBOT, P7855, DOI [10.1109/IROS40897.2019.8967590, 10.1109/iros40897.2019.8967590]
   Palazzolo E, 2018, IEEE INT CONF ROBOT, P6308
   Park J, 2017, IEEE I CONF COMP VIS, P143, DOI 10.1109/ICCV.2017.25
   Petersen N, 2013, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2013.6671771
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Reiners D, 1999, AUGMENTED REALITY, P31
   Runz Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4471, DOI 10.1109/ICRA.2017.7989518
   Rünz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024
   Scona R, 2018, IEEE INT CONF ROBOT, P3849, DOI 10.1109/ICRA.2018.8460681
   Taneja A, 2013, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2013.22
   Tang A., 2003, COMP EFFECTIVENESS A, P73
   Tölgyessy M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020413
   Ulusoy AO, 2014, LECT NOTES COMPUT SC, V8691, P31, DOI 10.1007/978-3-319-10578-9_3
   Wang B, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P459, DOI 10.1109/VR.2018.8446602
   Wasenmüller O, 2016, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2016.15
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Whitlock Matt, 2020, P GRAPHICS INTERFACE, P431, DOI DOI 10.20380/GI2020.43
   Wong YS, 2021, COMPUT GRAPH FORUM, V40, P511, DOI 10.1111/cgf.142651
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
   Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI [10.1109/ICRA.2019.8794371, 10.1109/icra.2019.8794371]
   Yamaguchi Masahiro, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1010, DOI 10.1145/3379337.3415819
   Zauner J, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P237, DOI 10.1109/ISMAR.2003.1240707
   Zhou B, 2020, IEEE T VIS COMPUT GR, V26, P3514, DOI 10.1109/TVCG.2020.3023635
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zogopoulos Vasilios, 2022, Procedia CIRP, P84, DOI 10.1016/j.procir.2022.02.159
   Zollmann S, 2012, INT SYM MIX AUGMENT, P167, DOI 10.1109/ISMAR.2012.6402554
NR 50
TC 9
Z9 9
U1 2
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3821
EP 3831
DI 10.1109/TVCG.2022.3203104
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200025
PM 36048990
DA 2024-11-06
ER

PT J
AU Li, M
   Pan, JJ
   Gao, Y
   Shen, Y
   Luo, F
   Dai, J
   Hao, AM
   Qin, H
AF Li, Ming
   Pan, Junjun
   Gao, Yang
   Shen, Yang
   Luo, Fang
   Dai, Ju
   Hao, Aimin
   Qin, Hong
TI Neurophysiological and Subjective Analysis of VR Emotion Induction
   Paradigm
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Emotion induction; Virtual Reality; Neurophysiological analysis;
   Electroencephalogram
ID VIRTUAL-REALITY; EEG; RECOGNITION; BRAIN; EXTRACTION; SELECTION;
   FEATURES
AB The ecological validity of emotion-inducing scenarios is essential for emotion research. In contrast to the classical passive induction paradigm, immersive VR fully engages the psychological and physiological components of the subject, which is considered an ecologically valid paradigm for studying emotion. Several studies investigate the emotional responses to different VR tasks or games using subjective scales. However, little research regards VR as an eliciting material, especially when systematically analyzing emotional processes in VR from a neurophysiological perspective. To fill this gap and scientifically evaluate VR's ability to be used as an active method for emotion elicitation, we investigate the dynamic relationship between explicit information (subjective evaluations) and implicit information (objective neurophysiological data). A total of 28 participants are enlisted to watch eight VR videos while their SAM/IPQ scores and EEG data are recorded simultaneously. In ecologically valid scenarios, the subjective results demonstrate that VR has significant advantages for evoking emotion in arousal-valence. This conclusion is backed by our examination of objective neurophysiological evidence that VR videos effectively induce high-arousal emotions. In addition, we obtain features of critical channels and frequency oscillations associated with emotional valence, thereby validating previous research in more lifelike circumstances. In particular, we discover hemispheric asymmetry in the occipital region under high and low emotional arousal, which adds to our understanding of neural features and the dynamics of emotional arousal. As a result, we successfully integrate EEG and VR to demonstrate that VR is more pragmatic for evoking natural feelings and is beneficial for emotional research. Our research has set a precedent for new methodologies of using VR induction paradigms to acquire a more reliable explanation of affective computing.
C1 [Li, Ming] Beihang Univ, State Key Lab Virtual RealityTechnol & Syst, Beijing, Peoples R China.
   [Pan, Junjun; Gao, Yang; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Pan, Junjun; Gao, Yang; Hao, Aimin] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing, Peoples R China.
   [Pan, Junjun; Gao, Yang; Hao, Aimin] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg Technol, 2019RU004, Beijing, Peoples R China.
   [Pan, Junjun; Dai, Ju; Hao, Aimin] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Shen, Yang; Luo, Fang] Beijing Normal Univ, Sch Psychol, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Beihang University; Beihang University; Beihang University; Chinese
   Academy of Medical Sciences - Peking Union Medical College; Peng Cheng
   Laboratory; Beijing Normal University; State University of New York
   (SUNY) System; Stony Brook University
RP Gao, Y (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM gaoyangvr@buaa.edu.cn
RI Gao, Yang/JQV-9627-2023; Pan, Junjun/A-1316-2013; Zhao,
   Mingyu/HHS-0141-2022
OI Gao, Yang/0000-0002-9149-3554
FU National Natural Science Foundation of China [61872020, 62172437,
   U20A20195, 62102208, 62002010]; Beijing Natural Science Foundation
   [4214066]; Beijing Advanced Innovation Center for Biomedical Engineering
   [ZF138G1714]; National Science Foundation of USA [IIS-1715985,
   IIS-1812606]; Global Visiting Fellowship of Bournemouth University;
   Research Program Funds of the Collaborative Innovation Center of
   Assessment toward Basic Education Quality at Beijing Normal University
   [2021-01-131-BZK01]; Fundamental Research Funds for the Central
   Universities [:310422116]
FX This work was supported by National Natural Science Foundation of China
   (No.61872020, 62172437, U20A20195, 62102208, 62002010), Beijing Natural
   Science Foundation under Grant (4214066), Beijing Advanced Innovation
   Center for Biomedical Engineering under Grant ZF138G1714, National
   Science Foundation of USA under Grants IIS-1715985 and IIS-1812606, and
   Global Visiting Fellowship of Bournemouth University. This work was
   supported by the Research Program Funds of the Collaborative Innovation
   Center of Assessment toward Basic Education Quality at Beijing Normal
   University: 2021-01-131-BZK01 supported by the Fundamental Research
   Funds for the Central Universities:310422116.
CR AHERN GL, 1985, NEUROPSYCHOLOGIA, V23, P745, DOI 10.1016/0028-3932(85)90081-8
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Bastug E, 2017, IEEE COMMUN MAG, V55, P110, DOI 10.1109/MCOM.2017.1601089
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Baumgartner T, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.008.2008
   Bradley M. M., 2007, Technical report D-1
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cao R., 2021, IEEE VIRTUAL REALITY
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chaumon M, 2015, J NEUROSCI METH, V250, P47, DOI 10.1016/j.jneumeth.2015.02.025
   Coan JA, 2004, BIOL PSYCHOL, V67, P7, DOI 10.1016/j.biopsycho.2004.03.002
   Damasio AR, 2000, NAT NEUROSCI, V3, P1049, DOI 10.1038/79871
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Fontaine J. R. J., 2013, Components of Emotional Meaning: A Sourcebook, eds
   Freeman J., 2005, PRESENCE 2005, P21
   Frijda NH., 2017, The laws of emotion, V1st
   Galvao F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103414
   Hadjidimitriou SK, 2012, IEEE T BIO-MED ENG, V59, P3498, DOI 10.1109/TBME.2012.2217495
   HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837
   Hofmann SM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P128, DOI 10.1109/AIVR.2018.00026
   Jenke R, 2014, IEEE T AFFECT COMPUT, V5, P327, DOI 10.1109/TAFFC.2014.2339834
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/vr.2019.8798334, 10.1109/VR.2019.8798334]
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kim A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P601, DOI 10.1109/VR.2018.8446046
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Lang P.J., 1997, NIMH CTR STUDY EMOT, V1, P39
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Liu YJ, 2018, IEEE T AFFECT COMPUT, V9, P550, DOI 10.1109/TAFFC.2017.2660485
   Luft CD, 2015, SCI REP-UK, V5, DOI 10.1038/srep15717
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Meuleman B, 2021, IEEE T AFFECT COMPUT, V12, P189, DOI 10.1109/TAFFC.2018.2864730
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Moghimi M, 2020, IEEE T AFFECT COMPUT, V11, P45, DOI 10.1109/TAFFC.2017.2764896
   Mohammadi G, 2022, IEEE T AFFECT COMPUT, V13, P1127, DOI 10.1109/TAFFC.2020.3028109
   Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165
   Pallavicini F, 2019, SIMULAT GAMING, V50, P136, DOI 10.1177/1046878119831420
   Petrescu L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247088
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Radüntz T, 2015, J NEUROSCI METH, V243, P84, DOI 10.1016/j.jneumeth.2015.01.030
   RAY WJ, 1985, SCIENCE, V228, P750, DOI 10.1126/science.3992243
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Scherer K. R., 2001, Appraisal processes in emotion: Theory, Methods, Research, DOI [10.1093/oso/9780195130072.003.0005, DOI 10.1093/OSO/9780195130072.003.0005]
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Solomon O. M, 1991, PSD COMPUTATIONS USI, V92
   Somarathna R., 2021, ARXIV
   Subramanian R, 2018, IEEE T AFFECT COMPUT, V9, P147, DOI 10.1109/TAFFC.2016.2625250
   Vallade JI, 2021, COMMUN EDUC, V70, P127, DOI 10.1080/03634523.2020.1791351
   Voigt Antons J. N., 2021, IEEE VIRTUAL REALITY
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   Zhang Y, 2021, IEEE T AFFECT COMPUT, P1
   Zhao GZ, 2018, FRONT BEHAV NEUROSCI, V12, DOI 10.3389/fnbeh.2018.00225
   Zheng WL, 2019, IEEE T AFFECT COMPUT, V10, P417, DOI 10.1109/TAFFC.2017.2712143
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 62
TC 12
Z9 13
U1 16
U2 75
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3832
EP 3842
DI 10.1109/TVCG.2022.3203099
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200026
PM 36049001
DA 2024-11-06
ER

PT J
AU Wang, ZM
   Zhao, YX
   Lu, F
AF Wang, Zhimin
   Zhao, Yuxin
   Lu, Feng
TI Gaze-Vergence-Controlled See-Through Vision in Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Augmented Reality; See-through Vision; Gaze Vergence Control; Gaze Depth
   Estimation
ID DEPTH JUDGMENTS
AB Augmented Reality (AR) see-through vision is an interesting research topic since it enables users to see through a wall and see the occluded objects. Most existing research focuses on the visual effects of see-through vision, while the interaction method is less studied. However, we argue that using common interaction modalities, e.g., midair click and speech, may not be the optimal way to control see-through vision. This is because when we want to see through something, it is physically related to our gaze depth/vergence and thus should be naturally controlled by the eyes. Following this idea, this paper proposes a novel gaze-vergence-controlled (GVC) see-through vision technique in AR. Since gaze depth is needed, we build a gaze tracking module with two infrared cameras and the corresponding algorithm and assemble it into the Microsoft HoloLens 2 to achieve gaze depth estimation. We then propose two different GVC modes for see-through vision to fit different scenarios. Extensive experimental results demonstrate that our gaze depth estimation is efficient and accurate. By comparing with conventional interaction modalities, our GVC techniques are also shown to be superior in terms of efficiency and more preferred by users. Finally, we present four example applications of gaze-vergence-controlled see-through vision.
C1 [Wang, Zhimin; Zhao, Yuxin; Lu, Feng] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Lu, Feng] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
C3 Beihang University; Peng Cheng Laboratory
RP Lu, F (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM zm.wang@buaa.edu.cn; zyuxin@buaa.edu.cn; lufeng@buaa.edu.cn
RI Zhao, Yuxin/HNS-3187-2023
OI Wang, Zhimin/0000-0001-5089-977X
FU National Natural Science Foundation of China (NSFC) [61972012]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC) under Grant 61972012.
CR Alt F., 2014, Proceedings of the 19th international conference on Intelligent User Interfaces, P267
   [Anonymous], 2014, P 2014 ACM INT S WEA
   Avery B., 2007, PROC ISMAR, DOI [10.1109/ISMAR.2007.4538869, DOI 10.1109/ISMAR.2007.4538869]
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Bardins S., 2008, P 1 ACM WORKSH VIS N, P47, DOI [10.1145/1461893.1461903, DOI 10.1145/1461893.1461903]
   Barnum P, 2009, INT SYM MIX AUGMENT, P111, DOI 10.1109/ISMAR.2009.5336483
   Billinghurst M, 2009, LECT NOTES COMPUT SC, V5622, P13, DOI 10.1007/978-3-642-02771-0_2
   blog.relaycars, APPLE VS MICROSOFT W
   Casiez G., 2012, P SIGCHI C HUM FACT, P2527, DOI DOI 10.1145/2207676.2208639
   Chen JX, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P189, DOI 10.1145/1344471.1344518
   Cheng YH, 2020, IEEE T IMAGE PROCESS, V29, P5259, DOI 10.1109/TIP.2020.2982828
   Demer JL, 2018, J NEUROPHYSIOL, V120, P2571, DOI 10.1152/jn.00485.2018
   Dierkes K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319819
   Elmadjian C, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206351
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   github, MESSAGEPACK
   github, NETMQ
   Gruenefeld Uwe, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P179, DOI 10.1145/3428361.3428402
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hirzle T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300855
   Itoh Y, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P75, DOI 10.1109/3DUI.2014.6798846
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Kameda Y, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P151, DOI 10.1109/ISMAR.2004.45
   Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kirst Dominik, 2016, CHI EA '16), P1519, DOI [DOI 10.1145/2851581.2892307, 10.1145/2851581.2892307]
   Kudo S., 2013, CHI 13 EXTENDED ABST, P1335
   Kwon Y.-M., 2006, International Journal of Virtual Reality, V5, P41, DOI 10.20870/ijvr.2006.5.3.2697
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Liu YF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3815, DOI 10.1109/ICCV48922.2021.00381
   Mantiuk R, 2011, LECT NOTES COMPUT SC, V6944, P1, DOI 10.1007/978-3-642-23834-5_1
   Mardanbegi D, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319822
   Martinez H., 2014, J MULTIMEDIA THEORY, V2
   microsoft, Microsoft HoloLens 2
   mobidev.biz, 10 AUGMENTED REALITY
   Mohan P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P79, DOI 10.1109/ISMAR-Adjunct.2018.00039
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Öney SZ, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391835
   Orlosky J, 2016, KUNSTL INTELL, V30, P301, DOI 10.1007/s13218-015-0411-y
   Park HM, 2008, INT SYM MIX AUGMENT, P175, DOI 10.1109/ISMAR.2008.4637353
   Pfeiffer Thies., 2008, JVRB-Journal of Virtual Reality and Broadcasting, V5
   Pilnick AR, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-90564-1
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Santini T, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204578
   Su D, 2019, IEEE T IND INFORM, V15, P2660, DOI 10.1109/TII.2018.2867952
   Sunggeun Ahn, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382908
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Swan JE, 2006, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2006.13
   Swirski L., 2015, THESIS
   Takahashi K, 2012, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2012.6247783
   Toyama T., 2015, P 20 INT C INT US IN, P322, DOI DOI 10.1145/2678025.2701384
   trtworld, INTRO NEXT GENERATIO
   Van Krevelen D., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10.20870/ijvr.2010.9.2.2767
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Vidal M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P439, DOI 10.1145/2493432.2493477
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   Wang ZM, 2021, INT SYM MIX AUGMENT, P11, DOI 10.1109/ISMAR52148.2021.00015
   Wang ZM, 2021, IEEE T HUM-MACH SYST, V51, P524, DOI 10.1109/THMS.2021.3097973
   Wang ZM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P165, DOI [10.1109/ISMAR-Adjunct51615.2020.00052, 10.1109/BDEIM52318.2020.00045]
   Weier M, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204547
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zhimin Wang, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P548, DOI 10.1109/VRW55335.2022.00125
   Zhou HY, 2021, GRAPH MODELS, V116, DOI 10.1016/j.gmod.2021.101109
NR 71
TC 11
Z9 12
U1 1
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3843
EP 3853
DI 10.1109/TVCG.2022.3203110
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200027
PM 36049007
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Deng, NC
   He, ZY
   Ye, JN
   Duinkharjav, B
   Chakravarthula, P
   Yang, XB
   Sun, Q
AF Deng, Nianchen
   He, Zhenyi
   Ye, Jiannan
   Duinkharjav, Budmonde
   Chakravarthula, Praneeth
   Yang, Xubo
   Sun, Qi
TI FoV-NeRF: Foveated Neural Radiance Fields for Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Virtual Reality; Gaze-Contingent Graphics; Neural Representation;
   Foveated Rendering
AB Virtual Reality (VR) is becoming ubiquitous with the rise of consumer displays and commercial VR platforms. Such displays require low latency and high quality rendering of synthetic imagery with reduced compute overheads. Recent advances in neural rendering showed promise of unlocking new possibilities in 3D computer graphics via image-based representations of virtual or physical environments. Specifically, the neural radiance fields (NeRF) demonstrated that photo-realistic quality and continuous view changes of 3D scenes can be achieved without loss of view-dependent effects. While NeRF can significantly benefit rendering for VR applications, it faces unique challenges posed by high field-of-view, high resolution, and stereoscopic/egocentric viewing, typically causing low quality and high latency of the rendered images. In VR, this not only harms the interaction experience but may also cause sickness. To tackle these problems toward six-degrees-of-freedom, egocentric, and stereo NeRF in VR, we present the first gaze-contingent 3D neural representation and view synthesis method. We incorporate the human psychophysics of visual- and stereo-acuity into an egocentric neural representation of 3D scenery. We then jointly optimize the latency/performance and visual quality while mutually bridging human perception and neural scene synthesis to achieve perceptually high-quality immersive interaction. We conducted both objective analysis and subjective studies to evaluate the effectiveness of our approach. We find that our method significantly reduces latency (up to 99% time reduction compared with NeRF) without loss of high-fidelity rendering (perceptually identical to full-resolution ground truth). The presented approach may serve as the first step toward future VR/AR systems that capture, teleport, and visualize remote environments in real-time.
C1 [Deng, Nianchen; Ye, Jiannan; Yang, Xubo] Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.
   [He, Zhenyi] NYU, Dept Comp Sci, New York, NY 10003 USA.
   [Duinkharjav, Budmonde] NYU, Immers Comp Lab, New York, NY 10003 USA.
   [Chakravarthula, Praneeth] Univ N Carolina, Comp Sci, Chapel Hill, NC USA.
   [Yang, Xubo] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Sun, Qi] NYU, Tandon Sch Engn, New York, NY 10003 USA.
C3 Shanghai Jiao Tong University; New York University; New York University;
   University of North Carolina; University of North Carolina Chapel Hill;
   Peng Cheng Laboratory; New York University; New York University Tandon
   School of Engineering
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Software, Shanghai, Peoples R China.; Yang, XB (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.; Sun, Q (corresponding author), NYU, Tandon Sch Engn, New York, NY 10003 USA.
EM dengnianchen@sjtu.edu.cn; zh719@nyu.edu; wsyhdyjn@sjtu.edu.cn;
   budmonde@gnail.com; cpk@cs.unc.edu; yangxubo@sjtu.edu.cn; qisun@nyu.edu
RI Deng, Nianchen/GXZ-4749-2022; He, Zhenyi/IXD-6881-2023; Chakravarthula,
   Praneeth Kumar/AFZ-2211-2022
OI Chakravarthula, Praneeth Kumar/0000-0002-3092-7435; Deng,
   Nianchen/0000-0002-5292-266X
FU National Key Research and Development Program of China [2018YFB1004902]
FX This work was partially supported by the National Key Research and
   Development Program of China (2018YFB1004902).
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Attal Benjamin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P441, DOI 10.1007/978-3-030-58452-8_26
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Barron J.T., 2022, CVPR
   Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   CAMPBELL FW, 1960, J PHYSIOL-LONDON, V151, P285, DOI 10.1113/jphysiol.1960.sp006438
   CHABRA ROHAN, 2020, COMPUTER VISION ECCV, P608
   Chakravarthula P, 2021, IEEE T VIS COMPUT GR, V27, P4194, DOI 10.1109/TVCG.2021.3106433
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P2157, DOI 10.1109/TVCG.2022.3150522
   Choi I, 2019, IEEE I CONF COMP VIS, P7780, DOI 10.1109/ICCV.2019.00787
   Freeman J, 2011, NAT NEUROSCI, V14, P1195, DOI 10.1038/nn.2889
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Gropp A., ARXIV
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Kai-En Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P328, DOI 10.1007/978-3-030-58601-0_20
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li QB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417785
   Lin C, 2020, ARXIV
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu L, 2021, POSTGRAD MED, V133, P265, DOI 10.1080/00325481.2020.1803666
   Lu C, 2020, INT SYM MIX AUGMENT, P320, DOI 10.1109/ISMAR50242.2020.00058
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Mengtian Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P473, DOI 10.1007/978-3-030-58536-5_28
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mochizuki H., 2012, KITASATO MED J, V42, P1
   Niemeyer M, 2019, IEEE I CONF COMP VIS, P5378, DOI 10.1109/ICCV.2019.00548
   Oechsle M, 2019, IEEE I CONF COMP VIS, P4530, DOI 10.1109/ICCV.2019.00463
   Park E, 2017, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2017.82
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pozo AP, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356555
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Serrano A., 2019, IEEE T VIS COMPUT GR
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Sitzmann V., 2020, Proc. NeurIPS
   Sitzmann V., 2020, arXiv
   Sitzmann V, 2019, ADV NEUR IN, V32
   Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254
   Sun Q, 2020, OPT EXPRESS, V28, P6734, DOI 10.1364/OE.28.006734
   Sun Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130807
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P293, DOI 10.1007/978-3-030-58517-4_18
   Tursun OT, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322985
   Walton DR, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459943
   Watson AB, 2014, J VISION, V14, DOI 10.1167/14.7.15
   Winkler T, 2010, COMPUT GRAPH FORUM, V29, P309, DOI 10.1111/j.1467-8659.2009.01600.x
   Wizadwongsa Suttisak, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P8530, DOI 10.1109/CVPR46437.2021.00843
   Yariv Lior, 2020, Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance, P2
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3381866
NR 58
TC 38
Z9 41
U1 4
U2 37
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3854
EP 3864
DI 10.1109/TVCG.2022.3203102
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200028
PM 36044494
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Fereydooni, N
   Tenenboim, E
   Walker, BN
   Peeta, S
AF Fereydooni, Nadia
   Tenenboim, Einat
   Walker, Bruce N.
   Peeta, Srinivas
TI Incorporating Situation Awareness Cues in Virtual Reality for Users in
   Dynamic in-Vehicle Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Virtual Reality; Situation Awareness; Perceived Risk; Fully Automated
   Vehicles
ID RISK; PERFORMANCE; ENGAGEMENT; COMMUTERS; AGE
AB The increasing ubiquity and mobility of virtual reality (VR) devices has introduced novel use cases, one of which is using VR in vehicles, both human-driven and fully automated. However, the effects of the adoption of VR-in-the-car on user task performance, safety, trust, and perceived risk are still largely unknown or not fully understood. Blocking out the physical world and substituting it with a virtual environment has many potential benefits including fewer distractions and greater productivity. However, one shortcoming of this seclusion is losing situation awareness which becomes critical in dynamic, in-vehicle environments, even when the user is not in the driver's seat. Hence, this study aims to understand the effects of providing VR users with situation awareness cues about the real world, when riding in a human-driven or a fully automated car. The results of this driving simulator experiment provide valuable insights into passengers' experience and their information needs while immersed in VR environments. Identifying passengers' unique challenges and needs, as well as developing solutions for them, is expected to improve users' travel experience towards a wider adoption of VR devices.
C1 [Fereydooni, Nadia] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
   [Tenenboim, Einat; Peeta, Srinivas] Georgia Inst Technol, Sch Civil & Environm Engn, Atlanta, GA 30332 USA.
   [Walker, Bruce N.] Georgia Inst Technol, Dept Psychol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology;
   University System of Georgia; Georgia Institute of Technology;
   University System of Georgia; Georgia Institute of Technology
RP Fereydooni, N (corresponding author), Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
EM nadia.fereydooni@gatech.edu; einat.tenenboim@gatech.edu;
   bruce.walker@psych.gatech.edu; peeta@gatech.edu
CR Anthes C., 2016, State of the Art of Virtual Reality Technologies", DOI [DOI 10.1109/AERO.2016.7500674, 10.1109/AERO.2016.7500674]
   Arning K, 2009, LECT NOTES COMPUT SC, V5889, P20
   Bajorunaite L, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P432, DOI 10.1109/VRW52623.2021.00098
   Barathi SC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173982
   BASIL MD, 1994, COMMUN RES, V21, P177, DOI 10.1177/009365094021002003
   Burd Charlynn, 2021, American Community Survey Reports, United States Census Bureau, V2
   Burnett G.E., 2007, Proceedings of the Road Safety and Simulation Conference. Rom. S, P33
   C. Limited, 2015, CASTR VIRT RAC
   Card S.K., 2018, The Psychology of Human-Computer Interaction
   Carson B., IS WINNING WORLD IT
   Casterson S, 2016, HTC VIVE GUIDE BEGIN, V1
   Chatterjee K., 2017, COMMUTING WELLBEING
   Chen PP, 2003, IEEE FIFTH INTERNATIOANL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P120
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Christian ThomasJ., 2009, Opportunity costs surrounding exercise and dietary behaviors: Quantifying trade-offs between commuting time and health-related activities
   Davis S, 2015, P 11 AUSTR C INT ENT
   Durso F.T., 1998, Air Traffic Control Quarterly, V6, P1, DOI [10.2514/atcq.6.1.1, DOI 10.2514/ATCQ.6.1.1]
   Ekman F, 2018, IEEE T HUM-MACH SYST, V48, P95, DOI 10.1109/THMS.2017.2776209
   Endsley M. R., 1988, Proceedings of the IEEE 1988 National Aerospace and Electronics Conference: NAECON 1988 (Cat. No.88CH2596-5), P789, DOI 10.1109/NAECON.1988.195097
   engadget, RENAULTS CONCEPT EV
   Fereydooni N., 2020, Virtual reality as a remote workspace platform: Opportunities and challenges
   Fereydooni N., 2019, P 11 INT C AUTOMOTIV, P99, DOI [10.1145/3349263.3351502, DOI 10.1145/3349263.3351502]
   Fereydooni N, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489914
   Fereydooni N, 2021, EXTENDED ABSTRACTS OF 23RD INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447527.3474868
   Figueroa JCM, 2018, ADV INTELL SYST, V591, P366, DOI 10.1007/978-3-319-60591-3_33
   Fox-Glassman KT, 2016, J MATH PSYCHOL, V75, P157, DOI 10.1016/j.jmp.2016.05.003
   Frazier M., 2013, J TRUST RES, V3, P76, DOI DOI 10.1080/21515581.2013.820026
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gable T., 2013, Georgia Tech Simulator Sickness Screening Protocol
   Gardner B, 2007, TRANSPORT RES F-TRAF, V10, P187, DOI 10.1016/j.trf.2006.09.004
   George C, 2020, IEEE T VIS COMPUT GR, V26, P3414, DOI 10.1109/TVCG.2020.3023607
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Gugenheimer J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299028
   Haeling J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P757, DOI 10.1109/VR.2018.8446461
   Hakkila J., 2014, Adjunct Proceedings of the 6th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P1, DOI 10.1145/2667239.2667288
   HART S G, 1988, P139
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   He DB, 2019, TRANSPORT RES REC, V2673, P142, DOI 10.1177/0361198119843476
   Helldin T., 2013, P 5 INT C AUT US INT, P210, DOI [10.1145/2516540.2516554, DOI 10.1145/2516540.2516554]
   Hillmann C., 2019, Unreal for Mobile and Standalone VR, P141, DOI 10.1007/978-1-4842-4360-2_5
   Hock P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4034, DOI 10.1145/3025453.3025665
   Hu P., 2021, Transportation Statistics Annual Report 2021
   Kanamori K, 2019, 2019 12TH ASIA PACIFIC WORKSHOP ON MIXED AND AUGMENTED REALITY (APMAR), P15, DOI 10.1109/APMAR.2019.8709270
   Kang H, 2020, VISUAL COMPUT, V36, P2065, DOI 10.1007/s00371-020-01907-4
   Keenan RY, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3378576
   Kennedy RS, 2000, PRESENCE-TELEOP VIRT, V9, P463, DOI 10.1162/105474600566952
   Kodama R, 2017, IEEE SYMP 3D USER, P130, DOI 10.1109/3DUI.2017.7893329
   Kun AL, 2016, IEEE PERVAS COMPUT, V15, P32, DOI 10.1109/MPRV.2016.14
   Kunze A, 2019, AUTOMOTIVEUI'19: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P329, DOI 10.1145/3342197.3344537
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Li Jingyi, 2020, 12 INT C AUT US INT, P92, DOI [10.1145/3409251.3411732, DOI 10.1145/3409251.3411732]
   McGill M, 2020, VIRTUAL REAL-LONDON, V24, P583, DOI 10.1007/s10055-019-00420-x
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   McGill Mark, 2019, P 11 INT C AUT US IN, P434, DOI DOI 10.1145/3349263.3351330
   McGlynn Sean A., 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P1782, DOI 10.1177/1541931218621404
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Mestre DR, 2011, PRESENCE-VIRTUAL AUG, V20, P1, DOI 10.1162/pres_a_00031
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Oculus, OC GUARD SYST
   Paredes Pablo E., 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287062
   Perri J., UBER VS LYFT WHOS TO
   Perterer N, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971556
   Petersen L., 2019, SITUATIONAL AWARENES, P26, DOI [DOI 10.4271/12-02-02-0009, 10.2139/ssrn.3345543]
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Pudane B, 2019, TRANSPORT RES D-TR E, V71, P222, DOI 10.1016/j.trd.2018.11.014
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Ruijten Peter A. M., 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2040062
   Rungtai Lin, 1994, Design Studies, V15, P185, DOI 10.1016/0142-694X(94)90024-8
   Salem M., 2015, EM POL ETH HUM ROB I
   Schaefer K. E., 2014, MET FACT INFL DEV TR, DOI [10.1177/0018720816634228, DOI 10.1177/0018720816634228]
   Schartmüller C, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229459
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Simcock P, 2006, J MARKET MANAG-UK, V22, P355, DOI 10.1362/026725706776861163
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Singapore A., 2016, AUDI SINGAPORE PRESE
   Singleton PA, 2019, TRANSPORT REV, V39, P50, DOI 10.1080/01441647.2018.1470584
   Slovic P, 2004, RISK ANAL, V24, P311, DOI 10.1111/j.0272-4332.2004.00433.x
   Society of Automotive Engineers, 2018, J3016TM SAE
   Sousa M, 2019, Arxiv, DOI arXiv:1911.13032
   Stuck Rachel E., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1316, DOI 10.1177/1071181319631128
   Stuck R. E., 2020, THESIS GEORGIA I TEC
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Taylor R., 2017, Situational awareness, P111, DOI [10.4324/9781315087924-8/SITUATIONAL-AWARENESS-RATING-TECHNIQUE-SARTDEVELOPMENT-TOOL-AIRCREW-SYSTEMS-DESIGN-TAYLOR, DOI 10.4324/9781315087924-8/SITUATIONAL-AWARENESS-RATING-TECHNIQUE-SARTDEVELOPMENT-TOOL-AIRCREW-SYSTEMS-DESIGN-TAYLOR]
   Thomsen ASS, 2017, OPHTHALMOLOGY, V124, P524, DOI 10.1016/j.ophtha.2016.11.015
   Ubisoft, UB VR REN AUT CAR YO
   Vidulich M. A., 2012, Handbook of human factors and ergonomics, P243, DOI [10.1002/9781118131350.ch8, DOI 10.1002/0470048204.CH9]
   VR A., AIRPANO VR
   Wandtner B, 2018, TRANSPORT RES F-TRAF, V58, P253, DOI 10.1016/j.trf.2018.06.001
   WILDAVSKY A, 1990, DAEDALUS, V119, P41
   Wilson RS, 2019, RISK ANAL, V39, P777, DOI 10.1111/risa.13207
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
NR 94
TC 6
Z9 6
U1 4
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3865
EP 3873
DI 10.1109/TVCG.2022.3203086
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200029
PM 36048985
DA 2024-11-06
ER

PT J
AU Hirsch, L
   George, C
   Butz, A
AF Hirsch, Linda
   George, Ceenu
   Butz, Andreas
TI Traces in Virtual Environments: A Framework and Exploration to
   Conceptualize the Design of Social Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE traces; traces of use; asynchronous; social VE; framework; social
   presence
ID REALITY
AB Creating social Virtual Environments (VEs) is an ongoing challenge. Traces of prior human interactions, or traces of use, are used in Physical Environments (PEs) to create more meaningful relationships with the PE and the people within it. In this paper, we explore how the concept of traces of use can be transferred from PEs to VEs to increase known success factors for social VEs, such as increased social presence. First, we introduce a conceptualization and discussion (N = 4 expert interviews) of a "Traces in VEs" framework. Second, we evaluate the framework in two lab studies (N = 46 in total), exploring the effect of traces in (i) VE vs. PE, and (ii) on social presence. Our findings confirm that traces increase the feeling of social presence. However, their meaning may differ depending on the environment. Our framework offers a structured overview of relevant components and relationships that need to be considered when designing meaningful user experiences in VE using traces. Thus, our work is valuable for practitioners and researchers who systematically want to create social VEs.
C1 [Hirsch, Linda; Butz, Andreas] Ludwig Maximilians Univ Munchen, Munich, Germany.
   [George, Ceenu] Univ Augsburg, Augsburg, Germany.
C3 University of Munich; University of Augsburg
RP Hirsch, L (corresponding author), Ludwig Maximilians Univ Munchen, Munich, Germany.
EM linda.hirsch@ifi.lmu.de; ceenu.george@ifi.lmu.de; butz@ifi.lmu.de
RI Hirsch, Linda/KFA-8942-2024
OI George, Ceenu/0009-0002-8616-0234
CR Albarrak Luluah, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488537
   Alves S, 2014, EUR SPAT RES POLICY, V21, P13, DOI 10.1515/esrp-2015-0002
   [Anonymous], 2016, No Man's Sky
   [Anonymous], META METAVERSE
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Baxter WL, 2016, MATER DESIGN, V90, P1218, DOI 10.1016/j.matdes.2015.04.019
   Ben Shneiderman, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3419764
   Bleakley Anna, 2020, P 2 C CONV US INT BI, P1, DOI [10.1145/3405755.3406144, DOI 10.1145/3405755.3406144]
   Blizzard Entertainment, 2004, WORLD WARCR
   Bogner A, 2009, RES METHODS SER, P1, DOI 10.1057/9780230244276
   C. I. GmbH, 2021, COND
   Chow Kevin, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359142
   Clarke V., 2017, COLLECTING QUALITATI, P45, DOI [DOI 10.1017/9781107295094, 10.1017/9781107295094]
   Cunningham JM, 2015, ONLINE LEARN, V19, P34
   Dijk J., 2013, THESIS, DOI [10.6100/IR759609, DOI 10.6100/IR759609]
   Dong T., 2014, Proceedings of the 2014 Conference on Designing Interactive Systems (DIS'14), P63
   Dourish Paul, 2006, P ACM C COMP SUPP CO, P299, DOI DOI 10.1145/1180875.1180921
   Duan H., 2021, P 29 ACM INT C MULTI, P153, DOI DOI 10.1145/3474085.3479238
   Dupont L, 2014, LANDSCAPE RES, V39, P417, DOI 10.1080/01426397.2013.773966
   Egerer D., 2014, CHI SPARKS 2014 CREA
   Fink A., 2010, Survey Research Methods, V3rd, P152, DOI [DOI 10.1016/B978-0-08-044894-7.00296-7, 10.1016/B978-0-08-044894-7.00296-7]
   Games G., 2010, HORIZON ZERO DAWN
   George C, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'18), DOI 10.1145/3180308.3180355
   Giaccardi E, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2447, DOI 10.1145/2702123.2702337
   Giaccardi Elisa, 2014, P 2014 C DES INT SYS, P473
   Glisczinski D, 2018, J TRANSFORM EDUC, V16, P175, DOI 10.1177/1541344618777367
   Guimaraes M., 2020, IMPACT VIRTUAL REALI
   Gunawardena C. N., 1997, AM J DISTANCE EDUC, V11, P8, DOI [DOI 10.1080/08923649709526970, 10.1080/08923649709526970]
   Hai W, 2015, PROCEEDINGS OF THE 31ST INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2016), P7, DOI 10.1145/3205326.3205345
   Hirsch L., 2021, LNCS
   Hirsch L., 2022, Interactions, V29, P58, DOI [10.1145/3501358, DOI 10.1145/3501358]
   Hirsch L, 2021, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, TEI 2021, DOI 10.1145/3430524.3440625
   Hirsch L, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P729, DOI 10.1145/3374920.3375007
   Innocent T., 2007, P 4 AUSTRALASIAN C I
   Jarvela Simo, 2021, ACM Transactions on Social Computing, V4, DOI 10.1145/3449358
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   Kojima Productions, 2019, DEATH STRAND
   Kukkakorpi M, 2021, JOURNAL PRACT, V15, P785, DOI 10.1080/17512786.2020.1799237
   L. GmbH, 2006, LIM
   Laarni J., 2015, Immersed in Media: Telepresence Theory, Measurement Technology, P139, DOI [DOI 10.1007/978-3-319-10190-38, 10.1007/978-3-319- 10190- 3_8, DOI 10.1007/978-3-319-10190-3_8]
   Lee MH, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P251, DOI 10.1145/2901790.2901812
   Lee S, 2008, INTERACT COMPUT, V20, P491, DOI 10.1016/j.intcom.2008.07.003
   Luck M, 2000, APPL ARTIF INTELL, V14, P3, DOI 10.1080/088395100117142
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   Microsoft Inc, ALTSP
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mirumur, 2011, about us
   Mols I, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971494
   Monastero B., 2018, TRACES STUDYING PUBL, P1
   Morozov M., 2013, Transactions on Computational Science, P81
   Mozilki, MOZ HUBS
   Murray EG, 2016, PSYCHOL SPORT EXERC, V22, P328, DOI 10.1016/j.psychsport.2015.09.007
   Naz A, 2017, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2017.7892225
   Nuernberger B, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P129, DOI 10.1145/2993369.2993371
   Oculus, 2019, OC QUEST
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   P. C. LP, 2006, GOTR
   Patton Michael Q., 2002, QUALITATIVE EVALUATI
   Ramic-Brkic Belma, 2013, P 29 SPRING C COMP G, P91, DOI DOI 10.1145/2508244.2508256
   Robbins H, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971538
   Rogowitz B., 2021, TOUCHING ART METHOD
   Rosner DanielaK., 2013, Proc. SIGCHI Conf. Hum. Factors Comput. Syst. - CHI, V13, P1649, DOI DOI 10.1145/2470654.2466218
   Roth D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P215, DOI 10.1109/VR.2018.8447550
   Roth D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P357, DOI 10.1145/2993369.2996302
   Shih LF, 2005, CSCL 2005: Computer Supported Collaborative Learning 2005: The Next 10 Years, Proceedings, P602
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Steed A., 2015, Immersed in Media: Telepresence Theory, Measurement Technology, P263, DOI DOI 10.1007/978-3-319-10190-3{_}11
   Steed Anthony., 2003, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, P51
   Teo T, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365687
   Tsai WC, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P889, DOI 10.1145/3064663.3064791
   Tsai WC, 2018, INT J DES, V12, P57
   Wagener N., 2021, REFLECTING EMOTIONS, P256
   Wu P, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927933
   Wu P, 2016, PROCEDIA ENGINEER, V159, P108, DOI 10.1016/j.proeng.2016.08.132
   Yassien A., 2020, DESIGN SPACE SOCIAL
NR 78
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3874
EP 3884
DI 10.1109/TVCG.2022.3203092
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200030
PM 36048991
DA 2024-11-06
ER

PT J
AU Williams, AS
   Ortega, FR
AF Williams, Adam S.
   Ortega, Francisco R.
TI The Impacts of Referent Display on Gesture and Speech Elicitation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Human computer interaction (HCI); User studies; Mixed / augmented
   reality; Gestural input; Elicitation
ID IMITATION
AB Elicitation studies have become a popular method of participatory design. While traditionally used to examine unimodal gesture interactions, elicitation has started being used with other novel interaction modalities. Unfortunately, there has been no work that examines the impact of referent display on elicited interaction proposals. To address that concern this work provides a detailed comparison between two elicitation studies that were similar in design apart from the way that participants were prompted for interaction proposals (i.e., the referents). Based on this comparison the impact of referent display on speech and gesture interaction proposals are each discussed. The interaction proposals between these elicitation studies were not identical. Gesture proposals were the least impacted by referent display, showing high proposal similarity between the two works. Speech proposals were highly biased by text referents with proposals directly mirroring text-based referents an average of 69.36% of the time. In short, the way that referents are presented during elicitation studies can impact the resulting interaction proposals; however, the level of impact found is dependent on the modality of input elicited.
C1 [Williams, Adam S.; Ortega, Francisco R.] Colorado State Univ, Comp Sci Dept, Ft Collins, CO 80523 USA.
C3 Colorado State University
RP Williams, AS (corresponding author), Colorado State Univ, Comp Sci Dept, Ft Collins, CO 80523 USA.
EM AdamWil@colostate.edu; F.Ortega@colostate.edu
FU National Science Foundation (NSF) [IIS-1948254, IIS-2037417,
   CNS-2016714, CNS-2106590, BCS-1928502]; Defense Advanced Research
   Projects Agency (DARPA) ARO [W911NF-15-10459]
FX This work was supported by the National Science Foundation (NSF) awards
   IIS-1948254, IIS-2037417, CNS-2016714, CNS-2106590, and BCS-1928502.
   This work was also supported by the Defense Advanced Research Projects
   Agency (DARPA) ARO contract W911NF-15-10459.
CR Altakrouri B, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971502
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 2013, P 2013 ACM INT C INT, DOI [10.1145/2512349.2512825, DOI 10.1145/2512349.2512825]
   Bowman D., 2004, 3D USER INTERFACES T
   Brass M, 2005, TRENDS COGN SCI, V9, P489, DOI 10.1016/j.tics.2005.08.007
   Cafaro F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174167
   Chan E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3403, DOI 10.1145/2858036.2858589
   Chen Z, 2018, INT J HUM-COMPUT INT, V34, P238, DOI 10.1080/10447318.2017.1342943
   Cohen Phil., 2008, P 10 INT C MULTIMODA, P137
   Connell S., 2013, P ACM C INTERACTION, P277, DOI DOI 10.1145/2485760.2485823
   Corradini A, 2005, TEXT SPEECH LANG TEC, V30, P97
   Costagliola G, 2018, J VISUAL LANG COMPUT, V47, P1, DOI 10.1016/j.jvlc.2018.04.002
   Cracco E, 2018, PSYCHOL BULL, V144, P453, DOI 10.1037/bul0000143
   Dim NK, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P204, DOI 10.1145/2901790.2901834
   Felberbaum Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173908
   Gowen E, 2016, COGNITION, V146, P431, DOI 10.1016/j.cognition.2015.10.010
   Hansen W. J., 1971, AFIP Conference proceedings, Vol.39 1971 fall joint computer conference, P523
   HART S G, 1988, P139
   Hinckley Ken, 2010, P 23 ANN ACM S US IN, P27, DOI [DOI 10.1145/1866029.1866036, DOI 10.1145/1866029.18660362]
   Hoff L, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P86, DOI 10.1145/2839462.2839472
   Huang YJ, 2017, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2017.8031577
   Khan S, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102847
   Kopsel Anne, 2015, ACM Interactions, V22, P44, DOI 10.1145/2803169
   Koutsabasis Panayiotis., 2016, P INT WORKING C ADV, P21, DOI [DOI 10.1145/2909132.2909248, 10.1145/2909132.2909248]
   Kuhl PK, 1996, J ACOUST SOC AM, V100, P2425, DOI 10.1121/1.417951
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Lee Lina., 2014, P HCI KOREA HCIK 15, P63
   Lee Minkyung, 2008, P 10 INT C MULT 08, P249, DOI [DOI 10.1145/1452392.1452444, 10.1145/1452392.1452444]
   Liepelt R, 2010, EXP PSYCHOL, V57, P221, DOI 10.1027/1618-3169/a000028
   May KR, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P74, DOI 10.1145/3122986.3123015
   MELTZOFF AN, 1989, DEV PSYCHOL, V25, P954, DOI 10.1037/0012-1649.25.6.954
   Micire M., 2009, P 900 INT C INTERACT, P41, DOI DOI 10.1145/1731903.1731912
   Moors A, 2006, PSYCHOL BULL, V132, P297, DOI 10.1037/0033-2909.132.2.297
   Morris Meredith Ringel, 2012, P 2012 ACM INT C INT, P95, DOI DOI 10.1145/2396636.2396651
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI DOI 10.1145/2591689
   Nebeling Michael, 2014, P 9 ACM INT C INT TA, P15, DOI [DOI 10.1145/2669485.2669497, 10.1145/2669485.2669497]
   Ortega FR, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1723, DOI 10.1109/VR.2019.8798105
   Ortega FR, 2017, IEEE SYMP 3D USER, P144, DOI 10.1109/3DUI.2017.7893331
   Ortega FranciscoR., 2016, INTERACTION DESIGN 3
   Oviatt Sharon, 2004, P 6 INT C MULT INT, P129, DOI DOI 10.1145/1027933.1027957
   Pham T, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P227, DOI 10.1145/3196709.3196719
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Plank T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4548, DOI 10.1145/3025453.3025537
   Rovelo G, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4077, DOI 10.1145/2556288.2557113
   Ruiz J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3347, DOI 10.1145/2702123.2702583
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Silpasuwanchai C, 2015, INT J HUM-COMPUT ST, V80, P1, DOI 10.1016/j.ijhcs.2015.02.010
   Sukumar PT, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P97, DOI 10.1145/3279778.3279793
   Tarre K, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281590
   Tsandilas T, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3182168
   Vatavu RD, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3476101
   Vatavu RD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300454
   Vatavu RD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1325, DOI 10.1145/2702123.2702223
   Vatavu Radu-Daniel., 2013, EUROITV 13 PAGE, P143, DOI DOI 10.1145/2465958.2465972
   Villarreal-Narvaez Santiago., 2020, P ACM INT C DESIGNIN
   Vogiatzidakis Panagiotis, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2040065
   Welbourn L.K., 1988, P 4 C BRIT COMPUTER, P363
   Williams Adam S., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427330
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Wittorf ML, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971503
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wobbrock Jacob O, 2005, Maximizing the guessability of symbolic input
   WOLF CG, 1987, INT J MAN MACH STUD, V27, P91, DOI 10.1016/S0020-7373(87)80045-7
   Zaiti IA, 2015, PERS UBIQUIT COMPUT, V19, P821, DOI 10.1007/s00779-015-0863-y
NR 65
TC 4
Z9 4
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3885
EP 3895
DI 10.1109/TVCG.2022.3203090
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200031
PM 36049005
DA 2024-11-06
ER

PT J
AU Li, Y
   Tahmid, IA
   Lu, FY
   Bowman, DA
AF Li, Yuan
   Tahmid, Ibrahim A.
   Lu, Feiyu
   Bowman, Doug A.
TI Evaluation of Pointing Ray Techniques for Distant Object Referencing in
   Model-Free Outdoor Collaborative Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Augmented Reality; Collaboration; Ray Visualization; Model-Free; Outdoor
ID MIXED REALITY
AB Referencing objects of interest is a common requirement in many collaborative tasks. Nonetheless, accurate object referencing at a distance can be challenging due to the reduced visibility of the objects or the collaborator and limited communication medium. Augmented Reality (AR) may help address the issues by providing virtual pointing rays to the target of common interest. However, such pointing ray techniques can face critical limitations in large outdoor spaces, especially when the environment model is unavailable. In this work, we evaluated two pointing ray techniques for distant object referencing in model-free AR from the literature: the Double Ray technique enhancing visual matching between rays and targets, and the Parallel Bars technique providing artificial orientation cues. Our experiment in outdoor AR involving participants as pointers and observers partially replicated results from a previous study that only evaluated observers in simulated AR. We found that while the effectiveness of the Double Ray technique is reduced with the additional workload for the pointer and human pointing errors, it is still beneficial for distant object referencing.
C1 [Li, Yuan; Tahmid, Ibrahim A.; Lu, Feiyu; Bowman, Doug A.] Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
   [Li, Yuan; Tahmid, Ibrahim A.; Lu, Feiyu; Bowman, Doug A.] Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University; Virginia Polytechnic
   Institute & State University
RP Li, Y (corresponding author), Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.; Li, Y (corresponding author), Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
EM y1i92@vt.edu; iatahmid@vt.edu; feiyulu@vt.edu; dbowman@vt.edu
RI Li, Yuan/GZG-6876-2022
CR Argelaguet F, 2011, INT J HUM-COMPUT ST, V69, P387, DOI 10.1016/j.ijhcs.2011.01.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Baldwin D., 1995, JOINT ATTENTION ITS, P131
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Chastine J., 2008, Proceedings of graphics interface, P275
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen L, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3485297
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Davis J, 2002, DISPLAYS, V23, P205, DOI 10.1016/S0141-9382(02)00039-2
   DIX A, 1994, COMP SUPPORT COMP W, P9
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Erickson A, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418445
   Erickson A, 2020, IEEE T VIS COMPUT GR, V26, P1934, DOI 10.1109/TVCG.2020.2973054
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   GORDON B, 2022, KEEPING IT REAL POTE, V1, DOI DOI 10.25401/CARDIFFMET.19011608.V1
   Gutkowski N, 2021, INT SYM MIX AUGMENT, P26, DOI 10.1109/ISMAR-Adjunct54149.2021.00016
   HART S G, 1988, P139
   Huo K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P19, DOI 10.1145/3242587.3242595
   Joe H, 2008, COMPUT STAT DATA AN, V52, P5066, DOI 10.1016/j.csda.2008.05.002
   Jordan P.W., 1996, Usability Evaluation in Industry
   JOTA R., 2009, A comparison of ray pointing techniques for very large displays
   Kim S, 2020, IEEE ACCESS, V8, P224145, DOI 10.1109/ACCESS.2020.3043783
   KJELLDAHL L, 1995, COMPUT GRAPH, V19, P199, DOI 10.1016/0097-8493(94)00143-M
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Lages WS, 2019, INT SYM MIX AUGMENT, P301, DOI 10.1109/ISMAR.2019.00028
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Li Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.681585
   Li Y, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357583
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   Maglia D., 2021, BEST LUX METER APP I
   MCGILL M, 2020, P C HUM FACT COMP SY, P1
   Merenda C, 2019, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2019.00-10
   Nakagawa S, 2013, METHODS ECOL EVOL, V4, P133, DOI 10.1111/j.2041-210x.2012.00261.x
   Neider MB, 2010, PSYCHON B REV, V17, P718, DOI 10.3758/PBR.17.5.718
   Oda O, 2012, INT SYM MIX AUGMENT, P207, DOI 10.1109/ISMAR.2012.6402558
   Oh JY, 2002, PROC GRAPH INTERF, P141
   Olsen D. R.  Jr., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P17, DOI 10.1145/365024.365030
   Parker J.K., 2005, Proc. GI, P33
   Pascoal R, 2018, IBER CONF INF SYST
   Rabbi I., 2013, ACTA GRAPH, V24, P29, DOI DOI 10.9790/0661-0222329
   Riege K, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P63
   Teather RJ, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P43
   Thomas B. H., 2002, Virtual Reality, V6, P167, DOI 10.1007/s100550200017
   Voida Stephen, 2005, P SIGCHI C HUM FACT, P611, DOI DOI 10.1145/1054972.1055056
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28
   Whittaker S, 2003, HUM-COMPUT INTERACT, V18, P149, DOI 10.1207/S15327051HCI1812_6
NR 50
TC 3
Z9 3
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3896
EP 3906
DI 10.1109/TVCG.2022.3203094
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200032
PM 36048980
DA 2024-11-06
ER

PT J
AU Kohm, K
   Babu, S
   Pagano, C
   Robb, A
AF Kohm, Kristopher
   Babu, Sabarish, V
   Pagano, Christopher
   Robb, Andrew
TI Objects May Be Farther Than They Appear: Depth Compression Diminishes
   Over Time with Repeated Calibration in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Distance estimation; calibration; perception; longitudinal; virtual
   reality
ID DISTANCE PERCEPTION; PERFORMANCE; RETENTION
AB Prior research in depth perception and perceptuo-motor calibration have primarily focused on participants completing experiments in single sessions and therefore do not empirically evaluate changes over time. Further, these studies do not typically take into account the amount of experience that the participants have in virtual reality (VR) prior to participation, the role of experience during participation, or calibration that may occur throughout the experiment session. In this contribution, we conducted a novel empirical evaluation of how calibration affects perception-action coordination over time. We recruited novice VR users and they completed eight sessions of a depth perception reaching experiment over the course of 12 weeks. During these experiments, we examined how participants' ability to estimate depth in a virtual environment changed as they gradually gained experience. While previous literature has shown that participants tend to underestimate distances, we found that this underestimation diminished over time as they gained experience in the virtual environment. Our study highlights the need for carrying out VR studies over time and the influence that longitudinal calibration can have on spatial perception in long-term VR experiences.
C1 [Kohm, Kristopher; Babu, Sabarish, V; Pagano, Christopher; Robb, Andrew] Clemson Univ, Clemson, SC 29631 USA.
C3 Clemson University
RP Kohm, K (corresponding author), Clemson Univ, Clemson, SC 29631 USA.
EM kckohm@clemson.edu; cpagano@clemson.edu; arobb@clemson.edu
RI Kohm, Kristopher/KVY-1160-2024
OI Robb, Andrew/0000-0002-0398-5576
FU US National Science Foundation (CISE HCC) [1717937, 2007435]; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [2007435, 1717937] Funding Source: National Science Foundation
FX The authors would like to thank the participants of our longitudinal
   study for their time and effort. This work was supported in part by the
   US National Science Foundation (CISE HCC) under Grants #1717937 and
   #2007435.
CR Altenhoff BlissM., 2012, P ACM S APPL PERCEPT, P71, DOI DOI 10.1145/2338676.2338691
   [Anonymous], 2014, P 2 ACM S SPAT US IN
   [Anonymous], 2016, P 11 ICDVRAT
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bailenson JN, 2006, PRESENCE-TELEOP VIRT, V15, P699, DOI 10.1162/pres.15.6.699
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bingham GP, 1998, J EXP PSYCHOL HUMAN, V24, P145, DOI 10.1037/0096-1523.24.1.145
   Bingham GP, 1999, J EXP PSYCHOL HUMAN, V25, P1331
   Bingham GP, 2001, J EXP PSYCHOL HUMAN, V27, P1314, DOI 10.1037//0096-1523.27.6.1314
   Blau J. J, INTRO ECOLOGICAL PSY
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   BRING J, 1994, AM STAT, V48, P209, DOI 10.2307/2684719
   Buck L., FRONTIERS VIRTUAL RE, P157
   Cnaan A, 1997, STAT MED, V16, P2349, DOI 10.1002/(SICI)1097-0258(19971030)16:20<2349::AID-SIM667>3.0.CO;2-E
   Creem-Regehr SH, 2005, PERCEPTION, V34, P191, DOI 10.1068/p5144
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Mendes FAD, 2012, PHYSIOTHERAPY, V98, P217, DOI 10.1016/j.physio.2012.06.001
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Ebrahimi Elham, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P97, DOI 10.1109/3DUI.2015.7131732
   Ebrahimi E., 2014, P ACM S APPL PERC, P103
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Ebrahimi E, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2947617
   Freeman D, 2013, PSYCHOL MED, V43, P2673, DOI 10.1017/S003329171300038X
   Gagnon HC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P798, DOI 10.1109/VR50410.2021.00107
   Kelly Jonathan W., 2022, Frontiers in Virtual Reality, V3, P27
   Khojasteh N, 2021, FRONTIERS VIRTUAL RE, V2, P53, DOI DOI 10.3389/FRVIR.2021.643331
   Kim HJ, 2020, J MED INTERNET RES, V22, DOI 10.2196/23024
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Krueger Charlene, 2004, Biol Res Nurs, V6, P151, DOI 10.1177/1099800404267682
   Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13
   Leyrer M., 2011, P ACM SIGGRAPH S APP, P67, DOI [10.1145/2077451.20774642, DOI 10.1145/2077451.20774642, 10.1145/2077451.2077464]
   Lin WY, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P232, DOI 10.1109/VR51125.2022.00042
   Ludecke D., 2021, JOSS, V6, P60
   MAZUR JE, 1978, PSYCHOL BULL, V85, P1256, DOI 10.1037/0033-2909.85.6.1256
   Meteyard L, 2020, J MEM LANG, V112, DOI 10.1016/j.jml.2020.104092
   Moustafa F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281527
   Nakagawa S, 2017, J R SOC INTERFACE, V14, DOI 10.1098/rsif.2017.0213
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Nordahl R., 2019, PROC IEEE VR WORKSHO
   Phillips L, 2012, PRESENCE-VIRTUAL AUG, V21, P119, DOI 10.1162/PRES_a_00100
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Phillips Lane., 2009, P 6 S APPL PERCEPTIO, P11, DOI [10.1145/1620993.1620996, DOI 10.1145/1620993.1620996]
   Ping JM, 2020, J SOC INF DISPLAY, V28, P164, DOI 10.1002/jsid.840
   Porter J, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P277, DOI 10.1145/3311350.3347159
   Porter J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P405, DOI 10.1145/3242671.3242677
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Ricca A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI 10.1109/VR50410.2021.00031
   SATTERTHWAITE FE, 1946, BIOMETRICS BULL, V2, P110, DOI 10.2307/3002019
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Smith SJ, 2016, NURS EDUC PERSPECT, V37, P210, DOI 10.1097/01.NEP.0000000000000035
   Steinicke F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019631
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   Takala TM, 2016, INFORM EDUC, V15, P287, DOI 10.15388/infedu.2016.15
   TanyaHill Hanneke, 2021, 2021 7 INT C IMMERSI, P1
   Tarnanas I, 2013, JMIR SERIOUS GAMES, V1, P16, DOI 10.2196/games.2778
   Venkatesh V, 2002, PERS PSYCHOL, V55, P661, DOI 10.1111/j.1744-6570.2002.tb00125.x
   Voeten C.C., 2020, USING BUILDMER AUTOM
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Winkler-Schwartz A, 2016, J SURG EDUC, V73, P942, DOI 10.1016/j.jsurg.2016.04.013
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Zielasko D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P165, DOI 10.1109/VRW52623.2021.00038
NR 63
TC 4
Z9 4
U1 2
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3907
EP 3916
DI 10.1109/TVCG.2022.3203112
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200033
PM 36048992
DA 2024-11-06
ER

PT J
AU Luong, T
   Holz, C
AF Luong, Tiffany
   Holz, Christian
TI Characterizing Physiological Responses to Fear, Frustration, and Insight
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Virtual Reality; Affective Computing; Physiological Measures
ID ELEMENTS; EMOTION; BLINK
AB Physiological sensing often complements studies of human behavior in virtual reality (VR) to detect users' affective and cognitive states. Some psychological states, such as fear and frustration, can be particularly hard to differentiate from a physiological perspective as they are close in the arousal and valence emotional space. Moreover, it is largely unclear how users' physiological reactions are expressed in response to transient psychological states such as fear, frustration, and insight-especially since these are rich indicators for characterizing users' responses to dynamic systems but are hard to capture in highly interactive settings. We conducted a study (N = 24) to analyze participants' pulmonary, electrodermal, cardiac, and pupillary responses to moments of fear, frustration, and insight in immersive settings. Participants interacted in five VR environments, throughout which we measured their physiological reactions and analyzed the patterns we observed. We also measured subjective fear and frustration using questionnaires. We found differences between fear and frustration pupillary, respiratory, and electrodermal responses, as well as between the pupillary changes that followed fear in a horror game and those that followed fear in a vertigo experiment. We present the relationships between fear levels, frustration levels, and their physiological responses. To detect these affective events and states, we introduce user-independent binary classification models that achieved an average micro F1 score of 71% for detecting fear in a horror game, 75% for fear of vertigo, 76% for frustration, and 75% for insight, showing the promise for detecting these states from passive and objective signals.
C1 [Luong, Tiffany; Holz, Christian] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Luong, T (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
EM tiffany.luong@inf.ethz.ch; christian.holz@inf.ethz.ch
RI Holz, Christian/AAV-4925-2020
OI Holz, Christian/0000-0001-9655-9519
CR Babiker A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01921
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Bernal G, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P160, DOI 10.1145/3267242.3267268
   Blatz WE, 1925, J EXP PSYCHOL, V8, P109, DOI 10.1037/h0071039
   Boucsein W, 2012, ELECTRODERMAL ACTIVITY, SECOND EDITION, P1, DOI 10.1007/978-1-4614-1126-0
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Chao CJ, 2017, HUM FACTOR ERGON MAN, V27, P187, DOI 10.1002/hfm.20702
   Chen H., 2017, Exploring pupil dilation in emotional virtual reality environments
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Collins J, 2019, INT SYM MIX AUGMENT, P351, DOI 10.1109/ISMAR.2019.00033
   Danek AH, 2020, COGNITION, V205, DOI 10.1016/j.cognition.2020.104411
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Gao Y, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395138
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Gurusamy KS, 2009, COCHRANE DB SYST REV, DOI [10.1002/14651858.CD006575.pub2, 10.1002/14651858.CD006575.pub3]
   HART S G, 1988, P139
   HEDBERG AG, 1972, PROF PSYCHOL, V3, P389, DOI 10.1037/h0020743
   Heidrich David, 2020, HCI International 2020 - Late Breaking Papers. Virtual and Augmented Reality. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12428), P343, DOI 10.1007/978-3-030-59990-4_26
   Hershman R, 2018, BEHAV RES METHODS, V50, P107, DOI 10.3758/s13428-017-1008-1
   Hoddes E., 1972, Enzyklopadie der Schlafmedizin, V1184
   HODGES LF, 1995, COMPUTER, V28, P27, DOI 10.1109/2.391038
   Holz Christian, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3132024
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   KAPLAN CA, 1990, COGNITIVE PSYCHOL, V22, P374, DOI 10.1016/0010-0285(90)90008-R
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Keefe D.F., 2001, P S INT 3D GRAPH NEW, P85
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kolakowska A., 2015, Information Systems Development and Applications, P55
   Kounios J, 2009, CURR DIR PSYCHOL SCI, V18, P210, DOI 10.1111/j.1467-8721.2009.01638.x
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Lazar J, 2006, BEHAV INFORM TECHNOL, V25, P239, DOI 10.1080/01449290500196963
   Lin JHT, 2017, COMPUT HUM BEHAV, V72, P350, DOI 10.1016/j.chb.2017.02.057
   Luong T, 2020, INT SYM MIX AUGMENT, P425, DOI 10.1109/ISMAR50242.2020.00068
   Luong Tiffany, 2021, IEEE Transactions on Visualization and Computer Graphics
   Malbos E, 2012, PRESENCE-TELEOP VIRT, V21, P268, DOI 10.1162/PRES_a_00112
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Meier M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P519, DOI 10.1109/VR50410.2021.00076
   Moon P, 1944, J OPT SOC AM, V34, P319, DOI 10.1364/JOSA.34.000319
   Novak D, 2012, INTERACT COMPUT, V24, P154, DOI 10.1016/j.intcom.2012.04.003
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Paladines-Jaramillo Fernando, 2020, C INFORM COMMUNICATI, P377
   Pallavicini F, 2018, LECT NOTES COMPUT SC, V10908, P87, DOI 10.1007/978-3-319-92052-8_8
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   Parsons TD, 2012, IEEE T CONSUM ELECTR, V58, P197, DOI 10.1109/TCE.2012.6227413
   Portugal D, 2016, LECT NOTES COMPUT SC, V9755, P79, DOI 10.1007/978-3-319-39949-2_8
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Romat H, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P306, DOI 10.1109/VR50410.2021.00053
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Seinfeld S, 2016, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01969
   Selvidge PR, 2002, INT J IND ERGONOM, V29, P15, DOI 10.1016/S0169-8141(01)00045-2
   Siegle GJ, 2008, PSYCHOPHYSIOLOGY, V45, P679, DOI 10.1111/j.1469-8986.2008.00681.x
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M., 2003, PRES 2003 6 ANN INT, V157
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Sprugnoli G, 2017, INTELLIGENCE, V62, P99, DOI 10.1016/j.intell.2017.03.004
   Taylor B, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P517, DOI 10.1145/2750858.2805847
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wiederhold BK, 2002, CYBERPSYCHOL BEHAV, V5, P77, DOI 10.1089/109493102753685908
   WOLPE J, 1968, Conditional Reflex, V3, P234
NR 64
TC 3
Z9 3
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3917
EP 3927
DI 10.1109/TVCG.2022.3203113
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200034
PM 36048988
DA 2024-11-06
ER

PT J
AU Batmaz, AU
   Stuerzlinger, W
AF Batmaz, Anil Ufuk
   Stuerzlinger, Wolfgang
TI Effective Throughput Analysis of Different Task Execution Strategies for
   Mid-Air Fitts' Tasks in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Fitts' task; Virtual Reality; Effective Throughput; Speed-Accuracy
   Trade-off
ID MOTOR-PERFORMANCE; VERBAL FEEDBACK; LAW; INDIVIDUALS
AB Fitts' law and throughput based on effective measures are two mathematical models frequently used to analyze human motor performance in a standardized pointing task, e.g., to compare the performance of input and output devices. Even though pointing has been deeply studied in 2D, it is not well understood how different task execution strategies affect throughput in pointing in 3D virtual environments. In this work, we examine the effective throughput measure, claimed to be invariant to task execution strategies, in Virtual Reality (VR) systems with three such strategies, "as fast, as precise, and as fast and as precise as possible" for ray casting and virtual hand interaction, by re-analyzing data from a 3D pointing IS0 9241-411 study. Results show that effective throughput is not invariant for different task execution strategies in VR, which also matches a more recent 2D result. Normalized speed vs. accuracy curves also did not fit the data. We thus suggest that practitioners, developers, and researchers who use MacKenzie's effective throughput formulation should consider our findings when analyzing 3D user pointing performance in VR systems.
C1 [Batmaz, Anil Ufuk] Concordia Univ, Comp Sci Dept, Montreal, PQ, Canada.
   [Stuerzlinger, Wolfgang] Simon Fraser Univ, Sch Interact Arts & Amp Technol, Burnaby, BC, Canada.
C3 Concordia University - Canada; Simon Fraser University
RP Batmaz, AU (corresponding author), Concordia Univ, Comp Sci Dept, Montreal, PQ, Canada.
EM ufuk.batmaz@concordia.ca; w.s@sfu.ca
RI Batmaz, Anil Ufuk/ABE-7803-2021
OI Stuerzlinger, Wolfgang/0000-0002-7110-5024
CR ALMEIDA GL, 1994, PHYS THER, V74, P1000, DOI 10.1093/ptj/74.11.1000
   [Anonymous], 2012, ISO 9241-411:2012.
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argus CK, 2011, J STRENGTH COND RES, V25, P3282, DOI 10.1519/JSC.0b013e3182133b8c
   Batmaz Anil Ufuk, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382796
   Batmaz A. U., 2020, 26 S VIRTUAL REALITY
   Batmaz A. U, 2022, C HUMAN FACTORS COMP
   Batmaz A. U., 2020, Advances in Intelligent Systems and Computing, V1289, DOI [10.1007/978-3-030-63089-8_52, DOI 10.1007/978-3-030-63089-8_52, 10.1007/978-3-030-63089- 8_52]
   Batmaz AU, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P85, DOI 10.1109/VR50410.2021.00029
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Batmaz AU, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364249
   Batmaz AU, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312752
   Batmaz AU, 2019, PERCEPTION, V48, P21
   Batmaz Anil Ufuk, 2016, BMC Psychol, V4, P55
   Bowman D., 2001, USING PINCH GLOVES T
   Brickler D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419986
   Brown Michelle A., 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P13, DOI 10.1007/978-3-319-39516-6_2
   Cha Y, 2013, INT J IND ERGONOM, V43, P350, DOI 10.1016/j.ergon.2013.05.005
   Clark LD, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102413
   Didehkhorshid S. A. A, 2020, P GRAPHICS INTERFACE, P148, DOI [10.20380/GI2020.16, DOI 10.20380/GI2020.16]
   Doose-Grünefeld S, 2015, FRONT INTEGR NEUROSC, V9, DOI 10.3389/fnint.2015.00003
   Dresp-Langley B, 2018, INFORMATION, V9, DOI 10.3390/info9120316
   Ens B, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P107, DOI 10.1145/2983310.2985756
   Faniel IM, 2010, COMPUT SUPP COOP W J, V19, P355, DOI 10.1007/s10606-010-9117-8
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Gentili R, 2006, NEUROSCIENCE, V137, P761, DOI 10.1016/j.neuroscience.2005.10.013
   George D., 2003, Using SPSS for Windows Step by Step: A Simple Guide and Reference, P1
   Gori J, 2020, BIOL CYBERN, V114, P621, DOI 10.1007/s00422-020-00853-7
   Gori J, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3231595
   Gori J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173770
   Guiard Y, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1619
   Hair J.F., 1998, Multivariate data analysis, V5th ed.
   Hartswood M., 2012, P SIGCHI C HUMAN FAC, P909
   Hazell T, 2007, J AGING PHYS ACTIV, V15, P349, DOI 10.1123/japa.15.3.349
   Heise KF, 2014, FRONT AGING NEUROSCI, V6, DOI 10.3389/fnagi.2014.00146
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Kantowitz B., 1983, HUMAN FACTORS UNDERS
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kropotov JD, 2011, NEUROIMAGE, V57, P565, DOI 10.1016/j.neuroimage.2011.04.060
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Liu CN, 2007, PERCEPT MOTOR SKILL, V105, P959, DOI 10.2466/PMS.105.3.959-967
   Machuca MDB, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188540
   Machuca MDB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300437
   MACKENZIE CL, 1987, Q J EXP PSYCHOL-A, V39, P629, DOI 10.1080/14640748708401806
   Mackenzie I. S., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P336, DOI 10.1145/274644.274691
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   MacKenzie IS, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1633
   MacKenzie I. Scott, 2015, INT C HUM COMP INT, P238
   MACKENZIE IS, 1989, J MOTOR BEHAV, V21, P323
   MEEHL PE, 1967, PHILOS SCI, V34, P103, DOI 10.1086/288135
   Murata A, 2001, HUM MOVEMENT SCI, V20, P791, DOI 10.1016/S0167-9457(01)00058-6
   Mutasim AK, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382924
   Oh JY, 2002, PROC GRAPH INTERF, P141
   Olafsdottir Halla B., 2012, P 26 ANN BCS INTERAC, P119
   Pfeiffer Max, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P117, DOI 10.1109/3DUI.2015.7131735
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364264
   Pham H. P., RO MAN 2009 18 IEEE, P1099
   Popovic MD, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/520374
   Porte MC, 2007, AM J SURG, V193, P105, DOI 10.1016/j.amjsurg.2006.03.016
   Prytz Erik., 2012, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V56, P1391, DOI [10.1177/1071181312561396, DOI 10.1177/1071181312561396]
   Puddefoot T, 1997, PHYSIOTHERAPY, V83, P76, DOI [10.1016/S0031-9406(05)65581-2, DOI 10.1016/S0031-9406(05)65581-2]
   Ramcharitar Adrian., 2018, Proceedings of the 44th Graphics Interface Conference, P123
   Rozand V, 2015, NEUROSCIENCE, V297, P219, DOI 10.1016/j.neuroscience.2015.03.066
   Ruffino C, 2019, EXP BRAIN RES, V237, P1375, DOI 10.1007/s00221-019-05514-1
   Sasangohar F., 2009, P HUMAN FACTORS ERGO, V53, P839, DOI [DOI 10.1177/154193120905301216, 10.1177/154193120905301216]
   Shelton J. N., 2014, IFAC P, V47, P7208
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Sprague DW, 2006, PROC GRAPH INTERF, P131
   Steed A., 2020, Interaction, V27, P62, DOI [DOI 10.1145/3406098, 10.1145/3406098]
   Stoelen MF, 2010, HUM FACTORS, V52, P63, DOI 10.1177/0018720810366560
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Teather R.J., 2014, CHI'14 Extended Abstracts on Human Factors in Computing Systems, P519, DOI [10.1145/2559206, DOI 10.1145/2559206]
   Teather R.J., 2014, Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P127, DOI [DOI 10.1145/2659766, DOI 10.1145/2659766.2659770]
   Teather RJ, 2010, P IEEE VIRT REAL ANN, P307, DOI 10.1109/VR.2010.5444753
   Teather RJ, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P43, DOI 10.1109/3DUI.2009.4811204
   van Zon NCM, 2020, HUM FACTORS, V62, P897, DOI 10.1177/0018720819862146
   Wallis JC, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067332
   Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1639
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Zhai SM, 2004, INT J HUM-COMPUT ST, V61, P823, DOI 10.1016/j.ijhcs.2004.09.007
NR 82
TC 10
Z9 10
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3939
EP 3947
DI 10.1109/TVCG.2022.3203105
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200036
PM 36044498
DA 2024-11-06
ER

PT J
AU Chaudhary, AK
   Nair, N
   Bailey, RJ
   Pelz, JB
   Talathi, SS
   Diaz, GJ
AF Chaudhary, Aayush K.
   Nair, Nitinraj
   Bailey, Reynold J.
   Pelz, Jeff B.
   Talathi, Sachin S.
   Diaz, Gabriel J.
TI <i>Temporal RIT-Eyes</i>: From real infrared eye-images to synthetic
   sequences of gaze behavior
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE
DE Eye-tracking; image segmentation; synthetic dataset; temporal dataset;
   eye rendering; renderings for ML; AR/VR
AB Current methods for segmenting eye imagery into skin, sclera, pupil, and iris cannot leverage information about eye motion. This is because the datasets on which models are trained are limited to temporally non-contiguous frames. We present Temporal RIT-Eyes, a Blender pipeline that draws data from real eye videos for the rendering of synthetic imagery depicting natural gaze dynamics. These sequences are accompanied by ground-truth segmentation maps that may be used for training image-segmentation networks. Temporal RIT-Eyes relies on a novel method for the extraction of 3D eyelid pose (top and bottom apex of eyelids/eyeball boundary) from raw eye images for the rendering of gaze-dependent eyelid pose and blink behavior. The pipeline is parameterized to vary in appearance, eye/head/camera/illuminant geometry, and environment settings (indoor/outdoor). We present two open-source datasets of synthetic eye imagery: sGiW is a set of synthetic-image sequences whose dynamics are modeled on those of the Gaze in Wild dataset. and sOpenEDS2 is a series of temporally non-contiguous eye images that approximate the OpenEDS-2019 dataset. We also analyze and demonstrate the quality of the rendered dataset qualitatively and show significant overlap between latent-space representations of the source and the rendered datasets.
C1 [Chaudhary, Aayush K.; Nair, Nitinraj; Bailey, Reynold J.; Pelz, Jeff B.; Diaz, Gabriel J.] Rochester Inst Technol, Rochester, NY 14623 USA.
   [Talathi, Sachin S.] Real Res Labs, Menlo Pk, CA USA.
C3 Rochester Institute of Technology
RP Chaudhary, AK (corresponding author), Rochester Inst Technol, Rochester, NY 14623 USA.
EM akc5959@rit.edu; nrn2741@rit.edu; rjb@cs.rit.edu; pelz@cis.rit.edu;
   stalathi@fb.com; gabriel.diaz@rit.edu
RI Pelz, Jeff/A-8272-2009
OI Talathi, Sachin/0009-0004-4614-8534
FU Reality Research Labs (Meta)
FX The authors would like to acknowledge Artem Romanenko, Kade Kelsch,
   Chengyi Ma, Jackson Shuminski for helping with renderings in different
   phases of the project. The authors would also like to thank RC Research
   Computing [34]. The project was funded by Reality Research Labs (Meta).
CR [Anonymous], 2021, EYELASH EXTENSION CH
   B.O. Community, 2018, Blender - a 3D Modelling and Rendering Package
   Chaudhary AK, 2019, IEEE INT CONF COMP V, P3698, DOI 10.1109/ICCVW.2019.00568
   Chaudhary AK, 2019, J EYE MOVEMENT RES, V12, DOI 10.16910/jemr.12.6.4
   Chaudhuri A, 2023, ANN OPER RES, V327, P401, DOI 10.1007/s10479-021-04307-6
   Deng YB, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P870, DOI 10.1145/3240508.3240531
   Einhäuser W, 2007, NETWORK-COMP NEURAL, V18, P267, DOI 10.1080/09548980701671094
   Fuhl W, 2021, Arxiv, DOI arXiv:2102.02115
   Fuhl W, 2016, Arxiv, DOI [arXiv:1601.04902, 10.48550/arXiv.1601.04902, DOI 10.48550/ARXIV.1601.04902]
   Fuhl W, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P123, DOI 10.1145/2857491.2857505
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Hayhoe M, 2014, CURR BIOL, V24, pR622, DOI 10.1016/j.cub.2014.05.020
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZX, 2019, IEEE INT CONF MOB DA, P226, DOI 10.1109/MDM.2019.00-53
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Garbin SJ, 2019, Arxiv, DOI arXiv:1905.03702
   Jiang W, 2019, Arxiv, DOI arXiv:1903.01716
   Jin XJ, 2017, IEEE I CONF COMP VIS, P5581, DOI 10.1109/ICCV.2017.595
   Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695
   Kim J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300780
   Ko HK, 2010, NAT NEUROSCI, V13, P1549, DOI 10.1038/nn.2663
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Kothari R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59251-5
   Kothari RS, 2021, IEEE T VIS COMPUT GR, V27, P2757, DOI 10.1109/TVCG.2021.3067765
   Mathis A, 2018, NAT NEUROSCI, V21, P1281, DOI 10.1038/s41593-018-0209-y
   Matthis JS, 2018, CURR BIOL, V28, P1224, DOI 10.1016/j.cub.2018.03.008
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nair N, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407935
   Neggers SFW, 2001, J NEUROPHYSIOL, V86, P961, DOI 10.1152/jn.2001.86.2.961
   Palmero C., 2020, ARXIV
   Palmero C, 2020, Arxiv, DOI arXiv:2005.11670
   Read SA, 2007, CLIN EXP OPTOM, V90, P5, DOI 10.1111/J.1444-0938.2007.00112.x
   Rochester Institute of Technology, 2019, RES COMP SERV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakurada M., 2014, P MLSDA 2014 2 WORKS, P4, DOI DOI 10.1145/2689746.2689747
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Swirski L., 2013, PROC PETMEI, P1
   swirski L., 2015, GAZE ESTIMATION GLAS
   Tonsen M, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P139, DOI 10.1145/2857491.2857520
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wood E, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P131, DOI 10.1145/2857491.2857492
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Wu ZY, 2019, IEEE INT CONF COMP V, P3683, DOI 10.1109/ICCVW.2019.00455
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
NR 45
TC 3
Z9 3
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3948
EP 3958
DI 10.1109/TVCG.2022.3203100
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200037
PM 36044495
DA 2024-11-06
ER

PT J
AU Zhu, LF
   Jiang, XD
   Shen, JW
   Zhang, H
   Mo, YT
   Song, AG
AF Zhu, Lifeng
   Jiang, Xudong
   Shen, Jiangwei
   Zhang, Heng
   Mo, Yiting
   Song, Aiguo
TI TapeTouch: A Handheld Shape-changing Device for Haptic Display of Soft
   Objects
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 21st IEEE International Symposium on Mixed and Augmented Reality (ISMAR)
CY OCT 17-22, 2022
CL Singapore, SINGAPORE
SP IEEE, IEEE Comp Soc, IEEE VGTC, ACM SIGGRAPH, Zoom, Qualcomm, Nvidia, Oppo, Advent2 Labs Consultat, Serl Io, Hiverlab
DE Haptic Feedback; Shape; Softness; Virtual Reality
ID FEEDBACK
AB Haptic feedback is widely used to enhance realism in virtual reality (VR). Shape and softness are two common factors perceived by the users in the haptic rendering of soft objects. To integrate these factors, we propose a new handheld shape-changing device, TapeTouch, to provide various shapes and softness in real time. TapeTouch is based on a controllable shape-changing tape, which is mainly composed of four motors and a section of brass tape. We design a structure of the components to fit a portable controller and allow to flexibly adjust the shape of the brass tape. After decoding desired shapes into the signals to control the motor, we automatically reproduce varying shapes and levels of softness to the finger or palm touching the shape-changing tape. We conducted two user studies to understand the capability of TapeTouch to render shape and softness, and the results showed that TapeTouch could provide a variety of distinguishable shapes as well as multiple levels of softness. Based on the results, we performed two VR experience studies to verify that the haptic feedback from TapeTouch enhances VR realism.
C1 [Zhu, Lifeng; Jiang, Xudong; Shen, Jiangwei; Zhang, Heng; Mo, Yiting; Song, Aiguo] Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Bioelect, Jiangsu Key Lab Remote Measurement & Control, Chengdu 210096, Peoples R China.
C3 Southeast University - China
RP Zhu, LF (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Bioelect, Jiangsu Key Lab Remote Measurement & Control, Chengdu 210096, Peoples R China.
EM lfzhulf@gmail.com
RI Zhang, Heng/JYQ-3365-2024; shen, jiangwei/GQO-7856-2022; zhu,
   lifeng/IST-2069-2023
FU NSFC [62133009, 92148205]; Natural Science Foundation of Jiangsu
   Province [BK20211159]; Fundamental Research Funds for the Central
   Universities
FX The authors would like to thank anonymous reviewers for their valuable
   comments. This work has been supported by the NSFC under Grants
   No.62133009 and 92148205, the Natural Science Foundation of Jiangsu
   Province under Grants No. BK20211159, and the Fundamental Research Funds
   for the Central Universities.
CR Amirpour E, 2022, MECHATRONICS, V81, DOI 10.1016/j.mechatronics.2021.102695
   Arora J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300286
   Aziz KMA, 2020, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR50242.2020.00047
   Bau O., 2010, P 23 ANN ACM S US IN, P283, DOI DOI 10.1145/1866029.1866074
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bermejo C, 2017, Arxiv, DOI [arXiv:1709.00698, 10.1145/3465396]
   Bianchi M, 2016, IEEE HAPTICS SYM, P277, DOI 10.1109/HAPTICS.2016.7463190
   Bordegoni M, 2010, PRESENCE-TELEOP VIRT, V19, P341, DOI 10.1162/PRES_a_00010
   Bouzbib E., 2021, 32E C FRANCOPHONE LI, P1
   Bouzit M, 2002, 10TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P145, DOI 10.1109/HAPTIC.2002.998952
   Cheng CH, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281569
   Chinello F, 2018, IEEE T HAPTICS, V11, P39, DOI 10.1109/TOH.2017.2755015
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Chu S.-Y., 2021, 34 ANN ACM S USER IN, P724
   Culbertson H, 2017, IEEE T HAPTICS, V10, P63, DOI 10.1109/TOH.2016.2598751
   D. SYSTEMS, 2022, HAPT DEV
   Danieau F, 2013, IEEE T HAPTICS, V6, P193, DOI [10.1109/ToH.2012.70, 10.1109/TOH.2012.70]
   Dostmohamed H, 2005, EXP BRAIN RES, V164, P387, DOI 10.1007/s00221-005-2262-5
   Le DTG, 2021, INT J INTELL ROBOT, V5, P395, DOI 10.1007/s41315-021-00197-w
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   Fani S, 2018, IEEE T HAPTICS, V11, P304, DOI 10.1109/TOH.2017.2708717
   Feng YL, 2018, LECT NOTES COMPUT SC, V10894, P180, DOI 10.1007/978-3-319-93399-3_17
   Follmer S., 2013, P 26 ANN ACM S US IN, V13, P417, DOI [10.1145/2501988.2502032, DOI 10.1145/2501988.2502032]
   Friedman RM, 2008, EXP BRAIN RES, V191, P133, DOI 10.1007/s00221-008-1507-5
   Frisoli A, 2008, PRESENCE-TELEOP VIRT, V17, P550, DOI 10.1162/pres.17.6.550
   Gabardi M, 2018, IEEE HAPTICS SYM, P100, DOI 10.1109/HAPTICS.2018.8357160
   Gu XC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1991, DOI 10.1145/2858036.2858487
   Hamza-Lup FG, 2019, PROCEEDINGS OF THE 2019 ANNUAL ACM SOUTHEAST CONFERENCE (ACMSE 2019), P141, DOI 10.1145/3299815.3314445
   Hashizume S., 2016, SIGGRAPH ASIA 2016 E, DOI [10.1145/2988240.2988246, DOI 10.1145/2988240.2988246]
   Hayward V., 2000, P 8 S HAPTIC INTERFA, P1309
   Heo S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186544
   Hirota K., 1995, Proceedings. Virtual Reality Annual International Symposium '95 (Cat. No.95CH35761), P211, DOI 10.1109/VRAIS.1995.512498
   Horie A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P260, DOI 10.1109/VR50410.2021.00048
   Huang DY, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/3126594.3126610
   Iwata H, 2001, COMP GRAPH, P469, DOI 10.1145/383259.383314
   Kim H, 2020, HARDWAREX, V8, DOI 10.1016/j.ohx.2020.e00153
   Kim S, 2002, P IEEE VIRT REAL ANN, P283, DOI 10.1109/VR.2002.996540
   Kovacs Robert, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1046, DOI 10.1145/3379337.3415854
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lu Jasmine, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P239, DOI 10.1145/3472749.3474747
   Ma Z, 2015, IEEE-ASME T MECH, V20, P641, DOI 10.1109/TMECH.2014.2305842
   Moy G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3409, DOI 10.1109/ROBOT.2000.845247
   Murakami T., 2017, ACMSIGGRAPH 2017 EME, P1
   Murata K. A., 2018, ICAT EGVE, P123
   Nakagaki K, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P131, DOI 10.1145/3374920.3374933
   Nakagaki K, 2019, TEI'19: PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P615, DOI 10.1145/3294109.3295621
   Nakamura Fumihiko, 2021, SA '21 XR: SIGGRAPH Asia 2021 XR, DOI 10.1145/3478514.3487625
   Neung Ryu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1035, DOI 10.1145/3379337.3415862
   Piovarci M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925885
   Saraiji Y, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P65, DOI 10.1145/3242587.3242665
   Schorr SB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3115, DOI 10.1145/3025453.3025744
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Siu AF, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173865
   Son C, 2016, MICROSYST TECHNOL, V22, P2587, DOI 10.1007/s00542-015-2634-0
   Spakov O, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P333, DOI 10.1109/WHC.2015.7177734
   Stanley AA, 2017, IEEE T VIS COMPUT GR, V23, P1029, DOI 10.1109/TVCG.2016.2525788
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   Suzuki Ryo, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1269, DOI 10.1145/3472749.3474821
   Trinitalova D, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P73, DOI [10.1109/WHC.2019.8816136, 10.1109/whc.2019.8816136]
   Tsai HR, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445262
   Tsai HR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300450
   Wang DX, 2020, IEEE T IND ELECTRON, V67, P610, DOI 10.1109/TIE.2019.2920602
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Wijntjes MWA, 2009, IEEE T HAPTICS, V2, P94, DOI [10.1109/TOH.2009.1, 10.1109/ToH.2009.1]
   Wills J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559760
   Ye Xupeng, 2021, J COMPUTER COMMUNICA, V9, P1, DOI [10.4236/jcc.2021.99001, DOI 10.4236/JCC.2021.99001]
   Yoshida S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376358
   Zhu KN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300923
NR 69
TC 5
Z9 5
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2022
VL 28
IS 11
BP 3928
EP 3938
DI 10.1109/TVCG.2022.3203087
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 5M3ZS
UT WOS:000871038200035
PM 36048984
DA 2024-11-06
ER

PT J
AU Zhou, H
   Zhang, WM
   Chen, KJ
   Li, WX
   Yu, NH
AF Zhou, Hang
   Zhang, Weiming
   Chen, Kejiang
   Li, Weixiang
   Yu, Nenghai
TI Three-Dimensional Mesh Steganography and Steganalysis: A Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Faces; Measurement; Robustness; Geometry; Transforms; Systematics;
   Standards; 3-D; polygonal mesh; information hiding; steganography;
   steganalysis; survey; review
ID IMAGE STEGANOGRAPHY; WATERMARKING; CAPACITY; ALGORITHM; ROBUST;
   DISTORTION; SURFACES; MODELS; DOMAIN
AB Three-dimensional (3-D) meshes are commonly used to represent virtual surfaces and volumes. Over the past decade, 3-D meshes have emerged in industrial, medical, and entertainment applications, being of large practical significance for 3-D mesh steganography and steganalysis. In this article, we provide a systematic survey of the literature on 3-D mesh steganography and steganalysis. Compared with an earlier survey (Girdhar et al., 2017), we propose a new taxonomy of steganographic algorithms with four categories: 1) two-state domain, 2) LSB domain, 3) permutation domain, and 4) transform domain. Regarding steganalysis algorithms, we divide them into two categories: 1) universal steganalysis and 2) specific steganalysis. For each category, the history of technical developments and the current technological level are introduced and discussed. Finally, we highlight some promising future research directions and challenges in improving the performance of 3-D mesh steganography and steganalysis.
C1 [Zhou, Hang] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Zhang, Weiming; Chen, Kejiang; Li, Weixiang; Yu, Nenghai] Univ Sci & Technol China, CAS Key Lab Electromagnet Space Informat, Hefei 230026, Peoples R China.
C3 Simon Fraser University; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Zhou, H (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM zhouhang2991@gmail.com; zhangwm@ustc.edu.cn; chenkj@ustc.edu.cn;
   wxli6049@mail.ustc.edu.cn; ynhi@ustc.edu.cn
RI Zhang, Zhiyong/KPY-6346-2024; Chen, Kejiang/ABD-7057-2020; Zhou,
   Hang/AAI-5565-2021; Li, Weixiang/X-1220-2019
OI Zhou, Hang/0000-0001-7860-8452; Li, Weixiang/0000-0001-5094-6548; Zhang,
   Weiming/0000-0001-5576-6108; Chen, Kejiang/0000-0002-9868-3414
FU Natural Science Foundation of China [62002334, 62072421]; Anhui Science
   Foundation of China [2008085QF296]; Anhui Initiative in Quantum
   Information Technologies [AHY150400]; Fundamental Research Funds for the
   Central Universities [WK2100000018]
FX The authors would like to thank Ali Mahdavi-Amiri from Simon Fraser
   University and the anonymous reviewers, whose comments helped us improve
   the article significantly. This work was supported in part by the
   Natural Science Foundation of China under Grants 62002334 and 62072421,
   by Anhui Science Foundation of China under Grant 2008085QF296, by Anhui
   Initiative in Quantum Information Technologies under Grant AHY150400,
   and by the Fundamental Research Funds for the Central Universities under
   Grant WK2100000018.
CR Alface Patrice Rondao, 2007, Transactions on Data Hiding and Multimedia Security II. (Lecture Notes in Computer Science vol. 4499), P91
   [Anonymous], B LADEN STEGANOGRAPH
   [Anonymous], Definition of STEGANOGRAPHY
   [Anonymous], 2001, DAILY TELEGRAPH
   [Anonymous], 1883, J SCI MILITAIRES
   Artz D, 2001, IEEE INTERNET COMPUT, V5, P75, DOI 10.1109/4236.935180
   Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276
   Bernard S, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P216, DOI 10.1145/3335203.3335737
   Bhme R., 2010, ADV STAT STEGANALYSI
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Bollobas B., 2013, MODERN GRAPH THEORY
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Bors AG, 2013, IEEE T IMAGE PROCESS, V22, P1822, DOI 10.1109/TIP.2012.2236345
   Botsch Mario., 2010, POLYGON MESH PROCESS
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chandramouli R, 2004, LECT NOTES COMPUT SC, V2939, P35
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cho JW, 2007, IEEE T SIGNAL PROCES, V55, P142, DOI 10.1109/TSP.2006.882111
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Denemark Tomas, 2015, P 3 ACM WORKSH INF H, P5
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Eigensatz M, 2008, COMPUT GRAPH FORUM, V27, P241, DOI 10.1111/j.1467-8659.2008.01121.x
   Fawcett T., 2004, MACH LEARN, V31, P1
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Frank J., 2018, BIODIVERSITY INF SCI, V2
   Fridrich J, 2004, PROC SPIE, V5306, P70, DOI 10.1117/12.521353
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J., 2009, Steganography in Digital Media:Principles, Algorithms, and Applications
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Girdhar A, 2018, IET IMAGE PROCESS, V12, P1, DOI 10.1049/iet-ipr.2017.0162
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Huang NC, 2009, IEEE SIGNAL PROC LET, V16, P802, DOI 10.1109/LSP.2009.2024794
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Itier V, 2017, MULTIMED TOOLS APPL, V76, P26421, DOI 10.1007/s11042-016-4163-y
   Jiang RQ, 2018, IEEE T MULTIMEDIA, V20, P55, DOI 10.1109/TMM.2017.2723244
   Johnson N. F., 2001, Information hiding: steganography and watermarkingattacks and countermeasures: steganography and watermarking: attacks and countermeasures, V1
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   KANAI Satoshi., 1998, P 6 IFIP WG 5 2 INT, P296
   Ker AD, 2007, LECT NOTES COMPUT SC, V4437, P265
   Ker AD, 2007, IEEE SIGNAL PROC LET, V14, P525, DOI 10.1109/LSP.2006.891319
   Kim D, 2017, LECT NOTES ELECTR EN, V424, P358, DOI 10.1007/978-981-10-4154-9_42
   Koch J, 2020, NAT BIOTECHNOL, V38, P39, DOI 10.1038/s41587-019-0356-z
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kolata G., 2001, VEILED MESSAGES TERR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levenberg K., 1944, Q. Appl. Math, V2, P164, DOI [10.1090/QAM/10666, 10.1090/qam/10666, DOI 10.1090/QAM/10666]
   Li B., 2011, J. Inf. Hiding Multimedia Signal Process., V2, P142
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li WX, 2020, IEEE T COMMUN, V68, P3948, DOI 10.1109/TCOMM.2020.2982624
   Li ZY, 2020, INFORM SCIENCES, V522, P164, DOI 10.1016/j.ins.2020.02.061
   Li ZY, 2020, IEEE T CYBERNETICS, V50, P1989, DOI 10.1109/TCYB.2018.2883082
   Li ZY, 2018, LECT NOTES COMPUT SC, V11068, P223, DOI 10.1007/978-3-030-00021-9_21
   Li ZY, 2018, IEEE IMAGE PROC, P1683, DOI 10.1109/ICIP.2018.8451643
   Li ZY, 2017, IEEE IMAGE PROC, P510, DOI 10.1109/ICIP.2017.8296333
   Li ZY, 2017, INFORM SCIENCES, V415, P85, DOI 10.1016/j.ins.2017.06.011
   Li ZY, 2016, INT C PATT RECOG, P4256, DOI 10.1109/ICPR.2016.7900302
   Li ZY, 2016, INT CONF ACOUST SPEE, P2144, DOI 10.1109/ICASSP.2016.7472056
   Lounsbery M, 1997, ACM T GRAPHIC, V16, P34, DOI 10.1145/237748.237750
   Luo XY, 2008, SIGNAL PROCESS, V88, P2138, DOI 10.1016/j.sigpro.2008.03.016
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nematollahi M.A., 2017, Digital watermarking
   Ohbuchi Ryutarou, 2001, GRAPHICS INTERFACE, V2001, P9
   Pahati O., CONFOUNDING CARNIVOR
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Praun E, 1999, COMP GRAPH, P49, DOI 10.1145/311535.311540
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Rugis J, 2006, LECT NOTES COMPUT SC, V4319, P138
   Sastry SP, 2014, ENG COMPUT-GERMANY, V30, P535, DOI 10.1007/s00366-014-0363-0
   Schaathun H.G., 2012, Machine Learning in Image Steganalysis
   Schneider R, 2001, COMPUT AIDED GEOM D, V18, P359, DOI 10.1016/S0167-8396(01)00036-X
   Shontz SM, 2008, PROCEEDINGS OF THE 17TH INTERNATIONAL MESHING ROUNDTABLE, P107, DOI 10.1007/978-3-540-87921-3_7
   Simmons G. J., 1984, Advances in Cryptology. Proceedings of Crypto 83, P51
   Sun Y, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P825, DOI 10.1109/ICIP.2002.1039099
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Tu H., 2010, Int.J.VirtualReality, V9, P55
   Tu SC, 2012, COMPUT GRAPH-UK, V36, P767, DOI 10.1016/j.cag.2012.06.002
   Tu SC, 2010, VISUAL COMPUT, V26, P1177, DOI 10.1007/s00371-009-0398-1
   Wang CM, 2006, COMPUT GRAPH-UK, V30, P244, DOI 10.1016/j.cag.2006.01.030
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang K, 2011, COMPUT GRAPH-UK, V35, P1, DOI 10.1016/j.cag.2010.09.010
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wang YM, 2019, IEEE ACCESS, V7, P183300, DOI 10.1109/ACCESS.2019.2960455
   Wang YP, 2009, IEEE T VIS COMPUT GR, V15, P285, DOI 10.1109/TVCG.2008.101
   Wayner P, 2009, DISAPPEARING CRYPTOGRAPHY: INFORMATION HIDING: STEGANOGRAPHY & WATERMARKING, 3RD EDITION, P1
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang Y., 2013, THESIS DURHAM U DURH
   Yang Y, 2017, IEEE T VIS COMPUT GR, V23, P1002, DOI 10.1109/TVCG.2016.2525771
   Yang Y, 2014, IEEE IMAGE PROC, P4782, DOI 10.1109/ICIP.2014.7025969
   Yang Y, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2535555
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P45, DOI 10.1109/TVCG.2012.106
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Zafeiriou S, 2005, IEEE T VIS COMPUT GR, V11, P596, DOI 10.1109/TVCG.2005.71
   Zhang WM, 2017, IEEE T CIRC SYST VID, V27, P2274, DOI 10.1109/TCSVT.2016.2587388
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
   Zhao W., 2019, arXiv
   Zhou H, 2021, IEEE T VIS COMPUT GR, V27, P57, DOI 10.1109/TVCG.2019.2929041
   Zhou H, 2019, IEEE T MULTIMEDIA, V21, P1384, DOI 10.1109/TMM.2018.2882088
NR 106
TC 7
Z9 7
U1 1
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5006
EP 5025
DI 10.1109/TVCG.2021.3075136
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400075
PM 33886472
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yan, ZH
   Yi, ZM
   Hu, RZ
   Mitra, NJ
   Cohen-Or, D
   Huang, H
AF Yan, Zihao
   Yi, Zimu
   Hu, Ruizhen
   Mitra, Niloy J.
   Cohen-Or, Daniel
   Huang, Hui
TI Consistent Two-Flow Network for Tele-Registration of Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural networks; Training data; Computer graphics; Three-dimensional
   displays; Computational modeling; Computer network reliability; Point
   cloud compression; Point cloud registration; tele-registration; shape
   completion; shape prediction; deep points learning
AB Rigid registration of partial observations is a fundamental problem in various applied fields. In computer graphics, special attention has been given to the registration between two partial point clouds generated by scanning devices. State-of-the-art registration techniques still struggle when the overlap region between the two point clouds is small, and completely fail if there is no overlap between the scan pairs. In this article, we present a learning-based technique that alleviates this problem, and allows registration between point clouds, presented in arbitrary poses, and having little or even no overlap, a setting that has been referred to as tele-registration. Our technique is based on a novel neural network design that learns a prior of a class of shapes and can complete a partial shape. The key idea is combining the registration and completion tasks in a way that reinforces each other. In particular, we simultaneously train the registration network and completion network using two coupled flows, one that register-and-complete, and one that complete-and-register, and encourage the two flows to produce a consistent result. We show that, compared with each separate flow, this two-flow training leads to robust and reliable tele-registration, and hence to a better point cloud prediction that completes the registered scans. It is also worth mentioning that each of the components in our neural network outperforms state-of-the-art methods in both completion and registration. We further analyze our network with several ablation studies and demonstrate its performance on a large number of partial point clouds, both synthetic and real-world, that have only small or no overlap.
C1 [Yan, Zihao; Yi, Zimu; Hu, Ruizhen; Cohen-Or, Daniel; Huang, Hui] Shenzhen Univ, Coll Comp Sci & Software Engn, Visual Comp Res Ctr, Shenzhen 518060, Peoples R China.
   [Mitra, Niloy J.] UCL, London WC1E 6BT, England.
   [Mitra, Niloy J.] Adobe Res, London EC1Y 8AF, England.
C3 Shenzhen University; University of London; University College London
RP Hu, RZ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Visual Comp Res Ctr, Shenzhen 518060, Peoples R China.
EM mr.salingo@gmail.com; yizimu@gmail.com; ruizhen.hu@gmail.com;
   n.mitra@cs.ucl.ac.uk; cohenor@gmail.com; hhzhiyan@gmail.com
RI Yan, Zihao/AAC-5822-2021; Huang, Hui/JGB-1049-2023
OI Zihao, Yan/0000-0003-2160-9109; Huang, Hui/0000-0003-3212-0544
FU NSFC [U2001206, 61872250]; GD Talent Program [2019JC05X328]; GD Natural
   Science Foundation [2021B1515020085, 2020A0505100064]; DEGP Key Project
   [2018KZDXM058]; Shenzhen Science and Technology Program
   [RCJC20200714114435012]; Royal Society [NAF-R1-180099]; ISF [2472/17,
   2492/20]; GD Laboratory of Artificial Intelligence and Digital Economy
FX This work was supported in part by the NSFC under Grants U2001206 and
   61872250, in part by the GD Talent Program under Grant 2019JC05X328, in
   part by the GD Natural Science Foundation under Grants 2021B1515020085
   and 2020A0505100064, in part by the DEGP Key Project under Grant
   2018KZDXM058, in part by the Shenzhen Science and Technology Program
   under Grant RCJC20200714114435012, in part by the Royal Society under
   Grant NAF-R1-180099, in part by the ISF under Grants 2472/17 and
   2492/20, and in part by the GD Laboratory of Artificial Intelligence and
   Digital Economy (SZ). Our code is available at
   https://github.com/Salingo/CTF-Net
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267
   Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117
   Chen SL, 2020, IEEE T GEOSCI REMOTE, V58, P2530, DOI 10.1109/TGRS.2019.2952086
   Choi S, 2016, Arxiv, DOI [arXiv:1602.02481, 10.48550/arXiv.1602.02481, DOI 10.48550/ARXIV.1602.02481]
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Elbaz G, 2017, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2017.265
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Groueix T, 2019, COMPUT GRAPH FORUM, V38, P123, DOI 10.1111/cgf.13794
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3267347
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508373
   Huang H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366198
   Huang ZT, 2020, PROC CVPR IEEE, P7659, DOI 10.1109/CVPR42600.2020.00768
   Liu MH, 2020, AAAI CONF ARTIF INTE, V34, P11596
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Segal Aleksandr, 2009, Generalized-icpRobotics: Sci Syst, V2, P435, DOI [DOI 10.15607/RSS.2009.V.021, DOI 10.7551/MITPRESS/8727.003.0022]
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang YL, 2019, ADV NEUR IN, V32
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Yang ZP, 2020, PROC CVPR IEEE, P2452, DOI 10.1109/CVPR42600.2020.00253
   Yang ZP, 2019, PROC CVPR IEEE, P4526, DOI 10.1109/CVPR.2019.00466
   Yew ZJ, 2020, PROC CVPR IEEE, P11821, DOI 10.1109/CVPR42600.2020.01184
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
NR 35
TC 14
Z9 14
U1 6
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4304
EP 4318
DI 10.1109/TVCG.2021.3086113
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5T5BI
UT WOS:000875881400001
PM 34077360
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Feng, WQ
   Zhang, JY
   Zhou, YF
   Xin, SQ
AF Feng, Wanquan
   Zhang, Juyong
   Zhou, Yuanfeng
   Xin, Shiqing
TI GDR-Net: A Geometric Detail Recovering Network for 3D Scanned Objects
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Surface reconstruction; Geometry;
   Computational modeling; Task analysis; Solid modeling; Surface
   representation; geometric detail recovery; 3D scanning; mesh
   reconstruction
ID SUBDIVISION SCHEME; SURFACES; CONSTRUCTION
AB This article addresses the problem of mesh super-resolution such that the geometry details which are not well represented in the low-resolution models can be recovered and well represented in the generated high-quality models. The main challenges of this problem are the nonregularity of 3D mesh representation and the high complexity of 3D shapes. We propose a deep neural network called GDR-Net to solve this ill-posed problem, which resolves the two challenges simultaneously. First, to overcome the nonregularity, we regress a displacement in radial basis function parameter space instead of the vertex-wise coordinates in the euclidean space. Second, to overcome the high complexity, we apply the detail recovery process to small surface patches extracted from the input surface and obtain the overall high-quality mesh by fusing the refined surface patches. To train the network, we constructed a dataset composed of both real-world and synthetic scanned models, including high/low-quality pairs. Our experimental results demonstrate that GDR-Net works well for general models and outperforms previous methods for recovering geometric details.
C1 [Feng, Wanquan; Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
   [Zhou, Yuanfeng; Xin, Shiqing] Shandong Univ, Sch Software, Jinan 264209, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Shandong University
RP Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
EM lcfwq@mail.ustc.edu.cn; juyong@ustc.edu.cn; yfzhou@sdu.edu.cn;
   xinshiqing@sdu.edu.cn
RI Zhou, Yuanfeng/AAT-4670-2020
FU National Natural Science Foundation of China [62122071 61772016,
   62172257, 61772312]; Youth Innovation Promotion Association CAS
   [2018495]; Fundamental Research Funds for the Central Universities
   [WK3470000021]; Key Research Development program of Shandong Province
   [2019GGX101021]; NSFC-Zhejiang Joint Fund of the Integration of
   Informatization and Industrialization [U1909210]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62122071 61772016, 62172257, and
   61772312, the Youth Innovation Promotion Association CAS under Grant
   2018495, "the Fundamental Research Funds for the Central Universities"
   under Grant WK3470000021, the Key Research Development program of
   Shandong Province under Grant 2019GGX101021, and the NSFC-Zhejiang Joint
   Fund of the Integration of Informatization and Industrialization under
   Grant U1909210.
CR [Anonymous], 2018, SHAPE CLASSIFICATION
   [Anonymous], 2019, AZURE KINECT DK
   [Anonymous], 2006, PROC 3 EUROGRAPHICSI
   Arvanitis G, 2019, IEEE T VIS COMPUT GR, V25, P1513, DOI 10.1109/TVCG.2018.2802926
   Béarzi Y, 2018, COMPUT GRAPH FORUM, V37, P13, DOI 10.1111/cgf.13338
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Chen K, 2019, LECT NOTES COMPUT SC, V11363, P100, DOI 10.1007/978-3-030-20893-6_7
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Choi S, 2016, Arxiv, DOI [arXiv:1602.02481, 10.48550/arXiv.1602.02481, DOI 10.48550/ARXIV.1602.02481]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Cignoni P, 2005, COMPUT GRAPH-UK, V29, P125, DOI 10.1016/j.cag.2004.11.012
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Della Vecchia G, 2008, COMPUT AIDED GEOM D, V25, P801, DOI 10.1016/j.cagd.2008.08.003
   DOO D, 1978, COMPUT AIDED DESIGN, V10, P356, DOI 10.1016/0010-4485(78)90111-2
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Einscan-pro+, 2017, HANDH 3D SCANN EINSC
   Genova K, 2019, IEEE I CONF COMP VIS, P7153, DOI 10.1109/ICCV.2019.00725
   Gong SW, 2019, IEEE INT CONF COMP V, P4141, DOI 10.1109/ICCVW.2019.00509
   Gu X., 2005, SPM 05, P27
   Hamdi-Cherif A, 2018, COMPUT GRAPH FORUM, V37, P60, DOI 10.1111/cgf.13216
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Huang YC, 2014, J COMPUT SCI TECH-CH, V29, P1014, DOI 10.1007/s11390-014-1486-x
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kammerl J., 2013, PCL
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kipf T., 2016, ARXIV
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kobbelt L, 2000, COMP GRAPH, P103, DOI 10.1145/344779.344835
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li ZQ, 2019, AAAI CONF ARTIF INTE, P8682
   Liao YY, 2018, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR.2018.00308
   Lim I, 2019, LECT NOTES COMPUT SC, V11131, P349, DOI 10.1007/978-3-030-11015-4_26
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Liu HTD, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392418
   Liu SH, 2020, PROC CVPR IEEE, P2016, DOI 10.1109/CVPR42600.2020.00209
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Luciano L, 2018, PATTERN RECOGN LETT, V105, P182, DOI 10.1016/j.patrec.2017.05.011
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mi ZX, 2020, Arxiv, DOI arXiv:1911.07401
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Niessner M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077347
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Peters J, 1997, ACM T GRAPHIC, V16, P420, DOI 10.1145/263834.263851
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Schäfer H, 2015, PROCEEDINGS - I3D 2015, P31, DOI 10.1145/2699276.2699282
   Taubin G, 2012, IEEE COMPUT GRAPH, V32, P88, DOI 10.1109/MCG.2012.80
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P293, DOI 10.1007/978-3-030-58517-4_18
   Vallet B, 2008, COMPUT GRAPH FORUM, V27, P251, DOI 10.1111/j.1467-8659.2008.01122.x
   Wang PS, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818068
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Warren J., 2002, SUBDIVISION METHODS
   Wickramasinghe Udaranga, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P299, DOI 10.1007/978-3-030-59719-1_30
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xu C, 2019, IEEE I CONF COMP VIS, P3731, DOI 10.1109/ICCV.2019.00383
   Xu D, 2014, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2014.198
   Ying LX, 2004, ACM T GRAPHIC, V23, P271, DOI 10.1145/1015706.1015714
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zhang JY, 2022, IEEE T PATTERN ANAL, V44, P3450, DOI 10.1109/TPAMI.2021.3054619
   Zhang JY, 2019, IEEE T VIS COMPUT GR, V25, P1774, DOI 10.1109/TVCG.2018.2816926
NR 74
TC 2
Z9 2
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 3959
EP 3973
DI 10.1109/TVCG.2021.3110658
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400001
PM 34495834
DA 2024-11-06
ER

PT J
AU Otaran, A
   Farkhatdinov, I
AF Otaran, Ata
   Farkhatdinov, Ildar
TI Haptic Ankle Platform for Interactive Walking in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Haptic interfaces; Avatars; Tracking; Foot; Robots;
   Rendering (computer graphics); Locomotion in VR; walking-in-place;
   human-robot interaction; proprioceptive feedback
AB This article presents an impedance type ankle haptic interface for providing users with an immersive navigation experience in virtual reality (VR). The ankle platform, actuated by an electric motor with feedback control, enables the use of foot-tapping gestures to create a walking experience like a real one and to haptically render different types of walking terrains. Experimental studies demonstrated that the interface can be easily used to generate virtual walking and is capable of rendering terrains, such as hard and soft surfaces, and multi-layer complex dynamic terrains. The designed system is a seated-type VR locomotion interface, therefore allowing its user to maintain a stable seated posture to comfortably navigate a virtual scene.
C1 [Otaran, Ata; Farkhatdinov, Ildar] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.
   [Farkhatdinov, Ildar] Imperial Coll Sci Technol & Med, Dept Bioengn, London SW7 2BX, England.
C3 University of London; Queen Mary University London; Imperial College
   London
RP Otaran, A (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.
EM a.otaran@qmul.ac.uk; i.farkhatdinov@qmul.ac.uk
RI Farkhatdinov, Ildar/A-9905-2012
FU UK EPSRC [EP/R02572X/1]; Queen MaryUniversity of London
FX This work was supported in part by the UK EPSRC under Grant EP/R02572X/1
   and in part by the Ph.D. studentship of Queen MaryUniversity of London.
CR Bouguila L., 2005, ACTIVE WALKING INTER, P22
   Bouguila L., 2003, PROC INT C ARTIF REA
   Chester MR, 2002, INT J IND ERGONOM, V29, P289, DOI 10.1016/S0169-8141(01)00069-5
   Cirio G, 2013, IEEE T HAPTICS, V6, P117, DOI 10.1109/TOH.2012.34
   CyberShoes, US
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Gibbs BB, 2017, OCCUP MED-OXFORD, V67, P121, DOI 10.1093/occmed/kqw115
   Giordano BL, 2012, J ACOUST SOC AM, V131, P4002, DOI 10.1121/1.3699205
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Hidayah R, 2019, IEEE ROBOT AUTOM LET, V4, P3948, DOI 10.1109/LRA.2019.2929989
   Horlings CGC, 2009, NEUROSCI LETT, V451, P227, DOI 10.1016/j.neulet.2008.12.057
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Jayakumar R. P., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P425, DOI 10.1109/HAPTIC.2012.6183826
   Kato G, 2018, IEEE T VIS COMPUT GR, V24, P1506, DOI 10.1109/TVCG.2018.2793641
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lee J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092832
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Nilsson N. C., 2013, P MOT GAM, P155, DOI DOI 10.1145/2522628.2522655
   Otaran Ata, 2019, Towards Autonomous Robotic Systems. 20th Annual Conference, TAROS 2019. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11649), P338, DOI 10.1007/978-3-030-23807-0_28
   Otaran A, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P592, DOI 10.1109/WHC49131.2021.9517167
   Pan CT, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P498, DOI 10.1109/ICASI.2018.8394296
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Razzaque S., 2001, P EUR
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   SLATER M, 1994, ARTIFICIAL LIFE AND VIRTUAL REALITY, P125
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Soave F, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P377, DOI 10.1109/VRW52623.2021.00077
   Son H, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186474
   Templeman JN, 2007, IEEE Virtual Reality 2007, Proceedings, P285
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Visell Yon, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P133, DOI 10.1109/HAPTIC.2010.5444664
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Whitton M.C., 2013, Human Walking in Virtual Environments: Perception, Technology, and Applications, P241
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Yokota T., 2015, P 6 AUGM HUM INT C, P45, DOI 10.1145/2735711.2735829
NR 40
TC 12
Z9 13
U1 3
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 3974
EP 3985
DI 10.1109/TVCG.2021.3111675
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400002
PM 34506284
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU He, Y
   Liu, YT
   Jin, YH
   Zhang, SH
   Lai, YK
   Hu, SM
AF He, Yu
   Liu, Ying-Tian
   Jin, Yi-Han
   Zhang, Song-Hai
   Lai, Yu-Kun
   Hu, Shi-Min
TI Context-Consistent Generation of Indoor Virtual Environments Based on
   Geometry Constraints
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Solid modeling; Sensors; Layout; Computational modeling; Virtual
   environments; Valves; Upper bound; Virtual reality; obstacle awareness;
   user interaction; scene generation; geometric constraints; contextual
   relation; layout patterns
ID REAL
AB In this article, we propose a system that can automatically generate immersive and interactive virtual reality (VR) scenes by taking real-world geometric constraints into account. Our system can not only help users avoid real-world obstacles in virtual reality experiences, but also provide context-consistent contents to preserve their sense of presence. To do so, our system first identifies the positions and bounding boxes of scene objects as well as a set of interactive planes from 3D scans. Then context-consistent virtual objects that have similar geometric properties to the real ones can be automatically selected and placed into the virtual scene, based on learned object association relations and layout patterns from large amounts of indoor scene configurations. We regard virtual object replacement as a combinatorial optimization problem, considering both geometric and contextual consistency constraints. Quantitative and qualitative results show that our system can generate plausible interactive virtual scenes that highly resemble real environments, and have the ability to keep the sense of presence for users in their VR experiences.
C1 [He, Yu; Liu, Ying-Tian; Zhang, Song-Hai; Hu, Shi-Min] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Jin, Yi-Han] Tianjin Univ Technol, Dept Comp Sci & Engn, Tianjin 300384, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Tsinghua University; Tianjin University of Technology; Cardiff
   University
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM hooyeeevan2511@gmail.com; liuyingt20@mails.tsinghua.edu.cn;
   1127703753@qq.com; shz@tsinghua.edu.cn; Yukun.Lai@cs.cardiff.ac.uk;
   shimin@tsinghua.edu.cn
RI Hu, Shi-Min/AAW-1952-2020; He, Yu/ABD-4698-2021; Lai,
   Yu-Kun/D-2343-2010; Yu, He/B-5774-2017
OI Hu, Shi-Min/0000-0001-7507-6542; Yu, He/0000-0002-0357-681X; Lai,
   Yukun/0000-0002-2094-5680
FU National Key Technology RD Program [2017YFB1002604]; National Natural
   Science Foundation of China [61521002, 61772298]; Research Grant of
   Beijing Higher Institution Engineering Research Center; Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology
FX The authors would like to thank Prof. Sheng-Yong Chen from the Tianjin
   University of Technology for his valuable comments in the conception of
   this work and the process of experiments which have greatly improved the
   manuscript. This work was supported in part by the National Key
   Technology R&D Program under Grant 2017YFB1002604, in part by the
   National Natural Science Foundation of China under Grants 61521002 and
   61772298, and in part by the Research Grant of Beijing Higher
   Institution Engineering Research Center and Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology.
CR [Anonymous], 2009, Proceedings of the Second ACM international Conference on Web Search and Data Mining (Barcelona, Spain, February 09-12, DOI DOI 10.1145/1498759.1498809
   Avetisyan A, 2020, Arxiv, DOI arXiv:2003.12622
   Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   Blei D. M., 2007, P 20 INT C NEUR INF, P121
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dong Z, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P43
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Ester M., 1996, P KDD, P226
   Fang SF, 2000, COMPUT GRAPH-UK, V24, P433, DOI 10.1016/S0097-8493(00)00038-8
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fu H, 2021, Arxiv, DOI arXiv:2011.09127
   GARCIAPEREZ MA, 1994, BRIT J MATH STAT PSY, V47, P247, DOI 10.1111/j.2044-8317.1994.tb01037.x
   Girau E, 2019, IEEE ENG MED BIO, P5690, DOI [10.1109/EMBC.2019.8856777, 10.1109/embc.2019.8856777]
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Kanamori K, 2018, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR.2018.00033
   Keller M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1012, DOI [10.1109/VR.2019.8798260, 10.1109/vr.2019.8798260]
   Keller M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P763, DOI 10.1109/VR.2018.8446385
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lacoste-Julien S., 2008, ADV NEURAL INFORM PR, P897
   Li L, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050433
   Liu C, 2019, PROC CVPR IEEE, P4445, DOI 10.1109/CVPR.2019.00458
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Nassani A., 2015, P SOC PHOTO-OPT INS, P1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Peasley B, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P197, DOI 10.1109/WORV.2013.6521938
   Qayyum U., 2013, PROC AUSTRALAS C ROB, P342
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ramage Daniel., 2009, EMNLP
   Rauter M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1134, DOI [10.1109/vr.2019.8797873, 10.1109/VR.2019.8797873]
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Schwarz M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866201
   Sousa M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365737
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Stühmer J, 2010, LECT NOTES COMPUT SC, V6376, P11
   Sutherland I. E., 1968, P DEC 9 11 1968 FA 1, P757, DOI [https://doi.org/10.1145/1476589.1476686, DOI 10.1145/1476589.1476686]
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.00-82, 10.1109/VR46266.2020.1581503942658]
   Valkov D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P340, DOI [10.1109/VR.2019.8798036, 10.1109/vr.2019.8798036]
   Wang M, 2020, COMPUT VIS MEDIA, V6, P3, DOI 10.1007/s41095-020-0162-z
   Wu F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1882, DOI [10.1109/VR.2019.8798015, 10.1109/vr.2019.8798015]
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Yuan Liang, 2018, Computational Visual Media, V4, P123, DOI 10.1007/s41095-018-0110-3
   Zhang Song-Hai, 2020, PREPRINT
NR 47
TC 6
Z9 8
U1 2
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 3986
EP 3999
DI 10.1109/TVCG.2021.3111729
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400003
PM 34506285
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Garcia-Zanabria, G
   Raimundo, MM
   Poco, J
   Nery, MB
   Silva, CT
   Adorno, S
   Nonato, LG
AF Garcia-Zanabria, Germain
   Raimundo, Marcos M.
   Poco, Jorge
   Nery, Marcelo Batista
   Silva, Claudio T.
   Adorno, Sergio
   Nonato, Luis Gustavo
TI CriPAV: Street-Level Crime Patterns Analysis and Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Time series analysis; Urban areas; Tools; Task
   analysis; Deep learning; Visual analytics; Crime data; spatio-temporal
   data; visual analytics; crime hotspots; stochastic matrix
ID LONGITUDINAL ANALYSIS; ALCOHOL OUTLETS; ORIENTED DATA; MICRO PLACES;
   VIOLENCE; TRENDS; CITY
AB Extracting and analyzing crime patterns in big cities is a challenging spatiotemporal problem. The hardness of the problem is linked to two main factors, the sparse nature of the crime activity and its spread in large spatial areas. Sparseness hampers most time series (crime time series) comparison methods from working properly, while the handling of large urban areas tends to render the computational costs of such methods impractical. Visualizing different patterns hidden in crime time series data is another issue in this context, mainly due to the number of patterns that can show up in the time series analysis. In this article, we present a new methodology to deal with the issues above, enabling the analysis of spatiotemporal crime patterns in a street-level of detail. Our approach is made up of two main components designed to handle the spatial sparsity and spreading of crimes in large areas of the city. The first component relies on a stochastic mechanism from which one can visually analyze probablexintensive crime hotspots. Such analysis reveals important patterns that can not be observed in the typical intensity-based hotspot visualization. The second component builds upon a deep learning mechanism to embed crime time series in Cartesian space. From the embedding, one can identify spatial locations where the crime time series have similar behavior. The two components have been integrated into a web-based analytical tool called CriPAV (Crime Pattern Analysis and Visualization), which enables global as well as a street-level view of crime patterns. Developed in close collaboration with domain experts, CriPAV has been validated through a set of case studies with real crime data in Sao Paulo - Brazil. The provided experiments and case studies reveal the effectiveness of CriPAV in identifying patterns such as locations where crimes are not intense but highly probable to occur as well as locations that are far apart from each other but bear similar crime patterns.
C1 [Garcia-Zanabria, Germain; Nonato, Luis Gustavo] ICMC USP, BR-13566590 Sao Carlos, SP, Brazil.
   [Raimundo, Marcos M.; Poco, Jorge] Fundacao Getulio Vargas, BR-88010001 Florianopolis, SC, Brazil.
   [Nery, Marcelo Batista] RIDC FAPESP, BR-05508010 Sao Paulo, Brazil.
   [Nery, Marcelo Batista] Inst Adv Studies, Global Cities Program, BR-05508010 Sao Paulo, Brazil.
   [Silva, Claudio T.; Nonato, Luis Gustavo] NYU, New York, NY 10013 USA.
   [Adorno, Sergio] NEV CEPID USP, BR-05508900 Sao Paulo, Brazil.
C3 Getulio Vargas Foundation; Escola de Pos-Graduacao em Economia (EPGE);
   New York University
RP Garcia-Zanabria, G (corresponding author), ICMC USP, BR-13566590 Sao Carlos, SP, Brazil.
EM germain.garcia@ucsp.edu.pe; marcosmrai@gmail.com; jpocom@gmail.com;
   mbnery@gmail.com; csilva@nyu.edu; marsadorno@usp.br; gnonato@icmc.usp.br
RI Nery, Marcelo/JAN-6213-2023; Nonato, Luis/D-5782-2011; Poco,
   Jorge/F-3344-2016
OI Poco, Jorge/0000-0001-9096-6287; Silva, Claudio/0000-0003-2452-2295; M.
   Raimundo, Marcos/0000-0003-0499-2564; GARCIA-ZANABRIA,
   GERMAIN/0000-0003-3266-9043
FU CNPq-Brazil [302643/2013-3, 303552/ 2017-4, 301642/2017-63,
   312483/2018-0]; CAPES Brazil [10242771]; NEV-CEPID [2013/07923-7]; Sao
   Paulo Research Foundation (FAPESP)-Brazil [2013/ 07375-0, 2014/12236-1,
   2016/04391-2, 2017/05416-1, 2019/04434-1]; Getulio Vargas Foundation;
   MooreSloan Data Science Environment at NYU; NASA; NSF [CNS-1229185,
   CCF-1533564, CNS-1544753, CNS-1730396, CNS-1828576]; DARPA; Swedish
   Research Council [2017-05416] Funding Source: Swedish Research Council;
   Vinnova [2019-04434, 2017-05416] Funding Source: Vinnova
FX This work was supported by CNPq-Brazil under Grants 302643/2013-3,
   303552/ 2017-4, 301642/2017-63, and 312483/2018-0, in part by CAPES
   Brazil under Grant 10242771, in part by NEV-CEPID under Grant
   2013/07923-7, in part by Sao Paulo Research Foundation (FAPESP)-Brazil
   in part by under Grants 2013/ 07375-0, 2014/12236-1, 2016/04391-2,
   2017/05416-1, and 2019/04434-1, and Getulio Vargas Foundation. The work
   of Silva was supported in part by the MooreSloan Data Science
   Environment at NYU; NASA; NSF awards CNS-1229185, CCF-1533564,
   CNS-1544753, CNS-1730396, CNS-1828576, and DARPA.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Alves LGA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0069580
   Alves LGA, 2013, PHYSICA A, V392, P2672, DOI 10.1016/j.physa.2013.02.002
   Aminikhanghahi S, 2017, KNOWL INF SYST, V51, P339, DOI 10.1007/s10115-016-0987-z
   Anderson TK, 2009, ACCIDENT ANAL PREV, V41, P359, DOI 10.1016/j.aap.2008.12.014
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Arietta SM, 2014, IEEE T VIS COMPUT GR, V20, P2624, DOI 10.1109/TVCG.2014.2346446
   Bach B., 2014, EUR C VIS, P1
   Bailey T.C., 1995, INTERACTIVE SPATIAL
   Bernasco W, 2011, J RES CRIME DELINQ, V48, P33, DOI 10.1177/0022427810384135
   Block CarolynRebecca., 1995, Crime analysis through computer mapping, P15
   Boeing G, 2017, COMPUT ENVIRON URBAN, V65, P126, DOI 10.1016/j.compenvurbsys.2017.05.004
   Braga AA, 2011, J RES CRIME DELINQ, V48, P7, DOI 10.1177/0022427810384137
   Braga AA, 2010, J QUANT CRIMINOL, V26, P33, DOI 10.1007/s10940-009-9082-x
   Brantingham P.J., 1998, Studies on Crime and Crime Prevention, V7, P31
   Camara G, 1996, COMPUT GRAPH, V20, P395, DOI 10.1016/0097-8493(96)00008-8
   Camara G., 2008, OPEN SOURCE APPROACH, DOI DOI 10.1007/978-3-540-74831-1_12
   Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381
   Caplan J.M., 2010, Risk Terrain Modeling Manual: Theoretical Framework and Technical Steps of Spatial Risk Assessment
   Chainey S., 2005, GIS CRIME MAPPING, DOI [10.1002/9781118685181, DOI 10.1002/9781118685181]
   Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066
   Poveda AC, 2012, J INT DEV, V24, P809, DOI 10.1002/jid.2819
   Cozens PM, 2005, PROP MANAG, V23, P328, DOI 10.1108/02637470510631483
   Craglia M, 2000, URBAN STUD, V37, P711, DOI 10.1080/00420980050003982
   Day P, 2012, AUST NZ J PUBL HEAL, V36, P48, DOI 10.1111/j.1753-6405.2012.00827.x
   Neto JFD, 2016, SIBGRAPI, P305, DOI [10.1109/SIBGRAPI.2016.46, 10.1109/SIBGRAPI.2016.049]
   Demotto N., 2006, Cartography and Geographic Information Science, V33, P141, DOI DOI 10.1559/152304006777681715
   Demsar U, 2015, MOV ECOL, V3, DOI 10.1186/s40462-015-0032-y
   Eck J.E., 2015, Crime and Place: Crime Prevention Studies, V4, P1
   ESRI, 1999, US
   Ester M., 1996, P KDD, P226
   Garcia G, 2021, IEEE T VIS COMPUT GR, V27, P2313, DOI 10.1109/TVCG.2019.2947515
   Garcia-Zanabria G, 2020, SIBGRAPI, P148, DOI 10.1109/SIBGRAPI51738.2020.00028
   Godwin A, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P1372
   Gold O, 2018, ACM T ALGORITHMS, V14, DOI 10.1145/3230734
   Gomez-Lievano A, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040393
   Gomez-Nieto E, 2016, IEEE T VIS COMPUT GR, V22, P1223, DOI 10.1109/TVCG.2015.2489660
   Groff ER, 2010, J QUANT CRIMINOL, V26, P7, DOI 10.1007/s10940-009-9081-y
   Grubesic T.H., 2001, Proceedings from the Fifth Annual International Crime Mapping Research Conference, P26
   Grubesic TH, 2011, INT J HEALTH GEOGR, V10, DOI 10.1186/1476-072X-10-30
   Gruenewald PJ, 2006, ADDICTION, V101, P666, DOI 10.1111/j.1360-0443.2006.01405.x
   Hirschfield Alexander, 2001, Mapping and Analysing Crime Data: Lessons from Research and Practice
   Hojman D. E., 2001, UNEMPLOYMENT INEQUAL
   Hojman D.E., 2002, Bulletin of Latin American Research, V21, P121
   Jacobs B.A., 2000, Robbing drug dealers: Violence beyond the law
   Jean St.P. K., 2008, Pockets of Crime: Broken Windows, Collective efficacy, and the Criminal Point of View
   Jensen SK, 2017, IEEE T KNOWL DATA EN, V29, P2581, DOI 10.1109/TKDE.2017.2740932
   Johnson S.D., 2008, Built Environment, V34, P32
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kelly M, 2000, REV ECON STAT, V82, P530, DOI 10.1162/003465300559028
   Lauritsen JL, 2014, J CONTEMP CRIM JUST, V30, P7, DOI 10.1177/1043986213509024
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Levitt SD, 2001, J QUANT CRIMINOL, V17, P377, DOI 10.1023/A:1012541821386
   Liebow Elliot., 2003, TALLYS CORNER STUDY
   Livingston M, 2011, ADDICTION, V106, P919, DOI 10.1111/j.1360-0443.2010.03333.x
   Malik A., 2010, 2010 IEEE International Conference on Technologies for Homeland Security (HST 2010), P222, DOI 10.1109/THS.2010.5655057
   McCord E.S., 2009, Crime Patterns and Analysis, V2, P17
   McCulloch J, 2005, CURR ISSUES CRIMINAL, V17, P320
   McLafferty S., 2000, ANAL CRIME PATTERNS, P77
   Nie K, 2015, SUSTAINABILITY-BASEL, V7, P2662, DOI 10.3390/su7032662
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Oliveira M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183110
   Precisely company Burlington MA USA, 1995, MAPINFO PRO
   QGIS Development Team, 2021, QGIS Geographic Information System. Open Source Geospatial Foundation Project
   Ratcliffe J.H., 1999, J GEOGRAPHICAL INFOR, V1, P385, DOI DOI 10.1007/S101090050020
   Rosser G, 2017, J QUANT CRIMINOL, V33, P569, DOI 10.1007/s10940-016-9321-x
   Szabo F., 2015, The Linear Algebra Survival Guide: Illustrated with Mathematica
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang DW, 2013, COMPUT ENVIRON URBAN, V39, P93, DOI 10.1016/j.compenvurbsys.2013.01.008
   Weisburd D, 2004, CRIMINOLOGY, V42, P283, DOI 10.1111/j.1745-9125.2004.tb00521.x
   Weisburd D, 2009, J QUANT CRIMINOL, V25, P443, DOI 10.1007/s10940-009-9075-9
   Woodring J, 2009, IEEE T VIS COMPUT GR, V15, P123, DOI 10.1109/TVCG.2008.69
   Zhang L, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P137, DOI 10.1109/CSB.2003.1227313
NR 74
TC 4
Z9 4
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4000
EP 4015
DI 10.1109/TVCG.2021.3111146
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400004
PM 34516376
OA Green Published
DA 2024-11-06
ER

PT J
AU Mikawa, Y
   Sueishi, T
   Watanabe, Y
   Ishikawa, M
AF Mikawa, Yuri
   Sueishi, Tomohiro
   Watanabe, Yoshihiro
   Ishikawa, Masatoshi
TI Dynamic Projection Mapping for Robust Sphere Posture Tracking Using
   Uniform/Biased Circumferential Markers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Cameras; Estimation; Radar tracking; Real-time systems;
   Visualization; Target tracking; Circumferential marker; dynamic
   projection mapping; motion visualization; spatial augmented reality;
   spherical display
ID CAMERA CALIBRATION; CIRCLES
AB In spatial augmented reality, a widely dynamic projection mapping system has been developed as a novel approach to graphics presentation for widely moving objects in dynamic situations. However, this method necessitates a novel tracking marker design that is resistant to random and complex occlusion and out-of-focus blurring, which conventional markers have not achieved. This article presents a uniform circumferential marker that becomes an ellipse in perspective projection and expresses geometric information. It can track the relative posture of a dynamically moving sphere with high speed, high accuracy, and robustness owing to continuous contour lines, thereby supporting both wide-range movement in the depth direction and human interaction. Moreover, a biased circumferential marker is proposed to embed unique coding, where the absolute posture is decoded with a novel recognition algorithm. Moreover, rough initialization using the geometry of multiple ellipses is proposed for both markers to start the automatic and precise tracking. Real-time rotation visualization onto the surface of a moving sphere is made possible with the high-speed, widely dynamic projection mapping system. The tracking performance is demonstrated to exhibit sufficient basic tracking performance as well as robustness against blurring and occlusion compared to conventional dot-based markers.
C1 [Mikawa, Yuri] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.
   [Sueishi, Tomohiro; Ishikawa, Masatoshi] Univ Tokyo, Informat Technol Ctr, Tokyo 1138656, Japan.
   [Watanabe, Yoshihiro] Tokyo Inst Technol, Tokyo 1528550, Japan.
C3 University of Tokyo; University of Tokyo; Institute of Science Tokyo;
   Tokyo Institute of Technology
RP Mikawa, Y (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138656, Japan.
EM yuri_mikawa@ipc.i.u-tokyo.ac.jp; sueishi@ishikawa-vision.org;
   watanabe.y.cl@m.titech.ac.jp; ishikawa@ishikawa-vision.org
FU Grants-in-Aid for Scientific Research [20H05704] Funding Source: KAKEN
CR Abad F, 2004, LECT NOTES COMPUT SC, V3211, P688
   Bagherinia H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P806, DOI 10.1109/ICCVW.2011.6130335
   Bojanova I, 2014, IT PROF, V16, P12, DOI 10.1109/MITP.2014.54
   BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0
   Chen Q, 2004, LECT NOTES COMPUT SC, V3023, P521
   Datta Ankur, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1201, DOI 10.1109/ICCVW.2009.5457474
   Fafard DB, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281540
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Fremont V., 2002, INT C ARTIFICIAL REA, P93
   GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   Ishii I, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1916, DOI 10.1109/ROBOT.1999.770388
   Itoh Y, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875227
   Jiang G, 2005, IEEE I CONF COMP VIS, P333
   Kagami S, 2019, IEEE T VIS COMPUT GR, V25, P3094, DOI 10.1109/TVCG.2019.2932248
   Kim J. J., 2002, Proceedings of the 7th World Congress on Genetics Applied to Livestock Production, Montpellier, France, August, 2002. Session 21, P1
   Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80
   Leach RJ, 2017, MEASUREMENT, V112, P125, DOI 10.1016/j.measurement.2017.08.009
   Li ZQ, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1427, DOI 10.1145/3322276.3322314
   Liu Z, 2017, AER ADV ENG RES, V118, P602
   Luo PF, 2008, OPT ENG, V47, DOI 10.1117/1.2897237
   Ma WJ, 2009, OPT ENG, V48, DOI 10.1117/1.3130213
   Mikawa Y, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102813
   Mikawa Y, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275481
   Miyafuji S, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P33, DOI 10.1145/2992154.2992181
   Mohan A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531404
   Morikubo Y, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275494
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Okumura K, 2015, ADV ROBOTICS, V29, P457, DOI 10.1080/01691864.2015.1011299
   Park H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P272, DOI 10.1109/ISMAR.2004.37
   Soon T.J., 2008, Synth. J., P59
   Sueishi T., 2015, PROC SIGGRAPH ASIA P
   Sueishi T, 2016, PRESENCE-VIRTUAL AUG, V25, P299, DOI 10.1162/PRES_a_00275
   Sueishi Tomohiro, 2020, P AUGM HUM INT C KAI, DOI [10.1145/3384657.3385330, DOI 10.1145/3384657.3385330]
   Suzuki A, 2013, INT SYM MIX AUGMENT, P293, DOI 10.1109/ISMAR.2013.6671811
   Swirski L., 2012, P S EYE TRACK RES AP, P173, DOI DOI 10.1145/2168556.2168585
   Tabata S, 2015, IEEE INT C INT ROBOT, P3900, DOI 10.1109/IROS.2015.7353926
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Uchiyama H, 2011, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2011.5759433
   Watanabe Y, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P52, DOI 10.1109/ISMAR.2017.22
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P319, DOI 10.1016/j.imavis.2005.11.008
   Yamada W, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P635, DOI 10.1145/3126594.3126631
   Zhang BW, 2012, IET IMAGE PROCESS, V6, P870, DOI 10.1049/iet-ipr.2011.0421
   Zhao ZJ, 2014, J OPT SOC AM A, V31, P1186, DOI 10.1364/JOSAA.31.001186
NR 47
TC 6
Z9 6
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4016
EP 4031
DI 10.1109/TVCG.2021.3111085
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400005
PM 34516375
DA 2024-11-06
ER

PT J
AU Zhao, DY
   Li, YJ
   Chaudhuri, S
   Langlois, T
   Barbic, J
AF Zhao, Danyong
   Li, Yijing
   Chaudhuri, Siddhartha
   Langlois, Timothy
   Barbic, Jernej
TI ERGOBOSS: Ergonomic Optimization of Body-Supporting Surfaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ergonomics; CAD; optimization; shape design; FEM; contact; 3D printing
ID SITTING COMFORT; DISCOMFORT; MODELS; CONTACT; COMPLEX; DESIGN
AB Humans routinely sit or lean against supporting surfaces and it is important to shape these surfaces to be comfortable and ergonomic. We give a method to design the geometric shape of rigid supporting surfaces to maximize the ergonomics of physically based contact between the surface and a deformable human. We model the soft deformable human using a layer of FEM deformable tissue surrounding a rigid core, with measured realistic elastic material properties, and large-deformation nonlinear analysis. We define a novel cost function to measure the ergonomics of contact between the human and the supporting surface. We give a stable and computationally efficient contact model that is differentiable with respect to the supporting surface shape. This makes it possible to optimize our ergonomic cost function using gradient-based optimizers. Our optimizer produces supporting surfaces superior to prior work on ergonomic shape design. Our examples include furniture, apparel and tools. We also validate our results by scanning a real human subject's foot and optimizing a shoe sole shape to maximize foot contact ergonomics. We 3D-print the optimized shoe sole, measure contact pressure using pressure sensors, and demonstrate that the real unoptimized and optimized pressure distributions qualitatively match those predicted by our simulation.
C1 [Zhao, Danyong; Li, Yijing; Barbic, Jernej] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
   [Chaudhuri, Siddhartha] Adobe Syst Inc, Adobe Res, San Jose, CA 95110 USA.
   [Langlois, Timothy] Adobe Res, San Jose, CA 95110 USA.
C3 University of Southern California; Adobe Systems Inc.; Adobe Systems
   Inc.
RP Barbic, J (corresponding author), Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
EM danyongz@usc.edu; yijingl@usc.edu; sidch@adobe.com; tlangloi@adobe.com;
   jnb@usc.edu
RI ZHAO, DANYONG/HNP-0495-2023
OI ZHAO, DANYONG/0000-0003-0714-5715
CR AljaSafe, 2020, SMOOTHON INC
   Artec3D, 2018, EV SCANN
   Artec3D, 2018, SPID SCANN
   Bächer M, 2017, COMMUN ACM, V60, P92, DOI 10.1145/3068766
   Barbic J, 2008, IEEE T HAPTICS, V1, P39, DOI 10.1109/ToH.2008.1
   Baudisch Patrick, 2017, Foundations and Trends in Human-Computer Interaction, V10, P165, DOI 10.1561/1100000055
   Bendsoe MP, 2004, Topology Optimization: Theory, Methods, and Applications
   Brochu T, 2009, SIAM J SCI COMPUT, V31, P2472, DOI 10.1137/080737617
   Bucki M, 2016, MED ENG PHYS, V38, P845, DOI 10.1016/j.medengphy.2016.04.017
   Cani-Gascuel MP, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P201
   Chadwick J. E., 1989, Computer Graphics, V23, P243, DOI 10.1145/74334.74358
   Chaudhuri S, 2020, COMPUT GRAPH FORUM, V39, P643, DOI 10.1111/cgf.14020
   Chen D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073669
   de Looze MP, 2003, ERGONOMICS, V46, P985, DOI 10.1080/0014013031000121977
   FujiFilm, 2020, FUJ PRESC PRES MEAS
   Galoppo N., 2006, Proc. Symp. on Computer Animation, P73
   Galoppo N, 2007, COMPUT GRAPH FORUM, V26, P243, DOI 10.1111/j.1467-8659.2007.01046.x
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Hu RZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201287
   Irving G., 2004, P ACM SIGGRAPH EUR S, P131, DOI DOI 10.1145/1028523.1028541
   James D., 2008, HAPTIC RENDERING FDN, P395
   Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385
   Kikuuwe R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477934
   Kim M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073685
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Kyung G, 2008, INT J IND ERGONOM, V38, P526, DOI 10.1016/j.ergon.2007.08.011
   Kyung G, 2009, ERGONOMICS, V52, P939, DOI 10.1080/00140130902763552
   Langlois T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982436
   Leimer K, 2020, COMPUT AIDED GEOM D, V79, DOI 10.1016/j.cagd.2020.101855
   Leimer K, 2018, COMPUT GRAPH FORUM, V37, P349, DOI 10.1111/cgf.13573
   Liang J., 2019, Advances in Neural Information Processing Systems, P771
   Liu H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201344
   Luboz V, 2018, J TISSUE VIABILITY, V27, P54, DOI 10.1016/j.jtv.2017.06.002
   METAXAS D, 1992, COMP GRAPH, V26, P309, DOI 10.1145/142920.134085
   Miguel E, 2012, COMPUT GRAPH FORUM, V31, P519, DOI 10.1111/j.1467-8659.2012.03031.x
   Montes J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392477
   Pai DK, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201296
   Pauly M., 2004, Eurographics/SIGGRAPH Symposium on Computer Animation, P109, DOI 10.1145/1028523.1028539
   Pérez J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766998
   Préost R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461957
   Press W. H., 1992, Numerical recipes in c, V2nd ed.
   Putz-Anderson V, 1997, 97141 NIOSH
   Romero C, 2020, COMPUT GRAPH FORUM, V39, P77, DOI 10.1111/cgf.13913
   Saul G, 2011, TEI 2011: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION, P73
   Savonnet L, 2018, COMPUT METHOD BIOMEC, V21, P379, DOI 10.1080/10255842.2018.1466117
   Shugrina M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766994
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Tekscan, 2020, TEKSCAN
   TERZOPOULOS D, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.20317
   TurboSquid, 2020, TURBOSQUID
   U. G. S. Administration, 2020, ERG SEAT ADJ GUID
   Ulu E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073626
   Umetani N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601129
   Umetani N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185582
   van Dijk NP, 2013, STRUCT MULTIDISCIP O, V48, P437, DOI 10.1007/s00158-013-0912-y
   Wang L., 2016, Computer Graphics Forum, V35, P49, DOI 10.1111/cgf.12810
   Wang Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766952
   Wang ZQ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356489
   Yumer ME, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766908
   Zheng YY, 2016, IEEE T VIS COMPUT GR, V22, P1732, DOI 10.1109/TVCG.2015.2448084
NR 61
TC 2
Z9 2
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4032
EP 4047
DI 10.1109/TVCG.2021.3112127
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400006
PM 34520357
DA 2024-11-06
ER

PT J
AU Yuan, LP
   Zeng, W
   Fu, SW
   Zeng, ZL
   Li, HT
   Fu, CW
   Qu, HM
AF Yuan, Lin-Ping
   Zeng, Wei
   Fu, Siwei
   Zeng, Zhiliang
   Li, Haotian
   Fu, Chi-Wing
   Qu, Huamin
TI Deep Colormap Extraction From Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Color extraction; information visualization; deep learning; color
   histogram
ID INFORMATION; UNIVARIATE; SEQUENCES; SCHEMES
AB This article presents a new approach based on deep learning to automatically extract colormaps from visualizations. After summarizing colors in an input visualization image as a Lab color histogram, we pass the histogram to a pre-trained deep neural network, which learns to predict the colormap that produces the visualization. To train the network, we create a new dataset of similar to 64K visualizations that cover a wide variety of data distributions, chart types, and colormaps. The network adopts an atrous spatial pyramid pooling module to capture color features at multiple scales in the input color histograms. We then classify the predicted colormap as discrete or continuous, and refine the predicted colormap based on its color histogram. Quantitative comparisons to existing methods show the superior performance of our approach on both synthetic and real-world visualizations. We further demonstrate the utility of our method with two use cases, i.e., color transfer and color remapping.
C1 [Yuan, Lin-Ping; Li, Haotian; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Zeng, Wei] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 510070, Guangdong, Peoples R China.
   [Fu, Siwei] Zhejiang Lab, Hangzhou 311121, Peoples R China.
   [Zeng, Zhiliang; Fu, Chi-Wing] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS; Zhejiang
   Laboratory; Chinese University of Hong Kong
RP Zeng, W (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 510070, Guangdong, Peoples R China.
EM lyuanaa@connect.ust.hk; wei.zeng@siat.ac.cn; fusiwei339@gmail.com;
   zlzeng@cse.cuhk.edu.hk; haotian.li@connect.ust.hk; cwfu@cse.cuhk.edu.hk;
   huamin@cse.ust.hk
RI Fu, Chi-Wing/X-4703-2019
OI Li, Haotian/0000-0001-9547-3449; Yuan, Linping/0000-0001-6268-1583; Fu,
   Chi Wing/0000-0002-5238-593X; Zeng, Zhiliang/0000-0002-6538-2340; Zeng,
   Wei/0000-0002-5600-8824
FU National Natural Science Foundation of China [61802388]; SIAT Innovation
   Program for Excellent Young Researchers
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported in part by the National
   Natural Science Foundation of China under Grant 61802388 and in part by
   the SIAT Innovation Program for Excellent Young Researchers.
CR [Anonymous], D3 SCALE CHROMATIC
   Bernard J, 2015, PROC SPIE, V9397, DOI 10.1117/12.2079841
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Card SK., 1999, READINGS INFORM VISU
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Cheng SH, 2019, IEEE T VIS COMPUT GR, V25, P1361, DOI 10.1109/TVCG.2018.2808489
   coloplast, About us
   Colorbrewer2, US
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Irony R., 2005, Rendering techniques, P201
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Mittelstadt S., 2015, THESIS U KONSTANZ GE
   Mittelstädt S, 2014, COMPUT GRAPH FORUM, V33, P231, DOI 10.1111/cgf.12379
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Gowda SN, 2019, Arxiv, DOI arXiv:1902.00267
   Nardini P, 2021, IEEE T VIS COMPUT GR, V27, P3048, DOI 10.1109/TVCG.2019.2961674
   Pan JC, 2021, IEEE T VIS COMPUT GR, V27, P1655, DOI 10.1109/TVCG.2020.3030393
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   ROBERTSON PK, 1986, IEEE COMPUT GRAPH, V6, P24, DOI 10.1109/MCG.1986.276688
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   Tan JC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275054
   Tan JC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2988229
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Wang QW, 2021, Arxiv, DOI [arXiv:2012.00467, 10.1109/TVCG.2021.3106142, DOI 10.1109/TVCG.2021.3106142]
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P647, DOI 10.1109/TVCG.2017.2745859
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Ware C, 2010, Visual thinking for design
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Wu A., 2021, PROC ACM C HUM FACTO
   Wu Aoyu., 2021, AI4VIS: Survey on Artificial Intelligence Approaches for Data Visualization
   Wu ZH, 2019, Arxiv, DOI arXiv:1901.00596
   Yoo MJ, 2015, COMPUT GRAPH FORUM, V34, P373, DOI 10.1111/cgf.12567
   Yuan L.-P., 2021, ARXIV
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang Q, 2017, IEEE T IMAGE PROCESS, V26, P1952, DOI 10.1109/TIP.2017.2671779
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 61
TC 9
Z9 9
U1 7
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4048
EP 4060
DI 10.1109/TVCG.2021.3070876
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400007
PM 33819157
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Dewe, H
   Gottwald, JM
   Bird, LA
   Brenton, H
   Dillies, M
   Cowie, D
AF Dewe, Hayley
   Gottwald, Janna M.
   Bird, Laura-Ashleigh
   Brenton, Harry
   Dillies, Marco
   Cowie, Dorothy
TI My Virtual Self: The Role of Movement in Children's Sense of Embodiment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Rubber; Task analysis; Correlation; Robot sensing
   systems; Legged locomotion; Headphones; Agency; body ownership;
   embodiment; synchronous integration; psychology; user interaction;
   virtual reality
ID RUBBER-HAND ILLUSION; MULTISENSORY INTEGRATION; BODY REPRESENTATION;
   ILLUSORY OWNERSHIP; PERCEPTION; AGENCY; SKIN; RECALIBRATION;
   CONTINGENCY; EXPERIENCE
AB There are vast potential applications for children's entertainment and education with modern virtual reality (VR) experiences, yet we know very little about how the movement or form of such a virtual body can influence children's feelings of control (agency) or the sensation that they own the virtual body (ownership). In two experiments, we gave a total of 197 children aged 4-14 years a virtual hand which moved synchronously or asynchronously with their own movements and had them interact with a VR environment. We found that movement synchrony influenced feelings of control and ownership at all ages. In Experiment 1 only, participants additionally felt haptic feedback either congruently, delayed or not at all - this did not influence feelings of control or ownership. In Experiment 2 only, participants used either a virtual hand or non-human virtual block. Participants embodied both forms to some degree, provided visuomotor signals were synchronous (as indicated by ownership, agency, and location ratings). Yet, only the hand in the synchronous movement condition was described as feeling like part of the body, rather than like a tool (e.g., a mouse or controller). Collectively, these findings highlight the overall dominance of visuomotor synchrony for children's own-body representation; that children can embody non-human forms to some degree; and that embodiment is also somewhat constrained by prior expectations of body form.
C1 [Dewe, Hayley; Cowie, Dorothy] Univ Durham, Durham DH1 3LE, England.
   [Gottwald, Janna M.] Uppsala Univ, SE-75105 Uppsala, Sweden.
   [Bird, Laura-Ashleigh] UCL, London WC1E 6BT, England.
   [Brenton, Harry] Bespoke VR, London EC2A 4NE, England.
   [Dillies, Marco] Goldsmiths Univ London, London SE14 6NW, England.
C3 Durham University; Uppsala University; University of London; University
   College London; University of London; Goldsmiths University London
RP Dewe, H (corresponding author), Univ Durham, Durham DH1 3LE, England.; Gottwald, JM (corresponding author), Uppsala Univ, SE-75105 Uppsala, Sweden.
EM hayley.l.dewe@durham.ac.uk; janna.gottwald@psyk.uu.se; l.bird@ucl.ac.uk;
   harry@bespokevr.com; m.gillies@gold.ac.uk; dorothy.cowie@durham.ac.uk
RI Gottwald, Janna/I-1140-2019
OI Gillies, Marco/0000-0002-3100-9230; Gottwald, Janna/0000-0001-5497-4001;
   Bird, Laura-Ashleigh/0000-0002-1701-7912; Dewe,
   Hayley/0000-0003-1757-0432
FU Economic and Social Research Council [ES/P008798/1]; Swedish Research
   Council [VR-PG 2017-01504]; ESRC [ES/P008798/1] Funding Source: UKRI
FX The work of Hayley Dewe, Janna M. Gottwald and Dorothy Cowiewas
   supported by Economic and Social Research Council under Grant ESRC,
   ES/P008798/1. The work of Janna M. Gottwald was supported by Swedish
   Research Council under Grant VR-PG 2017-01504. The authors wish to thank
   Prof. Lynda Boothroyd for guidance on statistical analyses; the children
   who volunteered for these experiments; and the Life Science Centre in
   Newcastle, U.K. for hosting us. *Dr Dewe and Dr Gottwald contributed
   equally to the work and correspondence should be addressed to either.
CR Adams H, 2018, IEEE T VIS COMPUT GR, V24, P1408, DOI 10.1109/TVCG.2018.2794072
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Aymerich-Franch L, 2017, INT J SOC ROBOT, V9, P479, DOI 10.1007/s12369-017-0397-8
   Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Bahrick LE, 2013, CURR BIOL, V23, pR1039, DOI 10.1016/j.cub.2013.10.060
   BAHRICK LE, 1985, DEV PSYCHOL, V21, P963, DOI 10.1037/0012-1649.21.6.963
   Bailey JO, 2019, J APPL DEV PSYCHOL, V64, DOI 10.1016/j.appdev.2019.101052
   Bailey JO, 2017, COGNITIVE DEVELOPMENT IN DIGITAL CONTEXTS, P181, DOI 10.1016/B978-0-12-809481-5.00009-2
   Bailey JO, 2017, J CHILD MEDIA, V11, P107, DOI 10.1080/17482798.2016.1268779
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Braithwaite JJ, 2017, J EXP PSYCHOL HUMAN, V43, P1125, DOI 10.1037/xhp0000406
   Braithwaite JJ, 2014, J EXP PSYCHOL HUMAN, V40, P1131, DOI 10.1037/a0036077
   Bremner AJ, 2013, HAND, AN ORGAN OF THE MIND: WHAT THE MANUAL TELLS THE MENTAL, P27
   Corbetta D, 2009, INFANT BEHAV DEV, V32, P44, DOI 10.1016/j.infbeh.2008.10.004
   Cowie D, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12557
   Cowie D, 2016, J EXP CHILD PSYCHOL, V142, P230, DOI 10.1016/j.jecp.2015.10.003
   Cowie D, 2013, PSYCHOL SCI, V24, P762, DOI 10.1177/0956797612462902
   de Haan AM, 2018, J EXP CHILD PSYCHOL, V175, P48, DOI 10.1016/j.jecp.2018.05.002
   Delafield-Butt JT, 2018, DEVELOPMENTAL SCI, V21, DOI 10.1111/desc.12693
   Ehrsson H.H., 2012, HDB MULTISENSORY PRO, P775
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Filippetti ML, 2019, J EXP CHILD PSYCHOL, V185, P191, DOI 10.1016/j.jecp.2019.04.016
   Filippetti ML, 2013, CURR BIOL, V23, P2413, DOI 10.1016/j.cub.2013.10.017
   Freeman D, 2018, LANCET PSYCHIAT, V5, P625, DOI 10.1016/S2215-0366(18)30226-8
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gottwald JM, 2021, CHILD DEV, V92, P351, DOI 10.1111/cdev.13425
   Haans A, 2008, BODY IMAGE, V5, P389, DOI 10.1016/j.bodyim.2008.04.003
   Hoffman HG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00262
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Keenaghan S., ALICE WONDERLAND EFF, DOI [10.31234/osf.io/uw768, DOI 10.31234/OSF.IO/UW768]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI DOI 10.1145/2931002.2931006
   Litwin P, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0244594
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Longo MR, 2009, PERCEPTION, V38, P69, DOI 10.1068/p6045
   Ma K, 2015, CONSCIOUS COGN, V36, P75, DOI 10.1016/j.concog.2015.06.003
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Miller LE, 2017, EXP BRAIN RES, V235, P2917, DOI 10.1007/s00221-017-5028-y
   Morgan R, 1997, ECOL PSYCHOL, V9, P1, DOI 10.1207/s15326969eco0901_1
   Morrongiello BA, 2016, J PEDIATR PSYCHOL, V41, P265, DOI 10.1093/jpepsy/jsv078
   Nava E, 2017, PSYCHOL SCI, V28, P330, DOI 10.1177/0956797616682464
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   R. C. Team,, R PROJECT STAT COMPU
   Rochat P, 1998, EXP BRAIN RES, V123, P102, DOI 10.1007/s002210050550
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Roussou M, 2009, IEEE COMPUT GRAPH, V29, P82, DOI 10.1109/MCG.2009.1
   ROVEE CK, 1969, J EXP CHILD PSYCHOL, V8, P33, DOI 10.1016/0022-0965(69)90025-3
   S. R. Department, 2020, STAT ACT VIRT REAL U
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schneider BA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00474
   Segovia KY, 2009, MEDIA PSYCHOL, V12, P371, DOI 10.1080/15213260903287267
   Sethi AK, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2011.00395
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Smith LB, 2011, DEVELOPMENTAL SCI, V14, P9, DOI 10.1111/j.1467-7687.2009.00947.x
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Thelen E., 1996, A dynamic systems approach to the development of cognition and action
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P2740, DOI 10.1016/j.neuropsychologia.2010.05.021
   Tsakiris M, 2010, EXP BRAIN RES, V204, P343, DOI 10.1007/s00221-009-2039-3
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3_1
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zmyj N, 2011, COGNITION, V120, P82, DOI 10.1016/j.cognition.2011.03.001
   Zoia S, 2007, EXP BRAIN RES, V176, P217, DOI 10.1007/s00221-006-0607-3
NR 88
TC 8
Z9 8
U1 3
U2 33
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4061
EP 4072
DI 10.1109/TVCG.2021.3073906
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400008
PM 33872150
OA Green Accepted, Green Published
DA 2024-11-06
ER

PT J
AU Wang, WC
   Wang, SC
AF Wang, Wencheng
   Wang, Shengchun
TI Efficient Point-in-Polygon Tests by Grids Without the Trouble of Tuning
   the Grid Resolutions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point-in-polygon tests; grid; ray crossing
ID INCLUSION TEST; SETS
AB The grid-based approach is popular for point-in-polygon tests. However, there is a trade-off between the preprocessing and the inclusion test, which always requires the grid resolutions to be tuned. In this article, we address this challenge by enhancing the grid structure using y-axis-aligned stripes, which are formed by the y-axis-aligned lines passing through the endpoints of the edge segments in the cell, thereby managing the edge segments in each grid cell. Moreover, we precompute the inclusion properties of the x -axis-aligned top borders of the stripes during preprocessing. Therefore, to answer a query point with the ray crossing method, we can emit a ray from the point to propagate upwards until the ray arrives at the top border of a stripe. We thoroughly consider singular cases to guarantee each query point can be answered in the stripe that contains the point. In our method, the computational load can be decreased, as one coordinate of the intersection point between the ray and an edge is known in advance, and parallel computing can be well exploited because the branching operations for determining whether an edge intersects with the ray are saved. Experimental results show that the efficiency of our method does not vary much with respect to the grid resolutions, so the trouble of tuning grid resolutions can be avoided. Ultimately, our method with a low grid resolution can reduce the preprocessing time and still achieve a higher inclusion test efficiency than the existing methods with a high grid resolution, especially on GPUs.
C1 [Wang, Wencheng; Wang, Shengchun] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
   [Wang, Wencheng; Wang, Shengchun] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
EM whn@ios.ac.cn; wangsc@ios.ac.cn
RI Wang, Wencheng/A-3828-2009
OI wang, wen cheng/0000-0001-5094-4606; wang, sheng
   chun/0000-0002-7386-581X
FU National Natural Science Foundation of China [62072446, 61872348]
FX The authors would like to thanks to the anonymous reviewers for their
   constructive comments and suggestions. It is appreciated the help from
   Dr. Jing Li and Mr. Shuai Ma on implementation and experiments. This
   work was supported in part by the National Natural Science Foundation of
   China under Grant 62072446 and 61872348.
CR Cleary J. G., 1988, Visual Computer, V4, P65, DOI 10.1007/BF01905559
   de Berg M., 2008, Computational Geometry: Algorithms and Applications, DOI DOI 10.1007/978-3-540-77974-2
   FEITO F, 1995, COMPUT GRAPH, V19, P595, DOI 10.1016/0097-8493(95)00037-D
   Feito FR, 1997, COMPUT GRAPH, V21, P23, DOI 10.1016/S0097-8493(96)00067-2
   Haines E., 1994, GRAPHICS GEMS, P24
   Hormann K, 2001, COMP GEOM-THEOR APPL, V20, P131, DOI 10.1016/S0925-7721(01)00012-8
   Hughes J.F., 2014, Computer Graphics: Principles and Practice
   Jiménez JJ, 2009, COMPUT GEOSCI-UK, V35, P1843, DOI 10.1016/j.cageo.2008.09.013
   Li J., 2014, INT J ELECT ENG, V21, P85
   Li J, 2007, COMPUT GRAPH-UK, V31, P636, DOI 10.1016/j.cag.2007.03.002
   Li J, 2017, COMPUT AIDED DESIGN, V87, P20, DOI 10.1016/j.cad.2017.02.001
   Li Jing, 2012, Journal of Software, V23, P2481, DOI 10.3724/SP.J.1001.2012.04087
   Preparata F.P., 2012, Computational Geometry: An Introduction
   Rueda AJ, 2011, IEEE T VIS COMPUT GR, V17, P1325, DOI 10.1109/TVCG.2010.246
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Taylor G., 1994, Surv. Rev, V32, P479, DOI [DOI 10.1179/SRE.1994.32.254.479, 10.1179/sre.1994.32.254.479]
   Wang WC, 2005, COMPUT GRAPH-UK, V29, P427, DOI 10.1016/j.cag.2005.03.001
   Yang S, 2010, COMPUT GEOSCI-UK, V36, P205, DOI 10.1016/j.cageo.2009.06.008
   Zalik B, 2003, COMPUT GRAPH-UK, V27, P791, DOI 10.1016/S0097-8493(03)00151-1
   Zalik B, 2001, COMPUT GEOSCI-UK, V27, P1135, DOI 10.1016/S0098-3004(01)00037-1
NR 20
TC 2
Z9 2
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4073
EP 4084
DI 10.1109/TVCG.2021.3073919
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400009
PM 33872151
DA 2024-11-06
ER

PT J
AU Li, Q
   Wei, XG
   Lin, HB
   Liu, Y
   Chen, TJ
   Ma, XJ
AF Li, Quan
   Wei, Xiguang
   Lin, Huanbin
   Liu, Yang
   Chen, Tianjian
   Ma, Xiaojuan
TI Inspecting the Running Process of Horizontal Federated Learning via
   Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Data visualization; Training; Predictive models; Analytical
   models; Computational modeling; Servers; Federated learning; anomaly
   detection; contribution assessment; visualization
AB As a decentralized training approach, horizontal federated learning (HFL) enables distributed clients to collaboratively learn a machine learning model while keeping personal/private information on local devices. Despite the enhanced performance and efficiency of HFL over local training, clues for inspecting the behaviors of the participating clients and the federated model are usually lacking due to the privacy-preserving nature of HFL. Consequently, the users can only conduct a shallow-level analysis of potential abnormal behaviors and have limited means to assess the contributions of individual clients and implement the necessary intervention. Visualization techniques have been introduced to facilitate the HFL process inspection, usually by providing model metrics and evaluation results as a dashboard representation. Although the existing visualization methods allow a simple examination of the HFL model performance, they cannot support the intensive exploration of the HFL process. In this article, strictly following the HFL privacy-preserving protocol, we design an exploratory visual analytics system for the HFL process termed HFLens, which supports comparative visual interpretation at the overview, communication round, and client instance levels. Specifically, the proposed system facilitates the investigation of the overall process involving all clients, the correlation analysis of clients' information in one or different communication round(s), the identification of potential anomalies, and the contribution assessment of each HFL client. Two case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps in understanding and diagnosing the HFL process better.
C1 [Li, Quan] Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Wei, Xiguang] Shenzhen Semacare Med Technol Co Ltd, AI Dept, Shenzhen 518118, Guangdong, Peoples R China.
   [Lin, Huanbin; Liu, Yang; Chen, Tianjian] WeBank, AI Grp, Shenzhen 518052, Guangdong, Peoples R China.
   [Ma, Xiaojuan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
C3 ShanghaiTech University; Hong Kong University of Science & Technology
RP Li, Q (corresponding author), Shanghai Tech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
EM liquan@shanghaitech.edu.cn; marcus@semacare.com; bindylin@webank.com;
   yangliu@webank.com; tobychen@webank.com; mxj@cse.ust.hk
RI wei, xiguang/AAL-5410-2021
OI Li, Quan/0000-0003-2249-0728
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [C6030-18G]
FX The authors would like to thank the valuable feedback and comments
   provided by Prof. Qiang Yang and the anonymous reviewers. This work was
   supported by the Research Grants Council of the Hong Kong Special
   Administrative Region, China, under Grant C6030-18G.
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Berlingerio Michele., 2012, CORR
   Bhagoji AN, 2019, PR MACH LEARN RES, V97
   Bochkovskiy A, YOLOV4 OPTIMAL SPEED
   Bonawitz K., 2019, ARXIV, V1, P374
   Caldas S., 2018, ARXIV
   Caldas S., 2018, P SYSML C, P1
   Chenoweth JM, 2016, FLA MUS NAT HIST-RIP, P1
   Du W., 2018, OPENREVIEW NET, P1
   Fan T., 2018, FATE BOARD FATES VIS, P1
   Fedai, 2019, Computer vision Platform powered by Federated Learning
   Federico P, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P179, DOI 10.1109/ASONAM.2012.39
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao DS, 2020, Arxiv, DOI arXiv:1909.05784
   Geyer RC, 2017, ARXIV PREPRINT ARXIV
   Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Hard A, 2018, ARXIV
   Hardy S., 2017, ARXIV
   Hastie T., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, P9, DOI DOI 10.1007/978-0-387-84858-7
   Heimerl F, 2018, COMPUT GRAPH FORUM, V37, P253, DOI 10.1111/cgf.13417
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Huang L, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103291
   Huang Li, 2018, ARXIV
   Ilias C, 2019, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY (ICISSP), P544, DOI 10.5220/0007571705440551
   Kang JW, 2019, 2019 IEEE VTS ASIA PACIFIC WIRELESS COMMUNICATIONS SYMPOSIUM (APWCS 2019), DOI 10.1109/vts-apwcs.2019.8851649
   Kim M., 2016, ARXIV
   Kleinbaum D.G., 2002, Logistic regression
   Konecn J., 2016, ARXIV
   LeCun Y., 2015, Lenet-5, convolutional neural networks, V20, P14
   Lee J, 2018, JMIR MED INF, V6, P4, DOI 10.2196/medinform.7744
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Li Q, 2017, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2017.8031576
   Li SY, 2019, Arxiv, DOI arXiv:1910.09933
   Li WQ, 2019, LECT NOTES COMPUT SC, V11861, P133, DOI 10.1007/978-3-030-32692-0_16
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Lundberg SM, 2017, ADV NEUR IN, V30
   McLachlan P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1483
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mike, 2018, FED LEARN DISTR MACH
   Ming, 2017, THESIS HONG KONG U S
   Molnar C., 2020, Lulu. com
   Munroe R., 2009, Movie narrative charts
   Nock R., 2018, ARXIV
   Olden JD, 2002, ECOL MODEL, V154, P135, DOI 10.1016/S0304-3800(02)00064-9
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Redmon J, 2018, Arxiv, DOI arXiv:1804.02767
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rojek M., 2018, DEVICES LEARNING EAC, P7
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Smilkov D., 2016, ARXIV
   Wang G. R., 2019, ARXIV
   Wei XG, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6572
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xiao H., 2017, FASHION MNIST NOVEL
   y J. Konecn., 2016, arXiv
   Yang Q., 2019, ACM T INTEL SYST TEC, V10, p12:1, DOI DOI 10.1145/3298981
   Zhu L., 2019, P NEUR INF PROC SYST
   Zhuo HH, 2019, ARXIV
NR 65
TC 8
Z9 10
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4085
EP 4100
DI 10.1109/TVCG.2021.3074010
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400010
PM 33872152
OA Green Published
DA 2024-11-06
ER

PT J
AU Dimara, E
   Zhang, H
   Tory, M
   Franconeri, S
AF Dimara, Evanthia
   Zhang, Harry
   Tory, Melanie
   Franconeri, Steven
TI The Unmet Data Visualization Needs of Decision Makers Within
   Organizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Decision making; Organizations; Tools; Task
   analysis; Data analysis; Uncertainty; Decision making; visualization;
   interview; survey; organizations; management; business intelligence
ID INFORMATION VISUALIZATION; COMMUNICATION; ATTENTION; CULTURE
AB When an organization chooses one course of action over alternatives, this task typically falls on a decision maker with relevant knowledge, experience, and understanding of context. Decision makers rely on data analysis, which is either delegated to analysts, or done on their own. Often the decision maker combines data, likely uncertain or incomplete, with non-formalized knowledge within a multi-objective problem space, weighing the recommendations of analysts within broader contexts and goals. As most past research in visual analytics has focused on understanding the needs and challenges of data analysts, less is known about the tasks and challenges of organizational decision makers, and how visualization support tools might help. Here we characterize the decision maker as a domain expert, review relevant literature in management theories, and report the results of an empirical survey and interviews with people who make organizational decisions. We identify challenges and opportunities for novel visualization tools, including trade-off overviews, scenario-based analysis, interrogation tools, flexible data input and collaboration support. Our findings stress the need to expand visualization design beyond data analysis into tools for information management.
C1 [Dimara, Evanthia] Univ Utrecht, NL-3584 CS Utrecht, Netherlands.
   [Dimara, Evanthia] Univ Konstanz, D-78464 Constance, Germany.
   [Zhang, Harry; Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
   [Tory, Melanie] Tableau Software, Palo Alto, CA 94306 USA.
C3 Utrecht University; University of Konstanz; Northwestern University
RP Dimara, E (corresponding author), Univ Utrecht, NL-3584 CS Utrecht, Netherlands.
EM evanthia.dimara@gmail.com; haochi.zhang@kellogg.northwestern.edu;
   melanie.tory@gmail.com; franconeri@northwestern.edu
OI Tory, Melanie/0000-0002-6806-9253; Zhang, Harry/0000-0002-3576-0363;
   Franconeri, Steven/0000-0001-5244-9764; Dimara,
   Evanthia/0000-0001-5212-7888
FU European Union's Horizon 2020 Research and Innovation Program [825041];
   H2020 - Industrial Leadership [825041] Funding Source: H2020 -
   Industrial Leadership
FX The authors would like to thank J. Stasko, D. Keim, and DBVIS Team for
   their helpful feedback, and our participants for their time and
   insightful discussions. This work was supported by the European Union's
   Horizon 2020 Research and Innovation Program under Grant 825041.
CR Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Asahi T, 1995, INFORM SYST RES, V6, P357, DOI 10.1287/isre.6.4.357
   Aseniero BA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1479, DOI 10.1145/2702123.2702426
   Batch A, 2018, IEEE T VIS COMPUT GR, V24, P278, DOI 10.1109/TVCG.2017.2743990
   BEATTY RP, 1994, ADMIN SCI QUART, V39, P313, DOI 10.2307/2393238
   Behrisch M, 2019, IEEE T VIS COMPUT GR, V25, P3011, DOI 10.1109/TVCG.2018.2859973
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   BROWN AD, 1994, J MANAGE STUD, V31, P807, DOI 10.1111/j.1467-6486.1994.tb00640.x
   Carenini G., 2004, P WORK C ADV VIS INT, P150
   Choo CW, 2008, J AM SOC INF SCI TEC, V59, P792, DOI 10.1002/asi.20797
   Clement J, 2018, MANAGE SCI, V64, P3879, DOI 10.1287/mnsc.2017.2807
   COHEN MD, 1972, ADMIN SCI QUART, V17, P1, DOI 10.2307/2392088
   Cornelissen JP, 2014, ACAD MANAG ANN, V8, P181, DOI 10.1080/19416520.2014.875669
   Crandall B., 2006, WORKING MINDSA PRACT
   Cyert R. M., 1963, A Behavioral Theory of the Firm
   Dane E, 2007, ACAD MANAGE REV, V32, P33, DOI [10.2307/20159279, 10.5465/AMR.2007.23463682]
   DIMAGGIO PJ, 1983, AM SOCIOL REV, V48, P147, DOI 10.2307/2095101
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Dimara E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5475, DOI 10.1145/3025453.3025870
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Eppler MJ, 2004, INFORM SOC, V20, P325, DOI 10.1080/01972240490507974
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Fligstein N, 1997, AM BEHAV SCI, V40, P397, DOI 10.1177/0002764297040004003
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guetzkow H, 1955, MANAGE SCI, V1, P233, DOI 10.1287/mnsc.1.3-4.233
   HUBER GP, 1986, MANAGE SCI, V32, P572, DOI 10.1287/mnsc.32.5.572
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Joseph J, 2012, STRATEGIC MANAGE J, V33, P633, DOI 10.1002/smj.1971
   Kalleberg AL, 1996, AM SOCIOL REV, V61, P47, DOI 10.2307/2096406
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kandogan E, 2014, IEEE COMPUT GRAPH, V34, P42, DOI 10.1109/MCG.2014.62
   Keim DA, 2006, INFORMATION VISUALIZATION-BOOK, P9
   Kim M, 2016, PROC INT CONF SOFTW, P96, DOI 10.1145/2884781.2884783
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Kinkeldey C, 2017, CARTOGR GEOGR INF SC, V44, P1, DOI 10.1080/15230406.2015.1089792
   LAUGHLIN PR, 1980, J PERS SOC PSYCHOL, V38, P941, DOI 10.1037/0022-3514.38.6.941
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Madanagopal K, 2019, IEEE COMPUT GRAPH, V39, P30, DOI 10.1109/MCG.2019.2933419
   March J. G., 1958, Organizations
   MEYER JW, 1977, AM J SOCIOL, V83, P340, DOI 10.1086/226550
   Mosca A., 2019, P 21 EUR C VIS, P73
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nelson R. R., 1982, EVOL THEOR
   Newell A., 1972, Human Problem Solving
   Ocasio W, 1997, STRATEGIC MANAGE J, V18, P187, DOI 10.1002/(SICI)1097-0266(199707)18:1+<187::AID-SMJ936>3.3.CO;2-B
   Ocasio W, 1999, ADMIN SCI QUART, V44, P532, DOI 10.2307/2666961
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Padilla LMK, 2020, IEEE T VIS COMPUT GR, V26, P332, DOI 10.1109/TVCG.2019.2934286
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   PFEFFER J, 1974, ADMIN SCI QUART, V19, P135, DOI 10.2307/2393885
   Rees D, 2019, COMPUT GRAPH FORUM, V38, P610, DOI 10.1111/cgf.13595
   Rivkin JW, 2003, MANAGE SCI, V49, P290, DOI 10.1287/mnsc.49.3.290.12740
   Russell D. M., 2016, AVI, P7, DOI [DOI 10.1145/2909132.29332876, 10.1145/2909132.29332878, DOI 10.1145/2909132.29332878]
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Savikhin A., 2011, S2011 44 HAWAII INT, P1, DOI [10.1109/HICSS.2011.54, DOI 10.1109/HICSS.2011.54]
   Sedlmair M., 2010, PROC WORKSHOP TIME E, P79, DOI [DOI 10.1145/2110192.2110204, 10.1145/2110192.21102042,8, DOI 10.1145/2110192.21102042,8]
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Simon H. A., 1960, The New Science of Management Decision
   Simon H. A., 1947, Administrative behavior: A study of decision-making processes in administrative organizations, V4th ed.
   SPARROW PR, 1988, PSYCHOL AGING, V3, P307, DOI 10.1037/0882-7974.3.3.307
   Spence R., 2014, Information Visualization: An Introduction
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Ward M.O., 2015, INTERACTIVE DATA VIS
   Ware C., 2013, Information Visualization
   Weber K, 2017, ACAD MANAG ANN, V11, P886, DOI 10.5465/annals.2015.0152
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   WILLIAMSON C, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P338
   Wood JR, 2008, J USABILITY STUD, V4, P1
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Zhang ZY, 2013, IEEE T VIS COMPUT GR, V19, P1895, DOI 10.1109/TVCG.2013.89
NR 77
TC 21
Z9 23
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4101
EP 4112
DI 10.1109/TVCG.2021.3074023
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400011
PM 33872153
OA Green Submitted, Green Published
DA 2024-11-06
ER

PT J
AU Wilson, A
   Hua, H
AF Wilson, Austin
   Hua, Hong
TI Design of a Pupil-Matched Occlusion-Capable Optical See-Through Wearable
   Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optical imaging; Adaptive optics; Optical modulation; Pupils; Optical
   design; Optical reflection; Computer architecture; Occlusion;
   see-through display; augmented reality; color study
ID CALIBRATION
AB State-of-the-art optical see-through head-mounted displays (OST-HMD) for augmented reality applications lack the ability to correctly render light blocking behavior between digital and physical objects, known as mutual occlusion capability. In this article, we present a novel optical architecture for enabling a high performance, occlusion-capable optical see-through head-mounted display (OCOST-HMD). The design utilizes a single-layer, double-pass architecture, creating a compact OCOST-HMD that is capable of rendering per-pixel mutual occlusion, correctly pupil-matched viewing perspective between virtual and real scenes, and a wide see-through field of view (FOV). Based on this architecture, we present a design embodiment and a compact prototype implementation. The prototype demonstrates a virtual display with an FOV of 34 degrees by 22 degrees, an angular resolution of 1.06 arc minutes per pixel, and an average image contrast greater than 40 percent at the Nyquist frequency of 53 cycles/mm. Furthermore, the device achieves a see-through FOV of 90 degrees by 50 degrees, within which about 40 degrees diagonally is occlusion-enabled, and has an angular resolution of 1.0 arc minutes (comparable to a 20/20 vision) and a dynamic range greater than 100:1. We conclude the paper with a quantitative comparison of the key optical performance such as modulation transfer function, image contrast, and color rendering accuracy of our OCOST-HMD system with and without occlusion enabled for various lighting environments.
C1 [Wilson, Austin; Hua, Hong] Univ Arizona, James C Wyant Coll Opt Sci, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Hua, H (corresponding author), Univ Arizona, James C Wyant Coll Opt Sci, Tucson, AZ 85721 USA.
EM wilsona2@optics.arizona.edu; hhua@optics.arizona.edu
CR [Anonymous], 2012, PROC IEEE INT S MIXE
   Cakmakci O, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P16, DOI 10.1109/ISMAR.2004.2
   Gao CY, 2012, INT SYM MIX AUGMENT, P281, DOI 10.1109/ISMAR.2012.6402574
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Howlett ID, 2017, J SOC INF DISPLAY, V25, P185, DOI 10.1002/jsid.545
   Hua H, 2002, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VR.2002.996508
   Itoh Y, 2017, IEEE T VIS COMPUT GR, V23, P2463, DOI 10.1109/TVCG.2017.2734427
   Kaminokado T, 2020, IEEE T VIS COMPUT GR, V26, P3576, DOI 10.1109/TVCG.2020.3023569
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Kiyokawa K, 2001, COMPUT GRAPH-UK, V25, P765, DOI 10.1016/S0097-8493(01)00119-4
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   Lee S, 2013, P IEEE VIRT REAL ANN, P27, DOI 10.1109/VR.2013.6549353
   Maimone A, 2013, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2013.6671761
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Shah M. M., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P372
   Sharma G, 2002, P IEEE, V90, P605, DOI 10.1109/JPROC.2002.1002530
   Tatham EW, 1999, COMMUN ACM, V42, P96, DOI 10.1145/315762.315813
   Watterson CA, 2019, PROC FRONT EDUC CONF, DOI 10.1109/fie43999.2019.9028601
   Wetzstein G, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185576
   Wilson A., 2017, PROC SID S DIG TECH
   Wilson A, 2017, OPT EXPRESS, V25, P30539, DOI 10.1364/OE.25.030539
   Yamaguchi Y, 2016, APPL OPTICS, V55, pA144, DOI 10.1364/AO.55.00A144
NR 22
TC 3
Z9 3
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4113
EP 4126
DI 10.1109/TVCG.2021.3076069
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400012
PM 33905332
DA 2024-11-06
ER

PT J
AU Chen, R
   Shu, XH
   Chen, JH
   Weng, D
   Tang, JX
   Fu, SW
   Wu, YC
AF Chen, Ran
   Shu, Xinhuan
   Chen, Jiahui
   Weng, Di
   Tang, Junxiu
   Fu, Siwei
   Wu, Yingcai
TI Nebula: A Coordinating Grammar of Graphics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Grammar; Visualization; Usability; Libraries; Data
   models; Natural languages; Coordination; multiple coordinated views;
   interactive visualization; grammar of graphics
ID VISUALIZATION; SYSTEM; VEGA
AB In multiple coordinated views (MCVs), visualizations across views update their content in response to users' interactions in other views. Interactive systems provide direct manipulation to create coordination between views, but are restricted to limited types of predefined templates. By contrast, textual specification languages enable flexible coordination but expose technical burden. To bridge the gap, we contribute Nebula, a grammar based on natural language for coordinating visualizations in MCVs. The grammar design is informed by a novel framework based on a systematic review of 176 coordinations from existing theories and applications, which describes coordination by demonstration, i.e., how coordination is performed by users. With the framework, Nebula specification formalizes coordination as a composition of user- and coordination-triggered interactions in origin and destination views, respectively, along with potential data transformation between the interactions. We evaluate Nebula by demonstrating its expressiveness with a gallery of diverse examples and analyzing its usability on cognitive dimensions.
C1 [Chen, Ran; Chen, Jiahui; Weng, Di; Tang, Junxiu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Chen, Ran; Chen, Jiahui; Weng, Di; Tang, Junxiu; Fu, Siwei; Wu, Yingcai] Zhejiang Lab, Hangzhou 311121, Peoples R China.
   [Shu, Xinhuan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory; Hong Kong University of
   Science & Technology
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.; Fu, SW (corresponding author), Zhejiang Lab, Hangzhou 311121, Peoples R China.
EM chenran928@zju.edu.cn; xinhuan.shu@connect.ust.hk; jhchen6@zju.edu.cn;
   dweng@zju.edu.cn; tangjunxiu@zju.edu.cn; fusiwei339@gmail.com;
   ycwu@zju.edu.cn
RI wang, yixuan/JGM-3893-2023; Weng, Di/ABG-7408-2020
OI Tang, Junxiu/0000-0003-3594-926X; Chen, Ran/0000-0002-2770-4070; Shu,
   Xinhuan/0000-0002-9736-4454; Weng, Di/0000-0003-2712-7274; Chen,
   Jiahui/0000-0003-3980-0294
FU NSFC [62072400, 62002331]; Zhejiang Provincial Natural Science
   Foundation [LR18F020001]; 100 Talents Program of Zhejiang University;
   Zhejiang Lab
FX The authors would like to thank all the reviewers for their constructive
   suggestions and comments. This work was supported in part by NSFC under
   Grant 62072400, in part by NSFC under Grant 62002331, in part by the
   Zhejiang Provincial Natural Science Foundation under Grant LR18F020001,
   in part by the 100 Talents Program of Zhejiang University, and in part
   by Zhejiang Lab. Yingcai Wu and Siwei Fu are the co-corresponding
   authors.
CR Behrisch M, 2020, IEEE T VIS COMPUT GR, V26, P184, DOI 10.1109/TVCG.2019.2934300
   Blackwell AF, 2001, LECT NOTES ARTIF INT, V2117, P325
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Boukhelifa N, 2003, INTERNATIONAL CONFERENCE ON COORDINATED AND MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P76, DOI 10.1109/CMV.2003.1215005
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Grammel L., 2013, EuroVis-Short Papers, DOI DOI 10.2312/PE.EUROVISSHORT.EUROVISSHORT2013.019-023
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Hutchins EL., 1985, HUMAN COMPUTER INTER, V1, P311, DOI DOI 10.1207/S15327051HCI0104_2
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Koytek P, 2018, IEEE T VIS COMPUT GR, V24, P605, DOI 10.1109/TVCG.2017.2743859
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   North C, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P15, DOI 10.1109/INFVIS.2002.1173142
   North C., 1997, A taxonomy of multiple window coordination
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI DOI 10.1145/345513.345282
   Pattison Tim., 2001, P ASIA PACIFIC S VIS, P165
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Roberts JC, 2000, PROC SPIE, V3960, P176, DOI 10.1117/12.378894
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sadana R, 2016, COMPUT GRAPH FORUM, V35, P261, DOI 10.1111/cgf.12902
   Satyanarayan A., 2014, P 27 ANN ACM S US IN, P669, DOI DOI 10.1145/2642918.2647360
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Weaver C, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P165, DOI 10.1109/INFVIS.2005.1532143
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wilkinson L., 2005, The Grammar of Graphics, V2nd ed
   Xie C, 2017, IEEE T VIS COMPUT GR, V23, P51, DOI 10.1109/TVCG.2016.2598479
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yu BW, 2017, IEEE T VIS COMPUT GR, V23, P251, DOI 10.1109/TVCG.2016.2598497
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 40
TC 11
Z9 11
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4127
EP 4140
DI 10.1109/TVCG.2021.3076222
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400013
PM 33909565
DA 2024-11-06
ER

PT J
AU Wang, JP
   Zhang, W
   Yang, H
   Yeh, CCM
   Wang, L
AF Wang, Junpeng
   Zhang, Wei
   Yang, Hao
   Yeh, Chin-Chia Michael
   Wang, Liang
TI Visual Analytics for RNN-Based Deep Reinforcement Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Games; Visual analytics; Analytical models; Reinforcement learning;
   Recurrent neural networks; Perturbation methods; Data models; Deep
   reinforcement learning (DRL); recurrent neural network (RNN); model
   interpretation; visual analytics
AB Deep reinforcement learning (DRL) targets to train an autonomous agent to interact with a pre-defined environment and strives to achieve specific goals through deep neural networks (DNN). Recurrent neural network (RNN) based DRL has demonstrated superior performance, as RNNs can effectively capture the temporal evolution of the environment and respond with proper agent actions. However, apart from the outstanding performance, little is known about how RNNs understand the environment internally and what has been memorized over time. Revealing these details is extremely important for deep learning experts to understand and improve DRLs, which in contrast, is also challenging due to the complicated data transformations inside these models. In this article, we propose Deep Reinforcement Learning Interactive Visual Explorer (DRLIVE), a visual analytics system to effectively explore, interpret, and diagnose RNN-based DRLs. Having focused on DRL agents trained for different Atari games, DRLIVE accomplishes three tasks: game episode exploration, RNN hidden/cell state examination, and interactive model perturbation. Using the system, one can flexibly explore a DRL agent through interactive visualizations, discover interpretable RNN cells by prioritizing RNN hidden/cell states with a set of metrics, and further diagnose the DRL model by interactively perturbing its inputs. Through concrete studies with multiple deep learning experts, we validated the efficacy of DRLIVE.
C1 [Wang, Junpeng; Zhang, Wei; Yang, Hao; Yeh, Chin-Chia Michael; Wang, Liang] Visa Res, Palo Alto, CA 94301 USA.
RP Wang, JP (corresponding author), Visa Res, Palo Alto, CA 94301 USA.
EM junpenwa@visa.com; wzhan@visa.com; haoyang@visa.com; miyeh@visa.com;
   liawang@visa.com
RI Yeh, Michael/J-1738-2019
OI Wang, Junpeng/0000-0002-1130-9914
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Greydanus S, 2018, PR MACH LEARN RES, V80
   Grondman I, 2012, IEEE T SYST MAN CY C, V42, P1291, DOI 10.1109/TSMCC.2012.2218595
   He WB, 2020, IEEE PAC VIS SYMP, P36, DOI 10.1109/PacificVis48177.2020.7127
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Jaunet T, 2020, COMPUT GRAPH FORUM, V39, P49, DOI 10.1111/cgf.13962
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Karpathy A, 2015, Arxiv, DOI [arXiv:1506.02078, DOI 10.48550/ARXIV.1506.02078]
   Kempka M, 2016, IEEE CONF COMPU INTE
   Kober J., 2009, ADV NEURAL INFORM PR, P849
   Konda VR, 2000, ADV NEUR IN, V12, P1008
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   Madsen Andreas, 2019, DISTILL, DOI DOI 10.23915/DISTILL.00016
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Puri N, 2020, ICLR
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2020, IEEE PAC VIS SYMP, P51, DOI 10.1109/PacificVis48177.2020.3542
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wang QW, 2020, IEEE T VIS COMPUT GR, V26, P3340, DOI 10.1109/TVCG.2019.2921323
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhu Michael, 2018, P 6 INT C LEARN REPR
NR 48
TC 12
Z9 12
U1 5
U2 34
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4141
EP 4155
DI 10.1109/TVCG.2021.3076749
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400014
PM 33929961
DA 2024-11-06
ER

PT J
AU Martin-Gomez, A
   Weiss, J
   Keller, A
   Eck, U
   Roth, D
   Navab, N
AF Martin-Gomez, Alejandro
   Weiss, Jakob
   Keller, Andreas
   Eck, Ulrich
   Roth, Daniel
   Navab, Nassir
TI The Impact of Focus and Context Visualization Techniques on Depth
   Perception in Optical See-Through Head-Mounted Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Estimation; Task analysis; Color; Augmented reality;
   Rendering (computer graphics); Head-mounted displays; Augmented reality;
   perception; depth estimation; visualization techniques; human computer
   interaction; design and evaluation methods; user studies
ID AUGMENTED REALITY; JUDGMENTS; ISSUES
AB Estimating the depth of virtual content has proven to be a challenging task in Augmented Reality (AR) applications. Existing studies have shown that the visual system makes use of multiple depth cues to infer the distance of objects, occlusion being one of the most important ones. The ability to generate appropriate occlusions becomes particularly important for AR applications that require the visualization of augmented objects placed below a real surface. Examples of these applications are medical scenarios in which the visualization of anatomical information needs to be observed within the patient's body. In this regard, existing works have proposed several focus and context (F+C) approaches to aid users in visualizing this content using Video See-Through (VST) Head-Mounted Displays (HMDs). However, the implementation of these approaches in Optical See-Through (OST) HMDs remains an open question due to the additive characteristics of the display technology. In this article, we, for the first time, design and conduct a user study that compares depth estimation between VST and OST HMDs using existing in-situ visualization methods. Our results show that these visualizations cannot be directly transferred to OST displays without increasing error in depth perception tasks. To tackle this gap, we perform a structured decomposition of the visual properties of AR F+C methods to find best-performing combinations. We propose the use of chromatic shadows and hatching approaches transferred from computer graphics. In a second study, we perform a factorized analysis of these combinations, showing that varying the shading type and using colored shadows can lead to better depth estimation when using OST HMDs.
C1 [Martin-Gomez, Alejandro; Weiss, Jakob; Keller, Andreas; Eck, Ulrich; Navab, Nassir] Tech Univ Munich, Dept Informat, Chair Comp Aided Med Procedures & Augmented Real, D-80333 Munich, Germany.
   [Martin-Gomez, Alejandro; Navab, Nassir] Johns Hopkins Univ, Whiting Sch Engn, Lab Comp Aided Med Procedures, Baltimore, MD 21218 USA.
   [Roth, Daniel] FAU Erlangen Nurnberg, D-91054 Erlangen, Germany.
C3 Technical University of Munich; Johns Hopkins University; University of
   Erlangen Nuremberg
RP Martin-Gomez, A; Weiss, J (corresponding author), Tech Univ Munich, Dept Informat, Chair Comp Aided Med Procedures & Augmented Real, D-80333 Munich, Germany.
EM alejandro.martin@tum.de; jakob.weiss@tum.de; andi.keller@tum.de;
   ulrich.eck@tum.de; daniel.roth@tum.de; nassir.navab@tum.de
RI Gil-Ley, Alejandro/J-5851-2012; Keller, Andreas/ABB-6412-2021; Roth,
   Daniel/AFK-2613-2022
OI Eck, Ulrich/0000-0002-5322-4724; Martin-Gomez,
   Alejandro/0000-0001-9341-3477
FU Bayerische Forschungsstiftung [DOK-178-17]; Deutsche
   Forschungsgemeinschaft [NA-620/33-2]
FX This work was supported in part by the Bayerische Forschungsstiftung
   under Grant DOK-178-17 and in part by the Deutsche
   Forschungsgemeinschaft under Grant NA-620/33-2. The authors would also
   like to thank Marc Lazarovici and the Institut fur Notfallmedizin for
   their valuable support in conducting their user study on their premises.
   Alejandro Martin-Gomez and Jakob Weiss are contributed equally to this
   work as corresponding authors.
CR BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Bichlmeier C., 2007, INT S MIX AUGM REAL, P129, DOI DOI 10.1109/ISMAR.2007.4538837
   Björk S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P85, DOI 10.1109/INFVIS.2000.885094
   Bustamante Ernesto A., 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P1522
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Cutting JE, 2003, LOOKING INTO PICTURES, P215
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Edwards PJ, 2004, LECT NOTES COMPUT SC, V3150, P369
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   Elmqvist N, 2007, LECT NOTES COMPUT SC, V4662, P532
   Engen T., 1971, WOODWORTH SCHLOSBERG, V3rd, P11
   Ferwerda, 2008, SIGGRAPH 2008 ACM SI, P1
   Fuchs H, 1998, LECT NOTES COMPUT SC, V1496, P934, DOI 10.1007/BFb0056282
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Gescheider G. A., 2013, Psychophysics: The fundamentals
   Gescheider G.A., 1985, Psychophysics: Methods, Theory and Application
   Ghasemi S, 2017, PRESENCE-TELEOP VIRT, V26, P42, DOI 10.1162/PRES_a_00286
   Hansen C, 2010, INT J COMPUT ASS RAD, V5, P133, DOI 10.1007/s11548-009-0365-3
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hauser H., 2006, Scientific Visualization: The Visual Extraction of Knowledge from Data, P305, DOI [DOI 10.1007/3-540-30790-7_18, 10/dh5vbj]
   Heinrich F, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364245
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   Ishihara S., 1985, TEST COLOUR BLINDNES
   Jones J. A., 2011, P ACM SIGGRAPH S APP, P29, DOI [10.1145/2077451.2077457, DOI 10.1145/2077451.2077457]
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kalkofen Denis, 2007, P 6 IEEE ACM INT S M, P1, DOI [DOI 10.1109/ISMAR.2007.4538846, 10.1109/ISMAR.2007.4538846]
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lawonn K, 2015, LECT NOTES COMPUT SC, V9350, P399, DOI 10.1007/978-3-319-24571-3_48
   Lerotic M, 2007, LECT NOTES COMPUT SC, V4792, P102
   Li W, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239482
   Livingston Mark A., 2013, Human Factors in Augmented Reality Environments, P67, DOI [10.1007/978-1-4614-4205-94, DOI 10.1007/978-1-4614-4205-94, DOI 10.1007/978-1-4614-4205-9_4]
   Livingston MarkA., 2013, Human Factors in Augmented Reality Environments, P35, DOI [10.1007/978-1-4614-4205-93, DOI 10.1007/978-1-4614-4205-93]
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P237, DOI 10.1145/2993369.2993388
   Nagata Shojiro, 1991, PICTORIAL COMMUNICAT, P527
   Nicolau S, 2011, SURG ONCOL, V20, P189, DOI 10.1016/j.suronc.2011.07.002
   Otsuki M, 2013, INT SYM MIX AUGMENT, P283, DOI 10.1109/ISMAR.2013.6671806
   Otsuki Mai, 2015, P 25 INT C ART REAL, P45, DOI [10.2312/egve.20151309, DOI 10.2312/EGVE.20151309]
   Peillard E, 2020, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR50242.2020.00028
   Pelargos PE, 2017, J CLIN NEUROSCI, V35, P1, DOI 10.1016/j.jocn.2016.09.002
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Rolland JP, 2002, PRESENCE-TELEOP VIRT, V11, P610, DOI 10.1162/105474602321050730
   Rong Wang, 2016, Medical Imaging and Augmented Reality. 7th International Conference, MIAR 2016. Proceedings: LNCS 9805, P129, DOI 10.1007/978-3-319-43775-0_12
   Ropinski T, 2006, LECT NOTES COMPUT SC, V4073, P93
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Singh Gurjot., 2010, Proceedings of the 7th Symposium on Applied Perception in Graphics and Visualization, P149, DOI [10.1145/1836248.1836277, DOI 10.1145/1836248.1836277]
   Solteszova Veronika., 2011, Proc. of NPAR, P105, DOI DOI 10.1145/2024676.2024694
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Wetzlinger W., 2014, Lecture Notes in Computer Science (including subseries Lecture 8517 LNCS, Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) PART, P402, DOI DOI 10.1007/978-3-319-07668-3_39/COVER
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
NR 59
TC 10
Z9 10
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4156
EP 4171
DI 10.1109/TVCG.2021.3079849
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400015
PM 33979287
OA hybrid
DA 2024-11-06
ER

PT J
AU Lu, ZH
   Mao, WW
   Dai, YW
   Li, WQ
   Su, ZY
AF Lu, Zhuheng
   Mao, Weiwei
   Dai, Yuewei
   Li, Weiqing
   Su, Zhiyong
TI Slicing-Tracking-Detection: Simultaneous Multi-Cylinder Detection From
   Large-Scale and Complex Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Transforms; Task analysis;
   Reinforcement learning; Markov processes; Training; Cylinder detection;
   Markov decision process; primitive fitting; 3D reconstruction
ID RECONSTRUCTION; RECOGNITION; EXTRACTION
AB Multiple cylinders detection from large-scale and complex point clouds is a historical but challenging problem, considering the efficiency and accuracy. We propose a novel framework, named slicing-tracking-detection (STD), that detects multiple cylinders accurately and simultaneously from point clouds of large-scale and complex process plants. In this framework, the 3D cylinder detection problem is reformulated as a cylinder ingredients tracking task based on multi-object tracking (MOT). First, we generate slices from the input point cloud, and render them to slice sequence. Then, the cycle of a cylinder is modeled with a Markov Decision Process (MDP), where the ingredient is tracked with a template and the miss tracking is associated with ingredient proposals through reinforcement learning. Finally, by applying MDP for each cylinder, multiple cylinders can be detected simultaneously and accurately. Extensive experiments show that the proposed STD framework can significantly outperform the state-of-the-art approaches in efficiency, accuracy, and robustness. The source code is available at http://zhiyongsu.github.io.
C1 [Lu, Zhuheng; Mao, Weiwei; Su, Zhiyong] Nanjing Univ Sci & Technol, Sch Automat, Visual Comp Grp, Nanjing 210094, Jiangsu, Peoples R China.
   [Dai, Yuewei] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Jiangsu, Peoples R China.
   [Li, Weiqing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Information Science & Technology; Nanjing University of Science &
   Technology
RP Su, ZY (corresponding author), Nanjing Univ Sci & Technol, Sch Automat, Visual Comp Grp, Nanjing 210094, Jiangsu, Peoples R China.
EM lzharsenal@163.com; banyimao@163.com; dywjust@163.com;
   li_weiqing@njust.edu.cn; su@njust.edu.cn
RI mao, weiwei/AAA-5765-2020
OI Li, Weiqing/0000-0002-1929-3654; zhuheng, lu/0000-0003-2266-0790; su,
   zhiyong/0000-0001-9483-5268
FU National Key R&D Program of China [2018YFB1004904]; Fundamental Research
   Funds for the Central Universities [30918012203]; Pre-research Project
   of The 13th Five Year Plan [61409230104, 315100104]
FX The authors would like to thank anonymous reviewers for their insights
   and comments to further improve the quality of the manuscript, the
   participants in the study for their valuable time, and the members of
   the Visual Computing Group at NJUST for their feedback. This work was
   supported in part by the National Key R&D Program of Chinaunder Grant
   2018YFB1004904, in part by the Fundamental Research Funds for the
   Central Universities under Grant 30918012203, and in part by the
   Pre-research Project of The 13th Five Year Plan under Grants 61409230104
   and 315100104.
CR Abuzaina Anas, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P290, DOI 10.1007/978-3-642-40246-3_36
   Ahmed MF, 2014, J COMPUT CIVIL ENG, V28, DOI 10.1061/(ASCE)CP.1943-5487.0000329
   Araújo AMC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107161
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bey A, 2011, INT ARCH PHOTOGRAMM, V38-5, P289
   Birdal T, 2020, IEEE T PATTERN ANAL, V42, P1333, DOI 10.1109/TPAMI.2019.2900309
   Bolles RC, 1981, IJCAI, P637, DOI DOI 10.5555/1623264.1623272
   Bouguet J.Y., 1999, PYRAMIDAL IMPLEMENTA
   Camurri M, 2014, MACH VISION APPL, V25, P1877, DOI 10.1007/s00138-014-0640-3
   Chaperon T., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P35
   Dahyot R, 2009, IEEE T PATTERN ANAL, V31, P1502, DOI 10.1109/TPAMI.2008.288
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Lee T, 2009, IEEE T VIS COMPUT GR, V15, P355, DOI 10.1109/TVCG.2008.190
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li LX, 2019, PROC CVPR IEEE, P2647, DOI 10.1109/CVPR.2019.00276
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Liu YJ, 2013, IEEE T VIS COMPUT GR, V19, P1700, DOI 10.1109/TVCG.2013.74
   Maalek R, 2019, AUTOMAT CONSTR, V103, P150, DOI 10.1016/j.autcon.2019.03.013
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nguyen CHP, 2018, AUTOMAT CONSTR, V91, P44, DOI 10.1016/j.autcon.2018.03.008
   Oh S, 2009, IEEE T AUTOMAT CONTR, V54, P481, DOI 10.1109/TAC.2009.2012975
   Park Y, 2011, IEEE T VIS COMPUT GR, V17, P1728, DOI 10.1109/TVCG.2010.262
   Patil AK, 2017, AUTOMAT CONSTR, V75, P65, DOI 10.1016/j.autcon.2016.12.002
   Rabbani T, 2005, P ISPRS WORKSH LAS S, P6
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Sharma G, 2018, PROC CVPR IEEE, P5515, DOI 10.1109/CVPR.2018.00578
   Suna Kim, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P98, DOI 10.1007/978-3-642-37431-9_8
   Tran TT, 2015, COMPUT GRAPH-UK, V46, P345, DOI 10.1016/j.cag.2014.09.027
   Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160
   Valsangkar AA, 2019, IEEE T VIS COMPUT GR, V25, P1460, DOI 10.1109/TVCG.2018.2810068
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103
NR 40
TC 1
Z9 1
U1 2
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4172
EP 4185
DI 10.1109/TVCG.2021.3082572
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400016
PM 34018933
DA 2024-11-06
ER

PT J
AU Worrallo, AG
   Hartley, T
AF Worrallo, Adam Grant
   Hartley, Thomas
TI Robust Optical Based Hand Interaction for Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sensors; Optical sensors; Tracking; Sensor systems; Data aggregation;
   Resists; Headphones; Gestures; hand interaction; optical trackers;
   virtual reality
ID SENSOR
AB Using optical sensors to track hand gestures in virtual reality (VR) simulations requires issues such as occlusion, field-of-view, accuracy and stability of sensors to be addressed or mitigated. We introduce an optical hand-based interaction system that comprises two Leap Motion sensors mounted onto a VR headset at different orientations. Our system collects sensor data from the leap motions, combines and processes it to produce optimal hand tracking data, that minimises the effect of sensor occlusion and noise. This contrasts with previous systems that do not use multiple head-mounted sensors or incorporate hand-data aggregation. We also present a study that compares the proposed system with glove-based and traditional motion controller-based interaction. We investigate hand interactions effect on the feeling of naturalness and immersion. The results show that the use of two head-mounted sensors and the data aggregation system increased the number of valid hands presented to the user and can be successfully applied to VR. The user study shows that there is a strong preference for the proposed system due to the natural feeling and freeing interaction. The absence of an indirect interface such as gloves or controllers was found to aid in creating a more natural and immersive experience.
C1 [Worrallo, Adam Grant; Hartley, Thomas] Univ Wolverhampton, Wolverhampton WV1 1LY, England.
C3 University of Wolverhampton
RP Worrallo, AG (corresponding author), Univ Wolverhampton, Wolverhampton WV1 1LY, England.
EM adam.worrallo@wlv.ac.uk; t.hartley2@wlv.ac.uk
CR Anthes C, 2016, IEEE AEROSPACE C IEE
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Breslauer N, 2019, TEH VJESN, V26, P560, DOI 10.17559/TV-20181012093055
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI [10.1371/journal.pone.0170531, DOI 10.1371/JOURNAL.PONE.0170531]
   Buchanan T, 2018, HANDS LOOK STATE INP
   Caputo F., 2015, P 11 BIANN C IT SIGC, P74, DOI 10.1145/2808435.2808439
   Caserman P, 2020, IEEE T VIS COMPUT GR, V26, P3089, DOI 10.1109/TVCG.2019.2912607
   Chapoulie Emmanuelle, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P109, DOI 10.1109/3DUI.2015.7131734
   Chaudhary A., 2011, International Journal of Computer Science Engineering Survey, V2, P122, DOI DOI 10.5121/IJCSES.2011.2109
   Cheng H, 2016, IEEE T CIRC SYST VID, V26, P1659, DOI 10.1109/TCSVT.2015.2469551
   Clark Andrew., 2016, P ANN C S AFR I COMP, P1, DOI 10.1145/2987491.2987511
   Derpanis K., 2004, REV VISION BASED HAN
   Figueiredo L, 2018, COMPUT GRAPH-UK, V77, P108, DOI 10.1016/j.cag.2018.10.006
   Gallotti P., 2011, 2011 XIII Symposium on Virtual Reality (SVR), P242, DOI 10.1109/SVR.2011.21
   Han S, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9020022
   Hannema D., 2001, THESIS U AMSTERDAM N
   Heekyu Park, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P20, DOI 10.1109/ISUVR.2017.14
   Jarvis M, 2016, DEV VRS HARDWARE CON
   Jin HY, 2016, CAAI T INTELL TECHNO, V1, P104, DOI 10.1016/j.trit.2016.03.010
   Kent State University, SPSS TUT PEARS CORR
   Kiselev V, 2019, PROC CONF OPEN INNOV, P163, DOI [10.23919/FRUCT.2019.8711887, 10.23919/fruct.2019.8711887]
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Laerd Statistics, 2018, CRONB ALPH SPSS STAT
   Lee N, 2016, CHALLENGES CREATING
   Lombard M, 2002, HUM COMMUN RES, V28, P587, DOI 10.1111/j.1468-2958.2002.tb00826.x
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Murthy G.R.S., 2009, Int. J. Inform. Technol. Knowl. Manage., V2, P405
   Navarro D, 2019, HUCAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P103, DOI 10.5220/0007362401030110
   Pinto J., 2015, PROC PORTUGUESE MEET, P63
   Placidi G, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P184, DOI 10.5220/0006197801840192
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Stephanie, 2014, COHENS KAPPA STAT
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yan X., THESIS UMEA U UMEA
   Zeutzheim B., 2019, THESIS U KOBLENZ LAN
   Zou YY, 2019, LECT NOTES ARTIF INT, V11742, P472, DOI 10.1007/978-3-030-27535-8_42
NR 38
TC 3
Z9 3
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4186
EP 4197
DI 10.1109/TVCG.2021.3083411
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400017
PM 34033541
DA 2024-11-06
ER

PT J
AU Bhargava, A
   Venkatakrishnan, R
   Venkatakrishnan, R
   Solini, H
   Lucaites, K
   Robb, AC
   Pagano, CC
   Babu, SV
AF Bhargava, Ayush
   Venkatakrishnan, Roshan
   Venkatakrishnan, Rohith
   Solini, Hannah
   Lucaites, Kathryn
   Robb, Andrew C.
   Pagano, Christopher C.
   Babu, Sabarish, V
TI Did I Hit the Door? Effects of Self-Avatars and Calibration in a
   Person-Plus-Virtual-Object System on Perceived Frontal Passability in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Affordances; Calibration; Apertures; Task analysis; Training; Tracking;
   Tools; Virtual reality; self-avatars; virtual objects; affordance
   perception; passability
ID PERCEPTION; AFFORDANCES; JUDGMENTS; LIMBS
AB The availability of new and improved display, tracking and input devices for Virtual Reality experiences has facilitated the use of partial and full body self-avatars in interaction with virtual objects in the environment. However, scaling the avatar to match the user's body dimensions remains to be a cumbersome process. Moreover, the effect of body-scaled self-avatars on size perception of virtual handheld objects and related action capabilities has been relatively unexplored. To this end, we present an empirical evaluation investigating the effect of the presence or absence of body-scaled self-avatars and visuo-motor calibration on frontal passability affordance judgments when interacting with virtual handheld objects. The self-avatar's dimensions were scaled to match the participant's eyeheight, arms length, shoulder width and body depth along the mid section. The results indicate that the presence of body-scaled self-avatars produce more realistic judgments of passability and aid the calibration process when interacting with virtual objects. Also, participants rely on the visual size of virtual objects to make judgments even though the kinesthetic and proprioceptive feedback of the object is missing or mismatched.
C1 [Bhargava, Ayush] Key Lime Interact, Brooklyn, NY 11201 USA.
   [Venkatakrishnan, Roshan; Venkatakrishnan, Rohith; Robb, Andrew C.; Babu, Sabarish, V] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
   [Solini, Hannah; Lucaites, Kathryn; Pagano, Christopher C.] Clemson Univ, Dept Psychol, Clemson, SC 29634 USA.
C3 Clemson University; Clemson University
RP Bhargava, A (corresponding author), Key Lime Interact, Brooklyn, NY 11201 USA.
EM ayush.bhargava92@gmail.com; rvenkat@g.clemson.edu;
   rohithv@g.clemson.edu; hsolini@clemson.edu; klucait@clemson.edu;
   arobb@clemson.edu; cpagano@clemson.edu; sbabu@Clemson.edu
RI Venkatakrishnan, Roshan/JDC-3508-2023; Venkatakrishnan,
   Rohith/JCE-8736-2023; Bhargava, Ayush/AAJ-2387-2021
OI Venkatakrishnan, Rohith/0000-0002-8484-3915; Venkatakrishnan,
   Roshan/0000-0002-6538-627X; Bhargava, Ayush/0000-0001-8957-1317; Robb,
   Andrew/0000-0002-0398-5576
CR Agresti A., 2002, INTRO CATEGORICAL DA
   [Anonymous], 2012, P ACM S APPL PERCEPT
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Bhargava A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P519, DOI [10.1109/VR46266.2020.1581293987781, 10.1109/VR46266.2020.00-31]
   Bhargava A, 2020, VIRTUAL REAL-LONDON, V24, P713, DOI 10.1007/s10055-020-00432-y
   Blin F, 2016, LANG STUD SCI ENGINE, V2, P41, DOI 10.1075/lsse.2.03bli
   Buck LE, 2019, IEEE T VIS COMPUT GR, V25, P2123, DOI 10.1109/TVCG.2019.2899232
   Cohen J., 1975, APPL MULTIPLE REGRES
   Comalli D, 2013, EXP BRAIN RES, V228, P183, DOI 10.1007/s00221-013-3550-0
   CRASKE B, 1977, SCIENCE, V196, P71, DOI 10.1126/science.841342
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Day B, 2017, ACTA PSYCHOL, V181, P27, DOI 10.1016/j.actpsy.2017.09.014
   de Siqueira AG, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P606, DOI 10.1109/VR50410.2021.00086
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Fajen BR, 2007, ECOL PSYCHOL, V19, P383, DOI 10.1080/10407410701557877
   Franchak J, 2014, ECOL PSYCHOL, V26, P109, DOI 10.1080/10407413.2014.874923
   Franchak JM, 2017, ATTEN PERCEPT PSYCHO, V79, P1816, DOI 10.3758/s13414-017-1339-0
   Franchak JM, 2014, ATTEN PERCEPT PSYCHO, V76, P460, DOI 10.3758/s13414-013-0578-y
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI 10.1145/1836248.1836259
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hackney AL, 2014, J MOTOR BEHAV, V46, P319, DOI 10.1080/00222895.2014.913002
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Kim Jangyoon, 2017, P 27 INT C ART REAL, P153
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   LIN Q., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P7
   LIN Q., 2013, P ACM S APPL PERCEPT, P107, DOI DOI 10.1145/2492494.2492511
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Lok B, 2003, P IEEE VIRT REAL ANN, P125, DOI 10.1109/VR.2003.1191130
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Lucaites KM, 2020, ECOL PSYCHOL, V32, P95, DOI 10.1080/10407413.2020.1741323
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Mine D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232290
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Pagano CC, 1996, ECOL PSYCHOL, V8, P43, DOI 10.1207/s15326969eco0801_3
   Pagano CC, 1998, J APPL BIOMECH, V14, P331, DOI 10.1123/jab.14.4.331
   Pagano CC, 2021, TECHNOL ARCHIT DES, V5, P31, DOI 10.1080/24751448.2021.1863665
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Petrucci MN, 2016, ECOL PSYCHOL, V28, P108, DOI 10.1080/10407413.2016.1163987
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Snijders T. A. B., 2012, Multilevel Analysis, V2nd
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Stevens SS., 1975, PSYCHOPHYSICS INTRO
   Wagman JB, 2005, ECOL PSYCHOL, V17, P105, DOI 10.1207/s15326969eco1702_3
   Warren W. H., 2005, PHILOS TOPICS, V33, P335, DOI [DOI 10.5840/PHILTOPICS200533113, DOI 10.5840/PHILT0PICS200533113]
   Warren WH, 2006, PSYCHOL REV, V113, P358, DOI 10.1037/0033-295X.113.2.358
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Watson G, 2011, HUM MOVEMENT SCI, V30, P942, DOI 10.1016/j.humov.2010.08.004
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 57
TC 10
Z9 13
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4198
EP 4210
DI 10.1109/TVCG.2021.3083423
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400018
PM 34033542
DA 2024-11-06
ER

PT J
AU Shen, IC
   Chen, BY
AF Shen, I-Chao
   Chen, Bing-Yu
TI ClipGen: A Deep Generative Model for Clipart Vectorization and Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Three-dimensional displays; Solid modeling; Geometry; Graphics;
   Task analysis; Computational modeling; ClipGen; clipnet; clipart; vector
   graphics; deep learning; deep generative model
AB This article presents a novel deep learning-based approach for automatically vectorizing and synthesizing the clipart of man-made objects. Given a raster clipart image and its corresponding object category (e.g., airplanes), the proposed method sequentially generates new layers, each of which is composed of a new closed path filled with a single color. The final result is obtained by compositing all layers together into a vector clipart image that falls into the target category. The proposed approach is based on an iterative generative model that (i) decides whether to continue synthesizing a new layer and (ii) determines the geometry and appearance of the new layer. We formulated a joint loss function for training our generative model, including the shape similarity, symmetry, and local curve smoothness losses, as well as vector graphics rendering accuracy loss for synthesizing clipart recognizable by humans. We also introduced a collection of man-made object clipart, ClipNet, which is composed of closed-path layers, and two designed preprocessing tasks to clean up and enrich the original raw clipart. To validate the proposed approach, we conducted several experiments and demonstrated its ability to vectorize and synthesize various clipart categories. We envision that our generative model can facilitate efficient and intuitive clipart designs for novice users and graphic designers.
C1 [Shen, I-Chao; Chen, Bing-Yu] Natl Taiwan Univ, Taipei 10617, Taiwan.
C3 National Taiwan University
RP Shen, IC (corresponding author), Natl Taiwan Univ, Taipei 10617, Taiwan.
EM jdilyshen@gmail.com; robin@ntu.edu.tw
RI Shen, I-Chao/AHA-3605-2022; Shen, Yuecheng/AFJ-9304-2022; Chen,
   Bing-Yu/E-7498-2016
OI Chen, Bing-Yu/0000-0003-0169-7682
FU Ministry of Science and Technology, Taiwan [MOST109-2218-E-002-030,
   109-2634-F-002-032]; National Taiwan University; MediaTek Fellowship;
   Grants-in-Aid for Scientific Research [21F20075] Funding Source: KAKEN
FX The authors would like to thank the National Center for High-Performance
   Computing. The authors would also like to thank Tzu-mao Li, Sheng-Jie
   Luo, Yu-Ting Wu, Chi-Lan Yang, and anonymous reviewers for insightful
   suggestions and discussion. This work was supported in part by the
   Ministry of Science and Technology, Taiwan, under Grants
   MOST109-2218-E-002-030 and 109-2634-F-002-032, and in part by National
   Taiwan University. The work of I-Chao Shen was supported by the MediaTek
   Fellowship.
CR Acuna D, 2018, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2018.00096
   Adobe, 2020, AD ILL 2020 IM TRAC
   Arjovsky M, 2017, Arxiv, DOI [arXiv:1701.07875, DOI 10.48550/ARXIV.1701.07875]
   Ba J.L., 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06450
   Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023
   Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002
   Bengio Y., 2009, P 26 ANN INT C MACH, P41
   Bessmeltsev M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3202661
   Chaudhuri S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964930
   Hin TCL, 2020, Arxiv, DOI arXiv:1906.09840
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Favreau JD, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130888
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Garces E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601131
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gryaditskaya Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356533
   Guérin E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130804
   Ha D, 2017, Arxiv, DOI arXiv:1704.03477
   Hacohen G, 2019, Arxiv, DOI arXiv:1904.03626
   Han C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275082
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoshyari S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201312
   Inkscape Project, 2020, INKSC
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2018, Arxiv, DOI [arXiv:1611.07004, DOI 10.48550/ARXIV.1611.07004]
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Karras T, 2020, Arxiv, DOI arXiv:1912.04958
   Kim B, 2018, COMPUT GRAPH FORUM, V37, P329, DOI 10.1111/cgf.13365
   Kingma DP, 2014, ADV NEUR IN, V27
   Koch S, 2019, PROC CVPR IEEE, P9593, DOI 10.1109/CVPR.2019.00983
   Kopf J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964994
   Li J., 2019, PROC INT C LEARN REP
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Lin S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461988
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y., 2016, PROC INT S NONPHOTOR
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lopes RG, 2019, IEEE I CONF COMP VIS, P7929, DOI 10.1109/ICCV.2019.00802
   Lopez-Moreno J, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461972
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Orzan A, 2013, COMMUN ACM, V56, P101, DOI 10.1145/2483852.2483873
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Paszke A., 2017, AUT WORKSH LONG BEAC
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Sbai O, 2019, Arxiv, DOI arXiv:1812.05484
   Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241
   Shugrina M, 2019, PROC CVPR IEEE, P5379, DOI 10.1109/CVPR.2019.00553
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Sorkine Olga, 2004, P 2004 EUR ACM SIGGR, P175
   Stepin M., 2003, HQX
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Vector Magic, 2020, CED LAK VENT
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Wang Tuanfeng Y., 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3272127.3275074
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xia T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618461
   Xie J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6695, DOI 10.1145/3025453.3025872
   Yan ZH, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356573
   Yin WP, 2017, Arxiv, DOI arXiv:1702.01923
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
   Zhu CY, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275008
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zou CH, 2017, IEEE I CONF COMP VIS, P900, DOI 10.1109/ICCV.2017.103
NR 76
TC 5
Z9 5
U1 3
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4211
EP 4224
DI 10.1109/TVCG.2021.3084944
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400019
PM 34057894
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lee, DJL
   Setlur, V
   Tory, M
   Karahalios, K
   Parameswaran, A
AF Lee, Doris Jung-Lin
   Setlur, Vidya
   Tory, Melanie
   Karahalios, Karrie
   Parameswaran, Aditya
TI Deconstructing Categorization in Visualization Recommendation: A
   Taxonomy and Comparative Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Taxonomy; Encoding; Recommender
   systems; Task analysis; Visual analytics; Visual analysis; analytical
   workflow; discovery-driven analysis; visualization recommendations
ID DATA EXPLORATION
AB Visualization recommendation (VisRec) systems provide users with suggestions for potentially interesting and useful next steps during exploratory data analysis. These recommendations are typically organized into categories based on their analytical actions, i.e., operations employed to transition from the current exploration state to a recommended visualization. However, despite the emergence of a plethora of VisRec systems in recent work, the utility of the categories employed by these systems in analytical workflows has not been systematically investigated. Our article explores the efficacy of recommendation categories by formalizing a taxonomy of common categories and developing a system, Frontier, that implements these categories. Using Frontier, we evaluate workflow strategies adopted by users and how categories influence those strategies. Participants found recommendations that add attributes to enhance the current visualization and recommendations that filter to sub-populations to be comparatively most useful during data exploration. Our findings pave the way for next-generation VisRec systems that are adaptive and personalized via carefully chosen, effective recommendation categories.
C1 [Lee, Doris Jung-Lin; Parameswaran, Aditya] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Setlur, Vidya] Tableau Res, Palo Alto, CA 94306 USA.
   [Tory, Melanie] Northeastern Univ, Boston, MA 02115 USA.
   [Karahalios, Karrie] Univ Illinois, Champaign, IL 61820 USA.
C3 University of California System; University of California Berkeley;
   Northeastern University; University of Illinois System; University of
   Illinois Urbana-Champaign
RP Lee, DJL (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM dorisjunglinlee@gmail.com; vidya.setlur@gmail.com;
   m.tory@northeastern.edu; kkarahal@cs.uiuc.edu; adityagp@berkeley.edu
OI Lee, Jung Lin/0000-0003-1922-2482
CR Adomavicius G., 2008, 2008 WORK INF TECHNO, P151
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Anand A, 2016, IEEE T VIS COMPUT GR, V22, P669, DOI 10.1109/TVCG.2015.2467323
   [Anonymous], VEGA DATASET CARS
   [Anonymous], 120 YEARS OLYMPIC HI
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Clarke C.L., 2008, P 31 ANN INT ACM SIG, P659, DOI [10.1145/1390334.1390446, DOI 10.1145/1390334.1390446]
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Cui Z, 2018, Arxiv, DOI arXiv:1802.08621
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   eBay, US
   English J., 2002, FLEXIBLE SEARCH NAVI
   Fast E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174047
   Google, 2015, EXPL GOOGL SHEETS
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Haas P. J., 2017, arXiv
   Hearst M, 2002, COMMUN ACM, V45, P42, DOI 10.1145/567498.567525
   Hearst MartiA., 2006, P SIGIR 2006 WORKSH, P26
   Horvitz E, 1999, P CHI, P159, DOI DOI 10.1145/302979.303030
   Hu K, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209910
   Joglekar Manas, 2015, Proceedings VLDB Endowment, V8, P1928
   Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Key A., 2012, P ACM SIGMOD INT C M, P681, DOI DOI 10.1145/2213836.2213931
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P427, DOI 10.1109/TVCG.2018.2864526
   Lee D. J.-L., 2020, MEDIUM FEB
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lee DJL, 2020, IEEE T VIS COMPUT GR, V26, P1267, DOI 10.1109/TVCG.2019.2934666
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Mahyar N, 2014, IEEE T VIS COMPUT GR, V20, P1633, DOI 10.1109/TVCG.2014.2346573
   McNee S.M., 2006, CHI 06 EXTENDED ABST, P1103
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, PROC VIS ANAL, P42, DOI [10.1201/b17511-4, DOI 10.1201/B17511-4]
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Nielsen J., 1990, SIGCHI Bulletin, P249
   Parameswaran A., 2019, P IEEE S INF VIS
   Rivest RL, 2009, Introduction to Algorithms
   Sarawagi S, 1998, LECT NOTES COMPUT SC, V1377, P168
   Sarvghad A, 2017, IEEE T VIS COMPUT GR, V23, P21, DOI 10.1109/TVCG.2016.2598466
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Strauss A., 1994, HDB QUALITATIVE RES, P273, DOI DOI 10.1007/BF00988593
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Tunkelang D., 2009, Faceted Search
   Us department of education, COLL SCOR DAT
   van den Elzen S, 2013, COMPUT GRAPH FORUM, V32, P191, DOI 10.1111/cgf.12106
   Vargas Saul, 2011, 5 ACM C REC SYST REC, P109, DOI DOI 10.1145/2043932.2043955
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Viegas Fernanda, 2018, Patent No. [US 20180088753 A1, 20180088753]
   White Ryen W., 2007, P 16 INT C WORLD WID, P21, DOI [DOI 10.1145/1242572.1242576, 10.1145/1242572.1242576]
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Wu E, 2013, PROC VLDB ENDOW, V6, P553, DOI 10.14778/2536354.2536356
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI [DOI 10.1145/642611.642681, 10.1145/642611.642681]
   Zhou T, 2010, P NATL ACAD SCI USA, V107, P4511, DOI 10.1073/pnas.1000488107
   US
NR 76
TC 5
Z9 7
U1 4
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4225
EP 4239
DI 10.1109/TVCG.2021.3085751
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400020
PM 34061748
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Parger, M
   Tang, CC
   Xu, YL
   Twigg, CD
   Tao, LL
   Li, YJ
   Wang, R
   Steinberger, M
AF Parger, Mathias
   Tang, Chengcheng
   Xu, Yuanlu
   Twigg, Christopher D.
   Tao, Lingling
   Li, Yijing
   Wang, Robert
   Steinberger, Markus
TI UNOC: Understanding Occlusion for Embodied Presence in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tracking; Cameras; Three-dimensional displays; Headphones; Kinematics;
   Videos; Optical sensors; Motion capture; machine learning; body
   tracking; embodied presence; virtual reality
AB Tracking body and hand motions in 3D space is essential for social and self-presence in augmented and virtual environments. Unlike the popular 3D pose estimation setting, the problem is often formulated as egocentric tracking based on embodied perception (e.g., egocentric cameras, handheld sensors). In this article, we propose a new data-driven framework for egocentric body tracking, targeting challenges of omnipresent occlusions in optimization-based methods (e.g., inverse kinematics solvers). We first collect a large-scale motion capture dataset with both body and finger motions using optical markers and inertial sensors. This dataset focuses on social scenarios and captures ground truth poses under self-occlusions and body-hand interactions. We then simulate the occlusion patterns in head-mounted camera views on the captured ground truth using a ray casting algorithm and learn a deep neural network to infer the occluded body parts. Our experiments show that our method is able to generate high-fidelity embodied poses by applying the proposed method to the task of real-time egocentric body tracking, finger motion synthesis, and 3-point inverse kinematics.
C1 [Parger, Mathias; Steinberger, Markus] Graz Univ Technol, A-8010 Graz, Austria.
   [Tang, Chengcheng; Xu, Yuanlu; Twigg, Christopher D.; Tao, Lingling; Li, Yijing; Wang, Robert] Facebook Real Labs Res, Menlo Pk, CA 94025 USA.
C3 Graz University of Technology
RP Parger, M (corresponding author), Graz Univ Technol, A-8010 Graz, Austria.
EM mathias.parger@icg.tugraz.at; tangchengcheng717@gmail.com;
   yuanluxu@ieee.org; cdtwigg@gmail.com; taolingling06@gmail.com;
   yijingli@fb.com; rywang@csail.mit.edu; steinberger@icg.tugraz.at
RI Tang, Chengcheng/F-9865-2017; Yuanlu, Xu/W-6921-2019
OI Wang, Robert/0000-0002-9298-7337; Xu, Yuanlu/0000-0002-7095-1018; Twigg,
   Christopher/0000-0003-3778-2520; Parger, Mathias/0000-0002-9074-4374
CR [Anonymous], 2007, DOCUMENTATION MOCAP
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Bertasius G., 2019, ADV NEUR IN, V32
   Bleser G., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P103, DOI 10.1109/ISMAR.2011.6092528
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137
   Cheng Y, 2020, AAAI CONF ARTIF INTE, V34, P10631
   Cheng Y, 2019, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2019.00081
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Doersch C., 2019, PROC ADV NEURAL INF, P12905
   Ericson C., 2004, Real-Time Collision Detection (The Morgan Kaufmann Series in Interactive 3-D Technology)
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Ghiasi G, 2014, PROC CVPR IEEE, P2401, DOI 10.1109/CVPR.2014.308
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guerra-Filho G, 2012, IMAGE VISION COMPUT, V30, P251, DOI 10.1016/j.imavis.2011.12.002
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang F, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P309, DOI 10.1145/3013971.3013987
   Jiang H, 2017, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2017.373
   Jörg S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366208
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Lee G, 2019, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2019.00085
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Mantiuk RK, 2012, COMPUT GRAPH FORUM, V31, P2478, DOI 10.1111/j.1467-8659.2012.03188.x
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mousas C, 2015, PROCEEDINGS SCCG: 2015 31ST SPRING CONFERENCE ON COMPUTER GRAPHICS, P96, DOI 10.1145/2788539.2788552
   Mueller F, 2017, IEEE INT CONF COMP V, P1284, DOI 10.1109/ICCVW.2017.82
   Parger M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281529
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Peng X, 2018, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2018.00237
   Radwan I, 2013, IEEE I CONF COMP VIS, P1888, DOI 10.1109/ICCV.2013.237
   Rhodin H, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980235
   Rhodin H, 2015, IEEE I CONF COMP VIS, P765, DOI 10.1109/ICCV.2015.94
   Rogez G, 2016, ADV NEUR IN, V29
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sigal Leonid., 2006, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V2, P2041
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338
   Taheri Omid, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P581, DOI 10.1007/978-3-030-58548-8_34
   Tome D, 2019, IEEE I CONF COMP VIS, P7727, DOI 10.1109/ICCV.2019.00782
   Wang YY, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2874357
   Xu WP, 2019, IEEE T VIS COMPUT GR, V25, P2093, DOI 10.1109/TVCG.2019.2898650
   Xu YL, 2019, IEEE I CONF COMP VIS, P7759, DOI 10.1109/ICCV.2019.00785
   Yuan Y, 2018, LECT NOTES COMPUT SC, V11220, P763, DOI 10.1007/978-3-030-01270-0_45
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
NR 50
TC 6
Z9 6
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4240
EP 4251
DI 10.1109/TVCG.2021.3085407
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400021
PM 34061744
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yuan, LP
   Zhou, ZQ
   Zhao, J
   Guo, YQ
   Du, F
   Qu, HM
AF Yuan, Lin-Ping
   Zhou, Ziqi
   Zhao, Jian
   Guo, Yiqiu
   Du, Fan
   Qu, Huamin
TI InfoColorizer: Interactive Recommendation of Color Palettes for
   Infographics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Tools; Visualization; Layout; Engines; Deep
   learning; Data visualization; Color palettes design; infographics;
   visualization recommendation; machine learning
ID SCHEMES; DESIGN
AB When designing infographics, general users usually struggle with getting desired color palettes using existing infographic authoring tools, which sometimes sacrifice customizability, require design expertise, or neglect the influence of elements' spatial arrangement. We propose a data-driven method that provides flexibility by considering users' preferences, lowers the expertise barrier via automation, and tailors suggested palettes to the spatial layout of elements. We build a recommendation engine by utilizing deep learning techniques to characterize good color design practices from data, and further develop InfoColorizer, a tool that allows users to obtain color palettes for their infographics in an interactive and dynamic manner. To validate our method, we conducted a comprehensive four-part evaluation, including case studies, a controlled user study, a survey study, and an interview study. The results indicate that InfoColorizer can provide compelling palette recommendations with adequate flexibility, allowing users to effectively obtain high-quality color design for input infographics with low effort.
C1 [Yuan, Lin-Ping; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Zhou, Ziqi; Zhao, Jian] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   [Guo, Yiqiu] Xi An Jiao Tong Univ, Xian 710061, Peoples R China.
   [Du, Fan] Adobe Res, San Jose, CA 95110 USA.
C3 Hong Kong University of Science & Technology; University of Waterloo;
   Xi'an Jiaotong University; Adobe Systems Inc.
RP Zhao, J (corresponding author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
EM lyuanaa@cse.ust.hk; z229zhou@uwaterloo.ca; jianzhao@uwaterloo.ca;
   maxleaf@stu.xjtu.edu.cn; fdu@adobe.com; huamin@cse.ust.hk
OI Yuan, Linping/0000-0001-6268-1583; Zhou, Ziqi/0000-0002-0861-1805
FU NSERC Discovery Grant; Microsoft Research Asia; Adobe Gift Fund
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported in part by the NSERC
   Discovery Grant, in part by the Research Grant from Microsoft Research
   Asia, and in part by Adobe Gift Fund.
CR Adobe Color, 2020, ADOBE COLOR
   [Anonymous], 2020, SVG INFOGRAPHICS
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Color brewer, 2020, COLORBREWER
   Coolors, 2020, COOLORS
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Desolneux A, 2004, THEORY DECIS LIB A, V38, P71
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Feichtner EM, 2005, P AM MATH SOC, V133, P999, DOI 10.1090/S0002-9939-04-07731-7
   Figurnov M., 2019, PROC INT C LEARN REP, P1
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Heer J., 2012, P SIGCHI C HUM FACT, P1007, DOI [DOI 10.1145/2207676.22085472,4, 10.1145/2207676.2208547, DOI 10.1145/2207676.2208547, 10.1145/2207676.22085472,4]
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Jalal G, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4207, DOI 10.1145/2702123.270217
   Kim J, 2012, J MACH LEARN RES, V13, P2529
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kingma D. P., 2014, INT C LEARNING REPRE
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   LEVKOWITZ H, 1992, IEEE COMPUT GRAPH, V12, P72, DOI 10.1109/38.135886
   Lin S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461988
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Lu M, 2020, PROC CHI C HUM FACTO, P770
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   MassVis, 2020, MASSVIS
   Meier BJ, 2004, IEEE COMPUT GRAPH, V24, P64, DOI 10.1109/MCG.2004.1297012
   Mittelstädt S, 2014, COMPUT GRAPH FORUM, V33, P231, DOI 10.1111/cgf.12379
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Palmer SE, 2013, ANNU REV PSYCHOL, V64, P77, DOI 10.1146/annurev-psych-120710-100504
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ramer-Douglas-Peucker, 1972, RAM DOUGL PEUCK ALG
   ROTH SF, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P112, DOI 10.1145/191666.191719
   Saleh B, 2015, Arxiv, DOI arXiv:1505.01214
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Shugrina M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300686
   Shugrina M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073690
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   van Buuren S, 2011, J STAT SOFTW, V45, P1
   visdata, 2020, VIUSALLY29K
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Yoon J, 2018, PR MACH LEARN RES, V80
   Zhao NX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201355
NR 71
TC 25
Z9 26
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4252
EP 4266
DI 10.1109/TVCG.2021.3085327
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400022
PM 34061743
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Abramson, MA
   Kent, GD
   Smith, GW
AF Abramson, Mark A.
   Kent, Griffin D.
   Smith, Gavin W.
TI Penetration Depth Between Two Convex Polyhedra: An Efficient Stochastic
   Global Optimization Approach
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Computational modeling; Stochastic processes; Linear
   programming; Atmospheric modeling; Mathematical model; Interference;
   Constrained optimization; global optimization; nonlinear optimization;
   penetration depth; geometric modelling
ID ALGORITHM; SEARCH; DISTANCES
AB During the detailed design phase of an aerospace program, one of the most important consistency checks is to ensure that no two distinct objects occupy the same physical space. Since exact geometrical modeling is usually intractable, geometry models are discretized, which often introduces small interferences not present in the fully detailed model. In this paper, we focus on computing the depth of the interference, so that these false positive interferences can be removed, and attention can be properly focused on the actual design. Specifically, we focus on efficiently computing the penetration depth between two polyhedra, which is a well-studied problem in the computer graphics community. We formulate the problem as a constrained five-variable global optimization problem, and then derive an equivalent unconstrained, two-variable nonsmooth problem. To solve the optimization problem, we apply a popular stochastic multistart optimization algorithm in a novel way, which exploits the advantages of each problem formulation simultaneously. Numerical results for the algorithm, applied to 14 randomly generated pairs of penetrating polytopes, illustrate both the effectiveness and efficiency of the method.
C1 [Abramson, Mark A.; Kent, Griffin D.] Utah Valley Univ, Orem, UT 84058 USA.
   [Kent, Griffin D.] Lehigh Univ, Bethlehem, PA 18015 USA.
   [Smith, Gavin W.] Intel Corp, Hillsboro, OR 97124 USA.
C3 Utah System of Higher Education; Utah Valley University; Lehigh
   University; Intel Corporation
RP Abramson, MA (corresponding author), Utah Valley Univ, Orem, UT 84058 USA.
EM mark.bramson@uvu.edu; 10764442@my.uvu.edu; gavin.w.smith@intel.com
CR Abramson M. A., 2014, SATECH14004 BOEING C
   Abramson MA, 2005, SIAM J OPTIMIZ, V16, P515, DOI 10.1137/04060367X
   Agarwal P. K., 2000, Nordic Journal of Computing, V7, P227
   Audet C, 2003, SIAM J OPTIMIZ, V13, P889, DOI 10.1137/S1052623400378742
   BAJAJ CL, 1992, SIAM J COMPUT, V21, P339, DOI 10.1137/0221025
   Byrd RH, 2000, MATH PROGRAM, V89, P149, DOI 10.1007/PL00011391
   Byrd RH, 1999, SIAM J OPTIMIZ, V9, P877, DOI 10.1137/S1052623497325107
   Cameron S, 1997, IEEE INT CONF ROBOT, P3112, DOI 10.1109/ROBOT.1997.606761
   Cameron S. A., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P591
   Chazelle B., 1981, P 13 ANN ACM S THEOR, P70, DOI DOI 10.1145/800076.802459
   DOBKIN D, 1993, ALGORITHMICA, V9, P518, DOI 10.1007/BF01190153
   FLETCHER R, 1963, COMPUT J, V6, P163, DOI 10.1093/comjnl/6.2.163
   GILBERT EG, 1988, IEEE T ROBOTIC AUTOM, V4, P193, DOI 10.1109/56.2083
   Gill P.E., 1981, PRACTICAL OPTIMIZATI
   GOLDFARB D, 1970, MATH COMPUT, V24, P23, DOI 10.2307/2004873
   HAN SP, 1977, J OPTIMIZ THEORY APP, V22, P297, DOI 10.1007/BF00932858
   Kan A. H. G. R., 1984, STOCHASTIC APPROACH
   KAN AHGR, 1987, MATH PROGRAM, V39, P27, DOI 10.1007/BF02592070
   KAN AHGR, 1987, MATH PROGRAM, V39, P57
   Kim YJ, 2004, IEEE T VIS COMPUT GR, V10, P152, DOI 10.1109/TVCG.2004.1260767
   Kim YJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P921, DOI 10.1109/ROBOT.2002.1013474
   Kolda TG, 2003, SIAM REV, V45, P385, DOI [10.1137/S003614450242889, 10.1137/S0036144502428893]
   Kraft D, 1988, Technical Report DFVLR-FB 88-28
   Lalee M, 1998, SIAM J OPTIMIZ, V8, P682, DOI 10.1137/S1052623493262993
   Lewis RM, 1999, SIAM J OPTIMIZ, V9, P1082, DOI 10.1137/S1052623496300507
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Ong CJ, 1996, IEEE T ROBOTIC AUTOM, V12, P888, DOI 10.1109/70.544772
   Powell M. J. D., 1978, Proceedings of the Biennial Conference on numerical analysis, P144
   Powell M.J.D., 1978, Nonlinear Programming, V3, P27
   Spellucci P, 1998, MATH METHOD OPER RES, V47, P355, DOI 10.1007/BF01198402
   TONE K, 1983, MATH PROGRAM, V26, P144, DOI 10.1007/BF02592051
   Waltz RA, 2006, MATH PROGRAM, V107, P391, DOI 10.1007/s10107-004-0560-5
   Zhang L., 2006, PROC ACM SOLID PHYS, P173
NR 33
TC 2
Z9 2
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4267
EP 4273
DI 10.1109/TVCG.2021.3085703
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400023
PM 34061747
DA 2024-11-06
ER

PT J
AU Xiong, WD
   Cheung, CM
   Sander, PV
   Joneja, A
AF Xiong, Weidan
   Cheung, Chong Mo
   Sander, Pedro, V
   Joneja, Ajay
TI Rationalizing Architectural Surfaces Based on Clustering of Joints
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Shape; Clustering algorithms; Geometry; Measurement; Steel;
   Indexing; Joints; discrete equivalence joint classes; conformal
   geometry; architectural geometry
ID ALGORITHM
AB We introduce the problem of clustering the set of vertices in a given 3D mesh. The problem is motivated by the need for value engineering in architectural projects. We first derive a max-norm based metric to estimate the geometric disparity between a given pair of vertices, and characterize the problem in terms of this measure. We show that this distance can be computed by using Sequential Quadratic Programming (SQP). Next we introduce two different algorithms for clustering the set of vertices on a given mesh, respectively based on two disparity measurements: max-norm and L2-norm based metric. An equivalence is established between mesh vertices and physical joints in an architectural mesh. By replacing individual joints by their equivalent cluster representative, the number of unique joints in the facade mesh, and therefore the fabrication cost, is dramatically reduced. Finally, we present an algorithm for remeshing a given surface in order to further reduce the number of joint clusters. The framework is tested for a set of real-world architectural surfaces to illustrate the effectiveness and utility of our approach. Overall, this approach tackles the important problem reducing fabrication cost of joints without modifying the underlying connectivity that was specified by the architect.
C1 [Xiong, Weidan] Nanyang Technol Univ, Singapore 639798, Singapore.
   [Cheung, Chong Mo; Sander, Pedro, V; Joneja, Ajay] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Nanyang Technological University; Hong Kong University of Science &
   Technology
RP Sander, PV; Joneja, A (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM wxiongab@connect.ust.hk; ieterence@ust.hk; psander@cse.ust.hk;
   joneja@ust.hk
RI Xiong, Weidan/KCL-5461-2024
OI Xiong, Weidan/0000-0001-5490-3676
FU UGC GRF [613312, 16213519]
FX The authors would like to thank the Departments of CSE, IEDA, and ECE in
   HKUST. The authors also would like to thank our reviewers for their
   helpful comments. Part of the research was supported by UGC GRF Grants
   #613312 and #16213519.
CR Alliez P, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P49
   Aloise D, 2009, MACH LEARN, V75, P245, DOI 10.1007/s10994-009-5103-0
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Botsch Mario, 2004, P 2004 EUR ACM SIGGR, P185, DOI DOI 10.1145/1057432.1057457
   Botsch Mario., 2010, POLYGON MESH PROCESS
   Cabrera D, 2010, SOUMAYA
   Chen HK, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P862, DOI 10.1109/IS3C.2016.219
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Dasgupta S, 2009, IEEE T INFORM THEORY, V55, P3229, DOI 10.1109/TIT.2009.2021326
   De Berg M., 2000, Computational geometry: Algorithms and applications
   DIRAC PAM, 1953, PHYSICA, V19, P888, DOI 10.1016/S0031-8914(53)80099-6
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048
   Eigensatz M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778782
   FEYNMAN RP, 1963, ANN PHYS-NEW YORK, V24, P118, DOI 10.1016/0003-4916(63)90068-X
   Hinojosa J., 2011, MUSEO SOUMAYA MEXICO
   Jiang CG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073619
   Jiang CG, 2014, COMPUT GRAPH FORUM, V33, P185, DOI 10.1111/cgf.12444
   KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P543, DOI 10.1109/34.291441
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kumar A, 2004, ANN IEEE SYMP FOUND, P454, DOI 10.1109/FOCS.2004.7
   Lai YK, 2006, VISUAL COMPUT, V22, P604, DOI 10.1007/s00371-006-0047-x
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Pietroni N, 2015, COMPUT GRAPH FORUM, V34, P627, DOI 10.1111/cgf.12590
   RLPhongkong, 2013, CHIN OP CTR W KOWL C
   Schiftner A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618485
   Singh M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778783
   Sorkine-Hornung O., 2017, Computing, V1, P1
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Wang HZ, 2011, R J, V3, P29, DOI 10.32614/rj-2011-015
   Xiong WD, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3198034
   Zimmer H, 2014, IEEE T VIS COMPUT GR, V20, P1461, DOI 10.1109/TVCG.2014.2307885
NR 35
TC 1
Z9 1
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4274
EP 4288
DI 10.1109/TVCG.2021.3085685
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400024
PM 34061746
DA 2024-11-06
ER

PT J
AU Cooper, VL
   Bieron, JC
   Peers, P
AF Cooper, Victoria L.
   Bieron, James C.
   Peers, Pieter
TI Estimating Homogeneous Data-Driven BRDF Parameters From a Reflectance
   Map Under Known Natural Lighting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Estimation; Shape; Analytical models; Optimization; Encoding;
   Maximum a posteriori estimation; Homogeneous BRDF; data-driven; natural
   lighting
AB In this article we demonstrate robust estimation of the model parameters of a fully-linear data-driven BRDF model from a reflectance map under known natural lighting. To regularize the estimation of the model parameters, we leverage the reflectance similarities within a material class. We approximate the space of homogeneous BRDFs using a Gaussian mixture model, and assign a material class to each Gaussian in the mixture model. We formulate the estimation of the model parameters as a non-linear maximum a-posteriori optimization, and introduce a linear approximation that estimates a solution per material class from which the best solution is selected. We demonstrate the efficacy and robustness of our method using the MERL BRDF database under a variety of natural lighting conditions, and we provide a proof-of-concept real-world experiment.
C1 [Cooper, Victoria L.] Randolph Macon Coll, Ashland, VA 23005 USA.
   [Cooper, Victoria L.; Bieron, James C.; Peers, Pieter] Coll William & Mary, Williamsburg, VA 23185 USA.
C3 William & Mary
RP Peers, P (corresponding author), Coll William & Mary, Williamsburg, VA 23185 USA.
EM vlcooper@email.wm.edu; jcbieron@email.wm.edu; ppeers@cs.wm.edu
FU NSF [IIS-1350323, IIS-1909028]
FX This work was supported in part by NSF under Grants IIS-1350323 and
   IIS-1909028, and gifts from Google, Activision, and Nvidia.
CR Bagher MM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2907941
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Bieron J, 2020, COMPUT GRAPH FORUM, V39, P59, DOI 10.1111/cgf.14054
   Bieron J. C., 2020, PROC EUROGRAPHICS WO
   Cooper V. L., 2019, PROC EUROGRAPHICS WO
   Debevec P., 1998, LIGHT PROBE GALLERY
   Dong Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661283
   Dorsey J, 2008, MKS COMP GRAPH GEOME, P1
   Jakob Wenzel., 2010, Mitsuba physically based renderer
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275055
   Li ZQ, 2018, LECT NOTES COMPUT SC, V11207, P74, DOI 10.1007/978-3-030-01219-9_5
   Lin Y, 2019, COMPUT GRAPH FORUM, V38, P15, DOI 10.1111/cgf.13766
   Lombardi S, 2016, IEEE T PATTERN ANAL, V38, P129, DOI 10.1109/TPAMI.2015.2430318
   Matusik W., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P241
   Matusik W, 2003, ACM T GRAPHIC, V22, P759, DOI 10.1145/882262.882343
   Nielsen JB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818085
   Nishino K, 2011, J OPT SOC AM A, V28, P8, DOI 10.1364/JOSAA.28.000008
   Oxholm G, 2016, IEEE T PATTERN ANAL, V38, P376, DOI 10.1109/TPAMI.2015.2450734
   Palma G, 2012, COMPUT GRAPH FORUM, V31, P1491, DOI 10.1111/j.1467-8659.2012.03145.x
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Rematas K, 2016, PROC CVPR IEEE, P4508, DOI 10.1109/CVPR.2016.488
   Romeiro F, 2008, LECT NOTES COMPUT SC, V5305, P859, DOI 10.1007/978-3-540-88693-8_63
   Romeiro F, 2010, LECT NOTES COMPUT SC, V6311, P45, DOI 10.1007/978-3-642-15549-9_4
   Serrano A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980242
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P135, DOI 10.1111/cgf.13348
   Vávra R, 2016, COMPUT GRAPH FORUM, V35, P299, DOI 10.1111/cgf.13027
   Walter B., 2007, RENDERING TECHNIQUES
   WARD GJ, 1992, COMP GRAPH, V26, P265, DOI 10.1145/142920.134078
   Weinmann M., 2015, PROC SIGGRAPHASIA CO, P1
   Xia R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980248
   Xu ZX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982396
   Ye WJ, 2018, COMPUT GRAPH FORUM, V37, P201, DOI 10.1111/cgf.13560
   Zhou ZM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980247
NR 35
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4289
EP 4303
DI 10.1109/TVCG.2021.3085560
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400025
PM 34061745
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Huang, H
   Zhong, F
   Qin, XY
AF Huang, Hong
   Zhong, Fan
   Qin, Xueying
TI Pixel-Wise Weighted Region-Based 3D Object Tracking Using Contour
   Constraints
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Search problems; Three-dimensional displays;
   Object tracking; Histograms; Color; Solid modeling; Pose estimation; 3D
   object tracking; region-based method; pixel-wise weighting
ID TIME VISUAL TRACKING; POSE ESTIMATION; SEGMENTATION
AB Region-based methods are currently achieving state-of-the-art performance for monocular 3D object tracking. However, they are still prone to fail in cases of partial occlusions and ambiguous colors. We propose a novel region-based method to tackle these problems. The key idea is to derive a pixel-wise weighted region-based cost function using contour constraints. First, we propose a novel region-based cost function using search lines around the object contour, which is more efficient than previous region-based cost functions using signed distance transform, and in the meantime can deal with partial occlusions and ambiguous colors more effectively. Second, we propose an optimal searching strategy to search the object contour points in cluttered scenes, and then use the object contour points to detect partial occlusions and ambiguous colors. Third, we propose a pixel-wise weight function based on color and distance constraints of the object contour points, and integrate it into the proposed region-based cost function to reduce the negative impact of partial occlusions and ambiguous colors. We verify the effectiveness and efficiency of our method on challenging public datasets. Experiments demonstrate that our method outperforms the recent state-of-the-art region-based methods in complex scenarios, especially in the presence of partial occlusions and ambiguous colors.
C1 [Huang, Hong; Qin, Xueying] Shandong Univ, Sch Software, Jinan 250100, Peoples R China.
   [Zhong, Fan] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
C3 Shandong University; Shandong University
RP Qin, XY (corresponding author), Shandong Univ, Sch Software, Jinan 250100, Peoples R China.; Zhong, F (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Peoples R China.
EM huanghone@sina.com; zhongfan@sdu.edu.cn; qxy@sdu.edu.cn
OI Huang, Hong/0000-0003-4111-0698
FU Zhejiang Lab [2020NB0AB02]; SenseTime
FX The authors gratefully acknowledge the reviewers for their comments to
   help us to improve our article, and also thank for their enormous help
   in revising this article. This work was supported in part by SenseTime
   and Zhejiang Lab under Grant 2020NB0AB02.
CR Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Dambreville S, 2008, LECT NOTES COMPUT SC, V5303, P169, DOI 10.1007/978-3-540-88688-4_13
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Felzenszwalb P.F., 2012, Theory Comput, V8, P415, DOI [10.4086/toc.2012.v008a019, DOI 10.4086/TOC.2012.V008A019]
   Harris C., 1990, BMVC90 Proceedings of the British Machine Vision Conference, P73
   Hexner J, 2016, INT J COMPUT VISION, V118, P95, DOI 10.1007/s11263-015-0873-2
   Hinterstoisser S, 2007, IEEE I CONF COMP VIS, P1372
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hinterstoisser V., 2012, PROC ASIAN C COMPUT, P548
   Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2
   Imperoli M, 2015, LECT NOTES COMPUT SC, V9163, P316, DOI 10.1007/978-3-319-20904-3_29
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/978-3-030-01231-1_42, 10.1007/s11263-019-01250-9]
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Manhardt F, 2018, LECT NOTES COMPUT SC, V11218, P833, DOI 10.1007/978-3-030-01264-9_49
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256
   Seo BK, 2014, IEEE T VIS COMPUT GR, V20, P99, DOI 10.1109/TVCG.2013.94
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tjaden H, 2019, IEEE T PATTERN ANAL, V41, P1797, DOI 10.1109/TPAMI.2018.2884990
   Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23
   Tjaden H, 2016, LECT NOTES COMPUT SC, V9908, P423, DOI 10.1007/978-3-319-46493-0_26
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wang B, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095172
   Wang B, 2019, MULTIMED TOOLS APPL, V78, P12307, DOI 10.1007/s11042-018-6727-5
   Wang GF, 2015, VISUAL COMPUT, V31, P979, DOI 10.1007/s00371-015-1098-7
   Wu PC, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P186, DOI 10.1109/ISMAR-Adjunct.2017.62
   Zhao S, 2014, IEEE IMAGE PROC, P486, DOI 10.1109/ICIP.2014.7025097
   Zhong LS, 2020, IEEE T IMAGE PROCESS, V29, P5065, DOI 10.1109/TIP.2020.2973512
   Zhong LS, 2019, INT J COMPUT VISION, V127, P973, DOI 10.1007/s11263-018-1119-x
   Zhong LS, 2018, IEEE T CIRC SYST VID, V28, P2302, DOI 10.1109/TCSVT.2017.2731519
NR 35
TC 5
Z9 6
U1 1
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4319
EP 4331
DI 10.1109/TVCG.2021.3085197
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400026
PM 34077359
DA 2024-11-06
ER

PT J
AU Oagaz, H
   Schoun, B
   Choi, MH
AF Oagaz, Hawkar
   Schoun, Breawn
   Choi, Min-Hyung
TI Performance Improvement and Skill Transfer in Table Tennis Through
   Training in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports; Training; Physics; Videos; Games; Visualization; Real-time
   systems; Virtual reality; training; motor learning; performance
   improvement; skill transfer
ID FEEDBACK
AB Sports professionals have been increasingly using Virtual Reality (VR) for training and assessment of skill-based sports. Yet fundamental questions about the virtue of VR training for skill-based sports remain unanswered: Can the complex motor skills in these sports be learned in VR? If so, do these skills transfer to the real world? We have developed a VR table tennis system that incorporates customized physics with realistic audio-visual stimuli, haptics, and motion capture to enhance VR immersion and collect information about the player's posture and technique. We have assessed skill acquisition and training transfer by comparing real table tennis performance between a control group (n=7) that received no training and an experimental group (n=8) trained for five sessions in VR. Results show a significant improvement in technique but no significant changes in the number of the returned balls in the experimental group in the real-life retention session. However, no significant differences are found in the control group. Our findings support the notion that complex skills can be learned in VR and that obtained skills can transfer to the real world. This work offers an inexpensive VR table tennis training platform, enabling effective training via real-time motor and ball returning technique feedback.
C1 [Oagaz, Hawkar; Schoun, Breawn; Choi, Min-Hyung] Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80204 USA.
C3 University of Colorado System; University of Colorado Denver
RP Choi, MH (corresponding author), Univ Colorado, Dept Comp Sci & Engn, Denver, CO 80204 USA.
EM hawkar.oagaz@ucdenver.edu; breawn.schoun@ucdenver.edu;
   min.choi@ucdenver.edu
OI Schoun, Breawn/0000-0001-7540-3398
FU Comcast Media and Technology Center at the University of Colorado Denver
FX The authors would like to thank Thomas D. Goddard and Ritesh Sood for
   their contribution to the physics simulation. The authors would also
   like to thank Angelo Gandullia, our professional table tennis trainer.
   This work was supported in part by the Comcast Media and Technology
   Center at the University of Colorado Denver.
CR [Anonymous], 2021, HDB INT TABLE TENNIS
   Appelbaum LG, 2018, INT REV SPORT EXER P, V11, P160, DOI 10.1080/1750984X.2016.1266376
   Berndt D. J., 1994, P KDD WORKSH SEATTL, P359, DOI DOI 10.5555/3000850.3000887
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Brunnett G, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.92
   Calatayud D, 2010, ANN SURG, V251, P1181, DOI 10.1097/SLA.0b013e3181deb630
   Covaci A, 2015, IEEE COMPUT GRAPH, V35, P55, DOI 10.1109/MCG.2015.95
   Crecente B., 2013, REV KINECT SPORTS
   D_orrfuss K, 2008, PROC SEMINAR HUM COM
   experttabletennis, PLAY TABLE TENNIS
   Gobel S., 2010, Proceedings of the International Conference on Advanced Visual Interfaces, P337, DOI [DOI 10.1145/1842993.1843056, 10.1145/1842993.1843056]
   Gray R, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02183
   Knoerlein Benjamin, 2007, Advances in Computer Entertainment Technology, P91, DOI [10.1145/1255047.1255065, DOI 10.1145/1255047.1255065]
   KOZAK JJ, 1993, ERGONOMICS, V36, P777, DOI 10.1080/00140139308967941
   Lammfromm R., 2011, BIOWEB C, V1, P00054, DOI DOI 10.1051/BIOCONF/20110100054
   Li YZ, 2010, IEEE INT CONF INF VI, P500, DOI 10.1109/IV.2010.97
   Mas A, 2018, 2018 IEEE FOURTH VR INTERNATIONAL WORKSHOP ON COLLABORATIVE VIRTUAL ENVIRONMENTS (3DCVE)
   Mestre DR, 2011, PRESENCE-VIRTUAL AUG, V20, P1, DOI 10.1162/pres_a_00031
   Michalski SC, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02159
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Miles HC, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P56, DOI 10.1109/CW.2013.45
   Miles HC, 2012, COMPUT GRAPH-UK, V36, P714, DOI 10.1016/j.cag.2012.04.007
   Rauter G, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082145
   SALMONI AW, 1984, PSYCHOL BULL, V95, P355, DOI 10.1037/0033-2909.95.3.355
   Strandbygaard J, 2013, ANN SURG, V257, P839, DOI 10.1097/SLA.0b013e31827eee6e
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Tirp Judith, 2015, Psychological Test and Assessment Modeling, V57, P57, DOI DOI 10.3389/FPSYG.2017.02183
   Todorov E, 1997, J MOTOR BEHAV, V29, P147, DOI 10.1080/00222899709600829
   Wong DWC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155203
   Woodward C., 2004, Proceedings of the 2004 ACM SIGCHI International Conference on Advances in computer entertainment technology, P275
NR 30
TC 24
Z9 24
U1 15
U2 89
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4332
EP 4343
DI 10.1109/TVCG.2021.3086403
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400027
PM 34081582
DA 2024-11-06
ER

PT J
AU Han, DY
   Parsad, G
   Kim, H
   Shim, J
   Kwon, OS
   Son, KA
   Lee, J
   Cho, I
   Ko, S
AF Han, Dongyun
   Parsad, Gorakh
   Kim, Hwiyeon
   Shim, Jaekyom
   Kwon, Oh-Sang
   Son, Kyung A.
   Lee, Jooyoung
   Cho, Isaac
   Ko, Sungahn
TI HisVA: A Visual Analytics System for Studying History
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE History; Encyclopedias; Internet; Information services; Electronic
   publishing; Education; Tools; Visualization for education; event
   visualization; studying history; Wikipedia
ID FLIPPED CLASSROOMS; DISORIENTATION; SUPPORT; DESIGN; POINT; WEB
AB Studying history involves many difficult tasks. Examples include searching for proper data in a large event space, understanding stories of historical events by time and space, and finding relationships among events that may not be apparent. Instructors who extensively use well-organized and well-argued materials (e.g., textbooks and online resources) can lead students to a narrow perspective in understanding history and prevent spontaneous investigation of historical events, with the students asking their own questions. In this article, we proposed HisVA, a visual analytics system that allows the efficient exploration of historical events from Wikipedia using three views: event, map, and resource. HisVA provides an effective event exploration space, where users can investigate relationships among historical events by reviewing and linking them in terms of space and time. To evaluate our system, we present two usage scenarios, a user study with a qualitative analysis of user exploration strategies, and in-class deployment results.
C1 [Han, Dongyun; Cho, Isaac] Utah State Univ, Logan, UT 84322 USA.
   [Parsad, Gorakh; Kim, Hwiyeon] UNIST, Dept Comp Sci, Ulsan 44919, South Korea.
   [Shim, Jaekyom] UNIST, Leadership Ctr, Ulsan 44919, South Korea.
   [Kwon, Oh-Sang] UNIST, Dept Biomed Engn, Ulsan 44919, South Korea.
   [Son, Kyung A.] UNIST, U Innovat Educ Ctr, Ulsan 44919, South Korea.
   [Lee, Jooyoung] UNIST, Sch Liberal Arts, Ulsan 44919, South Korea.
   [Ko, Sungahn] UNIST, Sch Comp Sci & Engn, Ulsan 44919, South Korea.
C3 Utah System of Higher Education; Utah State University; Ulsan National
   Institute of Science & Technology (UNIST); Ulsan National Institute of
   Science & Technology (UNIST); Ulsan National Institute of Science &
   Technology (UNIST); Ulsan National Institute of Science & Technology
   (UNIST); Ulsan National Institute of Science & Technology (UNIST); Ulsan
   National Institute of Science & Technology (UNIST)
RP Ko, S (corresponding author), UNIST, Sch Comp Sci & Engn, Ulsan 44919, South Korea.
EM dongyun.han@aggiemail.usu.edu; badyalgaurav@unist.ac.kr;
   gnldus28@unist.ac.kr; jaekyom@unist.ac.kr; oskwon@unist.ac.kr;
   kasohn@unist.ac.kr; shallibrown@unist.ac.kr; isaac.cho@usu.edu;
   sako@unist.ac.kr
RI Cho, Isaac/KIE-5167-2024; Kwon, Oh-Sang/HOC-9591-2023
OI Kwon, Oh-Sang/0000-0002-9866-8222; Ko, Sungahn/0000-0002-7410-5652; Han,
   Dongyun/0000-0002-9517-5326
FU National Research Foundation (NRF) [2021R1A2C1004542,
   2020R1H1A110101311]; MSIT (Ministry of Science and ICT), Korea, under
   the ITRC (Information Technology Research Center) support program
   [IITP-2021-2017-0-01635]; Institute of Information & Communications
   Technology Planning & Evaluation (IITP) - Korea government (MSIT),
   Artificial Intelligence graduate school program (UNIST) [2020-0-01336]
FX This work was supported in part by the National Research Foundation
   (NRF) grant (No. 2021R1A2C1004542, No. 2020R1H1A110101311) and by the
   MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) support program (IITP-2021-2017-0-01635)
   supervised by the IITP (Institute for Information& Communications
   Technology Promotion). This work was also supported in part by Institute
   of Information & Communications Technology Planning & Evaluation (IITP)
   grant funded by the Korea government (MSIT)-No.2020-0-01336, Artificial
   Intelligence graduate school program (UNIST). The development and
   evaluation of the system and initial draft of this manuscript were done
   when Dongyun Han worked toward his M.S. degree atUNIST, Korea.
CR Alpha history, US
   Andrienko G, 2010, COMPUT GRAPH FORUM, V29, P913, DOI 10.1111/j.1467-8659.2009.01664.x
   [Anonymous], 2006, GEOPY
   [Anonymous], 2000, In search of understanding
   Bergmann J., 2012, FLIP YOUR CLASSROOM
   Bertin J., 1983, Semiology of Graphics
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boadu G., 2014, International Journal of Learning, Teaching and Educational Research, V8, P187
   Cabiness C, 2013, TECHTRENDS, V57, P38
   Chen Q, 2020, IEEE T VIS COMPUT GR, V26, P1622, DOI 10.1109/TVCG.2018.2872961
   Cho I, 2016, IEEE T VIS COMPUT GR, V22, P210, DOI 10.1109/TVCG.2015.2467971
   Clark J, 2017, EDUC PHILOS THEORY, V49, P656, DOI 10.1080/00131857.2015.1104231
   d3js, about us
   Dias P, 1999, J EDUC COMPUT RES, V20, P93, DOI 10.2190/G8C5-342V-DJX3-Q53F
   Dimitrov D, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P917, DOI 10.1145/3038912.3052613
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   Driscoll M. P., 1994, Psychology of learning for instruction
   EHuf2EK R, 2010, P LREC 2010 WORKSHOP, P46
   El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654
   Eveland WP, 2001, COMMUN RES, V28, P48, DOI 10.1177/009365001028001002
   Finkel Jenny Rose, 2005, P 43 ANN M ASS COMP, P363
   Firat E. E., 2018, P C COMP GRAPH VIS C, P91, DOI DOI 10.2312/CGVC.20181211
   Flask, About us
   Francesco Ricci B. S., 2015, RECOMMENDER SYSTEMS
   github, LEAFLET MARKERCLUSTE
   Grishman R., 1996, COLING, DOI 10.3115/992628.992709
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Hammond M., 2014, SELF DIRECTED LEARNI
   Hoffman M., 2010, ADV NEURAL INFORM PR
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Itoh M., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P283, DOI 10.1109/IV.2012.55
   Kim MK, 2014, INTERNET HIGH EDUC, V22, P37, DOI 10.1016/j.iheduc.2014.04.003
   Knowles M. S., 1975, SELF DIRECTED LEARNI
   Ko S, 2012, COMPUT GRAPH FORUM, V31, P1245, DOI 10.1111/j.1467-8659.2012.03117.x
   Krahenbuhl K.S., 2016, Clear. House A J. Educ. Strategies, Issues Ideas, V89, P97, DOI [10.1080/00098655.2016.1191311, DOI 10.1080/00098655.2016.1191311]
   Leaflet, about Us
   LEBOW D, 1993, ETR&D-EDUC TECH RES, V41, P4, DOI 10.1007/BF02297354
   Lee C, 2020, IEEE T VIS COMPUT GR, V26, P3133, DOI 10.1109/TVCG.2019.2922597
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lévesque S, 2015, REV ESTUD SOC, P32
   Liang HN, 2009, INTERACT LEARN ENVIR, V17, P53, DOI 10.1080/10494820701610605
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Mayr E., 2016, PROC IEEE VIS WORKSH
   McCallum A, 2002, A machine learning for language toolkit
   McCarthy J.P., 2000, Innov. High. Educ, V24, P279, DOI DOI 10.1023/B:IHIE.0000047415.48495.05
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Nguyen PH, 2019, IEEE T VIS COMPUT GR, V25, P2838, DOI 10.1109/TVCG.2018.2859969
   O'Flaherty J, 2015, INTERNET HIGH EDUC, V25, P85, DOI 10.1016/j.iheduc.2015.02.002
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Poitras EG, 2014, ETR&D-EDUC TECH RES, V62, P335, DOI 10.1007/s11423-014-9338-5
   Rector LH, 2008, REF SERV REV, V36, P7, DOI 10.1108/00907320810851998
   Richardson V, 2003, TEACH COLL REC, V105, P1623, DOI 10.1046/j.1467-9620.2003.00303.x
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324
   Samoilenko A, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P843, DOI 10.1145/3178876.3186132
   Samoilenko Anna, 2017, P 11 INT AAAI C WEB, P210, DOI DOI 10.1609/ICWSM.V11I1.14881
   Savich C, 2008, NETWORKS, V11, P1
   Schwarzer M, 2016, ACM-IEEE J CONF DIG, P191, DOI 10.1145/2910896.2910908
   Seefeldt D., 2009, PERSPECTIVES HIST
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Teh Y. W., 2004, P 17 INT C NEUR INF, P1385
   Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748
   Ware C., 2019, Information Visualization: Perception for Design
   Westad Odd Arne, 2005, The Global Cold War: Third World Interventions and the Making of Our Times
   Whitelaw M, 2015, DIGIT HUMANITIES Q, V9
   wikipedia, COLD WAR
   wikipedia, WORLD WAR 2
   wikipedia, WORLD WAR 1
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
NR 70
TC 6
Z9 6
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4344
EP 4359
DI 10.1109/TVCG.2021.3086414
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400028
PM 34086573
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ramamurthi, Y
   Agarwal, T
   Chattopadhyay, A
AF Ramamurthi, Yashwanth
   Agarwal, Tripti
   Chattopadhyay, Amit
TI A Topological Similarity Measure Between Multi-Resolution Reeb Spaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topology; Measurement; Extraterrestrial measurements; Shape; Current
   measurement; Distortion measurement; Particle measurements; Multi-field;
   reeb space; similarity measure; multi-resolution; joint contour net
ID PERSISTENCE; GRAPHS
AB Searching similarity between a pair of shapes or data is an important problem in data analysis and visualization. The problem of computing similarity measures using scalar topology has been studied extensively and proven useful in the shape and data matching. Even though multi-field or multivariate (consists of multiple scalar fields) topology reveals richer topological features, research on building tools for computing similarity measures using multi-field topology is still in its infancy. In the current article, we propose a novel similarity measure between two piecewise-linear multi-fields based on their multi-resolution Reeb spaces - a newly developed data-structure that captures the topology of a multi-field. Overall, our method consists of two steps: (i) building a multi-resolution Reeb space corresponding to each of the multi-fields and (ii) proposing a similarity measure between two multi-resolution Reeb spaces by computing a list of topologically consistent matching pairs (of nodes) and the similarity between them. We demonstrate the effectiveness of the proposed similarity measure in detecting topological features from real time-varying multi-field data in two application domains - one from computational physics and one from computational chemistry.
C1 [Ramamurthi, Yashwanth; Chattopadhyay, Amit] Int Inst Informat Technol IIIT, Bangalore 560100, Karnataka, India.
   [Agarwal, Tripti] Univ Utah, SCI, Salt Lake City, UT 84112 USA.
C3 International Institute of Information Technology Bangalore (IIIT
   Bangalore); Utah System of Higher Education; University of Utah
RP Chattopadhyay, A (corresponding author), Int Inst Informat Technol IIIT, Bangalore 560100, Karnataka, India.
EM yashwanth@iiitb.ac.in; tripti.agarwal@iiitb.org;
   a.chattopadhyay@iiitb.ac.in
OI Ramamurthi, Yashwanth/0000-0003-4933-0898; Chattopadhyay,
   Amit/0000-0003-4691-3019
FU Science and Engineering Research Board (SERB), India
   [SERB/CRG/2018/000702]; International Institute of Information
   Technology(IIITB), Bangalore
FX Amit Chattopadhyay would like to thank Prof. Osamu Saeki for his
   feedback on the initial draft of the article. The authors would like to
   thank the anonymous reviewers for their valuable suggestions and
   feedback to improve the article. This work was supported in part by the
   Science and Engineering Research Board (SERB), India, under Grant
   SERB/CRG/2018/000702 and in part by the International Institute of
   Information Technology (IIITB), Bangalore.
CR AGARWAL PK, 2018, ACM T ALGORITHMS, V14
   Agarwal T, 2019, Arxiv, DOI arXiv:1911.00687
   [Anonymous], 2004, FDN COMPUTATIONAL MA
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Bauer U, 2014, Arxiv, DOI arXiv:1412.6646
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Biasotti S, 2003, LECT NOTES COMPUT SC, V2886, P194
   Biasotti S, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1391729.1391731
   Biasotti S, 2006, COMPUT AIDED DESIGN, V38, P1002, DOI 10.1016/j.cad.2006.07.003
   Burago D., 2001, CRM P LECT NOTES
   Carlsson G, 2010, J COMPUT GEOM, V1, P72
   Carlsson G, 2009, DISCRETE COMPUT GEOM, V42, P71, DOI 10.1007/s00454-009-9176-0
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H, 2014, IEEE T VIS COMPUT GR, V20, P1100, DOI 10.1109/TVCG.2013.269
   Carriere M., 2017, PROC INT S COMPUT GE, P25
   Chattopadhyay A., 2014, PROC EUROVIS SHORT P, P1
   Chattopadhyay A, 2016, COMP GEOM-THEOR APPL, V58, P1, DOI 10.1016/j.comgeo.2016.05.006
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cole-McLaughlin K, 2003, P 19 ANN S COMP GEOM, P344, DOI [10.1145/777792.777844, DOI 10.1145/777792.777844]
   de Silva V, 2016, DISCRETE COMPUT GEOM, V55, P854, DOI 10.1007/s00454-016-9763-9
   Dey T.K., 2014, P 30 ANN S COMP GEOM, P345, DOI DOI 10.1145/2582112.2582165
   Dey Tamal, 2016, P 27 S DISCR ALG, P997, DOI DOI 10.1137/1.9781611974331.CH71
   Di Fabio B, 2016, DISCRETE COMPUT GEOM, V55, P423, DOI 10.1007/s00454-016-9758-6
   Dimakis N, 2009, J PHYS CHEM C, V113, P18730, DOI 10.1021/jp9036809
   Duke D, 2012, IEEE T VIS COMPUT GR, V18, P2033, DOI 10.1109/TVCG.2012.287
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P242, DOI 10.1145/1377676.1377720
   Gao XB, 2010, PATTERN ANAL APPL, V13, P113, DOI 10.1007/s10044-008-0141-y
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Junyi Tu, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P99, DOI 10.1007/978-3-030-33720-9_8
   Dey TK, 2017, Arxiv, DOI arXiv:1503.07414
   Kendrick I, 2010, J AM CHEM SOC, V132, P17611, DOI 10.1021/ja1081487
   Kerber M, 2019, DISCRETE COMPUT GEOM, V61, P852, DOI 10.1007/s00454-018-0030-0
   Narayanan V, 2015, IEEE PAC VIS SYMP, P263, DOI 10.1109/PACIFICVIS.2015.7156386
   Patra A., 2018, THESIS TEMPLE U PHIL
   Saeki O, 2014, VISUALIZING MULTIVAR
   Saeki O., 2004, TOPOLOGY SINGULAR FI
   Saeki O., 2017, TOPOLOGICAL METHODS, V4
   Saikia H., 2015, TOPOLOGICAL METHODS, P121, DOI [10.1007/978-3-319-44684-4_7, DOI 10.1007/978-3-319-44684-4_7]
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Schroeder WJ, 2004, VISUALIZATION TOOLKI
   Singh G., 2007, S POINT BAS GRAPH, P91
   Somorjai G. A., 2010, INTRO SURFACE CHEM C
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Staszczak A, 2006, Arxiv, DOI arXiv:nucl-th/0612017
   TARJAN RE, 1975, J ACM, V22, P215, DOI 10.1145/321879.321884
   The GUDHI Project, 2020, GUDHI USER REFERENCE
   Thomas DM, 2014, IEEE T VIS COMPUT GR, V20, P2427, DOI 10.1109/TVCG.2014.2346332
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748
   Tung T, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P157, DOI 10.1109/SMI.2004.1314503
   Zhang X., 2004, Fast matching of volumetric functions using multi-resolution dual contour trees
NR 52
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4360
EP 4374
DI 10.1109/TVCG.2021.3087273
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400029
PM 34101594
DA 2024-11-06
ER

PT J
AU Corbalán-Navarro, D
   Aragón, JL
   Anglada, M
   de Lucas, E
   Parcerisa, JM
   González, A
AF Corbalan-Navarro, David
   Aragon, Juan L.
   Anglada, Marti
   de Lucas, Enrique
   Parcerisa, Joan-Manuel
   Gonzalez, Antonio
TI Omega-Test: A Predictive Early-Z Culling to Improve the Graphics
   Pipeline Energy-Efficiency
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Pipelines; Graphics processing units;
   Graphics; Computer architecture; Geometry; Games; Graphics processors;
   mobile processors; portable devices; hardware architecture; processor
   architecture; energy-aware systems; low-power design; hidden line;
   surface removal; visibility determination
AB The most common task of GPUs is to render images in real time. When rendering a 3D scene, a key step is to determine which parts of every object are visible in the final image. There are different approaches to solve the visibility problem, the Z-Test being the most common. A main factor that significantly penalizes the energy efficiency of a GPU, especially in the mobile arena, is the so-called overdraw, which happens when a portion of an object is shaded and rendered but finally occluded by another object. This useless work results in a waste of energy; however, a conventional Z-Test only avoids a fraction of it. In this article we present a novel microarchitectural technique, the Omega-Test, to drastically reduce the overdraw on a Tile-Based Rendering (TBR) architecture. Graphics applications have a great degree of inter-frame coherence, which makes the output of a frame very similar to the previous one. The proposed approach leverages the frame-to-frame coherence by using the resulting information of the Z-Test for a tile (a buffer containing all the calculated pixel depths for a tile), which is discarded by nowadays GPUs, to predict the visibility of the same tile in the next frame. As a result, the Omega-Test early identifies occluded parts of the scene and avoids the rendering of non-visible surfaces eliminating costly computations and off-chip memory accesses. Our experimental evaluation shows average EDP savings in the overall GPU/Memory system of 26.4 percent and an average speedup of 16.3 percent for the evaluated benchmarks.
C1 [Corbalan-Navarro, David; Aragon, Juan L.] Univ Murcia, Dept Ingn & Tecnol Comp, E-30100 Murcia, Spain.
   [Anglada, Marti; Parcerisa, Joan-Manuel; Gonzalez, Antonio] Univ Politecn Cataluna, Dept Arquitectura Comp, Barcelona 08034, Spain.
   [de Lucas, Enrique] Imaginat Technol, Imaginat House, Kings Langley WD4 8LZ, England.
C3 University of Murcia; Universitat Politecnica de Catalunya
RP Corbalán-Navarro, D (corresponding author), Univ Murcia, Dept Ingn & Tecnol Comp, E-30100 Murcia, Spain.
EM dcorbalan@ditec.um.es; jlaragon@ditec.um.es; manglada@ac.upc.edu;
   enrique.delucas@imgtec.com; jmanel@ac.upc.edu; antonio@ac.upc.edu
RI Aragón, Juan/ABB-5489-2020; Aragon, Juan Luis/E-1340-2015; Gonzalez,
   Antonio/I-2961-2014
OI Corbalan-Navarro, David/0000-0002-7079-6687; Aragon, Juan
   Luis/0000-0002-4955-7235; Gonzalez, Antonio/0000-0002-0009-0996;
   Parcerisa, Joan-Manuel/0000-0001-5771-8118; Anglada,
   Marti/0000-0002-1204-1841
FU CoCoUnit ERC Advanced Grant through EU's Horizon 2020 Program [833057];
   Spanish State Research Agency [TIN2016-75344-R]; ICREA Academia Program;
   University of Murcia
FX This work was supported in part by the CoCoUnit ERC Advanced Grant
   through EU's Horizon 2020 Program under Grant 833057, in part by the
   Spanish State Research Agency under Grant TIN2016-75344-R (AEI/FEDER,
   EU), and in part by the ICREA Academia Program. The work of D.
   Corbalan-Navarro was supported by a PhD Research Fellowship from the
   University of Murcia.
CR Akenine-Moller T., 2019, Real-time rendering
   Akenine-Möller T, 2008, P IEEE, V96, P779, DOI 10.1109/JPROC.2008.917719
   Andersson M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818138
   Anglada M, 2019, INT S HIGH PERF COMP, P635, DOI 10.1109/HPCA.2019.00015
   [Anonymous], Android SDK
   [Anonymous], 2013, KEYNOTE TALK HIGH PE
   Arnau J.-M., 2013, ICS 13, P37, DOI [10.1145/2464996.2464999, DOI 10.1145/2464996.2464999]
   beyond3d.com, PHOTO REALISTIC DEFE
   Bittner J, 2003, ENVIRON PLANN B, V30, P729, DOI 10.1068/b2957
   De Lucas E., 2018, THESIS U POLITECNICA
   de Lucas E, 2019, IEEE T PARALL DISTR, V30, P473, DOI 10.1109/TPDS.2018.2866246
   developer.arm.com, ARM MALI 450 GPU
   Gallium3d, GALLIUM3D
   Gapid, GAPID
   Greene N., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P65, DOI 10.1145/237170.237207
   Greene N., 1993, Computer Graphics Proceedings, P231, DOI 10.1145/166117.166147
   Haines E., 1996, J GRAPH TOOLS, V1, P1
   Hubschman H., 1982, ACM Transactions on Graphics, V1, P129
   I. T. Limited, POWERVR HARDWARE ARC
   Lim J, 2014, ACM T DES AUTOMAT EL, V19, DOI 10.1145/2611758
   Morein S., 2000, PRESENTED SIGGRAPHEU
   Patil S, 2015, L N INST COMP SCI SO, V162, P51, DOI 10.1007/978-3-319-29003-4_4
   Pool J., 2012, THESIS U N CAR CHAP
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Segal M., 1999, The opengl graphics system: A specification
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Shreiner Dave., 2010, OPENGL PROGRAMMING G
   Thibieroz Nicolas, 2004, Shader X, V2, P251
   Wilson Andrew, 2001, PROC 9 ACM INT C MUL, P348
   Zhang H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P77, DOI 10.1145/258734.258781
NR 30
TC 2
Z9 2
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4375
EP 4388
DI 10.1109/TVCG.2021.3087863
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400030
PM 34106856
OA Green Published
DA 2024-11-06
ER

PT J
AU Panagiotidou, G
   Vandam, R
   Poblome, J
   Vande Moere, A
AF Panagiotidou, Georgia
   Vandam, Ralf
   Poblome, Jeroen
   Vande Moere, Andrew
TI Implicit Error, Uncertainty and Confidence in Visualization: An
   Archaeological Case Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Data visualization; Cognition; Probes; Encoding; Decision
   making; Visual analytics; Data uncertainty; data visualization; implicit
   error; qualitative study; digital humanities; design study; archaeology
ID ATTITUDE CERTAINTY; VISUAL ANALYTICS; FRAMEWORK; TRUST
AB While we know that the visualization of quantifiable uncertainty impacts the confidence in insights, little is known about whether the same is true for uncertainty that originates from aspects so inherent to the data that they can only be accounted for qualitatively. Being embedded within an archaeological project, we realized how assessing such qualitative uncertainty is crucial in gaining a holistic and accurate understanding of regional spatio-temporal patterns of human settlements over millennia. We therefore investigated the impact of visualizing qualitative implicit errors on the sense-making process via a probe that deliberately represented three distinct implicit errors, i.e., differing collection methods, subjectivity of data interpretations and assumptions on temporal continuity. By analyzing the interactions of 14 archaeologists with different levels of domain expertise, we discovered that novices became more actively aware of typically overlooked data issues and domain experts became more confident of the visualization itself. We observed how participants quoted social factors to alleviate some uncertainty, while in order to minimize it they requested additional contextual breadth or depth of the data. While our visualization did not alleviate all uncertainty, we recognized how it sparked reflective meta-insights regarding methodological directions of the data. We believe our findings inform future visualizations on how to handle the complexity of implicit errors for a range of user typologies and for highly data-critical application domains such as the digital humanities.
C1 [Panagiotidou, Georgia; Vande Moere, Andrew] Katholieke Univ Leuven, RxD, B-3001 Leuven, Belgium.
   [Panagiotidou, Georgia; Vandam, Ralf; Poblome, Jeroen] Katholieke Univ Leuven, Sagalassos Archaeol Res Project, B-3000 Leuven, Belgium.
   [Vandam, Ralf] Vrije Univ Brussel, B-1050 Ixelles, Belgium.
C3 KU Leuven; KU Leuven; Vrije Universiteit Brussel
RP Panagiotidou, G (corresponding author), Katholieke Univ Leuven, RxD, B-3001 Leuven, Belgium.
EM georgia.panagiotidou@kuleuven.be; ralf.vandam@kuleuven.be;
   jeroen.poblome@kuleuven.be; andrew.vandemoere@kuleuven.be
RI Poblome, Jeroen/AAX-6812-2020; Vandam, Ralf/CAF-3469-2022; Vande Moere,
   Andrew/A-8491-2016
OI Poblome, Jeroen/0000-0002-7403-1921; Vandam, Ralf/0000-0002-9542-8477;
   Panagiotidou, Georgia/0000-0003-4408-6371; Vande Moere,
   Andrew/0000-0002-0085-4941
FU KU Leuven Research Fund; Research Foundation Flanders
FX The authors would like to thank the Sagalassos team for their support,
   as well as the reviewers for their constructive feedback. This work was
   supported by the KU Leuven Research Fund and the Research Foundation
   Flanders.
CR Banning E., 2002, ARCHAEOLOGICAL SURVE
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Boyatzis R., 1998, Transferring qualitative information", V1st
   Chapman R, 2016, DEBATE ARCHAEOL, P1
   Dasgupta A, 2017, IEEE T VIS COMPUT GR, V23, P271, DOI 10.1109/TVCG.2016.2598544
   Deitrick S., 2006, PROGR SPATIAL DATA H, P719, DOI [DOI 10.1007/3-540-35589-8_45, 10.1007/3-540-35589-8_45]
   Drucker J, 2011, DIGIT HUMANITIES Q, V5
   Elsden C., 2017, P 3 BIENN RES DES C, P148
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Franke M., 2019, PROC WORKSHOP VIS DI
   Galey A, 2010, LIT LINGUIST COMPUT, V25, P405, DOI 10.1093/llc/fqq021
   Glinka K, 2017, DIGIT HUMANITIES Q, V11
   Gortana F, 2018, OPEN LIBR HUMANIT, V4, DOI 10.16995/olh.280
   Greis M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P828, DOI 10.1145/3025453.3025998
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   Hinrichs U, 2016, IEEE T VIS COMPUT GR, V22, P429, DOI 10.1109/TVCG.2015.2467452
   Hogan T, 2016, IEEE T VIS COMPUT GR, V22, P2579, DOI 10.1109/TVCG.2015.2511718
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hutchinson Hilary, 2003, C HUM FACT COMP SYST
   Johanna D., 2012, DIGITAL HUMANITIES, P140
   Kale A., 2019, P 2019 CHI C HUMAN F, P1
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Kinkeldey C, 2017, CARTOGR GEOGR INF SC, V44, P1, DOI 10.1080/15230406.2015.1089792
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Lamqaddam H, 2021, IEEE T VIS COMPUT GR, V27, P1084, DOI 10.1109/TVCG.2020.3030426
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   Liu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376533
   Liu ZC, 2008, IEEE T VIS COMPUT GR, V14, P1173, DOI 10.1109/TVCG.2008.121
   Llobera M, 2011, J ARCHAEOL METHOD TH, V18, P193, DOI 10.1007/s10816-010-9098-4
   Lucas Gavin., 2012, Understanding the Archaeological Record, DOI DOI 10.1017/CBO9780511845772
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   MacEachren A.M., 2015, EUROVIS WORKSHOP ONV, P55
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Manovich L, 2011, VISUAL STUD, V26, P36, DOI 10.1080/1472586X.2011.548488
   McCall G., 2018, Strategies for Quantitative Research
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   McCurdy N, 2016, IEEE T VIS COMPUT GR, V22, P439, DOI 10.1109/TVCG.2015.2467811
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Miller P., 1995, CAA94 Proceedings of the 22nd CAA Conference, P19
   Moretti Franco, 2005, Graphs, Maps, Trees: Abstract Models for a Literary History
   Mortier R., 2014, SOCIAL SCI RES NETW
   Padilla LMK, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.579267
   Passi Samir, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274405
   Passi S, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P2436, DOI 10.1145/2998181.2998331
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Petrocelli JV, 2007, J PERS SOC PSYCHOL, V92, P30, DOI 10.1037/0022-3514.92.1.30
   Poblome J., 2018, Rei Cretariae Romanae Fautorum, V45, P731
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Schafer U.U., 2019, DAH Journal, V3, P87
   Schofield A.J., 1991, INTERPRETING ARTEFAC
   Tak S, 2014, IEEE T VIS COMPUT GR, V20, P935, DOI 10.1109/TVCG.2013.247
   Therón R, 2018, SIXTH INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY (TEEM'18), P826, DOI 10.1145/3284179.3284323
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Thudt A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173728
   Tormala ZL, 2007, SOC PERSONAL PSYCHOL, V1, P469, DOI 10.1111/j.1751-9004.2007.00025.x
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   Vandam R., 2019, MEANWHILE MOUNTAINS, P262
   Walker R, 2013, IEEE T VIS COMPUT GR, V19, P2139, DOI 10.1109/TVCG.2013.132
   White AR, 2019, INT J APPL EARTH OBS, V74, P37, DOI 10.1016/j.jag.2018.08.026
   Whitelaw M, 2015, DIGIT HUMANITIES Q, V9
   Windhager F., 2019, PROC WORKSHOPVIS DIG
   Windhager F., 2018, PROC EUROGRAPH PROC, P7
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Young AL, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P431, DOI 10.1145/2675133.2675183
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 70
TC 5
Z9 6
U1 2
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4389
EP 4402
DI 10.1109/TVCG.2021.3088339
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400031
PM 34110995
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Liu, KL
   Chen, DD
   Liao, J
   Zhang, WM
   Zhou, H
   Zhang, J
   Zhou, WB
   Yu, NH
AF Liu, Kunlin
   Chen, Dongdong
   Liao, Jing
   Zhang, Weiming
   Zhou, Hang
   Zhang, Jie
   Zhou, Wenbo
   Yu, Nenghai
TI JPEG Robust Invertible Grayscale
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Gray-scale; Transform coding; Image color analysis; Image restoration;
   Color; Training; Image coding; Invertible grayscale; adversarial
   training; JPEG robust
ID COLOR; CONVERSION; GREYSCALE; IMAGES
AB Invertible grayscale is a special kind of grayscale from which the original color can be recovered. Given an input color image, this seminal work tries to hide the color information into its grayscale counterpart while making it hard to recognize any anomalies. This powerful functionality is enabled by training a hiding sub-network and restoring sub-network in an end-to-end way. Despite its expressive results, two key limitations exist: 1) The restored color image often suffers from some noticeable visual artifacts in the smooth regions. 2) It is very sensitive to JPEG compression, i.e., the original color information cannot be well recovered once the intermediate grayscale image is compressed by JPEG. To overcome these two limitations, this article introduces adversarial training and JPEG simulator respectively. Specifically, two auxiliary adversarial networks are incorporated to make the intermediate grayscale images and final restored color images indistinguishable from normal grayscale and color images. And the JPEG simulator is utilized to simulate real JPEG compression during the online training so that the hiding and restoring sub-networks can automatically learn to be JPEG robust. Extensive experiments demonstrate that the proposed method is superior to the original invertible grayscale work both qualitatively and quantitatively while ensuring the JPEG robustness. We further show that the proposed framework can be applied under different types of grayscale constraints and achieve excellent results.
C1 [Liu, Kunlin; Zhang, Weiming; Zhou, Hang; Zhang, Jie; Zhou, Wenbo; Yu, Nenghai] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Anhui, Peoples R China.
   [Chen, Dongdong] Microsoft Res, Redmond, WA 98052 USA.
   [Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft; City University of Hong Kong
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230026, Anhui, Peoples R China.
EM lkl6949@cityu.edu.hk; cddlyf@gmail.com; jingliao@cityu.edu.hk;
   zhangwm@ustc.edu.cn; zh2991@cityu.edu.hk; zjzac@cityu.edu.hk;
   welbeckz@cityu.edu.hk; ynh@ustc.edu.cn
RI Chen, Dongdong/AAR-4481-2020; Zhou, Hang/AAI-5565-2021; Zhang,
   Zhiyong/KPY-6346-2024
OI LIAO, Jing/0000-0001-7014-5377; Chen, Dongdong/0000-0002-4642-4373;
   Zhang, Jie/0000-0002-4230-1077; Zhang, Weiming/0000-0001-5576-6108;
   Zhou, Hang/0000-0001-7860-8452
FU National Natural Science Foundation of China [62002334U20B2047,
   62072421]; Anhui Science Foundation of China [2008085QF296]; Anhui
   Initiative in Quantum Information Technologies [AHY15040]; Fundamental
   Research Funds for Central Universities of China [WK2100000018];
   Research Grants Council of the Hong Kong [CityU 21209119]; Natural
   Science Foundation of China [62072421, 62002334]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62002334U20B2047 and 62072421, in part
   by the Anhui Science Foundation of China under Grant 2008085QF296, in
   part by the Anhui Initiative in Quantum Information Technologies under
   Grant AHY15040, in part by the Fundamental Research Funds for Central
   Universities of China under Grant WK2100000018, in part by an ECS grant
   from the Research Grants Council of the Hong Kong (Project No. CityU
   21209119), and in part by the Natural Science Foundation of China
   (Project No. 62072421 and 62002334). Kunlin Liu and Dongdong Chen are
   co-first authors.
CR Alturki F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958548
   Bala R, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P82
   Bugeau A, 2014, IEEE T IMAGE PROCESS, V23, P298, DOI 10.1109/TIP.2013.2288929
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Cui M, 2010, VISUAL COMPUT, V26, P1349, DOI 10.1007/s00371-009-0412-7
   de Queiroz RL, 2010, PATTERN RECOGN LETT, V31, P269, DOI 10.1016/j.patrec.2008.11.010
   Fairchild M. D., 2013, Color appearance models, DOI 10.1002/9781118653128
   Fang FM, 2020, IEEE T VIS COMPUT GR, V26, P2931, DOI 10.1109/TVCG.2019.2908363
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gupta R.K., 2012, P 20 ACM INT C MULT, P369, DOI [10.1145/2393347.2393402, DOI 10.1145/2393347.2393402]
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Horiuchi T, 2018, IEEE SW SYMP IMAG, P13, DOI 10.1109/SSIAI.2018.8470306
   Horiuchi T, 2010, PATTERN RECOGN LETT, V31, P2405, DOI 10.1016/j.patrec.2010.07.014
   Iizuka S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925974
   Irony R., 2005, Rendering techniques, P201
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kuk JG, 2011, LECT NOTES COMPUT SC, V6495, P513, DOI 10.1007/978-3-642-19282-1_41
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Lin JQ, 2014, IEEE SW SYMP IMAG, P41, DOI 10.1109/SSIAI.2014.6806024
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu C.-C., 2007, Proc. International Semiconductor Device Research Symposium, P1, DOI [DOI 10.1109/ICCPHOT.2012.6215215, 10.1109/ICCPhot.2012.6215215]
   Luan Q., 2007, P 18 EUR REND TECHN, P309
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Neumann L., 2007, PROC 3 EUR C COMPUTA, P73
   Nohara F, 2009, IEEE IMAGE PROC, P485, DOI 10.1109/ICIP.2009.5414355
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Ramkumar M, 1999, PROC SPIE, V3845, P55, DOI 10.1117/12.371234
   Rasche K, 2005, IEEE COMPUT GRAPH, V25, P22, DOI 10.1109/MCG.2005.54
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Su JW, 2020, PROC CVPR IEEE, P7965, DOI 10.1109/CVPR42600.2020.00799
   Tan ZT, 2022, IEEE T PATTERN ANAL, V44, P4852, DOI 10.1109/TPAMI.2021.3076487
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Vitoria P, 2020, IEEE WINT CONF APPL, P2434, DOI [10.1109/wacv45572.2020.9093389, 10.1109/WACV45572.2020.9093389]
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Welsh T, 2002, ACM T GRAPHIC, V21, P277, DOI 10.1145/566570.566576
   Widadi K. C., 2005, PROC IEEE 5 INT C IN, P1125
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Xia MH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275080
   Xiao Y, 2022, IEEE T VIS COMPUT GR, V28, P1557, DOI 10.1109/TVCG.2020.3021510
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073703
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhu J, 2018, IEEE T VIS COMPUT GR, V24, P2473, DOI 10.1109/TVCG.2017.2753255
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 6
Z9 8
U1 2
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4403
EP 4417
DI 10.1109/TVCG.2021.3088531
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400032
PM 34115588
DA 2024-11-06
ER

PT J
AU Liu, Z
   Li, YL
   Wang, WN
   Liu, LG
   Chen, RJ
AF Liu, Zheng
   Li, Yanlei
   Wang, Weina
   Liu, Ligang
   Chen, Renjie
TI Mesh Total Generalized Variation for Denoising
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Noise reduction; TV; Faces; Smoothing methods; Optimization; Image
   restoration; Three-dimensional displays; Mesh denoising; total
   generalized variation; augmented Lagrangian method; total variation;
   normal filtering
ID REGULARIZATION; DIFFUSION; ROF
AB Recent studies have shown that the Total Generalized Variation (TGV) is highly effective in preserving sharp features as well as smooth transition variations for image processing tasks. However, currently there is no existing work that is suitable for applying TGV to 3D data, in particular, triangular meshes. In this article, we develop a novel framework for discretizing second-order TGV on triangular meshes. Further, we propose a TGV-based variational method for the denoising of face normal fields on triangular meshes. The TGV regularizer in our method is composed of a first-order term and a second-order term, which are automatically balanced. The first-order term allows our TGV regularizer to locate and preserve sharp features, while the second-order term allows our regularizer to recognize and recover smoothly curved regions. To solve the optimization problem, we introduce an efficient iterative algorithm based on variable-splitting and augmented Lagrangian method. Extensive results and comparisons on synthetic and real scanning data validate that the proposed method outperforms the state-of-the-art visually and numerically.
C1 [Liu, Zheng; Li, Yanlei] China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Sch Geog & Informat Engn, Wuhan 430074, Hubei, Peoples R China.
   [Wang, Weina] Hangzhou Dianzi Univ, Dept Math, Hangzhou 310018, Zhejiang, Peoples R China.
   [Liu, Ligang; Chen, Renjie] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
C3 China University of Geosciences; Hangzhou Dianzi University; Chinese
   Academy of Sciences; University of Science & Technology of China, CAS
RP Chen, RJ (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Anhui, Peoples R China.
EM liu.zheng.jojo@gmail.com; leelele@cug.edu.cn; wnwang@hdu.edu.cn;
   lgliu@ustc.edu.cn; renjiec@ustc.edu.cn
RI Chen, Renjie/AFU-3325-2022; Liu, Ligang/IZQ-5817-2023; chen,
   renjie/I-5995-2016
OI chen, renjie/0000-0001-8395-4392; Liu, Zheng/0000-0001-6713-6680
FU NSF of China [62072422, 12001144, 62025207, 62076227, 61702467];
   National Key R&D Program of China [2020YFC1523102]; NSF of Anhui
   Province, China [2008085MF195]; Youth Science and Technology Foundation
   of Gansu [20JR5RA050]; NSF of Zhejiang Province, China [LQ20A010007];
   Zhejiang Lab [2019NB0AB03]
FX This work was supported in part by the NSF of China under Grants
   62072422, 12001144, 62025207, 62076227, and 61702467, in part by the
   National Key R&D Program of China under Grant 2020YFC1523102, in part by
   the NSF of Anhui Province, China, under Grant 2008085MF195, in part by
   the Youth Science and Technology Foundation of Gansu under Grant
   20JR5RA050, in part by the NSF of Zhejiang Province, China, under Grant
   LQ20A010007, and in part by the Zhejiang Lab under Grant 2019NB0AB03.
CR Arvanitis G, 2019, IEEE T VIS COMPUT GR, V25, P1513, DOI 10.1109/TVCG.2018.2802926
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Bajaj CL, 2003, ACM T GRAPHIC, V22, P4, DOI 10.1145/588272.588276
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chen HH, 2019, COMPUT AIDED DESIGN, V115, P122, DOI 10.1016/j.cad.2019.05.036
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Feng WS, 2014, IEEE T IMAGE PROCESS, V23, P1831, DOI 10.1109/TIP.2014.2308432
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   He L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461965
   Jones TR, 2003, ACM T GRAPHIC, V22, P943, DOI 10.1145/882262.882367
   Jung M, 2015, SIAM J IMAGING SCI, V8, P721, DOI 10.1137/140967416
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lai RJ, 2013, SIAM J SCI COMPUT, V35, pA675, DOI 10.1137/110846634
   Li XZ, 2021, IEEE T VIS COMPUT GR, V27, P4060, DOI 10.1109/TVCG.2020.3001681
   Li XZ, 2018, COMPUT GRAPH FORUM, V37, P155, DOI 10.1111/cgf.13556
   Li ZQ, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102861
   Liu Z, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102857
   Liu Z, 2020, COMPUT AIDED DESIGN, V126, DOI 10.1016/j.cad.2020.102858
   Liu Z, 2019, COMPUT AIDED GEOM D, V71, P190, DOI 10.1016/j.cagd.2019.04.013
   Liu Z, 2019, SIAM J SCI COMPUT, V41, pB1, DOI 10.1137/17M115743X
   Lu X., 2019, COMPUT AIDED GEOM D, V114, P133
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Lu XQ, 2016, IEEE T VIS COMPUT GR, V22, P1181, DOI 10.1109/TVCG.2015.2500222
   Niu SZ, 2014, PHYS MED BIOL, V59, P2997, DOI 10.1088/0031-9155/59/12/2997
   Pan W, 2020, COMPUT AIDED DESIGN, V121, DOI 10.1016/j.cad.2019.102807
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sun XF, 2007, IEEE T VIS COMPUT GR, V13, P925, DOI 10.1109/TVCG.2007.1065
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Wang CCL, 2006, IEEE T VIS COMPUT GR, V12, P629, DOI 10.1109/TVCG.2006.60
   Wang J, 2019, COMPUT AIDED DESIGN, V114, P133, DOI 10.1016/j.cad.2019.05.027
   Wang J, 2012, COMPUT AIDED DESIGN, V44, P597, DOI 10.1016/j.cad.2012.03.001
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wei M, 2019, COMPUT GRAPH FORUM, V38, P591, DOI 10.1111/cgf.13863
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P2910, DOI 10.1109/TVCG.2018.2865363
   Wei MQ, 2017, IEEE T AUTOM SCI ENG, V14, P931, DOI 10.1109/TASE.2016.2553449
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Wu XQ, 2015, COMPUT GRAPH FORUM, V34, P35, DOI 10.1111/cgf.12743
   Yadav SK, 2019, IEEE T VIS COMPUT GR, V25, P2304, DOI 10.1109/TVCG.2018.2828818
   Yadav SK, 2018, IEEE T VIS COMPUT GR, V24, P2366, DOI 10.1109/TVCG.2017.2740384
   Zhang HY, 2015, IEEE T VIS COMPUT GR, V21, P873, DOI 10.1109/TVCG.2015.2398432
   Zhang JY, 2019, IEEE T VIS COMPUT GR, V25, P1774, DOI 10.1109/TVCG.2018.2816926
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zhao WB, 2021, IEEE T VIS COMPUT GR, V27, P1937, DOI 10.1109/TVCG.2019.2944357
   Zhao Y, 2018, COMPUT AIDED DESIGN, V101, P82, DOI 10.1016/j.cad.2018.04.001
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
   Zhong SS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051001
NR 49
TC 20
Z9 21
U1 2
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4418
EP 4433
DI 10.1109/TVCG.2021.3088118
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400033
PM 34115587
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Thiel, KK
   Naumann, F
   Jundt, E
   Günnemann, S
   Klinker, G
AF Thiel, Kevin Kennard
   Naumann, Florian
   Jundt, Eduard
   Guennemann, Stephan
   Klinker, Gudrun
TI C.DOT-Convolutional Deep Object Tracker for Augmented Reality Based
   Purely on Synthetic Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Target tracking; Optical imaging; Training; Neural networks;
   Tuning; Task analysis; Object tracking; deep learning; industry 4; 0;
   neural network; synthetic data; augmented reality; computer vision
ID TOOL
AB Augmented reality applications use object tracking to estimate the pose of a camera and to superimpose virtual content onto the observed object. Today, a number of tracking systems are available, ready to be used in industrial applications. However, such systems are hard to handle for a service maintenance engineer, due to obscure configuration procedures. In this article, we investigate options towards replacing the manual configuration process with a machine learning approach based on automatically synthesized data. We present an automated process of creating object tracker facilities exclusively from synthetic data. The data is highly enhanced to train a convolutional neural network, while still being able to receive reliable and robust results during real world applications only from simple RGB cameras. Comparison against related work using the LINEMOD dataset showed that we are able to outperform similar approaches. For our intended industrial applications with high accuracy demands, its performance is still lower than common object tracking methods with manual configuration. Yet, it can greatly support those as an add-on during initialization, due to its higher reliability.
C1 [Thiel, Kevin Kennard; Naumann, Florian; Jundt, Eduard] Volkswagen Grp, D-38440 Wolfsburg, Germany.
   [Thiel, Kevin Kennard; Guennemann, Stephan; Klinker, Gudrun] Tech Univ Munich, D-80333 Munich, Germany.
C3 Volkswagen; Volkswagen Germany; Technical University of Munich
RP Thiel, KK (corresponding author), Volkswagen Grp, D-38440 Wolfsburg, Germany.
EM kevin.thiel@volkswagen.de; florian.naumann@volkswagen.de;
   eduard.jundt@volkswagen.de; guennemann@in.tum.de; klinker@in.tum.de
RI Klinker, Gudrun/JVP-3665-2024
OI Naumann, Florian/0000-0001-6236-5628; Thiel, Kevin/0000-0003-2940-8061;
   Klinker, Gudrun/0000-0003-0971-5726
CR [Anonymous], 2015, ARXIV
   [Anonymous], 2016, IND 4 0 AUTOMOBILPRO
   [Anonymous], 2007, J VIRT REALITY BROAD, DOI DOI 10.20385/1860-2037/4.2007.1
   Bay H., 2008, COMPUT VIS IMAGE UND, V110, P346, DOI [10.1016/j.cviu.2007.09.014, DOI 10.1016/j.cviu.2007.09.014]
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Carreker D., 2012, The Game Developer's Dictionary: A Multidisciplinary Lexicon for Professionals and Students
   Csurka G, 2017, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-319-58347-1
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Echtler F, 2003, VIRTUAL AUGMENTED RE
   Engelke T., 2015, Proceedings of the 6th ACM Multimedia Systems Conference on-MMSys '15, P105, DOI 10.1145/2713168.2713169
   Esengün M, 2018, SPRINGER SER ADV MAN, P201, DOI 10.1007/978-3-319-57870-5_12
   Everingham M., 2012, PASCAL VISUAL OBJECT
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Garon M, 2018, LECT NOTES COMPUT SC, V11215, P608, DOI 10.1007/978-3-030-01252-6_36
   Garon M, 2017, IEEE T VIS COMPUT GR, V23, P2410, DOI 10.1109/TVCG.2017.2734599
   Gay-Bellile G., 2012, PROC IEEE ISMAR WORK
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinterstoisser S, 2019, LECT NOTES COMPUT SC, V11129, P682, DOI 10.1007/978-3-030-11009-3_42
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Hinterstoisser V., 2012, PROC ASIAN C COMPUT, P548
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Jakobi N, 1995, LECT NOTES ARTIF INT, V929, P704
   Karras T., 2017, ARXIV
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Khirodkar R, 2019, IEEE WINT CONF APPL, P1932, DOI 10.1109/WACV.2019.00210
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Klein George, 2007, P1
   Klinker G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2002.1115076
   Klinker G, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P124, DOI 10.1109/ISAR.2001.970522
   Klinker G., 2004, PROC IUI CADUI 04 WO, V91
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mallios A, 2014, AUTON ROBOT, V36, P181, DOI 10.1007/s10514-013-9345-0
   Manhardt F, 2018, LECT NOTES COMPUT SC, V11218, P833, DOI 10.1007/978-3-030-01264-9_49
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Montserrat D. M., 2019, MULTIVIEW MATCHING N
   Nölle S, 2006, INT SYM MIX AUGMENT, P114
   Olbrich M., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P269, DOI 10.1109/ISMAR.2011.6143896
   Ondrúska P, 2016, AAAI CONF ARTIF INTE, P3361
   Papon J, 2015, IEEE I CONF COMP VIS, P774, DOI 10.1109/ICCV.2015.95
   Pentenrieder K., 2007, 2007 6 IEEE ACM INT, P31
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rambach J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P164, DOI 10.1109/ISMAR-Adjunct.2018.00058
   Rambach J, 2018, COMPUTERS, V7, DOI 10.3390/computers7010006
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Reiners D, 1999, AUGMENTED REALITY, P31
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Resch C, 2016, IEEE T VIS COMPUT GR, V22, P1291, DOI 10.1109/TVCG.2015.2450934
   Schreiber W., 2011, Virtuelle Techniken im industriellen Umfeld: Das AVILUSProjekt; Technologien und Anwendungen, V1
   Schreiber W, ARVIDA BMBF PROJECT
   Schwerdtfeger B, 2008, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2008.4637331
   Sermanet P., 2014, INT C LEARN REPR
   Stanimirovic D, 2014, INT SYM MIX AUGMENT, P305, DOI 10.1109/ISMAR.2014.6948462
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Su YZ, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P222, DOI 10.1109/ISMAR-Adjunct.2019.00-42
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan DJ, 2015, IEEE I CONF COMP VIS, P693, DOI 10.1109/ICCV.2015.86
   Thiel K. K., 2017, PROC IEEE INT S MIXE, P132
   Thiel K. K., 2021, CDOT GROUND TRUTH DA, DOI [10.14459/2021mp1614575.001, DOI 10.14459/2021MP1614575.001]
   Tobin Josh, 2017, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P23, DOI 10.1109/IROS.2017.8202133
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wasenmüller O, 2016, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2016.15
   Welch G, 2002, IEEE COMPUT GRAPH, V22, P24, DOI 10.1109/MCG.2002.1046626
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Wong JM, 2017, IEEE INT C INT ROBOT, P5784, DOI 10.1109/IROS.2017.8206470
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Yim MYC, 2017, J INTERACT MARK, V39, P89, DOI 10.1016/j.intmar.2017.04.001
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 78
TC 7
Z9 7
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4434
EP 4451
DI 10.1109/TVCG.2021.3089096
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400034
PM 34125682
OA hybrid
DA 2024-11-06
ER

PT J
AU Goncalves, A
   Borrego, A
   Latorre, J
   Llorens, R
   Badia, SBI
AF Goncalves, Afonso
   Borrego, Adrian
   Latorre, Jorge
   Llorens, Roberto
   Badia, Sergi Bermudez, I
TI Evaluation of a Low-Cost Virtual Reality Surround-Screen Projection
   System
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE H.5 Information Interfaces and Representation (HCI); H.5.1.b Artificial;
   augmented; and virtual realities; H.5.2.e Evaluation/methodology
ID ENVIRONMENTS
AB Two of the most popular mediums for virtual reality are head-mounted displays and surround-screen projection systems, such as CAVE Automatic Virtual Environments. In recent years, HMDs suffered a significant reduction in cost and have become widespread consumer products. In contrast, CAVEs are still expensive and remain accessible to a limited number of researchers. This study aims to evaluate both objective and subjective characteristics of a CAVE-like monoscopic low-cost virtual reality surround-screen projection system compared to advanced setups and HMDs. For objective results, we measured the head position estimation accuracy and precision of a low-cost active infrared (IR) based tracking system, used in the proposed low-cost CAVE, relatively to an infrared marker-based tracking system, used in a laboratory-grade CAVE system. For subjective characteristics, we investigated the sense of presence and cybersickness elicited in users during a visual search task outside personal space, beyond arms reach, where the importance of stereo vision is diminished. Thirty participants rated their sense of presence and cybersickness after performing the VR search task with our CAVE-like system and a modern HMD. The tracking showed an accuracy error of 1.66 cm and .4 mm of precision jitter. The system was reported to elicit presence but at a lower level than the HMD, while causing significant lower cybersickness. Our results were compared to a previous study performed with a laboratory-grade CAVE and support that a VR system implemented with low-cost devices could be a viable alternative to laboratory-grade CAVEs for visual search tasks outside the user's personal space.
C1 [Goncalves, Afonso; Badia, Sergi Bermudez, I] Univ Madeira, Fac Ciencias Exatas & Engn, Madeira Interact Technol Inst M ITI, NOVA LINCS, P-9000072 Funchal, Portugal.
   [Borrego, Adrian; Latorre, Jorge; Llorens, Roberto] Univ Politecn Vakncia, Inst Invest & Innovac Bioingn, Neurorehabil & Brain Res Grp, Valencia 46011, Spain.
   [Latorre, Jorge; Llorens, Roberto] NEURORHB Serv Neurorrehabil Hosp Vithas, Valencia 46022, Spain.
C3 Universidade da Madeira
RP Goncalves, A (corresponding author), Univ Madeira, Fac Ciencias Exatas & Engn, Madeira Interact Technol Inst M ITI, NOVA LINCS, P-9000072 Funchal, Portugal.
EM afonso.gonvalves@m-iti.org; adborgon@upv.es; jlatorre@i3b.upv.es;
   rllorens@i3b.upv.es; sergi.bermudez@m-iti.org
RI gonzalez, adrian/AAU-2768-2020; Grau, Jorge/M-7176-2016; Borrego
   Gonzalez, Adrian/M-7165-2016; Llorens, Roberto/AAL-2604-2021; Bermudez i
   Badia, Sergi/C-8681-2018
OI Borrego Gonzalez, Adrian/0000-0001-5134-7811; Llorens,
   Roberto/0000-0002-8677-8707; Bermudez i Badia, Sergi/0000-0003-4452-0414
FU Fundacao para a Ciencia e Tecnologia through the AHA Project
   [CMUPERI/HCI/0046/2013]; INTERREG Program through the MACBIOIDI Project
   [MAC/1.1.b/098]; LARSyS [UIDB/50009/2020]; NOVA-LINCS
   [UID/CEC/04516/2019]; Fundacio la Marato de la TV3 [201701-10]; European
   Union through the Operational Program of the European Regional
   Development Fund (ERDF) of the Valencian Community 2014-2020
   [IDI-FEDER/2018/029]
FX Afonso Goncalves and Sergi Bermudez i Badia run the experiments on the
   feeling of presence with the KAVE and HTC Vive, which replicated the
   study from Adrian Borrego, Jorge Latorre, and Roberto Llorens, who
   provided the data collected with the CAVE and walking VR system from
   their paper [11]. Afonso Goncalves collected the data from the accuracy
   measures with Adrian Borrego, Jorge Latorre, and Roberto Llorens. This
   work was supported in part by the Fundacao para a Ciencia e Tecnologia
   through the AHA Project under Grant CMUPERI/HCI/0046/2013, in part by
   the INTERREG Program through the MACBIOIDI Project under Grant
   MAC/1.1.b/098, in part by the LARSyS under Grant UIDB/50009/2020, in
   part by the NOVA-LINCS under Grant UID/CEC/04516/2019, in part by the
   Fundacio la Marato de la TV3 under Grant 201701-10, and in part by the
   European Union through the Operational Program of the European Regional
   Development Fund (ERDF) of the Valencian Community 2014-2020 under Grant
   IDI-FEDER/2018/029.
CR Albert JA, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185104
   Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114
   Borrego A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0174-1
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Burdea G. C., 2003, VIRTUAL REALITY TECH, DOI 10.1162/105474603322955950
   Ciria LF, 2017, GAIT POSTURE, V52, P100, DOI 10.1016/j.gaitpost.2016.11.020
   Clark RA, 2019, GAIT POSTURE, V68, P193, DOI 10.1016/j.gaitpost.2018.11.029
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Febretti A, 2013, PROC SPIE, V8649, DOI 10.1117/12.2005484
   Goncalves Afonso, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229092
   Gonçalves AR, 2021, VISUAL COMPUT, V37, P19, DOI 10.1007/s00371-019-01736-0
   i3B UPV, US
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI [10.1145/2792790, DOI 10.1145/2792790]
   Juarez A, 2010, ENTERTAIN COMPUT, V1, P157, DOI 10.1016/j.entcom.2010.10.001
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lee J., Head tracking for desktop VR displays using the Wii remote
   Muñoz JE, 2019, GAMES HEALTH J, V8, P387, DOI 10.1089/g4h.2018.0028
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Otte K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166532
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   Sherman WR, 2018, Understanding virtual reality: interface, application, and design: Morgan Kaufmann
   Siena FL, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0905-x
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M., 1996, VRST'96. Proceedings of the ACM Symposium on Virtual Reality and Technology, P163
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Webster D, 2014, IEEE HAPTICS SYM, P455, DOI 10.1109/HAPTICS.2014.6775498
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 32
TC 4
Z9 4
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4452
EP 4461
DI 10.1109/TVCG.2021.3091485
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400035
PM 34156944
OA Green Published
DA 2024-11-06
ER

PT J
AU Xu, WP
   Liu, Y
   Yu, ML
   Wang, DX
   Hou, SM
   Li, B
   Wang, WM
   Liu, LG
AF Xu, Wenpeng
   Liu, Yi
   Yu, Menglin
   Wang, Dongxiao
   Hou, Shouming
   Li, Bo
   Wang, Weiming
   Liu, Ligang
TI A Support-Free Infill Structure Based on Layer Construction for 3D
   Printing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Three-dimensional printing;
   Load modeling; Optimization; Loading; Faces; Light-weight structure; 3D
   printing; self-supporting; structural performance; machine code
ID SURFACES
AB The design of the light-weight infill structure is a hot research topic in additive manufacturing. In recent years, various infill structures have been proposed to reduce the amount of printing material. However, 3D models filled with them may have very different structural performances under different loading conditions. In addition, most of them are not self-supporting. To mitigate these issues, a novel light-weight infill structure based on the layer construction is proposed in this article. The layers of the proposed infill structure continuously and periodically transform between triangles and hexagons. The geometries of two adjacent layers are controlled to be self-supporting for different 3D printing technologies. The machine code (Gcode) of the filled 3D model is generated in the construction of the infill structure for 3D printers. That means 3D models filled with the proposed infill structure do not need an extra slicing process before printing, which is time consuming in some cases. Structural simulations and physical experiments demonstrate that our infill structure has comparable structural performance under different loading conditions. Furthermore, the relationship between the structural stiffness and the parameters of the infill structure is investigated, which will be helpful for non-professional users.
C1 [Xu, Wenpeng; Liu, Yi; Wang, Dongxiao; Hou, Shouming] Henan Polytech Univ, Sch Comp Sci Technol, Jiaozuo 454000, Henan, Peoples R China.
   [Yu, Menglin] Henan Polytech Univ, Sch Mech & Power Engn, Jiaozuo 454000, Henan, Peoples R China.
   [Li, Bo] Nanchang Hongkong Univ, Sch Math & Informat Sci, Nanchang 330063, Jiangxi, Peoples R China.
   [Wang, Weiming] Dalian Univ Technol, Sch Math Sci, Key Lab Computat Math & Data Intelligence Liaonin, Dalian 116024, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
C3 Henan Polytechnic University; Henan Polytechnic University; Nanchang
   Hangkong University; Dalian University of Technology; Chinese Academy of
   Sciences; University of Science & Technology of China, CAS
RP Wang, WM (corresponding author), Dalian Univ Technol, Sch Math Sci, Key Lab Computat Math & Data Intelligence Liaonin, Dalian 116024, Peoples R China.
EM wpxu08@gmail.com; 492374666@qq.com; 2510392773@qq.com;
   1569796460@qq.com; housm@163.com; bolimath@gmail.com; wwmdlut@gmail.com;
   lgliu@ustc.edu.cn
RI Liu, Ligang/IZQ-5817-2023; Xu, Wenpeng/JQW-3191-2023; Wang,
   dongxiao/GPZ-7141-2022; Wang, Weiming/H-4944-2017
OI Wang, Weiming/0000-0001-6289-0094; Liu, Yi/0009-0002-6766-2191
FU Fundamental Research Funds for the Central Universities [DUT18RC(4)
   064]; Fundamental Research Funds for the Universities of Henan Province
   [NSFRF180401]; Key Scientific Research Projects of Colleges and
   Universities of Henan Province [21A520017]; Natural Science Foundation
   of Henan Polytechnic University [B2017-37]; Scientific and Technological
   Projects of Henan Province [182102210310, 182102210086]; Natural Science
   Foundation of China [U1811463, 61976040, 61762074, 61762064]; Jiangxi
   Science Fund for Distinguished Young Scholars [20192 BCBL23001]
FX This work supported in part by the Fundamental Research Funds for the
   Central Universities under Grant DUT18RC(4) 064, in part by the
   Fundamental Research Funds for the Universities of Henan Province under
   Grant NSFRF180401, in part by the Key Scientific Research Projects of
   Colleges and Universities of Henan Province under Grant 21A520017, in
   part by the Natural Science Foundation of Henan Polytechnic University
   under Grant B2017-37, in part by the Scientific and Technological
   Projects of Henan Province under Grants 182102210310 and 182102210086,
   in part by theNatural Science Foundation of China under Grants U1811463,
   61976040, 61762074, and 61762064, and in part by the Jiangxi Science
   Fund for Distinguished Young Scholars under Grant 20192 BCBL23001.
CR Abaqus, 2019, ABAQUS
   Cubic, 2020, CUBIC
   Cura, 2020, US
   Dai CK, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201342
   Deuss M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661266
   Gao W, 2015, COMPUT AIDED DESIGN, V69, P65, DOI 10.1016/j.cad.2015.04.001
   IceSL, 2020, ICESL
   Kuipers T, 2019, COMPUT AIDED DESIGN, V114, P37, DOI 10.1016/j.cad.2019.05.003
   Lee M, 2018, COMPUT AIDED DESIGN, V101, P23, DOI 10.1016/j.cad.2018.03.007
   Liu L, 2014, PROC SIGGRAPH ASIA C
   [刘利刚 Liu Ligang], 2015, [计算机学报, Chinese Journal of Computers], V38, P1243
   Liu Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461927
   Livesu M, 2017, COMPUT GRAPH FORUM, V36, P537, DOI 10.1111/cgf.13147
   Lu L, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601168
   Martínez J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201343
   Sá AME, 2015, VISUAL COMPUT, V31, P799, DOI 10.1007/s00371-015-1109-8
   MEYERS D, 1992, ACM T GRAPHIC, V11, P228, DOI 10.1145/130881.131213
   Plocher J, 2019, MATER DESIGN, V183, DOI 10.1016/j.matdes.2019.108164
   Reiner T, 2016, PROC EUROGRAPHICS SH
   Slic3r, 2020, US
   Slic3r, 2020, SLIC3R
   Stava O, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185544
   Telea A, 2011, LECT NOTES COMPUT SC, V6671, P393, DOI 10.1007/978-3-642-21569-8_34
   Umetani N., 2013, SIGGRAPH ASIA, DOI DOI 10.1145/2542355.2542361
   Vouga E, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185583
   Wang CCL, 2013, RAPID PROTOTYPING J, V19, P395, DOI 10.1108/RPJ-02-2012-0013
   Wang WM, 2018, IEEE T VIS COMPUT GR, V24, P2787, DOI 10.1109/TVCG.2017.2764462
   Wang WM, 2017, COMPUT GRAPH-UK, V66, P154, DOI 10.1016/j.cag.2017.05.022
   Wang WM, 2017, VISUAL COMPUT, V33, P949, DOI 10.1007/s00371-017-1386-5
   Wang WM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508382
   Wu J, 2018, IEEE T VIS COMPUT GR, V24, P1127, DOI 10.1109/TVCG.2017.2655523
   Wu J, 2016, COMPUT AIDED DESIGN, V80, P32, DOI 10.1016/j.cad.2016.07.006
   Xie Y, 2017, VIS INFORM, V1, P9, DOI 10.1016/j.visinf.2017.01.002
   Xie Y, 2015, COMPUT AIDED GEOM D, V35-36, P163, DOI 10.1016/j.cagd.2015.03.019
   Xu WP, 2016, J COMPUT SCI TECH-CH, V31, P439, DOI 10.1007/s11390-016-1638-2
   Yang Y, 2018, COMPUT GRAPH-UK, V70, P148, DOI 10.1016/j.cag.2017.07.005
   Youngs, 2020, YOUNGS
   Zhang XL, 2015, COMPUT AIDED GEOM D, V35-36, P149, DOI 10.1016/j.cagd.2015.03.012
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
NR 39
TC 6
Z9 9
U1 3
U2 38
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4462
EP 4476
DI 10.1109/TVCG.2021.3091509
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400036
PM 34156945
DA 2024-11-06
ER

PT J
AU Rittenbruch, M
   Vella, K
   Brereton, M
   Hogan, JM
   Johnson, D
   Heinrich, J
   O'Donoghue, S
AF Rittenbruch, Markus
   Vella, Kellie
   Brereton, Margot
   Hogan, James M.
   Johnson, Daniel
   Heinrich, Julian
   O'Donoghue, Sean
TI Collaborative Sense-Making in Genomic Research: The Role of
   Visualisation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Collaboration; Bioinformatics; Data visualization; Genomics; Visual
   analytics; Tools; Browsers; Computer-supported cooperative work;
   human-centered computing; human-computer interaction; scientific
   visualisation
ID PERFORMANCE; CHALLENGES; GENERATION; INSIGHT
AB Genomic research emerges from collaborative work within and across different scientific disciplines. A diverse range of visualisation techniques has been employed to aid this research, yet relatively little is known as to how these techniques facilitate collaboration. We conducted a case study of collaborative research within a biomedical institute to learn more about the role visualisation plays in genomic mapping. Interviews were conducted with molecular biologists (N = 5) and bioinformaticians (N = 6). We found that genomic research comprises a variety of distinct disciplines engaged in complex analytic tasks that each resist simplification, and their complexity influences how visualisations were used. Visualisation use was impacted by group-specific interactions and temporal work patterns. Visualisations were also crucial to the scientific workflow, used for both question formation and confirmation of hypotheses, and acted as an anchor for the communication of ideas and discussion. In the latter case, two approaches were taken: providing collaborators with either interactive or static imagery representing a viewpoint. The use of generic software for simplified visualisations, and quick production and curation was also noted. We discuss these findings with reference to group-specific interactions and present recommendations for improving collaborative practices through visual analytics.
C1 [Rittenbruch, Markus; Vella, Kellie; Brereton, Margot; Hogan, James M.; Johnson, Daniel] Queensland Univ Technol, Brisbane, Qld 4000, Australia.
   [Heinrich, Julian] Bayer Crop Sci, D-400607 Leverkusen, Germany.
   [O'Donoghue, Sean] Garvan Inst Med Res, Sydney, NSW 2000, Australia.
C3 Queensland University of Technology (QUT); Bayer AG; Bayer CropScience;
   Garvan Institute of Medical Research
RP Vella, K (corresponding author), Queensland Univ Technol, Brisbane, Qld 4000, Australia.
EM m.rittenbruch@qut.edu.au; kellie.vella@qut.edu.au;
   m.brereton@qut.edu.au; j.hogan@qut.edu.au; dm.johnson@qut.edu.au;
   julian@joules.de; sean@odonoghuelab.org
RI Brereton, Margot/J-1021-2012; Rittenbruch, Markus/J-1015-2012; Johnson,
   Daniel/J-1028-2012
OI Brereton, Margot/0000-0002-0982-3404; Vella, Kellie/0000-0002-1125-5530;
   Rittenbruch, Markus/0000-0001-9279-1599; Johnson,
   Daniel/0000-0003-1088-3460
FU Australian Research Council [LP140100574]; Australian Research Council
   [LP140100574] Funding Source: Australian Research Council
FX The authors would like to thank the participants at the Garvan Institute
   of Medical Research for their contribution. This study was conducted in
   accordance with Queensland University of Technology Ethics Approval
   1500000367 and approved by the Garvan Institute. This work was supported
   by the Australian Research Council under Linkage Project LP140100574.
CR Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389
   [Anonymous], 2010, PROC INT C ADV VIS I, DOI 10.1145/1842993.1843008
   [Anonymous], The Human Genome Project
   Behjati S, 2013, ARCH DIS CHILDHOOD-E, V98, P236, DOI 10.1136/archdischild-2013-304340
   Bishop C.M., 2006, Pattern Recognition and Machine Learning, VVolume 4
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Caban JJ, 2015, J AM MED INFORM ASSN, V22, P260, DOI 10.1093/jamia/ocv006
   Chen C., 2012, ILLUMINATED PATH IMP
   Choo J., 2012, VISUAL ANAL APPROACH
   Dema T, 2017, COMPUT SUPP COOP W J, V26, P693, DOI 10.1007/s10606-017-9286-9
   Fisher B. D, 2007, VISUAL REPRESENTATIO
   Garvan Institute of Medical Research, 2019, GARV I
   Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80
   Goodstadt M, 2017, FEBS LETT, V591, P2505, DOI 10.1002/1873-3468.12778
   Goodstadt MN, 2019, J MOL BIOL, V431, P1071, DOI 10.1016/j.jmb.2018.11.008
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Heimeriks G, 2013, SCI PUBL POLICY, V40, P97, DOI 10.1093/scipol/scs070
   Isenberg P, 2012, IEEE T VIS COMPUT GR, V18, P689, DOI 10.1109/TVCG.2011.287
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Jackson S. J., 2011, Proceedings of the ACM 2011 conference on Computer supported cooperative work, P245, DOI [DOI 10.1145/1958824.1958861, 10.1145/1958824]
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kent WJ, 2002, GENOME RES, V12, P996, DOI 10.1101/gr.229102
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   Leiserson MDM, 2015, NAT METHODS, V12, P483, DOI 10.1038/nmeth.3412
   Li J., 2008, P 20 AUSTRALASIAN C, P73
   Lieberman-Aiden E, 2009, SCIENCE, V326, P289, DOI 10.1126/science.1181369
   O'Donoghue SI, 2015, NAT METHODS, V12, P98, DOI 10.1038/nmeth.3258
   Procter J. B., 2017, DATA VISUALISATION I
   Saraiya P, 2006, IEEE T VIS COMPUT GR, V12, P1511, DOI 10.1109/TVCG.2006.85
   Shaer O, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1427
   Sing T, 2005, BIOINFORMATICS, V21, P3940, DOI 10.1093/bioinformatics/bti623
   Skidmore ZL, 2016, BIOINFORMATICS, V32, P3012, DOI 10.1093/bioinformatics/btw325
   Star SL, 2010, SCI TECHNOL HUM VAL, V35, P601, DOI 10.1177/0162243910377624
   Taberlay PC, 2016, GENOME RES, V26, P719, DOI 10.1101/gr.201517.115
   Thorvaldsdóttir H, 2013, BRIEF BIOINFORM, V14, P178, DOI 10.1093/bib/bbs017
   Zhou Xin, 2012, Curr Protoc Bioinformatics, VChapter 10, DOI 10.1002/0471250953.bi1010s40
NR 37
TC 2
Z9 2
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4477
EP 4489
DI 10.1109/TVCG.2021.3090746
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400037
PM 34156943
DA 2024-11-06
ER

PT J
AU Zhang, YJ
   Wang, R
   Peng, YF
   Hua, W
   Bao, HJ
AF Zhang, Yunjin
   Wang, Rui
   Peng, Yifan
   Hua, Wei
   Bao, Hujun
TI Color Contrast Enhanced Rendering for Optical See-Through Head-Mounted
   Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Color; Optical imaging; Rendering (computer
   graphics); Visualization; Hardware; Brightness; Color blending; color
   perception; human visual system; mixed reality; real-time rendering;
   post-processing effect
ID OCCLUSION; REAL; COMPENSATION; VISIBILITY; APPEARANCE; EYE
AB Most commercially available optical see-through head-mounted displays (OST-HMDs) utilize optical combiners to simultaneously visualize the physical background and virtual objects. The displayed images perceived by users are a blend of rendered pixels and background colors. Enabling high fidelity color perception in mixed reality (MR) scenarios using OST-HMDs is an important but challenging task. We propose a real-time rendering scheme to enhance the color contrast between virtual objects and the surrounding background for OST-HMDs. Inspired by the discovery of color perception in psychophysics, we first formulate the color contrast enhancement as a constrained optimization problem. We then design an end-to-end algorithm to search the optimal complementary shift in both chromaticity and luminance of the displayed color. This aims at enhancing the contrast between virtual objects and the real background as well as keeping the consistency with the original displayed color. We assess the performance of our approach using a simulated OST-HMD environment and an off-the-shelf OST-HMD. Experimental results from objective evaluations and subjective user studies demonstrate that the proposed approach makes rendered virtual objects more distinguishable from the surrounding background, thereby bringing a better visual experience.
C1 [Zhang, Yunjin; Wang, Rui; Hua, Wei; Bao, Hujun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
   [Peng, Yifan] Stanford Univ, Elect Engn, Stanford, CA 94305 USA.
C3 Zhejiang University; Stanford University
RP Wang, R; Bao, HJ (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
EM zhangyunjin@zju.edu.cn; ruiwang@zju.edu.cn; evanpeng@stanford.edu;
   huawei@cad.zju.edu.cn; bao@cad.zju.edu.cn
RI Peng, Yifan/M-1605-2016
OI Zhang, Yunjin/0000-0003-3582-8900
FU NSFC [61872319]; Zhejiang Provincial NSFC [LR18F020002]; National Key
   R&D Program of China [2017YFB1002605]; Zhejiang University Education
   FoundationGlobal Partnership Fund
FX The authors would like to thank all reviewers and editors for their
   insightful comments. The authors would also like to thank Hongyu Lu and
   other volunteers for taking part in our studies under the spread of
   COVID-19. This work was supported in part by the NSFC under Grant No.
   61872319, in part by the Zhejiang Provincial NSFC under Grant No.
   LR18F020002, in part by the National Key R&D Program of China under
   Grant No. 2017YFB1002605, and in part by the Zhejiang University
   Education FoundationGlobal Partnership Fund.
CR ANDERSON SJ, 1991, J PHYSIOL-LONDON, V442, P47, DOI 10.1113/jphysiol.1991.sp018781
   Brown RO, 1997, CURR BIOL, V7, P844, DOI 10.1016/S0960-9822(06)00372-1
   Cakmakci O, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P16, DOI 10.1109/ISMAR.2004.2
   CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574
   Ekroll V, 2013, J OPT SOC AM A, V30, P342, DOI 10.1364/JOSAA.30.000342
   Ekroll V, 2012, SEEING PERCEIVING, V25, P107, DOI 10.1163/187847612X626363
   Fukiage T, 2014, INT SYM MIX AUGMENT, P63, DOI 10.1109/ISMAR.2014.6948410
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Gao CY, 2012, INT SYM MIX AUGMENT, P281, DOI 10.1109/ISMAR.2012.6402574
   Gruber L., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P227, DOI 10.1109/ISMAR.2010.5643580
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Hassani N, 2019, COLOR RES APPL, V44, P492, DOI 10.1002/col.22380
   Hincapié-Ramos JD, 2015, IEEE T VIS COMPUT GR, V21, P1336, DOI 10.1109/TVCG.2015.2450745
   Huang HP, 2021, COLOR RES APPL, V46, P294, DOI 10.1002/col.22590
   Itoh Y, 2019, IEEE T VIS COMPUT GR, V25, P1951, DOI 10.1109/TVCG.2019.2899229
   Itoh Y, 2017, IEEE T VIS COMPUT GR, V23, P2463, DOI 10.1109/TVCG.2017.2734427
   Itoh Y, 2015, IEEE T VIS COMPUT GR, V21, P1269, DOI 10.1109/TVCG.2015.2459892
   JAMESON D, 1959, J OPT SOC AM, V49, P890, DOI 10.1364/JOSA.49.000890
   JAMESON D, 1961, J OPT SOC AM, V51, P46, DOI 10.1364/JOSA.51.000046
   Kim J.-W., 2017, PROC IEEE INT S MIXE, P95
   Kim K, 2019, PHOTOPTICS: PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PHOTONICS, OPTICS AND LASER TECHNOLOGY, P296, DOI 10.5220/0007612702990302
   Kiyokawa K, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P60, DOI 10.1109/ISAR.2000.880924
   Klauke S, 2015, J VISION, V15, DOI 10.1167/15.13.17
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   KRAUSKOPF J, 1986, J OPT SOC AM A, V3, P1752, DOI 10.1364/JOSAA.3.001752
   Kress Bernard C., 2017, SID Symposium Digest of Technical Papers, V48, P127, DOI 10.1002/sdtp.11586
   Langlotz T, 2016, IEEE T VIS COMPUT GR, V22, P2385, DOI 10.1109/TVCG.2016.2593781
   Lee KH, 2018, OPT ENG, V57, DOI 10.1117/1.OE.57.12.123104
   Lin JY, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188389
   Liu S, 2008, INT SYM MIX AUGMENT, P33, DOI 10.1109/ISMAR.2008.4637321
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P115, DOI 10.1109/VR.2009.4811009
   Livingston MarkA., 2013, Human Factors in Augmented Reality Environments, P35, DOI [10.1007/978-1-4614-4205-93, DOI 10.1007/978-1-4614-4205-93]
   MAHNY M, 1994, COLOR RES APPL, V19, P105
   Maimone A, 2013, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2013.6671761
   Menk C, 2013, IEEE T VIS COMPUT GR, V19, P236, DOI 10.1109/TVCG.2012.146
   Mori S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI 10.1109/VR.2018.8446441
   Murdoch MJ, 2020, J OPT SOC AM A, V37, P1927, DOI 10.1364/JOSAA.398931
   Oshima K, 2016, P IEEE VIRT REAL ANN, P253, DOI 10.1109/VR.2016.7504749
   Oskam T, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P49, DOI 10.1109/3DIMPVT.2012.36
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Ratnasingam S, 2017, J VISION, V17, DOI 10.1167/17.2.13
   Rhodes TJ, 2019, ACM SIGGRAPH 2019 EMERGING TECHNOLOGIES (SIGGRAPH '19), DOI 10.1145/3305367.3327984
   Ryu Je-Ho., 2016, 2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), P1
   Smithwick QYJ, 2014, PROC SPIE, V9011, DOI 10.1117/12.2035091
   Sridharan SrikanthKirshnamachari., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P231
   Uchida T., 2002, T VIRTUAL REALITY SO, V7, P151
   Webster Michael A, 2002, J Vis, V2, P505, DOI 10.1167/2.6.7
   Weiland C, 2009, LECT NOTES COMPUT SC, V5615, P603, DOI 10.1007/978-3-642-02710-9_67
   Wetzstein G, 2010, COMPUT GRAPH FORUM, V29, P1934, DOI 10.1111/j.1467-8659.2010.01660.x
   Wilson A, 2017, OPT EXPRESS, V25, P30539, DOI 10.1364/OE.25.030539
   Wolfe J.M., 2015, Sensation perception
NR 51
TC 10
Z9 11
U1 3
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4490
EP 4502
DI 10.1109/TVCG.2021.3091686
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400038
PM 34161241
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, XZ
   Li, RH
   Chen, GY
   Fu, CW
   Cohen-Or, D
   Heng, PA
AF Li, Xianzhi
   Li, Ruihui
   Chen, Guangyong
   Fu, Chi-Wing
   Cohen-Or, Daniel
   Heng, Pheng-Ann
TI A Rotation-Invariant Framework for Deep Point Cloud Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Feature extraction; Convolution;
   Neural networks; Task analysis; Network architecture; Point cloud
   analysis; rotation-invariant representation; deep neural network
AB Recently, many deep neural networks were designed to process 3D point clouds, but a common drawback is that rotation invariance is not ensured, leading to poor generalization to arbitrary orientations. In this article, we introduce a new low-level purely rotation-invariant representation to replace common 3D Cartesian coordinates as the network inputs. Also, we present a network architecture to embed these representations into features, encoding local relations between points and their neighbors, and the global shape structure. To alleviate inevitable global information loss caused by the rotation-invariant representations, we further introduce a region relation convolution to encode local and non-local information. We evaluate our method on multiple point cloud analysis tasks, including (i) shape classification, (ii) part segmentation, and (iii) shape retrieval. Extensive experimental results show that our method achieves consistent, and also the best performance, on inputs at arbitrary orientations, compared with all the state-of-the-art methods.
C1 [Li, Xianzhi; Li, Ruihui; Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Li, Xianzhi; Li, Ruihui; Chen, Guangyong; Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Guangdong, Peoples R China.
   [Cohen-Or, Daniel] Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
C3 Chinese University of Hong Kong; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Tel Aviv University
RP Li, RH (corresponding author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.; Li, RH (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Virtual Real & Human Interact Te, Shenzhen 518055, Guangdong, Peoples R China.
EM xzli@cse.cuhk.edu.hk; lirh@cse.cuhk.edu.hk; gy.chen@siat.ac.cn;
   cwfu@cse.cuhk.edu.hk; dcor@mail.tau.ac.il; pheng@cse.cuhk.edu.hk
RI Fu, Chi-Wing/X-4703-2019; Li, Ruihui/AAA-1369-2022; Li,
   Xianzhi/IUO-5698-2023
OI Heng, Pheng Ann/0000-0003-3055-5034; Li, Xianzhi/0000-0001-6835-5607;
   Fu, Chi Wing/0000-0002-5238-593X
FU Hong Kong Centre for Logistics Robotics, Hong Kong Research Grants
   Council [CUHK 14206320, 14201620]; National Natural Science Foundation
   of China [62006219]; Israel Science Foundation [2492/20]
FX The authors would like to thank reviewers for their valuable comments.
   This work was supported in part by the Hong Kong Centre for Logistics
   Robotics, Hong Kong Research Grants Council with under Project CUHK
   14206320 and 14201620, in part by the National Natural Science
   Foundation of China under Project 62006219, and in part by the Israel
   Science Foundation under Grant 2492/20.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Armeni I, 2016, PROC CVPR IEEE, P1534, DOI 10.1109/CVPR.2016.170
   Chen C, 2019, Arxiv, DOI arXiv:1905.08705
   Chen C, 2019, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR.2019.00513
   Chen SH, 2019, Arxiv, DOI arXiv:1905.04571
   Choi S, 2016, Arxiv, DOI [arXiv:1602.02481, 10.48550/arXiv.1602.02481, DOI 10.48550/ARXIV.1602.02481]
   Cohen MB, 2016, ACM S THEORY COMPUT, P9, DOI 10.1145/2897518.2897647
   Cohen T. S., 2018, INT C LEARNING REPRE
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Duan YQ, 2019, PROC CVPR IEEE, P949, DOI 10.1109/CVPR.2019.00104
   Esteves C, 2018, LECT NOTES COMPUT SC, V11217, P54, DOI 10.1007/978-3-030-01261-8_4
   Fernandez-Labrador Clara, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P546, DOI 10.1007/978-3-030-58595-2_33
   Furuya T., 2016, P BMVC, V7, P8
   Han ZZ, 2019, IEEE I CONF COMP VIS, P10441, DOI 10.1109/ICCV.2019.01054
   Hassani K, 2019, IEEE I CONF COMP VIS, P8159, DOI 10.1109/ICCV.2019.00825
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Hinton G.E., 2012, arXiv, DOI DOI 10.48550/ARXIV.1207.0580
   Kanezaki A, 2017, EUR WORKSH 3D OBJ RE
   Kingma D.P., 2014, P INT C LEARNING REP
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li XZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3366785
   Li YY, 2018, ADV NEUR IN, V31
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Poulenard A, 2019, INT CONF 3D VISION, P47, DOI 10.1109/3DV.2019.00015
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Rao YM, 2019, PROC CVPR IEEE, P452, DOI 10.1109/CVPR.2019.00054
   Sauder J, 2019, Arxiv, DOI arXiv:1901.08396
   Shen YR, 2018, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2018.00478
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Weiler M, 2018, ADV NEUR IN, V31
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xie Haozhe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P365, DOI 10.1007/978-3-030-58545-7_21
   Xu YF, 2018, LECT NOTES COMPUT SC, V11212, P90, DOI 10.1007/978-3-030-01237-3_6
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yongheng Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P1, DOI 10.1007/978-3-030-58452-8_1
   You Y, 2020, AAAI CONF ARTIF INTE, V34, P12717
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Yue Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P752, DOI 10.1007/978-3-030-58529-7_44
   Zhang BY, 2020, PUBLIC HEALTH NUTR, V23, P2973, DOI 10.1017/S1368980019004580
   Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169
   Zhang ZY, 2019, INT CONF 3D VISION, P204, DOI 10.1109/3DV.2019.00031
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhou H, 2019, IEEE I CONF COMP VIS, P1961, DOI 10.1109/ICCV.2019.00205
NR 58
TC 30
Z9 30
U1 8
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4503
EP 4514
DI 10.1109/TVCG.2021.3092570
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400039
PM 34170827
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Burns, A
   Xiong, C
   Franconeri, S
   Cairo, A
   Mahyar, N
AF Burns, Alyxander
   Xiong, Cindy
   Franconeri, Steven
   Cairo, Alberto
   Mahyar, Narges
TI Designing With Pictographs: Envision Topics Without Sacrificing
   Understanding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Taxonomy; Graphics; Bars; Task
   analysis; COVID-19; Infographics; pictographs; design; graph
   comprehension; understanding; casual sensemaking
ID PERCEPTUAL FLUENCY; VISUALIZATION; INFOGRAPHICS; RECALL; GRAPH
AB Past studies have shown that when a visualization uses pictographs to encode data, they have a positive effect on memory, engagement, and assessment of risk. However, little is known about how pictographs affect one's ability to understand a visualization, beyond memory for values and trends. We conducted two crowdsourced experiments to compare the effectiveness of using pictographs when showing part-to-whole relationships. In Experiment 1, we compared pictograph arrays to more traditional bar and pie charts. We tested participants' ability to generate high-level insights following Bloom's taxonomy of educational objectives via 6 free-response questions. We found that accuracy for extracting information and generating insights did not differ overall between the two versions. To explore the motivating differences between the designs, we conducted a second experiment where participants compared charts containing pictograph arrays to more traditional charts on 5 metrics and explained their reasoning. We found that some participants preferred the way that pictographs allowed them to envision the topic more easily, while others preferred traditional bar and pie charts because they seem less cluttered and faster to read. These results suggest that, at least in simple visualizations depicting part-to-whole relationships, the choice of using pictographs has little influence on sensemaking and insight extraction. When deciding whether to use pictograph arrays, designers should consider visual appeal, perceived comprehension time, ease of envisioning the topic, and clutteredness.
C1 [Burns, Alyxander; Mahyar, Narges] Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA.
   [Xiong, Cindy; Franconeri, Steven] Northwestern Univ, Dept Psychol, Evanston, IL 60208 USA.
   [Cairo, Alberto] Univ Miami, Sch Commun, Coral Gables, FL 33146 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   Northwestern University; University of Miami
RP Burns, A (corresponding author), Univ Massachusetts, Coll Informat & Comp Sci, Amherst, MA 01003 USA.
EM alyxanderbur@cs.umass.edu; cxiong@u.northwestern.edu;
   franconeri@northwestern.edu; a.cairo@miami.edu; nmahyar@cs.umass.edu
OI Franconeri, Steven/0000-0001-5244-9764; Xiong Bearfield,
   Cindy/0000-0002-1451-4083; Burns, Alyxander/0000-0002-2784-3011
CR Adar E, 2021, IEEE T VIS COMPUT GR, V27, P946, DOI 10.1109/TVCG.2020.3030375
   Ancona D., 2012, The handbook for teaching leadership: Knowing, doing, and being
   Arcia A, 2016, J AM MED INFORM ASSN, V23, P174, DOI 10.1093/jamia/ocv079
   Arneson JB, 2018, CBE-LIFE SCI EDUC, V17, DOI 10.1187/cbe.17-08-0178
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bates D., 2015, PACKAGE LME4
   Bloom BS., 1984, TAXONOMY ED OBJECTIV
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Boyatzis RE., 1998, TRANSFORMING QUALITA
   Brewer NT, 2012, BREAST CANCER RES TR, V133, P553, DOI 10.1007/s10549-011-1791-9
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Byrd Vetria, 2019, P E LEARN WORLD C E, P1039
   Cairo A., 2012, The Functional Art: An Introduction to Information Graph. and Visualization
   Cairo A., 2016, The truthful art: Data, charts, and maps for communication, New Riders
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chevalier F, 2013, IEEE T VIS COMPUT GR, V19, P2426, DOI 10.1109/TVCG.2013.210
   de Haan Y, 2018, JOURNALISM STUD, V19, P1293, DOI 10.1080/1461670X.2016.1267592
   Dervin B., 1998, Journal of Knowledge Management, V2, P36, DOI 10.1108/13673279810249369
   Dick M, 2014, DIGIT JOURNAL, V2, P490, DOI 10.1080/21670811.2013.841368
   Fuchs J, 2019, EUROGRAPHICS 2019 40, P1
   Galesic M, 2009, HEALTH PSYCHOL, V28, P210, DOI 10.1037/a0014474
   Garcia-Retamero R, 2013, CURR DIR PSYCHOL SCI, V22, P392, DOI 10.1177/0963721413491570
   Garcia-Retamero R, 2010, SOC SCI MED, V70, P1019, DOI 10.1016/j.socscimed.2009.11.031
   Genevsky A, 2013, J NEUROSCI, V 33, P17188, DOI 10.1523/JNEUROSCI.2348-13.2013
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Herve M., 2021, PACKAGE RVAIDEMEMOIR
   Houts PS, 2006, PATIENT EDUC COUNS, V61, P173, DOI 10.1016/j.pec.2005.05.004
   Huang WD, 2009, INFORM VISUAL, V8, P139, DOI 10.1057/ivs.2009.10
   Jones K.E., 2009, Island Bats: Evolution, Ecology, and Conservation, P1, DOI [DOI 10.1109/FIE.2009.5350598, 10.1109/fie.2009.5350598]
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300309
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Krum Randy, 2013, Cool infographics: Effective communication with data visualization and design
   Lenth R V., 2022, Emmeans: Estimated Marginal Means
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lyra KT, 2016, IEEE INT CONF ADV LE, P366, DOI 10.1109/ICALT.2016.83
   Mahyar N., WORKSHOP PERS VISUAL, V3, P2
   Malamed C., 2009, Visual Language for Designers: Principles for creating graphics that people understand
   Norman DA, 2004, EMOTIONAL DESIGN WHY
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Otten JJ, 2015, HEALTH AFFAIR, V34, P1901, DOI 10.1377/hlthaff.2015.0642
   Ovans A., WHAT MAKES BEST INFO
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   Park JH, 2018, IEEE COMPUT GRAPH, V38, P67, DOI 10.1109/MCG.2018.2879066
   Peer E, 2014, BEHAV RES METHODS, V46, P1023, DOI 10.3758/s13428-013-0434-y
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Pontis S., 2012, START BASICS
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   ProPublica, WEEPEOPLE FONT
   Quispel A, 2016, INFORM VISUAL, V15, P238, DOI 10.1177/1473871615606478
   Reber R, 1998, PSYCHOL SCI, V9, P45, DOI 10.1111/1467-9280.00008
   Reber R, 2004, PERS SOC PSYCHOL REV, V8, P364, DOI 10.1207/s15327957pspr0804_3
   Reber R, 1999, CONSCIOUS COGN, V8, P338, DOI 10.1006/ccog.1999.0386
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Sedlmair M., 2016, P BELIV 16 P WORKSH, piv
   Skau Drew., 2017, EuroVis Short Papers, P91, DOI DOI 10.2312/EUROVISSHORT.20171139
   Smiciklas M., 2012, The power of infographics: Using pictures to communicate and connect with your audiences
   Starbuck W.H., 1988, The executive effect: Concepts and methods for studying top managers, P35
   Trogu P., 2018, VISIBLE LANG, V52, P83
   Twyman M., 1975, GRAPH COMMUN ISOTYPE, V7
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Yin M., 2014, POWER DATA VISUALIZA
   Zender Mike., 2013, Visible Language, V47, P66
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zikmund-Fisher BJ, 2014, MED DECIS MAKING, V34, P443, DOI 10.1177/0272989X13511706
NR 72
TC 8
Z9 8
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4515
EP 4530
DI 10.1109/TVCG.2021.3092680
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400040
PM 34170828
DA 2024-11-06
ER

PT J
AU Guo, SN
   Jin, ZC
   Chen, Q
   Gotz, D
   Zha, HY
   Cao, N
AF Guo, Shunan
   Jin, Zhuochen
   Chen, Qing
   Gotz, David
   Zha, Hongyuan
   Cao, Nan
TI Interpretable Anomaly Detection in Event Sequences via Sequence Matching
   and Visual Comparison
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Anomaly detection; Data models; Data visualization; Task analysis;
   Sequences; Heart; Diabetes; Event sequences; visual analytics; anomaly
   detection
ID MODEL; ANALYTICS; OUTLIERS
AB Anomaly detection is a common analytical task that aims to identify rare cases that differ from the typical cases that make up the majority of a dataset. When analyzing event sequence data, the task of anomaly detection can be complex because the sequential and temporal nature of such data results in diverse definitions and flexible forms of anomalies. This, in turn, increases the difficulty in interpreting detected anomalies. In this article, we propose a visual analytic approach for detecting anomalous sequences in an event sequence dataset via an unsupervised anomaly detection algorithm based on Variational AutoEncoders. We further compare the anomalous sequences with their reconstructions and with the normal sequences through a sequence matching algorithm to identify event anomalies. A visual analytics system is developed to support interactive exploration and interpretations of anomalies through novel visualization designs that facilitate the comparison between anomalous sequences and normal sequences. Finally, we quantitatively evaluate the performance of our anomaly detection algorithm, demonstrate the effectiveness of our system through case studies, and report feedback collected from study participants.
C1 [Guo, Shunan; Jin, Zhuochen; Chen, Qing; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200092, Peoples R China.
   [Gotz, David] Univ N Carolina, Chapel Hill, NC 27514 USA.
   [Zha, Hongyuan] East China Normal Univ, Shanghai 200241, Peoples R China.
C3 Tongji University; University of North Carolina; University of North
   Carolina Chapel Hill; East China Normal University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200092, Peoples R China.
EM g.shunan@gmail.com; chjzcjames@gmail.com; jane.qing.chen@gmail.com;
   gotz@unc.edu; zha@cc.gatech.edu; nan.cao@gmail.com
RI Cao, Nan/O-5397-2014; Guo, Shunan/AAE-2616-2019
OI Gotz, David/0000-0002-6424-7374; Cao, Nan/0000-0003-1316-7515; Guo,
   Shunan/0000-0001-5355-8399
FU Joint NSFC-DFG Research Program [62061136003]; NSFC [62072338,
   6200070909]
FX This work was supported in part by the Joint NSFC-DFG Research Program
   under Grant 62061136003 and in part by the NSFC under Grants 62072338
   and 6200070909.
CR Abdulhammed R, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2879990
   An J., 2015, 20152 SNU DAT MIN CT
   [Anonymous], 2016, PROFESSORS DATASET
   Bock A, 2015, 2015 IEEE Scientific Visualization Conference (SciVis), P17, DOI 10.1109/SciVis.2015.7429487
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Budalakoti S., 2006, Anomaly detection in large sets of high-dimensional symbol sequences
   Cabrera JBD, 2001, SIGMOD REC, V30, P25, DOI 10.1145/604264.604269
   Cao N, 2018, IEEE T VIS COMPUT GR, V24, P23, DOI 10.1109/TVCG.2017.2744419
   Chae J, 2012, IEEE CONF VIS ANAL, P143, DOI 10.1109/VAST.2012.6400557
   Chalapathy R, 2019, Arxiv, DOI arXiv:1901.03407
   Chandola V, 2012, IEEE T KNOWL DATA EN, V24, P823, DOI 10.1109/TKDE.2010.235
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Du M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1285, DOI 10.1145/3133956.3134015
   Eskin E., 2002, Applications of Data Mining in Computer Security, P77, DOI [10.1007/978-1-4615-0953-04, DOI 10.1007/978-1-4615-0953-04]
   Forrest S, 1996, P IEEE S SECUR PRIV, P120, DOI 10.1109/SECPRI.1996.502675
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guerra-Gómez JA, 2013, IEEE T VIS COMPUT GR, V19, P2566, DOI 10.1109/TVCG.2013.231
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Guo SN, 2019, IEEE INT CONF BIG DA, P1125, DOI 10.1109/BigData47090.2019.9005687
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Guo Y, 2018, AS C MACH LEARN, P97
   Guo YF, 2020, IEEE T NETW SCI ENG, V7, P2231, DOI 10.1109/TNSE.2020.3027543
   Jiong Yang, 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P395, DOI 10.1145/502512.502571
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P2287, DOI 10.1109/TVCG.2013.122
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kim TY, 2018, EXPERT SYST APPL, V106, P66, DOI 10.1016/j.eswa.2018.04.004
   Kingma DP, 2015, ADV NEUR IN, V28
   Kingma DP, 2014, ADV NEUR IN, V27
   KOLODNER JL, 1992, ARTIF INTELL REV, V6, P3, DOI 10.1007/BF00155578
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Leys C, 2013, J EXP SOC PSYCHOL, V49, P764, DOI 10.1016/j.jesp.2013.03.013
   Li LY, 2021, IEEE T NEUR NET LEAR, V32, P1177, DOI 10.1109/TNNLS.2020.2980749
   Liao YH, 2002, COMPUT SECUR, V21, P439, DOI 10.1016/S0167-4048(02)00514-X
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   Lu WN, 2017, IEEE T IMAGE PROCESS, V26, P4321, DOI 10.1109/TIP.2017.2713048
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Munz G., 2007, GI ITG WORKSH MMBNET, P13
   Najafabadi M.M., 2015, J Big Data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Patcha A, 2007, COMPUT NETW, V51, P3448, DOI 10.1016/j.comnet.2007.02.001
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Qayyum A, 2005, IEEE: 2005 International Conference on Emerging Technologies, Proceedings, P270, DOI 10.1109/ICET.2005.1558893
   Qiao Y, 2002, ELECTRON LETT, V38, P663, DOI 10.1049/el:20020467
   Nguyen QP, 2019, IEEE CONF COMM NETW, P91, DOI 10.1109/cns.2019.8802833
   Ramaswamy S, 2000, SIGMOD REC, V29, P427, DOI 10.1145/335191.335437
   ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267
   Shen Y, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P592, DOI 10.1145/3243734.3243811
   Singh A., 2017, THESIS KTH STOCKHOLM
   Soelch M, 2016, Arxiv, DOI arXiv:1602.07109
   Thom D, 2012, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2012.6183572
   Tu Y, 2007, IEEE T VIS COMPUT GR, V13, P1286, DOI 10.1109/TVCG.2007.70529
   Vinayakumar R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P236, DOI 10.1109/ICACCI.2017.8125846
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
   Xie Y, 2009, IEEE ACM T NETWORK, V17, P54, DOI 10.1109/TNET.2008.923716
   Xiong GG, 2012, NEUROCOMPUTING, V83, P121, DOI 10.1016/j.neucom.2011.12.007
   Xu HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P187, DOI 10.1145/3178876.3185996
   Zhang XQ, 2003, PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PDCAT'2003, PROCEEDINGS, P249, DOI 10.1109/PDCAT.2003.1236299
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
NR 65
TC 5
Z9 5
U1 4
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4531
EP 4545
DI 10.1109/TVCG.2021.3093585
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400041
PM 34191728
DA 2024-11-06
ER

PT J
AU Truong, N
   Yuksel, C
   Watcharopas, C
   Levine, JA
   Kirby, RM
AF Truong, Nghia
   Yuksel, Cem
   Watcharopas, Chakrit
   Levine, Joshua A.
   Kirby, Robert M.
TI Particle Merging-and-Splitting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Solid modeling; Numerical models; Couplings; Solids; Computational
   modeling; Force; Mathematical model; Particle-based simulation;
   collision handling; solid-fluid coupling
ID RIGID BODIES; CONTACT; SIMULATION; COLLISIONS; FRICTION; BOUNDARIES;
   FLUIDS
AB Robustly handling collisions between individual particles in a large particle-based simulation has been a challenging problem. We introduce particle merging-and-splitting, a simple scheme for robustly handling collisions between particles that prevents inter-penetrations of separate objects without introducing numerical instabilities. This scheme merges colliding particles at the beginning of the time-step and then splits them at the end of the time-step. Thus, collisions last for the duration of a time-step, allowing neighboring particles of the colliding particles to influence each other. We show that our merging-and-splitting method is effective in robustly handling collisions and avoiding penetrations in particle-based simulations. We also show how our merging-and-splitting approach can be used for coupling different simulation systems using different and otherwise incompatible integrators. We present simulation tests involving complex solid-fluid interactions, including solid fractures generated by fluid interactions.
C1 [Truong, Nghia; Yuksel, Cem; Kirby, Robert M.] Univ Utah, Salt Lake City, UT 84112 USA.
   [Watcharopas, Chakrit] Kasetsart Univ, Bangkok 10900, Thailand.
   [Levine, Joshua A.] Univ Arizona, Tucson, AZ 85721 USA.
C3 Utah System of Higher Education; University of Utah; Kasetsart
   University; University of Arizona
RP Truong, N (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.
EM nghiatruong.vn@gmail.com; cem@cemyuksel.com; chakrit.w@ku.th;
   josh@email.arizona.edu; kirby@cs.utah.edu
OI Truong, Nghia/0000-0003-0062-5505; Yuksel, Cem/0000-0002-0122-4159
CR Akinci N, 2013, COMPUT ANIMAT VIRT W, V24, P195, DOI 10.1002/cav.1499
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Alduan Ivan, 2011, P 2011 ACM SIGGRAPHE, P25
   Anitescu M, 1997, NONLINEAR DYNAM, V14, P231, DOI 10.1023/A:1008292328909
   [Anonymous], 1997, P EUR WORKSH COMP AN
   Band S, 2018, COMPUT GRAPH-UK, V76, P37, DOI 10.1016/j.cag.2018.08.001
   Band S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180486
   Baraff D., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P23, DOI 10.1145/192161.192168
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Batty C, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239551, 10.1145/1276377.1276502]
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Bender J., 2006, P 19 INT C COMPUTER, P3
   Bender J, 2019, PROCEEDINGS OF THE 12TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2019, DOI 10.1145/3359566.3360077
   Bender J, 2020, IEEE T VIS COMPUT GR, V26, P2982, DOI 10.1109/TVCG.2020.3004245
   Bender J, 2014, COMPUT GRAPH FORUM, V33, P228, DOI 10.1111/cgf.12346
   Bhatacharya H., 2011, Symp. Comp. Anim, P17
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   Carnegie Mellon University, 1997, PHYS BAS MOD PRINC P
   Chentanez N., 2011, P 2011 ACM SIGGRAPHE, P83
   Cornelis J, 2015, COMPUT GRAPH-UK, V52, P72, DOI 10.1016/j.cag.2015.07.022
   Daviet G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925877
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Drumwright E, 2008, IEEE T VIS COMPUT GR, V14, P231, DOI 10.1109/TVCG.2007.70416
   Du P., 2012, PROC 11 ACM SIGGRAPH, P309
   Duriez C, 2006, IEEE T VIS COMPUT GR, V12, P36, DOI 10.1109/TVCG.2006.13
   Erleben K., 2013, P ACM SIGGRAPH COURS
   Fang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392438
   Fang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322968
   FARHAT C, 1990, COMPUT METHOD APPL M, V84, P147, DOI 10.1016/0045-7825(90)90114-2
   Faure F., 2008, P 2008 ACM SIGGRAPHE, P155
   Fei Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201392
   Fei Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073630
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201309
   Génevaux O, 2003, PROC GRAPH INTERF, P31
   Gissler C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3284980
   Guendelman E, 2003, ACM T GRAPHIC, V22, P871, DOI 10.1145/882262.882358
   Hahn J. K., 1988, Computer Graphics, V22, P299, DOI 10.1145/378456.378530
   Han XC, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340258
   Harmon D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531393
   Harmon David., 2011, P ACM SIGGRAPH EUR S, P247
   Hasegawa S., 2004, Transactions of the Society of Instrument and Control Engineers, V40, P122
   Heidelberger B., 2004, P VISION MODELING VI, P339
   Huber M, 2015, COMPUT GRAPH FORUM, V34, P14, DOI 10.1111/cgf.12455
   Jiang CFF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073623
   Klár G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925906
   Koschier D, 2020, Arxiv, DOI arXiv:2009.06944
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Kry PG, 2003, ACM T GRAPHIC, V22, P106, DOI 10.1145/588272.588280
   Levine J.A., 2014, P ACM SIGGRAPHEUROGR, P47
   LOTSTEDT P, 1984, SIAM J SCI STAT COMP, V5, P370, DOI 10.1137/0905028
   Macklin M, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601152, 10.1145/280/109/2601152]
   Mirtich B., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P181, DOI 10.1145/199404.199436
   Mishra BK, 2003, INT J MINER PROCESS, V71, P73, DOI 10.1016/S0301-7516(03)00032-2
   Moore M., 1988, Computer Graphics, V22, P289, DOI 10.1145/378456.378528
   Müller M, 2004, COMPUT ANIMAT VIRT W, V15, P159, DOI 10.1002/cav.18
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   MULLER M., 2006, P VIRTUAL REALITY IN, P71, DOI [10.2312/PE/vriphys/vriphys06/071-080, DOI 10.1007/978-3-319-08234-9_92-1]
   Newmark NM., 1959, Journal of the Engineering Mechanics Division, V85, P67, DOI 10.1061/JMCEA3.0000098
   Olson D, 2014, LECT NOTES COMPUT SC, V8353, P33, DOI 10.1007/978-3-662-43880-0_3
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Pauly M., 2004, Eurographics/SIGGRAPH Symposium on Computer Animation, P109, DOI 10.1145/1028523.1028539
   Ram D., 2015, ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P157
   Redon S, 2002, COMPUT GRAPH FORUM, V21, P279, DOI 10.1111/1467-8659.t01-1-00587
   Selle A, 2009, IEEE T VIS COMPUT GR, V15, P339, DOI 10.1109/TVCG.2008.79
   Shao X, 2015, COMPUT GRAPH FORUM, V34, P191, DOI 10.1111/cgf.12467
   Shao XQ, 2015, INT J NUMER MODEL EL, V28, P254, DOI 10.1002/jnm.2003
   Stewart DE, 1996, INT J NUMER METH ENG, V39, P2671
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Tampubolon AP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073651
   Tang M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185603
   Terzopoulos D., 1989, Proceedings. Graphics Interface'89, P219
   Terzopoulos Demetri, 1987, COMPUTER GRAPHICS PR, V21, P205
   TONNESEN D, 1991, GRAPH INTER, P255
   Trinkle J., 1995, DYNAMIC MULTIRIGID B, DOI [10.5555/892916, DOI 10.5555/892916]
   Vouga E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073689
   Wang S, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340259
   Watcharopas C, 2015, LECT NOTES COMPUT SC, V9474, P82, DOI 10.1007/978-3-319-27857-5_8
   Weinstein R, 2006, IEEE T VIS COMPUT GR, V12, P365, DOI 10.1109/TVCG.2006.48
   Wolper J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392428
   Yang LP, 2012, COMPUT GRAPH FORUM, V31, P2037, DOI 10.1111/j.1467-8659.2012.03196.x
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 83
TC 2
Z9 2
U1 2
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4546
EP 4557
DI 10.1109/TVCG.2021.3093776
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400042
PM 34191729
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yang, ZJ
   Chen, BJ
   Zheng, YY
   Chen, X
   Zhou, K
AF Yang, Zhenjie
   Chen, Beijia
   Zheng, Youyi
   Chen, Xiang
   Zhou, Kun
TI Human Bas-Relief Generation From a Single Photograph
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Solid modeling; Estimation;
   Computational modeling; Image reconstruction; Image resolution; Human
   bas-relief; multi-person; occlusion resolution; contour matching; single
   image
AB We present a semi-automatic method for producing human bas-relief from a single photograph. Given an input photo of one or multiple persons, our method first estimates a 3D skeleton for each person in the image. SMPL models are then fitted to the 3D skeletons to generate a 3D guide model. To align the 3D guide model with the image, we compute a 2D warping field to non-rigidly register the projected contours of the guide model with the body contours in the image. Then the normal map of the 3D guide model is warped by the 2D deformation field to reconstruct an overall base shape. Finally, the base shape is integrated with a fine-scale normal map to produce the final bas-relief. To tackle the complex intra- and inter-body interactions, we design an occlusion relationship resolution method that operates at the level of 3D skeletons with minimal user inputs. To tightly register the model contours to the image contours, we propose a non-rigid point matching algorithm harnessing user-specified sparse correspondences. Experiments demonstrate that our human bas-relief generation method is capable of producing perceptually realistic results on various single-person and multi-person images, on which the state-of-the-art depth and pose estimation methods often fail.
C1 [Yang, Zhenjie; Chen, Beijia] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zheng, Youyi; Chen, Xiang; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Zijingang Campus, Hangzhou 310058, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Chen, X (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Zijingang Campus, Hangzhou 310058, Peoples R China.
EM yangzhj@zju.edu.cn; beibeijia@zju.edu.cn; youyizheng@zju.edu.cn;
   xchen.cs@gmail.com; kunzhou@acm.org
RI Kun, Zhou/GMX-1497-2022
OI Chen, Xiang/0000-0002-6955-8729
FU National Key Research & Development Program of China [2018YFE0100900];
   National Natural Science Foundation of China [61772024, 61732016,
   61890954]; Fundamental Research Funds for the Central Universities
FX The authors would like to thank the anonymous reviewers for their
   constructive comments. This work was supported in part by the National
   Key Research & Development Program of China under Grant 2018YFE0100900,
   in part by the National Natural Science Foundation of China under Grants
   61772024, 61732016, and 61890954, and in part by the Fundamental
   Research Funds for the Central Universities. Zhenjie Yang and Beijia
   Chen are first authors.
CR Agarwal S., CERES SOLVER
   Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Barron JT, 2015, IEEE T PATTERN ANAL, V37, P1670, DOI 10.1109/TPAMI.2014.2377712
   Belhumeur PN, 1999, INT J COMPUT VISION, V35, P33, DOI 10.1023/A:1008154927611
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bradski G, 2000, DR DOBBS J, V25, P120
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Cignoni P., 1997, Journal of Graphics Tools, V2, P15, DOI 10.1080/10867651.1997.10487476
   DURSTENFELD R, 1964, COMMUN ACM, V7, P420, DOI 10.1145/364520.364540
   Fieraru M, 2018, IEEE COMPUT SOC CONF, P318, DOI 10.1109/CVPRW.2018.00058
   Gabeur V, 2019, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2019.00232
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Guennebaud G, 2010, Eigen v3
   Güler RA, 2019, PROC CVPR IEEE, P10876, DOI 10.1109/CVPR.2019.01114
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   He K., 2017, IEEE T PATTERN ANAL, V42, P386
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jafarian Y, 2021, PROC CVPR IEEE, P12748, DOI 10.1109/CVPR46437.2021.01256
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Jiang W, 2020, PROC CVPR IEEE, P5578, DOI 10.1109/CVPR42600.2020.00562
   Johnson MK, 2011, PROC CVPR IEEE
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Kerber J, 2012, COMPUT GRAPH FORUM, V31, P2363, DOI 10.1111/j.1467-8659.2012.03185.x
   Kolomenkin M, 2011, PROC CVPR IEEE, P993, DOI 10.1109/CVPR.2011.5995643
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Li ZQ, 2019, PROC CVPR IEEE, P4516, DOI 10.1109/CVPR.2019.00465
   Liu JY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531375
   Liu YP, 2020, COMPUT AIDED GEOM D, V80, DOI 10.1016/j.cagd.2020.101860
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2020, Arxiv, DOI arXiv:1907.00837
   Natsume R, 2019, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2019.00461
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Nie JH, 2019, Arxiv, DOI arXiv:1912.13140
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Reichinger A., 2011, Journal on Computing and Cultural Heritage, V4, P108, DOI [DOI 10.1145/2037820.2037822, 10.1145/2037820.2037822]
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Smith D, 2019, IEEE I CONF COMP VIS, P5329, DOI 10.1109/ICCV.2019.00543
   Sun XF, 2009, IEEE T VIS COMPUT GR, V15, P642, DOI 10.1109/TVCG.2009.21
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Tan FT, 2020, PROC CVPR IEEE, P647, DOI 10.1109/CVPR42600.2020.00073
   Tang SC, 2019, IEEE I CONF COMP VIS, P7749, DOI 10.1109/ICCV.2019.00784
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Wang P, 2016, LECT NOTES COMPUT SC, V9905, P545, DOI 10.1007/978-3-319-46448-0_33
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P1651, DOI 10.1109/TVCG.2018.2818146
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Wu TP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409072
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Zeng Q, 2014, GRAPH MODELS, V76, P140, DOI 10.1016/j.gmod.2013.10.001
   Zhang YW, 2020, IEEE T VIS COMPUT GR, V26, P2659, DOI 10.1109/TVCG.2019.2892439
   Zhang YW, 2019, COMPUT GRAPH FORUM, V38, P521, DOI 10.1111/cgf.13655
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
NR 71
TC 4
Z9 5
U1 1
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4558
EP 4569
DI 10.1109/TVCG.2021.3092877
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400043
PM 34191727
DA 2024-11-06
ER

PT J
AU Ceneda, D
   Arleo, A
   Gschwandtner, T
   Miksch, S
AF Ceneda, Davide
   Arleo, Alessio
   Gschwandtner, Theresia
   Miksch, Silvia
TI Show Me Your Face: Towards an Automated Method to Provide Timely
   Guidance in Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Timing; Task analysis; Visual analytics; Muscles; Data visualization;
   Silver; Real-time systems; Guidance; visual analytics; emotions; facial
   analysis; machine learning
AB Providing guidance during a Visual Analytics session can support analysts in pursuing their goals more efficiently. However, the effectiveness of guidance depends on many factors: Determining the right timing to provide it is one of them. Although in complex analysis scenarios choosing the right timing could make the difference between a dependable and a superfluous guidance, an analysis of the literature suggests that this problem did not receive enough attention. In this paper, we describe a methodology to determine moments in which guidance is needed. Our assumption is that the need of guidance would influence the user state-of-mind, as in distress situations during the analytical process, and we hypothesize that such moments could be identified by analyzing the user's facial expressions. We propose a framework composed by a facial recognition software and a machine learning model trained to detect when to provide guidance according to changes of the user facial expressions. We trained the model by interviewing eight analysts during their work and ranked multiple facial features based on their relative importance in determining the need of guidance. Finally, we show that by applying only minor modifications to its architecture, our prototype was able to detect a need of guidance on the fly and made our methodology well suited also for real-time analysis sessions. The results of our evaluations show that our methodology is indeed effective in determining when a need of guidance is present, which constitutes a prerequisite to providing timely and effective guidance in VA.
C1 [Ceneda, Davide; Arleo, Alessio; Gschwandtner, Theresia; Miksch, Silvia] TU Wien, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Ceneda, D (corresponding author), TU Wien, A-1040 Vienna, Austria.
EM Davide.Ceneda@tuwien.ac.at; Alessio.Arleo@tuwien.ac.at;
   Theresia.Gschwandtner@tuwien.ac.at; Silvia.Miksch@tuwien.ac.at
RI Ceneda, Davide/HTT-2753-2023; Arleo, Alessio/IRZ-8036-2023
OI Arleo, Alessio/0000-0003-2008-3651; Ceneda, Davide/0000-0003-1198-567X
FU Vienna Science and Technology Fund (WWTF) [ICT19-047]; Research Cluster
   "Smart Communities and Technologies (Smart CT)" at TU Wien; Austrian
   Research Promotion Agency (FFG) [880883]; Austrian Science Fund (FWF)
   [P31419-N31]; Austrian Science Fund (FWF) [P31419] Funding Source:
   Austrian Science Fund (FWF)
FX This work was supported by The Vienna Science and Technology Fund (WWTF)
   under Grant ICT19-047 (GuidedVA), by the Research Cluster "Smart
   Communities and Technologies (Smart CT)" at TU Wien, by the Austrian
   Research Promotion Agency (FFG), under Grant #880883 (DoRIAH) and in
   part by the Austrian Science Fund (FWF), under Grant P31419-N31 (KnoVA).
CR [Anonymous], 2006, P INT S GRAPH DRAW
   Archambault Daniel, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P475, DOI 10.1007/978-3-642-36763-2_42
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Barral O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P1, DOI 10.1145/3377325.3377517
   Bartlett MS, 1996, ADV NEUR IN, V8, P823
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Ceneda D., 2018, PROC IEEE S VIS DATA
   Ceneda D., 2018, EUROVA, P19, DOI DOI 10.2312/EUROVA.20181107
   Ceneda D, 2019, VIS INFORM, V3, P177, DOI 10.1016/j.visinf.2019.10.005
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Czerwinski M, 2000, PEOPL COMP 14 P HCI, P71
   Czerwinski M., 2004, P SIGCHI C HUM FACT, P175, DOI [10.1145/985692.985715, DOI 10.1145/985692.985715]
   D'Mello SK, 2009, INT J LEARN TECHNOL, V4, P165, DOI 10.1504/IJLT.2009.028805
   Ekman P., 2002, FACS investigators guide. A human face, P96
   Ekman P, 1978, Manual of the Facial Action Coding System (FACS)
   Ekman P., 1978, Facial action Codings System: A technique for the measurement of facial movement
   Ekman PE, 1994, The nature of emotion: fundamental questions
   Fan MM, 2020, IEEE T VIS COMPUT GR, V26, P343, DOI 10.1109/TVCG.2019.2934797
   Fujishiro I, 1997, VISUALIZATION '97 - PROCEEDINGS, P245, DOI 10.1109/VISUAL.1997.663889
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Grafsgaard JF, 2013, INT CONF AFFECT, P159, DOI 10.1109/ACII.2013.33
   Horvitz E, 1999, P CHI, P159, DOI DOI 10.1145/302979.303030
   James G, 2013, SPRINGER TEXTS STAT, V103, P15, DOI 10.1007/978-1-4614-7138-7_2
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Keim DA, 2006, INFORMATION VISUALIZATION-BOOK, P9
   Koop D, 2008, IEEE T VIS COMPUT GR, V14, P1691, DOI 10.1109/TVCG.2008.174
   Lalle Sebastien, 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI'16, P2529
   Lewis Michael., 2000, Handbook of Emotions, V2nd, P265
   Littlewort Gwen C., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P30, DOI 10.1109/FG.2011.5771418
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Qu Lei, 2004, P 9 INT C INT US INT, P307, DOI [10.1145/964442.964514, DOI 10.1145/964442.964514]
   Raschka S., 2018, ARXIV
   SILVER MS, 1991, MIS QUART, V15, P105, DOI 10.2307/249441
   Sims Shane D., 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P15, DOI 10.1145/3382507.3418828
   Tsubouchi K, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC '17 ADJUNCT), P922, DOI 10.1145/3123024.3124556
   Williams CKI, 2001, ADV NEUR IN, V13, P682
   Züger M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174165
NR 42
TC 3
Z9 3
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4570
EP 4581
DI 10.1109/TVCG.2021.3094870
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400044
PM 34232881
OA hybrid
DA 2024-11-06
ER

PT J
AU Balci, H
   Dogrusoz, U
AF Balci, Hasan
   Dogrusoz, Ugur
TI fCoSE: A Fast Compound Graph Layout Algorithm with Constraint Support
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Compounds; Stress; Data visualization; Time complexity; Springs;
   Heuristic algorithms; Information visualization; graph layout; visual
   analytics; compound graphs; constrained layout; spectral graph drawing
ID VISUALIZATION
AB Visual analysis of relational information is vital in most real-life analytics applications. Automatic layout is a key requirement for effective visual display of such information. This article introduces a new layout algorithm named fCoSE for compound graphs showing varying levels of groupings or abstractions with support for user-specified placement constraints. fCoSE builds on a previous compound spring embedder layout algorithm and makes use of the spectral graph drawing technique for producing a quick draft layout, followed by phases where constraints are enforced and compound structures are properly shown while polishing the layout with respect to commonly accepted graph layout criteria. Experimental evaluation verifies that fCoSE produces quality layouts and is fast enough for interactive applications with small to medium-sized graphs by combining the speed of spectral graph drawing technique with the quality of force-directed layout algorithms while satisfying specified constraints and properly displaying compound structures. An implementation of fCoSE along with documentation and a demo page is freely available on GitHub at https://github.com/iVis-at-Bilkent/cytoscape.js-fcose.
C1 [Balci, Hasan; Dogrusoz, Ugur] Bilkent Univ, I Vis Informat Visualizat Res Lab, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Dogrusoz, U (corresponding author), Bilkent Univ, I Vis Informat Visualizat Res Lab, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM hasan.balci@bilkent.edu; ugur@cs.bilkent.edu.tr
RI Balci, Hasan/AAD-1867-2022; Dogrusoz, Ugur/ABI-7050-2020
OI Dogrusoz, Ugur/0000-0002-7153-0784; Balci, Hasan/0000-0001-8319-7758
FU Scientific and Technological Research Council of Turkey [118E131,
   5180088]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey under Grants 118E131 and 5180088 and Google Summer of
   Code.
CR Ahmed RFM, 2020, ADV INTELL SYST, V1058, P3, DOI 10.1007/978-3-030-31129-2_1
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Bertault F, 1999, LECT NOTES COMPUT SC, V1731, P197
   Bohringer K. F., 1990, SIGCHI Bulletin, P43
   Borg I., 2005, MODERN MULTIDIMENSIO
   Brandes U., 2001, Drawing graphs. Methods and models (Lecture Notes in Computer Science Vol.2025), P71
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Bridgeman SS, 2000, COMP GEOM-THEOR APPL, V16, P53, DOI 10.1016/S0925-7721(99)00054-1
   Çivril A, 2007, LECT NOTES COMPUT SC, V4372, P30
   Dependency cruiser Github repository, CHALK DEP GRAP
   Devkota S, 2019, LECT NOTES COMPUT SC, V11904, P291, DOI 10.1007/978-3-030-35802-0_23
   Didimo W, 2014, J VISUAL LANG COMPUT, V25, P433, DOI 10.1016/j.jvlc.2014.01.002
   Didimo W, 2014, INFORM SCIENCES, V260, P185, DOI 10.1016/j.ins.2013.09.048
   Dogrusoz U, 2006, COMPUT GRAPH-UK, V30, P86, DOI 10.1016/j.cag.2005.10.015
   Dogrusoz U, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197238
   Dogrusoz U, 2009, INFORM SCIENCES, V179, P980, DOI 10.1016/j.ins.2008.11.017
   Dwyer T, 2006, IEEE T VIS COMPUT GR, V12, P821, DOI 10.1109/TVCG.2006.156
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   Dwyer T, 2009, LECT NOTES COMPUT SC, V5417, P230, DOI 10.1007/978-3-642-00219-9_22
   Eades P, 2006, ALGORITHMICA, V44, P1, DOI 10.1007/s00453-004-1144-8
   Eades P., 2004, Graph Algorithms And Applications, V2, P191
   Franz M, 2016, BIOINFORMATICS, V32, P309, DOI 10.1093/bioinformatics/btv557
   Frishman Y, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P191, DOI 10.1109/INFVIS.2004.18
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   He W., 1998, Constraints, V3, P289, DOI 10.1023/A:1009771921595
   Hu Yifan, 2005, Mathematica J., V10, P37
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kaur H., 2015, International Journal of Science and Research (IJSR), V4, P1362
   Klauske L. K., 2012, THESIS TU BERLIN BER
   Kobourov S. G., 2013, Handbook of Graph Drawing and Visualization, P383
   Koren Y, 2003, LECT NOTES COMPUT SC, V2697, P496
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Ryall K., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P97, DOI 10.1145/263407.263521
   Sander G., 1996, A0396 U SAARL
   Sedgewick R., 2011, Advances in neural information processing systems, V129, P661
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   SUGIYAMA K, 1991, IEEE T SYST MAN CYB, V21, P876, DOI 10.1109/21.108304
   Wang XB, 1996, LECT NOTES COMPUT SC, V1027, P504, DOI 10.1007/BFb0021835
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
NR 39
TC 6
Z9 6
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4582
EP 4593
DI 10.1109/TVCG.2021.3095303
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400045
PM 34232882
DA 2024-11-06
ER

PT J
AU Skarbez, R
   Gabbard, JL
   Bowman, DA
   Ogle, JT
   Tucker, T
AF Skarbez, Richard
   Gabbard, Joseph L.
   Bowman, Doug A.
   Ogle, J. Todd
   Tucker, Thomas
TI Virtual Replicas of Real Places: Experimental Investigations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Virtual environments; Human computer interaction;
   Coherence; Task analysis; Solid modeling; Lighting; Virtual reality;
   virtual environments; presence; psychophysics; user studies
ID ENHANCES REALISTIC RESPONSE; VISUAL REALISM; DISTANCE PERCEPTION;
   SIZE-CONSTANCY; ENVIRONMENTS; PLAUSIBILITY
AB As virtual reality (VR) technology becomes cheaper, higher-quality, and more widely available, it is seeing increasing use in a variety of applications including cultural heritage, real estate, and architecture. A common goal for all these applications is a compelling virtual recreation of a real place. Despite this, there has been very little research into how users perceive and experience such replicated spaces. This article reports the results from a series of three user studies investigating this topic. Results include that the scale of the room and large objects in it are most important for users to perceive the room as real and that non-physical behaviors such as objects floating in air are readily noticeable and have a negative effect even when the errors are small in scale.
C1 [Skarbez, Richard] La Trobe Univ, Melbourne, Vic 3086, Australia.
   [Gabbard, Joseph L.] Virginia Tech, Grad Dept Ind & Syst Engn, Blacksburg, VA 24061 USA.
   [Gabbard, Joseph L.; Bowman, Doug A.; Ogle, J. Todd; Tucker, Thomas] Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
   [Bowman, Doug A.] Virginia Tech, Dept Comp Sci, Blacksburg, VA 24061 USA.
   [Ogle, J. Todd] Virginia Tech, Appl Res Immers Environm & Simulat, Blacksburg, VA 24061 USA.
   [Tucker, Thomas] Virginia Tech, Sch Visual Arts, Blacksburg, VA 24061 USA.
C3 La Trobe University; Virginia Polytechnic Institute & State University;
   Virginia Polytechnic Institute & State University; Virginia Polytechnic
   Institute & State University; Virginia Polytechnic Institute & State
   University; Virginia Polytechnic Institute & State University
RP Skarbez, R (corresponding author), La Trobe Univ, Melbourne, Vic 3086, Australia.
EM r.skarbez@latrobe.edu.au; jgabbard@vt.edu; bowman@vt.edu; jogle@vt.edu
RI Skarbez, Richard/S-7298-2019
OI Bowman, Doug/0000-0003-0491-5067; Ogle, Todd/0000-0003-2940-3594;
   Skarbez, Richard/0000-0002-2783-5257
FU Facebook
FX The authors would like to thank Deborah Asabere, Shabi Mustafa, and
   Ahmed Salih for their considerable help in running these experiments.
   They would also like to thank their participants, without whom this work
   would not have been possible, and the anonymous reviewers, for their
   helpful feedback. This work was supported by a grant from Facebook.
CR Azevedo AS, 2015, PRESENCE-TELEOP VIRT, V23, P354, DOI 10.1162/PRES_a_00205
   Baños RM, 2000, CYBERPSYCHOL BEHAV, V3, P327, DOI 10.1089/10949310050078760
   Bekele MK, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3145534
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Bouchard S, 2012, INTERACT COMPUT, V24, P227, DOI 10.1016/j.intcom.2012.04.011
   Chang Angel X., 2015, arXiv
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Hernández L, 2011, EGA-REV EXPRES GRAF, P252
   Hvass JS, 2017, P IEEE VIRT REAL ANN, P339, DOI 10.1109/VR.2017.7892315
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Kenyon RV, 2008, ANN BIOMED ENG, V36, P342, DOI 10.1007/s10439-007-9414-7
   Kenyon RV, 2007, PRESENCE-TELEOP VIRT, V16, P172, DOI 10.1162/pres.16.2.172
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Naseer M, 2019, IEEE ACCESS, V7, P1859, DOI 10.1109/ACCESS.2018.2886133
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Portman ME, 2015, COMPUT ENVIRON URBAN, V54, P376, DOI 10.1016/j.compenvurbsys.2015.05.001
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Saleeb N., 2015, WIT T BUILT ENV, V149, P21
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Nguyen TD, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043608
   Welch RB, 1996, PRESENCE-TELEOP VIRT, V5, P263, DOI 10.1162/pres.1996.5.3.263
   Yoon J., 2000, P HUM FACTORS ERGON, V44, P515, DOI [10.1177/154193120004400508, DOI 10.1177/154193120004400508]
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
NR 30
TC 5
Z9 5
U1 0
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4594
EP 4608
DI 10.1109/TVCG.2021.3096494
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400046
PM 34255629
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, XB
   Ming, Y
   Wu, TS
   Zeng, HP
   Wang, Y
   Qu, HM
AF Wang, Xingbo
   Ming, Yao
   Wu, Tongshuang
   Zeng, Haipeng
   Wang, Yong
   Qu, Huamin
TI DeHumor: Visual Analytics for Decomposing Humor
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interviews; Public speaking; Speech; Semantics; Phonetics; Feature
   extraction; Visual analytics; Humor; context; multimodal features;
   visualization
ID VISUALIZATION; MARKERS
AB Despite being a critical communication skill, grasping humor is challenging-a successful use of humor requires a mixture of both engaging content build-up and an appropriate vocal delivery (e.g., pause). Prior studies on computational humor emphasize the textual and audio features immediately next to the punchline, yet overlooking longer-term context setup. Moreover, the theories are usually too abstract for understanding each concrete humor snippet. To fill in the gap, we develop DeHumor, a visual analytical system for analyzing humorous behaviors in public speaking. To intuitively reveal the building blocks of each concrete example, DeHumor decomposes each humorous video into multimodal features and provides inline annotations of them on the video script. In particular, to better capture the build-ups, we introduce content repetition as a complement to features introduced in theories of computational humor and visualize them in a context linking graph. To help users locate the punchlines that have the desired features to learn, we summarize the content (with keywords) and humor feature statistics on an augmented time matrix. With case studies on stand-up comedy shows and TED talks, we show that DeHumor is able to highlight various building blocks of humor examples. In addition, expert interviews with communication coaches and humor researchers demonstrate the effectiveness of DeHumor for multimodal humor analysis of speech content and vocal delivery.
C1 [Wang, Xingbo; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Ming, Yao] Bloomberg LP, New York, NY 10022 USA.
   [Wu, Tongshuang] Univ Washington, Seattle, WA 98195 USA.
   [Zeng, Haipeng] Sun Yat Sen Univ, Guangzhou 510275, Peoples R China.
   [Wang, Yong] Singapore Management Univ, Singapore 188065, Singapore.
C3 Hong Kong University of Science & Technology; Bloomberg L.P.; University
   of Washington; University of Washington Seattle; Sun Yat Sen University;
   Singapore Management University
RP Wang, XB (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM xwangeg@cse.ust.hk; yming7@bloomberg.net; wtshuang@cs.washington.edu;
   zenghp5@mail.sysu.edu.cn; yongwang@smu.edu.sg; huamin@cse.ust.hk
RI Wang, Yong/HKF-3903-2023; Wang, Xingbo/JHS-6567-2023
OI Wang, Xingbo/0000-0001-5693-1128
FU  [UIT/142]
FX The authors would like to thank the industry collaborator, Own The Room
   Asia Limited, for offering valuable resources. They also thank their
   domain experts and the anonymous reviewers for their insightful
   comments. This work was supported in part by aGrant from ITFUICP
   (ProjectNo. UIT/142).
CR Ahuja Vikram., 2018, Proceedings of the Second Workshop on Computational Modeling of Peoples Opinions, Personality, and Emotions in Social Media, P1
   Attardo S, 2013, REV COGN LINGUIST, V11, P402, DOI 10.1075/rcl.11.2.12att
   Attardo S, 2011, PRAGMAT COGN, V19, P224, DOI 10.1075/pc.19.2.03att
   Attardo S, 2011, HUMOR, V24, P233, DOI 10.1515/HUMR.2011.015
   Brown TB, 2020, Arxiv, DOI arXiv:2005.14165
   Bauman Richard., 1986, STORY PERFORMANCE EV, V10
   Bertero D, 2016, NAACL HLT 2016 2016, P130, DOI DOI 10.18653/V1/N16-1016
   Bertero D, 2016, IEEE W SP LANG TECH, P383, DOI 10.1109/SLT.2016.7846293
   Cao N., 2016, Introduction to Text Visualization
   Castro S, 2018, Arxiv, DOI arXiv:1710.00477
   Cattle A., 2018, P 27 INT C COMPUTATI, P1849
   Davidson Jeff., 2003, The complete guide to public speaking
   Davis D, 2008, HUMOR RES, V8, P543
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Don A., 2007, P 16 ACM C INF KNOWL, P213, DOI [DOI 10.1145/1321440, DOI 10.1145/1321440.1321473]
   Donahue D., 2017, P 11 INT WORKSH SEM, P98
   El-Assady M, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12919
   GOLDSTEIN JH, 1970, J EXP RES PERS, V4, P90
   Halliday Michael, 1985, INTRO FUNCTIONAL GRA
   Hasan M.K., 2019, arXiv
   Janicke Stefan, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P59
   Jefferson Gail., 1979, EVERYDAY LANGUAGE ST
   Kiddon Chloe., 2011, P 49 ANN M ASS COMPU, V2, P89
   Martin J.R., 1992, English text: System and structure
   Mihalcea R., 2005, P HUM LANG TECHN C C, P531
   Mihalcea R., 2004, P C EMP METH NAT LAN, P404
   Mihalcea R, 2007, LECT NOTES COMPUT SC, V4394, P337
   Mihalcea R, 2006, COMPUT INTELL-US, V22, P126, DOI 10.1111/j.1467-8640.2006.00278.x
   Morreall J., 1986, The Philosophy of Laughter and Humor
   Mulholland Joan., 2003, A Handbook of Persuasive Tactics: A Practical Language Guide
   Nash Walter., 2014, The language of humour, V16
   Oh J., CTR COMPUTER RES MUS
   Öktem A, 2017, INTERSPEECH, P809
   Patel R, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3203
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Petridis S, 2009, IEEE INT CON MULTI, P1444, DOI 10.1109/ICME.2009.5202774
   Petridis S, 2013, IMAGE VISION COMPUT, V31, P186, DOI 10.1016/j.imavis.2012.08.014
   Pickering L, 2009, DISCOURSE PROCESS, V46, P517, DOI 10.1080/01638530902959604
   Purandare Amruta, 2006, P 2006 C EMP METH NA, P208
   Radev D, 2015, Arxiv, DOI arXiv:1506.08126
   Raskin Victor, 2012, Semantic mechanisms of humor, V24
   Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982
   Reyes A, 2012, DATA KNOWL ENG, V74, P1, DOI 10.1016/j.datak.2012.02.005
   Riehmann P, 2015, COMPUT GRAPH FORUM, V34, P61, DOI 10.1111/cgf.12618
   Rony MMU, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P246, DOI 10.1109/VIS47514.2020.00056
   Rubin S, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P191, DOI 10.1145/2807442.2807464
   Schopenhauer Arthur., 1891, The world as will and idea, V1
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Sinclair J., 1991, Corpus, Concordance, Collocation
   South L, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P241, DOI 10.1109/VIS47514.2020.00055
   Subasic I, 2008, IEEE DATA MINING, P570, DOI 10.1109/ICDM.2008.138
   Tannen D., 2007, TALKING VOICES REPET, V26
   Taylor JM, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1315
   Taylor JM, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P429
   Vuillemot Romain, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P107, DOI 10.1109/VAST.2009.5333248
   Wang X., 2020, P CHI C HUM FACT COM, P1
   Watanabe A, 2000, IEEE T SPEECH AUDI P, V8, P454, DOI 10.1109/89.848226
   Wattenberg M, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P110, DOI 10.1109/INFVIS.2002.1173155
   Wilson T., 2005, Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT'05, P347, DOI [DOI 10.3115/1220575.1220619, 10.3115/1220575.1220619]
   Wooten P, 1996, Holist Nurs Pract, V10, P49
   Yan XR, 2017, Arxiv, DOI arXiv:1704.08390
   Yang D., 2015, EMNLP, P2367
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang Renxian, 2014, P 23 ACM INT C C INF, P889
NR 65
TC 9
Z9 9
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4609
EP 4623
DI 10.1109/TVCG.2021.3097709
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400047
PM 34270427
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Adams, H
   Stefanucci, J
   Creem-Regehr, S
   Pointon, G
   Thompson, W
   Bodenheimer, B
AF Adams, Haley
   Stefanucci, Jeanine
   Creem-Regehr, Sarah
   Pointon, Grant
   Thompson, William
   Bodenheimer, Bobby
TI Shedding Light on Cast Shadows: An Investigation of Perceived Ground
   Contact in AR and VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Rendering (computer graphics); Optical imaging; Optical
   sensors; Lighting; Layout; Image color analysis; Augmented reality; OST
   AR; VST AR; VR; perception; ground contact; shadows; contrast
ID DISTANCE PERCEPTION; ATTENUATION DISPLAY; SURFACE
AB Virtual objects in augmented reality (AR) often appear to float atop real world surfaces, which makes it difficult to determine where they are positioned in space. This is problematic as many applications for AR require accurate spatial perception. In the current study, we examine how the way we render cast shadows-which act as an important monocular depth cue for creating a sense of contact between an object and the surface beneath it-impacts spatial perception. Over two experiments, we evaluate people's sense of surface contact given both traditional and non-traditional shadow shading methods in optical see-through augmented reality (OST AR), video see-through augmented reality (VST AR), and virtual reality (VR) head-mounted displays. Our results provide evidence that nontraditional shading techniques for rendering shadows in AR displays may enhance the accuracy of one's perception of surface contact. This finding implies a possible tradeoff between photorealism and accuracy of depth perception, especially in OST AR displays. However, it also supports the use of more stylized graphics like non-traditional cast shadows to improve perception and interaction in AR applications.
C1 [Adams, Haley; Bodenheimer, Bobby] Vanderbilt Univ, Dept Elect & Comp Engn, Nashville, TN 37235 USA.
   [Stefanucci, Jeanine; Creem-Regehr, Sarah; Pointon, Grant] Univ Utah, Dept Psychol, Salt Lake City, UT 84112 USA.
   [Thompson, William] Univ Utah, Dept Comp Sci, Salt Lake City, UT 84112 USA.
C3 Vanderbilt University; Utah System of Higher Education; University of
   Utah; Utah System of Higher Education; University of Utah
RP Adams, H (corresponding author), Vanderbilt Univ, Dept Elect & Comp Engn, Nashville, TN 37235 USA.
EM haley.a.adams@vanderbilt.edu; jeanine.stefanucci@psych.utah.edu;
   sarah.creem@psych.utah.edu; grant.pointon@psych.utah.edu;
   thompson@cs.utah.edu; robert.e.bodenheimer@vanderbilt.edu
OI Adams, Haley/0000-0002-7329-7840; Bodenheimer, Bobby/0000-0002-0616-5936
FU Office of Naval Research [N00014-18-1-2964]
FX The authors would like to thank Sarah Miele for her insightful guidance
   and for inspiring us with her dauntless perseverance throughout this
   project. This material is based upon work supported by the Office of
   Naval Research under Grant N00014-18-1-2964.
CR Adams H, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P547, DOI [10.1109/VRW50115.2020.00125, 10.1109/VRW50115.2020.0-151]
   Ahn J.-g., 2019, HCI International 2019 - Posters, P337
   Ballestin G, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P184, DOI 10.1109/ISMAR-Adjunct.2018.00063
   Barreira J, 2018, IEEE T VIS COMPUT GR, V24, P1223, DOI 10.1109/TVCG.2017.2676777
   Bates D., 2012, LME4 LINEAR MIXED EF
   Berning M, 2014, INT SYM MIX AUGMENT, P93, DOI 10.1109/ISMAR.2014.6948413
   Bian Z, 2005, PERCEPT PSYCHOPHYS, V67, P802, DOI 10.3758/BF03193534
   Bruckner S, 2007, IEEE T VIS COMPUT GR, V13, P1344, DOI 10.1109/TVCG.2007.70555
   Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Casati R., 2019, The visual world of shadows
   CAVANAGH P, 1989, J EXP PSYCHOL HUMAN, V15, P3, DOI 10.1037/0096-1523.15.1.3
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.0070, 10.1109/ISMAR-Adjunct.2016.61]
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Dey A, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P127, DOI 10.1109/3DUI.2010.5444706
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Do TD, 2020, INT SYM MIX AUGMENT, P64, DOI 10.1109/ISMAR50242.2020.00026
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Elder JH, 2004, PERCEPTION, V33, P1319, DOI 10.1068/p5323
   EPSTEIN S, 1980, AM PSYCHOL, V35, P790, DOI 10.1037/0003-066X.35.9.790
   Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002
   Gao Y, 2020, J SOC INF DISPLAY, V28, P117, DOI 10.1002/jsid.832
   Gibson J J, 1951, J PHILOS, V48, P788, DOI DOI 10.3758/s13414-011-0170-2
   Gibson J.J., 1975, The implications of experiments on the perception of space and motion
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Green D.M., 1966, Signal detection theory and psychophysics, VVolume 1, P1969, DOI DOI 10.1007/s00702-004-0250-8
   Gruber L, 2015, P IEEE VIRT REAL ANN, P127, DOI 10.1109/VR.2015.7223334
   Harrison C.R., 2002, CAESAR SUMMARY STAT
   Hu HH, 2000, IEEE VISUAL, P179, DOI 10.1109/VISUAL.2000.885692
   Ihaka R., 2009, R LANG ENV STAT COMP
   Ikeda S, 2020, COMPUT GRAPH-UK, V91, P141, DOI 10.1016/j.cag.2020.07.003
   Imura T, 2008, J VISION, V8, DOI 10.1167/8.13.10
   Itoh Y, 2019, IEEE T VIS COMPUT GR, V25, P1951, DOI 10.1109/TVCG.2019.2899229
   Jacobs RA, 2002, TRENDS COGN SCI, V6, P345, DOI 10.1016/S1364-6613(02)01948-4
   Jacquemin Christian, 2011, P 19 ACM INT C MULT, P173, DOI DOI 10.1145/2072298.2072322
   Kaminokado T, 2020, IEEE T VIS COMPUT GR, V26, P3576, DOI 10.1109/TVCG.2020.3023569
   Kasahara S, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 STUDIO, DOI 10.1145/3306306.3328003
   Kato H, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P352, DOI 10.1109/ISMAR.2003.1240756
   Kersten D, 1997, PERCEPTION, V26, P171, DOI 10.1068/p260171
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kytö M, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.011006
   LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M
   Madison C, 2001, PERCEPT PSYCHOPHYS, V63, P187, DOI 10.3758/BF03194461
   Mamassian P, 1998, TRENDS COGN SCI, V2, P288, DOI 10.1016/S1364-6613(98)01204-2
   Manabe S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1331, DOI 10.1109/VR.2019.8798049
   Manabe S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P627, DOI 10.1109/VR.2018.8446052
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P237, DOI 10.1145/2993369.2993388
   Meng JC, 2002, PERCEPT PSYCHOPHYS, V64, P1, DOI 10.3758/BF03194553
   Meng JC, 2001, PERCEPT PSYCHOPHYS, V63, P1, DOI 10.3758/BF03200497
   Minomo Y., 2005, P 2005 ACM SIGCHI IN, P61, DOI [10.1145/1178477.1178485, DOI 10.1145/1178477.1178485]
   Nan Liu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P488, DOI 10.1109/WCSE.2009.716
   Ni R, 2005, VIS COGN, V12, P1235, DOI 10.1080/13506280444000724
   Ni R, 2004, PERCEPTION, V33, P1305, DOI 10.1068/p5288
   Ozkan K, 2010, VIS COGN, V18, P229, DOI 10.1080/13506280802674101
   Pelli D. G, 1999, Vision research: A practical guide to laboratory methods, V5, P129
   Ping JM, 2020, J SOC INF DISPLAY, V28, P892, DOI 10.1002/jsid.947
   Rensink RA, 2004, PERCEPTION, V33, P1339, DOI 10.1068/p5322
   ROLLAND JP, 1994, P SOC PHOTO-OPT INS, V2351, P293
   ROLLAND JP, 1995, VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM '95, PROCEEDINGS, P56
   Rosales CS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P237, DOI [10.1109/VR.2019.8798095, 10.1109/vr.2019.8798095]
   Smith PL, 2018, PSYCHON B REV, V25, P2083, DOI 10.3758/s13423-018-1451-8
   Solteszova Veronika., 2011, Proc. of NPAR, P105, DOI DOI 10.1145/2024676.2024694
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   Thompson W. B., 1998, UUCS98007
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Vaziri K, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119892
   Wu HS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1775, DOI [10.1109/vr.2019.8797965, 10.1109/VR.2019.8797965]
   Wu JR, 2014, COMPUT METH PROG BIO, V113, P869, DOI 10.1016/j.cmpb.2013.12.021
   YONAS A, 1978, PERCEPTION, V7, P333, DOI 10.1068/p070333
NR 68
TC 10
Z9 11
U1 3
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4624
EP 4639
DI 10.1109/TVCG.2021.3097978
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400048
PM 34280102
DA 2024-11-06
ER

PT J
AU Shi, L
   Hu, JN
   Tan, ZH
   Tao, J
   Ding, JY
   Jin, Y
   Wu, YJ
   Thompson, PM
AF Shi, Lei
   Hu, Junnan
   Tan, Zhihao
   Tao, Jun
   Ding, Jiayan
   Jin, Yan
   Wu, Yanjun
   Thompson, Paul M.
TI MV<SUP>2</SUP>Net: Multi-Variate Multi-View Brain Network Comparison
   Over Uncertain Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Brain network; visual comparison; multivariate analysis
ID WHITE-MATTER INTEGRITY; ALZHEIMERS-DISEASE; FUNCTIONAL CONNECTIVITY;
   CORPUS-CALLOSUM; CLINICAL CORE; FIBER TRACTS; DIFFUSION; VISUALIZATION;
   DTI; PATTERNS
AB Visually identifying effective bio-markers from human brain networks poses non-trivial challenges to the field of data visualization and analysis. Existing methods in the literature and neuroscience practice are generally limited to the study of individual connectivity features in the brain (e.g., the strength of neural connection among brain regions). Pairwise comparisons between contrasting subject groups (e.g., the diseased and the healthy controls) are normally performed. The underlying neuroimaging and brain network construction process is assumed to have 100 percent fidelity. Yet, real-world user requirements on brain network visual comparison lean against these assumptions. In this work, we present MV(2)Net, a visual analytics system that tightly integrates multivariate multi-view visualization for brain network comparison with an interactive wrangling mechanism to deal with data uncertainty. On the analysis side, the system integrates multiple extraction methods on diffusion and geometric connectivity features of brain networks, an anomaly detection algorithm for data quality assessment, single- and multi-connection feature selection methods for biomarker detection. On the visualization side, novel designs are introduced which optimize network comparisons among contrasting subject groups and related connectivity features. Our design provides level-of-detail comparisons, from juxtaposed and explicit-coding views for subject group comparisons, to high-order composite view for correlation of network comparisons, and to fiber tract detail view for voxel-level comparisons. The proposed techniques are inspired and evaluated in expert studies, as well as through case analyses on diffusion and geometric bio-markers of certain neurology diseases. Results in these experiments demonstrate the effectiveness and superiority of MV(2)Net over state-of-the-art approaches.
C1 [Shi, Lei] Beihang Univ, Sch Comp Sci & Engn, Beijing 100083, Peoples R China.
   [Hu, Junnan; Tao, Jun] Sun Yat Sen Univ, Natl Supercomp Ctr, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China.
   [Tan, Zhihao; Wu, Yanjun] Chinese Acad Sci, Inst Software, Beijing 100049, Peoples R China.
   [Ding, Jiayan] Tongji Univ, Coll Design & Innovat, Shanghai 200092, Peoples R China.
   [Jin, Yan] Univ Texas MD Anderson Canc Ctr, Dept Radiat Oncol, Houston, TX 77030 USA.
   [Thompson, Paul M.] Univ Southern Calif, Imaging Genet Ctr, Mark & Mary Stevens Inst Neuroimaging & Informat, Los Angeles, CA 90007 USA.
C3 Beihang University; Sun Yat Sen University; Chinese Academy of Sciences;
   Institute of Software, CAS; Tongji University; University of Texas
   System; UTMD Anderson Cancer Center; University of Southern California
RP Tao, J (corresponding author), Sun Yat Sen Univ, Natl Supercomp Ctr, Sch Data & Comp Sci, Guangzhou 510275, Peoples R China.; Wu, YJ (corresponding author), Chinese Acad Sci, Inst Software, Beijing 100049, Peoples R China.
EM leishi@buaa.edu.cn; hujn3@mail2.sysu.edu.cn;
   tanzhihao18@mails.ucas.edu.cn; taoj23@mail.sysu.edu.cn;
   dingjy@tongji.edu.cn; yjinz@ucla.edu; yanjun@iscas.ac.cn; pthomp@usc.edu
RI Thompson, Paul/C-4194-2018
OI Thompson, Paul/0000-0002-4720-8867
FU NSFC [61772504, 61902446]; Fundamental Research Funds for the Central
   Universities; SKLSDE
FX This work was supported in part by NSFC under Grants 61772504 and
   61902446, in part by the Fundamental Research Funds for the Central
   Universities, and in part by SKLSDE.
CR Airan RD, 2016, HUM BRAIN MAPP, V37, P1986, DOI 10.1002/hbm.23150
   Aisen PS, 2015, ALZHEIMERS DEMENT, V11, P734, DOI 10.1016/j.jalz.2015.05.005
   Aisen PS, 2010, ALZHEIMERS DEMENT, V6, P239, DOI 10.1016/j.jalz.2010.03.006
   Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   [Anonymous], 2021, LOBES BRAIN
   [Anonymous], 2012, FREESURFER
   Bach B, 2015, COMPUT GRAPH FORUM, V34, P31, DOI 10.1111/cgf.12615
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   BASSER PJ, 1994, BIOPHYS J, V66, P259, DOI 10.1016/S0006-3495(94)80775-1
   Beaulieu C, 2002, NMR BIOMED, V15, P435, DOI 10.1002/nbm.782
   Brecheisen R, 2013, VISUAL COMPUT, V29, P297, DOI 10.1007/s00371-012-0733-9
   Brecheisen R, 2009, IEEE T VIS COMPUT GR, V15, P1441, DOI 10.1109/TVCG.2009.170
   Brun A, 2004, LECT NOTES COMPUT SC, V3216, P368
   Buckner RL, 2005, J NEUROSCI, V25, P7709, DOI 10.1523/JNEUROSCI.2177-05.2005
   Bullmore ET, 2009, NAT REV NEUROSCI, V10, P186, DOI 10.1038/nrn2575
   Chen HD, 2014, IEEE PAC VIS SYMP, P350, DOI 10.1109/PacificVis.2014.68
   Chen J, 2020, IEEE T VIS COMPUT GR, V26, P2818, DOI 10.1109/TVCG.2019.2898438
   Corouge I, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P344
   Daianu M, 2013, BRAIN CONNECT, V3, P407, DOI 10.1089/brain.2012.0137
   Dasgupta A, 2015, IEEE T VIS COMPUT GR, V21, P996, DOI 10.1109/TVCG.2015.2413774
   de Ridder Michael, 2018, Brain Inform, V5, P5, DOI 10.1186/s40708-018-0083-0
   Della Nave R, 2011, NEURORADIOLOGY, V53, P367, DOI 10.1007/s00234-010-0807-1
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Ding ZH, 2003, MAGNET RESON MED, V49, P716, DOI 10.1002/mrm.10415
   Everts MH, 2015, IEEE T VIS COMPUT GR, V21, P808, DOI 10.1109/TVCG.2015.2403323
   Everts MH, 2009, IEEE T VIS COMPUT GR, V15, P1299, DOI 10.1109/TVCG.2009.138
   Finn ES, 2015, NAT NEUROSCI, V18, P1664, DOI 10.1038/nn.4135
   Fujiwara T, 2017, IEEE PAC VIS SYMP, P250, DOI 10.1109/PACIFICVIS.2017.8031601
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Guo DS, 2009, IEEE T VIS COMPUT GR, V15, P1041, DOI 10.1109/TVCG.2009.143
   Han J, 2012, MOR KAUF D, P1
   Hirono N, 1998, NEUROLOGY, V50, P380, DOI 10.1212/WNL.50.2.380
   HOF PR, 1990, J COMP NEUROL, V301, P44, DOI 10.1002/cne.903010105
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jalba AC, 2015, IEEE T IMAGE PROCESS, V24, P1025, DOI 10.1109/TIP.2015.2390139
   Jianu R, 2009, IEEE T VIS COMPUT GR, V15, P1449, DOI 10.1109/TVCG.2009.141
   Jin Y, 2017, HUM BRAIN MAPP, V38, P1191, DOI 10.1002/hbm.23448
   Jones DK, 2008, IEEE T MED IMAGING, V27, P1268, DOI 10.1109/TMI.2008.922191
   Jones DK, 2013, NEUROIMAGE, V73, P239, DOI 10.1016/j.neuroimage.2012.06.081
   Jönsson D, 2020, COMPUT GRAPH FORUM, V39, P392, DOI 10.1111/cgf.14045
   Junker BH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-109
   Kaye EM, 2001, PEDIATR NEUROL, V24, P11, DOI 10.1016/S0887-8994(00)00232-0
   Kubicki M, 2007, J PSYCHIATR RES, V41, P15, DOI 10.1016/j.jpsychires.2005.05.005
   Laidlaw DH, 1998, VISUALIZATION '98, PROCEEDINGS, P127, DOI 10.1109/VISUAL.1998.745294
   Lue LF, 1996, J NEUROPATH EXP NEUR, V55, P1083, DOI 10.1097/00005072-199655100-00008
   Margulies DS, 2013, NEUROIMAGE, V80, P445, DOI 10.1016/j.neuroimage.2013.04.111
   McGonigle J., 2011, PROC 17 ANN M ORG HU
   Merhof D, 2006, IEEE T VIS COMPUT GR, V12, P1181, DOI 10.1109/TVCG.2006.151
   Moberts B, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P65
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Nelson PT, 2011, ACTA NEUROPATHOL, V121, P571, DOI 10.1007/s00401-011-0826-y
   Nir TM, 2013, NEUROIMAGE-CLIN, V3, P180, DOI 10.1016/j.nicl.2013.07.006
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   PALMER AM, 1994, BRAIN RES, V645, P338, DOI 10.1016/0006-8993(94)91670-5
   Pandey A, 2020, IEEE T VIS COMPUT GR, V26, P938, DOI 10.1109/TVCG.2019.2934402
   Pfister H., 2014, Scientific Visualization, P221
   Salvador R, 2005, CEREB CORTEX, V15, P1332, DOI 10.1093/cercor/bhi016
   Sanz-Arigita EJ, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013788
   Scheff SW, 2011, J ALZHEIMERS DIS, V24, P547, DOI 10.3233/JAD-2011-101782
   Schmidt J, 2013, IEEE T VIS COMPUT GR, V19, P2090, DOI 10.1109/TVCG.2013.213
   Schoeffel S, 2016, IEEE INT CONF INF VI, P165, DOI 10.1109/IV.2016.41
   Shi L, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3023363
   Shi L, 2015, IEEE DATA MINING, P379, DOI 10.1109/ICDM.2015.135
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Song SK, 2005, NEUROIMAGE, V26, P132, DOI 10.1016/j.neuroimage.2005.01.028
   Sporns O., 2011, NETWORKS BRAIN
   Svetachov P, 2010, COMPUT GRAPH FORUM, V29, P1023, DOI 10.1111/j.1467-8659.2009.01692.x
   Teipel SJ, 2002, ARCH NEUROL-CHICAGO, V59, P243, DOI 10.1001/archneur.59.2.243
   Thompson PM, 2001, CEREB CORTEX, V11, P1, DOI 10.1093/cercor/11.1.1
   Toga AW, 2003, NAT REV NEUROSCI, V4, P37, DOI 10.1038/nrn1009
   WALLIS JW, 1989, IEEE T MED IMAGING, V8, P297, DOI 10.1109/42.41482
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Worsley KJ, 2005, PHILOS T R SOC B, V360, P913, DOI 10.1098/rstb.2005.1637
   Xia MR, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068910
   Yang XS, 2017, IEEE T VIS COMPUT GR, V23, P181, DOI 10.1109/TVCG.2016.2598472
   Zhang S, 2003, IEEE T VIS COMPUT GR, V9, P454, DOI 10.1109/TVCG.2003.1260740
NR 81
TC 1
Z9 1
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4640
EP 4657
DI 10.1109/TVCG.2021.3098123
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400049
PM 34283716
DA 2024-11-06
ER

PT J
AU Chowdhury, TI
   Quarles, J
AF Chowdhury, Tanvir Irfan
   Quarles, John
TI A Wheelchair Locomotion Interface in a VR Disability Simulation Reduces
   Implicit Bias
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; disability simulation; implicit association test; IAT;
   bias; immersion; presence; learning; information recall; head-mounted
   display; HMD
ID WALKING-IN-PLACE; ASSOCIATION TEST; VIRTUAL-REALITY; ENVIRONMENTS;
   EXPERIENCE
AB This research investigates how experiencing virtual embodiment in a wheelchair affects implicit bias towards people who use wheelchairs. We also investigate how receiving information from a virtual instructor who uses a wheelchair affects implicit bias towards people who use wheelchairs. Implicit biases are actions or judgments of people towards various concepts or stereotypes (e.g., races). We hypothesized that experiencing a Disability Simulation (DS) through an avatar in a wheelchair and receiving information from an instructor with a disability will have a significant effect on participants' ability to recall disability-related information and will reduce implicit biases towards people who use wheelchairs. To investigate this hypothesis, a 2x2 between-subjects user study was conducted where participants experienced an immersive VR DS that presents information about Multiple Sclerosis (MS) with factors of instructor (i.e., instructor with a disability versus instructor without a disability) and locomotion interface (i.e., without a disability locomotion through in-place-walking, with a disability - locomotion in a wheelchair). Participants took a disability-focused Implicit Association Test two times, once before and once after experiencing the DS. They also took a test of knowledge retention about MS. The primary result is: experiencing the DS through locomotion in a wheelchair was better for both the disability-related information recall task and reducing implicit bias towards people who use wheelchairs.
C1 [Chowdhury, Tanvir Irfan] Marshall Univ, Dept Comp Sci, Huntington, WV 25755 USA.
   [Quarles, John] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Marshall University; University of Texas System; University of Texas at
   San Antonio (UTSA)
RP Chowdhury, TI (corresponding author), Marshall Univ, Dept Comp Sci, Huntington, WV 25755 USA.
EM chowdhuryt@marshall.edu; john.quarles@utsa.edu
RI Chowdhury, Tanvir Irfan/IXD-4222-2023
OI Chowdhury, Tanvir Irfan/0000-0001-9528-3784
FU National Multiple Sclerosis Society; National Science Foundation
   [IIS-1350995]
FX This work was supported jointly by National Multiple Sclerosis Society
   and National Science Foundation under Grant IIS-1350995.
CR Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Allport Gordon W., 1979, The Nature of Prejudice, V25th
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Carli LL, 2016, PSYCHOL WOMEN QUART, V40, P244, DOI 10.1177/0361684315622645
   Casey P.M., 2013, Court Review, V49, P64
   Casey P.M., 2012, Helping courts address implicit bias: Strategies to reduce the influence of implicit bias
   Chowdhury T. I, 2017, MSQ
   Chowdhury TI, 2021, IEEE T VIS COMPUT GR, V27, P3079, DOI 10.1109/TVCG.2019.2958332
   Chowdhury TI, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139143
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Dovidio JF, 2017, GROUP PROCESS INTERG, V20, P606, DOI 10.1177/1368430217712052
   Edmonds D., 2018, MAHZARIN BANAJI IMPL
   Eichinger J, 1992, Int J Rehabil Res, V15, P53, DOI 10.1097/00004356-199203000-00006
   Fiarman SE, 2016, EDUC LEADERSHIP, V74, P10
   Flower A, 2007, REM SPEC EDUC, V28, P72, DOI 10.1177/07419325070280020601
   French S., 1992, Disability, Handicap Society, V7, P257, DOI [DOI 10.1080/02674649266780261, 10.1002/j.1556-6676.1994.tb01728.x, DOI 10.1002/J.1556-6676.1994.TB01728.X]
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Greenwald AG, 2001, Z EXP PSYCHOL, V48, P85, DOI 10.1026//0949-3946.48.2.85
   Greenwald AG, 2003, J PERS SOC PSYCHOL, V85, P197, DOI 10.1037/0022-3514.85.2.197
   Hartwell RD, 2001, EDUC LEADERSHIP, V58, P72
   Hill C., 2010, WHY SO FEW WOMEN SCI
   Hur J, 2017, COGNITION EMOTION, V31, P1294, DOI 10.1080/02699931.2016.1213703
   Implicit P., 2020, PROJECT IMPLICIT
   Jia Wang, 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P31, DOI 10.1109/3DUI.2012.6184181
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Maister L, 2013, COGNITION, V128, P170, DOI 10.1016/j.cognition.2013.04.002
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pettigrew TF, 2006, J PERS SOC PSYCHOL, V90, P751, DOI 10.1037/0022-3514.90.5.751
   Pettigrew TF, 2011, INT J INTERCULT REL, V35, P271, DOI 10.1016/j.ijintrel.2011.03.001
   Pfeiffer D., 1989, Journal of Postsecondary Education and Disability, V7, P53
   Pivik J., 2002, Journal of Educational Computing Research, V26, P203, DOI 10.2190/WACX-1VR9-HCMJ-RTKB
   Ragan ED, 2010, PRESENCE-TELEOP VIRT, V19, P527, DOI 10.1162/pres_a_00016
   SANDLER A, 1981, EDUC TRAIN MENT RET, V16, P97
   Sherman A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228784
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Steven JY, 2014, INT CONF HIGH VOLTA
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Takatalo J, 2011, MEDIA PSYCHOL, V14, P387, DOI 10.1080/15213269.2011.620538
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Winn W, 1993, TRR939 U WASH WASH T
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 51
TC 4
Z9 4
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4658
EP 4670
DI 10.1109/TVCG.2021.3099115
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400050
PM 34310308
DA 2024-11-06
ER

PT J
AU Gong, BJ
   Zhu, ZJ
   Yan, CG
   Shi, ZG
   Xu, F
AF Gong, Bingjian
   Zhu, Zunjie
   Yan, Chenggang
   Shi, Zhiguo
   Xu, Feng
TI PlaneFusion: Real-Time Indoor Scene Reconstruction With Planar Prior
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Three-dimensional displays; Real-time systems; Optimization;
   Simultaneous localization and mapping; Geometry; Image reconstruction;
   3D reconstruction; SLAM; plane detection; real-time
AB Real-time dense SLAM techniques aim to reconstruct the dense three-dimensional geometry of a scene in real time with an RGB or RGB-D sensor. An indoor scene is an important type of working environment for these techniques. The planar prior can be used in this scenario to improve the reconstruction quality, especially for large low-texture regions that commonly occur in an indoor scene. This article fully explores the planar prior in a dense SLAM pipeline. First, we propose a novel plane detection and segmentation method that runs at 200 Hz on a modern graphics processing unit. Our algorithm for constructing global plane constraints is very efficient; hence, we use it in the process of each input frame for the camera pose estimation while maintaining the real-time performance. Second, we propose herein a plane-based map representation that greatly reduces the memory footprint of plane regions while keeping the geometric details on planes. The experiments reveal that our system yields superior reconstruction results with planar information running at more than 30 fps. Aside from speed and storage improvements, our technique also handles the low-texture problem in plane regions.
C1 [Gong, Bingjian; Zhu, Zunjie; Yan, Chenggang] Hangzhou Dianzi Univ, Dept Automat, Hangzhou 310018, Peoples R China.
   [Shi, Zhiguo] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310018, Peoples R China.
   [Xu, Feng] Tsinghua Univ, BNRIST, Beijing 100084, Peoples R China.
   [Xu, Feng] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
C3 Hangzhou Dianzi University; Zhejiang University; Tsinghua University;
   Tsinghua University
RP Zhu, ZJ (corresponding author), Hangzhou Dianzi Univ, Dept Automat, Hangzhou 310018, Peoples R China.
EM bingjiangong@hdu.edu.cn; zunjiezhu@hdu.edu.cn; cgyan@hdu.edu.cn;
   shizg@zju.edu.cn; feng-xu@tsinghua.edu.cn
RI Shi, Z/ISB-4324-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Key Research and Development Program of China [2020YFB1406604];
   National Natural Science Foundation of China [61931008, 61671196,
   61701149, 61801157, 61971268, 61901145, 61901150, 61972123]; National
   Natural Science Major Foundation of Research Instrumentation of PR China
   [61427808]; Zhejiang Province Nature Science Foundation of China
   [R17F030006, Q19F010030]; Higher Education Discipline Innovation Project
   111 [D17019]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFB1406604, in part by the
   National Natural Science Foundation of China under Grants 61931008,
   61671196, 61701149, 61801157, 61971268, 61901145, 61901150, and
   61972123, in part by the National Natural Science Major Foundation of
   Research Instrumentation of PR China under Grant 61427808, in part by
   the Zhejiang Province Nature Science Foundation of China under Grants
   R17F030006 and Q19F010030, in part by Higher Education Discipline
   Innovation Project 111 under Project D17019. Bingjian Gong and Zunjie
   Zhu contributed equally to this work. Feng Xu and Chenggang Yan are
   co-corresponding authors.
CR Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Feng C, 2014, IEEE INT CONF ROBOT, P6218, DOI 10.1109/ICRA.2014.6907776
   Furukawa Y, 2009, PROC CVPR IEEE, P1422, DOI 10.1109/CVPRW.2009.5206867
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Glocker B, 2015, IEEE T VIS COMPUT GR, V21, P571, DOI 10.1109/TVCG.2014.2360403
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Holz Dirk, 2012, RoboCup 2011: Robot Soccer World Cup XV: LNCS 7416, P306, DOI 10.1007/978-3-642-32060-6_26
   Kähler O, 2016, LECT NOTES COMPUT SC, V9912, P500, DOI 10.1007/978-3-319-46484-8_30
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Kaess M, 2015, IEEE INT CONF ROBOT, P4605, DOI 10.1109/ICRA.2015.7139837
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650
   Kim P., 2017, P BRIT MACH VIS C
   Kim P, 2018, LECT NOTES COMPUT SC, V11208, P350, DOI 10.1007/978-3-030-01225-0_21
   Kim P, 2018, IEEE INT CONF ROBOT, P7247
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Low K.-L., 2004, CHAPEL HILL U N CARO, V4, P1
   Ma LN, 2016, IEEE INT CONF ROBOT, P1285, DOI 10.1109/ICRA.2016.7487260
   Maier R, 2014, LECT NOTES COMPUT SC, V8753, P54, DOI 10.1007/978-3-319-11752-2_5
   Ming Hsiao, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5110, DOI 10.1109/ICRA.2017.7989597
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Prisacariu VA, 2017, Arxiv, DOI arXiv:1708.00783
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Ren Carl Yuheng, 2011, GSLIC REAL TIME IMPL, P1
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salas-Moreno RF, 2014, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2014.6948422
   Shi YF, 2018, LECT NOTES COMPUT SC, V11212, P767, DOI 10.1007/978-3-030-01237-3_46
   Straub J, 2018, IEEE T PATTERN ANAL, V40, P235, DOI 10.1109/TPAMI.2017.2662686
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Teschner M, 2003, VISION, MODELING, AND VISUALIZATION 2003, P47
   Vidas S, 2013, IEEE INT CONF ROBOT, P2311, DOI 10.1109/ICRA.2013.6630890
   Wang WT, 2015, INT CONF MACH LEARN, P445, DOI 10.1109/ICMLC.2015.7340962
   Whelan T., 2012, RSS WORKSH RGB D ADV
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Whelan T, 2013, IEEE INT CONF ROBOT, P5724, DOI 10.1109/ICRA.2013.6631400
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Zhang YZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2768821
NR 41
TC 3
Z9 3
U1 6
U2 32
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4671
EP 4684
DI 10.1109/TVCG.2021.3099480
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400051
PM 34310310
DA 2024-11-06
ER

PT J
AU Chen, SY
   Miranda, F
   Ferreira, N
   Lage, M
   Doraiswamy, H
   Brenner, C
   Defanti, C
   Koutsoubis, M
   Wilson, L
   Perlin, K
   Silva, C
AF Chen, Shaoyu
   Miranda, Fabio
   Ferreira, Nivan
   Lage, Marcos
   Doraiswamy, Harish
   Brenner, Corinne
   Defanti, Connor
   Koutsoubis, Michael
   Wilson, Luc
   Perlin, Ken
   Silva, Claudio
TI UrbanRama: Navigating Cities in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Navigation; Strain; Three-dimensional displays; Task analysis; Urban
   planning; Buildings; Virtual environments; Virtual reality; VR
   navigation; cylindrical deformation
ID VISUALIZATION
AB Exploring large virtual environments, such as cities, is a central task in several domains, such as gaming and urban planning. VR systems can greatly help this task by providing an immersive experience; however, a common issue with viewing and navigating a city in the traditional sense is that users can either obtain a local or a global view, but not both at the same time, requiring them to continuously switch between perspectives, losing context and distracting them from their analysis. In this article, our goal is to allow users to navigate to points of interest without changing perspectives. To accomplish this, we design an intuitive navigation interface that takes advantage of the strong sense of spatial presence provided by VR. We supplement this interface with a perspective that warps the environment, called UrbanRama, based on a cylindrical projection, providing a mix of local and global views. The design of this interface was performed as an iterative process in collaboration with architects and urban planners. We conducted a qualitative and a quantitative pilot user study to evaluate UrbanRama and the results indicate the effectiveness of our system in reducing perspective changes, while ensuring that the warping doesn't affect distance and orientation perception.
C1 [Chen, Shaoyu; Doraiswamy, Harish; Brenner, Corinne; Defanti, Connor; Perlin, Ken; Silva, Claudio] NYU, New York, NY 10003 USA.
   [Miranda, Fabio] Univ Illinois, Chicago, IL 60607 USA.
   [Ferreira, Nivan] Univ Fed Pernambuco, BR-50670901 Recife, PE, Brazil.
   [Lage, Marcos] Univ Fed Fluminense, BR-24220900 Niteri, RJ, Brazil.
   [Koutsoubis, Michael; Wilson, Luc] Kohn Pedersen Fox Associates PC, New York, NY 10036 USA.
C3 New York University; University of Illinois System; University of
   Illinois Chicago; University of Illinois Chicago Hospital; Universidade
   Federal de Pernambuco; Universidade Federal Fluminense
RP Chen, SY (corresponding author), NYU, New York, NY 10003 USA.
EM sc6439@nyu.edu; fabiom@uic.edu; nivan@cin.ufpe.br; mlage@ic.uff.br;
   harishd@nyu.edu; cjb399@nyu.edu; cd1801@nyu.edu; mkoutsoubis@kpf.com;
   lwilson@kpf.com; kp1@nyu.edu; csilva@nyu.edu
RI Lage, Marcos/K-4098-2012
OI Lage, Marcos/0000-0003-3868-8886; Miranda, Fabio/0000-0001-8612-5805;
   Chen, Shaoyu/0000-0002-1856-6294; Ferreira, Nivan/0000-0001-6631-4609;
   Doraiswamy, Harish/0000-0003-2995-250X
FU NSF [CNS-1229185, CCF-1533564, CNS-1544753, CNS1730396, CNS-1828576,
   CNS-1626098]; CNPq [305974/2018-1]; FAPERJ [E-26/202.915/2019,
   E-26/211.134/2019]
FX The author's would like to thank their colleagues from Kohn Pedersen Fox
   and New York University for their help in this research. This work was
   supported in part by the NSF under Grants CNS-1229185, CCF-1533564,
   CNS-1544753, CNS1730396, CNS-1828576, and CNS-1626098, in part by CNPq
   under Grant 305974/2018-1, and in part by FAPERJ under Grants
   E-26/202.915/2019 and E-26/211.134/2019.
CR [Anonymous], 2011, PROC INT C ARTIF REA
   [Anonymous], OpenStreetMap
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Baudisch P., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P259, DOI 10.1145/503376.503423
   Bavoil L., 2008, NVIDIA DEVELOPER INF
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Charmaz K., 2007, GROUNDED THEORY, DOI [DOI 10.1002/9781405165518.WBEOSG070.PUB2, 10.1002/9781405165518.wbeosg070.pub2]
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   Christensen C, 2016, SYMP LARG DATA ANAL, P1, DOI 10.1109/LDAV.2016.7874304
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Coxeter H.S. M., 1963, INTRO GEOMETRY
   Darken RP, 1999, P IEEE VIRT REAL ANN, P133, DOI 10.1109/VR.1999.756944
   Donalek C, 2014, IEEE INT CONF BIG DA, P609, DOI 10.1109/BigData.2014.7004282
   Sanchez GME, 2017, LANDSCAPE URBAN PLAN, V167, P98, DOI 10.1016/j.landurbplan.2017.05.018
   Ehrlich JA, 1998, HUM FAC ERG SOC P, P1466
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elvezio C, 2017, P IEEE VIRT REAL ANN, P475, DOI 10.1109/VR.2017.7892386
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Fisher-Gewirtzman D, 2018, J URBAN DES, V23, P674, DOI 10.1080/13574809.2018.1444471
   Fukatsu S., 1998, the ACM symposium, P67, DOI [DOI 10.1145/3441852.3471230, 10.1145/293701, DOI 10.1145/293701]
   Hruby F., 2019, KN - Journal of Cartography and Geographic Information, V69, P19, DOI [10.1007/s42489-019-00003-5, DOI 10.1007/S42489-019-00003-5]
   Jamei E, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112006
   Jankowski J, 2015, COMPUT GRAPH FORUM, V34, P152, DOI 10.1111/cgf.12466
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   LaViola J. J., 2001, HANDS FREE MULTISCAL, P9, DOI [10.1145/364338.364339, DOI 10.1145/364338.364339]
   Lorenz H, 2009, LECT NOTES GEOINF CA, P301
   Medeiros D, 2020, IEEE T VIS COMPUT GR, V26, P2793, DOI 10.1109/TVCG.2019.2905200
   Miranda F, 2019, IEEE T VIS COMPUT GR, V25, P1559, DOI 10.1109/TVCG.2018.2802945
   Möser S, 2008, COMPUT GRAPH FORUM, V27, P1853, DOI 10.1111/j.1467-8659.2008.01332.x
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   Pasewaldt S., 2011, 19 INT C CENTRAL EUR, P111
   Pasewaldt S., 2012, Service-Oriented Mapping 2012, P261
   Pausch R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P399, DOI 10.1145/218380.218495
   Schulze J., MOMA TALK ME HERE TH
   Spur M., 2018, WORKSHOP CITY VIS UR
   Steam, STEAM HARDW SOFTW SU
   Tan D. S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P418, DOI 10.1145/365024.365307
   Tanaka Nobuhisa, 2004, J Physiol Anthropol Appl Human Sci, V23, P313, DOI 10.2114/jpa.23.313
   Tong X, 2017, IEEE T VIS COMPUT GR, V23, P891, DOI 10.1109/TVCG.2016.2599049
   Tong X, 2016, IEEE T VIS COMPUT GR, V22, P1788, DOI 10.1109/TVCG.2015.2502583
   Trueba R., 2009, SMART GRAPHICS
   Vallance S, 2001, AUST COMP S, V23, P93, DOI 10.1109/AUIC.2001.906282
   Wang LL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P708, DOI [10.1109/VR.2019.8798025, 10.1109/vr.2019.8798025]
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
NR 50
TC 12
Z9 12
U1 4
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4685
EP 4699
DI 10.1109/TVCG.2021.3099012
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400052
PM 34310307
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Babadi, A
   van de Panne, M
   Liu, CK
   Hämäläinen, P
AF Babadi, Amin
   van de Panne, Michiel
   Liu, C. Karen
   Hamalainen, Perttu
TI Learning Task-Agnostic Action Spaces for Movement Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Task analysis; Aerospace electronics; Trajectory
   optimization; Reinforcement learning; Training; Splines (mathematics);
   Movement optimization; trajectory optimization; policy optimization;
   hierarchical reinforcement learning; action space
AB We propose a novel method for exploring the dynamics of physically based animated characters, and learning a task-agnostic action space that makes movement optimization easier. Like several previous article, we parameterize actions as target states, and learn a short-horizon goal-conditioned low-level control policy that drives the agent's state towards the targets. Our novel contribution is that with our exploration data, we are able to learn the low-level policy in a generic manner and without any reference movement data. Trained once for each agent or simulation environment, the policy improves the efficiency of optimizing both trajectories and high-level policies across multiple tasks and optimization algorithms. We also contribute novel visualizations that show how using target states as actions makes optimized trajectories more robust to disturbances; this manifests as wider optima that are easy to find. Due to its simplicity and generality, our proposed approach should provide a building block that can improve a large variety of movement optimization methods and applications.
C1 [Babadi, Amin; Hamalainen, Perttu] Aalto Univ, Dept Comp Sci, Espoo 02150, Finland.
   [van de Panne, Michiel] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
   [Liu, C. Karen] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
C3 Aalto University; University of British Columbia; Stanford University
RP Babadi, A (corresponding author), Aalto Univ, Dept Comp Sci, Espoo 02150, Finland.
EM amin.babadi@aalto.fi; van@cs.ubc.ca; karenliu@cs.stanford.edu;
   perttu.hamalainen@aalto.fi
OI Hamalainen, Perttu/0000-0001-7764-3459; Babadi, Amin/0000-0003-4930-9917
FU Academy of Finland [299358]; Technology Industries of Finland Centennial
   Foundation; Academy of Finland (AKA) [299358] Funding Source: Academy of
   Finland (AKA)
FX This work was supported by Academy of Finland under Grant 299358 and the
   Technology Industries of Finland Centennial Foundation. The experiments
   utilized the Triton cloud computing infrastructure of Aalto University.
   Part of the research was conducted while the first author was a visiting
   researcher at the University of British Columbia, Canada.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Andrychowicz M., 2017, Advances in neural information processing systems, V30, P5048, DOI DOI 10.5555/3295222.3295258
   Babadi A., 2019, PROC MOTION INTERACT, P1
   Babadi Amin, 2018, PROC IEEE C COMPUT I, P1
   Bellemare MG, 2016, ADV NEUR IN, V29
   Bergamin K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356536
   Bin Peng X, 2020, Arxiv, DOI [arXiv:2004.00784, 10.48550/arXiv.2004.00784]
   Bin Peng X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925881
   Boney R., 2019, PROC C ROBOT LEARN
   Brockman G, 2016, Arxiv, DOI arXiv:1606.01540
   Chua K, 2018, ADV NEUR IN, V31
   Coros S, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409066
   Dayan P., 1993, Advances in neural information processing systems, P271
   Dhariwal P., 2017, Openai baselines.
   Dietterich TG, 2000, J ARTIF INTELL RES, V13, P227, DOI 10.1613/jair.639
   Fujimoto S, 2018, PR MACH LEARN RES, V80
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Ghosh D., 2019, Learning to reach goals without reinforcement learning
   Gupta A, 2020, Arxiv, DOI arXiv:1806.04640
   Haarnoja T, 2018, Arxiv, DOI [arXiv:1801.01290, 10.48550/arXiv.1801.01290]
   Hafner D, 2018, Arxiv, DOI arXiv:1709.02878
   Hafner D, 2020, Arxiv, DOI arXiv:1912.01603
   Hamalainen P, 2021, Arxiv, DOI arXiv:2006.12063
   H„m„l„inen P, 2020, Arxiv, DOI arXiv:1810.02541
   Hämäläinen P, 2022, IEEE T VIS COMPUT GR, V28, P1648, DOI 10.1109/TVCG.2020.3018187
   Hämäläinen P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601218
   Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75
   Hasenclever L, 2020, PR MACH LEARN RES, V119
   Heess N, 2017, Arxiv, DOI [arXiv:1707.02286, 10.48550/arXiv.1707.02286]
   Hester T, 2017, ARTIF INTELL, V247, P170, DOI 10.1016/j.artint.2015.05.002
   Hill A., 2018, Stable baselines
   Juliani A, 2020, Arxiv, DOI [arXiv:1809.02627, 10.48550/ARXIV.1809.02627]
   Kaiser A, 2020, PROC INT C LEARN REP
   Kumar Aviral, 2020, Conservative q-learning for offline reinforcement learning
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Levine S, 2013, INT C MACHINE LEARNI, V28, P1
   Levy A., 2019, PROC INT C LEARN REP
   Li H, 2018, ADV NEUR IN, V31
   Lillicrap T.P., 2015, arXiv
   Liu LB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083723
   Liu LB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366173
   Luo YS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392433
   Merel J., 2020, PROC INT C LEARN REP
   Merel J, 2019, Arxiv, DOI arXiv:1811.11711
   Merel J, 2017, Arxiv, DOI arXiv:1707.02201
   Merel J, 2019, Arxiv, DOI arXiv:1811.09656
   Merel J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392474
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mordatch I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185539
   Mordatch Igor, 2014, Robotics: Science and Systems, V4
   Nachum O, 2019, Arxiv, DOI arXiv:1810.01257
   Nachum O, 2018, ADV NEUR IN, V31
   Naderi K, 2018, COMPUT GRAPH FORUM, V37, P69, DOI 10.1111/cgf.13513
   Naderi K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073707
   Orseau L, 2013, LECT NOTES ARTIF INT, V8139, P158
   Park S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356501
   Peng XB, 2019, ADV NEUR IN, V32
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Peng XB, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099567
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Peng XB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766910
   Rajamäki J, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099579
   Rajamäki J, 2019, IEEE T VIS COMPUT GR, V25, P2540, DOI 10.1109/TVCG.2018.2849386
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Schmeckpeper K., 2019, Learning predictive models from observation and interaction
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438, DOI 10.48550/ARXIV.1506.02438]
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Sekar R, 2020, Arxiv, DOI arXiv:2005.05960
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1
   Tassa Y, 2012, IEEE INT C INT ROBOT, P4906, DOI 10.1109/IROS.2012.6386025
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   van Hasselt H, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON APPROXIMATE DYNAMIC PROGRAMMING AND REINFORCEMENT LEARNING, P272, DOI 10.1109/ADPRL.2007.368199
   Won J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392381
   Won J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130833
   Xie C, 2016, IEEE INT CONF ROBOT, P504, DOI 10.1109/ICRA.2016.7487172
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
NR 79
TC 1
Z9 1
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4700
EP 4712
DI 10.1109/TVCG.2021.3100095
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400053
PM 34314357
OA hybrid, Green Submitted, Green Published
DA 2024-11-06
ER

PT J
AU Tkachev, G
   Frey, S
   Ertl, T
AF Tkachev, Gleb
   Frey, Steffen
   Ertl, Thomas
TI S4: Self-Supervised Learning of Spatiotemporal Similarity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Task analysis; Data visualization; Data models;
   Spatiotemporal phenomena; Computational modeling; Visualization;
   Spatiotemporal data; machine learning; ensemble visualization; visual
   exploration
ID VISUAL ANALYSIS; VISUALIZATION
AB We introduce an ML-driven approach that enables interactive example-based queries for similar behavior in ensembles of spatiotemporal scientific data. This addresses an important use case in the visual exploration of simulation and experimental data, where data is often large, unlabeled and has no meaningful similarity measures available. We exploit the fact that nearby locations often exhibit similar behavior and train a Siamese Neural Network in a self-supervised fashion, learning an expressive latent space for spatiotemporal behavior. This space can be used to find similar behavior with just a few user-provided examples. We evaluate this approach on several ensemble datasets and compare with multiple existing methods, showing both qualitative and quantitative results.
C1 [Tkachev, Gleb; Ertl, Thomas] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Frey, Steffen] Univ Groningen, NL-9712 CP Groningen, Netherlands.
C3 University of Stuttgart; University of Groningen
RP Tkachev, G (corresponding author), Univ Stuttgart, D-70174 Stuttgart, Germany.
EM gleb.tkachev@nyu.edu; s.d.frey@rug.nl;
   thomas.ertl@visus.uni-stuttgart.de
OI Ertl, Thomas/0000-0003-4019-2505; Tkachev, Gleb/0000-0003-2515-5263;
   Frey, Steffen/0000-0002-1872-6905
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence Strategy -EXC-2075 (SimTech) [390740016]
FX This work was supported by the Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation) under Germany's Excellence Strategy
   -EXC-2075 (SimTech) under Grant 390740016.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Bertasius G, 2018, LECT NOTES COMPUT SC, V11216, P342, DOI 10.1007/978-3-030-01258-8_21
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cuturi M., 2013, Advances in Neural Information Processing Systems, V2, P2292
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Doersch C, 2017, Arxiv, DOI arXiv:1708.07860
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Flamary R., 2017, J MACH LEARN RES, V22, P1
   Fofonov A, 2019, COMPUT GRAPH FORUM, V38, P286, DOI 10.1111/cgf.13531
   Geppert A, 2017, EXP FLUIDS, V58, DOI 10.1007/s00348-017-2447-2
   Guo RC, 2020, VIS INFORM, V4, P72, DOI 10.1016/j.visinf.2020.04.001
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Han W, 2016, Arxiv, DOI [arXiv:1602.08465, DOI 10.48550/ARXIV.1602.08465]
   Hao LH, 2016, IEEE T VIS COMPUT GR, V22, P787, DOI 10.1109/TVCG.2015.2468093
   He WB, 2020, VIS INFORM, V4, P109, DOI 10.1016/j.visinf.2020.04.004
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P1716, DOI 10.1109/TVCG.2018.2879866
   Higgins I., 2017, PROC INT C LEARN
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Huang QQ, 2018, LECT NOTES COMPUT SC, V11217, P437, DOI 10.1007/978-3-030-01261-8_26
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Jarema M, 2015, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2015.7347634
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kingma DP, 2014, ADV NEUR IN, V27
   Koch G. R., 2015, PROC 32 INT C MACH L, V37
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma KL, 2007, IEEE COMPUT GRAPH, V27, P6, DOI 10.1109/MCG.2007.129
   Makhzani A, 2014, Arxiv, DOI arXiv:1312.5663
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang ZJ, 2016, IEEE T VIS COMPUT GR, V22, P807, DOI 10.1109/TVCG.2015.2467292
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   Wei TH, 2017, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2017.8031586
   Ye J., 2019, arXiv
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
NR 54
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4713
EP 4727
DI 10.1109/TVCG.2021.3101418
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400054
PM 34339374
OA Green Published
DA 2024-11-06
ER

PT J
AU Hoque, MN
   Mueller, K
AF Hoque, Md Naimul
   Mueller, Klaus
TI Outcome-Explorer: A Causality Guided Interactive Visual Interface for
   Interpretable Algorithmic Decision Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Predictive models; Tools; Data models; Biological system modeling;
   Computational modeling; Machine learning; Decision making; Explainable
   AI; causality; visual analytics; human-computer interaction
ID ANALYTICS APPROACH; EXPLORATION
AB The widespread adoption of algorithmic decision-making systems has brought about the necessity to interpret the reasoning behind these decisions. The majority of these systems are complex black box models, and auxiliary models are often used to approximate and then explain their behavior. However, recent research suggests that such explanations are not overly accessible to lay users with no specific expertise in machine learning and this can lead to an incorrect interpretation of the underlying model. In this article, we show that a predictive and interactive model based on causality is inherently interpretable, does not require any auxiliary model, and allows both expert and non-expert users to understand the model comprehensively. To demonstrate our method we developed Outcome Explorer, a causality guided interactive interface, and evaluated it by conducting think-aloud sessions with three expert users and a user study with 18 non-expert users. All three expert users found our tool to be comprehensive in supporting their explanation needs while the non-expert users were able to understand the inner workings of a model easily.
C1 [Hoque, Md Naimul] SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
   [Hoque, Md Naimul] Univ Maryland, Coll Informat Studies, College Pk, MD 20742 USA.
   [Mueller, Klaus] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   University System of Maryland; University of Maryland College Park;
   State University of New York (SUNY) System; Stony Brook University
RP Hoque, MN (corresponding author), SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.; Hoque, MN (corresponding author), Univ Maryland, Coll Informat Studies, College Pk, MD 20742 USA.
EM nhoque@umd.edu; mueller@cs.stonybrook.edu
RI Hoque, Md Naimul/JXL-7518-2024
OI Hoque, Md Naimul/0000-0003-0878-501X; Mueller, Klaus/0000-0002-0996-8590
FU US National Science Foundation [IIS 1527200, 1941613]; Direct For
   Computer & Info Scie & Enginr; Div Of Information & Intelligent Systems
   [1941613] Funding Source: National Science Foundation
FX This work was supported by the US National Science Foundation under
   Grants IIS 1527200 and 1941613.
CR Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Angwin J., 2016, ProPublica, V23, P139
   BENTLER PM, 1980, PSYCHOMETRIKA, V45, P289, DOI 10.1007/BF02293905
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brennan T, 2009, CRIM JUSTICE BEHAV, V36, P21, DOI 10.1177/0093854808326545
   Bucinca Z, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P454, DOI 10.1145/3377325.3377498
   Buolamwini J., 2018, C FAIRN ACC TRANSP, P77
   Cheng H.-F., 2019, P ACM C HUM FACT COM, P1
   Chouldechova Alexandra., 2018, C FAIRN ACC TRANSP, V81, P134, DOI DOI 10.1145/3555101
   Dietvorst BJ, 2018, MANAGE SCI, V64, P1155, DOI 10.1287/mnsc.2016.2643
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Glymour B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P269
   Glymour C, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00524
   Gomez O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P531, DOI 10.1145/3377325.3377536
   HARRISON D, 1978, J ENVIRON ECON MANAG, V5, P81, DOI 10.1016/0095-0696(78)90006-2
   Hastie T, 1986, Monographs on statistics and applied probability, V1, P297, DOI 10.1214/ss/1177013604
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Hong Shen, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415224
   Kusner MJ, 2018, Arxiv, DOI arXiv:1806.02380
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Keyes Os, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274357
   Khademi A, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2907, DOI 10.1145/3308558.3313559
   Kim B., 2014, Advances in Neural Information Processing Systems, P1952
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kumar IE, 2020, PR MACH LEARN RES, V119
   Lundberg SM, 2017, ADV NEUR IN, V30
   Madras D, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P349, DOI 10.1145/3287560.3287564
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Moraffah Raha, 2020, ACM SIGKDD Explorations Newsletter, V22, P18, DOI 10.1145/3400051.3400058
   Natsukawa H, 2021, IEEE T VIS COMPUT GR, V27, P506, DOI 10.1109/TVCG.2020.3028956
   Obermeyer Z, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P89, DOI 10.1145/3287560.3287593
   Onoue Y, 2018, IEEE PAC VIS SYMP, P21, DOI 10.1109/PacificVis.2018.00012
   Pearl J., 2013, Causality. Models, Reasoning
   Pearl J., 2018, BASIC BOOKS
   Loftus JR, 2018, Arxiv, DOI arXiv:1805.05859
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rudin C., 2019, HARVARD DATA SCI REV, V1, P1, DOI [DOI 10.1162/99608F92.5A8A3A3D, https://doi.org/10.1162/99608f92.5a8a3a3d]
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Ryan R. M., 2008, HDB PERSONALITY THEO, P654, DOI DOI 10.1002/9781444318111.CH8
   Schell J, 2008, The Art of Game Design: A book of lenses, V2nd
   Shen XP, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59669-x
   Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261
   Tople Shruti, 2020, P 37 INT C MACH LEAR, P9537
   Voigt P., 2017, PRACTICAL GUIDE, V1st
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   West S. G., 1995, Structural Equation Modeling: Issues and Applications, "p, DOI DOI 10.1037/0008-400X.26.2.210
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wu YK, 2019, ADV NEUR IN, V32
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhang JZ, 2018, AAAI CONF ARTIF INTE, P2037
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang ZY, 2012, IEEE PAC VIS SYMP, P17
NR 58
TC 13
Z9 13
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4728
EP 4740
DI 10.1109/TVCG.2021.3102051
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400055
PM 34347601
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Sun, MY
   Namburi, A
   Koop, D
   Zhao, J
   Li, TY
   Chung, HY
AF Sun, Maoyuan
   Namburi, Akhil
   Koop, David
   Zhao, Jian
   Li, Tianyi
   Chung, Haeyong
TI Towards Systematic Design Considerations for Visualizing Cross-View Data
   Relationships
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Task analysis; Organizations;
   Systematics; Periodic structures; Computer science; Cross-view data
   relationship; multiple views; visual analytics
ID SET; EXPLORATION; FRAMEWORK; LINKING
AB Due to the scale of data and the complexity of analysis tasks, insight discovery often requires coordinating multiple visualizations (views), with each view displaying different parts of data or the same data from different perspectives. For example, to analyze car sales records, a marketing analyst uses a line chart to visualize the trend of car sales, a scatterplot to inspect the price and horsepower of different cars, and a matrix to compare the transaction amounts in types of deals. To explore related information across multiple views, current visual analysis tools heavily rely on brushing and linking techniques, which may require a significant amount of user effort (e.g., many trial-and-error attempts). There may be other efficient and effective ways of displaying cross-view data relationships to support data analysis with multiple views, but currently there are no guidelines to address this design challenge. In this article, we present systematic design considerations for visualizing cross-view data relationships, which leverages descriptive aspects of relationships and usable visual context of multi-view visualizations. We discuss pros and cons of different designs for showing cross-view data relationships, and provide a set of recommendations for helping practitioners make design decisions.
C1 [Sun, Maoyuan; Namburi, Akhil; Koop, David] Northern Illinois Univ, Dept Comp Sci, De Kalb, IL 60115 USA.
   [Zhao, Jian] Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Li, Tianyi] Purdue Univ, Dept Comp Informat Technol, W Lafayette, IN 47906 USA.
   [Chung, Haeyong] Univ Alabama, Dept Comp Sci, Huntsville, AL 35805 USA.
C3 Northern Illinois University; University of Waterloo; Purdue University
   System; Purdue University; University of Alabama System; University of
   Alabama Huntsville
RP Sun, MY (corresponding author), Northern Illinois Univ, Dept Comp Sci, De Kalb, IL 60115 USA.
EM smaoyuan@niu.edu; namburi.akhil12@niu.edu; dakoop@niu.edu;
   jianzhao@uwaterloo.ca; li4251@purdue.edu; chung@uah.edu
RI Sun, Maoyuan/AAJ-4301-2020
OI Zhao, Jian/0000-0001-5008-4319; Sun, Maoyuan/0000-0002-0990-2620
FU NSF [IIS-2002082/IIS-1850036]; NSERC Discovery Grant
FX This work was supported in part by the NSF under Grant
   IIS-2002082/IIS-1850036 and in part by the NSERC Discovery Grant.
CR Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B., 2014, EUR C VIS EUROVIS, P1, DOI [DOI 10.2312/EUROVISSTAR.20141170, 10.2312/eurovisstar.20141170]
   Andrews C, 2012, IEEE CONF VIS ANAL, P123, DOI 10.1109/VAST.2012.6400559
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   [Anonymous], IN SPIRE
   [Anonymous], 2012, ACM CHI, DOI DOI 10.1145/2207676.2207741
   [Anonymous], TABLEAU SOFTWARE
   Björk S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P85, DOI 10.1109/INFVIS.2000.885094
   Boukhelifa N., 2003, Information Visualization, V2, P258, DOI 10.1057/palgrave.ivs.9500057
   Boukhelifa N, 2003, INTERNATIONAL CONFERENCE ON COORDINATED AND MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P76, DOI 10.1109/CMV.2003.1215005
   Boyandin I, 2011, COMPUT GRAPH FORUM, V30, P971, DOI 10.1111/j.1467-8659.2011.01946.x
   Burtner R, 2013, PROC SPIE, V8654, DOI 10.1117/12.2004735
   Card S. K., 1999, READINGS INFORM VIS
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Chuah MC, 1996, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION '96, PROCEEDINGS, P29, DOI 10.1109/INFVIS.1996.559213
   Chung H., 2017, PERS UBIQUIT COMPUT, V22, P1
   Chung HY, 2015, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2015.7347628
   Chung HY, 2014, PERS UBIQUIT COMPUT, V18, P1169, DOI 10.1007/s00779-013-0727-2
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Dinkla K, 2012, COMPUT GRAPH FORUM, V31, P875, DOI 10.1111/j.1467-8659.2012.03080.x
   Dunne C., 2012, P SIGCHI C HUMAN FAC, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Fekete J., 2003, P IEEE S INF VIS C C, P82
   Fiaux P, 2013, COMPUTER, V46, P90, DOI 10.1109/MC.2013.269
   Geymayer T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3705, DOI 10.1145/2556288.2557032
   Gratzl S, 2014, IEEE T VIS COMPUT GR, V20, P2023, DOI 10.1109/TVCG.2014.2346260
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hienert D., 2011, PROC INT C WEB INF S, P177
   Huron S, 2013, IEEE T VIS COMPUT GR, V19, P2446, DOI 10.1109/TVCG.2013.227
   Im JF, 2013, IEEE T VIS COMPUT GR, V19, P2606, DOI 10.1109/TVCG.2013.160
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kieffer S, 2016, IEEE T VIS COMPUT GR, V22, P349, DOI 10.1109/TVCG.2015.2467451
   Knudsen Soren, 2016, PROC NORDIC C HUM CO, P1
   Koytek P, 2018, IEEE T VIS COMPUT GR, V24, P605, DOI 10.1109/TVCG.2017.2743859
   Langner R, 2018, IEEE T VIS COMPUT GR, V24, P626, DOI 10.1109/TVCG.2017.2744019
   Lex A, 2012, COMPUT GRAPH FORUM, V31, P1175, DOI 10.1111/j.1467-8659.2012.03110.x
   Lex A, 2011, IEEE T VIS COMPUT GR, V17, P2291, DOI 10.1109/TVCG.2011.250
   Lex A, 2010, IEEE PAC VIS SYMP, P57, DOI 10.1109/PACIFICVIS.2010.5429609
   Lex A, 2010, IEEE T VIS COMPUT GR, V16, P1027, DOI 10.1109/TVCG.2010.138
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Munzner T., 2014, VIS ANAL DESIGN
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI DOI 10.1145/345513.345282
   North C., 1997, TR9790 U MARYLAND CO
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pattison Tim., 2001, P ASIA PACIFIC S VIS, P165
   Prouzeau A, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P241, DOI 10.1145/3343055.3359709
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Roberts JC, 2000, PROC SPIE, V3960, P176, DOI 10.1117/12.378894
   Roberts JC, 2005, EXPLORING GEOVISUALI
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   Streit M, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S6-S4
   Sun M., 2016, Proceedings of the International Working Conference on Advanced Visual Interfaces, P44
   Sun MY, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P246, DOI [10.1109/visual.2019.8933546, 10.1109/VISUAL.2019.8933546]
   Sun MY, 2019, IEEE T VIS COMPUT GR, V25, P2983, DOI 10.1109/TVCG.2018.2861397
   Sun MY, 2016, IEEE T VIS COMPUT GR, V22, P310, DOI 10.1109/TVCG.2015.2467813
   Sun MY, 2014, IEEE T VIS COMPUT GR, V20, P1713, DOI 10.1109/TVCG.2014.2346665
   Viau C, 2012, COMPUT GRAPH FORUM, V31, P1285, DOI 10.1111/j.1467-8659.2012.03121.x
   Waldner M, 2011, IEEE PAC VIS SYMP, P115, DOI 10.1109/PACIFICVIS.2011.5742380
   Waldner Manuela, 2010, P C GRAPH INT GI 10, P129
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [DOI 10.1145/345513.345271, 10/cqq2cj]
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Weaver C, 2010, IEEE T VIS COMPUT GR, V16, P192, DOI 10.1109/TVCG.2009.94
   Wertheimer M, 1944, SOC RES, V11, P78
   Wu H, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3047017
   Yalçin MA, 2016, IEEE T VIS COMPUT GR, V22, P688, DOI 10.1109/TVCG.2015.2467051
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zgraggen E, 2014, IEEE T VIS COMPUT GR, V20, P2112, DOI 10.1109/TVCG.2014.2346293
   Zhang Hao, 2015, P 2015 ACM INT WORKS, P37, DOI DOI 10.1145/2713579.2713583
   Zhao J., 2015, THESIS U TORNOTO TOR
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P195, DOI 10.1109/TVCG.2017.2744458
   Zhao J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5003, DOI 10.1145/2858036.2858488
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
NR 86
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4741
EP 4756
DI 10.1109/TVCG.2021.3102966
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400056
PM 34357866
DA 2024-11-06
ER

PT J
AU Sevastjanova, R
   El-Assady, M
   Bradley, A
   Collins, C
   Butt, M
   Keim, D
AF Sevastjanova, Rita
   El-Assady, Mennatallah
   Bradley, Adam
   Collins, Christopher
   Butt, Miriam
   Keim, Daniel
TI VisInReport: Complementing Visual Discourse Analytics Through
   Personalized Insight Reports
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Tools; Linguistics; Visual analytics; Task analysis;
   Market research; Time series analysis; Visual analytics; text analysis;
   report generation; visualization; verbalization
ID TEXT; VISUALIZATION; COLLECTIONS; EXPLORATION; PROVENANCE
AB We present VisInReport, a visual analytics tool that supports the manual analysis of discourse transcripts and generates reports based on user interaction. As an integral part of scholarly work in the social sciences and humanities, discourse analysis involves an aggregation of characteristics identified in the text, which, in turn, involves a prior identification of regions of particular interest. Manual data evaluation requires extensive effort, which can be a barrier to effective analysis. Our system addresses this challenge by augmenting the users' analysis with a set of automatically generated visualization layers. These layers enable the detection and exploration of relevant parts of the discussion supporting several tasks, such as topic modeling or question categorization. The system summarizes the extracted events visually and verbally, generating a content-rich insight into the data and the analysis process. During each analysis session, VisInReport builds a shareable report containing a curated selection of interactions and annotations generated by the analyst. We evaluate our approach on real-world datasets through a qualitative study with domain experts from political science, computer science, and linguistics. The results highlight the benefit of integrating the analysis and reporting processes through a visual analytics system, which supports the communication of results among collaborating researchers.
C1 [Sevastjanova, Rita; El-Assady, Mennatallah; Butt, Miriam; Keim, Daniel] Univ Konstanz, D-78464 Constance, Germany.
   [Bradley, Adam; Collins, Christopher] Ontario Tech Univ, Oshawa, ON L1G 0C5, Canada.
C3 University of Konstanz
RP Sevastjanova, R (corresponding author), Univ Konstanz, D-78464 Constance, Germany.
EM rita.sevastjanova@uni-konstanz.de;
   mennatallah.el-assady@uni-konstanz.de; adam.bradley@ontariotechu.ca;
   christopher.collins@ontariotechu.ca; miriam.butt@uni-konstanz.de;
   keim@uni-konstanz.de
RI Keim, Daniel/X-7749-2019; Collins, Christopher/AAJ-6345-2020
OI El-Assady, Mennatallah/0000-0001-8526-2613; SEVASTJANOVA,
   RITA/0000-0002-2629-9579; Collins, Christopher/0000-0002-4520-7000
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) of the
   FOR2111 "Questions at the Interfaces" [KE 740/17-2, BU 1806/10-2];
   Natural Sciences and Engineering Research Council of Canada (NSERC)
FX The authors would like to thank the Deutsche Forschungsgemeinschaft
   (DFG, German Research Foundation) for funding within Projects KE
   740/17-2 and BU 1806/10-2 of the FOR2111 "Questions at the Interfaces"
   and the Natural Sciences and Engineering Research Council of Canada
   (NSERC).
CR Alexander E, 2014, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2014.7042493
   Allahyari M, 2017, Arxiv, DOI [arXiv:1707.02268, DOI 10.14569/IJAC-SA.2017.0810522]
   Angus D, 2012, IEEE T AUDIO SPEECH, V20, P1795, DOI 10.1109/TASL.2012.2189566
   Angus D, 2012, IEEE T VIS COMPUT GR, V18, P988, DOI 10.1109/TVCG.2011.100
   [Anonymous], 2003, Technical Report
   Bergstrom T, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2349
   Biber D., 1991, Variation across Speech and Writing
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blundell C., 2012, ARXIV
   Butt M., 2020, LingVis: Visual Analytics for Linguistics
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Chaney A. J.-B., 2012, P INT AAAI C WEB SOC, P419
   Cheema M. F., 2016, PROC IEEE VIS WORKSH
   Correll M, 2011, COMPUT GRAPH FORUM, V30, P731, DOI 10.1111/j.1467-8659.2011.01922.x
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   El-Assady M, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P13
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   El-Assady M, 2018, IEEE T VIS COMPUT GR, V24, P382, DOI 10.1109/TVCG.2017.2745080
   El-Assady M, 2017, COMPUT GRAPH FORUM, V36, P213, DOI 10.1111/cgf.13181
   El-Assady M, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12919
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Gold V., 2015, P EUR C VIS, DOI [10.2312/eurovisshort.20151130, DOI 10.2312/EUROVISSHORT.20151130]
   Halsall JP, 2016, COGENT SOC SCI, V2, DOI 10.1080/23311886.2016.1244145
   Hautli-Janisz A, 2017, ARGUM COMPUT, V8, P153, DOI 10.3233/AAC-170022
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Hearst M.A., 2008, P P 41 ANN HAWAII IN, P160, DOI DOI 10.1109/HICSS.2008.422
   Hogenboom F, 2016, DECIS SUPPORT SYST, V85, P12, DOI 10.1016/j.dss.2016.02.006
   J_anicke S., 2015, Eurographics Conference on Visualization, P83, DOI [DOI 10.2312/EUROVISSTAR.20151113, 10.2312/eurovisstar.20151113]
   Jentner W., 2017, In EuroVA 2017: EuroVis Workshop on Visual Analytics, P13
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kerr B, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P211, DOI 10.1109/INFVIS.2003.1249028
   Koshik Irene., 2005, RHETORICAL QUESTIONS
   Kucher K, 2016, INFORM VISUAL, V15, P93, DOI 10.1177/1473871615575079
   Kupiec J., 1995, P ACMSIGIR C RES DEV, P68
   Malik S, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P726
   Mani I., 2001, Automatic Summarization, P1
   Mathisen A, 2019, COMPUT GRAPH FORUM, V38, P649, DOI 10.1111/cgf.13717
   Morrow B, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P1, DOI [10.1109/visual.2019.8933582, 10.1109/VISUAL.2019.8933582]
   Oelke D, 2009, IEEE S VIS AN SCI TE, P187, DOI DOI 10.1109/VAST.2009.5333919
   Riezler S, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P197
   Sevastjanova R, 2018, PROC IEEE VIS WORKSH
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Singhal Amit, 2001, IEEE Data Eng. Bull., V24, P35
   Soto AJ, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2812115
   South L, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P241, DOI 10.1109/VIS47514.2020.00055
   Stitz H, 2016, COMPUT GRAPH FORUM, V35, P481, DOI 10.1111/cgf.12924
   Takamura H., 2009, P 12 C EUROPEAN CHAP, P781
   van Dijk T.A., 1997, Belgian Journal of Linguistics, V11, P11, DOI [10.1075/bjl.11.03dij, DOI 10.1075/BJL.11.03DIJ]
   VANDIJK TA, 1995, DISCOURSE SOC, V6, P243, DOI 10.1177/0957926595006002006
   Wang XT, 2016, IEEE T VIS COMPUT GR, V22, P2508, DOI 10.1109/TVCG.2016.2515592
   Wattenberg M, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P110, DOI 10.1109/INFVIS.2002.1173155
   Wei Furu, 2010, P 16 ACM SIGKDD INT, P153, DOI [10.1145/1835804.1835827, DOI 10.1145/1835804.1835827]
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Wong K. F., 2008, P 22 INT C COMPUTATI, P985
   Xu K, 2015, IEEE COMPUT GRAPH, V35, P54, DOI 10.1109/MCG.2015.50
   Yan X., 2013, P 22 INT C WORLD WID, P1445, DOI 10.1145/2488388.2488514
   Zhou L, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P284
NR 59
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4757
EP 4769
DI 10.1109/TVCG.2021.3104026
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400057
PM 34379592
OA Green Published
DA 2024-11-06
ER

PT J
AU Angelini, M
   Blasilli, G
   Lenti, S
   Palleschi, A
   Santucci, G
AF Angelini, Marco
   Blasilli, Graziano
   Lenti, Simone
   Palleschi, Alessia
   Santucci, Giuseppe
TI Effectiveness Error: Measuring and Improving RadViz Visual Effectiveness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Linear programming; Image color analysis; Heuristic
   algorithms; Statistical analysis; Springs; Proposals; Dimensionality
   reduction; RadViz; dimension arrangement; visual quality metrics
ID VISUALIZATION
AB RadViz contributes to multidimensional analysis by using 2D points for encoding data elements and interpreting them along the original data dimensions. For these characteristics it is used in different application domains, like clustering, anomaly detection, and software visualization. However, it is likely that using the dimension arrangement that comes with the data will produce a plot that leads users to make inaccurate conclusions about points values and data distribution. This article attacks this problem without altering the original RadViz design: It defines, for both a single point and a set of points, the metric of effectiveness error, and uses it to define the objective function of a dimension arrangement strategy, arguing that minimizing it increases the overall RadViz visual quality. This article investigated the intuition that reducing the effectiveness error is beneficial for other well-known RadViz problems, like points clumping toward the center, many-to-one plotting of non-proportional points, and cluster separation. It presents an algorithm that reduces to zero the effectiveness error for a single point and a heuristic that approximates the dimension arrangement minimizing the effectiveness error for an arbitrary set of points. A set of experiments based on 21 real datasets has been performed, with the goals of analyzing the advantages of reducing the effectiveness error, comparing the proposed dimension arrangement strategy with other related proposals, and investigating the heuristic accuracy. The Effectiveness Error metric, the algorithm, and the heuristic presented in this article have been made available in a d3.js plugin at https://aware-diag-sapienza.github.io/d3-radviz.
C1 [Angelini, Marco; Blasilli, Graziano; Lenti, Simone; Palleschi, Alessia; Santucci, Giuseppe] Sapienza Univ Rome, I-00185 Rome, Italy.
C3 Sapienza University Rome
RP Angelini, M (corresponding author), Sapienza Univ Rome, I-00185 Rome, Italy.
EM angelini@diag.uniroma1.it; blasilli@diag.uniroma1.it;
   lenti@diag.uniroma1.it; palleschi@diag.uniroma1.it;
   santucci@diag.uniroma1.it
RI Blasilli, Graziano/HLQ-6056-2023; Lenti, Simone/ABA-3229-2020; Santucci,
   Giuseppe/F-3907-2011
OI Blasilli, Graziano/0000-0003-3339-6403; Santucci,
   Giuseppe/0000-0003-4350-1123; Lenti, Simone/0000-0001-8281-3723;
   Angelini, Marco/0000-0001-9051-6972
CR Ahmed M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P273, DOI 10.1109/SmartCity.2015.83
   Albuquerque G., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P19, DOI 10.1109/VAST.2010.5652433
   Angelini M., 2018, PROC EUROGRAPHIEEE V, P85
   Angelini M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P226, DOI [10.1109/visual.2019.8933775, 10.1109/VISUAL.2019.8933775]
   Ankerst M, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P52, DOI 10.1109/INFVIS.1998.729559
   Bennett K. P., 1992, Optimization methods and software, V1, P23, DOI DOI 10.1080/10556789208805504
   Bertino E., 2006, Proceedings 2006 10th International Conference on Computer Supported Cooperative Work in Design (IEEE Cat. No. 06EX1292)
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   Cicirello Vincent A., 2019, Bio-inspired Information and Communication Technologies. 11th EAI International Conference, BICT 2019. Proceedings. Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering (LNICST 289), P81, DOI 10.1007/978-3-030-24202-2_7
   Cortez P, 2007, P 13 EPIA 2007 PORT
   Cortez P, 2009, DECIS SUPPORT SYST, V47, P547, DOI 10.1016/j.dss.2009.05.016
   CROES GA, 1958, OPER RES, V6, P791, DOI 10.1287/opre.6.6.791
   DAGOSTIN.R, 1973, BIOMETRIKA, V60, P613, DOI 10.1093/biomet/60.3.613
   DAGOSTINO RB, 1971, BIOMETRIKA, V58, P341, DOI 10.2307/2334522
   Dasarathy B.V., 1991, Nearest Neighbor (NN) Norms: NN Pattern Classification Techniques
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dehouche N, 2020, DATA BRIEF, V30, DOI 10.1016/j.dib.2020.105661
   Di Caro L, 2010, LECT NOTES ARTIF INT, V6119, P125
   Dua D, 2017, UCI MACHINE LEARNING
   Fotheringham AS, 1999, PROG HUM GEOG, V23, P597, DOI 10.1191/030913299667756016
   Han J, 2012, MOR KAUF D, P1
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hoffman P., 1999, P WORKSH NEW PAR INF, P9, DOI [10.1145/331770.331775, DOI 10.1145/331770.331775]
   Kahraman HT, 2013, KNOWL-BASED SYST, V37, P283, DOI 10.1016/j.knosys.2012.08.009
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Kumar R., 2010, P 19 INT C WORLD WID, P571
   Leban G, 2006, DATA MIN KNOWL DISC, V13, P119, DOI 10.1007/s10618-005-0031-5
   Lee JA, 2007, INFORM SCI STAT, P1
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Martínez A, 2013, IEEE INT CONF FUZZY, DOI 10.1109/FUZZ-IEEE.2013.6622420
   Martins R.M., 2015, CGVC, P7, DOI [10.2312/cgvc.20151234, DOI 10.2312/CGVC.20151234]
   Mumtaz H, 2018, 2018 SIXTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P12, DOI 10.1109/VISSOFT.2018.00010
   Nováková L, 2011, J INTELL INF SYST, V37, P355, DOI 10.1007/s10844-011-0157-4
   Nováková L, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P104, DOI 10.1109/IV.2009.103
   Novikova E, 2020, LECT NOTES COMPUT SC, V11980, P402, DOI 10.1007/978-3-030-42048-2_26
   [Новикова Евгения Сергеевна Novikova Evgenia Sergeevna], 2016, [Труды СПИИРАН, Trudy SPIIRAN], P32, DOI 10.15622/sp.48.2
   Pagliosa LD, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020016
   Pagliosa P, 2015, NEUROCOMPUTING, V150, P599, DOI 10.1016/j.neucom.2014.07.072
   Patrício M, 2018, BMC CANCER, V18, DOI 10.1186/s12885-017-3877-1
   Paulauskiene K, 2016, NONLINEAR ANAL-MODEL, V21, P92, DOI 10.15388/NA.2016.1.6
   Ono JHP, 2015, SIBGRAPI, P165, DOI 10.1109/SIBGRAPI.2015.38
   Pillat RM., 2005, P 2005 LATIN AM C HU, P20, DOI [DOI 10.1145/1111360.1111363, 10.1145/1111360.1111363]
   Renjith S, 2018, 2018 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P127, DOI 10.1109/RAICS.2018.8635080
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Rubio-Sánchez M, 2014, IEEE T VIS COMPUT GR, V20, P2013, DOI 10.1109/TVCG.2014.2346258
   Sharko J, 2008, IEEE T VIS COMPUT GR, V14, P1444, DOI 10.1109/TVCG.2008.173
   Tukey JW., 1977, EXPLORATORY DATA ANA
   Venna J, 2001, LECT NOTES COMPUT SC, V2130, P485
   Wang YC, 2019, VISUAL COMPUT, V35, P1567, DOI 10.1007/s00371-018-1558-y
   Wang YC, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095155
   Yeh IC, 2007, CEMENT CONCRETE COMP, V29, P474, DOI 10.1016/j.cemconcomp.2007.02.001
   Zhou F., 2017, P 10 INT S VIS INF C, P9, DOI [10.1145/3105971.3105980, DOI 10.1145/3105971.3105980]
   Zhou FF, 2015, IEEE PAC VIS SYMP, P111, DOI 10.1109/PACIFICVIS.2015.7156365
NR 56
TC 7
Z9 7
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4770
EP 4786
DI 10.1109/TVCG.2021.3104879
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400058
PM 34398753
DA 2024-11-06
ER

PT J
AU Banerjee, NT
   Baughman, AJ
   Lin, SY
   Witte, ZA
   Klaus, DM
   Anderson, AP
AF Banerjee, Neil T.
   Baughman, Alex J.
   Lin, Shu-Yu
   Witte, Zoe A.
   Klaus, David M.
   Anderson, Allison P.
TI Side-by-Side Comparison of Human Perception and Performance Using
   Augmented, Hybrid, and Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; X reality; Space vehicles; Solid modeling; Virtual
   environments; Three-dimensional displays; Resists; Artificial;
   augmented; virtual realities; human-computer interaction; human factors;
   ergonomics; usability testing; virtual environment modeling
ID DESIGN; ENVIRONMENTS; ARCHITECTURE; SITUATION
AB Alternative reality (XR) technologies, including physical, augmented, hybrid, and virtual reality, offer ways for engineered spaces to be evaluated. Traditionally, practitioners (such as those designing spacecraft habitats) have relied on physical mockups to perform such design evaluations, but digital XR technologies present several streamlining advantages over their physical counterparts. These digital environments vary in their level of virtuality, and consequently have different effects on human perception and performance, with respect to a completely physical mockup environment. To date, very little has been done to characterize and quantify such differences in human perception and performance across XR environments of equal fidelity for the same end application. Here, we show that perception and performance in the virtual reality environment most closely mirror those in the physical reality environment, as measured through volumetric assessment and functional task experiments. These experiments required subjects to judge the dimensions of 3D objects and perform operational tasks presented via checklists. Our results highlight the potential for virtual reality systems to accelerate the iterative design of engineered spaces relative to the use of physical mockups, while preserving the human perception and performance characteristics of a completely physical environment. These findings also elucidate specific advantages and disadvantages to specific digital XR technologies with respect to one another and the physical reality baseline. Practitioners may inform their selection of an XR modality for their specific end application based on this comparative analysis, as it contextualizes the niche for each technology in the realm of iterative design for engineered spaces.
C1 [Banerjee, Neil T.; Baughman, Alex J.; Lin, Shu-Yu; Witte, Zoe A.; Klaus, David M.; Anderson, Allison P.] Univ Colorado, Ann & HJ Smead Dept Aerosp Engn Sci, Boulder, CO 80303 USA.
C3 University of Colorado System; University of Colorado Boulder
RP Banerjee, NT (corresponding author), Univ Colorado, Ann & HJ Smead Dept Aerosp Engn Sci, Boulder, CO 80303 USA.
EM neil.banerjee@colorado.edu; alexander.j.baughman@colorado.edu;
   shuyu.lin@colorado.edu; zoe.witte@colorado.edu; klaus@colorado.edu;
   allison.p.anderson@colorado.edu
OI Banerjee, Neil/0000-0002-6825-917X
FU  [80NSSC18K0198]
FX The authors wish to acknowledge Abhishektha Boppana for his initial
   efforts in developing the XR environments. This work was supported
   byNASA under Grant 80NSSC18K0198.
CR Anderson A, 2021, VIRTUAL REAL-LONDON, V25, P147, DOI 10.1007/s10055-020-00448-4
   [Anonymous], 2006, PROC C CONSTRUCTION
   [Anonymous], HoloLens 2-Overview
   [Anonymous], VIVE PROPROFESSIONAL
   Arayici Y., 2011, Structural Survey, V29, P7, DOI 10.1108/02630801111118377
   Arrighi PA, 2019, J INTELL MANUF, V30, P743, DOI 10.1007/s10845-016-1276-0
   Banerjee N. T., VIR REALITY, P401
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Botden SMBI, 2007, WORLD J SURG, V31, P764, DOI 10.1007/s00268-006-0724-y
   Bouchlaghem D, 2005, AUTOMAT CONSTR, V14, P287, DOI 10.1016/j.autcon.2004.08.012
   Campos J.L., 2012, NEURAL BASEMULTISE
   Castronovo F., 2013, P 13 INT C CONSTR AP
   Chamaret D., 2008, PROC ACMSYMP VIRT RE
   Cirulis A, 2013, PROCEDIA COMPUT SCI, V25, P71, DOI 10.1016/j.procs.2013.11.009
   Crison F, 2005, P IEEE VIRT REAL ANN, P139
   De Crescenzio F, 2011, IEEE COMPUT GRAPH, V31, P96, DOI 10.1109/MCG.2011.4
   Delgado F. J. N., 2017, PROC GPU TECHNOL C
   Deligiannidis L, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P143, DOI 10.1109/TRIDUI.2006.1618284
   Dubois E, 2010, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-84882-733-2_1
   Edwards G., 2015, Visualization in Engineering, V3, P1, DOI DOI 10.1186/S40327-015-0018-2
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Ganier F, 2014, ERGONOMICS, V57, P828, DOI 10.1080/00140139.2014.899628
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Goode L, 2019, HOLOLENS 2 PUTS FULL
   Gopher D, 2012, WORK, V41, P2284, DOI 10.3233/WOR-2012-0452-2284
   Gopinath R., 2004, PROC C CONSTRUCTION, P14
   Gosselin F, 2005, WORLD HAPTICS CONFERENCE: FIRST JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRUTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P202
   Gray R, 2013, P IEEE, V101, P2113, DOI 10.1109/JPROC.2012.2225811
   Hale KS, 2009, THEOR ISS ERGON SCI, V10, P245, DOI 10.1080/14639220802151310
   Hecht D, 2006, PRESENCE-TELEOP VIRT, V15, P515, DOI 10.1162/pres.15.5.515
   Higdon K. P., 2008, PROC 11 BIENNIAL ASC, P1, DOI [10.1061/40988(323)96, DOI 10.1061/40988(323)96]
   Hirshorn S., 2017, NASA SYST ENG HDB, P67
   Issa RRA, 2000, CONSTRUCTION CONGRESS VI, PROCEEDING, P1007
   Ivson P, 2020, IEEE T VIS COMPUT GR, V26, P3109, DOI 10.1109/TVCG.2019.2907583
   Jordan Patrick W, 1996, Industry
   Kanas N, 2008, SPACE TECHNOL LIB, V22, P15, DOI 10.1007/978-1-4020-6770-9_2
   Keshner EA, 2011, IEEE ENG MED BIO, P1379, DOI 10.1109/IEMBS.2011.6090324
   Kim M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051141
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Majumdar T., 2006, PROC JOINT INT C COM
   Maldovan K., 2006, JOINT INT C COMPUTIN, P14
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nolle Stefan, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P249, DOI 10.1109/ISMAR.2006.297829
   Rhienmora P., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, P97, DOI [10.1145/1889863.1889883, DOI 10.1145/1889863.1889883]
   Seth A, 2011, VIRTUAL REAL-LONDON, V15, P5, DOI 10.1007/s10055-009-0153-y
   SUEMATU Y, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1770, DOI 10.1109/IECON.1993.339342
   Vassallo R, 2017, PROC SPIE, V10136, DOI 10.1117/12.2255831
   Wang P, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15061204
   Wang Xiangyu., 2009, Mixed Reality In Architecture Design, and Construction, V2, P15
   Wang Xiangyu., 2008, Mixed reality in architecture, design, and construction
   Westerdahl B, 2006, AUTOMAT CONSTR, V15, P150, DOI 10.1016/j.autcon.2005.02.010
   Whyte J, 2000, AUTOMAT CONSTR, V10, P43, DOI 10.1016/S0926-5805(99)00012-6
   Woodward C., 2011, AUGMENTED REALITY SO
   Yue K, 2016, PROC SPIE, V10155, DOI 10.1117/12.2243981
NR 55
TC 9
Z9 9
U1 3
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4787
EP 4796
DI 10.1109/TVCG.2021.3105606
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400059
PM 34406940
DA 2024-11-06
ER

PT J
AU Meinecke, C
   Wrisley, DJ
   Janicke, S
AF Meinecke, Christofer
   Wrisley, David Joseph
   Janicke, Stefan
TI Explaining Semi-Supervised Text Alignment Through Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Semantics; Task analysis; Visual analytics; Pipelines;
   Data visualization; Collaboration; Text alignment; word embeddings;
   human-in-the-loop; visualization in the humanities; professional reading
ID DIGITAL HUMANITIES; VISUAL ANALYTICS
AB The analysis of variance in complex text traditions is an arduous task when carried out manually. Text alignment algorithms provide domain experts with a robust alternative to such repetitive tasks. Existing white-box approaches allow the digital humanities to establish syntax-based metrics taking into account the spelling, morphology and order of words. However, they produce limited results, as semantic meanings are typically not taken into account. Our interdisciplinary collaboration between visualization and digital humanities combined a semi-supervised text alignment approach based on word embeddings that take not only syntactic but also semantic text features into account, thereby improving the overall quality of the alignment. In our collaboration, we developed different visual interfaces that communicate the word distribution in high-dimensional vector space generated by the underlying neural network for increased transparency, assessment of the tool's reliability and overall improved hypothesis generation. We further offer visual means to enable the expert reader to feed domain knowledge into the system at multiple levels with the aim of improving both the product and the process of text alignment. This ultimately illustrates how visualization can engage with and augment complex modes of reading in the humanities.
C1 [Meinecke, Christofer] Univ Leipzig, D-04109 Leipzig, Germany.
   [Wrisley, David Joseph] New York Univ Abu Dhabi, Abu Dhabi 25586, U Arab Emirates.
   [Janicke, Stefan] Univ Southern Denmark, DK-5230 Odense, Denmark.
C3 Leipzig University; New York University; New York University Abu Dhabi;
   University of Southern Denmark
RP Meinecke, C (corresponding author), Univ Leipzig, D-04109 Leipzig, Germany.
EM cmeinecke@informatik.uni-leipzig.de; djw12@nyu.edu;
   stjaenicke@imada.sdu.dk
OI Meinecke, Christofer/0000-0002-5637-9975; Wrisley, David
   Joseph/0000-0002-0355-1487
CR Abdul-Rahman A, 2017, COMPUT GRAPH FORUM, V36, P237, DOI 10.1111/cgf.12798
   Abdul-Rahman A, 2013, COMPUT GRAPH FORUM, V32, P381, DOI 10.1111/cgf.12125
   Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Alharbi M, 2022, IEEE T VIS COMPUT GR, V28, P1397, DOI 10.1109/TVCG.2020.3012778
   [Anonymous], 1971, SMART RETRIEVAL SYST
   Asokarajan Bharathi, 2016, EUROVIS WORKSHOP VIS, P19, DOI [10.2312/eurova.20161119, DOI 10.2312/EUROVA.20161119]
   Baumann M., 2019, PROC LEIPZIG S VIS A
   Behrisch M., 2012, P EUROVA INT WORKSH, P61
   Bode K, 2017, MOD LANG QUART, V78, P77, DOI 10.1215/00267929-3699787
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bradley AJ, 2018, IEEE COMPUT GRAPH, V38, P26, DOI 10.1109/MCG.2018.2878900
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   EHuf2EK R, 2010, P LREC 2010 WORKSHOP, P46
   El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Ethayarajh K, 2018, REPRESENTATION LEARNING FOR NLP, P91
   Geng Z, 2015, INFORM VISUAL, V14, P273, DOI 10.1177/1473871613495845
   Hazem A, 2019, 1ST INTERNATIONAL WORKSHOP ON COMPUTATIONAL APPROACHES TO HISTORICAL LANGUAGE CHANGE, P240
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hinrichs U., 2017, 2 WORKSHOP VISUALIZA
   J_anicke S., 2015, Eurographics Conference on Visualization, P83, DOI [DOI 10.2312/EUROVISSTAR.20151113, 10.2312/eurovisstar.20151113]
   Jänicke S, 2017, IEEE CONF VIS ANAL, P127, DOI 10.1109/VAST.2017.8585505
   Jänicke S, 2017, DIGIT SCHOLARSH HUM, V32, P106, DOI 10.1093/llc/fqx033
   Jaenicke S, 2016, IEEE T VIS COMPUT GR, V22, P200, DOI 10.1109/TVCG.2015.2467620
   Janicke Stefan, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P59
   Janicke S., 2020, Proceedings of VisGap, P35
   Janicke S., 2015, PROC DIGIT HUMANITIE, V2015
   Janicke S, 2016, PROC WORKSHOP VIS DI
   Jiang L, 2019, J VISUAL-JAPAN, V22, P401, DOI 10.1007/s12650-018-0531-1
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kallio K., 2020, FOLKLORE FELLOWSNETW, V54, P12
   Kashcha A, WORD2VEC GRAPH
   Katricheva N., 2019, PROC INT C ANAL IMAG, P190
   Kucher K, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3132169
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Kutuzov A., 2017, PROC SOFTW DEMONSTRA, P99
   Lee J. J., 2018, J ISSN, V2371
   Li J, 2016, Visualizing and Understanding Neural Models in NLP Association for Computational Linguistics, DOI DOI 10.18653/V1/N16-1082
   Liu A, 2020, PMLA, V135, P130
   Makki Raheleh, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P178
   Meinecke C., 2019, PROC LEIPZIG S VIS A
   Meyer P., 1882, Romania, V11, P213
   Mikolov T., 2013, P 2013 C N AM CHAPT, P746
   Mikolov T., 2013, P 26 C NEUR INF PROC, P3111
   Mikolov T., 2013, ICLR WORKSHOP TRACK
   Mu J., 2018, INT C LEARNING REPRE
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Petit de Julleville L, 1878, ALPHONSE LEMERRE CLA
   Riehmann P, 2015, COMPUT GRAPH FORUM, V34, P61, DOI 10.1111/cgf.12618
   Schetinger V., 2019, 4 WORKSHOP VISUALIZA
   Schreibman S, VERSIONING MACHINE
   Siemens R, 2009, DIGIT HUMANITIES Q, V3
   Smarzewski R, 2020, INT J APPROX REASON, V124, P123, DOI [10.1016/j.ijar.2020.06.001, 10.1080/18824889.2021.1893936, 10.1038/s41598-022-19167-8]
   Smilkov D., 2016, PROC WORKSHOP INTERP
   Snyder LS, 2020, IEEE T VIS COMPUT GR, V26, P558, DOI 10.1109/TVCG.2019.2934614
   Tang S, 2019, Arxiv, DOI arXiv:1905.10971
   Underwood T, 2017, DIGIT HUMANITIES Q, V11
   Van Zundert J. J., 2020, Digital Technology and the Practices of Humanities Research, P123, DOI [10.11647/obp.0192/ch6.xhtml, DOI 10.11647/OBP.0192/CH6.XHTML]
   von Wartburg W, 1959, FRANZOSISCHES ETYMOL
   Wheeles D., 2013, PROC DIGIT HUMANITIE
   Wrisley D. J., 2018, P 3 WORKSH VIS DIG H
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yousef T., 2019, LEVIA 19 LEIPZIG S V
   Yousef T, 2021, IEEE T VIS COMPUT GR, V27, P1149, DOI 10.1109/TVCG.2020.3028975
   Zumthor Paul., 1992, Toward a Medieval Poetics
NR 68
TC 5
Z9 5
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4797
EP 4809
DI 10.1109/TVCG.2021.3105899
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400060
PM 34406941
DA 2024-11-06
ER

PT J
AU Lu, JM
   Li, CF
   Cao, GC
   Hu, SM
AF Lu, Jia-Ming
   Li, Chen-Feng
   Cao, Geng-Chen
   Hu, Shi-Min
TI Simulating Fractures With Bonded Discrete Element Method
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Mathematical model; Finite element analysis;
   Graphics; Solids; Adaptation models; Solid modeling; Physically based
   animation; solid material; fracture; fragmentation; particle-based
   method
ID CRACK-GROWTH; ANIMATION; MODEL; CALIBRATION
AB Along with motion and deformation, fracture is a fundamental behaviour for solid materials, playing a critical role in physically-based animation. Many simulation methods including both continuum and discrete approaches have been used by the graphics community to animate fractures for various materials. However, compared with motion and deformation, fracture remains a challenging task for simulation, because the material's geometry, topology and mechanical states all undergo continuous (and sometimes chaotic) changes as fragmentation develops. Recognizing the discontinuous nature of fragmentation, we propose a discrete approach, namely the Bonded Discrete Element Method (BDEM), for fracture simulation. The research of BDEM in engineering has been growing rapidly in recent years, while its potential in graphics has not been explored. We also introduce several novel changes to BDEM to make it more suitable for animation design. Compared with other fracture simulation methods, the BDEM has some attractive benefits, e.g., efficient handling of multiple fractures, simple formulation and implementation, and good scaling consistency. But it also has some critical weaknesses, e.g., high computational cost, which demand further research. A number of examples are presented to demonstrate the pros and cons, which are then highlighted in the conclusion and discussion.
C1 [Lu, Jia-Ming; Hu, Shi-Min] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
   [Lu, Jia-Ming; Hu, Shi-Min] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Li, Chen-Feng] Swansea Univ, Coll Engn, Swansea SA2 8PP, W Glam, Wales.
   [Cao, Geng-Chen] Tsinghua Univ, Dept Phys, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University; Swansea University; Tsinghua
   University
RP Hu, SM (corresponding author), Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.; Hu, SM (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM jaimeyzzz@outlook.com; c.f.li@swansea.ac.uk;
   cgc17@mails.tsinghua.edu.cn; shimin@tsinghua.edu.cn
RI Li, Chenfeng/AFQ-6554-2022; lu, jm/JPK-3675-2023; Hu,
   Shi-Min/AAW-1952-2020
OI Lu, Jia-Ming/0000-0002-7793-0463; Cao, Geng-Chen/0000-0001-6605-7219;
   Hu, Shi-Min/0000-0001-7507-6542; Li, Chenfeng/0000-0003-0441-211X
FU China's National Key Technology RD Program [2017YFB1002701]; National
   Natural Science Foundation of China [61521002]
FX The authors would like to thank all the anonymous reviewers for their
   suggestions. This work was supported in part by the China's National Key
   Technology R&D Program under Grant 2017YFB1002701, in part by the
   National Natural Science Foundation of China under Grant 61521002.
CR André D, 2012, COMPUT METHOD APPL M, V213, P113, DOI 10.1016/j.cma.2011.12.002
   [Anonymous], 2015, ACM T GRAPHIC
   [Anonymous], 2009, PROC CONGRESO ESPANO
   Bao ZS, 2007, IEEE T VIS COMPUT GR, V13, P370, DOI 10.1109/TVCG.2007.39
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   BELL BYM05, 2005, P 2005 ACM SIGGRAPH, P77, DOI [10.1145/1073368.10733794, DOI 10.1145/1073368.10733794, DOI 10.1145/1073368.1073379]
   Belytschko T, 1999, INT J NUMER METH ENG, V45, P601, DOI 10.1002/(SICI)1097-0207(19990620)45:5<601::AID-NME598>3.0.CO;2-S
   Bergou M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360662
   Busaryev O, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461920
   Chen ZL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601115
   CUNDALL PA, 1979, GEOTECHNIQUE, V29, P47, DOI 10.1680/geot.1979.29.1.47
   Cundall PA, 1971, P INT S ROCK FRACT
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   H_adrich T., 2020, PROC EUROGRAPHICS AC, DOI [10.2312/sca.20201215, DOI 10.2312/SCA.20201215]
   Hahn D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925902
   Hahn D, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766896
   He XW, 2018, IEEE T VIS COMPUT GR, V24, P2589, DOI 10.1109/TVCG.2017.2755646
   Hu YM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356506
   ITASCA Consulting Group, 2021, PFC VERS 7 00 141
   Kaufmann P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531356
   Koschier D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073666
   Koteras JR, 2007, INT J NUMER METH ENG, V69, P2780, DOI 10.1002/nme.1865
   Kugelstadt T., 2016, P S COMP AN, P169
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Levine J.A., 2014, P ACM SIGGRAPHEUROGR, P47
   Liu TT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508406
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Luding S., 2008, Eur. J. Environ. Civ, V12, P785, DOI DOI 10.1080/19648189.2008
   Moës N, 1999, INT J NUMER METH ENG, V46, P131, DOI 10.1002/(SICI)1097-0207(19990910)46:1<131::AID-NME726>3.0.CO;2-J
   Molino N, 2004, ACM T GRAPHIC, V23, P385, DOI 10.1145/1015706.1015734
   Müller M, 2004, PROC GRAPH INTERF, P239
   Müller M, 2001, SPRING EUROGRAP, P113
   MULLER MATTHIAS, 2004, P 2004 ACM SIGGRAPH, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542]
   Mulligan M., 2011, ACM T GRAPHIC, P1
   Norton A., 1991, Visual Computer, V7, P210, DOI 10.1007/BF01900837
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   O'Brien JF, 1999, COMP GRAPH, P137, DOI 10.1145/311535.311550
   Parker E.G., 2009, PROC S COMP ANIM, P165, DOI DOI 10.1145/1599470.1599492
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Pfaff T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601132
   Potyondy DO, 2004, INT J ROCK MECH MIN, V41, P1329, DOI 10.1016/j.ijrmms.2004.09.011
   Qu TM, 2020, POWDER TECHNOL, V366, P527, DOI 10.1016/j.powtec.2020.02.077
   Qu TM, 2020, INT J NUMER ANAL MET, V44, P1281, DOI 10.1002/nag.3061
   Qu TM, 2019, POWDER TECHNOL, V356, P795, DOI 10.1016/j.powtec.2019.09.016
   Rungjiratananon W, 2008, COMPUT GRAPH FORUM, V27, P1887, DOI 10.1111/j.1467-8659.2008.01336.x
   Sifakis E, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P73
   Silling SA, 2005, COMPUT STRUCT, V83, P1526, DOI 10.1016/j.compstruc.2004.11.026
   Smith J, 2001, COMPUT GRAPH FORUM, V20, P81, DOI 10.1111/1467-8659.t01-1-00202
   Soler C, 2018, COMPUT GRAPH FORUM, V37, P137, DOI 10.1111/cgf.13519
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   SULSKY D, 1995, COMPUT PHYS COMMUN, V87, P236, DOI 10.1016/0010-4655(94)00170-7
   Tampubolon AP, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073651
   Terzopoulos D., 1988, Computer Graphics, V22, P269, DOI 10.1145/378456.378522
   Wang Y., 2014, Proc ACM SIGGRAPH/Eurographics Symp Comp Anim, SCA '14, P77, DOI 10.2312/sca.20141125
   Wicke M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778786
   Wolper J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322949
   Yue YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275095
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zienkiewicz OC, 2005, FINITE ELEMENT METHOD FOR FLUID DYNAMICS, 6TH EDITION, P1
NR 59
TC 3
Z9 3
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4810
EP 4824
DI 10.1109/TVCG.2021.3106738
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400061
PM 34437065
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Kuták, D
   Selzer, MN
   Byska, J
   Ganuza, ML
   Barisic, I
   Kozlíková, B
   Miao, HC
AF Kutak, David
   Nicolas Selzer, Matias
   Byska, Jan
   Lujan Ganuza, Maria
   Barisic, Ivan
   Kozlikova, Barbora
   Miao, Haichao
TI Vivern-A Virtual Environment for Multiscale Visualization and Modeling
   of DNA Nanostructures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE DNA; Nanostructures; Data visualization; Solid modeling; Lattices;
   Three-dimensional displays; Nanoscale devices; Virtual reality;
   abstraction; DNA origami; nanostructures; visualization; focus plus
   context; interaction; in silico modeling; nanotechnology; multiscale;
   magic scale lens
ID REALITY; PLATFORM; SHAPES
AB DNA nanostructures offer promising applications, particularly in the biomedical domain, as they can be used for targeted drug delivery, construction of nanorobots, or as a basis for molecular motors. One of the most prominent techniques for assembling these structures is DNA origami. Nowadays, desktop applications are used for the in silico design of such structures. However, as such structures are often spatially complex, their assembly and analysis are complicated. Since virtual reality (VR) was proven to be advantageous for such spatial-related tasks and there are no existing VR solutions focused on this domain, we propose Vivern, a VR application that allows domain experts to design and visually examine DNA origami nanostructures. Our approach presents different abstracted visual representations of the nanostructures, various color schemes, and an ability to place several DNA nanostructures and proteins in one environment, thus allowing for the detailed analysis of complex assemblies. We also present two novel examination tools, the Magic Scale Lens and the DNA Untwister, that allow the experts to visually embed different representations into local regions to preserve the context and support detailed investigation. To showcase the capabilities of our solution, prototypes of novel nanodevices conceptualized by our collaborating experts, such as DNA-protein hybrid structures and DNA origami superstructures, are presented. Finally, the results of two rounds of evaluations are summarized. They demonstrate the advantages of our solution, especially for scenarios where current desktop tools are very limited, while also presenting possible future research directions.
C1 [Kutak, David; Byska, Jan; Kozlikova, Barbora] Masaryk Univ, Brno 60177, Czech Republic.
   [Kutak, David; Barisic, Ivan; Miao, Haichao] AIT Austrian Inst Technol, A-2444 Vienna, Austria.
   [Nicolas Selzer, Matias; Lujan Ganuza, Maria] VyGlab Res Lab, RA-8000 Bahia Blanca, Buenos Aires, Argentina.
   [Nicolas Selzer, Matias; Lujan Ganuza, Maria] Inst Comp Sci & Engn CONICET UNS, RA-8000 Bahia Blanca, Buenos Aires, Argentina.
   [Nicolas Selzer, Matias] Comis Invest Cient CIC, RA-8000 Bahia Blanca, Buenos Aires, Argentina.
   [Miao, Haichao] TU Wien, A-1040 Vienna, Austria.
C3 Masaryk University Brno; Austrian Institute of Technology (AIT);
   Comision de Investigaciones Cientificas; Technische Universitat Wien
RP Kuták, D (corresponding author), Masaryk Univ, Brno 60177, Czech Republic.; Kuták, D (corresponding author), AIT Austrian Inst Technol, A-2444 Vienna, Austria.
EM kutak@mail.muni.cz; matias.selzer@cs.uns.edu.ar; byska@mail.muni.cz;
   mlg@cs.uns.edu.ar; ivan.barisic@ait.ac.at; kozlikova@mail.muni.cz;
   haichao.miao.fl@ait.ac.at
RI Selzer, Matias/GLS-3152-2022; Miao, Haichao/HNJ-6239-2023; Kozlikova,
   Barbora/G-3890-2014
OI Kutak, David/0000-0002-4346-6850; Byska, Jan/0000-0001-9483-7562;
   Ganuza, Maria Lujan/0000-0003-4576-2124; Barisic,
   Ivan/0000-0002-1301-6197; Selzer, Matias Nicolas/0000-0002-6305-0668
FU Ministry of Education, Youth and Sports of the Czech Republic under the
   INTER-COST research project [LTC20033]; ILLVISATION grant by WWTF
   [VRG11-010]; King Abdullah University of Science and Technology (KAUST)
   Office of Sponsored Research (OSR) [OSR-2019-CPF-4108]; European Union
   [952110]
FX The presented work has been supported by the Ministry of Education,
   Youth and Sports of the Czech Republic under the INTER-COST research
   project no. LTC20033. This work was also supported by ILLVISATION grant
   by WWTF (VRG11-010) and by the King Abdullah University of Science and
   Technology (KAUST) Office of Sponsored Research (OSR) under Award No.
   OSR-2019-CPF-4108. This project has received funding from the European
   Union's Horizon 2020 research and innovation program under Grant 952110
   (MARILIA). They alsowould like to thank Vojtech Jurik for his help with
   the formal parts of the case study and user study. They would also like
   to thank all experts involved during the user study for their time and
   valuable feedback.
CR Ahmadi Y, 2020, SMALL, V16, DOI 10.1002/smll.202001855
   [Anonymous], NATURAL COMPUT
   Balo AR, 2017, NAT METHODS, V14, P1122, DOI 10.1038/nmeth.4506
   Benson E., 2017, VHELIX FREE FORM DNA
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Bier E. A., 1993, Computer Graphics Proceedings, P73, DOI 10.1145/166117.166126
   Britton L. A., 2012, THESIS STATE U NEW J
   Clarafi, 2020, MOL MAY
   Darty K, 2009, BIOINFORMATICS, V25, P1974, DOI 10.1093/bioinformatics/btp250
   de Llano E, 2020, NUCLEIC ACIDS RES, V48, P8269, DOI 10.1093/nar/gkaa593
   DeRijk P, 1997, NUCLEIC ACIDS RES, V25, P4679, DOI 10.1093/nar/25.22.4679
   Dhinakaran K., 2017, THESIS AALTO U ESPOO
   Douglas SM, 2012, SCIENCE, V335, P831, DOI 10.1126/science.1214081
   Douglas SM, 2009, NUCLEIC ACIDS RES, V37, P5001, DOI 10.1093/nar/gkp436
   Driscoll T., DRUMS COLOR SCHEMES
   Everts MH, 2015, IEEE T VIS COMPUT GR, V21, P808, DOI 10.1109/TVCG.2015.2403323
   Facebook Technologies LLC, 2020, OC SDK
   Fitzmaurice G. W., 1996, THESIS U TORONTO TOR
   Fuhrmann A, 1998, VISUALIZATION '98, PROCEEDINGS, P305, DOI 10.1109/VISUAL.1998.745317
   García-Hernández RJ, 2019, COMPUT PHYS COMMUN, V237, P230, DOI 10.1016/j.cpc.2018.11.013
   Gardner A, 2018, IEEE COMPUT GRAPH, V38, P51, DOI 10.1109/MCG.2018.2877076
   Gobe S.J., 1993, QUAL HEALTH RES, V3, P430, DOI DOI 10.1177/104973239300300403
   Google, 2020, BLOCKS
   Grebner C, 2016, FUTURE MED CHEM, V8, DOI 10.4155/fmc-2016-0081
   Halladjian S, 2020, IEEE T VIS COMPUT GR, V26, P654, DOI 10.1109/TVCG.2019.2934334
   Hecker N, 2013, BIOINFORMATICS, V29, P2941, DOI 10.1093/bioinformatics/btt496
   Herisson J., 2004, Proceedings of the 3rd international conference on Computer graphics, virtual reality, visualisation and interaction in Africa, AFRIGRAPH '04, P35
   Herisson J., 2005, Data Science Journal, V4, P82, DOI [10.2481/dsj.4.82, DOI 10.2481/DSJ.4.82]
   Hornus S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0053609
   HTC Corporation and VALVE Corporation, 2020, VIV
   Kekic T, 2020, bioRxiv, DOI [10.1101/804518, 10.1101/804518, DOI 10.1101/804518]
   Kingsley LJ, 2019, J MOL GRAPH MODEL, V89, P234, DOI 10.1016/j.jmgm.2019.03.010
   Klein T, 2019, COMPUT GRAPH FORUM, V38, P57, DOI 10.1111/cgf.13816
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Li DD, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28542-3
   Lindow N, 2019, IEEE T VIS COMPUT GR, V25, P967, DOI 10.1109/TVCG.2018.2864507
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   Mela I, 2020, ANGEW CHEM INT EDIT, V59, P12698, DOI 10.1002/anie.202002740
   Mendes D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P261, DOI 10.1145/2993369.2993396
   Miao H, 2018, COMPUT GRAPH FORUM, V37, P403, DOI 10.1111/cgf.13429
   Miao HC, 2019, J MOL BIOL, V431, P1049, DOI 10.1016/j.jmb.2018.09.004
   Miao HC, 2018, IEEE T VIS COMPUT GR, V24, P1014, DOI 10.1109/TVCG.2017.2743981
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Mota RCR, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P21, DOI 10.1109/SciVis.2018.8823618
   Norrby M, 2015, J CHEM INF MODEL, V55, P2475, DOI 10.1021/acs.jcim.5b00544
   O'Connor MB, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5092590
   Oculus V.R., 2015, Oculus Rift
   PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444
   Ratamero EM, 2018, J COMPUT AID MOL DES, V32, P703, DOI 10.1007/s10822-018-0123-0
   Rocha A, 2019, IEEE T VIS COMPUT GR, V25, P2568, DOI 10.1109/TVCG.2018.2850781
   Rothemund PWK, 2006, NATURE, V440, P297, DOI 10.1038/nature04586
   SciVis Group, 2020, BIOBLENDER
   SHAPIRO BA, 1982, NUCLEIC ACIDS RES, V10, P7041, DOI 10.1093/nar/10.21.7041
   SHAPIRO BA, 1984, NUCLEIC ACIDS RES, V12, P75, DOI 10.1093/nar/12.1Part1.75
   Sulc P, 2012, J CHEM PHYS, V137, DOI 10.1063/1.4754132
   Thubagere AJ, 2017, SCIENCE, V357, DOI 10.1126/science.aan6558
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Unity Technologies, 2020, UN ENG
   Valve, 2020, OPENVR SDK
   Veit M., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, VRST'09, (New York, NY, USA), P51, DOI [10.1145/1643928.1643942, DOI 10.1145/1643928.1643942]
   Viega John, 1996, P 9 ANN ACM S USER I, P51, DOI DOI 10.1145/237091.237098
   Waldispühl J, 2018, METHODS, V142, P74, DOI 10.1016/j.ymeth.2018.05.008
   Wang XY, 2019, COMPUT GRAPH FORUM, V38, P635, DOI 10.1111/cgf.13716
   Werkhoven PJ, 1998, HUM FACTORS, V40, P432, DOI 10.1518/001872098779591322
   Zhang E., 2019, bioRxiv, DOI [10.1101/855379, 10.1101/855379, DOI 10.1101/855379]
   Zhang JF, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2666-z
NR 68
TC 8
Z9 8
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4825
EP 4838
DI 10.1109/TVCG.2021.3106328
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400062
PM 34437064
OA hybrid
DA 2024-11-06
ER

PT J
AU Zhao, Y
   Shi, JC
   Liu, JW
   Zhao, J
   Zhou, FF
   Zhang, WZ
   Chen, KY
   Zhao, X
   Zhu, CY
   Chen, W
AF Zhao, Ying
   Shi, Jingcheng
   Liu, Jiawei
   Zhao, Jian
   Zhou, Fangfang
   Zhang, Wenzhi
   Chen, Kangyi
   Zhao, Xin
   Zhu, Chunyao
   Chen, Wei
TI Evaluating Effects of Background Stories on Graph Perception
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Visual perception; Layout; Shape; Psychology; Bridges;
   Semantics; Graph visualization; node-link diagram; storytelling;
   evaluation
ID LARGE-SCALE GRAPHS; INFORMATION VISUALIZATION; KNOWLEDGE; LAYOUT;
   MEMORABILITY; CONTEXT
AB A graph is an abstract model that represents relations among entities, for example, the interactions between characters in a novel. A background story endows entities and relations with real-world meanings and describes the semantics and context of the abstract model, for example, the actual story that the novel presents. Considering practical experience and prior research, human viewers who are familiar with the background story of a graph and those who do not know the background story may perceive the same graph differently. However, no previous research has adequately addressed this problem. This research article thus presents an evaluation that investigated the effects of background stories on graph perception. Three hypotheses that focused on the role of visual focus areas, graph structure identification, and mental model formation on graph perception were formulated and guided three controlled experiments that evaluated the hypotheses using real-world graphs with background stories. An analysis of the resulting experimental data, which compared the performance of participants who read and did not read the background stories, obtained a set of instructive findings. First, having knowledge about a graph's background story influences participants' focus areas during interactive graph explorations. Second, such knowledge significantly affects one's ability to identify community structures but not high degree and bridge structures. Third, this knowledge influences graph recognition under blurred visual conditions. These findings can bring new considerations to the design of storytelling visualizations and interactive graph explorations.
C1 [Zhao, Ying; Shi, Jingcheng; Liu, Jiawei; Zhou, Fangfang; Zhang, Wenzhi; Chen, Kangyi; Zhao, Xin; Zhu, Chunyao] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
   [Zhao, Jian] Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Peoples R China.
C3 Central South University; University of Waterloo; Zhejiang University
RP Zhou, FF (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM zhaoying@csu.edu.cn; 429433693@qq.com; 870656034@qq.com;
   jianzhao@uwaterloo.ca; zff@csu.edu.cn; 1093894600@qq.com;
   2500150552@qq.com; 1064253658@qq.com; 240427611@qq.com;
   chenwei@cad.zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Zhao, Liangyu/IAO-7294-2023; Liu,
   Jiawei/CAJ-1777-2022; Zhang, Wenzhi/S-3658-2018
OI Chen, Kangyi/0000-0003-3795-5444; Chen, Wei/0000-0002-8365-4741
FU National Key Research and Development Program of China [2018YFB1700403];
   National Natural Science Foundation of China [61872388, 62072470];
   National Natural Science Foundation of Hunan Province [2020JJ4758]
FX The authors would like to thank all the reviewers for fruitful
   suggestions. They wish to thank Yang You from Graph Visualization Lab in
   Mininglamp Technology Group. This work was supported in part by the
   National Key Research and Development Program of China under Grant
   2018YFB1700403, in part by the National Natural Science Foundation of
   China under Grants 61872388 and 62072470, and in part by the National
   Natural Science Foundation of Hunan Province under Grant 2020JJ4758.
CR [Anonymous], GROUND TRUTH
   [Anonymous], 2018, PROC FMT
   [Anonymous], 2006, P INT S GRAPH DRAW
   [Anonymous], DYNAMIC HEATMAPS WEB
   [Anonymous], 2006, P AS PAC S INF VIS
   [Anonymous], SYNERGY EFFECT
   Archambault Daniel, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P475, DOI 10.1007/978-3-642-36763-2_42
   Archambault D, 2007, IEEE T VIS COMPUT GR, V13, P305, DOI 10.1109/TVCG.2007.46
   Archambault D, 2012, IEEE PAC VIS SYMP, P89, DOI 10.1109/PacificVis.2012.6183578
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Auber D., TULIP 5
   Batagelj V., UCINET 4 DATASETS
   Batagelj V., Pajek datasets
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Beck F, 2014, STATE ART VISUALIZIN
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Bennett C., 2007, P EUR C COMP AESTH G, P57, DOI [10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Beveridge A., 2016, MATH HORIZONS, V23, P18, DOI [DOI 10.4169/MATHHORIZONS.23.4.18, 10.4169/mathhorizons.23.4.18]
   Blascheck T, 2017, COMPUT GRAPH FORUM, V36, P260, DOI 10.1111/cgf.13079
   Bollob B, 1998, GRADUATE TEXTS MATH
   Borgo R, 2018, COMPUT GRAPH FORUM, V37, P573, DOI 10.1111/cgf.13444
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Braly KW, 1933, J EXP PSYCHOL, V16, P613, DOI 10.1037/h0069843
   Charness G, 2012, J ECON BEHAV ORGAN, V81, P1, DOI 10.1016/j.jebo.2011.08.009
   Chimani M., 2013, Handbook of Graph Drawing and Visualization, P543, DOI [10.1201/b153854, DOI 10.1201/B153854]
   Cui Weiwei., 2007, SURVEY GRAPH VISUALI
   De Cesarei A, 2008, EMOTION, V8, P352, DOI 10.1037/1528-3542.8.3.352
   Dimara E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5475, DOI 10.1145/3025453.3025870
   Dunne C, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2411412
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   Eidels A, 2008, J EXP PSYCHOL HUMAN, V34, P1441, DOI 10.1037/a0012320
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Fine GaryAlan., 1987, With the Boys: Little League Baseball and Preadolescent Culture
   Furnham A., 2011, The journal of socioeconomics, V40, P35, DOI DOI 10.1016/J.SOCEC.2010.10.008
   Gansner ER, 2011, IEEE PAC VIS SYMP, P187, DOI 10.1109/PACIFICVIS.2011.5742389
   Gedraite ES, 2011, ELMAR PROC, P393
   Ghani S, 2012, COMPUT GRAPH FORUM, V31, P1205, DOI 10.1111/j.1467-8659.2012.03113.x
   Ghani S, 2013, IEEE T VIS COMPUT GR, V19, P2032, DOI 10.1109/TVCG.2013.223
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gorochowski TE, 2012, IEEE T VIS COMPUT GR, V18, P1343, DOI 10.1109/TVCG.2011.142
   Greadability.js, GREADABILITY JS
   Hadlak S., 2015, EUROGRAPHICS C VISUA, P1, DOI [DOI 10.2312/EUROVISSTAR.20151109, 10.2312/eurovisstar.20151109]
   Hagberg A., 2008, P 7 PYTH SCI C
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Huang WD, 2016, IEEE PAC VIS SYMP, P199, DOI 10.1109/PACIFICVIS.2016.7465270
   Humphrey K, 2009, BRIT J PSYCHOL, V100, P377, DOI 10.1348/000712608X344780
   Jahnke Marko, 2007, 2007 32nd IEEE Conference on Local Computer Networks, P1035, DOI 10.1109/LCN.2007.45
   Jia YT, 2008, IEEE T VIS COMPUT GR, V14, P1285, DOI 10.1109/TVCG.2008.151
   Kasyanov VN, 2013, ENTERP INF SYST-UK, V7, P187, DOI 10.1080/17517575.2012.743188
   Kim NW, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3131275
   Kim SH, 2012, IEEE T VIS COMPUT GR, V18, P2421, DOI 10.1109/TVCG.2012.215
   Lupyan G, 2017, J EXP PSYCHOL HUMAN, V43, P794, DOI 10.1037/xhp0000343
   Ma KL, 2013, COMPUTER, V46, P39, DOI 10.1109/MC.2013.242
   Magoni D, 2001, ACM SIGCOMM COMP COM, V31, P26, DOI 10.1145/505659.505663
   Maier M, 2014, BRAIN COGNITION, V91, P1, DOI 10.1016/j.bandc.2014.07.008
   Marriott K, 2012, IEEE T VIS COMPUT GR, V18, P2477, DOI 10.1109/TVCG.2012.245
   McDonald S., 2001, THESIS U LETHBRIDGE
   McGrath C, 1997, SOC NETWORKS, V19, P223, DOI 10.1016/S0378-8733(96)00299-7
   Muthumanickam PK, 2019, IEEE T VIS COMPUT GR, V25, P87, DOI 10.1109/TVCG.2018.2865042
   Norman DA, 2004, EMOTIONAL DESIGN WHY
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Rahman RA, 2008, PSYCHON B REV, V15, P1055, DOI 10.3758/PBR.15.6.1055
   Ruppert T, 2015, PUB ADMIN INF TECH, V10, P321, DOI 10.1007/978-3-319-12784-2_15
   Saha Tanwistha, 2011, Machine Learning and Data Mining in Pattern Recognition. Proceedings 7th International Conference, MLDM 2011, P584, DOI 10.1007/978-3-642-23199-5_43
   Scott MacKenzie I., 2013, Human-Computer Interaction: An Empirical Research Perspective, V1st
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Soni U, 2018, COMPUT GRAPH FORUM, V37, P169, DOI 10.1111/cgf.13410
   Suarez-Alvarez MM, 2012, P ROY SOC A-MATH PHY, V468, P2630, DOI 10.1098/rspa.2011.0704
   Suderman M, 2007, BIOINFORMATICS, V23, P2651, DOI 10.1093/bioinformatics/btm401
   Tarawaneh R.M., 2012, VISUALIZATION LARGE, V27, P151
   Taylor M, 2005, Ninth International Conference on Information Visualisation, Proceedings, P651, DOI 10.1109/IV.2005.19
   Telea A, 2010, COMPUT GRAPH FORUM, V29, P843, DOI 10.1111/j.1467-8659.2009.01680.x
   Todorovic D., 2008, SCHOLARPEDIA, V3, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   van Ham F, 2008, IEEE T VIS COMPUT GR, V14, P1333, DOI 10.1109/TVCG.2008.155
   Vuong QC, 2004, VISION RES, V44, P1717, DOI 10.1016/j.visres.2004.02.002
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P566, DOI 10.1109/TVCG.2018.2864911
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Ware C., 2005, Information Visualization, V4, P49, DOI 10.1057/palgrave.ivs.9500090
   WASSERTHEIL S, 1970, BIOMETRICS, V26, P588, DOI 10.2307/2529115
   Westheimer G, 2013, J VISION, V13, DOI 10.1167/13.5.13
   Willey S., 1984, Marilyn Zurmuehlen Working Papers in Art Education, V3, P2
   Wirth M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00653
   Woolley G., 2014, LITERACY ARTS, P215, DOI [10.1007/978-3-319-04846-8_13, DOI 10.1007/978-3-319-04846-8_13]
   Wu YH, 2017, IEEE T VIS COMPUT GR, V23, P401, DOI 10.1109/TVCG.2016.2598867
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhao Y, 2018, IEEE ACCESS, V6, P53006, DOI 10.1109/ACCESS.2018.2870684
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 94
TC 36
Z9 37
U1 3
U2 59
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4839
EP 4854
DI 10.1109/TVCG.2021.3107297
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400063
PM 34437066
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Crisan, A
   Fisher, SE
   Gardy, JL
   Munzner, T
AF Crisan, Anamaria
   Fisher, Shannah E.
   Gardy, Jennifer L.
   Munzner, Tamara
TI GEViTRec: Data Reconnaissance Through Recommendation Using a
   Domain-Specific Visualization Prevalence Design Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Encoding; Bioinformatics; Genomics;
   Image color analysis; Epidemiology; Heterogeneous data; multiple
   coordinated views; data reconnaissance; bioinformatics
ID VISUAL ANALYSIS; EXPLORATION; LAYOUTS; VIEWS; EYES
AB Genomic Epidemiology (genEpi) is a branch of public health that uses many different data types including tabular, network, genomic, and geographic, to identify and contain outbreaks of deadly diseases. Due to the volume and variety of data, it is challenging for genEpi domain experts to conduct data reconnaissance; that is, have an overview of the data they have and make assessments toward its quality, completeness, and suitability. We present an algorithm for data reconnaissance through automatic visualization recommendation, GEViTRec. Our approach handles a broad variety of dataset types and automatically generates visually coherent combinations of charts, in contrast to existing systems that primarily focus on singleton visual encodings of tabular datasets. We automatically detect linkages across multiple input datasets by analyzing non-numeric attribute fields, creating a data source graph within which we analyze and rank paths. For each high-ranking path, we specify chart combinations with positional and color alignments between shared fields, using a gradual binding approach to transform initial partial specifications of singleton charts to complete specifications that are aligned and oriented consistently. A novel aspect of our approach is its combination of domain-agnostic elements with domain-specific information that is captured through a domain-specific visualization prevalence design space. Our implementation is applied to both synthetic data and real Ebola outbreak data. We compare GEViTRec's output to what previous visualization recommendation systems would generate, and to manually crafted visualizations used by practitioners. We conducted formative evaluations with ten genEpi experts to assess the relevance and interpretability of our results. Code, Data, and Study Materials Availability: https://github.com/amcrisan/GEVitRec.
C1 [Crisan, Anamaria] Tableau Res, Seattle, WA 98103 USA.
   [Fisher, Shannah E.; Munzner, Tamara] Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.
   [Gardy, Jennifer L.] Gates Fdn, Seattle, WA 98109 USA.
C3 University of British Columbia; Bill & Melinda Gates Foundation
RP Munzner, T (corresponding author), Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.
EM acrisan@tableau.com; shannahelizabeth@gmail.com;
   jennifer.gardy@gatesfoundation.org; tmm@cs.ubc.ca
RI Munzner, Tamara/HKP-2536-2023
OI Munzner, Tamara/0000-0002-3294-3869
FU CIHR Vanier Scholarship; NSERC [RGPIN-2014-06309]
FX The authors would like to thank Madison Elliott, Steve Kasica, Zipeng
   Liu, Michael Oppermann, and Ben Shneiderman for their thoughtful
   comments and feedback. The authors would also like to thank study
   participants for their time and insights. This work was funded by a CIHR
   Vanier Scholarship and NSERC Discovery RGPIN-2014-06309.
CR Alsallakh B., 2014, PROC EUROGRAPH C VIS, DOI [10.2312/eurovisstar.20141170.001-021, DOI 10.2312/EUROVISSTAR.20141170.001-021]
   Angelelli P, 2014, IEEE COMPUT GRAPH, V34, P70, DOI 10.1109/MCG.2014.40
   Argimón S, 2016, MICROB GENOMICS, V2, DOI 10.1099/mgen.0.000093
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Boy J, 2016, IEEE T VIS COMPUT GR, V22, P639, DOI 10.1109/TVCG.2015.2467201
   Cammarano M, 2007, IEEE T VIS COMPUT GR, V13, P1200, DOI 10.1109/TVCG.2007.70617
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Crisan A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P46, DOI [10.1109/visual.2019.8933542, 10.1109/VISUAL.2019.8933542]
   Crisan A, 2019, BIOINFORMATICS, V35, P1668, DOI 10.1093/bioinformatics/bty832
   Crisan A, 2018, PEERJ, V6, DOI 10.7717/peerj.4218
   Crisan A, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P1, DOI 10.1145/2993901.2993911
   Cruz A, 2019, BRIEF BIOINFORM, V20, P1513, DOI 10.1093/bib/bby019
   Demiralp C, 2017, PROC IEEE WORKSHOP D
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dudas G., baltic
   Dudas G, 2017, NATURE, V544, P309, DOI 10.1038/nature22040
   Gardy JL, 2018, NAT REV GENET, V19, P9, DOI 10.1038/nrg.2017.88
   Gilson O, 2008, COMPUT GRAPH FORUM, V27, P959, DOI 10.1111/j.1467-8659.2008.01230.x
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gratzl S, 2014, IEEE T VIS COMPUT GR, V20, P2023, DOI 10.1109/TVCG.2014.2346260
   Hadfield J, 2018, BIOINFORMATICS, V34, P4121, DOI 10.1093/bioinformatics/bty407
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hey T., 2009, The Fourth Paradigm: Data-Intensive Scientific Discovery
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Huerta-Cepas J, 2016, MOL BIOL EVOL, V33, P1635, DOI 10.1093/molbev/msw046
   Kairam S, 2015, COMPUT GRAPH FORUM, V34, P301, DOI 10.1111/cgf.12642
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Key A., 2012, ACM, P681
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   Lam H, 2008, IEEE T VIS COMPUT GR, V14, P1149, DOI 10.1109/TVCG.2008.109
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   McNutt Andrew M, 2021, Integrated Visualization Editing via Parameterized Declarative Templates
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Morton K, 2014, SIGMOD REC, V43, P17
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Mutlu B, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2983923
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P1543, DOI 10.1109/TVCG.2018.2811488
   Paradis E, 2019, BIOINFORMATICS, V35, P526, DOI 10.1093/bioinformatics/bty633
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Seo J, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P65
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Slingsby A, 2009, IEEE T VIS COMPUT GR, V15, P977, DOI 10.1109/TVCG.2009.128
   van Wijk JJ, 2006, IEEE T VIS COMPUT GR, V12, P421, DOI 10.1109/TVCG.2006.80
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Wickham H, 2016, ggplot2: elegant graphics for data analysis
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xie CL, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018769775
   Yu GC, 2017, METHODS ECOL EVOL, V8, P28, DOI 10.1111/2041-210X.12628
NR 63
TC 5
Z9 9
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4855
EP 4872
DI 10.1109/TVCG.2021.3107749
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400064
PM 34449391
OA hybrid
DA 2024-11-06
ER

PT J
AU Liu, JY
   Hui, BY
   Li, K
   Liu, YK
   Lai, YK
   Zhang, YX
   Liu, YB
   Yang, JY
AF Liu, Jingying
   Hui, Binyuan
   Li, Kun
   Liu, Yunke
   Lai, Yu-Kun
   Zhang, Yuxiang
   Liu, Yebin
   Yang, Jingyu
TI Geometry-Guided Dense Perspective Network for Speech-Driven Facial
   Animation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Facial animation; Solid modeling; Faces;
   Geometry; Correlation; Decoding; Speech-driven; 3D facial animation;
   geometry-guided; speaker-independent
AB Realistic speech-driven 3D facial animation is a challenging problem due to the complex relationship between speech and face. In this paper, we propose a deep architecture, called Geometry-guided Dense Perspective Network (GDPnet), to achieve speaker-independent realistic 3D facial animation. The encoder is designed with dense connections to strengthen feature propagation and encourage the re-use of audio features, and the decoder is integrated with an attention mechanism to adaptively recalibrate point-wise feature responses by explicitly modeling interdependencies between different neuron units. We also introduce a non-linear face reconstruction representation as a guidance of latent space to obtain more accurate deformation, which helps solve the geometry-related deformation and is good for generalization across subjects. Huber and HSIC (Hilbert-Schmidt Independence Criterion) constraints are adopted to promote the robustness of our model and to better exploit the non-linear and high-order correlations. Experimental results on the public dataset and real scanned dataset validate the superiority of our proposed GDPnet compared with state-of-the-art model. The code is available for research purposes at http://cic.tju.edu.cn/faculty/likun/projects/GDPnet.
C1 [Liu, Jingying; Hui, Binyuan; Li, Kun; Liu, Yunke] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
   [Zhang, Yuxiang; Liu, Yebin] Tsinghua Univ, Dept Automat, Beijing 10084, Peoples R China.
   [Yang, Jingyu] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University; Cardiff University; Tsinghua University; Tianjin
   University
RP Li, K (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM 981132775@qq.com; 787782917@qq.com; huybery@gmail.com; lik@tju.edu.cn;
   Yukunlai@cs.cardiff.ac.uk; yx-z19@mails.tsinghua.edu.cn;
   liuyebin@mail.tsinghua.edu.cn; yjy@tju.edu.cn
RI Yan, Miaochen/JLL-5061-2023; YANG, JINGYU (Gracy)/AAD-3341-2021; Lai,
   Yu-Kun/D-2343-2010; Li, Yan/JRW-0176-2023; Li, Kun/EPZ-3203-2022
OI Lai, Yukun/0000-0002-2094-5680
FU National Natural Science Foundation of China [62171317, 62122058,
   61771339]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62171317, 62122058, and 61771339. The authors would
   like to thank the Associate Editor and anonymous reviews for their help
   in improving this paper. Jingying Liu and Binyuan Hui are equal
   contribution to this work.
CR Abadi M., 2015, Tensorflow: Large-scale machine learning on heterogeneous distributed systems, DOI DOI 10.48550/ARXIV.1603.04467
   [Anonymous], 1986, Proc. DARPA Workshop on speech recognition
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Ding C, 2015, MULTIMED TOOLS APPL, V74, P9871, DOI 10.1007/s11042-014-2156-2
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163
   Glorot X., 2011, JMLR WORKSHOP C P, P315, DOI DOI 10.1002/ECS2.1832
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Hannun A, 2014, Arxiv, DOI arXiv:1412.5567
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong PY, 2002, IEEE T NEURAL NETWOR, V13, P916, DOI 10.1109/TNN.2002.1021892
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   Kakumanu P., 2001, PROC WORKSHOP PERCEP, P1
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kingma DP, 2014, ADV NEUR IN, V27
   Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815
   Li K, 2019, COMPUT GRAPH FORUM, V38, P215, DOI 10.1111/cgf.13830
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liu YL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818122
   Ma WDK, 2020, AAAI CONF ARTIF INTE, V34, P5085
   Pei Y, 2007, IEEE T VIS COMPUT GR, V13, P58, DOI 10.1109/TVCG.2007.22
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Rey D., 2011, Wilcoxon-signed-rank test. International encyclopedia of statistical science, P1658, DOI [DOI 10.1007/978-3-642-04898-2616, 10.1007/978-3-642-04898-2616]
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor S. L., 2012, P 11 ACM SIGGRAPHEUR, P275, DOI DOI 10.2312/SCA/SCA12/275-284
   Taylor S, 2016, INTERSPEECH, P1482, DOI 10.21437/Interspeech.2016-483
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Xu C, 2019, AAAI CONF ARTIF INTE, P5525
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
NR 43
TC 8
Z9 9
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4873
EP 4886
DI 10.1109/TVCG.2021.3107669
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400065
PM 34449390
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Meng, WL
   Xin, SQ
   Tu, CH
   Chen, SM
   He, Y
   Wang, WP
AF Meng, Wenlong
   Xin, Shiqing
   Tu, Changhe
   Chen, Shuangmin
   He, Ying
   Wang, Wenping
TI Geodesic Tracks: Computing Discrete Geodesics With Track-Based Steiner
   Point Propagation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Discrete geodesics; shortest paths; geodesic tracks; Steiner points;
   ridge points
ID APPROXIMATING SHORTEST PATHS
AB This article presents a simple yet effective method for computing geodesic distances on triangle meshes. Unlike the popular window propagation methods that partition mesh edges into intervals of varying lengths, our method places evenly-spaced, source-independent Steiner points on edges. Given a source vertex, our method constructs a Steiner-point graph that partitions the surface into mutually exclusive tracks, called geodesic tracks. Inside each triangle, the tracks form sub-regions in which the change of distance field is approximately linear. Our method does not require any pre-computation, and can effectively balance speed and accuracy. Experimental results show that with 5 Steiner points on each edge, the mean relative error is less than 0.3% for common 3D models used in the graphics community. We propose a set of effective filtering rules to eliminate a large amount of useless broadcast events. For a 1000K-face model, our method runs 10 times faster than the conventional Steiner point method that examines a complete graph of Steiner points in each triangle. We also observe that using more Steiner points increases the accuracy at only a small extra computational cost. Our method works well for meshes with poor triangulation and non-manifold configuration, which often poses challenges to the existing PDE methods. We show that geodesic tracks, as a new data structure that encodes rich information of discrete geodesics, support accurate geodesic path and isoline tracing, and efficient distance query. Our method can be easily extended to meshes with non-constant density functions and/or anisotropic metrics.
C1 [Meng, Wenlong; Xin, Shiqing; Tu, Changhe] Shandong Univ, Sch Comp Sci & Technol, Jinan 250355, Shandong, Peoples R China.
   [Chen, Shuangmin] Qingdao Univ Sci & Technol, Sch Informat & Technol, Qingdao 266061, Shandong, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Wang, Wenping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Shandong University; Qingdao University of Science & Technology; Nanyang
   Technological University; University of Hong Kong
RP Xin, SQ; Tu, CH (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250355, Shandong, Peoples R China.
EM longwuya@163.com; xinshiqing@163.com; chtu@sdu.edu.cn; csmqq@163.com;
   yhe@ntu.edu.sg; wenping@cs.hku.hk
RI He, Ying/A-3708-2011; Tu, Changhe/H-5162-2013
OI He, Ying/0000-0002-6749-4485; Chen, Shuangmin/0000-0002-0835-3316
FU National Natural Science Foundation of China [61772016, 62002190,
   61772318, 62072284]; NSF of Shandong Province, China [ZR2020MF036]; Key
   Research Development program of Shandong Province [2019GGX101021]; Key
   Program of Shandong Natural Science Foundation [2020ZLYS01]; Singapore
   Ministry of Education [RG20/20, T2EP20220-0014]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions. This work was supported in part by
   the National Natural Science Foundation of China under Grants 61772016,
   62002190, 61772318, and 62072284, in part by the NSF of Shandong
   Province, China, under Grant ZR2020MF036, the Key Research Development
   program of Shandong Province under Grant 2019GGX101021, in part by the
   Key Program of Shandong Natural Science Foundation under Grant
   2020ZLYS01, and in part by the Singapore Ministry of Education under
   Grants RG20/20 and T2EP20220-0014.
CR Adikusuma YY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3144567
   Aiello R, 2015, LECT NOTES COMPUT SC, V9279, P282, DOI 10.1007/978-3-319-23231-7_26
   Aleksandov L., 2000, Proceedings of the Thirty Second Annual ACM Symposium on Theory of Computing, P286, DOI 10.1145/335305.335339
   Aleksandrov L, 2005, J ACM, V52, P25, DOI 10.1145/1044731.1044733
   Aleksandrov L, 1998, LECT NOTES COMPUT SC, V1432, P11, DOI 10.1007/BFb0054351
   Bommes D., 2007, Proceedings of the Vision, Modeling, and Visualization Conference 2007, VMV 2007, Saarbrcken, Germany, November 7-9, 2007, P151
   Bose P, 2011, COMP GEOM-THEOR APPL, V44, P486, DOI 10.1016/j.comgeo.2011.05.006
   Campen M, 2013, COMPUT GRAPH FORUM, V32, P63, DOI 10.1111/cgf.12173
   Cao LM, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102879
   CHEN JD, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P360, DOI 10.1145/98524.98601
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Dijkstra E. W., 1959, Numer. Math, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/BF01386390]
   Du J, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102943
   Farias R, 2020, IEEE T VIS COMPUT GR, V26, P2863, DOI 10.1109/TVCG.2019.2904271
   He T, 2019, PROC CVPR IEEE, P6881, DOI 10.1109/CVPR.2019.00705
   Kanai T., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P241, DOI 10.1109/GMAP.2000.838256
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Lanthier M, 2003, PARALLEL COMPUT, V29, P1445, DOI 10.1016/j.parco.2003.05.004
   Lanthier M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P274, DOI 10.1145/262839.262984
   Lanthier M, 2001, ALGORITHMICA, V30, P527, DOI 10.1007/s00453-001-0027-5
   Liu BQ, 2017, COMPUT AIDED DESIGN, V90, P105, DOI 10.1016/j.cad.2017.05.022
   Liu YJ, 2007, VISUAL COMPUT, V23, P661, DOI 10.1007/s00371-007-0136-5
   Liu YJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2999532
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   LO SH, 1985, INT J NUMER METH ENG, V21, P1403, DOI 10.1002/nme.1620210805
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Mata C. S., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P264, DOI 10.1145/262839.262983
   Melvær EL, 2012, COMPUT GRAPH FORUM, V31, P2423, DOI 10.1111/j.1467-8659.2012.03187.x
   MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045
   Nazzaro G, 2020, Arxiv, DOI arXiv:2007.10918
   Peyré G, 2005, PROG NONLINEAR DIFFE, V63, P157
   Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079
   Qin YP, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925930
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   Calla LAR, 2019, COMPUT GRAPH-UK, V84, P77, DOI 10.1016/j.cag.2019.08.014
   Sharir Micha., 1984, STOC 84, P144
   Sharp N., 2019, T GRAPH LATIONS, V38, P1
   Sharp N, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417839
   Sun Z, 2006, J ALGORITHM, V58, P1, DOI 10.1016/j.jalgor.2004.07.004
   Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228
   Tao J, 2021, IEEE T PATTERN ANAL, V43, P579, DOI 10.1109/TPAMI.2019.2933209
   Varadarajan KR, 2000, SIAM J COMPUT, V30, P1321, DOI 10.1137/S0097539799352759
   Wang XN, 2017, COMPUT AIDED GEOM D, V52-53, P262, DOI 10.1016/j.cagd.2017.03.010
   Xin S Q., 2012, Proc. - I3D: ACM SIGGRAPH Symp. Interact. 3D Graph. Games, P31
   Xin SQ, 2007, COMPUT AIDED DESIGN, V39, P1081, DOI 10.1016/j.cad.2007.08.001
   Xin SQ, 2011, COMPUT AIDED DESIGN, V43, P1468, DOI 10.1016/j.cad.2011.08.027
   Xin SQ, 2010, COMPUT AIDED DESIGN, V42, P942, DOI 10.1016/j.cad.2010.05.009
   Xin SQ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559761
   Xin SQ, 2018, COMPUT AIDED DESIGN, V102, P128, DOI 10.1016/j.cad.2018.04.021
   Xu CX, 2015, IEEE T VIS COMPUT GR, V21, P822, DOI 10.1109/TVCG.2015.2407404
   Yan YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925938
   Ye JB, 2016, VISUAL COMPUT, V32, P553, DOI 10.1007/s00371-015-1071-5
   Ye ZP, 2019, COMPUT AIDED DESIGN, V114, P73, DOI 10.1016/j.cad.2019.05.025
   Ying X, 2019, COMPUT AIDED DESIGN, V115, P161, DOI 10.1016/j.cad.2019.05.023
   Ying X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2534161
   Ying X, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508379
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
NR 57
TC 4
Z9 4
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4887
EP 4901
DI 10.1109/TVCG.2021.3109042
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400066
PM 34469303
DA 2024-11-06
ER

PT J
AU Zeng, Q
   Zhao, YW
   Wang, YQ
   Zhang, J
   Cao, Y
   Tu, CH
   Viola, I
   Wang, YH
AF Zeng, Qiong
   Zhao, Yongwei
   Wang, Yinqiao
   Zhang, Jian
   Cao, Yi
   Tu, Changhe
   Viola, Ivan
   Wang, Yunhai
TI Data-Driven Colormap Adjustment for Exploring Spatial Variations in
   Scalar Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Data visualization; Task analysis; Tools;
   Histograms; Extremities; Encoding; Colormapping; scientific
   visualization
ID MAPS
AB Colormapping is an effective and popular visualization technique for analyzing patterns in scalar fields. Scientists usually adjust a default colormap to show hidden patterns by shifting the colors in a trial-and-error process. To improve efficiency, efforts have been made to automate the colormap adjustment process based on data properties (e.g., statistical data value or histogram distribution). However, as the data properties have no direct correlation to the spatial variations, previous methods may be insufficient to reveal the dynamic range of spatial variations hidden in the data. To address the above issues, we conduct a pilot analysis with domain experts and summarize three requirements for the colormap adjustment process. Based on the requirements, we formulate colormap adjustment as an objective function, composed of a boundary term and a fidelity term, which is flexible enough to support interactive functionalities. We compare our approach with alternative methods under a quantitative measure and a qualitative user study (25 participants), based on a set of data with broad distribution diversity. We further evaluate our approach via three case studies with six domain experts. Our method is not necessarily more optimal than alternative methods of revealing patterns, but rather is an additional color adjustment option for exploring data with a dynamic range of spatial variations.
C1 [Zeng, Qiong; Zhao, Yongwei; Wang, Yinqiao; Tu, Changhe; Wang, Yunhai] Shandong Univ, Sch Comp Sci & Technol, Qingdao 250100, Shandong, Peoples R China.
   [Zhang, Jian] Chinese Acad Sci, Comp Network Informat Ctr, Supercomp Ctr, Beijing 100864, Peoples R China.
   [Cao, Yi] Inst Appl Phys & Computat Math, Beijing 100088, Peoples R China.
   [Viola, Ivan] King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
C3 Shandong University; Chinese Academy of Sciences; Computer Network
   Information Center, CAS; Chinese Academy of Sciences; Institute of
   Applied Physics & Computational Mathematics - China; King Abdullah
   University of Science & Technology
RP Zeng, Q; Wang, YH (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao 250100, Shandong, Peoples R China.
EM qiong.zn@sdu.edu.cn; yongwei_zhao@163.com; yinqiaowong@gmail.com;
   zhangjian@sccas.cn; caoywill@hotmail.com; chtu@sdu.edu.cn;
   ivan.viola@kaust.edu.sa; cloudseawang@gmail.com
RI Tu, Changhe/H-5162-2013; Viola, Ivan/O-8944-2014
OI Viola, Ivan/0000-0003-4248-6574; zhao, yongwei/0000-0003-1722-8848;
   Wang, Yinqiao/0000-0002-6099-206X; Cao, Yi/0000-0002-2131-5453; Zhang,
   Jian/0000-0003-1348-8124
FU NSFC [61602273, 61772315, 61861136012, 61772318]; Special Project of
   Science and Technology Innovation Base of Key Laboratory of Shandong
   Province for Software Engineering [11480004042015]; King Abdullah
   University of Science and Technology (KAUST) [BAS/1/1680-01-01]
FX The authors would like to thank Kresimir Matkovic at VRVis Center for
   Virtual Reality and Visualisation GmbH, Vienna, Austria, Renata Raidou
   at TU Wien, Austria, Michael Bottinger at Deutsches Klimarechenzentrum,
   Germany, Thomas Theussl at KAUST, Saudi Arabia, Mingkui Li at Ocean
   University of China, Zhi Zeng at University of South China and Qianqian
   Guo at Shandong University, China, for providing precious visualization
   resources and evaluating the quality of our cases, Christian Tominski at
   University of Rostock for providing valuable discussions and source
   codes, and the anonymous reviewers and the associate editor for precious
   encouragement, suggestions, and comments. This work was supported in
   part by the NSFC under Grants 61602273, 61772315, 61861136012, and
   61772318, in part by the Special Project of Science and Technology
   Innovation Base of Key Laboratory of Shandong Province for Software
   Engineering under Grant 11480004042015, and in part by the funding from
   King Abdullah University of Science and Technology (KAUST) under Grant
   BAS/1/1680-01-01. Part of this research was conducted using resources at
   the Visualization Core Lab at KAUST.
CR Ahrens J., 2005, Vis. Handb., P717, DOI 10.1016/B978-012387582-2/50038-1
   Andrews L.C., 1998, Special Functions of Mathematics for Engineers
   Bergman LD, 1995, VISUALIZATION '95 - PROCEEDINGS, P118, DOI 10.1109/VISUAL.1995.480803
   Bernard J, 2015, PROC SPIE, V9397, DOI 10.1117/12.2079841
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Borland D, 2011, IEEE COMPUT GRAPH, V31, P7, DOI 10.1109/MCG.2011.55
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [DOI 10.1016/B978-0-08-042415-6.50014-4, 10.1016/b978-0-08-042415-6.50014-4]
   Bujack R, 2018, IEEE T VIS COMPUT GR, V24, P923, DOI 10.1109/TVCG.2017.2743978
   Byrd RH, 2006, NONCONVEX OPTIM, V83, P35
   Caban JJ, 2008, IEEE T VIS COMPUT GR, V14, P1364, DOI 10.1109/TVCG.2008.169
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CLEVELAND WS, 1984, AM STAT, V38, P270, DOI 10.2307/2683401
   Correa CD, 2009, IEEE T VIS COMPUT GR, V15, P1465, DOI 10.1109/TVCG.2009.189
   Crameri F, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19160-7
   Dasgupta A, 2020, IEEE T VIS COMPUT GR, V26, P1577, DOI 10.1109/TVCG.2018.2876539
   Eisemann M., 2011, P EUROVA INT WORKSH
   Elmqvist N, 2011, IEEE T VIS COMPUT GR, V17, P795, DOI 10.1109/TVCG.2010.94
   Kindlmann G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P299, DOI 10.1109/VISUAL.2002.1183788
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   Maciejewski R, 2013, IEEE T VIS COMPUT GR, V19, P130, DOI 10.1109/TVCG.2012.64
   Mittal Saurabh., 2015, P C SUMMER COMPUTER, P1
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Nardini P, 2021, IEEE T VIS COMPUT GR, V27, P1043, DOI 10.1109/TVCG.2020.3028955
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Nuñez JR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199239
   Pfister H, 2001, IEEE COMPUT GRAPH, V21, P16, DOI 10.1109/38.920623
   Phillips G.M., 2003, Interpolation and Approximation by Polynomials
   PIZER SM, 1981, COMPUT VISION GRAPH, V17, P262, DOI 10.1016/0146-664X(81)90006-X
   Reda K, 2021, IEEE T VIS COMPUT GR, V27, P1032, DOI 10.1109/TVCG.2020.3030439
   Reda K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173846
   Rogowitz BE, 1998, IEEE SPECTRUM, V35, P52, DOI 10.1109/6.736450
   Rogowitz E. E., 1996, Computers in Physics, V10, P268
   Schulze-Wollgast P., 2005, WSCG'05, P203
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   Sisneros Robert, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P391, DOI 10.1007/978-3-319-50835-1_36
   Thompson David, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P77, DOI 10.1109/LDAV.2013.6675161
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Wald N., 2016, P IEEE INT C SCI EL, P1, DOI DOI 10.1109/ICSEE.2016.7806155
   Waldin N, 2019, COMPUT GRAPH FORUM, V38, P150, DOI 10.1111/cgf.13611
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Ware C, 2019, IEEE T VIS COMPUT GR, V25, P2777, DOI 10.1109/TVCG.2018.2855742
   Zeng Q, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P266, DOI [10.1109/VISUAL.2019.8933764, 10.1109/visual.2019.8933764]
   Zhou L, 2020, IEEE T VIS COMPUT GR, V26, P2156, DOI 10.1109/TVCG.2020.2970522
   Zhou L, 2019, J COMPUT LANG, V55, DOI 10.1016/j.cola.2019.100911
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
   Zhou L, 2019, IEEE INT CONF AUTOMA, P642
NR 50
TC 0
Z9 0
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4902
EP 4917
DI 10.1109/TVCG.2021.3109014
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400067
PM 34469302
DA 2024-11-06
ER

PT J
AU Cakmak, E
   Jäckle, D
   Schreck, T
   Keim, DA
   Fuchs, J
AF Cakmak, Eren
   Jaeckle, Dominik
   Schreck, Tobias
   Keim, Daniel A.
   Fuchs, Johannes
TI Multiscale Visualization: A Structured Literature Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Navigation; Visualization; Taxonomy; Encoding;
   Molecular biology; Libraries; Multiscale visualization; multiscale
   navigation; multiscale exploration; literature analysis; taxonomy;
   survey
ID VISUAL ANALYSIS; TIME-SERIES; EXPLORATION; SCALE; SUMMARIES; DISPLAYS;
   SPACE
AB Multiscale visualizations are typically used to analyze multiscale processes and data in various application domains, such as the visual exploration of hierarchical genome structures in molecular biology. However, creating such multiscale visualizations remains challenging due to the plethora of existing work and the expression ambiguity in visualization research. Up to today, there has been little work to compare and categorize multiscale visualizations to understand their design practices. In this article, we present a structured literature analysis to provide an overview of common design practices in multiscale visualization research. We systematically reviewed and categorized 122 published journal or conference articles between 1995 and 2020. We organized the reviewed articles in a taxonomy that reveals common design factors. Researchers and practitioners can use our taxonomy to explore existing work to create new multiscale navigation and visualization techniques. Based on the reviewed articles, we examine research trends and highlight open research challenges.
C1 [Cakmak, Eren; Keim, Daniel A.; Fuchs, Johannes] Univ Konstanz, Dept Comp & Informat Sci, D-78547 Constance, Germany.
   [Schreck, Tobias] Graz Univ Technol, Inst Comp Graph & Knowledge Visualisat, A-8010 Graz, Austria.
C3 University of Konstanz; Graz University of Technology
RP Cakmak, E (corresponding author), Univ Konstanz, Dept Comp & Informat Sci, D-78547 Constance, Germany.
EM eren.cakmak@uni-konstanz.de; dominikjaeckle@gmail.com;
   tobias.schreck@cgv.tugraz.at; keim@uni-konstanz.de;
   johannes.fuchs@uni-konstanz.de
RI Keim, Daniel/X-7749-2019
OI Schreck, Tobias/0000-0003-0778-8665; Fuchs, Johannes/0000-0001-5474-4214
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under
   Germany's Excellence Strategy [EXC 2117 - 422037984]
FX This work was funded by the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) under Germany's Excellence Strategy - EXC 2117 -
   422037984. MaterialDesign icons are licensed under theApache License
   2.0.
CR Alber M, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0193-y
   Andrews K., 2008, AVI WORKSHOP TIME ER
   [Anonymous], VIS PAPER SUBMISSION
   [Anonymous], INFOVIS PAPER TYPES
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Auber D, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/INFVIS.2003.1249011
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cakmak E, 2020, 2020 IEEE VISUALIZATION IN DATA SCIENCE (VDS 2020), P32, DOI 10.1109/VDS51726.2020.00008
   Cakmak E, 2021, IEEE T VIS COMPUT GR, V27, P517, DOI 10.1109/TVCG.2020.3030398
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Cho M, 2014, IEEE T VIS COMPUT GR, V20, P808, DOI 10.1109/TVCG.2013.2297933
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Cui QG, 2006, IEEE T VIS COMPUT GR, V12, P709, DOI 10.1109/TVCG.2006.161
   Dictionary.com and O. U. Press, 2020, LEX
   Dumont M, 2020, INT J CARTOGRAPHY, V6, P121, DOI 10.1080/23729333.2020.1717832
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Ebert  David, 2014, SCI VISUALIZATION, P353
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Elmqvist N, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1333
   Ezzati-Jivan N, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4068
   Furnas G. W., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P234
   Glueck M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P561, DOI 10.1145/2556288.2557195
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Gou L., 2010, PROC 3 INT S VIS INF, P1
   Green BN, 2006, J CHIROPR MED, V5, P101, DOI 10.1016/S0899-3467(07)60142-6
   Guiard Y., 2004, Proceedings of the ACM Conference on Advanced Visual Interfaces, P117
   Halladjian S, 2020, IEEE T VIS COMPUT GR, V26, P654, DOI 10.1109/TVCG.2019.2934334
   Isenberg P., 2014, RR8580 INRIA
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Jakobsen MR, 2013, IEEE T VIS COMPUT GR, V19, P2336, DOI 10.1109/TVCG.2013.170
   Jakobsen MR, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1451
   Javed W., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI '12, P287, DOI DOI 10.1145/2207676.2207716
   Javed W, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P217, DOI 10.1145/2254556.2254597
   Javed W, 2013, IEEE T VIS COMPUT GR, V19, P1362, DOI 10.1109/TVCG.2012.323
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jul S., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P97, DOI 10.1145/288392.288578
   Käser D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1601
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Keim DA, 2006, INFORMATION VISUALIZATION-BOOK, P9
   Kouril D, 2021, IEEE T VIS COMPUT GR, V27, P3493, DOI 10.1109/TVCG.2020.2975583
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lopez U, 2012, INTERFACE FOCUS, V2, P693, DOI 10.1098/rsfs.2012.0033
   Mao Y, 2007, IEEE T VIS COMPUT GR, V13, P1208, DOI 10.1109/TVCG.2007.70592
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Miao HC, 2019, J MOL BIOL, V431, P1049, DOI 10.1016/j.jmb.2018.09.004
   Miao HC, 2018, IEEE T VIS COMPUT GR, V24, P1014, DOI 10.1109/TVCG.2017.2743981
   Mittmann A, 2016, IEEE INT CONF INF VI, P312, DOI 10.1109/IV.2016.64
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Openshaw S., 1984, MODIFIABLE AREAL UNI
   Pálenik J, 2020, IEEE T VIS COMPUT GR, V26, P643, DOI 10.1109/TVCG.2019.2934258
   Peng GCY, 2021, ARCH COMPUT METHOD E, V28, P1017, DOI 10.1007/s11831-020-09405-5
   Pezzotti N, 2018, COMPUT GRAPH FORUM, V37, P549, DOI 10.1111/cgf.13441
   Pietriga E, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1215
   Richer G., 2018, P WORKSH EDBT ICDT 2, V2083, P76
   Robertson G, 2009, INFORM VISUAL, V8, P247, DOI 10.1057/ivs.2009.23
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Shi WQ, 2022, IEEE T VIS COMPUT GR, V28, P1810, DOI 10.1109/TVCG.2020.3026021
   Sips M, 2012, IEEE T VIS COMPUT GR, V18, P2899, DOI 10.1109/TVCG.2012.191
   Stolte C, 2003, IEEE T VIS COMPUT GR, V9, P176, DOI 10.1109/TVCG.2003.1196005
   Tao WB, 2021, IEEE T VIS COMPUT GR, V27, P401, DOI 10.1109/TVCG.2020.3030372
   Tao WB, 2019, COMPUT GRAPH FORUM, V38, P529, DOI 10.1111/cgf.13708
   Tominski C, 2017, COMPUT GRAPH FORUM, V36, P173, DOI 10.1111/cgf.12871
   Turkay C, 2014, IEEE T VIS COMPUT GR, V20, P2033, DOI 10.1109/TVCG.2014.2346265
   van Wijk JJ, 2004, IEEE T VIS COMPUT GR, V10, P447, DOI 10.1109/TVCG.2004.1
   Vaquero R. M. M., 2014, 3D MULTISCALE PHYSL, P107, DOI DOI 10.1007/978-1-4471-6275-9_5
   Veras R, 2017, IEEE T VIS COMPUT GR, V23, P631, DOI 10.1109/TVCG.2016.2598591
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Woodring J, 2009, IEEE T VIS COMPUT GR, V15, P123, DOI 10.1109/TVCG.2008.69
   Xu K, 2019, IEEE T VIS COMPUT GR, V25, P109, DOI 10.1109/TVCG.2018.2864825
   Yang J, 2003, COMPUT GRAPH-UK, V27, P265, DOI 10.1016/S0097-8493(02)00283-2
   Ying-Huey Fua, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P43, DOI 10.1109/VISUAL.1999.809866
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zhang JW, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2940, DOI 10.1145/3025453.3025801
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
NR 82
TC 6
Z9 6
U1 3
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4918
EP 4929
DI 10.1109/TVCG.2021.3109387
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400068
PM 34478370
OA Green Published
DA 2024-11-06
ER

PT J
AU Xia, QW
   Zhang, JY
   Fang, Z
   Li, J
   Zhang, MY
   Deng, BL
   He, Y
AF Xia, Qianwei
   Zhang, Juyong
   Fang, Zheng
   Li, Jin
   Zhang, Mingyue
   Deng, Bailin
   He, Ying
TI GeodesicEmbedding (GE): A High-Dimensional Embedding Approach for Fast
   Geodesic Distance Queries
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Optimization; Relays; Shape; Complexity theory; Germanium;
   Computer science; Geodesic distance queries; saddle vertices; high
   dimension embedding; cascaded optimization
ID GRAPH
AB In this article, we develop a novel method for fast geodesic distance queries. The key idea is to embed the mesh into a high-dimensional space, such that the euclidean distance in the high-dimensional space can induce the geodesic distance in the original manifold surface. However, directly solving the high-dimensional embedding problem is not feasible due to the large number of variables and the fact that the embedding problem is highly nonlinear. We overcome the challenges with two novel ideas. First, instead of taking all vertices as variables, we embed only the saddle vertices, which greatly reduces the problem complexity. We then compute a local embedding for each non-saddle vertex. Second, to reduce the large approximation error resulting from the purely euclidean embedding, we propose a cascaded optimization approach that repeatedly introduces additional embedding coordinates with a non-euclidean function to reduce the approximation residual. Using the precomputation data, our approach can determine the geodesic distance between any two vertices in near-constant time. Computational testing results show that our method is more desirable than previous geodesic distance queries methods.
C1 [Xia, Qianwei; Zhang, Juyong; Zhang, Mingyue] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
   [Fang, Zheng; He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Li, Jin] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230052, Peoples R China.
   [Deng, Bailin] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Nanyang Technological University; Chinese Academy of
   Sciences; University of Science & Technology of China, CAS; Cardiff
   University
RP Zhang, JY (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
EM xqw000@mail.ustc.edu.cn; juyong@ustc.edu.cn; fz0420@hotmail.com;
   jarvis@mail.ustc.edu.cn; zmy1256@mail.ustc.edu.cn; DengB3@cardiff.ac.uk;
   yhe@ntu.edu.sg
RI He, Ying/A-3708-2011
OI Deng, Bailin/0000-0002-0158-7670; Fang, Zheng/0000-0003-2601-8148; He,
   Ying/0000-0002-6749-4485
FU National Natural Science Foundation of China [62122071]; Youth
   Innovation Promotion Association CAS [2018495]; Fundamental Research
   Funds for the Central Universities [WK3470000021]; Guangdong
   International Science and Technology Cooperation Project [2021A
   0505030009]; Singapore MOE [RG26/17]
FX This work was supported by National Natural Science Foundation of China
   under Grant 62122071, the Youth Innovation Promotion Association CAS
   under Grant 2018495, "the Fundamental Research Funds for the Central
   Universities" under Grant WK3470000021, Guangdong International Science
   and Technology Cooperation Project 2021A 0505030009, and Singapore MOE
   RG26/17.
CR Adikusuma YY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3144567
   Agarwal S., CERES SOLVER
   [Anonymous], 2013, P 21 INT MESH ROUNDT, DOI DOI 10.1007/978-3-642-33573-021
   Belyaev AG, 2015, COMPUT GRAPH FORUM, V34, P104, DOI 10.1111/cgf.12611
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   CHEN JD, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P360, DOI 10.1145/98524.98601
   Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102
   Cox T.F., 2000, Multidimensional Scaling, DOI DOI 10.1111/j.1365-2699.2007.01772.x
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Jain V, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P118
   Kimmel R, 1998, P NATL ACAD SCI USA, V95, P8431, DOI 10.1073/pnas.95.15.8431
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Liu TT, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2990496
   Liu YJ, 2013, COMPUT AIDED DESIGN, V45, P695, DOI 10.1016/j.cad.2012.11.005
   MEAD A, 1992, STATISTICIAN, V41, P27, DOI 10.2307/2348634
   Melvær EL, 2012, COMPUT GRAPH FORUM, V31, P2423, DOI 10.1111/j.1467-8659.2012.03187.x
   MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Panozzo D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461935
   Qin YP, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925930
   Raviv D, 2010, INT J COMPUT VISION, V89, P18, DOI 10.1007/s11263-010-0320-3
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Solomon J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601175
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Surazhsky V, 2005, ACM T GRAPHIC, V24, P553, DOI 10.1145/1073204.1073228
   Tao J, 2021, IEEE T PATTERN ANAL, V43, P579, DOI 10.1109/TPAMI.2019.2933209
   Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775
   Wang XN, 2017, COMPUT AIDED GEOM D, V52-53, P262, DOI 10.1016/j.cagd.2017.03.010
   Xin S Q., 2012, Proc. - I3D: ACM SIGGRAPH Symp. Interact. 3D Graph. Games, P31
   Xin SQ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559761
   Xin SQ, 2018, COMPUT AIDED DESIGN, V102, P128, DOI 10.1016/j.cad.2018.04.021
   Xu CX, 2015, IEEE T VIS COMPUT GR, V21, P822, DOI 10.1109/TVCG.2015.2407404
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618484
   Ying X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2534161
   Ying X, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508379
   Zhong ZC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201369
   Zigelman G, 2002, IEEE T VIS COMPUT GR, V8, P198, DOI 10.1109/2945.998671
NR 38
TC 0
Z9 0
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4930
EP 4939
DI 10.1109/TVCG.2021.3109975
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400069
PM 34478373
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, X
   Zhang, BW
   Wu, JJ
   Hu, RZ
   Komura, T
AF Zhao, Xi
   Zhang, Bowen
   Wu, Jinji
   Hu, Ruizhen
   Komura, Taku
TI Relationship-Based Point Cloud Completion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Task analysis; Shape; Geometry; Training
   data; Semantics; Robot vision systems; Point cloud completion; spatial
   relationships
ID OBJECT DETECTION
AB We propose a partial point cloud completion approach for scenes that are composed of multiple objects. We focus on pairwise scenes where two objects are in close proximity and are contextually related to each other, such as a chair tucked in a desk, a fruit in a basket, a hat on a hook and a flower in a vase. Different from existing point cloud completion methods, which mainly focus on single objects, we design a network that encodes not only the geometry of the individual shapes, but also the spatial relations between different objects. More specifically, we complete missing parts of the objects in a conditional manner, where the partial or completed point cloud of the other object is used as an additional input to help predict missing parts. Based on the idea of conditional completion, we further propose a two-path network, which is guided by a consistency loss between different sequences of completion. Our method can handle difficult cases where the objects heavily occlude each other. Also, it only requires a small set of training data to reconstruct the interaction area compared to existing completion approaches. We evaluate our method qualitatively and quantitatively via ablation studies and in comparison to the state-of-the-art point cloud completion methods.
C1 [Zhao, Xi; Zhang, Bowen; Wu, Jinji] Xi An Jiao Tong Univ, Sch Comp Sci & Technol, Xian 710049, Peoples R China.
   [Hu, Ruizhen] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Komura, Taku] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
C3 Xi'an Jiaotong University; Shenzhen University; University of Edinburgh
RP Hu, RZ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
EM zhaoxi.jade@gmail.com; zbw1682123@stu.xjtu.edu.cn;
   walf568@stu.xjtu.edu.can; ruizhen.hu@gmail.com; tkomura@ed.ac.uk
RI Zhang, Bowen/AAM-8371-2020
FU National Natural Science Foundation of China [62072366, 61872250]; China
   Postdoctoral Science Foundation [2020M673407]; Fundamental Research
   Funds for the Central Universities [xzy012019048]; Guangdong Natural
   Science Foundation [2021B1515020085]; University of Hong Kong
   [182DRTAKU, 187FRTAKU, 230DRTAKU]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62072366 and 61872250, in part by the
   China Postdoctoral Science Foundation Funded Project under Grant
   2020M673407, in part by the Fundamental Research Funds for the Central
   Universities under Grant xzy012019048, in part by the Guangdong Natural
   Science Foundation under Grant 2021B1515020085, and in part by a
   start-up fund by The University of Hong Kong under Grants 182DRTAKU,
   187FRTAKU, and 230DRTAKU.
CR Alberti Marina., 2014, AAAI 2014 SPRING S Q
   Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   Cosmo L, 2017, COMPUT GRAPH FORUM, V36, P209, DOI 10.1111/cgf.12796
   Dai A, 2020, PROC CVPR IEEE, P846, DOI 10.1109/CVPR42600.2020.00093
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dwibedi D, 2019, PROC CVPR IEEE, P1801, DOI 10.1109/CVPR.2019.00190
   Fisher M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366154
   Garcia-Garcia A, 2016, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2016.7727386
   Hou J, 2020, Arxiv, DOI arXiv:1904.12012
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Huang QX, 2013, COMPUT GRAPH FORUM, V32, P177, DOI 10.1111/cgf.12184
   Huang QX, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601111
   Huang ZT, 2020, PROC CVPR IEEE, P7659, DOI 10.1109/CVPR42600.2020.00768
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kusupati U, 2020, PROC CVPR IEEE, P2186, DOI 10.1109/CVPR42600.2020.00226
   Li ZM, 2019, IEEE INT CON MULTI, P387, DOI 10.1109/ICME.2019.00074
   Liu MH, 2020, AAAI CONF ARTIF INTE, V34, P11596
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Qi CR, 2017, ADV NEUR IN, V30
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Song YC, 2019, COMPUT AIDED GEOM D, V75, DOI 10.1016/j.cagd.2019.101775
   Sunkel M, 2013, COMPUT GRAPH FORUM, V32, P205, DOI 10.1111/cgf.12040
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Wang XL, 2019, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2019.00267
   Xie Haozhe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P365, DOI 10.1007/978-3-030-58545-7_21
   Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zamir AR, 2020, PROC CVPR IEEE, P11194, DOI 10.1109/CVPR42600.2020.01121
   Zhang ZW, 2019, PROC CVPR IEEE, P11076, DOI 10.1109/CVPR.2019.01134
   Zhao X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2574860
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 37
TC 7
Z9 9
U1 2
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4940
EP 4950
DI 10.1109/TVCG.2021.3109392
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400070
PM 34478371
DA 2024-11-06
ER

PT J
AU Ghahremani, P
   Boorboor, S
   Mirhosseini, P
   Gudisagar, C
   Ananth, M
   Talmage, D
   Role, LW
   Kaufman, AE
AF Ghahremani, Parmida
   Boorboor, Saeed
   Mirhosseini, Pooya
   Gudisagar, Chetan
   Ananth, Mala
   Talmage, David
   Role, Lorna W.
   Kaufman, Arie E.
TI NeuroConstruct: 3D Reconstruction and Visualization of Neurites in
   Optical Microscopy Brain Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neurites; Image segmentation; Three-dimensional displays; Rendering
   (computer graphics); Microscopy; Image reconstruction; Visualization;
   Wide-field microscopy; neuron morphology; segmentation; registration;
   hybrid volume rendering; CNN
ID VOLUME RECONSTRUCTION; MOUSE-BRAIN; NEURON; SOFTWARE
AB We introduce NeuroConstruct, a novel end-to-end application for the segmentation, registration, and visualization of brain volumes imaged using wide-field microscopy. NeuroConstruct offers a Segmentation Toolbox with various annotation helper functions that aid experts to effectively and precisely annotate micrometer resolution neurites. It also offers an automatic neurites segmentation using convolutional neuronal networks (CNN) trained by the Toolbox annotations and somas segmentation using thresholding. To visualize neurites in a given volume, NeuroConstruct offers a hybrid rendering by combining iso-surface rendering of high-confidence classified neurites, along with real-time rendering of raw volume using a 2D transfer function for voxel classification score versus voxel intensity value. For a complete reconstruction of the 3D neurites, we introduce a Registration Toolbox that provides automatic coarse-to-fine alignment of serially sectioned samples. The quantitative and qualitative analysis show that NeuroConstruct outperforms the state-of-the-art in all design aspects. NeuroConstruct was developed as a collaboration between computer scientists and neuroscientists, with an application to the study of cholinergic neurons, which are severely affected in Alzheimer's disease.
C1 [Ghahremani, Parmida; Boorboor, Saeed; Mirhosseini, Pooya; Gudisagar, Chetan; Kaufman, Arie E.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Ananth, Mala; Talmage, David; Role, Lorna W.] NIH, Bethesda, MD 20892 USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   National Institutes of Health (NIH) - USA
RP Ghahremani, P (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM pghahremani@cs.stonybrook.edu; sboorboor@cs.stonybrook.edu;
   semirhossein@cs.stonybrook.edu; fchetan@cs.stonybrook.edu;
   mala.ananth@nih.gov; david.talmage@nih.gov; lorna.role@nih.gov;
   ari@cs.stonybrook.edu
RI Boorboor, Saeed/ABI-7739-2020; Role, Lorna/JQX-1231-2023
OI Ananth, Mala/0000-0003-1736-2350; Ghahremani,
   Parmida/0000-0002-6935-817X; Boorboor, Saeed/0000-0001-6644-5983;
   Talmage, David/0000-0003-4627-3007; Kaufman, Arie/0000-0002-0796-6196
FU NSF [CNS1650499, OAC1919752, ICER1940302, IIS2107224]; Intramural
   Research Program of NIH, NINDS; NIH, NIMH
FX This work was supported in part by the NSF under Grants CNS1650499,
   OAC1919752, ICER1940302, and IIS2107224 and in part by the Intramural
   Research Program of NIH, NINDS, and NIMH.
CR [Anonymous], WebGL-based viewer for volumetric data
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Bagci U, 2010, IEEE T MED IMAGING, V29, P1688, DOI 10.1109/TMI.2010.2050594
   Bajcsy P, 2006, J MICROSC-OXFORD, V221, P30, DOI 10.1111/j.1365-2818.2006.01539.x
   Ballinger EC, 2016, NEURON, V91, P1199, DOI 10.1016/j.neuron.2016.09.006
   Basu S, 2014, IEEE IMAGE PROC, P3597, DOI 10.1109/ICIP.2014.7025730
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Boorboor S, 2019, IEEE T VIS COMPUT GR, V25, P1018, DOI 10.1109/TVCG.2018.2864852
   Chen Hanbo, 2017, Brain Inform, V4, P183, DOI 10.1007/s40708-017-0063-9
   Chen Hanbo, 2015, Brain Inform, V2, P135
   Dercksen VJ, 2014, NEUROINFORMATICS, V12, P325, DOI 10.1007/s12021-013-9213-2
   Fakhry A, 2017, IEEE T MED IMAGING, V36, P447, DOI 10.1109/TMI.2016.2613019
   Ferreira-Vieira TH, 2016, CURR NEUROPHARMACOL, V14, P101, DOI 10.2174/1570159X13666150716165726
   GLASER JR, 1990, COMPUT MED IMAG GRAP, V14, P307, DOI 10.1016/0895-6111(90)90105-K
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Haehn D, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4030029
   Haehn D, 2014, IEEE T VIS COMPUT GR, V20, P2466, DOI 10.1109/TVCG.2014.2346371
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Ibanez L., 2003, ITK SOFTWARE GUIDE
   Ikeno H, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00061
   Januszewski M, 2018, NAT METHODS, V15, P605, DOI 10.1038/s41592-018-0049-4
   Ju T, 2006, J NEUROSCI METH, V156, P84, DOI 10.1016/j.jneumeth.2006.02.020
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee SC, 2008, COMPUT VIS IMAGE UND, V110, P19, DOI 10.1016/j.cviu.2007.02.005
   LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042
   Li RJ, 2017, IEEE T MED IMAGING, V36, P1533, DOI 10.1109/TMI.2017.2679713
   Li SW, 2019, FRONT NEUROANAT, V13, DOI 10.3389/fnana.2019.00018
   Liang HY, 2017, CONF REC ASILOMAR C, P1260, DOI 10.1109/ACSSC.2017.8335554
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liu SQ, 2016, NEUROINFORMATICS, V14, P387, DOI 10.1007/s12021-016-9302-0
   Longair MH, 2011, BIOINFORMATICS, V27, P2453, DOI 10.1093/bioinformatics/btr390
   Lucas B., 1981, P 7 INT JOINT C ART, V81, P1
   Luck J., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3739, DOI 10.1109/ROBOT.2000.845314
   Luther K, 2019, I S BIOMED IMAGING, P244, DOI [10.1109/isbi.2019.8759576, 10.1109/ISBI.2019.8759576]
   Magliaro C, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00036
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   Mosaliganti K, 2008, IEEE T VIS COMPUT GR, V14, P863, DOI 10.1109/TVCG.2008.30
   Nakao M, 2014, COMPUT BIOL MED, V53, P85, DOI 10.1016/j.compbiomed.2014.07.007
   Peng HC, 2011, BIOINFORMATICS, V27, pI239, DOI 10.1093/bioinformatics/btr237
   Peng HC, 2010, NAT BIOTECHNOL, V28, P348, DOI 10.1038/nbt.1612
   Pfister H., 2014, Scientific Visualization, P221
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Quan TW, 2016, NAT METHODS, V13, P51, DOI [10.1038/NMETH.3662, 10.1038/nmeth.3662]
   Rasband W. S., 2012, Astrophysics Source Code Library, ascl-1206
   Roberts M, 2011, LECT NOTES COMPUT SC, V6891, P621, DOI 10.1007/978-3-642-23623-5_78
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroeder WJ, 2004, VISUALIZATION TOOLKI
   Tsai CL, 2011, J MICROSC-OXFORD, V243, P154, DOI 10.1111/j.1365-2818.2011.03489.x
   Wan Y, 2012, IEEE PAC VIS SYMP, P201, DOI 10.1109/PacificVis.2012.6183592
   Wang Y, 2011, NEUROINFORMATICS, V9, P193, DOI 10.1007/s12021-011-9110-5
   Xiao H, 2013, BIOINFORMATICS, V29, P1448, DOI 10.1093/bioinformatics/btt170
   Yang J, 2019, NEUROINFORMATICS, V17, P185, DOI 10.1007/s12021-018-9392-y
   Yigitsoy M, 2013, IEEE T MED IMAGING, V32, P1657, DOI 10.1109/TMI.2013.2263151
   Zhou Zhi, 2018, Brain Inform, V5, P3, DOI 10.1186/s40708-018-0081-2
   Zhou Z, 2016, NEUROINFORMATICS, V14, P41, DOI 10.1007/s12021-015-9278-1
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 56
TC 11
Z9 12
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4951
EP 4965
DI 10.1109/TVCG.2021.3109460
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400071
PM 34478372
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Iuricich, F
AF Iuricich, Federico
TI Persistence Cycles for Visual Exploration of Persistent Homology
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data analysis; Visualization; Three-dimensional
   displays; Matrices; Indexes; Topology; Persistent homology; topological
   data analysis; scalar fields
ID MORSE-SMALE COMPLEXES; EFFICIENT COMPUTATION; TOPOLOGY; SIMPLIFICATION;
   ALGORITHM
AB Persistent homology is a fundamental tool in topological data analysis used for the most diverse applications. Information captured by persistent homology is commonly visualized using scatter plots representations. Despite being widely adopted, such a visualization technique limits user understanding and is prone to misinterpretation. This article proposes a new approach for the efficient computation of persistence cycles, a geometric representation of the features captured by persistent homology. We illustrate the importance of rendering persistence cycles when analyzing scalar fields, and we discuss the advantages that our approach provides compared to other techniques in topology-based visualization. We provide an efficient implementation of our approach based on discrete Morse theory, as a new module for the Topology Toolkit. We show that our implementation has comparable performance with respect to state-of-the-art toolboxes while providing a better framework for visually analyzing persistent homology information.
C1 [Iuricich, Federico] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
C3 Clemson University
RP Iuricich, F (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
EM fiurici@clemson.edu
OI Iuricich, Federico/0000-0003-1782-9715
FU NIH/NIDCD [DC000422]
FX The TTK plugin presented in this work can be found at
   https://github.com/IuricichF/PersistenceCycles. The HURRICANE dataset
   produced by the Weather Research and Forecast (WRF) model is courtesy of
   NCAR and the U.S. National Science Foundation (NSF). The BRAIN dataset
   is courtesy of Prof. Mark Eckert at theMedical School of South Carolina
   and was supported with funding from NIH/NIDCD DC000422. The authors
   would also wish to thank anonymous reviewers whose comments helped to
   improve this manuscript.
CR Adams Henry, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P129, DOI 10.1007/978-3-662-44199-2_23
   Adams H, 2017, J MACH LEARN RES, V18
   [Anonymous], 2014, TOPOLOGICAL METHODS
   [Anonymous], 2020, HOMCLOUD A DATA ANAL
   [Anonymous], 2020, DIAMORSE DIGITAL IMA
   Attali D, 2015, COMP GEOM-THEOR APPL, V48, P606, DOI 10.1016/j.comgeo.2014.08.010
   Attali D, 2011, COMPUTATIONAL GEOMETRY (SCG 11), P501
   Bauer Ulrich, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P137, DOI 10.1007/978-3-662-44199-2_24
   Bauer U., 2014, P 16 WORKSH ALG ENG, P31, DOI [10.1137/1.9781611973198.4, DOI 10.1137/1.9781611973198.4]
   Bauer U., 2019, Ripser: efficient computation of Vietoris-Rips persistence barcodes, DOI DOI 10.1186/s13059-016-0980-6
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Brendel P, 2012, LECT NOTES COMPUT SC, V7309, P117, DOI 10.1007/978-3-642-30238-1_13
   Capd, 2019, CAPD REDHOM SIMPLICI
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Chambers EW, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P377
   Chen C., 2011, 27 EUROPEAN WORKSHOP, V45, P28
   Chen C, 2013, COMP GEOM-THEOR APPL, V46, P435, DOI 10.1016/j.comgeo.2012.02.010
   Chen C, 2011, DISCRETE COMPUT GEOM, V45, P425, DOI 10.1007/s00454-010-9322-8
   Chen C, 2010, COMP GEOM-THEOR APPL, V43, P169, DOI 10.1016/j.comgeo.2009.06.004
   Cheng JH, 2018, 2018 IEEE/ACM 11TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING (CHASE), P57, DOI 10.1145/3195836.3195838
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   de Silva V, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/12/124003
   Delgado-Friedrichs O, 2015, IEEE T PATTERN ANAL, V37, P654, DOI 10.1109/TPAMI.2014.2346172
   Dey T.K., 2014, P 30 ANN S COMP GEOM, P345, DOI DOI 10.1145/2582112.2582165
   Dey TK, 2020, PROCEEDINGS OF THE THIRTY-FIRST ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS (SODA'20), P2587
   Dey TK, 2019, LECT NOTES COMPUT SC, V11382, P123, DOI 10.1007/978-3-030-10828-1_10
   Di Fabio B, 2015, LECT NOTES COMPUT SC, V9279, P294, DOI 10.1007/978-3-319-23231-7_27
   Dionysus, 2019, DIONYSUS C LIB COMPU
   Dlotko P, 2011, DISCRETE COMPUT GEOM, V46, P361, DOI 10.1007/s00454-010-9303-y
   Eckert MA, 2006, BRAIN LANG, V98, P102, DOI 10.1016/j.bandl.2006.04.002
   Eckert MA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111809
   Eckert MA, 2019, J NEUROSCI METH, V322, P1, DOI 10.1016/j.jneumeth.2019.04.007
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2010, American Mathematical Soc., DOI [10.1090/mbk/069, DOI 10.1090/MBK/069]
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   G_unther D., 2014, Topological Methods in Data Analysis and Visualization, VIII, P135
   Ghrist R, 2008, B AM MATH SOC, V45, P61, DOI 10.1090/s0273-0979-07-01191-3
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Harker S, 2014, FOUND COMPUT MATH, V14, P151, DOI 10.1007/s10208-013-9145-0
   Hatcher A., 2002, ALGEBRAIC TOPOLOGY, pxii+544
   Hausmann JC, 1995, ANN MATH STUD, P175
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Henselman G, 2017, Arxiv, DOI arXiv:1606.00199
   Iuricich F, 2015, COMPUT GRAPH-UK, V51, P157, DOI 10.1016/j.cag.2015.05.007
   King H, 2005, EXP MATH, V14, P435, DOI 10.1080/10586458.2005.10128941
   Kusano G, 2018, J MACH LEARN RES, V18
   Labache L, 2019, BRAIN STRUCT FUNCT, V224, P859, DOI 10.1007/s00429-018-1810-2
   Lewiner T, 2013, COMPUT AIDED GEOM D, V30, P609, DOI 10.1016/j.cagd.2012.03.012
   Lilleodden ET, 2018, MRS BULL, V43, P20, DOI 10.1557/mrs.2017.303
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Maria Clement, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P167, DOI 10.1007/978-3-662-44199-2_28
   McDevitt KM, 2019, MATERIALIA, V7, DOI 10.1016/j.mtla.2019.100393
   Milnor J., 1963, MORSE THEORY, V71
   Mischaikow K, 2013, DISCRETE COMPUT GEOM, V50, P330, DOI 10.1007/s00454-013-9529-6
   Mrozek M, 2009, DISCRETE COMPUT GEOM, V41, P96, DOI 10.1007/s00454-008-9073-y
   Munkres J R, 1984, Elements of algebraic topology, DOI DOI 10.1109/JPROC.2006.887293
   Murty NA, 2013, INT C HIGH PERFORM, P333, DOI 10.1109/HiPC.2013.6799139
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Otter N, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0109-5
   Pascucci V, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P187, DOI 10.1109/VISUAL.2002.1183774
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Reininghaus J, 2015, PROC CVPR IEEE, P4741, DOI 10.1109/CVPR.2015.7299106
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Saul N., 2019, SCIKIT TDA TOPOLOGIC, DOI DOI 10.5281/ZENODO.2533369
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   Wu PX, 2017, LECT NOTES COMPUT SC, V10265, P80, DOI 10.1007/978-3-319-59050-9_7
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y
   Zomorodian A, 2008, COMP GEOM-THEOR APPL, V41, P126, DOI 10.1016/j.comgeo.2008.02.003
   Zomorodian A, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P257, DOI 10.1145/1810959.1811004
NR 85
TC 3
Z9 3
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4966
EP 4979
DI 10.1109/TVCG.2021.3110663
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400072
PM 34495835
DA 2024-11-06
ER

PT J
AU Li, Z
   Wang, XT
   Yang, WK
   Wu, J
   Zhang, ZY
   Liu, ZY
   Sun, MS
   Zhang, H
   Liu, SX
AF Li, Zhen
   Wang, Xiting
   Yang, Weikai
   Wu, Jing
   Zhang, Zhengyan
   Liu, Zhiyuan
   Sun, Maosong
   Zhang, Hui
   Liu, Shixia
TI A Unified Understanding of Deep NLP Models for Text Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Analytical models; Visualization; Internet; Data
   models; Computer architecture; Adaptation models; Explainable AI; visual
   debugging; visual analytics; deep NLP model; information-based
   interpretation
AB The rapid development of deep natural language processing (NLP) models for text classification has led to an urgent need for a unified understanding of these models proposed individually. Existing methods cannot meet the need for understanding different models in one framework due to the lack of a unified measure for explaining both low-level (e.g., words) and high-level (e.g., phrases) features. We have developed a visual analysis tool, DeepNLPVis, to enable a unified understanding of NLP models for text classification. The key idea is a mutual information-based measure, which provides quantitative explanations on how each layer of a model maintains the information of input words in a sample. We model the intra- and inter-word information at each layer measuring the importance of a word to the final prediction as well as the relationships between words, such as the formation of phrases. A multi-level visualization, which consists of a corpus-level, a sample-level, and a word-level visualization, supports the analysis from the overall training set to individual samples. Two case studies on classification tasks and comparison between models demonstrate that DeepNLPVis can help users effectively identify potential problems caused by samples and model architectures and then make informed improvements.
C1 [Li, Zhen; Yang, Weikai; Zhang, Hui; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Wang, Xiting] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff CF10 3AT, Wales.
   [Zhang, Zhengyan; Liu, Zhiyuan; Sun, Maosong] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
C3 Tsinghua University; Microsoft Research Asia; Microsoft; Cardiff
   University; Tsinghua University
RP Zhang, H (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM thu.lz@outlook.com; xitwan@microsoft.com;
   yangwk21@mails.tsinghua.edu.cn; wuj11@cardiff.ac.uk;
   zy-z19@mails.tsinghua.edu.cn; liuzy@tsinghua.edu.cn;
   sms@tsinghua.edu.cn; huizhang@tsinghua.edu.cn; shixia@tsinghua.edu.cn
RI Liu, Zhiyuan/I-2233-2014; wang, xiting/HGF-3827-2022; zhengyan,
   zhang/D-2029-2012; Liu, Shi-Xia/C-5574-2016
OI yang, wei kai/0000-0002-6520-1642; Wu, Jing/0000-0001-5123-9861; Liu,
   Zhiyuan/0000-0002-7709-2543
FU National Key R&D Program of China [2020YFB2104100]; National Natural
   Science Foundation of China [U21A20469, 61936002]; Institute Guo Qiang;
   THUIBCS; BLBCI; Tsinghua-Kuaishou Institute of Future Media Data
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020YFB2104100, in part by the National Natural Science
   Foundation of China under Grants U21A20469 and 61936002, grants from the
   Institute Guo Qiang, THUIBCS, and BLBCI, and in part by the
   Tsinghua-Kuaishou Institute of Future Media Data.
CR [Anonymous], 2019, Glue: A multi-task benchmark and analysis platform for natural language understanding
   [Anonymous], 2019, PROC NAACL
   Baehrens D, 2010, J MACH LEARN RES, V11, P1803
   Brunner G., 2020, ICLR
   Cashman D, 2018, IEEE COMPUT GRAPH, V38, P39, DOI 10.1109/MCG.2018.2878902
   Chawla P, 2020, VIS INFORM, V4, P132, DOI 10.1016/j.visinf.2020.04.006
   Cui WW, 2011, IEEE T VIS COMPUT GR, V17, P2412, DOI 10.1109/TVCG.2011.239
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Dong ZH, 2020, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis48177.2020.1031
   Dosilovic FK, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P210, DOI 10.23919/MIPRO.2018.8400040
   Gehrmann S, 2020, IEEE T VIS COMPUT GR, V26, P884, DOI 10.1109/TVCG.2019.2934595
   Guan CY, 2019, PR MACH LEARN RES, V97
   Hinton G., 2015, NEURIPS DEEP LEARNIN, V14, P38
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Houlsby N, 2019, PR MACH LEARN RES, V97
   Ji XN, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.03.003
   Karpathy A., 2016, PROC WORKSHOP INT C
   Kim AY, 2021, J STAT DATA SCI EDUC, V29, pS51, DOI 10.1080/10691898.2020.1799728
   Kim Y, 2014, ARXIV, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lei Shi, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P99, DOI 10.1109/VAST.2010.5652931
   Li J, 2016, Visualizing and Understanding Neural Models in NLP Association for Computational Linguistics, DOI DOI 10.18653/V1/N16-1082
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu SS, 2019, IEEE T VIS COMPUT GR, V25, P651, DOI 10.1109/TVCG.2018.2865230
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Minaee S., 2021, ACM computing surveys (CSUR), V54, P1, DOI DOI 10.1145/3439726
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Radford Alec., 2018, Improving language understanding by generative pre-training
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Socher R, 2013, P ADV NEUR INF PROC, P935, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107
   Tenney Ian, 2019, INT C LEARNING REPRE
   Tolstikhin I, 2021, ADV NEUR IN, V34
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang RZ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1405
   Yahav I, 2019, IEEE T KNOWL DATA EN, V31, P437, DOI 10.1109/TKDE.2018.2840127
   Yang Yaoqing, 2020, Advances in Neural Information Processing Systems, V33, P6223, DOI 10.48550/arXiv.2007.05086
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhang TY, 2018, AAAI CONF ARTIF INTE, P6053
NR 49
TC 20
Z9 23
U1 4
U2 31
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4980
EP 4994
DI 10.1109/TVCG.2022.3184186
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400073
PM 35724276
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, Y
   Jiao, CH
   Bace, M
   Bulling, A
AF Wang, Yao
   Jiao, Chuhan
   Bace, Mihai
   Bulling, Andreas
TI VisRecall: Quantifying Information Visualisation Recallability via
   Question Answering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Task analysis; Question answering
   (information retrieval); Image recognition; Computational modeling;
   Bars; Information visualisation; machine learning; memorability;
   recallability
ID MEMORABILITY; RECOGNITION; MEMORY
AB Despite its importance for assessing the effectiveness of communicating information visually, fine-grained recallability of information visualisations has not been studied quantitatively so far. In this work, we propose a question-answering paradigm to study visualisation recallability and present VisRecall - a novel dataset consisting of 200 visualisations that are annotated with crowd-sourced human (N = 305) recallability scores obtained from 1,000 questions of five question types. Furthermore, we present the first computational method to predict recallability of different visualisation elements, such as the title or specific data values. We report detailed analyses of our method on VisRecall and demonstrate that it outperforms several baselines in overall recallability and FE-, F-, RV-, and U-question recallability. Our work makes fundamental contributions towards a new generation of methods to assist designers in optimising visualisations.
C1 [Wang, Yao; Bace, Mihai; Bulling, Andreas] Univ Stuttgart, Inst Visualisat & Interact Syst, D-70174 Stuttgart, Germany.
   [Jiao, Chuhan] Aalto Univ, Espoo 02150, Finland.
C3 University of Stuttgart; Aalto University
RP Wang, Y (corresponding author), Univ Stuttgart, Inst Visualisat & Interact Syst, D-70174 Stuttgart, Germany.
EM yao.wang@vis.uni-stuttgart.de; chuhan.jiao@aalto.fi;
   mihai.bace@vis.uni-stuttgart.de; andreas.bulling@vis.uni-stuttgart.de
RI Bulling, Andreas/A-3947-2009
OI Jiao, Chuhan/0000-0002-1769-2854; Wang, Yao/0000-0002-3633-8623
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [251654672 - TRR 161]; Swiss National Science Foundation (SNSF) Early
   Postdoc. Mobility Fellowship [199991]; European Research Council
   [801708]; European Research Council (ERC) [801708] Funding Source:
   European Research Council (ERC)
FX The work of Yao Wang was supported by Deutsche Forschungsgemeinschaft
   (DFG, German Research Foundation) under Grant 251654672 - TRR 161. The
   work of Mihai Bace was supported by a Swiss National Science Foundation
   (SNSF) Early Postdoc. Mobility Fellowship under Grant 199991. The work
   of Andreas Bulling was supported by the European Research Council under
   Grant 801708.
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 1990, Envisioning information
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bainbridge WA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07830-6
   Bainbridge WA, 2017, NEUROIMAGE, V149, P141, DOI 10.1016/j.neuroimage.2017.01.063
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   Bylinskii Z., 2021, PROC HUMAN PERCEPTIO, P207
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fajtl J, 2018, PROC CVPR IEEE, P6363, DOI 10.1109/CVPR.2018.00666
   Fosco C., 2020, P 33 ANN ACM S US IN, P249, DOI DOI 10.1145/3379337.3415825
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   HAIST F, 1992, J EXP PSYCHOL LEARN, V18, P691, DOI 10.1037/0278-7393.18.4.691
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hulman J, 2018, IEEE T VIS COMPUT GR, V24, P446, DOI 10.1109/TVCG.2017.2743898
   Inbar O., 2007, P ACM EUR C COGN ERG, P185, DOI DOI 10.1145/1362550.1362587
   Isola P., 2011, UNDERSTANDING INSTRI
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Jaegle A, 2019, ELIFE, V8, DOI 10.7554/eLife.47596
   Jonides J, 2008, ANNU REV PSYCHOL, V59, P193, DOI 10.1146/annurev.psych.59.103006.093615
   Kafle K, 2020, IEEE WINT CONF APPL, P1487, DOI 10.1109/WACV45572.2020.9093494
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou Samira Ebrahimi, 2018, arXiv, DOI DOI 10.48550/ARXIV.1710.07300
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Kim SH, 2012, IEEE T VIS COMPUT GR, V18, P2421, DOI 10.1109/TVCG.2012.215
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kingma DP, 2014, ADV NEUR IN, V27
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   KOSSLYN SM, 1989, APPL COGNITIVE PSYCH, V3, P185, DOI 10.1002/acp.2350030302
   Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041
   Methani N, 2020, IEEE WINT CONF APPL, P1516, DOI 10.1109/WACV45572.2020.9093523
   Newman A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376799
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Perera S, 2019, IEEE COMPUT SOC CONF, P800, DOI 10.1109/CVPRW.2019.00108
   Pinker S., 1990, Artif. Intell. Future Testing, V73, P73, DOI DOI 10.1145/2046684.2046699
   Polatsek P, 2018, COMPUT GRAPH-UK, V72, P26, DOI 10.1016/j.cag.2018.01.010
   Rust NC, 2020, TRENDS COGN SCI, V24, P557, DOI 10.1016/j.tics.2020.04.001
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Yonelinas AP, 2002, J MEM LANG, V46, P441, DOI 10.1006/jmla.2002.2864
NR 55
TC 1
Z9 1
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 4995
EP 5005
DI 10.1109/TVCG.2022.3198163
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400074
PM 35951578
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Quadri, GJ
   Rosen, P
AF Quadri, Ghulam Jilani
   Rosen, Paul
TI A Survey of Perception-Based Visualization Studies by Task
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Taxonomy; Encoding;
   Guidelines; Crowdsourcing; Visualization; perception; graphical
   perception; visual analytics tasks; evaluation; survey
ID RANKING VISUALIZATIONS; CLUSTER PERCEPTION; SCATTERPLOTS; DESIGN;
   BIASES; GRAPH; IDENTIFICATION; ORIENTATION; SEPARATION; DENSITY
AB Knowledge of human perception has long been incorporated into visualizations to enhance their quality and effectiveness. The last decade, in particular, has shown an increase in perception-based visualization research studies. With all of this recent progress, the visualization community lacks a comprehensive guide to contextualize their results. In this report, we provide a systematic and comprehensive review of research studies on perception related to visualization. This survey reviews perception-focused visualization studies since 1980 and summarizes their research developments focusing on low-level tasks, further breaking techniques down by visual encoding and visualization type. In particular, we focus on how perception is used to evaluate the effectiveness of visualizations, to help readers understand and apply the principles of perception of their visualization designs through a task-optimized approach. We concluded our report with a summary of the weaknesses and open research questions in the area.
C1 [Quadri, Ghulam Jilani; Rosen, Paul] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33647 USA.
C3 State University System of Florida; University of South Florida
RP Quadri, GJ (corresponding author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33647 USA.
EM ghulamjilani@usf.edu; prosen@usf.edu
RI Rosen, Paul/AAN-1370-2021
OI Quadri, Ghulam Jilani/0000-0002-8054-5048; Rosen,
   Paul/0000-0002-0873-9518
FU National Science Foundation [IIS-1845204]
FX The authors would like to thank the reviewers for their helpful feedback
   on the construction of this article. This work was supported by the
   National Science Foundation under Grant IIS-1845204.
CR Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Afzal S, 2012, IEEE T VIS COMPUT GR, V18, P2556, DOI 10.1109/TVCG.2012.264
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Alexander E, 2018, IEEE T VIS COMPUT GR, V24, P2397, DOI 10.1109/TVCG.2017.2723397
   ALLEN RC, 1981, SURV OPHTHALMOL, V26, P22, DOI 10.1016/0039-6257(81)90121-1
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 1834, De pulsu, resorptione, auditu et tactu: Annotationes anotomicae et physiologicae, auctore
   [Anonymous], 2007, P 16 INT C WORLD WID, DOI DOI 10.1145/1242572.1242826
   Aupetit M, 2016, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2016.7465244
   Battle L, 2020, IEEE T VIS COMPUT GR, V26, P1246, DOI 10.1109/TVCG.2019.2934556
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bertini Enrico., 2016, P EUR IEEE VGTC C VI, P91, DOI [10.2312/EUROVISSHORT.20161167, DOI 10.2312/EUROVISSHORT.20161167]
   Best LA, 2006, LECT NOTES COMPUT SC, V4045, P244
   BOBKO P, 1979, PERS PSYCHOL, V32, P313, DOI 10.1111/j.1744-6570.1979.tb02137.x
   Borgo R, 2018, COMPUT GRAPH FORUM, V37, P573, DOI 10.1111/cgf.13444
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Chan YH, 2013, IEEE T VIS COMPUT GR, V19, P1768, DOI 10.1109/TVCG.2013.20
   Chang CL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1397, DOI 10.1145/3025453.3026024
   Chang R., 2016, SOC IMAGING SCI TECH, V16, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.16HVEI-131
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1982, SCIENCE, V216, P1138, DOI 10.1126/science.216.4550.1138
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Conati C, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12393
   Coren S., 1999, SENSATION PERCEPTION
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Diehl A., 2018, EuroVis 2018 - Short Papers, P61, DOI DOI 10.2312/EUROVISSHORT.20181079
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dimara E, 2017, IEEE T VIS COMPUT GR, V23, P471, DOI 10.1109/TVCG.2016.2598594
   Doherty ME, 2007, PERCEPT PSYCHOPHYS, V69, P1261, DOI 10.3758/BF03193961
   Eells WC, 1926, J AM STAT ASSOC, V21, P119, DOI 10.2307/2277140
   Elliott M, 2020, Arxiv, DOI arXiv:2009.06855
   Ellis G., 2018, Cognitive biases in visualizations, DOI DOI 10.1007/978-3-319-95831-6
   Felix C, 2018, IEEE T VIS COMPUT GR, V24, P657, DOI 10.1109/TVCG.2017.2746018
   Few S, 2017, JOURNEY ZVINCA MAKIN
   Few Stephen, 2008, VISUAL BUSINESS INTE
   Gelfand S. A., 2017, Hearing: An Introduction to Psychological and Physiological Acoustics
   Gescheider G. A., 2013, Psychophysics: The fundamentals
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Gramazio CC, 2014, IEEE T VIS COMPUT GR, V20, P1953, DOI 10.1109/TVCG.2014.2346983
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Gutwin C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P208, DOI 10.1145/3025453.3025984
   Haroz S, 2012, IEEE T VIS COMPUT GR, V18, P2402, DOI 10.1109/TVCG.2012.233
   Harrison L., 2013, P SIGCHI C HUMAN FAC, P2949, DOI DOI 10.1145/2470654.24814109
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Harrison L, 2012, IEEE CONF VIS ANAL, P227, DOI 10.1109/VAST.2012.6400540
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Nguyen H, 2018, IEEE T VIS COMPUT GR, V24, P1301, DOI 10.1109/TVCG.2017.2661309
   Holten D, 2010, COMPUT GRAPH FORUM, V29, P793, DOI 10.1111/j.1467-8659.2009.01666.x
   Hornbæk K, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3523, DOI 10.1145/2556288.2557004
   Hullman J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P143, DOI 10.1145/2993901.2993919
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kosara R, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P162, DOI 10.1145/2993901.2993909
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   L'Yi S, 2019, COMPUT GRAPH FORUM, V38, P201, DOI 10.1111/cgf.13682
   LAUER TW, 1989, BEHAV INFORM TECHNOL, V8, P235, DOI 10.1080/01449298908914554
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Li J, 2010, IEEE PAC VIS SYMP, P105, DOI 10.1109/PACIFICVIS.2010.5429604
   Li J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2553
   Li J, 2010, INFORM VISUAL, V9, P13, DOI 10.1057/ivs.2008.13
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   Loomis JM, 1999, BEHAV RES METH INS C, V31, P557, DOI 10.3758/BF03200735
   Ma LQ, 2013, IEEE T VIS COMPUT GR, V19, P1808, DOI 10.1109/TVCG.2013.99
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Matejka J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2707, DOI 10.1145/2702123.2702585
   Matute J, 2018, IEEE T VIS COMPUT GR, V24, P542, DOI 10.1109/TVCG.2017.2744339
   MEYER DE, 1971, J EXP PSYCHOL, V90, P227, DOI 10.1037/h0031564
   Meyer J, 1997, J EXP PSYCHOL-APPL, V3, P3, DOI 10.1037/1076-898X.3.1.3
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   MORGAN MJ, 1990, VISION RES, V30, P1793, DOI 10.1016/0042-6989(90)90160-M
   Mylavarapu P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300422
   Neumann L., 1998, Computer Graphics Forum, V17, pC233, DOI 10.1111/1467-8659.00270
   Nguyen Hoa., 2016, International Joint Conference on Computer Vision, Imaging and Computer Graphics, P264
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Nusrat S, 2018, IEEE T VIS COMPUT GR, V24, P1100, DOI 10.1109/TVCG.2016.2642109
   OCALLAGH.JF, 1974, PERCEPTION, V3, P33, DOI 10.1068/p030033
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Pan Y., 1995, Journal of Consumer Psychology, V4, P85
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Perin C., 2013, P SIGCHI C HUMAN FAC, P3217, DOI [10.1145/2470654.24664412,3,4, DOI 10.1145/2470654.24664412,3,4, DOI 10.1145/2470654.2466441]
   POLLACK I, 1960, J EXP PSYCHOL, V59, P351, DOI 10.1037/h0042245
   Preim B, 2016, COMPUT GRAPH FORUM, V35, P501, DOI 10.1111/cgf.12927
   Quadri G. J., 2019, ARXIV
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Raidou RG, 2016, IEEE T VIS COMPUT GR, V22, P589, DOI 10.1109/TVCG.2015.2467872
   Reda K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173846
   Reijner H., 2008, The development of the horizon graph
   Rensink R, 2006, PROC AM STATIST ASS
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Rensink Ronald A., 2014, HDB HUMAN CENTRIC VI, P147, DOI [DOI 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485- 2_6]
   Rivadeneira AW, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P995
   Rosenbaum R, 2012, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2012.6183570
   Rosling Hans., 2009, Gapminder
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sadahiro Y., 1997, Cartographica: The International Journal for Geographic Information and Geovisualization, V34, P49, DOI DOI 10.3138/Y308-2422-8615-1233
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Saket B, 2018, IEEE T VIS COMPUT GR, V24, P1316, DOI 10.1109/TVCG.2017.2680452
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Sarikaya A, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13408
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Schrammel J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2037
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Seizova-Cajic T, 2006, VISION RES, V46, P2525, DOI 10.1016/j.visres.2006.02.010
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Sher V, 2017, COMPUT GRAPH FORUM, V36, P61, DOI 10.1111/cgf.13168
   Siegrist M, 1996, BEHAV INFORM TECHNOL, V15, P96, DOI 10.1080/014492996120300
   Siirtola H, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P3, DOI 10.1109/IV.2009.25
   Skau D, 2016, COMPUT GRAPH FORUM, V35, P121, DOI 10.1111/cgf.12888
   Skau D, 2015, COMPUT GRAPH FORUM, V34, P221, DOI 10.1111/cgf.12634
   Skau Drew., 2017, EuroVis Short Papers, P91, DOI DOI 10.2312/EUROVISSHORT.20171139
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Smart S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300899
   Song H, 2019, IEEE T VIS COMPUT GR, V25, P914, DOI 10.1109/TVCG.2018.2864914
   Soni U, 2018, COMPUT GRAPH FORUM, V37, P169, DOI 10.1111/cgf.13410
   SPENCE I, 1991, APPL COGNITIVE PSYCH, V5, P61, DOI 10.1002/acp.2350050106
   Srinivasan Arjun, 2018, P 2018 CHI C HUM FAC
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P489, DOI 10.1109/TVCG.2015.2467759
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Dang TN, 2014, IEEE T VIS COMPUT GR, V20, P1624, DOI 10.1109/TVCG.2014.2346572
   Turton T. L., 2017, PROC EUROVIS WORKSHO, P1
   Valdez A.C., 2017, FRAMEWORK STUDYING B
   Valdez AC, 2018, IEEE T VIS COMPUT GR, V24, P584, DOI 10.1109/TVCG.2017.2744138
   van Ham F, 2008, IEEE T VIS COMPUT GR, V14, P1333, DOI 10.1109/TVCG.2008.155
   Wacharamanotham C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376448
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Ware C., 2019, Information Visualization: Perception for Design
   Ware C, 2013, INFORM VISUAL, V12, P221, DOI 10.1177/1473871612465214
   Weber E.H., 1834, WEBERS LAW JUST NOTI
   Weber EH, 1996, E.H. Weber on the tactile senses
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Wilkinson L, 2018, IEEE T VIS COMPUT GR, V24, P256, DOI 10.1109/TVCG.2017.2744685
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu W., 1999, P AM SOC MECH ENG DY, V67, P19
   Wun T, 2016, COMPUT GRAPH FORUM, V35, P111, DOI 10.1111/cgf.12887
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Yang FM, 2019, IEEE T VIS COMPUT GR, V25, P1474, DOI 10.1109/TVCG.2018.2810918
   Yau C, 2019, COMPUT GRAPH FORUM, V38, P375, DOI 10.1111/cgf.13696
   Yost B, 2006, IEEE T VIS COMPUT GR, V12, P837, DOI 10.1109/TVCG.2006.184
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Zgraggen E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174053
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 165
TC 21
Z9 22
U1 7
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5026
EP 5048
DI 10.1109/TVCG.2021.3098240
PG 23
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400076
PM 34283717
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wu, AY
   Wang, Y
   Shu, XH
   Moritz, D
   Cui, WW
   Zhang, HD
   Zhang, DM
   Qu, HM
AF Wu, Aoyu
   Wang, Yun
   Shu, Xinhuan
   Moritz, Dominik
   Cui, Weiwei
   Zhang, Haidong
   Zhang, Dongmei
   Qu, Huamin
TI AI4VIS: Survey on Artificial Intelligence Approaches for Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Artificial intelligence; Taxonomy;
   Data mining; Computers; Vocabulary; Survey; data visualization;
   artificial intelligence; data format; machine learning
ID CHART IMAGES; VISUAL INFORMATION; DATA EXPLORATION; GENERATION;
   INFOGRAPHICS; GRAMMAR
AB Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data. We highlight a set of common tasks that researchers apply to the visualization data and present a detailed discussion of AI approaches developed to accomplish those tasks. Drawing upon our literature review, we discuss several important research questions surrounding the management and exploitation of visualization data, as well as the role of AI in support of those processes. We make the list of surveyed papers and related material available online at.
C1 [Wu, Aoyu; Shu, Xinhuan; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Yun; Cui, Weiwei; Zhang, Haidong; Zhang, Dongmei] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Moritz, Dominik] Carnegie Mellon Univ, HumanComp Interact Inst, Pittsburgh, PA USA.
C3 Hong Kong University of Science & Technology; Microsoft; Microsoft
   Research Asia; Carnegie Mellon University
RP Wang, Y (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM awuac@cse.ust.hk; wangyun@microsoft.com; xinhuan.shu@cse.ust.hk;
   domoritz@cmu.edu; weiwei.cui@microsoft.com; haidong.zhang@microsoft.com;
   dongmeiz@microsoft.com; huamin@cse.ust.hk
RI zhang, dongmei/B-8011-2013; Zhang, Haidong/J-9302-2019
OI Shu, Xinhuan/0000-0002-9736-4454; Moritz, Dominik/0000-0002-3110-1053;
   Wu, Aoyu/0000-0001-9187-9265
FU Hong Kong Theme-based Research Scheme [T41-709/17N]
FX The authors would like to thank anonymous reviewers for their
   constructive comments. This work was supported by Hong Kong Theme-based
   Research Scheme under Grant T41-709/17N.
CR Al-Zaidy R. A., 2016, WORKSH 30 AAAI C ART, P658
   Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Ananthanarayanan R, 2018, PROCEEDINGS OF THE 21ST WORKSHOP ON THE WEB AND DATABASES (WEBDB 2018), DOI 10.1145/3201463.3201465
   [Anonymous], COMP VIS
   [Anonymous], 2017, J OPEN SOURCE SOFTW, DOI DOI 10.21105/JOSS.00235
   [Anonymous], VIS MEETS AI WORKSH
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bolte F, 2021, IEEE T VIS COMPUT GR, V27, P3153, DOI 10.1109/TVCG.2019.2963651
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Brosz J., 2013, P 26 ANN ACM S USER, P97
   Browuer William, 2008, Joint Conference on Digital Libraries (JCDL 2008), P276, DOI 10.1145/1378889.1378936
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Burns Richard., 2012, P 7 INT C THEORY APP, P8
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Canfora G., 2004, Journal of Computing and Information Technology - CIT, V12, P175, DOI 10.2498/cit.2004.03.01
   Chagas P, 2018, IEEE IJCNN
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen C, 2020, IEEE WINT CONF APPL, P1526, DOI 10.1109/WACV45572.2020.9093592
   Chen C, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P482, DOI 10.1145/3341162.3345601
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Choudhury S. R., 2016, ser. SBD '16, P1, DOI DOI 10.1145/2928294.2928305
   Choudhury SR, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P667, DOI 10.1145/2740908.2741712
   Choudhury SR, 2016, ACM-IEEE J CONF DIG, P277, DOI 10.1145/2910896.2925469
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Ehsan H, 2018, IEEE T KNOWL DATA EN, V30, P263, DOI 10.1109/TKDE.2017.2765634
   Ehsan H, 2016, PROC INT CONF DATA, P731, DOI 10.1109/ICDE.2016.7498285
   Fan CR, 2021, IEEE T VIS COMPUT GR, V27, P4495, DOI 10.1109/TVCG.2020.3002950
   Fan CR, 2018, COMPUT GRAPH FORUM, V37, P111, DOI 10.1111/cgf.13405
   Fekete J.-D., 2020, PROC BIGVIS BIG DATA, V2578, P1
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Fu X, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P126, DOI [10.1109/visual.2019.8933570, 10.1109/VISUAL.2019.8933570]
   Gao JL, 2012, IEEE IMAGE PROC, P2865, DOI 10.1109/ICIP.2012.6467497
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   Huang WH, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P9
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou Samira Ebrahimi, 2018, arXiv, DOI DOI 10.48550/ARXIV.1710.07300
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Key A., 2012, ACM, P681
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim E, 2018, ASSETS'18: PROCEEDINGS OF THE 20TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P143, DOI 10.1145/3234695.3236357
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lalle Sebastien., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P357, DOI [10.1145/2678025.2701376, DOI 10.1145/2678025.2701376]
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P427, DOI 10.1109/TVCG.2018.2864526
   Lee B, 2019, IEEE COMPUT GRAPH, V39, P78, DOI 10.1109/MCG.2019.2914844
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038
   Li Z, 2015, DATA KNOWL ENG, V100, P191, DOI 10.1016/j.datak.2015.05.005
   Lifschitz V, 1999, LOGIC PROGRAMM, P23
   Lin AY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P873, DOI 10.1145/3178876.3186135
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu RZ, 2007, PROC INT CONF DOC, P521
   Lu M, 2017, IEEE PAC VIS SYMP, P61
   Luo YY, 2022, IEEE T KNOWL DATA EN, V34, P475, DOI 10.1109/TKDE.2020.2981464
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Mafrur R, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1123, DOI 10.1145/3269206.3271744
   McCandless David., 2009, Information Is Beautiful
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Methani N, 2020, IEEE WINT CONF APPL, P1516, DOI 10.1109/WACV45572.2020.9093523
   Mittal VO, 1998, COMPUT LINGUIST, V24, P431
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Obeid J., 2020, P 13 INT C NATURAL L, P138, DOI 10.48550/arXiv.2010.09142
   Ono J. P., 2018, WHY SHOULD WE TEACH
   Oppermann M, 2021, IEEE T VIS COMPUT GR, V27, P495, DOI 10.1109/TVCG.2020.3030387
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Prasad VSN, 2007, INT WORK CONTENT MUL, P85
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Qin XD, 2020, VLDB J, V29, P93, DOI 10.1007/s00778-019-00588-3
   Raji M, 2021, IEEE T VIS COMPUT GR, V27, P3656, DOI 10.1109/TVCG.2020.2984708
   Reddy R., 2019, P INT JOINT C NEUR N, P1
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Saket B., 2018, arXiv
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Savvides R, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1509, DOI 10.1145/3292500.3330994
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Singh H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3275
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Srinivasan A., 2017, EUR IEEE VGTC C VIS, P55, DOI 10.2312/eurovisshort.20171133
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Tang BB, 2016, SIGNAL PROCESS, V124, P156, DOI 10.1016/j.sigpro.2015.09.027
   Tsutsui S, 2017, PROC INT CONF DOC, P533, DOI 10.1109/ICDAR.2017.93
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Dang TN, 2013, IEEE T VIS COMPUT GR, V19, P470, DOI 10.1109/TVCG.2012.128
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang CL, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3371117
   Wang QW, 2021, Arxiv, DOI [arXiv:2012.00467, 10.1109/TVCG.2021.3106142, DOI 10.1109/TVCG.2021.3106142]
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wattenberg M., 2001, P 2001 CHI C HUM FAC, P381, DOI DOI 10.1145/634067.6342922
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Wu AY, 2021, Arxiv, DOI arXiv:2101.03680
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Wu  E., 2017, P CIDR, P1, DOI DOI 10.1109/ICEMS.2017.8056424
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yuan L.-P., 2021, ARXIV
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhou YP., 2001, 4th IAPR International Workshop on Graphics Recognition, GREC, P482
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
   Zhuo Li, 2014, Natural Language Processing and Information Systems. 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014. Proceedings: LNCS 8455, P101
NR 147
TC 54
Z9 56
U1 7
U2 77
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5049
EP 5070
DI 10.1109/TVCG.2021.3099002
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400077
PM 34310306
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Genay, A
   Lécuyer, A
   Hachet, M
AF Genay, Adelaide
   Lecuyer, Anatole
   Hachet, Martin
TI Being an Avatar "for Real": A Survey on Virtual Embodiment in Augmented
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Psychology; Visualization; Tools; Taxonomy; Augmented reality;
   Virtual environments; Augmented reality; avatar; sense of embodiment;
   psychology; social and behavioral sciences
ID BODY OWNERSHIP; RUBBER-HAND; SENSE; DISPLAYS; AGENCY; SKIN; CHALLENGES;
   EXPERIENCE; STIFFNESS; RESPONSES
AB Virtual self-avatars have been increasingly used in Augmented Reality (AR) where one can see virtual content embedded into physical space. However, little is known about the perception of self-avatars in such a context. The possibility that their embodiment could be achieved in a similar way as in Virtual Reality opens the door to numerous applications in education, communication, entertainment, or the medical field. This article aims to review the literature covering the embodiment of virtual self-avatars in AR. Our goal is (i) to guide readers through the different options and challenges linked to the implementation of AR embodiment systems, (ii) to provide a better understanding of AR embodiment perception by classifying the existing knowledge, and (iii) to offer insight on future research topics and trends for AR and avatar research. To do so, we introduce a taxonomy of virtual embodiment experiences by defining a "body avatarization" continuum. The presented knowledge suggests that the sense of embodiment evolves in the same way in AR as in other settings, but this possibility has yet to be fully investigated. We suggest that, whilst it is yet to be well understood, the embodiment of avatars has a promising future in AR and conclude by discussing possible directions for research.
C1 [Genay, Adelaide; Hachet, Martin] Inria, F-33405 Bordeaux, France.
   [Lecuyer, Anatole] Inria, F-35042 Rennes, France.
C3 Inria; Inria
RP Genay, A (corresponding author), Inria, F-33405 Bordeaux, France.
EM adelaide.genay@inria.fr; anatole.lecuyer@inria.fr;
   martin.hachet@inria.fr
OI Genay, Adelaide/0000-0003-3151-1164
FU Inria for the "Avatar Challenge" Inria Project Lab (IPL)
FX The research of this article was funded by Inria for the "Avatar
   Challenge" Inria Project Lab (IPL).
CR Abdi E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134501
   Adam H, 2012, J EXP SOC PSYCHOL, V48, P918, DOI 10.1016/j.jesp.2012.02.008
   Aglioti S, 1996, NEUROREPORT, V8, P293, DOI 10.1097/00001756-199612200-00058
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Anderegg R, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI [10.1145/3274247.3274511, 10.1145/3206004.3206023]
   [Anonymous], 2014, PROC 3 IUI WORKSHOP
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Armel KC, 2003, P ROY SOC B-BIOL SCI, V270, P1499, DOI 10.1098/rspb.2003.2364
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bainbridge WilliamSims., 2004, BERKSHIRE ENCY HUMAN
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Barbosa A., 2012, COMPUTATIONAL INTELL
   Baskar J., 2017, THESIS J HOPKINS U B
   Batmaz Anil Ufuk, 2020, P FUT TECHN C, P792
   Beltran K, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451739
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Buisine S, 2016, COGN TECHNOL WORK, V18, P583, DOI 10.1007/s10111-016-0378-y
   Cao Z, 2019, Arxiv, DOI [arXiv:1812.08008, DOI 10.48550/ARXIV.1812.08008]
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Collins J, 2017, PRESENCE-TELEOP VIRT, V26, P16, DOI 10.1162/PRES_a_00284
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Dourish P, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2442106.2442108
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022
   Eckhoff D., 2019, EXPLORING PERCEPTUAL
   Ehrsson H.H., 2012, HDB MULTISENSORY PRO, P775
   Ehrsson HH, 2005, J NEUROSCI, V25, P10564, DOI 10.1523/JNEUROSCI.0800-05.2005
   Eisert P, 2007, IEEE IMAGE PROC, P1121
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fröhner J, 2019, IEEE T HAPTICS, V12, P339, DOI 10.1109/TOH.2018.2889497
   Gaffary Y, 2017, IEEE T VIS COMPUT GR, V23, P2372, DOI 10.1109/TVCG.2017.2735078
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Genay A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679902
   Gervais R, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P227, DOI 10.1145/2839462.2839486
   Gilbers C., 2017, THESIS DEP INFORM CO
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Griffin NN, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364243
   Guegan J, 2016, COMPUT HUM BEHAV, V61, P165, DOI 10.1016/j.chb.2016.03.024
   Guterstam A, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017208
   Hachet Martin., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, P587, DOI DOI 10.1145/2047196.2047273
   Hamanishi N, 2019, PROCEEDINGS OF CHIUXID 2019: 5TH INTERNATIONAL ACM IN-COOPERATION HCI AND UX CONFERENCE, P1, DOI 10.1145/3328243.3328244
   Harrell DF, 2017, COMMUN ACM, V60, P50, DOI 10.1145/3098342
   Harrison Chris, 2011, P 24 ANN ACM S US IN, P441, DOI [DOI 10.1145/2047196.2047255, 10.1145/2047196.2047255]
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Heydrich L, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00946
   Hilsmann A, 2009, LECT NOTES COMPUT SC, V5496, P94, DOI 10.1007/978-3-642-01811-4_9
   Hoermann S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050942
   Holle H, 2011, COGN NEUROSCI-UK, V2, P171, DOI 10.1080/17588928.2011.603828
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Hyung-Seok Jang, 2011, Proceedings of the 1st IEEE First International Conference on Consumer Electronics - Berlin (IEEE ICCE-Berlin 2011), P274, DOI 10.1109/ICCE-Berlin.2011.6031808
   IJsselsteijn WA, 2006, PRESENCE-TELEOP VIRT, V15, P455, DOI 10.1162/pres.15.4.455
   Javornik A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4838, DOI 10.1145/3025453.3025722
   Jeon S, 2009, PRESENCE-TELEOP VIRT, V18, P387, DOI 10.1162/pres.18.5.387
   Jo HG, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00421
   Johnson Adrian S., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P169, DOI 10.1007/978-3-642-39405-8_20
   Johnson K, 2014, FASH TEXT, V1, DOI 10.1186/s40691-014-0020-7
   Jung S, 2019, CYBERPSYCH BEH SOC N, V22, P142, DOI 10.1089/cyber.2018.0028
   Kaneko F, 2019, FRONT SYST NEUROSCI, V13, DOI 10.3389/fnsys.2019.00076
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kellems RO, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4030048
   Kilteni K, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00141
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kim S., REAL TIME INVERSE KI
   Kirsh D, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2442106.2442109
   Kleinberger R, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P27, DOI 10.1145/3173225.3173249
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kraus MW, 2014, J EXP PSYCHOL GEN, V143, P2330, DOI 10.1037/xge0000023
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lamounier Jr E., 2012, J BIOENG BIOMED SCI, V1
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Likert R., 1932, ARCH PSYCHOL, V140, P55
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI DOI 10.1145/2931002.2931006
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Ma K, 2015, CONSCIOUS COGN, V36, P277, DOI 10.1016/j.concog.2015.07.008
   Makhataeva Z, 2020, ROBOTICS, V9, DOI 10.3390/robotics9020021
   Marotta A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168489
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003
   Medeiros D, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281511
   Meli L, 2018, IEEE ROBOT AUTOM LET, V3, P4297, DOI 10.1109/LRA.2018.2864354
   Mercier-Ganady J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P33, DOI 10.1109/VR.2014.6802047
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Moore JW, 2012, CONSCIOUS COGN, V21, P546, DOI 10.1016/j.concog.2011.12.002
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Moseley GL, 2008, P NATL ACAD SCI USA, V105, P13169, DOI 10.1073/pnas.0803768105
   Naert L, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6008
   Nilsen T., 2004, FUSE 04, V4, P86
   Nimcharoen C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P158, DOI 10.1109/ISMAR-Adjunct.2018.00057
   Nishino W, 2017, IEEE SYS MAN CYBERN, P1046, DOI 10.1109/SMC.2017.8122749
   Noh S., 2015, P INT C ART REAL TEL, P61
   Oshita M., 2013, Proceedings of the 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry - VRCAI, V13, P131
   Parekh P, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-020-00057-7
   PARFIT D, 1971, PHILOS REV, V80, P3, DOI 10.2307/2184309
   Park J, 2018, CYBERPSYCHOLOGY, V12, DOI 10.5817/CP2018-1-3
   Park S. J., 2019, THESIS DARTMOUTH COL
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Petkova VI, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003832
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Plasencia Diego Martinez, 2014, P 27 ANN ACM S USER, P341, DOI [10.1145/2642918.2647351, DOI 10.1145/2642918.2647351]
   Qian J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P133, DOI 10.1145/3332165.3347904
   Raz L, 2008, LECT NOTES COMPUT SC, V5024, P367, DOI 10.1007/978-3-540-69057-3_47
   Regenbrecht H, 2014, P IEEE, V102, P170, DOI 10.1109/JPROC.2013.2294178
   Reitmayr G., 2010, Proceedings of the 2010 International Symposium on Ubiquitous Virtual Reality (ISUVR 2010), P5, DOI 10.1109/ISUVR.2010.12
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rohde M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021659
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Rosa N, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3341225
   Rosa N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1138, DOI [10.1109/VR.2019.8798055, 10.1109/vr.2019.8798055]
   Rosa N, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P550, DOI 10.1145/2993148.2997618
   Roth D., 2017, P 2017 CHI C EXT ABS, VPart F1276, P2875, DOI DOI 10.1145/3027063.3053272
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Saakes D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P6058, DOI 10.1145/2858036.2858282
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Schettler A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01332
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seignette M, 2021, bioRxiv, DOI [10.1101/2020.12.17.423230, 10.1101/2020.12.17.423230, DOI 10.1101/2020.12.17.423230]
   Seinfeld S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79255-5
   Shapiro A, 2019, ACM SIGGRAPH 2019 APPY HOUR (SIGGRAPH '19), P13, DOI 10.1145/3305365.3329734
   Shibuya S, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02242
   Skola F, 2016, VISUAL COMPUT, V32, P761, DOI 10.1007/s00371-016-1246-8
   SLADE PD, 1973, PSYCHOL MED, V3, P188, DOI 10.1017/S0033291700048510
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Slepian ML, 2015, SOC PSYCHOL PERS SCI, V6, P661, DOI 10.1177/1948550615579462
   Soltani P, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103923
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Stone GregoryP., 1962, HUMAN BEHAV SOCIAL P, P86
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Teras M., 2015, CURT BUS SCH HIGH DE
   Thomas BH, 2012, COMPUT ENTERTAIN, V10, DOI 10.1145/2381876.2381879
   Hoang TN, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P253, DOI 10.1145/3196709.3196724
   Toothman N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P756, DOI [10.1109/vr.2019.8798108, 10.1109/VR.2019.8798108]
   Treepong B, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3277452
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   van Bommel J., 2017, THESIS DEP INFORM CO
   Walsh E, 2015, PERCEPTION, V44, P709, DOI 10.1177/0301006615594266
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wang K, 2017, IEEE ACCESS, V5, P10700, DOI 10.1109/ACCESS.2017.2711058
   Wang TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1221, DOI [10.1109/VR.2019.8798044, 10.1109/vr.2019.8798044]
   Watts I, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141198
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Yan Xu, 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P19, DOI 10.1109/ISMAR-AMH.2011.6093652
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yim MYC, 2019, J BUS RES, V100, P581, DOI 10.1016/j.jbusres.2018.10.041
   Yu XG, 2019, NATURE, V575, P473, DOI 10.1038/s41586-019-1687-0
   Zabels R., 2021, PROC OPTICAL ARCHITE, P213
   Zheng F, 2014, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR.2014.6948427
   Zollmann S, 2021, IEEE T VIS COMPUT GR, V27, P3808, DOI 10.1109/TVCG.2020.2986247
   Zoulias ID, 2016, LECT NOTES COMPUT SC, V9775, P479, DOI 10.1007/978-3-319-42324-1_47
NR 169
TC 39
Z9 41
U1 8
U2 91
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5071
EP 5090
DI 10.1109/TVCG.2021.3099290
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400078
PM 34310309
OA Green Published
DA 2024-11-06
ER

PT J
AU Guo, Y
   Guo, SN
   Jin, ZC
   Kaul, S
   Gotz, D
   Cao, N
AF Guo, Yi
   Guo, Shunan
   Jin, Zhuochen
   Kaul, Smiti
   Gotz, David
   Cao, Nan
TI Survey on Visual Analysis of Event Sequence Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visual analytics; Task analysis; Data mining;
   Sequences; Pipelines; Medical diagnostic imaging; Visual analysis; event
   sequences; visualization
ID MEDICAL-RECORDS; COHORT ANALYSIS; ANALYTICS; VISUALIZATION; EXPLORATION;
   PATTERNS; OPPORTUNITIES; DIFFUSION; AWARENESS; TIME
AB Event sequence data record series of discrete events in the time order of occurrence. They are commonly observed in a variety of applications ranging from electronic health records to network logs, with the characteristics of large-scale, high-dimensional and heterogeneous. This high complexity of event sequence data makes it difficult for analysts to manually explore and find patterns, resulting in ever-increasing needs for computational and perceptual aids from visual analytics techniques to extract and communicate insights from event sequence datasets. In this paper, we review the state-of-the-art visual analytics approaches, characterize them with our proposed design space, and categorize them based on analytical tasks and applications. From our review of relevant literature, we have also identified several remaining research challenges and future research opportunities.
C1 [Guo, Yi; Guo, Shunan; Jin, Zhuochen; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200092, Peoples R China.
   [Kaul, Smiti; Gotz, David] Univ N Carolina, Visual Anal & Commun Lab, Chapel Hill, NC 27599 USA.
C3 Tongji University; University of North Carolina; University of North
   Carolina Chapel Hill
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai 200092, Peoples R China.
EM dennis.guo.china@gmail.com; g.shunan@gmail.com; chjzcjames@gmail.com;
   smiti@unc.edu; gotz@unc.edu; nan.cao@gmail.com
RI Guo, Shunan/AAE-2616-2019; Cao, Nan/O-5397-2014
OI Cao, Nan/0000-0003-1316-7515; Guo, Shunan/0000-0001-5355-8399; Gotz,
   David/0000-0002-6424-7374
FU NSFC [62061136003]
FX This work was supported in part by the NSFC under Grant 62061136003. The
   authors would like to thank the reviewers, Prof. Catherine Plaisant,
   Prof. Ben Shneiderman, Prof. Daniel Weiskopf, and many other readers for
   their valuable feedback and suggestions.
CR Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   [Anonymous], 2011, IEEE VISWEEK WORKSH
   BHATTACHARJYA D, 2020, PROC AAAI C ARTIF IN, P3259
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Cao N, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.73
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   CHANKHIHORT DOUNG, 2017, International Journal of Contents, V13, P21, DOI 10.5392/IJoC.2017.13.2.021
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Chen Q, 2020, IEEE T VIS COMPUT GR, V26, P1622, DOI 10.1109/TVCG.2018.2872961
   Chen Q, 2016, IEEE T VIS COMPUT GR, V22, P2315, DOI 10.1109/TVCG.2015.2505305
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P1204, DOI 10.1109/TVCG.2019.2934263
   Chen SM, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3183347
   Chen YZ, 2018, IEEE INT CONF BIG DA, P975, DOI 10.1109/BigData.2018.8622571
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Choi E, 2016, ADV NEUR IN, V29
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Choudhry A, 2021, IEEE T VIS COMPUT GR, V27, P1332, DOI 10.1109/TVCG.2020.3030358
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   Du F, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200490
   Du F, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5498, DOI 10.1145/3025453.3025777
   Du F, 2017, IEEE T VIS COMPUT GR, V23, P1636, DOI 10.1109/TVCG.2016.2539960
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Elmqvist N., 2004, Information Visualization, V3, P154, DOI 10.1057/palgrave.ivs.9500074
   Elmqvist N., 2003, Proc. 1st ACM Symp. Softw. Vis, P17
   Fails JA, 2006, IEEE CONF VIS ANAL, P167
   Fan Du, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382971
   Fan XP, 2017, J VISUAL LANG COMPUT, V41, P111, DOI 10.1016/j.jvlc.2017.03.006
   Fischer F, 2012, IEEE SYM VIS CYB SEC, P80
   Franklin L, 2016, INTERACT COMPUT, V28, P238, DOI 10.1093/iwc/iwu043
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Gotz D, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P85, DOI 10.1145/2856767.2856779
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Goulden M. C., 2019, ELECT IMAGING, V1, P681, DOI 10.2352/issn.2470-1173.2019.1.vda-681
   Guo RC, 2020, VIS INFORM, V4, P72, DOI 10.1016/j.visinf.2020.04.001
   Guo SN, 2019, IEEE INT CONF BIG DA, P1125, DOI 10.1109/BigData47090.2019.9005687
   Guo SN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300803, 10.1109/peds44367.2019.8998889]
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Han Y, 2015, COMPUT GRAPH FORUM, V34, P51, DOI 10.1111/cgf.12617
   He H, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P99, DOI 10.1145/3300115.3309514
   Herr D, 2018, IEEE INT CON INF VIS, P251, DOI 10.1109/iV.2018.00051
   Hibbs MA, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-115
   Huisman O., 2005, P 17 ANN C SPAT INF, P155
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   JENTNER W, 2019, PROC HIGH UTILITY PA, P303
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Kadaba NR, 2007, IEEE T VIS COMPUT GR, V13, P1254, DOI 10.1109/TVCG.2007.70528
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kiernan J, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1631162.1631169
   Koldehofe B, 1999, SIGCSE BULL, V31, P103, DOI 10.1145/305786.305884
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krause J, 2016, IEEE T VIS COMPUT GR, V22, P91, DOI 10.1109/TVCG.2015.2467622
   Kwan MP, 1999, PROF GEOGR, V51, P210
   Kwon B C., 2016, ACM SIGKDD 2016 Workshop on Interactive Data Exploration and Analytics, P1, DOI DOI 10.1109/APSIPA.2016.7820895
   KWON BC, IN PRESS, DOI DOI 10.1109/TVCG.2020.2985689
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P396, DOI 10.1109/TVCG.2018.2864886
   Li W, 2019, J VISUAL-JAPAN, V22, P833, DOI 10.1007/s12650-019-00566-5
   Liu Z., 2016, P IEEE VIS 2016 WORK, P2
   Liu ZC, 2017, COMPUT GRAPH FORUM, V36, P527, DOI 10.1111/cgf.13208
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Malik S., 2015, P 20 INT C INT US IN, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10.1145/2678025.2701407]
   Malik S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2890478
   Mei HY, 2017, ADV NEUR IN, V30
   Michotte A., 1963, J PSYCHOL NORMALE PA, V60, P9
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Monroe M, 2014, Molecular Weight Calculator
   Mu X., 2019, EUROVIS SHORT PAPERS, P91, DOI [DOI 10.2312/EVS.20191176, 10.2312/evs20191176/091-0952, DOI 10.2312/EVS20191176/091-0952]
   Muelder C, 2016, IEEE T VIS COMPUT GR, V22, P1694, DOI 10.1109/TVCG.2016.2534558
   Ng K, 2014, J BIOMED INFORM, V48, P160, DOI 10.1016/j.jbi.2013.12.012
   Nguyen PH, 2020, IEEE T VIS COMPUT GR, V26, P77, DOI 10.1109/TVCG.2019.2934609
   Nguyen PH, 2019, IEEE T VIS COMPUT GR, V25, P2838, DOI 10.1109/TVCG.2018.2859969
   Nielsen CB, 2009, IEEE T VIS COMPUT GR, V15, P881, DOI 10.1109/TVCG.2009.116
   Perer A., 2013, Proceedings of the CHI Extended Abstracts on Human Factors in Computing Systems, P439, DOI [10.1145/2468356.2468434, DOI 10.1145/2468356.2468434]
   Perer A, 2015, J BIOMED INFORM, V56, P369, DOI 10.1016/j.jbi.2015.06.020
   Perer Adam, 2012, AMIA Annu Symp Proc, V2012, P716
   Perer Adam., 2014, P 19 INT C INTELLIGE, P153, DOI [10.1145/ 2557500.2557508, DOI 10.1145/2557500.2557508]
   Plaisant, 2016, PROC IEEE VIS WORKSH, P1
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Polack PJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3152888
   Polack PJ, 2015, IEEE CONF VIS ANAL, P209, DOI 10.1109/VAST.2015.7347682
   Qi J, 2020, IEEE T VIS COMPUT GR, V26, P1054, DOI 10.1109/TVCG.2019.2934289
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Robinson AC, 2017, CARTOGR GEOGR INF SC, V44, P216, DOI 10.1080/15230406.2016.1139467
   Rogers J, 2019, APPL CLIN INFORM, V10, P278, DOI 10.1055/s-0039-1687862
   Rosenthal P, 2013, COMPUT GRAPH FORUM, V32, P81, DOI 10.1111/cgf.12095
   Rzeszotarski JM, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P55
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Saraiya P, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P1, DOI 10.1109/INFVIS.2004.5
   Sarikaya A, 2016, COMPUT GRAPH FORUM, V35, P151, DOI 10.1111/cgf.12891
   Senin Pavel, 2015, Proceedings of the 18th International Conference on Extending Database Technology, EDBT, P481
   Seo J, 2002, COMPUTER, V35, P80
   SHI Y, IN PRESS, DOI DOI 10.1109/TBDATA.2020.2964169
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B, 2019, COMPUTER, V52, P27, DOI 10.1109/MC.2018.2890217
   Slack J., 2004, German Conference on Bioinformatics, P37
   Stopar L, 2019, IEEE T VIS COMPUT GR, V25, P1788, DOI 10.1109/TVCG.2018.2825424
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Sun GD, 2013, J COMPUT SCI TECH-CH, V28, P852, DOI 10.1007/s11390-013-1383-8
   Sun GD, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3106775
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Trumper J., 2012, Proceedings Theory and Practice of Computer Graphics, P45
   Viegas F., 2013, P 22 INT C WORLD WID, P1389
   Vrotsou K., 2010, THESIS SWEDEN
   Vrotsou K, 2009, IEEE T VIS COMPUT GR, V15, P945, DOI 10.1109/TVCG.2009.117
   Wang G, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P225, DOI 10.1145/2858036.2858107
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wang TD, 2009, IEEE T VIS COMPUT GR, V15, P1049, DOI 10.1109/TVCG.2009.187
   Wang TD, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P457
   Wang X., 2009, PROC SPIE VIS ANALYT
   Wei JS, 2012, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2012.6400494
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Wu WC, 2018, IEEE PAC VIS SYMP, P140, DOI 10.1109/PacificVis.2018.00026
   Wu YC, 2016, IEEE T MULTIMEDIA, V18, P2135, DOI 10.1109/TMM.2016.2614220
   Wu YC, 2014, IEEE T VIS COMPUT GR, V20, P1763, DOI 10.1109/TVCG.2014.2346920
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xu HT, 2016, PR MACH LEARN RES, V48
   Xu K, 2020, IEEE T VIS COMPUT GR, V26, P1107, DOI 10.1109/TVCG.2019.2934613
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yu H., 2006, CARTOGR GEOGR INF SC, V33, P3, DOI DOI 10.1559/152304006777323136
   Yuan XR, 2014, IEEE CONF VIS ANAL, P291, DOI 10.1109/VAST.2014.7042535
   Zgraggen E, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2683, DOI 10.1145/2702123.2702262
   Zhang W., 2020, arXiv
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhang ZY, 2015, INFORM VISUAL, V14, P289, DOI 10.1177/1473871614526077
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhou FF, 2019, J VISUAL-JAPAN, V22, P419, DOI 10.1007/s12650-018-0530-2
   Zhou FF, 2018, J VISUAL LANG COMPUT, V44, P58, DOI 10.1016/j.jvlc.2017.11.004
   Zhuochen Jin, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3344258
NR 141
TC 52
Z9 53
U1 10
U2 37
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5091
EP 5112
DI 10.1109/TVCG.2021.3100413
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400079
PM 34314358
DA 2024-11-06
ER

PT J
AU Marques, B
   Silva, S
   Alves, J
   Araujo, T
   Dias, P
   Santos, BS
AF Marques, Bernardo
   Silva, Samuel
   Alves, Joao
   Araujo, Tiago
   Dias, Paulo
   Santos, Beatriz Sousa
TI A Conceptual Model and Taxonomy for Collaborative Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Collaboration; Taxonomy; Collaborative work; Augmented reality;
   Visualization; Task analysis; Three-dimensional displays; Collaboration;
   augmented reality; conceptual model; taxonomy; human-centered;
   systematization
ID DESIGN; AWARENESS; CLASSIFICATION; PERFORMANCE; CHALLENGES; GROUPWARE;
   INDUSTRY; ISSUES; TOOLS; CUES
AB To support the nuances of collaborative work, many researchers have been exploring the field of Augmented Reality (AR), aiming to assist in co-located or remote scenarios. Solutions using AR allow taking advantage from seamless integration of virtual objects and real-world objects, thus providing collaborators with a shared understanding or common ground environment. However, most of the research efforts, so far, have been devoted to experiment with technology and mature methods to support its design and development. Therefore, it is now time to understand where the field stands and how well can it address collaborative work with AR, to better characterize and evaluate the collaboration process. In this article, we perform an analysis of the different dimensions that should be taken into account when analysing the contributions of AR to the collaborative work effort. Then, we bring these dimensions forward into a conceptual framework and propose an extended human-centered taxonomy for the categorization of the main features of Collaborative AR. Our goal is to foster harmonization of perspectives for the field, which may help create a common ground for systematization and discussion. We hope to influence and improve how research in this field is reported by providing a structured list of the defining characteristics. Finally, some examples of the use of the taxonomy are presented to show how it can serve to gather information for characterizing AR-supported collaborative work, and illustrate its potential as the grounds to elicit further studies.
C1 [Marques, Bernardo; Silva, Samuel; Alves, Joao; Dias, Paulo; Santos, Beatriz Sousa] Univ Aveiro, DETI, IEETA, P-3810193 Aveiro, Portugal.
   [Araujo, Tiago] Fed Univ Para, PPGCC, BR-66075110 Belem, Para, Brazil.
C3 Universidade de Aveiro; Universidade Federal do Para
RP Marques, B (corresponding author), Univ Aveiro, DETI, IEETA, P-3810193 Aveiro, Portugal.
EM bernardo.marques@ua.pt; sss@ua.pt; jbga@ua.pt; tiagoaraujo@ufpa.br;
   paulo.dias@ua.pt; bss@ua.pt
RI Marques, Bernardo/AGY-4340-2022; Dias, Paulo/G-3681-2013
OI Silva, Samuel/0000-0002-9858-8249; Marques,
   Bernardo/0000-0002-4454-710X; Dias, Paulo/0000-0002-3754-2749; Alves,
   Joao/0000-0002-3430-5211
FU FCT - Foundation for Science and Technology [SFRH/BD/143276/2019]; IEETA
   - Institute of Electronics and Informatics Engineering of Aveiro - FCT
   [UID/CEC/00127/2019]; Portugal2020 under the Competitiveness and
   Internationalization Operational Program; European Regional Development
   Fund through project SOCA - Smart Open Campus
   [CENTRO-01-0145-FEDER-000010]
FX The authors would like to thank the reviewers for their thoughtful
   comments and suggestions towards improving on an earlier version of this
   manuscript. The authors would also like to thank everyone involved in
   discussion groups and case studies for their time and expertise. This
   work was supported in the scope of the PhD under Grant
   SFRH/BD/143276/2019, funded by the FCT - Foundation for Science and
   Technology. This work was also supported in part by the IEETA -
   Institute of Electronics and Informatics Engineering of Aveiro, funded
   by National Funds through FCT under Grant UID/CEC/00127/2019, in part by
   the Portugal2020 under the Competitiveness and Internationalization
   Operational Program, and in part by the European Regional Development
   Fund through project SOCA - Smart Open Campus under Grant
   CENTRO-01-0145-FEDER-000010.
CR Altug Y., 2016, INT J RECENT TRENDS, V7, P23
   Antunes P, 2014, J SYST SOFTWARE, V89, P146, DOI 10.1016/j.jss.2013.11.1078
   Arias E., 2000, ACM Transactions on Computer-Human Interaction, V7, P84, DOI 10.1145/344949.345015
   Aschenbrenner D, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00037
   Aschenbrenner D, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P69, DOI 10.1109/ISMAR-Adjunct.2018.00036
   Augstein M, 2019, INTERACT COMPUT, V31, P27, DOI 10.1093/iwc/iwz003
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barnum Carol M., 2010, Usability Testing Essentials
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Bolstad CA, 2005, ERGON DES, V13, P7, DOI 10.1177/106480460501300404
   Bottani E, 2019, IISE TRANS, V51, P284, DOI 10.1080/24725854.2018.1493244
   Braz Jose M., 2008, International Journal of Virtual Reality, V7, P47
   Brockmann T, 2013, PROC 19 AMERICAS C I, P1
   Bruno F, 2019, INT J ADV MANUF TECH, V105, P875, DOI 10.1007/s00170-019-04254-4
   Carvalho RM, 2017, SOFTWARE QUAL J, V25, P743, DOI 10.1007/s11219-016-9320-z
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Cidota M., 2016, Augmented Human Research, P1, DOI DOI 10.1007/S41133-016-0003-X
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   Collazos CA, 2019, J AMB INTEL HUM COMP, V10, P4789, DOI 10.1007/s12652-018-1165-9
   de Belen R.A.J., 2019, AIMS ELECT ELECT ENG, V3, P181, DOI [10.3934/ElectrEng.2019.2.181, DOI 10.3934/ELECTRENG.2019.2.181]
   del Amo IF, 2018, COMPUT IND, V103, P47, DOI 10.1016/j.compind.2018.08.007
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dourish P., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P107, DOI 10.1145/143457.143468
   ELLIS CA, 1991, COMMUN ACM, V34, P38
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fernandes AM, 2012, COGN PROCESS, V13, P285, DOI 10.1007/s10339-012-0443-2
   Fischer JE, 2018, HUM-COMPUT INTERACT, V33, P305, DOI 10.1080/07370024.2018.1440556
   Gergle D, 2013, HUM-COMPUT INTERACT, V28, P1, DOI 10.1080/07370024.2012.678246
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Grudin J, 2013, ENCY HUMAN COMPUTER
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich P, 2015, COMPUT SUPP COOP W J, V24, P527, DOI 10.1007/s10606-015-9232-7
   Hadwin A. F., 2006, PROC 6 IEEE INT C AD, P1007
   Hall M., 2018, DS 92, P347
   Halskov K, 2015, INT J HUM-COMPUT ST, V74, P81, DOI 10.1016/j.ijhcs.2014.09.003
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Huang WD, 2019, J VIS COMMUN IMAGE R, V58, P428, DOI 10.1016/j.jvcir.2018.12.010
   Hugues O, 2011, HANDBOOK OF AUGMENTED REALITY, P47, DOI 10.1007/978-1-4614-0064-6_2
   Irlitti A, 2019, IEEE T VIS COMPUT GR, V25, P3178, DOI 10.1109/TVCG.2019.2932173
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Jacko JA, 2012, HUM FACTORS ERGON, P1, DOI 10.1201/b11963
   Jalo H, 2018, P 10 INT C KNOWL MAN, P41, DOI [10.5220/0006889800410051, DOI 10.5220/0006889800410051]
   Jetter J, 2018, COMPUT HUM BEHAV, V87, P18, DOI 10.1016/j.chb.2018.04.054
   Johansen Robert, 1988, Groupware: Computer support for business teams
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim S, 2020, J MULTIMODAL USER IN, V14, P313, DOI 10.1007/s12193-020-00346-8
   Kim S, 2020, J MULTIMODAL USER IN, V14, P321, DOI 10.1007/s12193-020-00335-x
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kim S, 2018, KSII T INTERNET INF, V12, P6034
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Kim S, 2014, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2014.6948412
   Knoke MQB, 2018, PROC CIRP, V72, P1130, DOI 10.1016/j.procir.2018.03.061
   Kreijns K, 2013, EDUC PSYCHOL-US, V48, P229, DOI 10.1080/00461520.2012.750225
   Kwon BC, 2017, IEEE T VIS COMPUT GR, V23, P221, DOI 10.1109/TVCG.2016.2598446
   Kwon JU, 2019, IEEE ACCESS, V7, P54155, DOI 10.1109/ACCESS.2019.2912397
   Lamberti F, 2014, IEEE T EMERG TOP COM, V2, P411, DOI 10.1109/TETC.2014.2368833
   Lee CP, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P179, DOI 10.1145/2675133.2675161
   Li Wenkai., 2017, Multimodal Technol. Interact., V1, P17, DOI DOI 10.3390/MTI1030017
   Lindeman RW, 2007, VRST 2007: ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, PROCEEDINGS, P175
   Lukosch S, 2015, COMPUT SUPP COOP W J, V24, P515, DOI 10.1007/s10606-015-9239-0
   Mackay W.E., 1998, Proceedings of the working conference on Advanced visual interfaces, P13
   Madeira Tiago, 2021, Human Systems Engineering and Design III. Proceedings of the 3rd International Conference on Human Systems Engineering and Design (IHSED2020): Future Trends and Applications. Advances in Intelligent Systems and Computing (AISC 1269), P83, DOI 10.1007/978-3-030-58282-1_14
   Marques B., 2021, PROC EUR C COMPUT SU, P1
   Marques B, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P1, DOI 10.1109/ISMAR-Adjunct51615.2020.00016
   Marques B, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P567, DOI 10.1109/VRW52623.2021.00166
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Miller MR, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216290
   Müller J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6481
   Narumi Takuji, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P260, DOI 10.1007/978-3-642-22021-0_29
   Neumann U, 1998, P IEEE VIRT REAL ANN, P4, DOI 10.1109/VRAIS.1998.658416
   Nguyen TV, 2014, CLIN CASE DERMATOL, P1, DOI [10.1007/978-1-4471-4312-3, 10.1109/3DCVE.2014.7160928]
   Nickerson RC, 2013, EUR J INFORM SYST, V22, P336, DOI 10.1057/ejis.2012.26
   Norman M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365691
   Normand Jean-Marie., 2012, Proceedings of the 3rd Augmented Human International Conference, P18, DOI [DOI 10.1145/2160125.2160143, 10.1145/2160125.2160143]
   Obermair F, 2020, 2020 IEEE 7TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA 2020), P942, DOI [10.1109/iciea49774.2020.9102078, 10.1109/ICIEA49774.2020.9102078]
   Olalere T., 2011, METHODOLOGY ACCOUNTI
   Olsson T, 2020, COMPUT SUPP COOP W J, V29, P29, DOI 10.1007/s10606-019-09345-0
   Ong SK, 2008, INT J PROD RES, V46, P2707, DOI 10.1080/00207540601064773
   Ostergaard KJ, 2009, J ENG DESIGN, V20, P57, DOI 10.1080/09544820701499654
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Patel H, 2012, APPL ERGON, V43, P1, DOI 10.1016/j.apergo.2011.04.009
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P218, DOI 10.1109/ISMAR-Adjunct.2017.72
   Regenbrecht H. T., 2002, Virtual Reality, V6, P151, DOI 10.1007/s100550200016
   Sandor C, 2015, Arxiv, DOI arXiv:1512.05471
   Schmutz J, 2015, EUR J WORK ORGAN PSY, V24, P761, DOI 10.1080/1359432X.2015.1018184
   Scott Stacey D., 2015, P 18 ACM C COMP COMP, P319, DOI [DOI 10.1145/2685553.2685564, 10.1145/2685553, DOI 10.1145/2685553]
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   She MR, 2017, INT J HUM-COMPUT INT, V33, P744, DOI 10.1080/10447318.2017.1282188
   Smite D, 2014, EMPIR SOFTW ENG, V19, P105, DOI 10.1007/s10664-012-9217-9
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Stokols D, 2008, AM J PREV MED, V35, pS96, DOI 10.1016/j.amepre.2008.05.003
   Suomela R., 2004, Virtual Real, V8, P71, DOI DOI 10.1007/S10055-004-0139-8
   T_onnis M, 2011, PRINCIPLES AUGMENTED
   Talkad Sukumar Poorna, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3381066
   Teo T, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364238
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Teruel MA, 2017, J SOFTW-EVOL PROC, V29, DOI 10.1002/smr.1858
   TERVEEN LG, 1995, KNOWL-BASED SYST, V8, P67, DOI 10.1016/0950-7051(95)98369-H
   Thomas P. J., 1996, CSCW REQUIREMENTS EV
   Usman M, 2017, INFORM SOFTWARE TECH, V85, P43, DOI 10.1016/j.infsof.2017.01.006
   Wang DX, 2020, ERGONOMICS, V63, P660, DOI 10.1080/00140139.2020.1755060
   Wang P, 2020, ENG COMPUT-GERMANY, V36, P1715, DOI 10.1007/s00366-019-00792-3
   Wang P, 2019, INT J ADV MANUF TECH, V105, P3031, DOI 10.1007/s00170-019-04434-2
   Wang TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1221, DOI [10.1109/VR.2019.8798044, 10.1109/vr.2019.8798044]
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wang X., 2006, Proceedings of the Joint International Conference On Computing and Decision Making, P1836
   Wildman JL, 2012, HUM RESOUR DEV REV, V11, P97, DOI 10.1177/1534484311417561
   Wood D.J., 1991, J. Appl. Behav. Sci., V27, P139
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Yoshioka T, 2001, ACM T INFORM SYST, V19, P431, DOI 10.1145/502795.502798
   Zollmann S, 2021, IEEE T VIS COMPUT GR, V27, P3808, DOI 10.1109/TVCG.2020.2986247
NR 120
TC 49
Z9 50
U1 0
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5113
EP 5133
DI 10.1109/TVCG.2021.3101545
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400080
PM 34347599
DA 2024-11-06
ER

PT J
AU Wang, QW
   Chen, ZT
   Wang, Y
   Qu, HM
AF Wang, Qianwen
   Chen, Zhutian
   Wang, Yong
   Qu, Huamin
TI A Survey on ML4VIS: Applying Machine Learning Advances to Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Pipelines; Human computer interaction; Task
   analysis; Guidelines; Data mining; Analytical models; ML4VIS; machine
   learning; data visualization; survey
ID OF-THE-ART; GRAPH LAYOUTS; GENERATION; DESIGN; IMAGES; CHARTS; MODEL
AB Inspired by the great success of machine learning (ML), researchers have applied ML techniques to visualizations to achieve a better design, development, and evaluation of visualizations. This branch of studies, known as ML4VIS, is gaining increasing research attention in recent years. To successfully adapt ML techniques for visualizations, a structured understanding of the integration of ML4VIS is needed. In this article, we systematically survey 88 ML4VIS studies, aiming to answer two motivating questions: "what visualization processes can be assisted by ML?" and "how ML techniques can be used to solve visualization problems? "This survey reveals seven main processes where the employment of ML techniques can benefit visualizations: Data Processing4VIS, Data-VIS Mapping, Insight Communication, Style Imitation, VIS Interaction, VIS Reading, and User Profiling. The seven processes are related to existing visualization theoretical models in an ML4VIS pipeline, aiming to illuminate the role of ML-assisted visualization in general visualizations. Meanwhile, the seven processes are mapped into main learning tasks in ML to align the capabilities of ML with the needs in visualization. Current practices and future opportunities of ML4VIS are discussed in the context of the ML4VIS pipeline and the ML-VIS mapping. While more studies are still needed in the area of ML4VIS, we hope this article can provide a stepping-stone for future exploration. A web-based interactive browser of this survey is available at https://ml4vis.github.io.
C1 [Wang, Qianwen] Harvard Univ, Cambridge, MA 02138 USA.
   [Chen, Zhutian] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Wang, Yong] Singapore Management Univ, Singapore 188065, Singapore.
   [Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn CSE, Hong Kong, Peoples R China.
C3 Harvard University; University of California System; University of
   California San Diego; Singapore Management University; Hong Kong
   University of Science & Technology
RP Wang, QW (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM qianwen_wang@hms.harvard.edu; zhutian@ucsd.edu; yongwang@smu.edu.sg;
   huamin@cse.ust.hk
RI Wang, Yong/HKF-3903-2023; Wang, Qianwen/GRJ-9435-2022
FU Hong Kong Themebased Research Scheme [T41-709/17N]; Singapore Ministry
   of Education (MOE) Academic Research Fund (AcRF) Tier 1
   [20-C220-SMU-011]
FX This work was supported in part by Hong Kong Themebased Research Scheme
   under Grant T41-709/17N and the Singapore Ministry of Education (MOE)
   Academic Research Fund (AcRF) Tier 1 under Grant 20-C220-SMU-011. The
   authors would like to thank all the anonymous reviewers for their
   constructive comments.
CR Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Al-Zaidy R. A., 2016, WORKSH 30 AAAI C ART, P658
   Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   Aupetit M, 2016, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2016.7465244
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brown ET, 2014, IEEE T VIS COMPUT GR, V20, P1663, DOI 10.1109/TVCG.2014.2346575
   Bylinskii Z, 2017, Arxiv, DOI arXiv:1709.09215
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Card SK., 1999, READINGS INFORM VISU
   Chang R, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.22
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671
   Chegini M, 2018, COMPUT GRAPH FORUM, V37, P99, DOI 10.1111/cgf.13404
   Chen C, 2020, IEEE T VIS COMPUT GR, V26, P216, DOI 10.1109/TVCG.2019.2934806
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Chowdhary KR., 2020, Introduction to Artificial Intelligence
   Cooke L, 2006, STC'S 53RD ANNUAL CONFERENCE PROCEEDINGS 2005, P252
   Correll M., 2017, PROC WORKSHOP DEALIN
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Fan CR, 2019, IEEE COMPUT GRAPH, V39, P28, DOI 10.1109/MCG.2018.2881502
   Fan CR, 2018, COMPUT GRAPH FORUM, V37, P111, DOI 10.1111/cgf.13405
   Fan CG, 2019, PROCEEDINGS OF 2019 FAR EAST NDT NEW TECHNOLOGY & APPLICATION FORUM (FENDT), P1, DOI [10.1109/fendt47723.2019.8962705, 10.1109/FENDT47723.2019.8962705]
   Fosco C., 2020, P 33 ANN ACM S US IN, P249, DOI DOI 10.1145/3379337.3415825
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Fu X, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P126, DOI [10.1109/visual.2019.8933570, 10.1109/VISUAL.2019.8933570]
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gan G., 2020, Data Clustering: Theory, Algorithms, and Applications, Vsecond
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Goodfellow I, 2017, Arxiv, DOI arXiv:1701.00160
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Gramazio CC, 2018, IEEE T VIS COMPUT GR, V24, P2270, DOI 10.1109/TVCG.2017.2734659
   Grotov A, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1215, DOI 10.1145/2911451.2914798
   Gui J, 2020, Arxiv, DOI [arXiv:2001.06937, 10.1109/TKDE.2021.3130191, DOI 10.1109/TKDE.2021.3130191]
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Hazarika S, 2020, IEEE T VIS COMPUT GR, V26, P34, DOI 10.1109/TVCG.2019.2934591
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Horvitz E, 1999, P CHI, P159, DOI DOI 10.1145/302979.303030
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   Huang ZS, 2020, IEEE T VIS COMPUT GR, V26, P1256, DOI 10.1109/TVCG.2019.2934671
   Jo J, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P136, DOI [10.1109/visual.2019.8933670, 10.1109/VISUAL.2019.8933670]
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kafle K, 2020, IEEE WINT CONF APPL, P1487, DOI 10.1109/WACV45572.2020.9093494
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou S.E., 2018, P INT C LEARN REPR I
   Kassel J., 2019, PROC 21 EUROGRAPHICS, P85
   Keim D.A., 2015, DAGSTUHL REPORTS, V5
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Key A., 2012, ACM, P681
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim D, 2018, PROC CVPR IEEE, P4167, DOI 10.1109/CVPR.2018.00438
   Kim N. W., 2019, THESIS HARVARD U CAM
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lalle Sebastien., 2015, Proceedings of the 20th International Conference on Intelligent User Interfaces, P357, DOI [10.1145/2678025.2701376, DOI 10.1145/2678025.2701376]
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P2482, DOI 10.1109/TVCG.2018.2834341
   Liu TF, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P569, DOI 10.1145/3242587.3242650
   Lu M., 2020, PROC ACMCONF HUM FAC, P1
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Madan S, 2018, Arxiv, DOI arXiv:1807.10441
   McCamish B, 2018, INT CONF MANAGE DATA, P83
   Milo T, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P576, DOI 10.1145/3219819.3219848
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mohammed H, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2841, DOI 10.1145/3318464.3384405
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Mutlu B, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2983923
   Nicolas P.R., 2015, SCALA MACHINE LEARNI
   Nielsen J., 1990, SIGCHI Bulletin, P249
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Oppermann M, 2021, IEEE T VIS COMPUT GR, V27, P495, DOI 10.1109/TVCG.2020.3030387
   Ottley A, 2019, COMPUT GRAPH FORUM, V38, P41, DOI 10.1111/cgf.13670
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/visual.2019.8933759, 10.1109/VISUAL.2019.8933759]
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Saha DK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2672
   Saket B., 2018, arXiv
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Savvides R, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1509, DOI 10.1145/3292500.3330994
   Scholar G., GOOGL SCHOL TOP PUBL
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Siddiqui T, 2018, PROC VLDB ENDOW, V11, P1962, DOI 10.14778/3229863.3236235
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Steichen B., 2013, P 2013 INT C INT US, P317, DOI [10.1145/2449396.2449439, DOI 10.1145/2449396.2449439]
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Toker D., 2014, P 19 INT C INT US IN, P105, DOI DOI 10.1145/2557500.2557524
   Valli A, 2008, MULTIMED TOOLS APPL, V38, P295, DOI 10.1007/s11042-007-0190-z
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P81, DOI 10.1109/VISUAL.2019.8933779
   Wang YF, 2021, IEEE T VIS COMPUT GR, V27, P1301, DOI 10.1109/TVCG.2020.3030374
   Wang YF, 2020, IEEE T VIS COMPUT GR, V26, P960, DOI 10.1109/TVCG.2019.2934369
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Yang Q, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173704
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao NX, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376618
   Zhao ZG, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1671, DOI 10.1145/3035918.3058749
   Zheng GJ, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P167, DOI 10.1145/3178876.3185994
   Zhou MY, 2021, Arxiv, DOI arXiv:2008.11015
   Zhou TF, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3704
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 148
TC 43
Z9 46
U1 1
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5134
EP 5153
DI 10.1109/TVCG.2021.3106142
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400081
PM 34437063
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Luong, T
   Lecuyer, A
   Martin, N
   Argelaguet, F
AF Luong, Tiffany
   Lecuyer, Anatole
   Martin, Nicolas
   Argelaguet, Ferran
TI A Survey on Affective and Cognitive VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Physiology; Load modeling; Virtual environments; Solid
   modeling; Mood; Measurement; Virtual reality; affective computing;
   affective states; cognitive states; emotions; mental workload;
   physiological measures; social and behavioral sciences
ID REALITY EXPOSURE THERAPY; VIRTUAL-REALITY; PUBLIC SPEAKING;
   SELF-ASSESSMENT; ANXIETY; EMOTION; WORKLOAD; ENVIRONMENTS; TASK; LOAD
AB In Virtual Reality (VR), users can be immersed in emotionally intense and cognitively engaging experiences. Yet, despite strong interest from scholars and a large amount of work associating VR and Affective and Cognitive States (ACS), there is a clear lack of structured and systematic form in which this research can be classified. We define "Affective and Cognitive VR" to relate to works which (1) induce ACS, (2) recognize ACS, or (3) exploit ACS by adapting virtual environments based on ACS measures. This survey clarifies the different models of ACS, presents the methods for measuring them with their respective advantages and drawbacks in VR, and showcases Affective and Cognitive VR studies done in an Immersive Virtual Environment (IVE) in a non-clinical context. Our article covers the main research lines in Affective and Cognitive VR. We provide a comprehensive list of references with the analysis of 63 research articles and summarize future works directions.
C1 [Luong, Tiffany] ETH Zrich, CH-8092 Zurich, Switzerland.
   [Lecuyer, Anatole; Argelaguet, Ferran] Univ Rennes, CNRS, IRISA, INRIA, F-35000 Rennes, France.
   [Martin, Nicolas] UGA, F-38400 St Martin Dheres, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Inria; Communaute Universite Grenoble Alpes; Universite Grenoble
   Alpes (UGA)
RP Luong, T (corresponding author), ETH Zrich, CH-8092 Zurich, Switzerland.
EM tiffany.luong@inf.ethz.ch; anatole.lecuyer@inria.fr;
   Nicolas.Martin6@univ-grenoble-alpes.fr; ferran.argelaguet@inria.fr
OI Martin, Nicolas/0000-0002-2788-1042
FU Future Investments program of the French National Research Agency
   [ANR-07-A0-AIRT]
FX This work was supported by b-com, an institute of research and
   technology dedicated to digital technologies and from the Future
   Investments program of the French National Research Agency under Grant
   ANR-07-A0-AIRT.
CR Abdessalem H. B., 2018, PROC 31 INT FLAIRS C, P276
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alcaniz M., 2003, PSYCHNOLOGY J, V1, P141
   Alsina-Jurnet I, 2010, INT J HUM-COMPUT ST, V68, P788, DOI 10.1016/j.ijhcs.2010.07.001
   Anderson AP, 2017, AEROSP MED HUM PERF, V88, P520, DOI 10.3357/AMHP.4747.2017
   Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Ayaz H, 2012, NEUROIMAGE, V59, P36, DOI 10.1016/j.neuroimage.2011.06.023
   Ayaz H, 2009, LECT NOTES ARTIF INT, V5638, P699, DOI 10.1007/978-3-642-02812-0_79
   Aymerich-Franch L, 2010, CYBERPSYCH BEH SOC N, V13, P649, DOI 10.1089/cyber.2009.0412
   Baker RSJD, 2010, INT J HUM-COMPUT ST, V68, P223, DOI 10.1016/j.ijhcs.2009.12.003
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Baños RM, 2008, CYBERPSYCHOL BEHAV, V11, P1, DOI 10.1089/cpb.2007.9936
   Baños RM, 2006, LECT NOTES COMPUT SC, V3962, P7
   Barrett L. F., 2017, EMOTIONS ARE MADE SE
   Beedie CJ, 2005, COGNITION EMOTION, V19, P847, DOI 10.1080/02699930541000057
   Ben Abdessalem H, 2019, LECT NOTES COMPUT SC, V11528, P214, DOI 10.1007/978-3-030-22244-4_26
   Bergström I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148060
   Bernal G, 2017, P 2017 CHI C HUM FAC, P2395
   Bernal G, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P160, DOI 10.1145/3267242.3267268
   Bernhardt KA, 2019, APPL ERGON, V77, P83, DOI 10.1016/j.apergo.2019.01.008
   Bersak D., 2001, PROC PAPER UBIQUITOU
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Bontchev B, 2016, CYBERN INF TECHNOL, V16, P3, DOI 10.1515/cait-2016-0032
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Boucsein W., 1992, Electrodermal activity
   Bourdin P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169343
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bradley MM, 1999, The International affective digitized sounds (IADS): stimuli, instruction manual and affective ratings, DOI DOI 10.1093/schbul/sbp030
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Cain B., 2007, RTOTRHFM121
   Cebeci B, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1893
   Cheetham M, 2009, FRONT HUM NEUROSCI, V3, DOI 10.3389/neuro.09.029.2009
   Chen H., 2017, Proceedings of the 29th Australian conference on computer-human interaction, P108, DOI DOI 10.1145/3152771.3152783
   Chen H, 2017, ICAT EGVE 2017, DOI [10.2312/EGVE.20171355, DOI 10.2312/EGVE.20171355]
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Collins J, 2019, INT SYM MIX AUGMENT, P351, DOI 10.1109/ISMAR.2019.00033
   Coral M, 2016, Analyzing cognitive workload through eye-related measurements: A meta-analysis
   DALE AM, 1993, J COGNITIVE NEUROSCI, V5, P162, DOI 10.1162/jocn.1993.5.2.162
   Dengel A., 2019, Immersive learing research network 5th international conference, P185
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Desmet P., 2002, DESIGNING EMOTIONS
   Dey A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P101, DOI 10.1145/3242671.3242676
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/VR.2019.8797840, 10.1109/vr.2019.8797840]
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Elkin C, 2020, ADV INTELL SYST COMP, V953, P185, DOI 10.1007/978-3-030-20473-0_19
   Fairclough SH, 2005, INT J PSYCHOPHYSIOL, V56, P171, DOI 10.1016/j.ijpsycho.2004.11.003
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Felnhofer A, 2015, INT J HUM-COMPUT ST, V82, P48, DOI 10.1016/j.ijhcs.2015.05.004
   Felnhofer A, 2014, CYBERPSYCH BEH SOC N, V17, P310, DOI 10.1089/cyber.2013.0472
   Galy E, 2012, INT J PSYCHOPHYSIOL, V83, P269, DOI 10.1016/j.ijpsycho.2011.09.023
   Gerry L, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188479
   Gilleade K., 2005, PROC INT C DIGRA 200
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   HART S G, 1988, P139
   HEDBERG AG, 1972, PROF PSYCHOL, V3, P389, DOI 10.1037/h0020743
   Houzangbe S., 2018, P 13 INT C FOUND DIG, P1
   Hupont I, 2013, PATTERN ANAL APPL, V16, P41, DOI 10.1007/s10044-012-0286-6
   Jack RE, 2013, VIS COGN, V21, P1248, DOI 10.1080/13506285.2013.835367
   Kalawsky R.S., 1996, EXPLOITING VIRTUAL R
   Kaplan S., 2013, Research Methods in Occupational Health Psychology. Mensurement, Design, P61
   Kawahara K, 2016, 13TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2016), DOI 10.1145/3001773.3001813
   KEMPER TD, 1987, AM J SOCIOL, V93, P263, DOI 10.1086/228745
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kitson A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01354
   Kivikangas JM, 2011, J GAMING VIRTUAL WOR, V3, P181, DOI 10.1386/jgvw.3.3.181_1
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Kolakowska A., 2015, Information Systems Development and Applications, P55
   Kothgassner OD, 2016, COMPUT HUM BEHAV, V62, P124, DOI 10.1016/j.chb.2016.03.081
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Kreibig SD, 2010, BIOL PSYCHOL, V84, P394, DOI 10.1016/j.biopsycho.2010.03.010
   Lang P.J., 1997, NIMH CTR STUDY EMOT, V1, P39
   Leventhal H., 1987, COGNITION EMOTION, V1, P3, DOI DOI 10.1080/02699938708408361
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li R, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P180, DOI 10.1145/3267242.3267265
   Li Y, 2015, IEEE INT SYMP SIGNAL, P57, DOI 10.1109/ISSPIT.2015.7394401
   Ling Y, 2012, PRESENCE-TELEOP VIRT, V21, P254, DOI 10.1162/PRES_a_00111
   Liu CC, 2008, IEEE T ROBOT, V24, P883, DOI 10.1109/TRO.2008.2001362
   Liu CC, 2009, INT J HUM-COMPUT INT, V25, P506, DOI 10.1080/10447310902963944
   Luong T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P662, DOI [10.1109/VR46266.2020.00-15, 10.1109/VR46266.2020.1581086856229]
   Luong T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P809, DOI [10.1109/vr.2019.8798029, 10.1109/VR.2019.8798029]
   Macedonio MF, 2007, CYBERPSYCHOL BEHAV, V10, P508, DOI 10.1089/cpb.2007.9997
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   Malbos E, 2012, PRESENCE-TELEOP VIRT, V21, P268, DOI 10.1162/PRES_a_00112
   Mania K, 2006, IEEE T VIS COMPUT GR, V12, P396, DOI 10.1109/TVCG.2006.55
   Marín-Morales J, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223881
   Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mavridou I, 2018, PROCEEDINGS OF THE WORKSHOP ON HUMAN-HABITAT FOR HEALTH (H3'18): HUMAN-HABITAT MULTIMODAL INTERACTION FOR PROMOTING HEALTH AND WELL-BEING IN THE INTERNET OF THINGS ERA, DOI 10.1145/3279963.3279969
   Mavridou I, 2017, P IEEE VIRT REAL ANN, P441, DOI 10.1109/VR.2017.7892369
   McCraty Rollin, 2015, Glob Adv Health Med, V4, P46, DOI 10.7453/gahmj.2014.073
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Munoz J.E., 2016, e-Health Networking, Applications and Services (Healthcom), 2016 IEEE 18th International Conference on, P1, DOI DOI 10.1109/HEALTHCOM.2016.7749512
   Nacke LE, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P103
   Noroozi F, 2018, Arxiv, DOI arXiv:1801.07481
   Novak D, 2012, INTERACT COMPUT, V24, P154, DOI 10.1016/j.intcom.2012.04.003
   O'Donnell R.D., 1986, Handbook of Perception and Human Performance: Cognitive Processes and Performance, V2
   Oliveira T, 2018, ADV INTELL SYST, V588, P71, DOI 10.1007/978-3-319-60582-1_8
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   ORTONY A, 1990, PSYCHOL REV, V97, P315, DOI 10.1037/0033-295X.97.3.315
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Osking H., 2019, IMMERSIVE LEARNING R, P199
   Paas F, 2003, EDUC PSYCHOL-US, V38, P63, DOI 10.1207/S15326985EP3801_8
   PAAS FGWC, 1994, EDUC PSYCHOL REV, V6, P351, DOI 10.1007/BF02213420
   Pallavicini F, 2018, LECT NOTES COMPUT SC, V10908, P87, DOI 10.1007/978-3-319-92052-8_8
   Pan Y, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364270
   Parsons TD, 2008, J BEHAV THER EXP PSY, V39, P250, DOI 10.1016/j.jbtep.2007.07.007
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   Parsons TD, 2012, IEEE T CONSUM ELECTR, V58, P197, DOI 10.1109/TCE.2012.6227413
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Picard R. W., 1995, Affective computing
   Plutchik Robert, 1991, The emotions
   Powers MB, 2008, J ANXIETY DISORD, V22, P561, DOI 10.1016/j.janxdis.2007.04.006
   Putze F, 2019, IEEE ENG MED BIO, P3103, DOI [10.1109/EMBC.2019.8856386, 10.1109/embc.2019.8856386]
   REID G B, 1988, P185
   Riva G, 2005, CYBERPSYCHOL BEHAV, V8, P220, DOI 10.1089/cpb.2005.8.220
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Robinette P, 2019, OCEANS-IEEE, DOI 10.1109/oceanse.2019.8867468
   Rose FD, 2005, CYBERPSYCHOL BEHAV, V8, P241, DOI 10.1089/cpb.2005.8.241
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Ruthrof Horst., 2015, The Body in Language
   Samson AC, 2016, COGNITION EMOTION, V30, P827, DOI 10.1080/02699931.2015.1031089
   Sanz F. A., FRONTI ROBOT, V2
   Scherer K. R., 1984, APPROACHES EMOTION, P26
   Scherer KR, 2005, SOC SCI INFORM, V44, P695, DOI 10.1177/0539018405058216
   Schmidt LA, 2001, COGNITION EMOTION, V15, P487, DOI 10.1080/0269993004200187
   Scholkmann F, 2014, NEUROIMAGE, V85, P6, DOI 10.1016/j.neuroimage.2013.05.004
   Schwerdtfeger A, 2004, INT J PSYCHOPHYSIOL, V52, P217, DOI 10.1016/j.ijpsycho.2003.10.008
   Sequeira H, 2009, INT J PSYCHOPHYSIOL, V71, P50, DOI 10.1016/j.ijpsycho.2008.07.009
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M., 2003, PRES 2003 6 ANN INT, V157
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2006, CYBERPSYCHOL BEHAV, V9, P627, DOI 10.1089/cpb.2006.9.627
   Spielberger CharlesD., 1999, Measuring anxiety and anger with the State-Trait Anxiety Inventory (STAI) and the State-Trait Anger Expression Inventory (STAXI)
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Stinson C, 2014, IEEE T VIS COMPUT GR, V20, P606, DOI 10.1109/TVCG.2014.23
   Sundar SS, 2017, CYBERPSYCH BEH SOC N, V20, P672, DOI 10.1089/cyber.2017.0271
   Suzuki K, 2017, P IEEE VIRT REAL ANN, P177, DOI 10.1109/VR.2017.7892245
   Tattersall AJ, 1996, ERGONOMICS, V39, P740, DOI 10.1080/00140139608964495
   Teo Grace, 2020, Human-Intelligent Systems Integration, V2, P1, DOI 10.1007/s42454-019-00005-8
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Tsang PS, 1996, ERGONOMICS, V39, P358, DOI 10.1080/00140139608964470
   Waard D.D., 1996, MEASUREMENT DRIVERSM
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wickens CD, 2008, HUM FACTORS, V50, P449, DOI 10.1518/001872008X288394
   Wu DR, 2010, IEEE T AFFECT COMPUT, V1, P109, DOI 10.1109/T-AFFC.2010.12
   Yerkes RM, 1908, J COMP NEUROL PSYCHO, V18, P459, DOI 10.1002/cne.920180503
   Zahabi M, 2020, VIRTUAL REAL-LONDON, V24, P725, DOI 10.1007/s10055-020-00434-w
   Zeagler C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P150, DOI 10.1145/3123021.3123042
   Zijlstra F. R. H., 1993, THESIS DELFT NETHERL
NR 158
TC 8
Z9 8
U1 7
U2 45
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5154
EP 5171
DI 10.1109/TVCG.2021.3110459
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400082
PM 34495833
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Livesu, M
   Cherchi, G
   Scateni, R
   Attene, M
AF Livesu, Marco
   Cherchi, Gianmarco
   Scateni, Riccardo
   Attene, Marco
TI Deterministic Linear Time Constrained Triangulation Using Simplified
   Earcut
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ear; Complexity theory; Time complexity; Force; Encoding; Convergence;
   Testing; Constrained triangulation; tessellation; segment insertion;
   earcut; CDT
ID DELAUNAY TRIANGULATION; SIMPLE POLYGON; ALGORITHM
AB Triangulation algorithms that conform to a set of non-intersecting input segments typically proceed in an incremental fashion, by inserting points first, and then segments. Inserting a segment amounts to: (1) deleting all the triangles it intersects; (2) filling the so generated hole with two polygons that have the wanted segment as shared edge; (3) triangulate each polygon separately. In this article we prove that these polygons are such that all their convex vertices but two can be used to form triangles in an earcut fashion, without the need to check whether other polygon points are located within each ear. The fact that any simple polygon contains at least three convex vertices guarantees the existence of a valid ear to cut, ensuring convergence. Not only this translates to an optimal deterministic linear time triangulation algorithm, but such algorithm is also trivial to implement. We formally prove the correctness of our approach, also validating it in practical applications and comparing it with prior art.
C1 [Livesu, Marco; Attene, Marco] CNR IMATI, Math & Comp Sci, I-27100 Genoa, Italy.
   [Cherchi, Gianmarco; Scateni, Riccardo] Univ Cagliari, Math & Comp Sci, I-09124 Cagliari, CA, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Matematica
   Applicata e Tecnologie Informatiche "Enrico Magenes" (IMATI-CNR);
   University of Cagliari
RP Cherchi, G (corresponding author), Univ Cagliari, Math & Comp Sci, I-09124 Cagliari, CA, Italy.
EM marco.livesu@gmail.com; cherchi.gianmarco@gmail.com; riccardo@unica.it;
   marco.attene@ge.imati.cnr.it
RI Livesu, Marco/AAV-9100-2020; Scateni, Riccardo/H-7803-2015
OI Scateni, Riccardo/0000-0002-0950-7372; CHERCHI,
   GIANMARCO/0000-0003-2029-1119
FU PON RI 2014-2020 [AIM1895943-1]; EU ERC Advanced Grant CHANGE [694515]
FX Gianmarco Cherchi gratefully acknowledges the support to his research by
   PON R&I 2014-2020 AIM1895943-1. Marco Livesu and Marco Attene's work was
   supported in part by EU ERC Advanced Grant CHANGE No. 694515.
CR Amato NM, 2001, DISCRETE COMPUT GEOM, V26, P245, DOI 10.1007/s00454-001-0027-x
   AMATO NM, 2000, P 16 ANN ACM S COMP, P201
   Anglada MV, 1997, COMPUT GRAPH, V21, P215, DOI 10.1016/S0097-8493(96)00085-4
   [Anonymous], 2008, GEOMETRIC TOOLS
   ASANO T, 1986, J ALGORITHM, V7, P221, DOI 10.1016/0196-6774(86)90005-2
   AVIS D, 1981, IEEE T COMPUT, V30, P910, DOI 10.1109/TC.1981.1675729
   Boissonnat JD, 2002, COMP GEOM-THEOR APPL, V22, P5, DOI 10.1016/S0925-7721(01)00054-2
   CHAZELLE B, 1991, DISCRETE COMPUT GEOM, V6, P485, DOI 10.1007/BF02574703
   Cherchi G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417818
   Chew L. P, 1990, TR90147 DARTM COLL D
   Chin F., 1998, SIAM Journal on Computing, V28, P471, DOI 10.1137/S0097539795285916
   DEFLORIANI L, 1992, CVGIP-GRAPH MODEL IM, V54, P290, DOI 10.1016/1049-9652(92)90076-A
   Eder G, 2018, COMP GEOM-THEOR APPL, V73, P15, DOI 10.1016/j.comgeo.2018.01.004
   FOURNIER A, 1984, ACM T GRAPHIC, V3, P153, DOI 10.1145/357337.357341
   GAREY MR, 1978, INFORM PROCESS LETT, V7, P175, DOI 10.1016/0020-0190(78)90062-5
   Held M, 2001, ALGORITHMICA, V30, P563, DOI 10.1007/s00453-001-0028-4
   Kao T.C., 1992, PROC 4 CANADIAN C CO, P170
   LEE DT, 1986, DISCRETE COMPUT GEOM, V1, P201, DOI 10.1007/BF02187695
   Livesu Marco, 2019, Transactions on Computational Science XXXIV. Lecture Notes in Computer Science (LNCS 11820), P64, DOI 10.1007/978-3-662-59958-7_4
   MEISTERS GH, 1975, AM MATH MON, V82, P648, DOI 10.2307/2319703
   RUPPERT J, 1992, DISCRETE COMPUT GEOM, V7, P227, DOI 10.1007/BF02187840
   Schonhardt E, 1928, MATH ANN, V98, P309, DOI 10.1007/BF01451597
   Shewchuk J.R., 1996, WORKSH APPL COMP GEO, P203
   Shewchuk JR, 2015, COMP GEOM-THEOR APPL, V48, P554, DOI 10.1016/j.comgeo.2015.04.006
   Shewchuk JR, 1997, DISCRETE COMPUT GEOM, V18, P305, DOI 10.1007/PL00009321
   TARJAN RE, 1988, SIAM J COMPUT, V17, P143, DOI 10.1137/0217010
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
NR 27
TC 0
Z9 0
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5172
EP 5177
DI 10.1109/TVCG.2021.3070046
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400083
PM 33788688
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Koch, MK
   Kelly, PHJ
   Vincent, PE
AF Koch, Marius K.
   Kelly, Paul H. J.
   Vincent, Peter E.
TI Identification and Classification of Off-Vertex Critical Points for
   Contour Tree Construction on Unstructured Meshes of Hexahedra
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Isosurfaces; Three-dimensional displays; Visualization; Topology;
   Inspection; Buildings; Isosurface; critical points; hexahedra; contour
   tree
AB The topology of isosurfaces changes at isovalues of critical points, making such points an important feature when building contour trees or Morse-Smale complexes. Hexahedral elements with linear interpolants can contain additional off-vertex critical points in element bodies and on element faces. Moreover, a point on the face of a hexahedron which is critical in the element-local context is not necessarily critical in the global context. Weber et al. (2002) introduce a method to determine whether critical points on faces are also critical in the global context, based on the gradient of the asymptotic decider (G. M. Nielson and B. Hamann) (1991) in each element that shares the face. However, as defined, the method of Weber et al. contains an error, and can lead to incorrect results. In this work we correct the error.
C1 [Koch, Marius K.; Vincent, Peter E.] Imperial Coll, Dept Aeronaut, London SW7 2BX, England.
   [Kelly, Paul H. J.] Imperial Coll, Dept Comp, London SW7 2BX, England.
C3 Imperial College London; Imperial College London
RP Vincent, PE (corresponding author), Imperial Coll, Dept Aeronaut, London SW7 2BX, England.
EM marius.koch16@imperial.ac.uk; p.kelly@imperial.ac.uk;
   p.vincent@imperial.ac.uk
RI Vincent, Peter/B-9288-2011
OI Vincent, Peter/0000-0002-1314-8827
FU Leverhulme Trust through Philip Leverhulme Prize; EPSRC [EP/L000407/1,
   EP/R029423/1, EP/K027379/1, EP/R030340/1]; EPSRC [EP/L000407/1,
   EP/K027379/1, EP/R030340/1, EP/R029423/1] Funding Source: UKRI
FX The work of Marius K. Koch and Peter E. Vincent was supported by the
   Leverhulme Trust through Philip Leverhulme Prize. The work of Peter E.
   Vincent and Paul H. J. Kelly was supported by the EPSRC under Grants
   EP/L000407/1, EP/R029423/1, EP/K027379/1, and EP/R030340/1.
CR Chernyaev E., 1995, MARCHING CUBES 33 CO
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   NIELSON GM, 1991, VISUALIZATION 91, P83
   Weber G. H., 2003, THESIS U KAISERSLAUT
   Weber GH, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P171, DOI 10.1109/VISUAL.2002.1183772
NR 5
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC 1
PY 2022
VL 28
IS 12
BP 5178
EP 5180
DI 10.1109/TVCG.2021.3074438
PG 3
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4XK
UT WOS:000873836400084
PM 33877978
DA 2024-11-06
ER

PT J
AU Wang, Y
   Hou, ZT
   Shen, LX
   Wu, TS
   Wang, JQ
   Huang, H
   Zhang, HD
   Zhang, DM
AF Wang, Yun
   Hou, Zhitao
   Shen, Leixian
   Wu, Tongshuang
   Wang, Jiaqi
   Huang, He
   Zhang, Haidong
   Zhang, Dongmei
TI Towards Natural Language-Based Visualization Authoring
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization authoring; Natural language interface; Natural language
   understanding
ID MULTIMODAL INTERACTION; EXPLORATION; SPEECH; DESIGN
AB A key challenge to visualization authoring is the process of getting familiar with the complex user interfaces of authoring tools. Natural Language Interface (NLI) presents promising benefits due to its learnability and usability. However, supporting NLIs for authoring tools requires expertise in natural language processing, while existing NLIs are mostly designed for visual analytic workflow. In this paper, we propose an authoring-oriented NLI pipeline by introducing a structured representation of users' visualization editing intents, called editing actions, based on a formative study and an extensive survey on visualization construction tools. The editing actions are executable, and thus decouple natural language interpretation and visualization applications as an intermediate layer. We implement a deep learning-based NL interpreter to translate NL utterances into editing actions. The interpreter is reusable and extensible across authoring tools. The authoring tools only need to map the editing actions into tool-specific operations. To illustrate the usages of the NL interpreter, we implement an Excel chart editor and a proof-of-concept authoring tool, VisTalk. We conduct a user study with VisTalk to understand the usage patterns of NL-based authoring systems. Finally, we discuss observations on how users author charts with natural language, as well as implications for future research.
C1 [Wang, Yun; Hou, Zhitao; Shen, Leixian; Wang, Jiaqi; Huang, He; Zhang, Haidong; Zhang, Dongmei] Microsoft Res Asia MSRA, Beijing, Peoples R China.
   [Shen, Leixian] Tsinghua Univ, Beijing, Peoples R China.
   [Wu, Tongshuang] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Wang, Jiaqi] Univ Oxford, Oxford, England.
C3 Tsinghua University; Carnegie Mellon University; University of Oxford
RP Wang, Y (corresponding author), Microsoft Res Asia MSRA, Beijing, Peoples R China.
EM wangyun@microsoft.com; zhith@microsoft.com; slx20@mails.tsinghua.edu.cn;
   sherryw@cs.cmu.edu; jiaqi.wang@cx.ox.ac.uk
OI Shen, Leixian/0000-0003-1084-4912
CR Affolter K, 2019, VLDB J, V28, P793, DOI 10.1007/s00778-019-00567-8
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Androutsopoulos Ion., 1995, Natural Language Engineering, V1, P29, DOI [10.1017/S135132490000005X, DOI 10.1017/S135132490000005X, 10.1017/S0269888900005476]
   [Anonymous], 2022, Tableau software: Business intelligence and analytics
   [Anonymous], 2022, Power bi q & a
   [Anonymous], 2022, Seqeval python library
   [Anonymous], 2022, Ibm watson analytics
   Aurisano J., 2016, IEEE VIS, V16, P1
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhamdhere K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P493, DOI 10.1145/3025171.3025227
   Diehl A., 2020, arXiv
   Fast E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174047
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Guo D, 2014, IEEE W SP LANG TECH, P554, DOI 10.1109/SLT.2014.7078634
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Iyyer M, 2018, Arxiv, DOI arXiv:1804.06059
   Kandogan E., 2016, Electronic Imaging, V28, P1, DOI 10.2352/ISSN.2470-1173.2016.16.HVEI-132
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kumar Abhinav, 2017, SEMDIAL 2017 SAARDIA, P41, DOI [10.21437/SemDial.2017-5, DOI 10.21437/SEMDIAL.2017-5]
   Lafferty J., 2001, PROC ICML
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Laput Gierad, 2013, C HUM FACT COMP SYST, P2185, DOI [10.1145/2470654.2481301, DOI 10.1145/2470654.2481301]
   Li YY, 2007, ACM T DATABASE SYST, V32, DOI 10.1145/1292609.1292620
   Likert R., 1932, ARCH PSYCHOL, V140, P1
   Liu B, 2016, INTERSPEECH, P685, DOI 10.21437/Interspeech.2016-1352
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Luo YY, 2021, INT CONF MANAGE DATA, P1235, DOI 10.1145/3448016.3457261
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Malandrakis N, 2019, Arxiv, DOI arXiv:1910.03487
   Mauri M, 2017, P 12 BIANN C IT SIGC, P1, DOI DOI 10.1145/3125571.3125585
   microsoft, Microsoft excel javascript api
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Oviatt S, 1997, HUM-COMPUT INTERACT, V12, P93, DOI 10.1207/s15327051hci1201&2_4
   Özcan F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2629, DOI 10.1145/3318464.3383128
   Ragavan SS, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P345, DOI 10.1145/3490099.3511161
   Ramshaw L.A., 1999, TEXT SPEECH LANG TEC, P157
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Riccardi G, 2005, IEEE T SPEECH AUDI P, V13, P504, DOI 10.1109/TSA.2005.848882
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Sawicki J., 2022, arXiv
   Setlur Vidya, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P966, DOI 10.1145/3379337.3415813
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Srinivasan A., 2021, P 34 ANN ACM S US IN, P1
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   Srinivasan A, 2019, PROCEEDINGS OF IUI 2019, P661, DOI 10.1145/3301275.3302292
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Srinivasan Arjun, 2017, P EUROVIS, P55, DOI [10.2312/ eurovisshort.20171133, DOI 10.2312/EUROVISSHORT.20171133]
   Stolte C, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P5, DOI 10.1109/INFVIS.2000.885086
   ThoughtSpot, 2020, About us
   Vaswani A., 2017, Advances in neural information processing systems
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wen Z, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P187, DOI 10.1109/INFVIS.2005.1532146
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Xu PY, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P78, DOI 10.1109/ASRU.2013.6707709
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Zhang X, 2016, IJCAI, P2993
   Zhong VC, 2017, Arxiv, DOI arXiv:1709.00103
NR 75
TC 21
Z9 23
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 1222
EP 1232
DI 10.1109/TVCG.2022.3209357
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E0N1J
UT WOS:001300050200001
PM 36197854
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ulbrich, P
   Waldner, M
   Furmanová, K
   Marques, SM
   Bednár, D
   Kozlíková, B
   Byska, J
AF Ulbrich, Pavol
   Waldner, Manuela
   Furmanova, Katarina
   Marques, Sergio M.
   Bednar, David
   Kozlikova, Barbora
   Byska, Jan
TI sMolBoxes: Dataflow Model for Molecular Dynamics Exploration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Molecular dynamics; structure; node-based visualization; progressive
   analytics
ID TUNNELS; VISUALIZATION; ENVIRONMENT; DESIGN
AB We present sMolBoxes, a dataflow representation for the exploration and analysis of long molecular dynamics (MD) simulations. When MD simulations reach millions of snapshots, a frame-by-frame observation is not feasible anymore. Thus, biochemists rely to a large extent only on quantitative analysis of geometric and physico-chemical properties. However, the usage of abstract methods to study inherently spatial data hinders the exploration and poses a considerable workload. sMolBoxes link quantitative analysis of a user-defined set of properties with interactive 3D visualizations. They enable visual explanations of molecular behaviors, which lead to an efficient discovery of biochemically significant parts of the MD simulation. sMolBoxes follow a node-based model for flexible definition, combination, and immediate evaluation of properties to be investigated. Progressive analytics enable fluid switching between multiple properties, which facilitates hypothesis generation. Each sMolBox provides quick insight to an observed property or function, available in more detail in the bigBox View. The case studies illustrate that even with relatively few sMolBoxes, it is possible to express complex analytical tasks, and their use in exploratory analysis is perceived as more efficient than traditional scripting-based methods.
C1 [Ulbrich, Pavol; Furmanova, Katarina; Kozlikova, Barbora; Byska, Jan] Masaryk Univ, Fac Informat, Visitlab, Brno, Czech Republic.
   [Byska, Jan] Univ Bergen, Bergen, Norway.
   [Waldner, Manuela] TU Wien, Vienna, Austria.
   [Marques, Sergio M.; Bednar, David] Masaryk Univ, Loschmidt Labs, Dept Expt Biol, Brno, Czech Republic.
   [Marques, Sergio M.; Bednar, David] Masaryk Univ, RECETOX, Fac Sci, Brno, Czech Republic.
   [Marques, Sergio M.; Bednar, David] St Annes Univ Hosp Brno, Int Clin Res Ctr, Brno, Czech Republic.
C3 Masaryk University Brno; University of Bergen; Technische Universitat
   Wien; Masaryk University Brno; Masaryk University Brno; St Anne's
   University Hospital Brno (FNUSA); St Anne's University Hospital Brno
   (FNUSA-ICRC)
RP Byska, J (corresponding author), Masaryk Univ, Fac Informat, Visitlab, Brno, Czech Republic.; Byska, J (corresponding author), Univ Bergen, Bergen, Norway.
EM byska@mail.muni.cz
RI Bednar, David/ABF-5943-2020; Waldner, Manuela/JZC-9267-2024; Marques,
   Sergio/H-8685-2012
OI Ulbrich, Pavol/0000-0003-1661-7905; Marques, Sergio/0000-0002-6281-7505
FU Czech Ministry of Education [INBIO -CZ.02.1.01/0.0/0.0/16 026/0008451,
   ELIXIR -LM2018131, eINFRA -LM2018140]; Czech Science Foundation
   [20-15915Y]
FX The authors wish to thank Sergej Stoppel, Robin Sk degrees anberg, and
   Mathieu Linares for their participation in the initial phases of the
   project. The authors would also like to express their gratitude to the
   Czech Ministry of Education (INBIO -CZ.02.1.01/0.0/0.0/16 026/0008451;
   ELIXIR -LM2018131; eINFRA -LM2018140) and the Czech Science Foundation
   (20-15915Y).
CR Alharbi N., 2016, Computer Graphics and Visual Computing (CGVC)
   Bidmon K, 2008, COMPUT GRAPH FORUM, V27, P935, DOI 10.1111/j.1467-8659.2008.01227.x
   Brezovsky J, 2018, METHODS MOL BIOL, V1685, P25, DOI 10.1007/978-1-4939-7366-8_3
   Bryden A, 2012, IEEE T VIS COMPUT GR, V18, P132, DOI 10.1109/TVCG.2010.250
   Byska J, 2019, COMPUT GRAPH FORUM, V38, P441, DOI 10.1111/cgf.13701
   Dabney J. B., 2004, Mastering simulink, V230
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   Elmqvist N, 2008, INFORM VISUAL, V7, P18, DOI 10.1057/palgrave.ivs.9500170
   Ertl T, 2014, FARADAY DISCUSS, V169, P167, DOI 10.1039/c3fd00156c
   Furmanová K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1448-0
   Hensen U, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0033931
   Hollingsworth SA, 2018, NEURON, V99, P1129, DOI 10.1016/j.neuron.2018.08.011
   J. Someone and T. Something, 2019, VVVV a multipurpose toolkit
   Javed W, 2013, COMPUT GRAPH FORUM, V32, P441, DOI 10.1111/cgf.12131
   Jurcik A, 2018, BIOINFORMATICS, V34, P3586, DOI 10.1093/bioinformatics/bty386
   Kaushik S, 2018, FEBS J, V285, P1456, DOI 10.1111/febs.14418
   Kodosky J, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3386328
   Kokkonen P, 2018, J AM CHEM SOC, V140, P17999, DOI 10.1021/jacs.8b09848
   Koudelakova T, 2013, ANGEW CHEM INT EDIT, V52, P1959, DOI 10.1002/anie.201206708
   Marques SM, 2017, J CHEM INF MODEL, V57, P1970, DOI 10.1021/acs.jcim.7b00070
   Marques SM, 2017, MED RES REV, V37, P1095, DOI 10.1002/med.21430
   Martinez X, 2020, BIOCHEM SOC T, V48, P499, DOI 10.1042/BST20190621
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Meyer-Spradow J, 2009, IEEE COMPUT GRAPH, V29, P6, DOI 10.1109/MCG.2009.130
   onsson D. J, 2019, IEEE Transactions on Visualization and Computer Graphics
   Patro R., 2011, 2011 IEEE Symposium on Biological Data Visualization, P111, DOI 10.1109/BioVis.2011.6094055
   Patro R., 2010, Scientific Visualization: Advanced Concepts, V1, P321
   Pavlova M, 2009, NAT CHEM BIOL, V5, P727, DOI 10.1038/nchembio.205
   Ritter F, 2011, IEEE PULSE, V2, P60, DOI 10.1109/MPUL.2011.942929
   Schatz K, 2021, COMPUT GRAPH FORUM, V40, P394, DOI 10.1111/cgf.14386
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Silva CT, 2007, COMPUT SCI ENG, V9, P82, DOI 10.1109/MCSE.2007.106
   Skanberg R., 2018, P EG WORKSH MOL GRAP, P19, DOI [10.2312/molva.20181102, DOI 10.2312/MOLVA.20181102]
   UPSON C, 1989, IEEE COMPUT GRAPH, V9, P30, DOI 10.1109/38.31462
   Vad V., P EUR WORKSH VIS COM, P33
   Vázquez P, 2018, COMPUT GRAPH FORUM, V37, P391, DOI 10.1111/cgf.13428
   Waser J, 2011, IEEE T VIS COMPUT GR, V17, P1872, DOI 10.1109/TVCG.2011.225
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yu BW, 2017, IEEE T VIS COMPUT GR, V23, P251, DOI 10.1109/TVCG.2016.2598497
NR 39
TC 4
Z9 4
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 581
EP 590
DI 10.1109/TVCG.2022.3209411
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA YE6M4
UT WOS:001266848400001
PM 36155456
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Linhares, CDG
   Ponciano, JR
   Pedro, DS
   Rocha, LEC
   Traina, AJM
   Poco, J
AF Linhares, Claudio D. G.
   Ponciano, Jean R.
   Pedro, Diogenes S.
   Rocha, Luis E. C.
   Traina, Agma J. M.
   Poco, Jorge
TI LargeNetVis: Visual Exploration of Large Temporal Networks Based on
   Community Taxonomies
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE temporal networks; dynamic graphs; network visualization; visual
   scalability; community taxonomy
ID DYNAMIC NETWORK; TASK TAXONOMY; VISUALIZATION; MODELS
AB Temporal (or time-evolving) networks are commonly used to model complex systems and the evolution of their components throughout time. Although these networks can be analyzed by different means, visual analytics stands out as an effective way for a pre-analysis before doing quantitative/statistical analyses to identify patterns, anomalies, and other behaviors in the data, thus leading to new insights and better decision-making. However, the large number of nodes, edges, and/or timestamps in many real-world networks may lead to polluted layouts that make the analysis inefficient or even infeasible. In this paper, we propose LargeNetVis, a web-based visual analytics system designed to assist in analyzing small and large temporal networks. It successfully achieves this goal by leveraging three taxonomies focused on network communities to guide the visual exploration process. The system is composed of four interactive visual components: the first (Taxonomy Matrix) presents a summary of the network characteristics, the second (Global View) gives an overview of the network evolution, the third (a node-link diagram) enables community- and node-level structural analysis, and the fourth (a Temporal Activity Map - TAM) shows the community- and node-level activity under a temporal perspective. We demonstrate the usefulness and effectiveness of LargeNetVis through two usage scenarios and a user study with 14 participants.
C1 [Linhares, Claudio D. G.; Pedro, Diogenes S.; Traina, Agma J. M.] Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, Brazil.
   [Rocha, Luis E. C.] Univ Ghent, Dept Econ, Ghent, Belgium.
   [Rocha, Luis E. C.] Univ Ghent, Dept Phys & Astron, Ghent, Belgium.
   [Ponciano, Jean R.; Poco, Jorge] Fdn Getulio Vargas, Sch Appl Math, Rio De Janeiro, Brazil.
C3 Universidade de Sao Paulo; Ghent University; Ghent University
RP Linhares, CDG (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci, Sao Carlos, Brazil.
EM claudiodgl@usp.br; jean.ponciano@fgv.br; diogenes.pedro@usp.br;
   luis.rocha@ugent.be; agma@icmc.usp.br; jorge.poco@fgv.br
RI Ponciano, Jean/AGE-0314-2022; Rocha, Luis/AAB-4049-2019; Traina,
   Agma/F-1299-2011; Poco, Jorge/F-3344-2016; Linhares,
   Claudio/AAJ-8869-2021
OI Traina, Agma/0000-0003-4929-7258; Silva Pedro,
   Diogenes/0000-0003-0956-9108; Poco, Jorge/0000-0001-9096-6287; Rocha,
   Luis/0000-0001-9046-8739; Linhares, Claudio/0000-0001-7012-4461;
   Ponciano, Jean Roberto/0000-0003-4629-3542
FU Sao Paulo Research Foundation (FAPESP) [2020/10049-0, 2020/07200-9,
   2016/17078-0]; Carlos Chagas Filho Foundation for Research Support of
   Rio de Janeiro State (FAPERJ) [E-26/201.424/2021]; CNPq; CAPES; School
   of Applied Mathematics at Fundacao Getulio Vargas (FGV)
FX This work was supported by grants #2020/10049-0, #2020/07200-9, and
   #2016/17078-0 from Sao Paulo Research Foundation (FAPESP), grant
   #E-26/201.424/2021 from Carlos Chagas Filho Foundation for Research
   Support of Rio de Janeiro State (FAPERJ), CNPq, CAPES, and by the School
   of Applied Mathematics at Fundacao Getulio Vargas (FGV). The authors
   thank Luis R. Pereira for providing an optimized version of his
   source-code [50].
CR Adhikari Bijaya., 2017, Proceedings of the 2017 SIAM International Conference on Data Mining, P417
   Ahmed NK, 2014, ACM T KNOWL DISCOV D, V8, DOI 10.1145/2601438
   Ahn JW, 2014, IEEE T VIS COMPUT GR, V20, P365, DOI 10.1109/TVCG.2013.238
   Archambault D, 2013, INT J HUM-COMPUT ST, V71, P1044, DOI 10.1016/j.ijhcs.2013.08.004
   Arleo A., 2021, EuroVis 2021-Short Papers, DOI DOI 10.2312/EVS.20211063
   Auber D., 2018, Tulip, V5, P3185, DOI [DOI 10.1007/978-1-4939-7131-2315, 10.1007/978-1-4939-7131-2_315, DOI 10.1007/978-1-4939-7131-2_315]
   Bach B, 2014, IEEE T VIS COMPUT GR, V20, P740, DOI 10.1109/TVCG.2013.254
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Bastian M., 2009, Association for the Advancement of Artificial Intelligence
   Batagelj V., 1998, Connect, V21, P47
   Beck F., 2014, EuroVis-STARs
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Brandes U., 2008, ForceDirected Graph Drawing, P1
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Cavaller V., 2021, Frontiers in Research Metrics and Analytics, V6
   Clementi A, 2015, THEOR COMPUT SCI, V584, P19, DOI 10.1016/j.tcs.2014.11.026
   Crnovrsanin T, 2021, IEEE T VIS COMPUT GR, V27, P539, DOI 10.1109/TVCG.2020.3030385
   Cui WW, 2014, IEEE PAC VIS SYMP, P121, DOI 10.1109/PacificVis.2014.48
   D3.js, D3.js-Data-Driven Documents
   Dang TN, 2016, COMPUT GRAPH FORUM, V35, P61, DOI 10.1111/cgf.12882
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Estrada E., 2012, The Structure of Complex Networks: Theory and Applications, DOI DOI 10.1093/ACPROF:OSO/9780199591756.001.0001
   Fischer MT, 2021, IEEE T VIS COMPUT GR, V27, P550, DOI 10.1109/TVCG.2020.3030408
   Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104
   Fortunato S, 2016, PHYS REP, V659, P1, DOI 10.1016/j.physrep.2016.09.002
   Fu K, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052399
   Gemmetto V, 2014, BMC INFECT DIS, V14, DOI 10.1186/s12879-014-0695-9
   Grinberg M., 2018, Flask Web Development: Developing Web Applications with Python
   Hagberg A., 2008, P 7 PYTH SCI C
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Holme P, 2012, PHYS REP, V519, P97, DOI 10.1016/j.physrep.2012.03.001
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hulovatyy Y, 2015, BIOINFORMATICS, V31, P171, DOI 10.1093/bioinformatics/btv227
   Kerracher N, 2015, IEEE T VIS COMPUT GR, V21, P1160, DOI 10.1109/TVCG.2015.2424889
   Kyrola A., 2012, P 10 USENIX S OP SYS, P31
   Lehmann S, 2019, COMPUT SOC SCI, P25, DOI 10.1007/978-3-030-23495-9_2
   Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893
   Li CH, 2017, J VISUAL-JAPAN, V20, P205, DOI 10.1007/s12650-016-0375-5
   Li M, 2018, BIOINFORMATICS, V34, P1597, DOI 10.1093/bioinformatics/btx821
   Lin ZY, 2013, INT CONF DAT MIN WOR, P1097, DOI 10.1109/ICDMW.2013.124
   Linhares C. D., 2017, P S APPL COMP, P187, DOI DOI 10.1145/3019612.3019686
   Linhares CDG, 2019, COMPUT GRAPH-UK, V84, P185, DOI 10.1016/j.cag.2019.08.006
   Malewicz G., 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167.1807184]
   Mi P, 2016, INFORMATICS-BASEL, V3, DOI 10.3390/informatics3040023
   NetworkX Developers, Networkx: network analysis in python
   Pereira F.S., 2016, STREAMEVOLV ECML PKD, P1
   Pereira LMV, 2019, IEEE INT SYMP CIRC S
   Pereira LR, 2021, ECOL COMPLEX, V45, DOI 10.1016/j.ecocom.2020.100904
   Ponciano JR, 2021, COMPUT GRAPH-UK, V97, P170, DOI 10.1016/j.cag.2021.04.006
   Rocha LEC, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001109
   Rossetti G, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3172867
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105
   Rosvall M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008694
   Saket B., 2014, EuroVis-Short Papers
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B, 2013, COMPUTER, V46, P58, DOI 10.1109/MC.2013.38
   Simonetto P, 2017, Arxiv, DOI arXiv:1709.00372
   Simonetto P, 2020, IEEE T VIS COMPUT GR, V26, P2373, DOI 10.1109/TVCG.2018.2886901
   Stanley N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29174-3
   Stivala AD, 2016, SOC NETWORKS, V47, P167, DOI 10.1016/j.socnet.2015.11.003
   Sultanum N, 2019, IEEE T VIS COMPUT GR, V25, P142, DOI 10.1109/TVCG.2018.2864905
   Traag VA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41695-z
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Wang PH, 2014, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2629564
   Wang Y., 2021, ACM Trans. Knowl. Discov. Data, V15
   Wang Y, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P241, DOI 10.1109/visual.2019.8933748
   Ware C., 2013, Interactive Technologies, P514, DOI 10.1016/B978-0-12-381464-7.00018-1
   Yao Y., 2012, Collection and streaming of graph datasets
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Yoghourdjian V, 2018, IEEE T VIS COMPUT GR, V24, P3081, DOI 10.1109/TVCG.2018.2790961
   Zhao Y, 2018, IEEE ACCESS, V6, P53006, DOI 10.1109/ACCESS.2018.2870684
NR 77
TC 5
Z9 5
U1 2
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 203
EP 213
DI 10.1109/TVCG.2022.3209477
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XO6M4
UT WOS:001262664200001
PM 36155451
OA Green Submitted, Green Published
DA 2024-11-06
ER

PT J
AU Morrical, N
   Sahistan, A
   Güdükbay, U
   Wald, I
   Pascucci, V
AF Morrical, Nate
   Sahistan, Alper
   Gudukbay, Ugur
   Wald, Ingo
   Pascucci, Valerio
TI Quick Clusters: A GPU-Parallel Partitioning for Efficient Path Tracing
   of Unstructured Volumetric Grids
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ray Tracing; Path Tracing; Volume Rendering; Scientific Visualization;
   Delta Tracking
ID AMR DATA; VISUALIZATION
AB We propose a simple yet effective method for clustering finite elements to improve preprocessing times and rendering performance of unstructured volumetric grids without requiring auxiliary connectivity data. Rather than building bounding volume hierarchies (BVHs) over individual elements, we sort elements along with a Hilbert curve and aggregate neighboring elements together, improving BVH memory consumption by over an order of magnitude. Then to further reduce memory consumption, we cluster the mesh on the fly into sub-meshes with smaller indices using a series of efficient parallel mesh re-indexing operations. These clusters are then passed to a highly optimized ray tracing API for point containment queries and ray-cluster intersection testing. Each cluster is assigned a maximum extinction value for adaptive sampling, which we rasterize into non-overlapping view-aligned bins allocated along the ray. These maximum extinction bins are then used to guide the placement of samples along the ray during visualization, reducing the number of samples required by multiple orders of magnitude (depending on the dataset), thereby improving overall visualization interactivity. Using our approach, we improve rendering performance over a competitive baseline on the NASA Mars Lander dataset from 6x (1 frame per second (fps) and 1.0 M rays per second (rps) up to now 6 fps and 12.4 M rps, now including volumetric shadows) while simultaneously reducing memory consumption by 3x (33 GB down to 11 GB) and avoiding any offline preprocessing steps, enabling high-quality interactive visualization on consumer graphics cards. Then by utilizing the full 48 GB of an RTX 8000, we improve the performance of Lander by 17x (1 fps up to 17 fps, 1.0 M rps up to 35.6 M rps).
C1 [Morrical, Nate; Pascucci, Valerio] Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.
   [Morrical, Nate; Wald, Ingo] NVIDIA, Santa Clara, CA 95051 USA.
   [Sahistan, Alper; Gudukbay, Ugur] Bilkent Univ, Ankara, Turkiye.
C3 Utah System of Higher Education; University of Utah; Nvidia Corporation;
   Ihsan Dogramaci Bilkent University
RP Morrical, N (corresponding author), Univ Utah, SCI Inst, Salt Lake City, UT 84112 USA.; Morrical, N (corresponding author), NVIDIA, Santa Clara, CA 95051 USA.
RI pascucci, Valerio/GXF-0616-2022
OI Sahistan, Alper/0000-0002-3480-7713; pascucci,
   valerio/0000-0002-8877-2042
CR Advanced Micro Devices Inc, 2020, Technical report
   Aman A, 2022, J VISUAL-JAPAN, V25, P1103, DOI 10.1007/s12650-022-00842-x
   Aman A, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2024
   Amanatides J., 1987, EUROGRAPHICS, V87, P3, DOI DOI 10.2312/EGTP.19871000
   Ament M, 2014, IEEE T VIS COMPUT GR, V20, P2437, DOI 10.1109/TVCG.2014.2346333
   Benthin C, 2018, HIGH-PERFORMANCE GRAPHICS 2018, DOI 10.1145/3231578.3231581
   Biedron R. T., 2019, FUN3D Manual: 13.6
   BUTZ AR, 1971, IEEE T COMPUT, VC 20, P424, DOI 10.1109/T-C.1971.223258
   Dammertz H, 2008, COMPUT GRAPH FORUM, V27, P1225, DOI 10.1111/j.1467-8659.2008.01261.x
   Engel K., 2004, ACM SIGGRAPH Course Notes, V29
   Ernst M, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P35, DOI 10.1109/RT.2008.4634618
   Ganter D, 2019, COMPUT GRAPH FORUM, V38, P13, DOI 10.1111/cgf.13756
   Gittings Michael, 2008, Computational Science and Discovery, V1, DOI 10.1088/1749-4699/1/1/015005
   Gralka P, 2020, SYMP LARG DATA ANAL, P42, DOI 10.1109/LDAV51489.2020.00012
   Gruen H., 2022, GAM DEV C
   Günther T, 2016, COMPUT GRAPH FORUM, V35, P381, DOI 10.1111/cgf.12914
   Ha L, 2009, COMPUT GRAPH FORUM, V28, P2368, DOI 10.1111/j.1467-8659.2009.01542.x
   Hofmann N, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406181
   Ishii M, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356198
   Jones K. E., 2019, Summit supercomputer simulates how humans will 'brake' during Mars landing
   Kahler R., 2006, P VOL GRAPH, P103
   Kiris C. C., 2014, AIAA J, P1
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Ljung P., 2006, P EUR IEEE WORKSH VO, P39, DOI DOI 10.2312/VG/VG06/039-046
   Martschinke J, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13771
   Moon B, 2001, IEEE T KNOWL DATA EN, V13, P124, DOI 10.1109/69.908985
   Moore D., 2008, Computational and Applied Mathematics,
   Moran PJ, 2011, IEEE T VIS COMPUT GR, V17, P1862, DOI 10.1109/TVCG.2011.252
   Morrical N., IEEE Transactions on Visualization and Computer Graphics
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Mueller-Roemer JS, 2018, COMPUT GRAPH FORUM, V37, P443, DOI 10.1111/cgf.13581
   Muigg P, 2011, IEEE T VIS COMPUT GR, V17, P2115, DOI 10.1109/TVCG.2011.216
   NVIDIA Corp, 2021, Technical report
   Parker SG, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778803
   Patchett J., 2016, Visualization and Analysis of Threats from Asteroid Ocean Impacts
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd
   Rathke B., 2015, P EUR S PAR GRAPH VI, P33
   Sahistan A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P91, DOI [10.1109/VIS49827.2021.9623298, 10.1109/VIS49827.2021.00026]
   Shirley P., 1990, ACM COMPUTER GRAPHIC, V24, P6370
   Ströter D, 2020, VISUAL COMPUT, V36, P2327, DOI 10.1007/s00371-020-01886-6
   Szirmay-Kalos L., 2010, Eurographics (Posters)
   Szirmay-Kalos L, 2011, COMPUT GRAPH FORUM, V30, P85, DOI 10.1111/j.1467-8659.2010.01831.x
   Wald I., 2021, arXiv
   Wald I., Ray Tracing Gems: High-Quality and Real-Time Rendering with DXR and Other APIs, P61
   Wald I, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P49, DOI 10.1109/RT.2008.4634620
   Wald I, 2020, Arxiv, DOI arXiv:2004.08475
   Wald I, 2022, IEEE T VIS COMPUT GR, V28, P583, DOI 10.1109/TVCG.2021.3114869
   Wald I, 2021, IEEE T VIS COMPUT GR, V27, P625, DOI 10.1109/TVCG.2020.3030470
   Weber G. H., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P31, DOI 10.1109/LDAV.2012.6378973
   Wolfe A, 2021, Arxiv, DOI arXiv:2112.09629
   Yue YH, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866199
NR 53
TC 4
Z9 4
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 537
EP 547
DI 10.1109/TVCG.2022.3209418
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EP4T6
UT WOS:001140122900001
PM 36166550
DA 2024-11-06
ER

PT J
AU Zhou, JH
   Wang, XM
   Wong, JK
   Wang, HL
   Wang, ZW
   Yang, XY
   Yan, XR
   Feng, HZ
   Qu, HM
   Ying, HC
   Chen, W
AF Zhou, Jiehui
   Wang, Xumeng
   Wong, Jason K.
   Wang, Huanliang
   Wang, Zhongwei
   Yang, Xiaoyu
   Yan, Xiaoran
   Feng, Haozhe
   Qu, Huamin
   Ying, Haochao
   Chen, Wei
TI DPVisCreator: Incorporating Pattern Constraints to Privacy-preserving
   Visualizations via Differential Privacy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Privacy-preserving visualization; visual analytics; differential
   privacy; tabular data
ID VISUAL ANALYSIS; EXPLORATION; METRICS; UTILITY
AB Data privacy is an essential issue in publishing data visualizations. However, it is challenging to represent multiple data patterns in privacy-preserving visualizations. The prior approaches target specific chart types or perform an anonymization model uniformly without considering the importance of data patterns in visualizations. In this paper, we propose a visual analytics approach that facilitates data custodians to generate multiple private charts while maintaining user-preferred patterns. To this end, we introduce pattern constraints to model users' preferences over data patterns in the dataset and incorporate them into the proposed Bayesian network-based Differential Privacy (DP) model PriVis. A prototype system, DPVisCreator, is developed to assist data custodians in implementing our approach. The effectiveness of our approach is demonstrated with quantitative evaluation of pattern utility under the different levels of privacy protection, case studies, and semi-structured expert interviews.
C1 [Zhou, Jiehui; Wang, Huanliang; Wang, Zhongwei; Yang, Xiaoyu; Feng, Haozhe; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Zhejiang, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou, Peoples R China.
   [Wang, Xumeng] Nankai Univ, TMCC, CS, Tianjin, Peoples R China.
   [Wong, Jason K.; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Yan, Xiaoran] Zhejiang Lab, Hangzhou, Peoples R China.
   [Ying, Haochao] Zhejiang Univ, Sch Publ Hlth, Hangzhou, Peoples R China.
   [Ying, Haochao] Key Lab Intelligent Prevent Med Zhejiang Prov, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Nankai University; Hong Kong
   University of Science & Technology; Zhejiang Laboratory; Zhejiang
   University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Zhejiang, Peoples R China.; Chen, W (corresponding author), Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou, Peoples R China.; Ying, HC (corresponding author), Zhejiang Univ, Sch Publ Hlth, Hangzhou, Peoples R China.; Ying, HC (corresponding author), Key Lab Intelligent Prevent Med Zhejiang Prov, Hangzhou, Peoples R China.
EM zhoujiehui@zju.edu.cn; wangxumeng@nankai.edu.cn; kkwongar@cse.ust.hk;
   22051090@zju.edu.cn; wzw09@zju.edu.cn; 22051142@zju.edu.cn;
   xiaoran.a.yan@gmail.com; fenghz@zju.edu.cn; huamin@cse.ust.hk;
   haochaoying@zju.edu.cn; chenvis@zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Zhou, Jiehui/KBC-2015-2024; yang,
   xiaoyu/AAH-9797-2020
OI Ying, Haochao/0000-0001-7832-2518; Zhou, Jiehui/0000-0003-0709-775X;
   Feng, Haozhe/0000-0002-5900-356X; WONG, Kam Kwai/0000-0002-2813-1972
FU National Natural Science Foundation of China [62132017, 62106218];
   Zhejiang Lab [2022NF0AC01]
FX We would like to thank all the reviewers for their constructive
   comments. This work was supported by the National Natural Science
   Foundation of China (62132017 and 62106218) and Zhejiang Lab
   (2022NF0AC01).
CR Andrienko N, 2016, INFORM VISUAL, V15, P117, DOI 10.1177/1473871615581216
   [Anonymous], 2007, Dynamic Time Warping, P69, DOI [DOI 10.1007/978-3-540-74048-34, 10.1007/978-3-540-74048-3]
   Atallah M., 1999, P 1999 WORKSH KNOWL, P45, DOI [10.1109/KDEX.1999.836532, DOI 10.1109/KDEX.1999.836532]
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Berger V. W., 2014, WILEY STATSREF STAT, DOI [DOI 10.1002/9781118445112.STAT06558, 10.1002/9781118445112.stat06558]
   Bertino E., 2006, Proceedings 2006 10th International Conference on Computer Supported Cooperative Work in Design (IEEE Cat. No. 06EX1292)
   Bhattacharjee K, 2020, COMPUT GRAPH FORUM, V39, P675, DOI 10.1111/cgf.14032
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Busa-Fekete R., 2012, EUROPEAN C ARTIFICIA, V242
   Chou J.-K., 2016, SIGGRAPH ASIA S VIS, P1, DOI [10.1145/3002151.3002153, DOI 10.1145/3002151.3002153]
   Chou JK, 2018, IEEE SYM VIS CYB SEC
   Chou JK, 2019, COMPUT GRAPH FORUM, V38, P340, DOI 10.1111/cgf.13535
   Chou JK, 2017, IEEE PAC VIS SYMP, P11, DOI 10.1109/PACIFICVIS.2017.8031573
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Clifton C, 2013, I C DATA ENGIN WORKS, P88, DOI 10.1109/ICDEW.2013.6547433
   Cohen I., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0, DOI 10.1007/978-3-642-00296-0_5]
   Cox M. A., 2008, Handbook of data visualization, P315, DOI DOI 10.1007/978-3-540-33037-014
   Craig D, 2017, J MASS COMMUN Q, V94, P168, DOI 10.1177/1077699016684796
   Dasgupta A, 2013, COMPUT GRAPH FORUM, V32, P35, DOI 10.1111/cgf.12142
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   Dasgupta A, 2011, IEEE T VIS COMPUT GR, V17, P2241, DOI 10.1109/TVCG.2011.163
   Dasgupta A, 2010, IEEE T VIS COMPUT GR, V16, P1017, DOI 10.1109/TVCG.2010.184
   Dinur I., 2003, P 22 ACM SIGMOD SIGA, P202, DOI DOI 10.1145/773153.773173
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Dwork C, 2010, PROC APPL MATH, V135, P174
   Ellis G., 2006, ser. AVI '06, P266, DOI DOI 10.1145/1133265.1133318
   Gaboardi M, 2018, Arxiv, DOI arXiv:1609.04340
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Greenwood C., 1996, A Guide to Chi-squared Testing
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Healy K, 2014, ANNU REV SOCIOL, V40, P105, DOI 10.1146/annurev-soc-071312-145551
   Henriksen-Bulmer J, 2016, INT J INFORM MANAGE, V36, P1184, DOI 10.1016/j.ijinfomgt.2016.08.002
   Jain P, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0124-9
   Johansson S, 2009, IEEE T VIS COMPUT GR, V15, P993, DOI 10.1109/TVCG.2009.153
   Kasiviswanathan SP, 2013, LECT NOTES COMPUT SC, V7785, P457, DOI 10.1007/978-3-642-36594-2_26
   Koppen M., 2000, 5 ONL WORLD C SOFT C, V1, P4
   Li HR, 2014, PROC VLDB ENDOW, V7, P1677, DOI 10.14778/2733004.2733059
   Li NH, 2007, PROC INT CONF DATA, P81
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI [10.1145/1217299.1217302, DOI 10.1145/1217299.1217302]
   Madsen AL, 2017, KNOWL-BASED SYST, V117, P46, DOI 10.1016/j.knosys.2016.07.031
   Marutho Dhendra, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P533, DOI 10.1109/ISEMANTIC.2018.8549751
   McKenna R., 2019, INT C MACH LEARN, V97, P4435
   McSherry F, 2007, ANN IEEE SYMP FOUND, P94, DOI 10.1109/FOCS.2007.66
   Mojsilovic A, 2004, IEEE T MULTIMEDIA, V6, P828, DOI 10.1109/TMM.2004.839607
   Mojsilovic A, 2001, IEEE IMAGE PROC, P18, DOI 10.1109/ICIP.2001.958942
   Nanayakkara Priyanka, 2022, arXiv
   Nie Y., 2016, INT C COLLABORATIVE, P152, DOI [DOI 10.1007/978-3-319-59288-6-14, 10.1007/978-3-319-59288-6-14]
   O'Donoghue SI, 2018, ANNU REV BIOMED DA S, V1, P275, DOI 10.1146/annurev-biodatasci-080917-013424
   O'Donoghue SI, 2010, NAT METHODS, V7, pS2, DOI 10.1038/nmeth.f.301
   Oksanen J, 2015, J TRANSP GEOGR, V48, P135, DOI 10.1016/j.jtrangeo.2015.09.001
   Perer Adam, 2012, AMIA Annu Symp Proc, V2012, P716
   Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7
   Qardaji W, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1435, DOI 10.1145/2588555.2588575
   Ren HD, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P54, DOI 10.1109/IWECA.2014.6845555
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Saket B, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P133, DOI 10.1145/2993901.2993903
   Shao L., 2014, EUROVIS, DOI 10-2312/eurova.20141140
   Steel E., 2010, The Wall Street Journal, V18
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Tao YC, 2022, Arxiv, DOI [arXiv:2112.09238, DOI 10.48550/ARXIV.2112.09238]
   Thaker P, 2020, Arxiv, DOI arXiv:2006.12018
   Trautman L. J., 2016, AM UNIV LAW REV, V66, P1231
   Vallender S, 1974, Theory Probab. Appl., V18, P784, DOI DOI 10.1137/1118101
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wang XM, 2018, IEEE T VIS COMPUT GR, V24, P351, DOI 10.1109/TVCG.2017.2745139
   Wasserman L, 2010, J AM STAT ASSOC, V105, P375, DOI 10.1198/jasa.2009.tm08651
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Xiao XK, 2011, IEEE T KNOWL DATA EN, V23, P1200, DOI 10.1109/TKDE.2010.247
   Zhang D., 2016, Theory Pract. Differe. Privacy, V2016, P1
   Zhang D, 2021, IEEE T VIS COMPUT GR, V27, P1786, DOI 10.1109/TVCG.2020.3030369
   Zhang J, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3134428
   Zhu TQ, 2017, ADV INFORM SECUR, V69, P67, DOI 10.1007/978-3-319-62004-6_7
NR 77
TC 8
Z9 9
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 809
EP 819
DI 10.1109/TVCG.2022.3209391
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M6EI0
UT WOS:001031124700001
PM 36166552
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, ZL
   Wang, WY
   Guo, MT
   Wang, Y
   Gotz, D
AF Zhou, Zhilan
   Wang, Wenyuan
   Guo, Mengtian
   Wang, Yue
   Gotz, David
TI A Design Space for Surfacing Content Recommendations in Visual Analytic
   Platforms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptive Visualization; Recommendation; Literature Survey; Design Space
ID VISUALIZATION; SYSTEMS
AB Recommendation algorithms have been leveraged in various ways within visualization systems to assist users as they perform of a range of information tasks. One common focus for these techniques has been the recommendation of content, rather than visual form, as a means to assist users in the identification of information that is relevant to their task context. A wide variety of techniques have been proposed to address this general problem, with a range of design choices in how these solutions surface relevant information to users. This paper reviews the state-of-the-art in how visualization systems surface recommended content to users during users' visual analysis; introduces a four-dimensional design space for visual content recommendation based on a characterization of prior work; and discusses key observations regarding common patterns and future research opportunities.
C1 [Zhou, Zhilan; Gotz, David] Univ North Carolina Chapel Hill, Dept Comp Sci, Chapel Hill, NC 27599 USA.
   [Wang, Wenyuan; Guo, Mengtian; Wang, Yue] Univ North Carolina Chapel Hill, Sch Informat, Lib Sci, Chapel Hill, NC USA.
   [Wang, Wenyuan; Guo, Mengtian; Wang, Yue] Univ North Carolina Chapel Hill, Lib Sci, Chapel Hill, NC USA.
C3 University of North Carolina; University of North Carolina Chapel Hill;
   University of North Carolina School of Medicine; University of North
   Carolina; University of North Carolina Chapel Hill; University of North
   Carolina School of Medicine; University of North Carolina; University of
   North Carolina Chapel Hill; University of North Carolina School of
   Medicine
RP Zhou, ZL (corresponding author), Univ North Carolina Chapel Hill, Dept Comp Sci, Chapel Hill, NC 27599 USA.
EM zzl@email.unc.edu; vaapad@live.unc.edu; mtguo@email.unc.edu;
   wangyue@unc.edu; gotz@unc.edu
RI ; Zhou, Zhilan/HZK-7461-2023
OI Wang, Yue/0000-0002-0278-2347; Zhou, Zhilan/0000-0003-1236-1287; Gotz,
   David/0000-0002-6424-7374
FU National Science Foundation [1704018]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1704018] Funding
   Source: National Science Foundation
FX The research reported in this article was supported in part by a grant
   from the National Science Foundation (#1704018).
CR Acm digital library, About Us
   Ahn J.-W., 2008, 2008 IEEE S VISUAL A
   Ahn J.-W., 2011, 2011 ICONFERENCE
   Ahn Jae, 2015, P 20 INT C INT US IN, P202, DOI DOI 10.1145/2678025.2701410
   [Anonymous], GOOGL SCHOL
   [Anonymous], 2009, Journal of clinical epidemiology, DOI 10.1016/j.jclinepi.2007.11.008
   Bae S., 2010, Proceedings of the 10th Annual Joint Conference on Digital Libraries, P177
   Bai XY, 2013, 2013 15TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P786, DOI 10.1109/ICCT.2013.6820481
   Banos O, 2015, INT CONF PER COMP, P1, DOI 10.4108/icst.pervasivehealth.2015.259083
   Bao C., 2022, ACM CHI C HUMAN FACT
   Barral O, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3447992
   Barral O, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P1, DOI 10.1145/3377325.3377517
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bonada S, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P83, DOI 10.1145/3009939.3009953
   Brusilovsky P., 2006, SIGCSE Bulletin, V38, P48, DOI 10.1145/1140123.1140140
   Brusilovsky P, 2006, INFORMATION VISUALIZATION-BOOK, P142
   Burkhardt D., 2020, 61 INTERSCIENTIFIC C
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chaudhuri A, 2009, IEEE PAC VIS SYMP, P105, DOI 10.1109/PACIFICVIS.2009.4906844
   Conati C., 2008, P WORK C ADV VIS INT, P199, DOI DOI 10.1145/1385569.1385602
   Coors V., 2002, P 2 INT S SMART GRAP, P140
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Cremonesi P, 2017, MULTIMED TOOLS APPL, V76, P5275, DOI 10.1007/s11042-016-3946-5
   dEntremont T., 2006, PRESENTATION ABSTRAC, P34
   Deuschel T, 2018, UMAP'18: ADJUNCT PUBLICATION OF THE 26TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P187, DOI 10.1145/3213586.3213587
   Domik G., 1994, IEEE VISUALIZATION 9
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6
   Glowacka D., 2013, ACM IUI, P117, DOI DOI 10.1145/2449396.2449413
   Göbel F, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204544
   Golemati M, 2006, INFORMATION VISUALIZATION-BOOK, P62
   Gotz D., 2021, ACM CHI C HUMAN FACT
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Guo ML, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND APPLICATIONS (WCNA2017), P122, DOI 10.1145/3180496.3180618
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   IEEE Xplore, About Us
   Kanai H, 2000, IEEE INFOR VIS, P277, DOI 10.1109/IV.2000.859768
   Karsai L., 2016, P WORKSHOP HUMAN IN, P1
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P38, DOI 10.1145/2858036.2858440
   Knijnenburg BP, 2012, USER MODEL USER-ADAP, V22, P441, DOI 10.1007/s11257-011-9118-4
   Knittel J, 2022, IEEE T VIS COMPUT GR, V28, P879, DOI 10.1109/TVCG.2021.3114800
   Lallé S, 2021, IEEE T VIS COMPUT GR, V27, P2941, DOI 10.1109/TVCG.2019.2958540
   Lehmann S, 2010, INFORM SYST, V35, P260, DOI 10.1016/j.is.2009.10.004
   Leuski A, 2004, USER MODEL USER-ADAP, V14, P259, DOI 10.1023/B:USER.0000028978.09823.47
   Miyamura H. N., 2011, 2011 8 INT JOINT C C
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mutlu B, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2983923
   Nazemi K., 2014, P 14 INT C KNOWLEDGE, P1
   Nazemi K, 2013, LECT NOTES COMPUT SC, V8034, P13, DOI 10.1007/978-3-642-41939-3_2
   Oscar N., 2017, 2017 C DESIGNING INT
   Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Pombinho P, 2011, IEEE INT CONF INF VI, P151, DOI 10.1109/IV.2011.34
   ROTH SF, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P112, DOI 10.1145/191666.191719
   Roussinov D., 1999, CHI 99 EXTENDED ABST
   Ruotsalo T, 2015, COMMUN ACM, V58, P86, DOI 10.1145/2656334
   Rusu A, 2006, INFORMATION VISUALIZATION-BOOK, P469
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schonhage B., 1997, 1997 WORKSHOP NEW PA, P8
   Shani G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P257, DOI 10.1007/978-0-387-85820-3_8
   Shi L, 2009, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2009.4906836
   Silva N., 2016, 9 FORUM MEDIA TECHNO
   Silva N, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204546
   Smith B, 2017, IEEE INTERNET COMPUT, V21, P12, DOI 10.1109/MIC.2017.72
   Srinivasan Arjun, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P864, DOI 10.1145/3472749.3474792
   Steichen B., 2013, P 2013 INT C INT US, P317, DOI [10.1145/2449396.2449439, DOI 10.1145/2449396.2449439]
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Thomas J. J., 2005, Illuminating the path: The research and development agenda for visual analytics
   Tonder B.v., 2008, Proceedings of the 2008 Annual Conference of the South African Institute of Computer Scientists and Information Technologists, P257
   Vartak M., 2014, PROC VLDB ENDOW
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Wang XB, 2022, Arxiv, DOI arXiv:2201.04868
   Wasinger R., SCRUTABLE USER MODEL
   Wiza W, 2005, IEEE INT SYM MULTIM, P151
   Wiza W., 2004, Components, V1, P29, DOI DOI 10.1145/985040.985045
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Yelizarov A., 2014, 7 INT S VISUAL INFOR
   Yu H., 2007, Supercomputing, P1
   Yu Jianwei, 2009, 2009 17 INT C GEOINF
   Zhang Y., 2018, 2018 26 INT C GEOINF
NR 83
TC 1
Z9 1
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 84
EP 94
DI 10.1109/TVCG.2022.3209445
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800001
PM 36194706
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zong, J
   Pollock, J
   Wootton, D
   Satyanarayan, A
AF Zong, Jonathan
   Pollock, Josh
   Wootton, Dylan
   Satyanarayan, Arvind
TI Animated Vega-Lite: Unifying Animation with a Grammar of Interactive
   Graphics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information visualization; Interaction; Toolkits; Systems; Declarative
   Specification
ID TRANSITIONS; VISUALIZATIONS
AB We present Animated Vega-Lite, a set of extensions to Vega-Lite that model animated visualizations as time-varying data queries. In contrast to alternate approaches for specifying animated visualizations, which prize a highly expressive design space, Animated Vega-Lite prioritizes unifying animation with the language's existing abstractions for static and interactive visualizations to enable authors to smoothly move between or combine these modalities. Thus, to compose animation with static visualizations, we represent time as an encoding channel. Time encodings map a data field to animation keyframes, providing a lightweight specification for animations without interaction. To compose animation and interaction, we also represent time as an event stream; Vega-Lite selections, which provide dynamic data queries, are now driven not only by input events but by timer ticks as well. We evaluate the expressiveness of our approach through a gallery of diverse examples that demonstrate coverage over taxonomies of both interaction and animation. We also critically reflect on the conceptual affordances and limitations of our contribution by interviewing five expert developers of existing animation grammars. These reflections highlight the key motivating role of in-the-wild examples, and identify three central tradeoffs: the language design process, the types of animated transitions supported, and how the systems model keyframes.
C1 [Zong, Jonathan; Pollock, Josh; Wootton, Dylan; Satyanarayan, Arvind] MIT CS IL, Cambridge, MA 02139 USA.
RP Zong, J (corresponding author), MIT CS IL, Cambridge, MA 02139 USA.
EM jzong@mit.edu; jopo@mit.edu; dwootton@mit.edu; arvindsatya@mit.edu
OI Zong, Jonathan/0000-0003-4811-4624; Satyanarayan,
   Arvind/0000-0001-5564-635X
FU National Science Foundation [1942659, 1900991, 1745302]; NSF's SaTC
   Program; Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1900991] Funding Source: National Science
   Foundation; Direct For Computer & Info Scie & Enginr; Div Of Information
   & Intelligent Systems [1942659] Funding Source: National Science
   Foundation
FX We thank our critical reflections interlocutors and anonymous reviewers.
   This work was supported by NSF grants #1942659 and #1900991 and by the
   NSF's SaTC Program. This material is based upon work supported by the
   National Science Foundation under Grant No. 1745302.
CR Abukhodair FA, 2013, PROC SPIE, V8654, DOI 10.1117/12.2001874
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock Mike, 2019, BAR CHART RACE EXPLA
   Bostock Mike, 2015, D3 EASE
   Bucher HJ, 2006, COMMUNICATIONS-GER, V31, P347, DOI 10.1515/COMMUN.2006.022
   Chevalier F, 2014, IEEE T VIS COMPUT GR, V20, P2241, DOI 10.1109/TVCG.2014.2346424
   Coblenz M, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3452379
   Dragicevic P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2009
   Elliott C, 1997, ACM SIGPLAN NOTICES, V32, P263, DOI 10.1145/258949.258973
   Ge T, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14005
   Ge Tong, 2021, P 2021 CHI C HUM FAC, P1
   Green T. R. G., 1989, People and Computers V. Proceedings of the Fifth Conference of the British Computer Society Human-Computer Interaction Specialist Group, P443
   Greussing E, 2020, SCI COMMUN, V42, P803, DOI 10.1177/1075547020962100
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Irwin N., 2014, NEW YORK TIMES
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kim Y, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P201, DOI [10.1109/VIS49827.2021.00048, 10.1109/VIS49827.2021.9623291]
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Kim Y, 2019, COMPUT GRAPH FORUM, V38, P541, DOI 10.1111/cgf.13709
   Kondo B, 2014, IEEE T VIS COMPUT GR, V20, P2003, DOI 10.1109/TVCG.2014.2346250
   La Sorte FA, 2016, P ROY SOC B-BIOL SCI, V283, DOI 10.1098/rspb.2015.2588
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Lu M, 2022, IEEE T VIS COMPUT GR, V28, P2628, DOI 10.1109/TVCG.2020.3037300
   McNutt A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445356
   Meyerovich LA, 2009, ACM SIGPLAN NOTICES, V44, P1, DOI 10.1145/1639949.1640091
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Myers BA, 2004, COMMUN ACM, V47, P47, DOI 10.1145/1015864.1015888
   Pedersen Thomas Lin, 2019, GGANIMATE HAS TRANSI
   Pedersen Thomas Lin, 2019, GRAMMAR ANIMATED GRA
   Pedersen Thomas Lin, 2018, GRAMMAR ANIMATION
   Periscopic, 2013, PERISCOPIC US GUN DE
   Plotly Graphing Libraries, 2012, PLOTLY GRAPHING LIB
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Rosling Hans, 2006, BEST STATS YOUVE EVE
   Satyanarayan A., 2014, P 27 ANN ACM S US IN, P669, DOI DOI 10.1145/2642918.2647360
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Thomas JG, 2022, PSYCHOTHER RES, V32, P128, DOI 10.1080/10503307.2021.1909770
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Thompson John, 2020, SWIMMING WORLD RECOR
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Wikipedia contributors, 2022, SER PAR GRAPH WIK
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Yee Stephanie, 2015, VISUAL INTRO MACHI 2
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 52
TC 10
Z9 11
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 149
EP 159
DI 10.1109/TVCG.2022.3209369
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800002
PM 36215347
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Swift, ME
   Ayers, W
   Pallanck, S
   Wehrwein, S
AF Swift, Melissa E.
   Ayers, Wyatt
   Pallanck, Sophie
   Wehrwein, Scott
TI Visualizing the Passage of Time with Video Temporal Pyramids
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time; time-frequency; video visualization; multi-scale; webcam
AB What can we learn about a scene by watching it for months or years? A video recorded over a long timespan will depict interesting phenomena at multiple timescales, but identifying and viewing them presents a challenge. The video is too long to watch in full, and some things are too slow to experience in real-time, such as glacial retreat or the gradual shift from summer to fall. Timelapse videography is a common approach to summarizing long videos and visualizing slow timescales. However, a timelapse is limited to a single chosen temporal frequency, and often appears flickery due to aliasing. Also, the length of the timelapse video is directly tied to its temporal resolution, which necessitates tradeoffs between those two facets. In this paper, we propose Video Temporal Pyramids, a technique that addresses these limitations and expands the possibilities for visualizing the passage of time. Inspired by spatial image pyramids from computer vision, we developed an algorithm that builds video pyramids in the temporal domain. Each level of a Video Temporal Pyramid visualizes a different timescale; for instance, videos from the monthly timescale are usually good for visualizing seasonal changes, while videos from the one-minute timescale are best for visualizing sunrise or the movement of clouds across the sky. To help explore the different pyramid levels, we also propose a Video Spectrogram to visualize the amount of activity across the entire pyramid, providing a holistic overview of the scene dynamics and the ability to explore and discover phenomena across time and timescales. To demonstrate our approach, we have built Video Temporal Pyramids from ten outdoor scenes, each containing months or years of data. We compare Video Temporal Pyramid layers to naive timelapse and find that our pyramids enable alias-free viewing of longer-term changes. We also demonstrate that the Video Spectrogram facilitates exploration and discovery of phenomena across pyramid levels, by enabling both overview and detail-focused perspectives.
C1 [Swift, Melissa E.; Ayers, Wyatt; Pallanck, Sophie; Wehrwein, Scott] Western Washington Univ, Bellingham, WA 98225 USA.
   [Swift, Melissa E.] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
C3 Western Washington University; United States Department of Energy (DOE);
   Pacific Northwest National Laboratory
RP Swift, ME (corresponding author), Western Washington Univ, Bellingham, WA 98225 USA.; Swift, ME (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99354 USA.
EM melissa.swift@pnnl.gov; ayersw2@wwu.edu; sophierosepallanck@gmail.com;
   scott.wehrwein@wwu.edu
OI Swift, Melissa/0000-0003-3955-0950
FU NASA [NNX15AJ98H]; National Science Foundation [2105372]; NASA Office of
   Stem Engagement; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [2105372] Funding Source: National
   Science Foundation
FX This work was supported in part by NASA Award NNX15AJ98H under the
   Washington NASA Space Grant Consortium, and in part by the National
   Science Foundation under Grant No. 2105372. The Washington NASA Space
   Grant Consortium is funded by the NASA Office of Stem Engagement. Any
   opinions, findings, and conclusions or recommendations expressed in this
   material are those of the author(s) and do not necessarily reflect the
   views of NASA or the NSF. The authors wish to thank Ann Tseng and Richie
   Mohan for their early contributions.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Ali M, 2019, VISUAL COMPUT, V35, P1013, DOI 10.1007/s00371-019-01673-y
   Barnes C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778826
   Bennett EP, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276505
   Borgo Rita, 2011, EUROGRAPHICS 2011 ST, P1, DOI [DOI 10.2312/EG2011/STARS/001-023, 10.2312/EG2011/stars/001-023]
   Buckley EMB, 2017, ECOL SOC, V22, DOI 10.5751/ES-09268-220330
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   BURT PJ, 1981, COMPUT VISION GRAPH, V16, P20, DOI 10.1016/0146-664X(81)90092-7
   Cakmak E, 2021, IEEE T VIS COMPUT GR, V27, P517, DOI 10.1109/TVCG.2020.3030398
   Cohen L., 1995, Time-Frequency Analysis, V778
   Finkelstein A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P281, DOI 10.1145/237170.237266
   Google, EXPL TIM GOOGLE EART
   Gutwin C., 2019, P 2019 CHI C HUMAN F, DOI [10.1145/3290605.3300785, DOI 10.1145/3290605.3300785]
   Hansen S, 2018, QUAL RES PSYCHOL, V15, P292, DOI 10.1080/14780887.2018.1430011
   Harrower M, 2001, Cartographic Perspectives, V39, P30, DOI [10.14714/CP39.637, DOI 10.14714/CP39.637]
   Hartill BW, 2020, FISH FISH, V21, P204, DOI 10.1111/faf.12413
   Höferlin M, 2012, IEEE T VIS COMPUT GR, V18, P2095, DOI 10.1109/TVCG.2012.222
   Jackson Daniel, 2013, P 26 ANN ACM S USER, DOI DOI 10.1145/2501988.2502038
   Joshi N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766954
   Kotack M., 2014, 4 ENV TIME LAPSE VID
   Kratochvil M., 2020, MULTIMEDIA MODELING, DOI [10.1007/978-3-030-37734-2.71, DOI 10.1007/978-3-030-37734-2.71]
   Lan ZZ, 2014, Arxiv, DOI arXiv:1408.7071
   Liu JF, 2016, ENVIRON EARTH SCI, V75, DOI 10.1007/s12665-015-5075-2
   Lobo MJ, 2019, IEEE T VIS COMPUT GR, V25, P1347, DOI 10.1109/TVCG.2018.2796557
   Martin-Brualla R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766903
   Monea B, 2023, QUAL RES, V23, P143, DOI 10.1177/14687941211019524
   Nakamura KW, 2019, EDUC SCI, V9, DOI 10.3390/educsci9030190
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rav-acha A., 2005, EVOLVING TIME FRONTS
   Rochan M, 2018, LECT NOTES COMPUT SC, V11216, P358, DOI 10.1007/978-3-030-01258-8_22
   Romero M, 2008, IEEE T VIS COMPUT GR, V14, P1261, DOI 10.1109/TVCG.2008.185
   Rossetto L, 2021, IEEE T MULTIMEDIA, V23, P243, DOI 10.1109/TMM.2020.2980944
   Rubinstein M, 2011, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2011.5995374
   Seyednasrollah B, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0229-9
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Temponaut, 2021, TEMPONAUT TOP 10 TIM
   Tibaut A, 2018, SUSTAIN SCI, V13, P1311, DOI 10.1007/s11625-018-0595-9
   United States Geological Survey, 2016, REP PHOT PROJ
   Vollmer Michael, 2018, Physics Education, V53, DOI 10.1088/1361-6552/aaa954
   Wang P, 2017, IEEE T CIRC SYST VID, V27, P2613, DOI 10.1109/TCSVT.2016.2576761
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Wehrwein S, 2021, IEEE T VIS COMPUT GR, V27, P2495, DOI 10.1109/TVCG.2020.2993195
   Wikipedia contributors, 2022, TIM LAPS PHOT WIK FR
   Yang J, 2015, ADV ENG INFORM, V29, P211, DOI 10.1016/j.aei.2015.01.011
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhang X, 2017, COMPUT GRAPH FORUM, V36, P105, DOI 10.1111/cgf.13276
   Zheng ZX, 2019, NEUROCOMPUTING, V358, P446, DOI 10.1016/j.neucom.2019.05.058
   Zhou F, 2014, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2014.429
NR 51
TC 1
Z9 1
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 171
EP 181
DI 10.1109/TVCG.2022.3209454
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800003
PM 36166532
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bae, SS
   Vanukuru, R
   Yang, RH
   Gyory, P
   Zhou, R
   Do, EYL
   Szafir, DA
AF Bae, S. Sandra
   Vanukuru, Rishi
   Yang, Ruhan
   Gyory, Peter
   Zhou, Ran
   Do, Ellen Yi-Luen
   Szafir, Danielle Albers
TI Cultivating Visualization Literacy for Children Through Curiosity and
   Play
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization literacy; children; constructionism; informal
   learning
ID BUILDING-BLOCKS
AB Fostering data visualization literacy (DVL) as part of childhood education could lead to a more data literate society. However, most work in DVL for children relies on a more formal educational context (i.e., a teacher-led approach) that limits children's engagement with data to classroom-based environments and, consequently, children's ability to ask questions about and explore data on topics they find personally meaningful. We explore how a curiosity-driven, child-led approach can provide more agency to children when they are authoring data visualizations. This paper explores how informal learning with crafting physicalizations through play and curiosity may foster increased literacy and engagement with data. Employing a constructionist approach, we designed a do-it-yourself toolkit made out of everyday materials (e.g., paper, cardboard, mirrors) that enables children to create, customize, and personalize three different interactive visualizations (bar, line, pie). We used the toolkit as a design probe in a series of in-person workshops with 5 children (6 to 11-year-olds) and interviews with 5 educators. Our observations reveal that the toolkit helped children creatively engage and interact with visualizations. Children with prior knowledge of data visualization reported the toolkit serving as more of an authoring tool that they envision using in their daily lives, while children with little to no experience found the toolkit as an engaging introduction to data visualization. Our study demonstrates the potential of using the constructionist approach to cultivate children's DVL through curiosity and play.
C1 [Bae, S. Sandra; Vanukuru, Rishi; Yang, Ruhan; Gyory, Peter; Zhou, Ran; Do, Ellen Yi-Luen] CU Boulder, Boulder, CO 80309 USA.
   [Szafir, Danielle Albers] Univ N Carolina, Chapel Hill, NC USA.
C3 University of Colorado System; University of Colorado Boulder;
   University of North Carolina; University of North Carolina Chapel Hill
RP Bae, SS (corresponding author), CU Boulder, Boulder, CO 80309 USA.
EM suba2574@colorado.edu; riva3436@colorado.edu; ruya6408@colorado.edu;
   pegy8859@colorado.edu; razh6791@colorado.edu; yido3201@colorado.edu;
   danielle.szafir@cs.unc.edu
RI Do, Ellen Yi-Luen/B-3621-2009
OI Do, Ellen Yi-Luen/0000-0002-9948-6375; Bae, Sandra/0000-0002-2023-6219;
   Yang, Ruhan/0000-0001-9689-0877; Zhou, Ran/0000-0002-5309-056X
FU National Science Foundation [IIS-2040489, IIS-2046725, STEM+C 1933915]
FX The authors would like to thank Dr. Shaz Zamore for their assistance on
   the project. This material is based upon work supported by the National
   Science Foundation under Grant No. IIS-2040489, IIS-2046725, & STEM+C
   1933915.
CR Airinei D., 2010, 2010 PROCEEDING WSEA
   Alimisis D., 2009, Teacher education on robotics-enhanced constructivist pedagogical methods, P11
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Anderson ML, 2012, TOP COGN SCI, V4, P717, DOI 10.1111/j.1756-8765.2012.01211.x
   [Anonymous], 2020, LANCET INFECT DIS, V20, P875, DOI 10.1016/S1473-3099(20)30565-X
   [Anonymous], 2012, P 6 INT C TANG EMB E, DOI DOI 10.1145/2148131.2148219
   Bae S, 2021, IDC '21: PROCEEDINGS OF INTERACTION DESIGN AND CHILDREN 2021, P433, DOI 10.1145/3459990.3465191
   Bhargava R., 2017, P 2017 DESIGNING INT
   Bishop F, 2020, IEEE T VIS COMPUT GR, V26, P451, DOI 10.1109/TVCG.2019.2934804
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Bohman Samuel, 2015, Electronic Government and the Information Systems Perspective. 4th International Conference, EGOVIS 2015. Proceedings: LNCS 9265, P302, DOI 10.1007/978-3-319-22389-6_22
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Brehmer M., 2021, MOBILE DATA VISUALIZ, P67
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Camba JD, 2022, IEEE COMPUT GRAPH, V42, P116, DOI 10.1109/MCG.2021.3132004
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Claes Sandy., 2015, Proceedings of the 4th International Symposium on Pervasive Displays (PerDis'15), P201, DOI DOI 10.1145/2757710.2757733
   D'Ignazio C., 2016, The Journal of Community Informatics, V12
   D'Ignazio C, 2018, DIGIT HUMANITIES Q, V12
   Dasgupta S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3620, DOI 10.1145/3025453.3025847
   Doan S, 2021, J BUS TECH COMMUN, V35, P73, DOI 10.1177/1050651920958392
   Dork Marian., 2013, PROC ACM CHI EXTENDE, P2189, DOI 10.1145/2468356.2468739
   Druin A, 2002, BEHAV INFORM TECHNOL, V21, P1, DOI [10.1080/01449290110108659, 10.1080/014492901101008659]
   Fekete JD, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P167, DOI 10.1109/INFVIS.2004.64
   Gäbler J, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P389, DOI 10.1145/3341215.3356283
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Goswami U., 2002, BLACKWELL HDB CHILDH
   Gourlet P, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P247, DOI 10.1145/3064663.3064794
   Heer J., 2005, P SIGCHI C HUM FACT, P421
   Hirsh-Pasek K, 2015, PSYCHOL SCI PUBL INT, V16, P3, DOI 10.1177/1529100615569721
   Hopkins A., 2020, VISACTIVITIES IEEE V
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Huron S., 2016, PEDAGOGY DATA VISUAL
   Huron S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1409, DOI 10.1145/3064663.3064798
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Huron Samuel, 2014, P 2014 C DES INT SYS, P433, DOI [DOI 10.1145/2598510.2598566, DOI 10.1145/ONDESIGNINGINTERACTIVESYSTEMS(DIS'2598510.2598566]
   Huynh E, 2021, IEEE T VIS COMPUT GR, V27, P924, DOI 10.1109/TVCG.2020.3030464
   jcmellado, 2018, JAV PORT AR LIB
   Jones Andrew Michael, 2017, FDN TRENDS ECONOMETR
   Kahn K, 2021, BRIT J EDUC TECHNOL, V52, P1130, DOI 10.1111/bjet.13088
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Knudsen S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186539
   Kokina J., 2017, J ACCOUNTING ED, V38, P50, DOI 10.1016/j.jaccedu.2016.12.005
   Lauer C, 2020, IEEE T PROF COMMUN, V63, P327, DOI 10.1109/TPC.2020.3032053
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee Victor R., 2022, Journal of Science Education and Technology, V31, P81, DOI 10.1007/s10956-021-09932-1
   Liu LJ, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050604
   Mareschal S., 2020, USING FOCUS GROUP DI
   Mendez GG, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P841, DOI 10.1145/3025453.3025942
   Moere AV, 2010, VISUAL INFORMATION COMMUNICATION, P1, DOI 10.1007/978-1-4419-0312-9_1
   Murphy SA, 2013, J WEB LIBRARIANSH, V7, P465, DOI 10.1080/19322909.2013.825148
   N. C. for Educational Statistics, 2021, CHILDR INT ACC HOM
   Oblinger D., 2005, EDUCAUSE Q, V1
   Oblinger D., 2004, Journal of Interactive Media in Education, V2004, DOI DOI 10.5334/2004-8-OBLINGER
   Papert S., 1994, The children's machine: Rethinking school in the age of the computer
   Payne WC, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445149
   Perin C, 2021, IEEE COMPUT GRAPH, V41, P48, DOI 10.1109/MCG.2021.3115417
   Punch S, 2002, CHILDHOOD, V9, P321, DOI 10.1177/0907568202009003005
   Resnick M, 2000, J LEARN SCI, V9, P7, DOI 10.1207/s15327809jls0901_3
   Resnick Mitchel, 2005, DESIGN PRINCIPLES TO, DOI DOI 10.1184/R1/6621917.V1
   Romero-Ramirez FJ, 2018, IMAGE VISION COMPUT, V76, P38, DOI 10.1016/j.imavis.2018.05.004
   Sarama J, 2004, EARLY CHILD RES Q, V19, P181, DOI 10.1016/j.ecresq.2004.01.014
   Sarama J, 2004, STUD MATH TH LEARN, P361
   Schwabish J.A., 2020, ELEVATE DEBATE MULTI
   Shneiderman B., 2020, MEDIUM
   Thudt A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173728
   Trajkova M, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7030035
   Verdine BN, 2014, CHILD DEV, V85, P1062, DOI 10.1111/cdev.12165
   Verhaert P., 2021, VISACTIVITIES IEEE V
   Weber RP., 1990, Basic content analysis, V2nd ed, DOI 10.4135/9781412983488
   Wickham C., 2016, CONSTRUCTIONISM, P34
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   WOOSTER JS, 1982, ENGL J, V71, P60, DOI 10.2307/816450
   Zheng C, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P909, DOI 10.1145/3357236.3395578
   Zinovyev Andrei, 2010, arXiv
NR 77
TC 13
Z9 13
U1 3
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 257
EP 267
DI 10.1109/TVCG.2022.3209442
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800004
PM 36155440
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ha, S
   Monadjemi, S
   Garnett, R
   Ottley, A
AF Ha, Sunwoo
   Monadjemi, Shayan
   Garnett, Roman
   Ottley, Alvitta
TI A Unified Comparison of User Modeling Techniques for Predicting Data
   Interaction and Detecting Exploration Bias
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual Analytics; Analytic Provenance; User Interaction Modeling;
   Machine Learning; Benchmark Study
ID VISUALIZATION; SCIENCE
AB The visual analytics community has proposed several user modeling algorithms to capture and analyze users' interaction behavior in order to assist users in data exploration and insight generation. For example, some can detect exploration biases while others can predict data points that the user will interact with before that interaction occurs. Researchers believe this collection of algorithms can help create more intelligent visual analytics tools. However, the community lacks a rigorous evaluation and comparison of these existing techniques. As a result, there is limited guidance on which method to use and when. Our paper seeks to fill in this missing gap by comparing and ranking eight user modeling algorithms based on their performance on a diverse set of four user study datasets. We analyze exploration bias detection, data interaction prediction, and algorithmic complexity, among other measures. Based on our findings, we highlight open challenges and new directions for analyzing user interactions and visualization provenance.
C1 [Ha, Sunwoo; Monadjemi, Shayan; Garnett, Roman; Ottley, Alvitta] Univ Washington, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Ha, S (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM sha@wustl.edu; monadjemi@wustl.edu; garnett@wustl.edu; alvitta@wustl.edu
RI Garnett, Roman/N-9894-2014
OI Ottley, Alvitta/0000-0002-9485-276X; Monadjemi,
   Shayan/0000-0002-9385-5969
FU National Science Foundation [OAC-2118201, IIS-2142977]
FX This work is supported in part by the National Science Foundation under
   Grant No. OAC-2118201 and IIS-2142977.
CR Battle L, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1363, DOI 10.1145/2882903.2882919
   Brod M, 2009, QUAL LIFE RES, V18, P1263, DOI 10.1007/s11136-009-9540-9
   Brown ET, 2014, IEEE T VIS COMPUT GR, V20, P1663, DOI 10.1109/TVCG.2014.2346575
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cho I, 2017, IEEE CONF VIS ANAL, P116, DOI 10.1109/VAST.2017.8585665
   Cook K.A., 2005, Technical Report
   Crouser R.J., 2013, Handbook of Human Computation, P615
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Ebbinghaus H., 1885, GEDACHTNIS UNTERSUCH
   Ebbinghaus H., 1880, URMANUSKRIPT UEBER G
   Ellis Geoffrey, 2018, Cognitive Biases in Visualizations
   Fan CR, 2018, COMPUT GRAPH FORUM, V37, P111, DOI 10.1111/cgf.13405
   Feng M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173711
   Feng M, 2019, IEEE T VIS COMPUT GR, V25, P501, DOI 10.1109/TVCG.2018.2865117
   Gadhave K, 2021, INFORM VISUAL, V20, P207, DOI 10.1177/14738716211038604
   Gigerenzer G, 2009, TOP COGN SCI, V1, P107, DOI 10.1111/j.1756-8765.2008.01006.x
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Gotz D, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P85, DOI 10.1145/2856767.2856779
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1744, DOI 10.1109/TVCG.2012.23
   Khan MA, 2019, PROCEEDINGS OF IUI 2019, P177, DOI 10.1145/3301275.3302291
   Kim Hae-Young, 2017, Restor Dent Endod, V42, P152, DOI 10.5395/rde.2017.42.2.152
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lightner R., 2016, INSIDE AM BOARDROOMS
   Liu ZL, 2020, COMPUT GRAPH FORUM, V39, P693, DOI 10.1111/cgf.14033
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   McHugh ML, 2013, BIOCHEM MEDICA, V23, P143, DOI 10.11613/BM.2013.018
   Monadjemi S, 2022, Arxiv, DOI arXiv:2010.08155
   Monadjemi S, 2021, IEEE T VIS COMPUT GR, V27, P412, DOI 10.1109/TVCG.2020.3030430
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murre JMJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120644
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P1009, DOI 10.1109/TVCG.2021.3114827
   Nickerson R.S., 1998, Review of General Psychology, V2, P175, DOI [DOI 10.1037/1089-2680.2.2.175, 10.1037/1089-2680.2.2.175, 10.1037/1089-2680.2.2.17]
   Ottley A, 2019, COMPUT GRAPH FORUM, V38, P41, DOI 10.1111/cgf.13670
   Perry J., 2009, Supporting cognitive models of sensemaking in analytics systems, V12
   Pike WA, 2009, INFORM VISUAL, V8, P263, DOI 10.1057/ivs.2009.22
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Ribarsky W, 2009, INFORM VISUAL, V8, P254, DOI 10.1057/ivs.2009.28
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Wall E, 2022, IEEE T VIS COMPUT GR, V28, P966, DOI 10.1109/TVCG.2021.3114862
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   WINSHIP C, 1992, ANNU REV SOCIOL, V18, P327, DOI 10.1146/annurev.so.18.080192.001551
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   ZhiYing Zhou, 2021, 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), P1, DOI 10.1109/GCCE53005.2021.9622105
NR 49
TC 3
Z9 4
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 483
EP 492
DI 10.1109/TVCG.2022.3209476
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800005
PM 36155457
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lin, HH
   Akbaba, D
   Meyer, M
   Lex, A
AF Lin, Haihan
   Akbaba, Derya
   Meyer, Miriah
   Lex, Alexander
TI Data Hunches: Incorporating Personal Knowledge into Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data Visualization; Uncertainty; Data Hunches
ID NOTE-TAKING; ADOPTION; ONLINE; IMPACT; EYES
AB The trouble with data is that it frequently provides only an imperfect representation of a phenomenon of interest. Experts who are familiar with their datasets will often make implicit, mental corrections when analyzing a dataset, or will be cautious not to be overly confident about their findings if caveats are present. However, personal knowledge about the caveats of a dataset is typically not incorporated in a structured way, which is problematic if others who lack that knowledge interpret the data. In this work, we define such analysts' knowledge about datasets as data hunches. We differentiate data hunches from uncertainty and discuss types of hunches. We then explore ways of recording data hunches, and, based on a prototypical design, develop recommendations for designing visualizations that support data hunches. We conclude by discussing various challenges associated with data hunches, including the potential for harm and challenges for trust and privacy. We envision that data hunches will empower analysts to externalize their knowledge, facilitate collaboration and communication, and support the ability to learn from others' data hunches.
C1 [Lin, Haihan; Akbaba, Derya; Lex, Alexander] Univ Utah, Salt Lake City, UT 84112 USA.
C3 Utah System of Higher Education; University of Utah
RP Lin, HH (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.
EM hhlin@sci.utah.edu; derya@cs.utah.edu; miriah.meyer@liu.se;
   alex@sci.utah.edu
OI Lex, Alexander/0000-0001-6930-5468; Akbaba, Derya/0000-0001-9419-3402;
   LIN, HAIHAN/0000-0001-9201-2268
FU National Science Foundation [OAC 1835904, IIS 1751238]; Wallenberg AI,
   Autonomous Systems and Software Program (WASP) - Knut and Alice
   Wallenberg Foundation
FX We wish to thank Anders Ynnerman, Ben Shneiderman, Ryan Metcalf, and the
   Visualization Design Lab for fruitful discussions and feedback. This
   work was supported by the National Science Foundation (OAC 1835904, IIS
   1751238), ARUP Laboratories, and by the Wallenberg AI, Autonomous
   Systems and Software Program (WASP) funded by the Knut and Alice
   Wallenberg Foundation.
CR Aisch G., 2015, NEW YORK TIMES MAY
   Arnold M, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2942288
   Badam SK, 2022, INFORM VISUAL, V21, P270, DOI 10.1177/14738716221079591
   Barlett CP, 2015, PSYCHOL POP MEDIA CU, V4, P70, DOI 10.1037/a0034335
   Baudel T., 2006, P 19 ANN ACM S USER, P67, DOI DOI 10.1145/1166253.1166265
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Boukhelifa N, 2012, IEEE T VIS COMPUT GR, V18, P2769, DOI 10.1109/TVCG.2012.220
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Brynjolfsson E, 2016, AM ECON REV, V106, P133, DOI 10.1257/aer.p20161016
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Covitt BA, 2022, SCI EDUC-NETHERLANDS, V31, P1155, DOI 10.1007/s11191-022-00322-6
   Cutler Z, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P116, DOI 10.1109/VIS47514.2020.00030
   DIgnazio Catherine, 2016, P WORKSH VIS DIG HUM
   Dork Marian., 2013, PROC ACM CHI EXTENDE, P2189, DOI 10.1145/2468356.2468739
   Drucker J, 2011, DIGIT HUMANITIES Q, V5
   Feng M, 2017, IEEE T VIS COMPUT GR, V23, P351, DOI 10.1109/TVCG.2016.2599058
   Fischer F, 2019, CRIT POLICY STUD, V13, P133, DOI 10.1080/19460171.2019.1602067
   Fleck Rowanne, 2010, P 22 C COMP HUM INT, P216, DOI DOI 10.1145/1952222.1952269
   Franke M., 2019, P 4 VIS4DH WORKSHOP
   Gadhave K., 2022, EUROVIS, DOI [10.31219/osf.io/udqjr, DOI 10.31219/OSF.IO/UDQJR]
   Gadhave K, 2021, INFORM VISUAL, V20, P207, DOI 10.1177/14738716211038604
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Goyal Nitesh, 2013, P SIGCHI C HUM FACT, P2721, DOI DOI 10.1145/2470654.2481376
   Guan T, 2018, COMPUT HUM BEHAV, V81, P137, DOI 10.1016/j.chb.2017.12.023
   HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066
   Heer J, 2009, COMMUN ACM, V52, P87, DOI 10.1145/1435417.1435439
   Hegarty M, 1997, LEARN INDIVID DIFFER, V9, P19, DOI 10.1016/S1041-6080(97)90018-2
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Iwasa J., 2020, SARS COV 2 VISUALIZA
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Karer B, 2021, IEEE T VIS COMPUT GR, V27, P1011, DOI 10.1109/TVCG.2020.3030376
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lin HH, 2021, INFORM VISUAL, V20, P123, DOI 10.1177/14738716211028565
   Mahyar N, 2012, INFORM VISUAL, V11, P190, DOI 10.1177/1473871611433713
   Marasoiu Mariana, 2016, P EUR IEEE VGTC C VI, P125
   Mathisen A, 2019, COMPUT GRAPH FORUM, V38, P649, DOI 10.1111/cgf.13717
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Mohammed S., 2001, J. Appl. Behav. Sci., V37, P408
   Morgan MG, 2014, P NATL ACAD SCI USA, V111, P7176, DOI 10.1073/pnas.1319946111
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   N. S. Foundation, NSFS 10 BIG ID SPEC
   Nowak S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P81, DOI 10.1109/VIS47514.2020.00023
   Padilla LMK, 2021, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.579267
   Padilla LMK, 2020, J EXP PSYCHOL-APPL, V26, P1, DOI 10.1037/xap0000245
   Panagiotidou G, 2022, IEEE T VIS COMPUT GR, V28, P4389, DOI 10.1109/TVCG.2021.3088339
   Passi Samir, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274405
   Potter K, 2010, COMPUT GRAPH FORUM, V29, P823, DOI 10.1111/j.1467-8659.2009.01677.x
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Potter K, 2012, INT J UNCERTAIN QUAN, V2, P397, DOI 10.1615/Int.J.UncertaintyQuantification.2012004074
   Quispel A, 2014, J VISUAL LANG COMPUT, V25, P107, DOI 10.1016/j.jvlc.2013.11.007
   Romat H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300272
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Schn D. A., 1983, The Reflective Practitioner: How Professionals Think in Action
   Thomson J, 2005, P SOC PHOTO-OPT INS, V5669, P146, DOI 10.1117/12.587254
   Troilo M, 2016, OMEGA-INT J MANAGE S, V59, P72, DOI 10.1016/j.omega.2015.05.011
   van der Bles AM, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181870
   VanderPlas J, 2018, J. Open Source Softw., V3, P1057, DOI DOI 10.21105/JOSS.01057
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Walker W. E., 2003, Integrated assessment, V4, P5, DOI [10.1076/iaij.4.1.5.16466, DOI 10.1076/IAIJ.4.1.5.16466]
   Walny J, 2018, IEEE T VIS COMPUT GR, V24, P770, DOI 10.1109/TVCG.2017.2745958
   Walny J, 2011, IEEE T VIS COMPUT GR, V17, P2508, DOI 10.1109/TVCG.2011.251
   Wang April Yi, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359141
   Willett W, 2015, IEEE COMPUT GRAPH, V35, P38, DOI 10.1109/MCG.2015.52
   Wittenbrink CM, 1996, IEEE T VIS COMPUT GR, V2, P266, DOI 10.1109/2945.537309
   Wood J, 2012, IEEE T VIS COMPUT GR, V18, P2749, DOI 10.1109/TVCG.2012.262
NR 74
TC 10
Z9 10
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 504
EP 514
DI 10.1109/TVCG.2022.3209451
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800006
PM 36155455
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bauer, D
   Wu, Q
   Ma, KL
AF Bauer, David
   Wu, Qi
   Ma, Kwan-Liu
TI FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volume data; volume visualization; deep learning; foveated rendering;
   neural reconstruction
ID OCCLUSION SHADING MODEL; AMBIENT OCCLUSION; OPTICAL-FLOW
AB Volume data is found in many important scientific and engineering applications. Rendering this data for visualization at high quality and interactive rates for demanding applications such as virtual reality is still not easily achievable even using professional-grade hardware. We introduce FoVolNet-a method to significantly increase the performance of volume data visualization. We develop a cost-effective foveated rendering pipeline that sparsely samples a volume around a focal point and reconstructs the full-frame using a deep neural network. Foveated rendering is a technique that prioritizes rendering computations around the user's focal point. This approach leverages properties of the human visual system, thereby saving computational resources when rendering data in the periphery of the user's field of vision. Our reconstruction network combines direct and kernel prediction methods to produce fast, stable, and perceptually convincing output. With a slim design and the use of quantization, our method outperforms state-of-the-art neural reconstruction techniques in both end-to-end frame times and visual quality. We conduct extensive evaluations of the system's rendering performance, inference speed, and perceptual properties, and we provide comparisons to competing neural image reconstruction techniques. Our test results show that FoVolNet consistently achieves significant time saving over conventional rendering while preserving perceptual quality.
C1 [Bauer, David; Wu, Qi; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Bauer, D (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM davbauer@ucdavis.edu; qadwu@ucdavis.edu; klma@ucdavis.edu
RI wu, qirui/GLU-4942-2022; Bauer, David/JDN-0139-2023
OI WU, Qi/0000-0003-0342-9366
FU Department of Energy [SC-DE0019486]; Intel's oneAPI Centers of
   Excellence grant
FX This research is sponsored in part by the Department of Energy through
   grant SC-DE0019486 and Intel's oneAPI Centers of Excellence grant.
CR Adler F.H., 2011, Adler's physiology of the eye
   AlanWolfe Nathan Morrical, 2022, P EUR S REND, P117, DOI DOI 10.2312/SR.20221161
   Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073708, 10.1145/3072959.3073703]
   Beyer J, 2014, EUR C VIS EUROVIS, DOI DOI 10.2312/EUROVISSTAR.20141175
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Dappa E, 2016, INSIGHTS IMAGING, V7, P849, DOI 10.1007/s13244-016-0518-1
   Díaz J, 2010, COMPUT GRAPH-UK, V34, P337, DOI 10.1016/j.cag.2010.03.005
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Facebook Inc, 2022, PYTORCH
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gharbi M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322954
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Hanika J., 2021, JCGT, V10, P19
   Hasselgren J, 2020, COMPUT GRAPH FORUM, V39, P147, DOI 10.1111/cgf.13919
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Hofmann N, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406181
   Huo Y, 2021, COMPUT VIS MEDIA, V7, P169, DOI 10.1007/s41095-021-0209-9
   Igouchkine O, 2018, IEEE T VIS COMPUT GR, V24, P3147, DOI 10.1109/TVCG.2017.2784830
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Kettunen M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323038
   Klacansky P., Open Scientific Visualization Datasets
   Kniss J, 2003, IEEE T VIS COMPUT GR, V9, P150, DOI 10.1109/TVCG.2003.1196003
   Kniss J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P109, DOI 10.1109/VISUAL.2002.1183764
   Krishnamoorthi R, 2018, Arxiv, DOI arXiv:1806.08342
   Kroes T., 2015, GPU Pro 6: Advanced Rendering Techniques, P475, DOI DOI 10.1201/9781351052108-172
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Le Besnerais G, 2005, IEEE IMAGE PROC, P493
   Levoy M., STANFORD VOLUME DATA
   Liu N, 2016, COMPUT ANIMAT VIRT W, V27, P394, DOI 10.1002/cav.1706
   Lu Y., 2020, SIGGRAPH ASIA 2020 T, P1, DOI DOI 10.1145/3410700
   Lundell F., 2011, THESIS LINKOPING U
   Maisano J., 2003, Digital Morphology
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Max N., 2010, SCI VISUALIZATION AD, V1, P259, DOI [10.4230/DFU.SciViz.2010.259, DOI 10.4230/DFU.SCIVIZ.2010.259]
   NVIDIA, 2022, Tensorrt
   Oak Ridge National Lab, SUP DAT
   Paladini G., 2015, IND TALK EG VGTC EUR
   Perez-Ortiz M, 2020, IEEE T IMAGE PROCESS, V29, P1139, DOI 10.1109/TIP.2019.2936103
   Plyer A, 2016, J REAL-TIME IMAGE PR, V11, P713, DOI 10.1007/s11554-014-0423-0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Ropinski T, 2010, IEEE PAC VIS SYMP, P169, DOI 10.1109/PACIFICVIS.2010.5429594
   Ruiz M., 2008, IEEE EG S VOLUME POI, P113, DOI DOI 10.2312/VG/VG-PBG08/113-1202
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Schott M, 2009, COMPUT GRAPH FORUM, V28, P855, DOI 10.1111/j.1467-8659.2009.01464.x
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Shih M, 2014, SYMP LARG DATA ANAL, P93, DOI 10.1109/LDAV.2014.7013209
   Silver D., VORTICES VOLUME DATA
   Soltészová V, 2010, COMPUT GRAPH FORUM, V29, P883, DOI 10.1111/j.1467-8659.2009.01695.x
   Stengel M, 2016, COMPUT GRAPH FORUM, V35, P129, DOI 10.1111/cgf.12956
   Sundén E, 2011, IEEE T VIS COMPUT GR, V17, P2125, DOI 10.1109/TVCG.2011.211
   Thomas MM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417786
   Vogels T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201388
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Weier M, 2017, COMPUT GRAPH FORUM, V36, P611, DOI 10.1111/cgf.13150
   Weier M, 2016, COMPUT GRAPH FORUM, V35, P289, DOI 10.1111/cgf.13026
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Wong KM, 2018, SA'18: SIGGRAPH ASIA 2018 TECHNICAL BRIEFS, DOI 10.1145/3283254.3283261
   Wright L., 2019, Ranger - a synergistic optimizer
   Xu B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356547
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YB, 2013, P ACM SIGGRAPH S INT, DOI DOI 10.1145/2448196.2448205
NR 66
TC 9
Z9 10
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 515
EP 525
DI 10.1109/TVCG.2022.3209498
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800007
PM 36155446
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lyi, S
   Gehlenborg, N
AF Lyi, Sehi
   Gehlenborg, Nils
TI Multi-View Design Patterns and Responsive Visualization for Genomics
   Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Responsive visualization; multi-view visualization; genomics;
   visualization grammar
ID BROWSER; DISPLAY; SPACE
AB A series of recent studies has focused on designing cross-resolution and cross-device visualizations, i.e., responsive visualization, a concept adopted from responsive web design. However, these studies mainly focused on visualizations with a single view to a small number of views, and there are still unresolved questions about how to design responsive multi-view visualizations. In this paper, we present a reusable and generalizable framework for designing responsive multi-view visualizations focused on genomics data. To gain a better understanding of existing design challenges, we review web-based genomics visualization tools in the wild. By characterizing tools based on a taxonomy of responsive designs, we find that responsiveness is rarely supported in existing tools. To distill insights from the survey results in a systematic way, we classify typical view composition patterns, such as "vertically long," "horizontally wide," "circular," and "cross-shaped" compositions. We then identify their usability issues in different resolutions that stem from the composition patterns, as well as discussing approaches to address the issues and to make genomics visualizations responsive. By extending the Gosling visualization grammar to support responsive constructs, we show how these approaches can be supported. A valuable follow-up study would be taking different input modalities into account, such as mouse and touch interactions, which was not considered in our study.
C1 [Lyi, Sehi; Gehlenborg, Nils] Harvard Med Sch, Boston, MA 02115 USA.
C3 Harvard University; Harvard Medical School
RP Lyi, S (corresponding author), Harvard Med Sch, Boston, MA 02115 USA.
EM sehi_lyi@hms.harvard.edu; nils@hms.harvard.edu
OI L'Yi, Sehi/0000-0001-7720-2848; Gehlenborg, Nils/0000-0003-0327-8297
FU National Institutes of Health [U01CA200059, U24CA237617, UM1HG011536,
   R01HG011773]
FX This work was supported by the National Institutes of Health
   (U01CA200059, U24CA237617, UM1HG011536, R01HG011773). We are grateful to
   the reviewers and to Qianwen Wang for their valuable feedback.
CR Aguet F, 2020, SCIENCE, V369, P1318, DOI 10.1126/science.aaz1776
   Andrews K., 2018, WORKSH DAT VIS MOB D, P4
   Andrews K., 2017, EUROVIS 2017 EUR ASS, DOI DOI 10.2312/EURP.20171182
   Aurisano J, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S11-S6
   Badam SK, 2021, INFORM VISUAL, V20, P229, DOI 10.1177/14738716211038614
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bremer N., 2022, WHY DO CATS
   Buels R, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-0924-1
   Cao XY, 2013, BIOINFORMATICS, V29, P1223, DOI 10.1093/bioinformatics/btt114
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Cook K.A., 2005, Technical Report
   Deng DZ, 2022, Arxiv, DOI [arXiv:2203.10476, 10.48550/arXiv.2203.10476, DOI 10.48550/ARXIV.2203.10476]
   Developers G., 2022, GOOGL SPREADSH
   Diesh C., 2022, LIST INTERESTING GEN
   Gardner B.S., 2011, Sigma Journal: Inside the Digital Ecosystem, V11, P13
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Goldman M, 2019, BIORXIV, V2019, DOI [10.1101/326470, DOI 10.1101/326470]
   Grant JR, 2008, NUCLEIC ACIDS RES, V36, pW181, DOI 10.1093/nar/gkn179
   Hoffswell J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376777
   Horak T, 2021, MOBILE DATA VISUALIZ, P33, DOI [10.1201/9781003090823-2, DOI 10.1201/9781003090823-2]
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Jänicke S, 2015, DIGIT SCHOLARSH HUM, V30, P83, DOI 10.1093/llc/fqv049
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kerpedjiev P., 2018, HIGLASS APP
   Kerpedjiev P, 2018, GENOME BIOL, V19, DOI 10.1186/s13059-018-1486-1
   Kim H., 2022, CHI C HUMAN FACTORS, P1
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim H, 2021, COMPUT GRAPH FORUM, V40, P459, DOI 10.1111/cgf.14321
   Kolishovski G, 2019, MAMM GENOME, V30, P353, DOI 10.1007/s00335-019-09821-4
   Koytek P, 2018, IEEE T VIS COMPUT GR, V24, P605, DOI 10.1109/TVCG.2017.2743859
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   Lee J, 2016, NUCLEIC ACIDS RES, V44, pW35, DOI 10.1093/nar/gkw310
   LePage P., 2022, RESPONSIVE WEB DESIG
   Li DF, 2019, NUCLEIC ACIDS RES, V47, pW158, DOI 10.1093/nar/gkz348
   Liu XT, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P269, DOI 10.1145/2702123.2702217
   Manz T., 2022, GOS DECLARATIVE LIB
   Moscovich T, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2319
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Myers B.A., 1995, ACM Trans. Comput.-Hum. Interact., V2, P64, DOI [10.1145/200968.200971, DOI 10.1145/200968.200971]
   Nusrat S, 2019, COMPUT GRAPH FORUM, V38, P781, DOI 10.1111/cgf.13727
   O'Brien TM, 2010, IEEE T VIS COMPUT GR, V16, P918, DOI 10.1109/TVCG.2010.163
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Pandey A., 2022, GENOREC RECOMMENDATI
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Rangwala SH, 2021, GENOME RES, V31, P159, DOI 10.1101/gr.266932.120
   Robinson JT, 2018, CELL SYST, V6, P256, DOI 10.1016/j.cels.2018.01.001
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   SCHNEIDER TD, 1990, NUCLEIC ACIDS RES, V18, P6097, DOI 10.1093/nar/18.20.6097
   Shih J., 2022, GENOCAT DATABASE GEN
   Sittig Dean F, 2015, COGNITIVE INFORM BIO, P59
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Stitz H, 2016, IEEE T VIS COMPUT GR, V22, P2594, DOI 10.1109/TVCG.2015.2513389
   Wagner J, 2018, NUCLEIC ACIDS RES, V46, P2777, DOI 10.1093/nar/gky136
   Wang JP, 2019, INFORM VISUAL, V18, P94, DOI 10.1177/1473871617733996
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Wilming LG, 2008, NUCLEIC ACIDS RES, V36, pD753, DOI 10.1093/nar/gkm987
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Zeidler C, 2017, J LOG ALGEBR METHODS, V89, P67, DOI 10.1016/j.jlamp.2017.01.004
   Zhang K., 2021, BIORXIV
   Zheng RB, 2019, NUCLEIC ACIDS RES, V47, pD729, DOI 10.1093/nar/gky1094
NR 69
TC 3
Z9 4
U1 4
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 559
EP 569
DI 10.1109/TVCG.2022.3209398
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800008
PM 36166553
OA Green Accepted, Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Pandey, A
   L'Yi, S
   Wang, QW
   Borkin, MA
   Gehlenborg, N
AF Pandey, Aditeya
   L'Yi, Sehi
   Wang, Qianwen
   Borkin, Michelle A.
   Gehlenborg, Nils
TI GenoREC: A Recommendation System for Interactive Genomics Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; genomics; visualization; recommendation systems; data;
   tasks
ID BROWSER; DESIGN
AB Interpretation of genomics data is critically reliant on the application of a wide range of visualization tools. A large number of visualization techniques for genomics data and different analysis tasks pose a significant challenge for analysts: which visualization technique is most likely to help them generate insights into their data? Since genomics analysts typically have limited training in data visualization, their choices are often based on trial and error or guided by technical details, such as data formats that a specific tool can load. This approach prevents them from making effective visualization choices for the many combinations of data types and analysis questions they encounter in their work. Visualization recommendation systems assist non-experts in creating data visualization by recommending appropriate visualizations based on the data and task characteristics. However, existing visualization recommendation systems are not designed to handle domain-specific problems. To address these challenges, we designed GenoREC, a novel visualization recommendation system for genomics. GenoREC enables genomics analysts to select effective visualizations based on a description of their data and analysis tasks. Here, we present the recommendation model that uses a knowledge-based method for choosing appropriate visualizations and a web application that enables analysts to input their requirements, explore recommended visualizations, and export them for their usage. Furthermore, we present the results of two user studies demonstrating that GenoREC recommends visualizations that are both accepted by domain experts and suited to address the given genomics analysis problem. All supplemental materials are available at https://osf.io/y73pt/.
C1 [Pandey, Aditeya; Borkin, Michelle A.] Northeastern Univ, Boston, MA 02115 USA.
   [L'Yi, Sehi; Wang, Qianwen; Gehlenborg, Nils] Harvard Med Sch, Boston, MA USA.
C3 Northeastern University; Harvard University; Harvard Medical School
RP Pandey, A (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM pandey.ad@northeastern.edu; sehi_lyi@hms.harvard.edu;
   qianwen_wang@hms.harvard.edu; m.borkin@northeastern.edu;
   nils@hms.harvard.edu
RI Wang, Qianwen/GRJ-9435-2022
OI L'Yi, Sehi/0000-0001-7720-2848; Gehlenborg, Nils/0000-0003-0327-8297;
   Borkin, Michelle/0000-0002-8016-355X
FU National Institutes of Health [U01CA200059, U24CA237617, UM1HG011536,
   R01HG011773]; Khoury College of Computer Sciences, Northeastern
   University
FX This work was supported by the National Institutes of Health
   (U01CA200059, U24CA237617, UM1HG011536, R01HG011773), and the Khoury
   College of Computer Sciences, Northeastern University. The authors are
   grateful to all anonymous study participants and the reviewers.
CR Abdennur N, 2020, BIOINFORMATICS, V36, P311, DOI 10.1093/bioinformatics/btz540
   Aggarwal C.C., 2016, RECOMMENDER SYSTEMS, P167, DOI DOI 10.1007/978-3-319-29659-3_5
   [Anonymous], WILCOXON SIGNED RANK
   [Anonymous], AWESOME GENOME VISUA
   [Anonymous], 2021, UCSC Genome Browser Home
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Buniello A, 2019, NUCLEIC ACIDS RES, V47, pD1005, DOI 10.1093/nar/gky1120
   Cha S.-H., 2007, City, V1, P1, DOI DOI 10.1016/j.physrep.2009.11.002
   CLEVELAND WS, 1985, SCIENCE, V229, P828, DOI 10.1126/science.229.4716.828
   Crisan A, 2020, Arxiv, DOI arXiv:2010.11975
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Diehl A., 2018, EuroVis 2018 - Short Papers, P61, DOI DOI 10.2312/EUROVISSHORT.20181079
   GenoCAT, US
   Gu ZG, 2016, BIOINFORMATICS, V32, P2372, DOI 10.1093/bioinformatics/btw161
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Karolchik D, 2003, NUCLEIC ACIDS RES, V31, P51, DOI 10.1093/nar/gkg129
   Kaur P, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P266, DOI 10.5220/0006175002660273
   Kent WJ, 2002, GENOME RES, V12, P996, DOI 10.1101/gr.229102
   Kerpedjiev P, 2018, GENOME BIOL, V19, DOI 10.1186/s13059-018-1486-1
   Kotkov D, 2016, KNOWL-BASED SYST, V111, P180, DOI 10.1016/j.knosys.2016.08.014
   Kristiansen L., 2021, IEEE T VIS COMPUT GR, V28, P53
   Krzywinski M, 2009, GENOME RES, V19, P1639, DOI 10.1101/gr.092759.109
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   L'Yi S, 2019, COMPUT GRAPH FORUM, V38, P201, DOI 10.1111/cgf.13682
   Li DF, 2019, NUCLEIC ACIDS RES, V47, pW158, DOI 10.1093/nar/gkz348
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Manz S. L&rsquo, 2022, GOS DECLARATIVE LIB, DOI [10.31219/osf .io/yn3ce, DOI 10.31219/OSF.IO/YN3CE]
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Nusrat S, 2019, COMPUT GRAPH FORUM, V38, P781, DOI 10.1111/cgf.13727
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ramírez F, 2016, NUCLEIC ACIDS RES, V44, pW160, DOI 10.1093/nar/gkw257
   Ramos PS, 2011, PLOS GENET, V7, DOI 10.1371/journal.pgen.1002406
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Robinson JT, 2011, NAT BIOTECHNOL, V29, P24, DOI 10.1038/nbt.1754
   ROTH SF, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P112, DOI 10.1145/191666.191719
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Shafer G., 1976, MATH THEORY EVIDENCE
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Staaf J, 2019, NAT MED, V25, P1526, DOI 10.1038/s41591-019-0582-4
   Stolte C, 2008, COMMUN ACM, V51, P75, DOI 10.1145/1400214.1400234
   Swearingen Kirsten, 2001, ACM SIGIR 2001 workshop on recommender systems, V13, P1
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Yi N., 2022, PREPRINT, DOI [10.31219/osf.io/pd7vq[28]S, DOI 10.31219/OSF.IO/PD7VQ[28]S]
   Yin TF, 2012, GENOME BIOL, V13, DOI 10.1186/gb-2012-13-8-r77
   Zeng Z., 2021, ARXIV
   Zheng RB, 2019, NUCLEIC ACIDS RES, V47, pD729, DOI 10.1093/nar/gky1094
   Zhou MY, 2021, Arxiv, DOI arXiv:2008.11015
NR 61
TC 4
Z9 5
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 570
EP 580
DI 10.1109/TVCG.2022.3209407
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800009
PM 36191105
OA hybrid, Green Accepted, Green Published
DA 2024-11-06
ER

PT J
AU Cheng, FR
   Keller, MS
   Qu, HM
   Gehlenborg, N
   Wang, QW
AF Cheng, Furui
   Keller, Mark S.
   Qu, Huamin
   Gehlenborg, Nils
   Wang, Qianwen
TI Polyphony: an Interactive Transfer Learning Framework for Single-Cell
   Data Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interactive Machine Learning; Transfer Learning; Single-cell Data
   Analysis; Human-AI Interaction
ID GENOME-WIDE EXPRESSION; DESIGN; VISUALIZATION; ATLAS; SEQ
AB Reference-based cell-type annotation can significantly reduce time and effort in single-cell analysis by transferring labels from a previously-annotated dataset to a new dataset. However, label transfer by end-to-end computational methods is challenging due to the entanglement of technical (e.g., from different sequencing batches or techniques) and biological (e.g., from different cellular microenvironments) variations, only the first of which must be removed. To address this issue, we propose Polyphony, an interactive transfer learning (ITL) framework, to complement biologists' knowledge with advanced computational methods. Polyphony is motivated and guided by domain experts' needs for a controllable, interactive, and algorithm-assisted annotation process, identified through interviews with seven biologists. We introduce anchors, i.e., analogous cell populations across datasets, as a paradigm to explain the computational process and collect user feedback for model improvement. We further design a set of visualizations and interactions to empower users to add, delete, or modify anchors, resulting in refined cell type annotations. The effectiveness of this approach is demonstrated through quantitative experiments, two hypothetical use cases, and interviews with two biologists. The results show that our anchor-based ITL method takes advantage of both human and machine intelligence in annotating massive single-cell datasets.
C1 [Cheng, Furui; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Keller, Mark S.; Gehlenborg, Nils; Wang, Qianwen] Harvard Univ, Cambridge, MA USA.
C3 Hong Kong University of Science & Technology; Harvard University
RP Cheng, FR (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM fchengaa@ust.hk; mark_keller@hms.harvard.edu; huamin@ust.hk;
   nils@hms.harvard.edu; qianwen_wang@hms.harvard.edu
RI Wang, Qianwen/GRJ-9435-2022
OI Cheng, Furui/0000-0003-2329-6126; Gehlenborg, Nils/0000-0003-0327-8297
FU National Institutes of Health [OT2OD02667, R33CA263666, UM1HG011536,
   T32HG002295]; Hong Kong Theme-based Research Scheme grant [T41-709/17N]
FX This work was supported by the National Institutes of Health(OT2OD02667,
   R33CA263666, UM1HG011536, T32HG002295) and Hong Kong Theme-based
   Research Scheme grant T41-709/17N. Theauthors are grateful to all
   anonymous study participants.
CR Amezquita RA, 2020, NAT METHODS, V17, P137, DOI 10.1038/s41592-019-0654-x
   [Anonymous], 2019, bioRxiv, DOI 10.1101/632216
   Argelaguet R, 2021, NAT BIOTECHNOL, V39, P1202, DOI 10.1038/s41587-021-00895-7
   Barkas N., 2021, pagoda2: Single Cell Analysis and Differential Expression
   Barkas N, 2019, NAT METHODS, V16, P695, DOI 10.1038/s41592-019-0466-z
   Baron M, 2016, CELL SYST, V3, P346, DOI 10.1016/j.cels.2016.08.011
   Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122
   Brehmer M., 2014, P 5 WORKSH TIM ERR N, P1, DOI DOI 10.1145/2669557.2669559
   Cakir B, 2020, NAR GENOM BIOINFORM, V2, DOI 10.1093/nargab/lqaa052
   Chan Zuckerberg Initiative, CELLXGENE INTERACTIV
   Chen KH, 2015, SCIENCE, V348, DOI 10.1126/science.aaa6090
   Chen S, 2019, NAT BIOTECHNOL, V37, P1452, DOI 10.1038/s41587-019-0290-0
   Demiralp Ç, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P1, DOI 10.1109/BioVis.2013.6664340
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Fails J. A., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P39, DOI 10.1145/604045.604056
   Felix C, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P153, DOI 10.1145/3242587.3242596
   Gardeux V, 2017, BIOINFORMATICS, V33, P3123, DOI 10.1093/bioinformatics/btx337
   Gayoso A, 2022, NAT BIOTECHNOL, V40, P163, DOI 10.1038/s41587-021-01206-w
   Gayoso A, 2021, NAT METHODS, V18, P272, DOI 10.1038/s41592-020-01050-x
   Grün D, 2016, CELL STEM CELL, V19, P266, DOI 10.1016/j.stem.2016.05.010
   Haghverdi L, 2018, NAT BIOTECHNOL, V36, P421, DOI 10.1038/nbt.4091
   Hao YH, 2021, CELL, V184, P3573, DOI 10.1016/j.cell.2021.04.048
   Tran HTN, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-019-1850-9
   Höllt T, 2016, COMPUT GRAPH FORUM, V35, P171, DOI 10.1111/cgf.12893
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Kang JB, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25957-x
   Kapoor A, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1343
   Keller MS, 2021, PREPRINT
   Korsunsky I, 2019, NAT METHODS, V16, P1289, DOI 10.1038/s41592-019-0619-0
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lähnemann D, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-1926-6
   Lawlor N, 2017, GENOME RES, V27, P208, DOI 10.1101/gr.212720.116
   Liao MF, 2020, NAT MED, V26, P842, DOI 10.1038/s41591-020-0901-9
   Lin Jia-Ren, 2016, Curr Protoc Chem Biol, V8, P251, DOI 10.1002/cpch.14
   Lopez R, 2018, ADV NEUR IN, V31
   Lotfollahi M, 2022, NAT BIOTECHNOL, V40, P121, DOI 10.1038/s41587-021-01001-7
   Lotfollahi M, 2020, BIOINFORMATICS, V36, pI610, DOI 10.1093/bioinformatics/btaa800
   Luecken MD, 2022, NAT METHODS, V19, P41, DOI 10.1038/s41592-021-01336-8
   Meyer M, 2010, IEEE T VIS COMPUT GR, V16, P908, DOI 10.1109/TVCG.2010.137
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Muraro MJ, 2016, CELL SYST, V3, P385, DOI 10.1016/j.cels.2016.09.002
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F., 2011, Mach Learn Python, V12, P2825
   Polanski K, 2020, BIOINFORMATICS, V36, P964, DOI 10.1093/bioinformatics/btz625
   Regev Aviv, 2017, Elife, V6, DOI 10.7554/eLife.27041
   Rodriques SG, 2019, SCIENCE, V363, P1463, DOI 10.1126/science.aaw1219
   Roth-Berghofer TR, 2004, LECT NOTES COMPUT SC, V3155, P389
   Rozenblatt-Rosen O, 2020, CELL, V181, P236, DOI 10.1016/j.cell.2020.03.053
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Segerstolpe Å, 2016, CELL METAB, V24, P593, DOI 10.1016/j.cmet.2016.08.020
   Sivaraman V, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P418, DOI 10.1145/3490099.3511137
   Smith-Renner A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376624
   Snyder MP, 2019, NATURE, V574, P187, DOI 10.1038/s41586-019-1629-x
   Sohn K, 2015, ADV NEUR IN, V28
   Somarakis A, 2021, IEEE T VIS COMPUT GR, V27, P733, DOI 10.1109/TVCG.2020.3030336
   Somarakis A, 2021, IEEE T VIS COMPUT GR, V27, P98, DOI 10.1109/TVCG.2019.2931299
   Speir ML, 2021, BIOINFORMATICS, V37, P4578, DOI 10.1093/bioinformatics/btab503
   Stuart T, 2019, CELL, V177, P1888, DOI 10.1016/j.cell.2019.05.031
   Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   Wang YJ, 2019, CELL SYST, V8, P506, DOI 10.1016/j.cels.2019.05.007
   Wolf FA, 2018, GENOME BIOL, V19, DOI 10.1186/s13059-017-1382-0
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
NR 66
TC 4
Z9 5
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 591
EP 601
DI 10.1109/TVCG.2022.3209408
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800010
PM 36155452
OA hybrid, Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Athawale, TM
   Johnson, CR
   Sane, S
   Pugmire, D
AF Athawale, Tushar M.
   Johnson, Chris R.
   Sane, Sudhanshu
   Pugmire, David
TI Fiber Uncertainty Visualization for Bivariate Data With Parametric and
   Nonparametric Noise Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; fiber surfaces; and probability
ID TOPOLOGY; SURFACES; DENSITY; SCATTERPLOTS; ENSEMBLES
AB Visualization and analysis of multivariate data and their uncertainty are top research challenges in data visualization. Constructing fiber surfaces is a popular technique for multivariate data visualization that generalizes the idea of level-set visualization for univariate data to multivariate data. In this paper, we present a statistical framework to quantify positional probabilities of fibers extracted from uncertain bivariate fields. Specifically, we extend the state-of-the-art Gaussian models of uncertainty for bivariate data to other parametric distributions (e.g., uniform and Epanechnikov) and more general nonparametric probability distributions (e.g., histograms and kernel density estimation) and derive corresponding spatial probabilities of fibers. In our proposed framework, we leverage Green's theorem for closed-form computation of fiber probabilities when bivariate data are assumed to have independent parametric and nonparametric noise. Additionally, we present a nonparametric approach combined with numerical integration to study the positional probability of fibers when bivariate data are assumed to have correlated noise. For uncertainty analysis, we visualize the derived probability volumes for fibers via volume rendering and extracting level sets based on probability thresholds. We present the utility of our proposed techniques via experiments on synthetic and simulation datasets.
C1 [Athawale, Tushar M.; Pugmire, David] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
   [Johnson, Chris R.] Univ Utah, Imaging SCI Inst, Salt Lake City, UT USA.
   [Sane, Sudhanshu] Luminary Cloud Inc, Redwood City, CA USA.
C3 United States Department of Energy (DOE); Oak Ridge National Laboratory;
   Utah System of Higher Education; University of Utah
RP Athawale, TM (corresponding author), Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
EM athawaletm@ornl.gov; crj@sci.utah.edu; sudhanshu.sane@gmail.com;
   pugmire@ornl.gov
OI Pugmire, David/0000-0003-0647-2634
FU Scientific Discovery through Advanced Computing (SciDAC) program in the
   U.S. Department of Energy; Intel Graphics and Visualization Institutes
   of XeLLENCE; Intel OneAPI CoE; NIH [R24 GM136986]; DOE [DE-FE0031880];
   Utah Office of Energy Development; Office of Science of the U.S.
   Department of Energy [DE-AC05-00OR22725]
FX This work was partially supported by the Scientific Discovery through
   Advanced Computing (SciDAC) program in the U.S. Department of Energy,
   the Intel Graphics and Visualization Institutes of XeLLENCE, the Intel
   OneAPI CoE, the NIH under award number R24 GM136986, the DOE under grant
   number DE-FE0031880, and the Utah Office of Energy Development. This
   research used resources of the Oak Ridge Leadership Computing Facility
   at the Oak Ridge National Laboratory, which is supported by the Office
   of Science of the U.S. Department of Energy under Contract No.
   DE-AC05-00OR22725. We wish to thank Dr. Jieyang Chen at the Oak Ridge
   National Laboratory for helping us with the GPU code implementation and
   the reviewers of this article for their valuable feedback.
CR [Anonymous], 2021, Mathematica, Version 12.3.1
   Athawale T, 2019, IEEE T VIS COMPUT GR, V25, P1163, DOI 10.1109/TVCG.2018.2864505
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale TM, 2022, IEEE T VIS COMPUT GR, V28, P1955, DOI 10.1109/TVCG.2020.3022359
   Athawale TM, 2021, IEEE T VIS COMPUT GR, V27, P1797, DOI 10.1109/TVCG.2020.3030394
   Bachthaler S, 2008, IEEE T VIS COMPUT GR, V14, P1428, DOI 10.1109/TVCG.2008.119
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bærentzen JA, 2005, IEEE T VIS COMPUT GR, V11, P243, DOI 10.1109/TVCG.2005.49
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Carr H, 2015, COMPUT GRAPH FORUM, V34, P241, DOI 10.1111/cgf.12636
   Carr H, 2010, COMP GEOM-THEOR APPL, V43, P42, DOI 10.1016/j.comgeo.2006.05.009
   Edelsbrunner H, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P242, DOI 10.1145/1377676.1377720
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Fout N, 2012, IEEE T VIS COMPUT GR, V18, P2335, DOI 10.1109/TVCG.2012.227
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Fuchs R, 2009, COMPUT GRAPH FORUM, V28, P1670, DOI 10.1111/j.1467-8659.2009.01429.x
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Guo HQ, 2016, IEEE T VIS COMPUT GR, V22, P1672, DOI 10.1109/TVCG.2016.2534560
   Hauser H, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P127, DOI 10.1109/INFVIS.2002.1173157
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Inselberg A., 2009, IEEE Trans Hum Mach Syst, P199, DOI [10.1007/978-0-387-68628-8, DOI 10.1007/978-0-387-68628-8]
   Jänicke H, 2008, IEEE T VIS COMPUT GR, V14, P1459, DOI 10.1109/TVCG.2008.116
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Jiao FX, 2012, IEEE PAC VIS SYMP, P193, DOI 10.1109/PacificVis.2012.6183591
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Johnson ER, 2010, J AM CHEM SOC, V132, P6498, DOI 10.1021/ja100936w
   Jones DK, 2003, MAGN RESON MED, V49, P7, DOI 10.1002/mrm.10331
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Klacansky P, 2017, IEEE T VIS COMPUT GR, V23, P1782, DOI 10.1109/TVCG.2016.2570215
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Knoll A, 2009, COMPUT GRAPH FORUM, V28, P26, DOI 10.1111/j.1467-8659.2008.01189.x
   Lodha SK, 1996, IEEE VISUAL, P249, DOI 10.1109/VISUAL.1996.568116
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   Nagaraj S, 2011, COMPUT GRAPH FORUM, V30, P1101, DOI 10.1111/j.1467-8659.2011.01959.x
   Otto M, 2011, IEEE PAC VIS SYMP, P67, DOI 10.1109/PACIFICVIS.2011.5742374
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Patchett J., 2016, Visualization and Analysis of Threats from Asteroid Ocean Impacts
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Raith F, 2019, IEEE T VIS COMPUT GR, V25, P1122, DOI 10.1109/TVCG.2018.2864846
   Rhodes P., 2003, Eurographics, P83, DOI [DOI 10.2312/EGS.20031054, 10.2312/ egs.20031054]
   Saeki O, 2004, LECT NOTES MATH, V1854, P1
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   Sakurai D., 2020, Mathematics and Visualization, P187, DOI DOI 10.1007/978-3-030-43036-8
   Sane S., 2021, EUROVIS 2021, DOI [10.2312/EVS.20211053, DOI 10.2312/EVS.20211053]
   Sanikommu S, 2020, J GEOPHYS RES-OCEANS, V125, DOI 10.1029/2019JC015611
   Sauber N, 2006, IEEE T VIS COMPUT GR, V12, P917, DOI 10.1109/TVCG.2006.165
   Schneider D., 2012, TOPOLOGICAL METHODS, P255, DOI [DOI 10.1007/978-3-642-23175-917, 10.1007/978-3-642-23175-917]
   Shusen Liu, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P73, DOI 10.1109/LDAV.2012.6378978
   Siddiqui F, 2021, COMPUT GRAPH FORUM, V40, P411, DOI 10.1111/cgf.14317
   Silverman B. W., 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   Thompson D., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P23, DOI 10.1109/LDAV.2011.6092313
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2017, IEEE T VIS COMPUT GR, V23, P960, DOI 10.1109/TVCG.2016.2599017
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   WAND MP, 1993, J AM STAT ASSOC, V88, P520, DOI 10.2307/2290332
   Ward Matthew O, 2008, HDB DATA VISUALIZATI, P179, DOI [DOI 10.1007/978-3-540-33037-0_8, 10.1007/978-3-540-33037-083, DOI 10.1007/978-3-540-33037-083]
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Wu K, 2017, IEEE T VIS COMPUT GR, V23, P941, DOI 10.1109/TVCG.2016.2599040
   Xie ZX, 2006, IEEE CONF VIS ANAL, P183
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Zheng BY, 2021, IEEE T VIS COMPUT GR, V27, P1819, DOI 10.1109/TVCG.2020.3030466
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 70
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 613
EP 623
DI 10.1109/TVCG.2022.3209424
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800011
PM 36155460
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Sakin, SA
   Bigelow, A
   Tohid, R
   Scully-Allison, C
   Scheidegger, C
   Brandt, SR
   Taylor, C
   Huck, KA
   Kaiser, H
   Isaacs, KE
AF Sakin, Sayef Azad
   Bigelow, Alex
   Tohid, R.
   Scully-Allison, Connor
   Scheidegger, Carlos
   Brandt, Steven R.
   Taylor, Christopher
   Huck, Kevin A.
   Kaiser, Hartmut
   Isaacs, Katherine E.
TI Traveler: Navigating Task Parallel Traces for Performance Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE software visualization; parallel computing; traces; performance
   analysis; event sequence visualization
ID VISUAL ANALYSIS; COMMUNICATION; VISUALIZATION
AB Understanding the behavior of software in execution is a key step in identifying and fixing performance issues. This is especially important in high performance computing contexts where even minor performance tweaks can translate into large savings in terms of computational resource use. To aid performance analysis, developers may collect an execution trace-a chronological log of program activity during execution. As traces represent the full history, developers can discover a wide array of possibly previously unknown performance issues, making them an important artifact for exploratory performance analysis. However, interactive trace visualization is difficult due to issues of data size and complexity of meaning. Traces represent nanosecond-level events across many parallel processes, meaning the collected data is often large and difficult to explore. The rise of asynchronous task parallel programming paradigms complicates the relation between events and their probable cause. To address these challenges, we conduct a continuing design study in collaboration with high performance computing researchers. We develop diverse and hierarchical ways to navigate and represent execution trace data in support of their trace analysis tasks. Through an iterative design process, we developed Traveler, an integrated visualization platform for task parallel traces. Traveler provides multiple linked interfaces to help navigate trace data from multiple contexts. We evaluate the utility of Traveler through feedback from users and a case study, finding that integrating multiple modes of navigation in our design supported performance analysis tasks and led to the discovery of previously unknown behavior in a distributed array library.
C1 [Sakin, Sayef Azad; Scully-Allison, Connor] Univ Arizona, Tucson, AZ 85721 USA.
   [Tohid, R.; Brandt, Steven R.; Kaiser, Hartmut] Louisiana State Univ, Baton Rouge, LA 70803 USA.
   [Scheidegger, Carlos] RStudio, Boston, MA USA.
   [Taylor, Christopher] Tact Comp Labs, Muenster, TX USA.
   [Isaacs, Katherine E.] Univ Utah, Salt Lake City, UT 84112 USA.
C3 University of Arizona; Louisiana State University System; Louisiana
   State University; Utah System of Higher Education; University of Utah
RP Sakin, SA (corresponding author), Univ Arizona, Tucson, AZ 85721 USA.
EM sayefsakin@email.arizona.edu; kisaacs@sci.utah.edu
RI Sakin, Sayef Azad/KBA-9698-2024; Huck, Kevin/KCZ-3001-2024
OI Tohid, Mohammad/0000-0001-7776-0380; Kaiser,
   Hartmut/0000-0002-8712-2806; Huck, Kevin/0000-0001-7064-8417
FU United States Department of Defense through DTIC [FA8075-14-D-002-007];
   Department of Energy [DE-SC0022044]; National Science Foundation
   [IIS-1844573]; U.S. Department of Energy (DOE) [DE-SC0022044] Funding
   Source: U.S. Department of Energy (DOE)
FX This work was supported by the United States Department of Defense
   through DTIC Contract FA8075-14-D-002-007, the Department of Energy
   under DE-SC0022044, and the National Science Foundation under NSF
   IIS-1844573.
CR Adhianto L, 2010, CONCURR COMP-PRACT E, V22, P685, DOI 10.1002/cpe.1553
   Ashby S., 2010, Summary Report of the Advanced Scientific Computing Advisory Committee (ASCAC) Subcommittee, P1
   bitbucket, BLAZ
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Browne S, 2000, INT J HIGH PERFORM C, V14, P189, DOI 10.1177/109434200001400303
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Diskcache, DISKCACHE DISK BACKE
   Drebes A., 2014, MULTIPROG
   Eschweiler D, 2012, ADV PARALLEL COMPUT, V22, P481, DOI 10.3233/978-1-61499-041-3-481
   Ezzati-Jivan N, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4068
   Fujiwara T, 2018, VIS INFORM, V2, P98, DOI 10.1016/j.visint2018.04.010
   Graham SL, 2004, ACM SIGPLAN NOTICES, V39, P49, DOI 10.1145/989393.989401
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   Haugen B., 2015, P 2 WORKSHOP VISUAL
   Huynh A., 2015, P 2 WORKSHOP VISUAL
   Isaacs KE, 2014, IEEE T VIS COMPUT GR, V20, P2349, DOI 10.1109/TVCG.2014.2346456
   Isaacs KatherineE., 2014, EUROVIS STARS, DOI DOI 10.2312/EUR0VISSTAR.20141177
   Karran Benjamin, 2013, 2013 First IEEE Working Conference on Software Visualization (VISSOFT), DOI 10.1109/VISSOFT.2013.6650534
   Kelly Christopher, 2020, ISAV'20: ISAV'20 In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, P15, DOI 10.1145/3426462.3426465
   Kesavan SP, 2020, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis48177.2020.9280
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Li JK, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P20, DOI [10.1109/VDS48975.2019.8973380, 10.1109/vds48975.2019.8973380]
   Muddukrishna A, 2016, ACM SIGPLAN NOTICES, V51, P337, DOI [10.1145/2851141.2851156, 10.1145/3016078.2851156]
   Muelder C, 2016, IEEE T VIS COMPUT GR, V22, P1694, DOI 10.1109/TVCG.2016.2534558
   Muelder C, 2009, IEEE T VIS COMPUT GR, V15, P1129, DOI 10.1109/TVCG.2009.196
   Nagel WE, 1996, SUPERCOMPUTER, V12, P69
   oracle, DGEMM
   Osmari DK, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P165, DOI 10.1109/SIBGRAPI.2014.2
   Pinto V. G., 2016, ANAL DYNAMIC TASK BA
   Ragan-Kelley J, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3150211
   Reinders J., 2005, VTune Performance Analyzer
   Reissmann N., 2017, P 4 INT WORKSHOP VIS
   Sanderson A, 2018, LECT NOTES COMPUT SC, V11203, P201, DOI 10.1007/978-3-030-02465-9_14
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sigovan C, 2013, COMPUT GRAPH FORUM, V32, P141, DOI 10.1111/cgf.12101
   Vetter J., 2017, CONT HIGH PERFORMANC
   Williams K, 2020, IEEE T VIS COMPUT GR, V26, P1118, DOI 10.1109/TVCG.2019.2934285
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zaki O, 1999, INT J HIGH PERFORM C, V13, P277, DOI 10.1177/109434209901300310
   Zhukov Ilya, 2014, P TOOLS HIGH PERF CO, P1, DOI DOI 10.1007/978-3-319-16012-2_1
NR 42
TC 3
Z9 5
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 788
EP 797
DI 10.1109/TVCG.2022.3209375
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800012
PM 36166559
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bollen, B
   Tennakoon, P
   Levine, JA
AF Bollen, Brian
   Tennakoon, Pasindu
   Levine, Joshua A. A.
TI Computing a Stable Distance on Merge Trees
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Merge trees; scalar fields; distance measure; stability; edit distance;
   persistence
ID REEB GRAPHS; COMPUTATION; PERSISTENCE
AB Distances on merge trees facilitate visual comparison of collections of scalar fields. Two desirable properties for these distances to exhibit are 1) the ability to discern between scalar fields which other, less complex topological summaries cannot and 2) to still be robust to perturbations in the dataset. The combination of these two properties, known respectively as stability and discriminativity, has led to theoretical distances which are either thought to be or shown to be computationally complex and thus their implementations have been scarce. In order to design similarity measures on merge trees which are computationally feasible for more complex merge trees, many researchers have elected to loosen the restrictions on at least one of these two properties. The question still remains, however, if there are practical situations where trading these desirable properties is necessary. Here we construct a distance between merge trees which is designed to retain both discriminativity and stability. While our approach can be expensive for large merge trees, we illustrate its use in a setting where the number of nodes is small. This setting can be made more practical since we also provide a proof that persistence simplification increases the outputted distance by at most half of the simplified value. We demonstrate our distance measure on applications in shape comparison and on detection of periodicity in the von Karman vortex street.
C1 [Bollen, Brian] Univ Arizona, Dept Math, Tucson, AZ 85721 USA.
   [Tennakoon, Pasindu; Levine, Joshua A. A.] Univ Arizona, Dept Comp Sci, Tucson, AZ USA.
C3 University of Arizona; University of Arizona
RP Bollen, B (corresponding author), Univ Arizona, Dept Math, Tucson, AZ 85721 USA.
EM bbollen23@math.arizona.edu; pasindut@cs.arizona.edu; josh@cs.arizona.edu
FU U.S. Department of Energy, Office of Science, Office of Advanced
   Scientific Computing Research [DE-SC-0019039]
FX We thank Raghavendra Sridharamurthy and Vijay Natarajan for providing
   the comparison results of their algorithm [36] on experiment used in
   Sect. 7.1. We also thank our anonymous reviewers for provided their
   detailed feedback and suggestions. This work is supported in part by the
   U.S. Department of Energy, Office of Science, Office of Advanced
   Scientific Computing Research, under Award Number(s) DE-SC-0019039.
CR Agarwal P. K., 2018, ACM T ALGORITHMS, V14
   Bauer U., 2022, LIPICS, V224
   Bauer U., 2016, EUR WORKSH 3D OBJ RE
   Bauer U., 2014, ANN S COMP GEOM SOCG
   Bauer U, 2021, FOUND COMPUT MATH, V21, P1441, DOI 10.1007/s10208-020-09488-3
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Bollen B., 2021, ABS211005631 CORR
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Cohen-Steiner D, 2009, FOUND COMPUT MATH, V9, P79, DOI 10.1007/s10208-008-9027-z
   Cohen-Steiner David, 2005, P 21 ANN S COMPUTATI, P263, DOI [DOI 10.1145/1064092.1064133, 10.1145/1064092.1064133]
   de Silva V., 2016, P DISCR COMP GEOM, P1
   Developers P., 2013, DIST REPR PER DIAGR
   Di Fabio B., 2012, MATH METHODS APPL SC, V35, P08
   Di Fabio B, 2016, DISCRETE COMPUT GEOM, V55, P423, DOI 10.1007/s00454-016-9758-6
   Duke D, 2012, IEEE T VIS COMPUT GR, V18, P2033, DOI 10.1109/TVCG.2012.287
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2022, Computational topology: an introduction
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   GROMOV M, 1981, PUBL MATH-PARIS, P53
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Morozov D., 2013, P TOP BAS METH VIS
   Oesterling P, 2011, IEEE T VIS COMPUT GR, V17, P1547, DOI 10.1109/TVCG.2011.27
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Pascucci V, 2009, MATH VIS, P19, DOI 10.1007/b106657_2
   Reeb G., 1946, ACAD DES SCI
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Sridharamurthy R., 2021, IEEE T VIS COMPUT GR, P1, DOI DOI 10.1109/TVCG.2021.3122176.2
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   TAI KC, 1979, J ACM, V26, P422, DOI 10.1145/322139.322143
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J., 2017, IEEE T VIS COMPUT GR
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Widanagamaachchi W, 2017, IEEE PAC VIS SYMP, P101, DOI 10.1109/PACIFICVIS.2017.8031584
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Zeng Z., 2009, PROC VLDB ENDOW, V1, P25, DOI [10.14778/1687627.1687631, DOI 10.14778/1687627.1687631]
NR 45
TC 3
Z9 3
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 1168
EP 1177
DI 10.1109/TVCG.2022.3209395
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800013
PM 36197851
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, QW
   Huang, KX
   Chandak, P
   Zitnik, M
   Gehlenborg, N
AF Wang, Qianwen
   Huang, Kexin
   Chandak, Payal
   Zitnik, Marinka
   Gehlenborg, Nils
TI Extending the Nested Model for User-Centric XAI: A Design Study on
   GNN-based Drug Repurposing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual Explanation; XAI; Graph Neural Network; Visualization Design
   Model; Drug Repurposing
AB Whether AI explanations can help users achieve specific tasks efficiently (i.e., usable explanations) is significantly influenced by their visual presentation. While many techniques exist to generate explanations, it remains unclear how to select and visually present AI explanations based on the characteristics of domain users. This paper aims to understand this question through a multidisciplinary design study for a specific problem: explaining graph neural network (GNN) predictions to domain experts in drug repurposing, i.e., reuse of existing drugs for new diseases. Building on the nested design model of visualization, we incorporate XAI design considerations from a literature review and from our collaborators' feedback into the design process. Specifically, we discuss XAI-related design considerations for usable visual explanations at each design layer: target user, usage context, domain explanation, and XAI goal at the domain layer; format, granularity, and operation of explanations at the abstraction layer; encodings and interactions at the visualization layer; and XAI and rendering algorithm at the algorithm layer. We present how the extended nested model motivates and informs the design of DrugExplorer, an XAI tool for drug repurposing. Based on our domain characterization, DrugExplorer provides path-based explanations and presents them both as individual paths and meta-paths for two key XAI operations, why and what else. DrugExplorer offers a novel visualization design called MetaMatrix with a set of interactions to help domain users organize and compare explanation paths at different levels of granularity to generate domain-meaningful insights. We demonstrate the effectiveness of the selected visual presentation and DrugExplorer as a whole via a usage scenario, a user study, and expert interviews. From these evaluations, we derive insightful observations and reflections that can inform the design of XAI visualizations for other scientific applications.
C1 [Wang, Qianwen; Zitnik, Marinka; Gehlenborg, Nils] Harvard Univ, Cambridge, MA 02138 USA.
   [Huang, Kexin] Stanford Univ, Stanford, CA USA.
   [Chandak, Payal] Harvard Hlth Sci & Technol, Cambridge, MA USA.
C3 Harvard University; Stanford University
RP Wang, QW (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM qianwen_wang@hms.harvard.com; kexinh@stanford.edu;
   payal_chandak@hst.harvard.edu; marinka@hms.harvard.com;
   nils@hms.harvard.com
RI Huang, Kexin/AAU-2699-2021; Wang, Qianwen/GRJ-9435-2022
FU NSF [IIS-2030459, IIS-2033384]; Air Force Contract [FA8702-15-D-0001];
   Harvard Data Science Initiative; Amazon Research Award; Bayer Early
   Excellence in Science Award; AstraZeneca Research; Roche Alliance with
   Distinguished Scientists Award
FX The authors wish to thank all the participants in the expert interviews
   and user studies. M.Z. is supported, in part, by NSF under Nos.
   IIS-2030459 and IIS-2033384, Air Force Contract No. FA8702-15-D-0001,
   Harvard Data Science Initiative, Amazon Research Award, Bayer Early
   Excellence in Science Award, AstraZeneca Research, and Roche Alliance
   with Distinguished Scientists Award.
CR A. D. Team, ANT DES
   Adebayo Julius, 2020, Advances in Neural Information Processing Systems, V33, P700
   Agarwal C, 2022, Arxiv, DOI arXiv:2106.09078
   Akimoto H, 2020, AM J ALZHEIMERS DIS, V35, DOI 10.1177/1533317519899546
   Alqaraawi A, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P275, DOI 10.1145/3377325.3377519
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Anuyah O., 2021, MENSCH COMPUTER 2021, DOI [10.18420/muc2021-mci-ws02-237, DOI 10.18420/MUC2021-MCI-WS02-237]
   Sastre AA, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD003804.pub2
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bucinca Z, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P454, DOI 10.1145/3377325.3377498
   Cai Carrie J., 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359206
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Card SK., 1999, READINGS INFORM VISU
   Chari Shruthi, 2020, The Semantic Web - ISWC 2020. 19th International Semantic Web Conference. Lecture Notes in Computer Science (LNCS 12507), P228, DOI 10.1007/978-3-030-62466-8_15
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Cheng HF, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300789
   Diaz-Gonzalez R, 2011, PLOS NEGLECT TROP D, V5, DOI 10.1371/journal.pntd.0001297
   Eiband M, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P211, DOI 10.1145/3172944.3172961
   F. Inc. React.js, FACEBOOK
   Feng S, 2019, PROCEEDINGS OF IUI 2019, P229, DOI 10.1145/3301275.3302265
   Ferreira Juliana J., 2020, Design, User Experience, and Usability. Design for Contemporary Interactive Environments. 9th International Conference, DUXU 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12201), P56, DOI 10.1007/978-3-030-49760-6_4
   Grinberg M., 2018, Flask Web Development: Developing Web Applications with Python
   Gysi DM, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2025581118
   Harbig TA, 2021, BIOINFORMATICS, V37, pI59, DOI 10.1093/bioinformatics/btab289
   Hohman Fred., 2019, P 2019 CHI C HUMAN F, p579:1
   Hong Sungsoo Ray, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392878
   Huang K, 2021, arXiv, DOI [10.48550/arXiv.2102.09548, DOI 10.48550/ARXIV.2102.09548]
   Jiménez-Luna J, 2020, NAT MACH INTELL, V2, P573, DOI 10.1038/s42256-020-00236-4
   Jin Weina, 2019, P IEEE VISUALIZATION, P20
   Jin Zhihua, 2020, arXiv
   Joung KI, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43066-0
   Kaur H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376219
   Konecni S, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P345, DOI 10.1109/IV.2009.75
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Langer M, 2021, ARTIF INTELL, V296, DOI 10.1016/j.artint.2021.103473
   Lex A, 2013, IEEE T VIS COMPUT GR, V19, P2536, DOI 10.1109/TVCG.2013.154
   Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590
   Lim GP, 2000, J NEUROSCI, V20, P5709, DOI 10.1523/JNEUROSCI.20-15-05709.2000
   Lopez J. R. A., 1048, JAMA-J AM MED ASSOC, V324
   Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0
   Meyer M, 2015, INFORM VISUAL, V14, P234, DOI 10.1177/1473871613510429
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   neo4j, NEO4J GRAPH DAT PLAT
   Nosengo N, 2016, NATURE, V534, P314, DOI 10.1038/534314a
   Ono K, 2006, NEUROCHEM INT, V48, P275, DOI 10.1016/j.neuint.2005.11.001
   Partl C, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12883
   Partl C, 2014, IEEE T VIS COMPUT GR, V20, P1883, DOI 10.1109/TVCG.2014.2346752
   Partl C, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S19-S3
   Paszke A, 2019, ADV NEUR IN, V32
   Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x
   Ruiz C, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21770-8
   Schäfer T, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0213-3
   Schlichtkrull M. S., 2020, arXiv preprint arXiv:2010.00577
   Schnake T, 2020, Arxiv, DOI arXiv:2006.03589
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Simkute A., 2021, "J. Responsible Technol., V7
   Sokol K, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P56, DOI 10.1145/3351095.3372870
   Sosa DN, 2020, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2020, P463
   Tonekaboni S, 2019, PR MACH LEARN RES, V106
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Velickovic Petar, 2018, ICLR 2018
   Vilone G, 2020, Arxiv, DOI [arXiv:2006.00093, 10.48550/arXiv.2006.00093]
   Wang D., 2019, P 2019 CHI C HUMAN F, P1
   Wang Q., 2022, IMPROVING UTILITY US
   Wang Q., 2021, P IEEE VIS
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang QW, 2020, IEEE T VIS COMPUT GR, V26, P3340, DOI 10.1109/TVCG.2019.2921323
   Wang QT, 2021, PLANT SOIL, V458, P277, DOI [10.1007/s11104-019-04156-0, 10.1145/3361242.3361254]
   Wang X, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2022, DOI 10.1145/3308558.3313562
   Wang XR, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P318, DOI 10.1145/3397481.3450650
   WEHREND S, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P139, DOI 10.1109/VISUAL.1990.146375
   Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240
   Yuan H., 2021, arXiv
   Yuan Hao, 2020, arXiv, DOI 10.1109/TPAMI.2022.3204236
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yun S, 2019, ADV NEUR IN, V32
   Zeng XX, 2020, J PROTEOME RES, V19, P4624, DOI 10.1021/acs.jproteome.0c00316
   Zhang MH, 2018, ADV NEUR IN, V31
   Zilke JR, 2016, LECT NOTES ARTIF INT, V9956, P457, DOI 10.1007/978-3-319-46307-0_29
   Zytek A, 2022, IEEE T VIS COMPUT GR, V28, P1161, DOI 10.1109/TVCG.2021.3114864
NR 87
TC 17
Z9 19
U1 5
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2023
VL 29
IS 1
BP 1266
EP 1276
DI 10.1109/TVCG.2022.3209435
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7F6YZ
UT WOS:000901991800014
PM 36223348
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Mueller, K
AF Mueller, Klaus
TI Farewell and New EIC Introduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Mueller, Klaus] SUNY Stony Brook, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University
RP Mueller, K (corresponding author), SUNY Stony Brook, Stony Brook, NY 11794 USA.
EM mueller@cs.stonybrook.edu
OI Mueller, Klaus/0000-0002-0996-8590
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1299
EP 1300
DI 10.1109/TVCG.2022.3219303
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100001
OA Bronze
DA 2024-11-06
ER

PT J
AU Yang, J
   Gao, L
   Tan, QY
   Huang, YH
   Xia, SH
   Lai, YK
AF Yang, Jie
   Gao, Lin
   Tan, Qingyang
   Huang, Yi-Hua
   Xia, Shihong
   Lai, Yu-Kun
TI Multiscale Mesh Deformation Component Analysis With Attention-Based
   Autoencoders
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multi-scale; shape analysis; attention mechanism; sparse regularization;
   stacked auto-encoder
ID SHAPE
AB Deformation component analysis is a fundamental problem in geometry processing and shape understanding. Existing approaches mainly extract deformation components in local regions at a similar scale while deformations of real-world objects are usually distributed in a multi-scale manner. In this article, we propose a novel method to exact multiscale deformation components automatically with a stacked attention-based autoencoder. The attention mechanism is designed to learn to softly weight multi-scale deformation components in active deformation regions, and the stacked attention-based autoencoder is learned to represent the deformation components at different scales. Quantitative and qualitative evaluations show that our method outperforms state-of-the-art methods. Furthermore, with the multiscale deformation components extracted by our method, the user can edit shapes in a coarse-to-fine fashion which facilitates effective modeling of new shapes.
C1 [Yang, Jie; Gao, Lin; Huang, Yi-Hua; Xia, Shihong] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
   [Yang, Jie; Gao, Lin; Huang, Yi-Hua; Xia, Shihong] Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
   [Tan, Qingyang] Univ Maryland, College Pk, MD 20742 USA.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; University System of Maryland; University of Maryland College Park;
   Cardiff University
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.; Gao, L (corresponding author), Univ Chinese Acad Sci, Beijing 100864, Peoples R China.
EM yangjie01@ict.ac.cn; gaolin@ict.ac.cn; qytan@cs.umd.edu;
   huangyihua16@mails.ucas.ac.cn; xsh@ict.ac.cn; LaiY4@cardiff.ac.uk
RI Tan, Qingyang/ISA-4109-2023; Gao, Lin/JNF-0375-2023; Yang,
   Jie/IAO-3586-2023; Lai, Yu-Kun/D-2343-2010
OI Lai, Yukun/0000-0002-2094-5680; Tan, Qingyang/0000-0002-9269-5289
FU National Natural Science Foundation of China [62061136007, 61872440];
   Beijing Municipal Natural Science Foundation [L182016]; Science and
   Technology Service Network Initiative; Chinese Academy of Sciences
   [KFJ-STS-QYZD-2021-11-001]; Royal Society Newton Advanced Fellowship
   [NAF\R2\192151]; Youth Innovation Promotion Association CAS; Zhejiang
   Lab [2021KE0AB06]
FX This work was supported by the National Natural Science Foundation
   ofChina under Grants 62061136007 and 61872440, the Beijing Municipal
   Nat-ural Science Foundation under Grant L182016, the Science and
   TechnologyService Network Initiative, Chinese Academy of Sciences under
   Grant KFJ-STS-QYZD-2021-11-001, Royal Society Newton Advanced Fellowship
   underGrant NAF\R2\192151, the Youth Innovation Promotion Association
   CASand the Open Research Projects of Zhejiang Lab under Grant
   2021KE0AB06
CR Abeyratne M. K., 2003, J APPL MATH, V2002
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Alleman CN, 2018, COMPUT MECH, V61, P207, DOI 10.1007/s00466-017-1481-5
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bednarík J, 2018, INT CONF 3D VISION, P606, DOI 10.1109/3DV.2018.00075
   Bernard F, 2016, PROC CVPR IEEE, P5629, DOI 10.1109/CVPR.2016.607
   Bogo F, 2017, PROC CVPR IEEE, P5573, DOI 10.1109/CVPR.2017.591
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Bruna J., 2013, ARXIV
   Chen MJ, 2020, COMPUT GRAPH-UK, V89, P50, DOI 10.1016/j.cag.2020.05.018
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Defferrard M, 2016, ADV NEUR IN, V29
   Duvenaudt D, 2015, ADV NEUR IN, V28
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Fröhlich S, 2011, COMPUT GRAPH FORUM, V30, P2246, DOI 10.1111/j.1467-8659.2011.01974.x
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Fulton L, 2019, COMPUT GRAPH FORUM, V38, P379, DOI 10.1111/cgf.13645
   Gao L, 2021, IEEE T VIS COMPUT GR, V27, P2085, DOI 10.1109/TVCG.2019.2941200
   Gao L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2908736
   Gao L, 2012, SCI CHINA INFORM SCI, V55, P983, DOI 10.1007/s11432-012-4574-y
   Hamidian H, 2020, IEEE T VIS COMPUT GR, V26, P3327, DOI 10.1109/TVCG.2019.2915567
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Huang HB, 2018, ACM T GRAPHIC, V37, DOI [10.1145/3137609, 10.1145/3072959.3073654]
   Huang ZC, 2014, COMPUT GRAPH FORUM, V33, P239, DOI 10.1111/cgf.12492
   Jiang C.M., 2019, ARXIV190102039
   Jiang CY, 2019, IEEE I CONF COMP VIS, P8768, DOI 10.1109/ICCV.2019.00886
   Kavan L, 2010, COMPUT GRAPH FORUM, V29, P327, DOI 10.1111/j.1467-8659.2009.01602.x
   Kingma D. P., 2017, P INT C LEARNING REP, P1
   Lam KC, 2017, MULTISCALE MODEL SIM, V15, P864, DOI 10.1137/16M1056614
   Lei H, 2019, PROC CVPR IEEE, P9623, DOI 10.1109/CVPR.2019.00986
   Li YY, 2018, ADV NEUR IN, V31
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Liu SL, 2020, COMPUT GRAPH FORUM, V39, P581, DOI 10.1111/cgf.13892
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Lu JS, 2016, ADV NEUR IN, V29
   Ma S, 2018, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2018.00593
   Malik J, 2018, INT CONF 3D VISION, P110, DOI 10.1109/3DV.2018.00023
   Mathew M, 2018, STRUCT CONTROL HLTH, V25, DOI 10.1002/stc.2166
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Neumann T, 2013, COMPUT GRAPH FORUM, V32, P285, DOI 10.1111/cgf.12048
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Niepert M, 2016, PR MACH LEARN RES, V48
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Sarkar K, 2018, LECT NOTES COMPUT SC, V11220, P74, DOI 10.1007/978-3-030-01270-0_5
   Sarkar K, 2018, IEEE WINT CONF APPL, P1925, DOI 10.1109/WACV.2018.00213
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sorkine M., 2007, P S GEOM PROC, P109, DOI DOI 10.1145/1073204.1073323
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sumner RW, 2005, ACM T GRAPHIC, V24, P488, DOI 10.1145/1073204.1073218
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tan QY, 2018, AAAI CONF ARTIF INTE, P2452
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Tretschk E, 2020, Arxiv, DOI arXiv:1905.10290
   Vása L, 2011, IEEE T VIS COMPUT GR, V17, P220, DOI 10.1109/TVCG.2010.38
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang P, 2017, PROC CVPR IEEE, P3909, DOI 10.1109/CVPR.2017.416
   Wang PS, 2020, IEEE COMPUT SOC CONF, P1074, DOI 10.1109/CVPRW50498.2020.00141
   Wang PS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275050
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YP, 2017, COMPUT GRAPH FORUM, V36, P247, DOI 10.1111/cgf.13076
   White R, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239485
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu WW, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531341
   Yang Y, 2013, IEEE T VIS COMPUT GR, V19, P1633, DOI 10.1109/TVCG.2013.12
   Yang Z, 2016, P 2016 C N AM CHAPTE, P1480, DOI DOI 10.18653/V1/N16-1174
   Yumer ME, 2016, LECT NOTES COMPUT SC, V9910, P294, DOI 10.1007/978-3-319-46466-4_18
   Yumer ME, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766908
   Yumer ME, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661234
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhou K, 2005, ACM T GRAPHIC, V24, P496, DOI 10.1145/1073204.1073219
   Zhuang BH, 2018, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR.2018.00447
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 79
TC 6
Z9 6
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1301
EP 1317
DI 10.1109/TVCG.2021.3112526
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100002
PM 34520358
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Hu, BY
   Ye, CY
   Su, JP
   Liu, LG
AF Hu, Bo-Yi
   Ye, Chunyang
   Su, Jian-Ping
   Liu, Ligang
TI Manifold-Constrained Geometric Optimization via Local Parameterizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geometric optimization; manifold constrains; developable-surface; low
   distortion parameterizations
ID DISCRETE UNIFORMIZATION THEOREM; CUT CONSTRUCTION; SURFACE; QUALITY;
   MAPS
AB Many geometric optimization problems contain manifold constraints that restrict the optimized vertices on some specified manifold surface. The constraints are highly nonlinear and non-convex, therefore existing methods usually suffer from a breach of condition or low optimization quality. In this article, we present a novel divide-and-conquer methodology for manifold-constrained geometric optimization problems. Central to our methodology is to use local parameterizations to decouple the optimization with hard constraints, which transforms nonlinear constraints into linear constraints. We decompose the input mesh into a set of developable or nearly-developable overlapping patches with disc topology, then flatten each patch into the planar domain with very low isometric distortion, optimize vertices with linear constraints and recover the patch. Finally, we project it onto the constrained manifold surface. We demonstrate the applicability and robustness of our methodology through a variety of geometric optimization tasks. Experimental results show that our method performs much better than existing methods.
C1 [Hu, Bo-Yi; Ye, Chunyang; Su, Jian-Ping; Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Liu, LG (corresponding author), Univ Sci & Technol China, Sch Math Sci, Hefei 230052, Peoples R China.
EM hbyiyiyi@mail.ustc.edu.cn; yechyang@mail.ustc.edu.cn;
   SJPing@mail.ustc.edu.cn; lgliu@ustc.edu.cn
RI Liu, Ligang/IZQ-5817-2023; su, Jian-Ping/ABC-5407-2021
OI Su, Jian-Ping/0000-0003-3692-6510
FU National Natural Science Foundation of China [62025207]; Zhejiang Lab
   [2019NB0AB03]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62025207 and Zhejiang Lab under Grant
   2019NB0AB03.(Corresponding author: Ligang Liu.
CR Aigerman N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766921
   Aigerman N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601158
   Bouaziz S, 2012, COMPUT GRAPH FORUM, V31, P1657, DOI 10.1111/j.1467-8659.2012.03171.x
   Chai SM, 2021, IEEE T VIS COMPUT GR, V27, P2469, DOI 10.1109/TVCG.2019.2947420
   Chai SM, 2018, COMPUT GRAPH-UK, V74, P66, DOI 10.1016/j.cag.2018.05.007
   Chen W., COMPUT METHOD APPL M, V366
   Fu XM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980231
   Fu XM, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766938
   Garg A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601106
   Golla B, 2018, COMPUT GRAPH FORUM, V37, P233, DOI 10.1111/cgf.13563
   Gu XF, 2018, J DIFFER GEOM, V109, P431, DOI 10.4310/jdg/1531188190
   Gu XD, 2018, J DIFFER GEOM, V109, P223, DOI 10.4310/jdg/1527040872
   Hu KM, 2017, IEEE T VIS COMPUT GR, V23, P2560, DOI 10.1109/TVCG.2016.2632720
   Intel Math Kernel Library, 2009, Reference Manual
   Jiang CG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392430
   Jiang ZS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130895
   Julius D, 2005, COMPUT GRAPH FORUM, V24, P581, DOI 10.1111/j.1467-8659.2005.00883.x
   Knupp PM, 2000, INT J NUMER METH ENG, V48, P401, DOI 10.1002/(SICI)1097-0207(20000530)48:3<401::AID-NME880>3.0.CO;2-D
   Kovalsky SZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925920
   Lam KC, 2015, MED IMAGE ANAL, V25, P45, DOI 10.1016/j.media.2015.04.006
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275042
   Liu C., 2019, PROC INT MESHING ROU
   Liu H, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323000
   Liu HY, 2020, COMPUT GRAPH FORUM, V39, P13, DOI 10.1111/cgf.14123
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Liu LG, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201331
   Peng Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201290
   Poranne R, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130845
   Pottmann H., 2002, Geometry of the squared distance function to curves and surfaces
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Sander P. V., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P87
   Schmidt P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392399
   Schmidt P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356519
   Sheffer A, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P291, DOI 10.1109/VISUAL.2002.1183787
   Sheffer A, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P61, DOI 10.1109/SMI.2002.1003529
   Shi R, 2017, IEEE T PATTERN ANAL, V39, P965, DOI 10.1109/TPAMI.2016.2567398
   Shtengel A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073618
   Smith B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3241041
   Smith J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766947
   Sorkine O., 2007, As-rigid-as-possible surface modeling, P109, DOI 10.1145/1281991.1282006
   Su JP, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392435
   SURAZHSKY V., 2003, P 12 INT MESHING ROU, P215
   Teran E., 2005, P ACM SIGGRAPH EUR S, P181, DOI [DOI 10.1145/1073368.1073394EVENT-PLACE, 10.1145/1073368, DOI 10.1145/1073368, DOI 10.1145/1073368.1073394]
   Yang Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392434
   Yang Y, 2019, COMPUT GRAPH FORUM, V38, P299, DOI 10.1111/cgf.13838
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zhang YJ, 2009, COMMUN NUMER METH EN, V25, P1, DOI 10.1002/cnm.1067
   Zhou Kun, 2004, P 2004 EUROGRAPHICSA, P45, DOI [DOI 10.1145/1057432.1057439, 10.1145/1057432.1057439]
   Zhu TY, 2020, COMPUT GRAPH FORUM, V39, P191, DOI 10.1111/cgf.13923
   Zhu YF, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201359
NR 51
TC 1
Z9 1
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1318
EP 1329
DI 10.1109/TVCG.2021.3112896
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100003
PM 34529566
DA 2024-11-06
ER

PT J
AU Song, Y
   Tang, F
   Dong, WM
   Huang, FY
   Lee, TY
   Xu, CS
AF Song, Yu
   Tang, Fan
   Dong, Weiming
   Huang, Feiyue
   Lee, Tong-Yee
   Xu, Changsheng
TI Balance-Aware Grid Collage for Small Image Collections
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Grid collage; visual balance; reinforcement learning
ID GENETIC ALGORITHMS; PHOTO COLLAGE
AB Grid collages (GClg) of small image collections are popular and useful in many applications, such as personal album management, online photo posting, and graphic design. In this article, we focus on how visual effects influence individual preferences through various arrangements of multiple images under such scenarios. A novel balance-aware metric is proposed to bridge the gap between multi-image joint presentation and visual pleasure. The metric merges psychological achievements into the field of grid collage. To capture user preference, a bonus mechanism related to a user-specified special location in the grid and uniqueness values of the subimages is integrated into the metric. An end-to-end reinforcement learning mechanism empowers the model without tedious manual annotations. Experiments demonstrate that our metric can evaluate the GClg visual balance in line with human subjective perception, and the model can generate visually pleasant GClg results, which is comparable to manual designs.
C1 [Song, Yu; Dong, Weiming; Xu, Changsheng] Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
   [Song, Yu; Dong, Weiming; Xu, Changsheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100040, Peoples R China.
   [Tang, Fan] Jinlin Univ, Sch Artificial Intelligence, Changchun 130012, Jilin, Peoples R China.
   [Huang, Feiyue] Tencent, Youtu Lab, Shanghai 200233, Peoples R China.
   [Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan 701, Taiwan.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Jilin University; Tencent; National Cheng Kung University
RP Dong, WM (corresponding author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.; Dong, WM (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100040, Peoples R China.
EM songyu2017@ia.ac.cn; tangfan@jlu.edu.cn; weiming.dong@ia.ac.cn;
   garyhuang@tencent.com; tonylee@mail.ncku.edu.tw; changsheng.xu@ia.ac.cn
RI Tang, Fan/O-3923-2018; zhang, zhenyu/HCI-5576-2022; DONG,
   Weiming/AAG-7678-2020
OI xu, chang sheng/0000-0001-8343-9665; tang, fan/0000-0002-3975-2483;
   Dong, Weiming/0000-0001-6502-145X
FU National Key R&D Program of China [2020AAA0106200]; National Natural
   Science Foundation of China [61832016, U20B2070, 6210070958]; Ministry
   of Science and Technology, Taiwan [110-2221-E-006-135-MY3]; Open
   Projects Program of National Laboratory of Pattern Recognition
FX This work was supported by National Key R&D Program of China under Grant
   2020AAA0106200, in part by National Natural Science Foundation of China
   under Grants 61832016, U20B2070, and 6210070958, in part by Ministry of
   Science and Technology under Grant 110-2221-E-006-135-MY3, Taiwan, and
   in part by Open Projects Program of National Laboratory of Pattern
   Recognition.
CR [Anonymous], 2010, ACM SAC
   Atkins C.B., 2008, Proceedings of the 16th ACM international conference on Multimedia, P821, DOI DOI 10.1145/1459359.1459496
   Brivio P, 2010, IEEE T VIS COMPUT GR, V16, P1261, DOI 10.1109/TVCG.2010.136
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601183
   Cao Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366160
   Cheung V, SHAPE COLLAGE
   Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Clegg A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275048
   collageitfree, COLLAGEIT
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   Gan Y, 2020, COMPUT GRAPH-UK, V88, P35, DOI 10.1016/j.cag.2020.02.006
   Geigel J, 2003, IEEE MULTIMEDIA, V10, P16, DOI 10.1109/MMUL.2003.1237547
   Geigel J, 2001, P SOC PHOTO-OPT INS, V4311, P79
   Han XT, 2016, IEEE T CYBERNETICS, V46, P1286, DOI 10.1109/TCYB.2015.2448236
   Hübner R, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519856040
   Hübner R, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00335
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Kosugi S, 2020, AAAI CONF ARTIF INTE, V34, P11296
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li LD, 2020, IEEE T IMAGE PROCESS, V29, P3898, DOI 10.1109/TIP.2020.2968285
   Liang Y, 2018, IEEE T VIS COMPUT GR, V24, P2728, DOI 10.1109/TVCG.2017.2764895
   Liu LJ, 2018, IEEE T VIS COMPUT GR, V24, P1956, DOI 10.1109/TVCG.2017.2703853
   Locher PJ, 1998, ACTA PSYCHOL, V99, P141, DOI 10.1016/S0001-6918(98)00008-0
   Lok S., 2004, P 9 INT C INT US INT, P101, DOI DOI 10.1145/964442.964462
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2015, IEEE T MULTIMEDIA, V17, P2021, DOI 10.1109/TMM.2015.2477040
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Mnih V, 2013, Playing atari with deep reinforcement learning, DOI DOI 10.1038/nature14236
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Pan XJ, 2021, IEEE T VIS COMPUT GR, V27, P2298, DOI 10.1109/TVCG.2019.2948611
   Sheng KK, 2021, COMPUT VIS MEDIA, V7, P139, DOI 10.1007/s41095-020-0193-5
   Sheng KK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P879, DOI 10.1145/3240508.3240554
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2022, COMPUT VIS MEDIA, V8, P199, DOI 10.1007/s41095-021-0221-0
   Song Y, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1047, DOI 10.1145/3240508.3240623
   Tan L, 2012, IEEE COMPUT GRAPH, V32, P46, DOI 10.1109/MCG.2011.89
   Thömmes K, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01050
   Thommes K., 2018, PROC VIS SCI ART C
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wang W, 2017, ICCV, P2186, DOI DOI 10.1109/CVPR.2018.00745
   Wilson A., 2005, Empir. Stud. Arts, V23, P165, DOI [10.2190/B1LR-MVF3-F36X-XR64, DOI 10.2190/B1LR-MVF3-F36X-XR64]
   Wu ZP, 2016, MULTIMED TOOLS APPL, V75, P1813, DOI 10.1007/s11042-014-2375-6
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang XY, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818709
   Yu ZQ, 2014, IEEE T VIS COMPUT GR, V20, P182, DOI 10.1109/TVCG.2013.106
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
   Zhou J, 2021, COMPUT VIS MEDIA, V7, P241, DOI 10.1007/s41095-021-0207-y
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 50
TC 3
Z9 3
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1330
EP 1344
DI 10.1109/TVCG.2021.3113031
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100004
PM 34529567
DA 2024-11-06
ER

PT J
AU Herveau, K
   Pfaffe, P
   Tillmann, M
   Tichy, WF
   Dachsbacher, C
AF Herveau, Killian
   Pfaffe, Philip
   Tillmann, Martin
   Tichy, Walter F. F.
   Dachsbacher, Carsten
TI Analysis of Acceleration Structure Parameters and Hybrid Autotuning for
   Ray Tracing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Acceleration structures; data structures; tables; models; machine
   learning; high-performance; performance analysis
ID BOUNDING VOLUME HIERARCHIES; VISUAL ANALYTICS; INTERACTIVE OPTIMIZATION;
   CONSTRUCTION
AB Finding optimal parameters for acceleration structures for raytracing is key to improved performance. Previous research has shown that a speedup of over 10% of rendering time is possible. Some parameters are interdependent which complicates the process of finding an optimal configuration. It is hence interesting to find them efficiently. Autotuning is an automatic optimization scheme able to search for optimal configurations and has been applied successfully to kD-trees in the past, which we apply today on BVHs. The more parameters to optimize, the more difficult it is to find optimal solutions. In this article, we analyze in detail the behavior of the parameters and their impact on acceleration structure building and rendering time. We show the interdependence and context sensitivity (i.e., scene, viewpoint) of the parameters. Based on the use case, this allows to target only crucial parameters. Convergence speed towards an optimal configuration is essential. To find better parameters, the autotuner needs to build the acceleration structure over and over, changing parameters every time. We introduce a hybrid model-based prediction and online autotuning method to address this issue. The prediction model allows for both instantaneous near-optimal configurations when inputs are known or similar, and efficient search of the configuration space when inputs are completely new. Online autotuning outperforms configurations recommended in literature by up to 11% median. The prediction model achieves 95% of the maximum speedup of the autotuner while reducing 90% of its overhead. Thus, hybrid online autonuning enables always-on tuning in ray tracing.
C1 [Herveau, Killian; Dachsbacher, Carsten] Karlsruhe Inst Technol IVD, D-76131 Karlsruhe, Germany.
   [Pfaffe, Philip; Tillmann, Martin; Tichy, Walter F. F.] Karlsruhe Inst Technol IVD, Inst Program Struct & Data Org, D-76131 Karlsruhe, Germany.
RP Herveau, K (corresponding author), Karlsruhe Inst Technol IVD, D-76131 Karlsruhe, Germany.
EM k.herveau@gmail.com; philip.pfaffe@gmail.com; martin.tillmann@gmail.com;
   walter.tichy@kit.edu; dachsbacher@kit.edu
OI Tichy, Walter/0000-0002-1288-454X
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [299215159, DA 1200/5-1, TI 264/10-1]
FX This work was supported by Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) - project 299215159 with Grants DA 1200/5-1 and TI
   264/10-1.
CR Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Balaprakash P, 2013, IEEE INT C CL COMP
   Bao WL, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/3011017
   Bittner J, 2015, COMPUT GRAPH-UK, V47, P135, DOI 10.1016/j.cag.2014.12.001
   Burley B, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182159
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Chang KH, 2012, EUR J OPER RES, V220, P684, DOI 10.1016/j.ejor.2012.02.028
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Christensen P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182162
   Dahm K, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085032
   Dammertz H, 2008, COMPUT GRAPH FORUM, V27, P1225, DOI 10.1111/j.1467-8659.2008.01261.x
   Ganestam P., 2012, PROC ANN WORKSHOP GE, P94
   Haines Eric., 2019, RAY TRACING GEMS HIG
   Havran V, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P209
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kay T. L., 1986, Computer Graphics, V20, P269, DOI 10.1145/15886.15916
   Kretchmar RW, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, P834, DOI 10.1109/ICNN.1997.616132
   Li T., 2018, PROC WORKSHOP MACH L
   Liu J, 2021, IEEE T VIS COMPUT GR, V27, P1764, DOI 10.1109/TVCG.2020.3030364
   Liu J, 2018, IEEE T VIS COMPUT GR, V24, P319, DOI 10.1109/TVCG.2017.2744418
   Maei Hamid Reza, 2010, Proceedings of the 27th International Conference on Machine Learning ICML 2010, P719
   McGuire Morgan, 2017, MCGUIRE COMPUT GRAPH
   MCKAY MD, 1979, TECHNOMETRICS, V21, P239, DOI 10.2307/1268522
   Meister D, 2018, COMPUT GRAPH FORUM, V37, P463, DOI 10.1111/cgf.13376
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Nocak J., 2010, PROC 31 ANN C EUR AS, P61
   Otsu H., 2018, LIGHTMETRICA3
   Park H, 2021, IEEE T VIS COMPUT GR, V27, P1407, DOI 10.1109/TVCG.2020.3030380
   Pharr Matt., 2017, Physically Based Rendering: From Theory to Implementation, VThird
   Reibold F, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275030
   Schied C, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233301
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Settles B., 2009, ACTIVE LEARING LIT S
   Stich M., 2009, P C HIGH PERF GRAPH, P7, DOI [10.1145/1572769.1572771, DOI 10.1145/1572769.1572771]
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tapus Cristian, 2002, SC 02 P 2002 ACMIEEE, P1, DOI DOI 10.1109/SC.2002.10062
   Tillmann M, 2016, INT PARALL DISTRIB P, P628, DOI 10.1109/IPDPS.2016.31
   Tokuyoshi Y., 2012, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, P183, DOI 10.1145/2159616.2159647
   Vinkler M, 2012, COMPUT GRAPH-UK, V36, P283, DOI 10.1016/j.cag.2012.02.013
   Vorba J, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2601097.2601203, 10.1145/2801097.2801203]
   Wald I, 2017, IEEE T VIS COMPUT GR, V23, P931, DOI 10.1109/TVCG.2016.2599041
   Wald I, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601199
   Wang PC, 2011, ADV ENG SOFTW, V42, P529, DOI 10.1016/j.advengsoft.2011.04.004
   Weber N., 2014, EGPGV, P57
   Whaley RC., 1998, P 1998 ACM IEEE C SU, DOI [DOI 10.1109/SC.1998.10004, 10.5555/509058.509096]
   Wodniok D, 2017, COMPUT GRAPH-UK, V62, P41, DOI 10.1016/j.cag.2016.12.003
NR 46
TC 0
Z9 0
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1345
EP 1356
DI 10.1109/TVCG.2021.3113499
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100005
PM 34543197
DA 2024-11-06
ER

PT J
AU Wei, MQ
   Chen, HH
   Zhang, YK
   Xie, HR
   Guo, YW
   Wang, J
AF Wei, Mingqiang
   Chen, Honghua
   Zhang, Yingkui
   Xie, Haoran
   Guo, Yanwen
   Wang, Jun
TI GeoDualCNN: Geometry-Supporting Dual Convolutional Neural Network for
   Noisy Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE GeoDualCNN; normal estimation; point cloud denoising; geometry domain
   knowledge; neural network
ID ROBUST NORMAL ESTIMATION; SURFACE RECONSTRUCTION; SHAPE; 3D
AB We propose a geometry-supporting dual convolutional neural network (GeoDualCNN) for both point cloud normal estimation and denoising. GeoDualCNN fuses the geometry domain knowledge that the underlying surface of a noisy point cloud is piecewisely smooth with the fact that a point normal is properly defined only when local surface smoothness is guaranteed. Centered around this insight, we define the homogeneous neighborhood (HoNe) which stays clear of surface discontinuities, and associate each HoNe with a point whose geometry and normal orientation is mostly consistent with that of HoNe. Thus, we not only obtain initial estimates of the point normals by performing PCA on HoNes, but also for the first time optimize these initial point normals by learning the mapping from two proposed geometric descriptors to the ground-truth point normals. GeoDualCNN consists of two parallel branches that remove noise using the first geometric descriptor (a homogeneous height map, which encodes the point-position information), while preserving surface features using the second geometric descriptor (a homogeneous normal map, which encodes the point-normal information). Such geometry-supporting network architectures enable our model to leverage previous geometry expertise and to benefit from training data. Experiments with noisy point clouds show that GeoDualCNN outperforms the state-of-the-art methods in terms of both noise-robustness and feature preservation.
C1 [Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, Shenzhen Res Inst, Sch Comp Sci & Technol, Nanjing 210016, Peoples R China.
   [Chen, Honghua; Wang, Jun] Nanjing Univ Aeronaut & Astronaut, Sch Mech & Elect Engn, Nanjing 210016, Peoples R China.
   [Zhang, Yingkui] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.
   [Guo, Yanwen] Nanjing Univ, Dept Comp Sci & Technol, Nanjing 210093, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Lingnan University; Nanjing
   University
RP Xie, HR (corresponding author), Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.; Guo, YW (corresponding author), Nanjing Univ, Dept Comp Sci & Technol, Nanjing 210093, Peoples R China.
EM mingqiang.wei@gmail.com; chenhonghuacn@gmail.com; yk.zhang1@siat.ac.cn;
   hrxie2@gmail.com; ywguo@nju.edu.cn; wjun@nuaa.edu.cn
RI Xie, Haoran/AFS-3515-2022
OI Xie, Haoran/0000-0003-0965-3617; Honghua, Chen/0000-0001-7473-1146
CR Adamson A, 2006, ACM T GRAPHIC, V25, P671, DOI 10.1145/1141911.1141940
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alliez Pierre, 2007, P 5 EUROGRAPHICS S G, V7, P39, DOI DOI 10.2312/SGP/SGP07/039-048(VERP.39
   Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Ben-Shabat Y, 2019, PROC CVPR IEEE, P10104, DOI 10.1109/CVPR.2019.01035
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Boulch A, 2012, COMPUT GRAPH FORUM, V31, P1765, DOI 10.1111/j.1467-8659.2012.03181.x
   Cazals F, 2005, COMPUT AIDED GEOM D, V22, P121, DOI 10.1016/j.cagd.2004.09.004
   Chen HH, 2019, COMPUT AIDED DESIGN, V115, P122, DOI 10.1016/j.cad.2019.05.036
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dey TK, 2006, COMP GEOM-THEOR APPL, V35, P124, DOI 10.1016/j.comgeo.2005.10.006
   Digne J., 2012, P IEEE CVF C COMP VI, P73
   Digne J, 2018, IEEE T VIS COMPUT GR, V24, P2238, DOI 10.1109/TVCG.2017.2719024
   Dinesh C, 2020, IEEE T IMAGE PROCESS, V29, P4143, DOI 10.1109/TIP.2020.2969052
   Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Garland M., 1997, P 24 ANN C COMP GRAP, P209, DOI DOI 10.1145/258734.258849
   Guennebaud G, 2008, COMPUT GRAPH FORUM, V27, P653, DOI 10.1111/j.1467-8659.2008.01163.x
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hashimoto Taisuke, 2019, IEEE C COMP VIS PATT, V1
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Lenssen JE, 2020, PROC CVPR IEEE, P11244, DOI 10.1109/CVPR42600.2020.01126
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Levoy M., 1985, 85022 U N CAR TR
   Li B, 2010, COMPUT GRAPH-UK, V34, P94, DOI 10.1016/j.cag.2010.01.004
   Liao B, 2013, COMPUT AIDED DESIGN, V45, P861, DOI 10.1016/j.cad.2013.02.003
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Lu DN, 2020, COMPUT AIDED DESIGN, V125, DOI 10.1016/j.cad.2020.102860
   Lu XQ, 2022, IEEE T VIS COMPUT GR, V28, P1835, DOI 10.1109/TVCG.2020.3026785
   Lu XQ, 2018, IEEE T VIS COMPUT GR, V24, P2315, DOI 10.1109/TVCG.2017.2725948
   Maximo A, 2011, GRAPH MODELS, V73, P231, DOI 10.1016/j.gmod.2011.05.002
   Mérigot Q, 2011, IEEE T VIS COMPUT GR, V17, P743, DOI 10.1109/TVCG.2010.261
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Preiner R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601172
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Remil O, 2017, COMPUT AIDED DESIGN, V88, P31, DOI 10.1016/j.cad.2017.04.004
   Rosman G, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12139
   Roveri R, 2018, COMPUT GRAPH FORUM, V37, P87, DOI 10.1111/cgf.13344
   Serna Andres, 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P819
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Wang PS, 2020, IEEE COMPUT SOC CONF, P1074, DOI 10.1109/CVPRW50498.2020.00141
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang Y, 2013, COMPUT AIDED DESIGN, V45, P1333, DOI 10.1016/j.cad.2013.06.003
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P2910, DOI 10.1109/TVCG.2018.2865363
   Wei MQ, 2015, IEEE T VIS COMPUT GR, V21, P43, DOI 10.1109/TVCG.2014.2326872
   Wei MQ, 2013, OPT LASER ENG, V51, P1223, DOI 10.1016/j.optlaseng.2013.04.018
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Xiong SY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661263
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu ZW, 2021, IEEE T VIS COMPUT GR, V27, P2851, DOI 10.1109/TVCG.2019.2959761
   Yadav SK, 2018, COMPUT GRAPH-UK, V74, P234, DOI 10.1016/j.cag.2018.05.014
   Yu LQ, 2018, Arxiv, DOI arXiv:1801.06761
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhang J, 2019, IEEE T VIS COMPUT GR, V25, P1693, DOI 10.1109/TVCG.2018.2827998
   Zhang WY, 2015, COMPUT GRAPH FORUM, V34, P23, DOI 10.1111/cgf.12742
   Zheng YY, 2011, IEEE T VIS COMPUT GR, V17, P1521, DOI 10.1109/TVCG.2010.264
   Zhou HR, 2020, PROC CVPR IEEE, P13235, DOI 10.1109/CVPR42600.2020.01325
   Zhou J, 2020, COMPUT AIDED DESIGN, V129, DOI 10.1016/j.cad.2020.102916
   Zhu L, 2013, COMPUT GRAPH FORUM, V32, P371, DOI 10.1111/cgf.12245
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
NR 71
TC 11
Z9 11
U1 4
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1357
EP 1370
DI 10.1109/TVCG.2021.3113463
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100006
PM 34546923
DA 2024-11-06
ER

PT J
AU Han, FZ
   Ye, SQ
   He, MM
   Chai, ML
   Liao, J
AF Han, Fangzhou
   Ye, Shuquan
   He, Mingming
   Chai, Menglei
   Liao, Jing
TI Exemplar-Based 3D Portrait Stylization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural style transfer; artistic portrait; 3D face modeling;
   differentiable rendering
AB Exemplar-based portrait stylization is widely attractive and highly desired. Despite recent successes, it remains challenging, especially when considering both texture and geometric styles. In this article, we present the first framework for one-shot 3D portrait style transfer, which can generate 3D face models with both the geometry exaggerated and the texture stylized while preserving the identity from the original content. It requires only one arbitrary style image instead of a large set of training examples for a particular style, provides geometry and texture outputs that are fully parameterized and disentangled, and enables further graphics applications with the 3D representations. The framework consists of two stages. In the first geometric style transfer stage, we use facial landmark translation to capture the coarse geometry style and guide the deformation of the dense 3D face geometry. In the second texture style transfer stage, we focus on performing style transfer on the canonical texture by adopting a differentiable renderer to optimize the texture in a multi-view framework. Experiments show that our method achieves robustly good results on different artistic styles and outperforms existing methods. We also demonstrate the advantages of our method via various 2D and 3D graphics applications.
C1 [Han, Fangzhou; Ye, Shuquan; Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [He, Mingming] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90007 USA.
   [Chai, Menglei] Snap Inc, Creat Vis Team, Los Angeles, CA 90291 USA.
C3 City University of Hong Kong; University of Southern California
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM han.fangzhou@my.cityu.edu.hk; shuquanye2-c@my.cityu.edu.hk;
   hmm.lillian@gmail.com; cmlatsim@gmail.com; jingliao@cityu.edu.hk
RI He, Mingming/AAY-5609-2021
OI Ye, Shuquan/0000-0001-5121-8040; LIAO, Jing/0000-0001-7014-5377
FU Donation-RMGS of CityU Hong Kong [9229064]; Shenzhen Basic Research
   General Program [JCYJ20190814112007258]
FX This work was supported in part by the Donation-RMGS of CityU Hong Kong
   under Grant 9229064, in part by the Shenzhen Basic Research General
   Program under Grant JCYJ20190814112007258.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Akleman E., 1997, ACM SIGGRAPH, DOI DOI 10.1145/259081.259231
   BRENNAN SE, 1985, LEONARDO, V18, P170, DOI 10.2307/1578048
   Cao C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275093
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cavalcante Vieira Roberto C., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P163, DOI 10.1109/SIBGRAPI.2013.31
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chu WQ, 2021, INT J COMPUT VISION, V129, P2663, DOI 10.1007/s11263-021-01489-1
   DLib, 2019, DLIB C LIB
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fiser J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073660
   FUTSCHIK D., 2019, Proceedings of the ACM/EG Expressive Symposium, P33
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gu SY, 2018, PROC CVPR IEEE, P8222, DOI 10.1109/CVPR.2018.00858
   Han XG, 2020, IEEE T VIS COMPUT GR, V26, P2349, DOI 10.1109/TVCG.2018.2886007
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kaidi Cao, 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3272127.3275046
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kolkin N, 2019, PROC CVPR IEEE, P10043, DOI 10.1109/CVPR.2019.01029
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Lewiner T, 2011, COMPUT GRAPH-UK, V35, P586, DOI 10.1016/j.cag.2011.03.005
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li WB, 2020, NEURAL NETWORKS, V132, P66, DOI 10.1016/j.neunet.2020.08.011
   Li YJ, 2017, ADV NEUR IN, V30
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu HTD, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275047
   Liu JF, 2009, COMPUT GRAPH FORUM, V28, P2104, DOI 10.1111/j.1467-8659.2009.01418.x
   Liu MY, 2017, ADV NEUR IN, V30
   Mordvintsev A., 2018, Distill, V3, DOI [DOI 10.23915/DISTILL.00012, 10.23915/distill.00012]
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Shi Y., 2019, PROC IEEECVF C COMPU, p10 762
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Xiang ST, 2018, Arxiv, DOI arXiv:1805.07997
   Yaniv J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322984
   Ye ZP, 2021, Arxiv, DOI arXiv:2003.06841
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 44
TC 15
Z9 15
U1 3
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1371
EP 1383
DI 10.1109/TVCG.2021.3114308
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100007
PM 34559656
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, J
   Xu, SY
   Chandrasegaran, S
   Bryan, C
   Du, F
   Mishra, A
   Qian, X
   Li, YR
   Ma, KL
AF Zhao, Jian
   Xu, Shenyu
   Chandrasegaran, Senthil
   Bryan, Chris
   Du, Fan
   Mishra, Aditi
   Qian, Xin
   Li, Yiran
   Ma, Kwan-Liu
TI ChartStory: Automated Partitioning, Layout, and Captioning of Charts
   into Comic-Style Narratives
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data story generation; narrative visualization; data-driven
   storytelling; data comics
ID VISUALIZATIONS; GENERATION; DESIGN
AB Visual data storytelling is gaining importance as a means of presenting data-driven information or analysis results, especially to the general public. This has resulted in design principles being proposed for data-driven storytelling, and new authoring tools being created to aid such storytelling. However, data analysts typically lack sufficient background in design and storytelling to make effective use of these principles and authoring tools. To assist this process, we present ChartStory for crafting data stories from a collection of user-created charts, using a style akin to comic panels to imply the underlying sequence and logic of data-driven narratives. Our approach is to operationalize established design principles into an advanced pipeline that characterizes charts by their properties and similarities to each other, and recommends ways to partition, layout, and caption story pieces to serve a narrative. ChartStory also augments this pipeline with intuitive user interactions for visual refinement of generated data comics. We extensively and holistically evaluate ChartStory via a trio of studies. We first assess how the tool supports data comic creation in comparison to a manual baseline tool. Data comics from this study are subsequently compared and evaluated to ChartStory's automated recommendations by a team of narrative visualization practitioners. This is followed by a pair of interview studies with data scientists using their own datasets and charts who provide an additional assessment of the system. We find that ChartStory provides cogent recommendations for narrative generation, resulting in data comics that compare favorably to manually-created ones.
C1 [Zhao, Jian] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   [Xu, Shenyu] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Chandrasegaran, Senthil] Delft Univ Technol, NL-2628 CD Delft, Netherlands.
   [Bryan, Chris; Mishra, Aditi] Arizona State Univ, Phoenix, AZ 85004 USA.
   [Du, Fan] Adobe Res, San Jose, CA 95110 USA.
   [Qian, Xin] Univ Maryland, College Pk, MD 20742 USA.
   [Li, Yiran; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of Waterloo; University System of Georgia; Georgia Institute
   of Technology; Delft University of Technology; Arizona State University;
   Arizona State University-Downtown Phoenix; Adobe Systems Inc.;
   University System of Maryland; University of Maryland College Park;
   University of California System; University of California Davis
RP Zhao, J (corresponding author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
EM jianzhao@uwaterloo.ca; shenyuxu@gatech.edu;
   r.s.k.chandrasegaran@tudelft.nl; chris.bryan@asu.edu; fdu@adobe.com;
   amishr45@asu.edu; xinq@umd.edu; ranli@ucdavis.edu; klma@ucdavis.edu
OI Ma, Kwan-Liu/0000-0001-8086-0366; Chandrasegaran,
   Senthil/0000-0003-0561-2148; Zhao, Jian/0000-0001-5008-4319
FU Natural Sciences and Engineering Research Council of Canada; U.S.
   National Science Foundation [IIS-1741536, IIS-1528203, OAC-1934766];
   Adobe gift fund
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada, the U.S. National Science Foundation under
   Grants IIS-1741536, IIS-1528203, and OAC-1934766, and an Adobe gift
   fund.
CR [Anonymous], 2019, COLL SCORECARD DATA
   [Anonymous], 2019, GUN DEATHS US 2012 2
   [Anonymous], 2019, wired
   [Anonymous], 2019, GLOB TERR DAT
   [Anonymous], 2016, Tech. rep. MSR-TR-2016-14
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2017, IEEE COMPUT GRAPH, V37, P6, DOI 10.1109/MCG.2017.33
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bateman JA, 2017, DIGIT SCHOLARSH HUM, V32, P476, DOI 10.1093/llc/fqw024
   Brehmer M., 2019, P COMP JOURN S
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Chapman Robyn, 2012, DRAWING COMICS LAB 5
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chu W.-T., 2013, PROC INT WORKSHOP IN, P1
   Chu WT, 2015, IEEE T MULTIMEDIA, V17, P201, DOI 10.1109/TMM.2014.2383616
   Cohn N, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00186
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Groensteen T., 2013, Comics and narration
   Han J, 2012, MOR KAUF D, P1
   HART S G, 1988, P139
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Kery MB, 2017, S VIS LANG HUM CEN C, P25, DOI 10.1109/VLHCC.2017.8103446
   Kim NW, 2019, P 2019 CHI C HUMAN F, P1, DOI DOI 10.1145/3290605.3300309
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Lancichinetti A, 2009, NEW J PHYS, V11, DOI 10.1088/1367-2630/11/3/033015
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McCloud Scott, 1993, Understanding comics the invisible art
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Subramanian K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376764
   Thomas J. J., 2005, PNNLSA45230 IEEE COM
   THORNDYKE PW, 1977, COGNITIVE PSYCHOL, V9, P77, DOI 10.1016/0010-0285(77)90005-6
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang ZZ, 2021, IEEE T VIS COMPUT GR, V27, P967, DOI 10.1109/TVCG.2020.3030433
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Xin Qian, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382946
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P340, DOI 10.1109/TVCG.2017.2745279
   Zhao Z., 2015, HCIL201515 U MAR
NR 58
TC 12
Z9 15
U1 4
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1384
EP 1399
DI 10.1109/TVCG.2021.3114211
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100008
PM 34559655
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, JL
   Fan, CJ
   Zhang, ZM
   Li, GZ
   Zhao, Z
   Deng, ZG
   Ding, Y
AF Chen, Jiali
   Fan, Changjie
   Zhang, Zhimeng
   Li, Gongzheng
   Zhao, Zeng
   Deng, Zhigang
   Ding, Yu
TI A Music-Driven Deep Generative Adversarial Model for Guzheng Playing
   Animation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep learning; generative adversarial networks; motion capture; guzheng
   animation; music-driven; data augmentation
ID BODY MOVEMENTS; EXPRESSIVENESS; MOTION
AB To date relatively few efforts have been made on the automatic generation of musical instrument playing animations. This problem is challenging due to the intrinsically complex, temporal relationship between music and human motion as well as the lacking of high quality music-playing motion datasets. In this article, we propose a fully automatic, deep learning based framework to synthesize realistic upper body animations based on novel guzheng music input. Specifically, based on a recorded audiovisual motion capture dataset, we delicately design a generative adversarial network (GAN) based approach to capture the temporal relationship between the music and the human motion data. In this process, data augmentation is employed to improve the generalization of our approach to handle a variety of guzheng music inputs. Through extensive objective and subjective experiments, we show that our method can generate visually plausible guzheng-playing animations that are well synchronized with the input guzheng music, and it can significantly outperform the state-of-the-art methods. In addition, through an ablation study, we validate the contributions of the carefully-designed modules in our framework.
C1 [Chen, Jiali; Fan, Changjie; Zhang, Zhimeng; Li, Gongzheng; Zhao, Zeng; Ding, Yu] Netease, Netease Fuxi AI Lab, Hangzhou, Zhejiang, Peoples R China.
   [Deng, Zhigang] Univ Houston, Dept Comp Sci, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Ding, Y (corresponding author), Netease, Netease Fuxi AI Lab, Hangzhou, Zhejiang, Peoples R China.
EM chenjiali02@corp.netease.com; fanchangjie@corp.netease.com;
   zhangzhimeng@corp.netease.com; ligongzheng@corp.netease.com;
   hzzhaozeng@corp.netease.com; zdeng4@central.uh.edu;
   dingyu01@corp.netease.com
OI Zhao, Zeng/0000-0002-7292-876X; Deng, Zhigang/0000-0002-0452-8676; Deng,
   Zhigang/0000-0003-2571-5865
CR Adam Paszke SG, 2017, NIPS 2017 WORKSH AUT
   Aguera PE, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/158970
   Alemi O., 2017, networks, V8
   Alom M. Z., 2017, arXiv, DOI DOI 10.1007/S00138-020-01157-3
   [Anonymous], 2015, PROC AVSP
   Bai SJ, 2018, Arxiv, DOI arXiv:1803.01271
   Berman A, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2431
   Bogaers A, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P22, DOI 10.1145/3395035.3425244
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Busso C, 2005, COMPUT ANIMAT VIRT W, V16, P283, DOI 10.1002/cav.80
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Cadoz Claude., 2000, Trends in Gestural Control of Music
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chen JL, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P108, DOI 10.1145/3308532.3329445
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Chou JC, 2018, Arxiv, DOI arXiv:1804.02812
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Dahl S, 2003, LECT NOTES ARTIF INT, V2915, P479
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Davidson J.W., 1993, PSYCHOL MUSIC, V21, P103, DOI [10.1177/030573569302100201, DOI 10.1177/030573569302100201]
   Deng Z., 2006, Proc. of ACM SIGGGRAPH/Eurographics Symposium on Computer Animation, P251
   Deng Zhigang., 2008, Data-driven 3D facial animation, P1
   Ding Y., 2012, PROC WORKSHOP AFFECT, P103
   Ding Y., 2017, HDB HUMAN MOTION, P1
   Ding Y, 2017, IEEE T AFFECT COMPUT, V8, P546, DOI 10.1109/TAFFC.2017.2754365
   Ding Y, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P773
   Ding Y, 2013, INT CONF ACOUST SPEE, P3756, DOI 10.1109/ICASSP.2013.6638360
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Ferstl Y, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P93, DOI 10.1145/3267851.3267898
   Friberg A., 2004, P MUS MUS SCI, V10, P28
   Fukayama S., 2014, Proceedings of the 11th Conference on Advances in Computer Entertainment Technology, P1
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   HALL CA, 1976, J APPROX THEORY, V16, P105, DOI 10.1016/0021-9045(76)90040-X
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HIRSCHBERG DS, 1977, J ACM, V24, P664, DOI 10.1145/322033.322044
   Hsuan-Kai Kao, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P147, DOI 10.1145/3394171.3413848
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang RZ, 2021, Arxiv, DOI arXiv:2006.06119
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Jin AB, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340250
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kingma DP, 2014, ADV NEUR IN, V27
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Le BH, 2012, IEEE T VIS COMPUT GR, V18, P1902, DOI 10.1109/TVCG.2012.74
   Lee H.-Y., 2019, P 33 C NEUR INF PROC, P3581
   Lee Juheon., 2019, Proceedings of the 20th International Society for Music Information Retrieval Conference (Delft, The Netherlands), P894, DOI [10.5281/zenodo.3527958, DOI 10.5281/ZENODO.3527958]
   Lee M, 2013, MULTIMED TOOLS APPL, V62, P895, DOI 10.1007/s11042-012-1288-5
   Lewis John P, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li B., 2018, P INT SOC MUS INF RE, P218, DOI [10.5281/zenodo.1492387, DOI 10.5281/ZENODO.1492387]
   Li LC, 2021, AAAI CONF ARTIF INTE, V35, P1911
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Liao M, 2020, Arxiv, DOI arXiv:2007.09198
   Liu JW, 2020, INT CONF ACOUST SPEE, P3787, DOI [10.1109/icassp40776.2020.9054463, 10.1109/ICASSP40776.2020.9054463]
   Ma L, 2019, COMPUT GRAPH FORUM, V38, P470, DOI 10.1111/cgf.13586
   Mancini M, 2017, ACM T INTERNET TECHN, V17, DOI 10.1145/2998571
   Mariooryad S, 2012, IEEE T AUDIO SPEECH, V20, P2329, DOI 10.1109/TASL.2012.2201476
   Mcknight P. E., 2010, CORSINI ENCY PSYCHOL, P1, DOI [10.3109/9780203450307-26, DOI 10.3109/9780203450307-26]
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Nair V, 2010, ICML, P807, DOI DOI 10.5555/3104322.3104425
   Odena A, 2016, Deconvolution and checkerboard artifacts, V1, P3, DOI [10.23915/distill.00003, 10.23915/distill.00003.-URL, DOI 10.23915/DISTILL.00003]
   Ofli F, 2012, IEEE T MULTIMEDIA, V14, P747, DOI 10.1109/TMM.2011.2181492
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, 10.48550/arXiv.1804.03999]
   Pavllo D, 2018, Arxiv, DOI arXiv:1805.06485
   Pavllo D, 2020, INT J COMPUT VISION, V128, P855, DOI 10.1007/s11263-019-01245-6
   Pecune F, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS (AAMAS'15), P1817
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Rodriguez I, 2019, ROBOT AUTON SYST, V114, P57, DOI 10.1016/j.robot.2018.11.024
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Shlizerman E, 2018, PROC CVPR IEEE, P7574, DOI 10.1109/CVPR.2018.00790
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thompson MR, 2012, MUSIC SCI, V16, P19, DOI 10.1177/1029864911423457
   van Welbergen H, 2015, LECT NOTES ARTIF INT, V9238, P139, DOI 10.1007/978-3-319-21996-7_16
   Wallace B, 2020, Arxiv, DOI arXiv:2011.13453
   Wang SZ, 2021, PROCEEDINGS OF THE THIRTIETH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2021, P1098
   Widmer G, 2009, AI MAG, V30, P35, DOI 10.1609/aimag.v30i3.2249
   Ye ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P744, DOI 10.1145/3394171.3414005
   Yu Ding, 2013, Intelligent Virtual Agents. 13th International Conference, IVA 2013. Proceedings: LNCS 8108, P217, DOI 10.1007/978-3-642-40415-3_19
   Alom MZ, 2018, Arxiv, DOI arXiv:1802.06955
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zhu YF, 2013, COMPUT ANIMAT VIRT W, V24, P445, DOI 10.1002/cav.1477
NR 89
TC 3
Z9 3
U1 7
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1400
EP 1414
DI 10.1109/TVCG.2021.3115902
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100009
PM 34582351
DA 2024-11-06
ER

PT J
AU Du, MH
   Cui, H
   Wang, Y
   Duh, HBL
AF Du, Minghan
   Cui, Hui
   Wang, Yuan
   Duh, Henry Been-Lirn
TI Learning from Deep Stereoscopic Attention for Simulator Sickness
   Prediction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Stereoscopic video; simulator sickness; virtual reality; attention
   mechanism; 3D CNN; I.4.9 [image processing and computer Vision];
   applications; H.5.1 [information interfaces and presentation];
   multimedia information systems
ID MOTION SICKNESS; DEPTH
AB Simulator sickness induced by 360 & DEG; stereoscopic video contents is a prolonged challenging issue in Virtual Reality (VR) system. Current machine learning models for simulator sickness prediction ignore the underlying interdependencies and correlations across multiple visual features which may lead to simulator sickness. We propose a model for sickness prediction by automatic learning and adaptive integrating multi-level mappings from stereoscopic video features to simulator sickness scores. Firstly, saliency, optical flow and disparity features are extracted from videos to reflect the factors causing simulator sickness, including human attention area, motion velocity and depth information. Then, these features are embedded and fed into a 3-dimensional convolutional neural network (3D CNN) to extract the underlying multi-level knowledge which includes low-level and higher-order visual concepts, and global image descriptor. Finally, an attentional mechanism is exploited to adaptively fuse multi-level information with attentional weights for sickness score estimation. The proposed model is trained by an end-to-end approach and validated over a public dataset. Comparison results with state-of-the-art models and ablation studies demonstrated improved performance in terms of Root Mean Square Error (RMSE) and Pearson Linear Correlation Coefficient.
C1 [Du, Minghan; Cui, Hui; Wang, Yuan; Duh, Henry Been-Lirn] La Trobe Univ, Dept Comp Sci & Informat Technol, Bundoora, Vic 3086, Australia.
C3 La Trobe University
RP Cui, H (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Bundoora, Vic 3086, Australia.
EM 19617849@students.latrobe.edu.au; l.cui@latrobe.edu.au;
   yuan.wang@latrobe.edu.au; b.duh@latrobe.edu.au
RI Duh, Henry/G-3220-2010
OI Duh, Henry/0000-0003-4808-6109
FU China Scholarship Council [201806030241]
FX This work was supported by China Scholarship Council under Grant
   201806030241
CR [Anonymous], 2009, THESIS MIT MA
   Bos JE, 1998, BRAIN RES BULL, V47, P537, DOI 10.1016/S0361-9230(98)00088-4
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Buhler H, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P517, DOI 10.1109/VR.2018.8446346
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   GIBSON JJ, 1977, SCAND J PSYCHOL, V18, P161, DOI 10.1111/j.1467-9450.1977.tb00272.x
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Harel J., 2007, P ADV NEUR INF PROC, P545
   Hell S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P153, DOI 10.1109/AIVR.2018.00032
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Huang JC, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102709
   Jetley S., 2018, LEARN PAY ATTENTION
   Jun-Goo Shin, 2017, 2017 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2017.8496170
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Schlemper J, 2019, MED IMAGE ANAL, V53, P197, DOI 10.1016/j.media.2019.01.012
   Tzovaras D, 1998, SIGNAL PROCESS-IMAGE, V11, P205, DOI 10.1016/S0923-5965(97)00029-5
   Wang YY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1874, DOI [10.1109/VR.2019.8798213, 10.1109/vr.2019.8798213]
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898
NR 30
TC 7
Z9 7
U1 0
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1415
EP 1423
DI 10.1109/TVCG.2021.3115901
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100010
PM 34582350
DA 2024-11-06
ER

PT J
AU Choi, J
   Lee, SE
   Lee, Y
   Cho, E
   Chang, S
   Jeong, WK
AF Choi, JunYoung
   Lee, Sang-Eun
   Lee, YeIn
   Cho, Eunji
   Chang, Sunghoe
   Jeong, Won-Ki
TI DXplorer: A Unified Visualization Framework for Interactive Dendritic
   Spine Analysis Using 3D Morphological Features
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Biomedical and medical visualization; machine learning; task and
   requirements analysis; user interfaces; intelligence analysis
ID THIN; PATHOLOGY; DENSITY
AB Dendritic spines are dynamic, submicron-scale protrusions on neuronal dendrites that receive neuronal inputs. Morphological changes in the dendritic spine often reflect alterations in physiological conditions and are indicators of various neuropsychiatric conditions. However, owing to the highly dynamic and heterogeneous nature of spines, accurate measurement and objective analysis of spine morphology are major challenges in neuroscience research. Most conventional approaches for analyzing dendritic spines are based on two-dimensional (2D) images, which barely reflect the actual three-dimensional (3D) shapes. Although some recent studies have attempted to analyze spines with various 3D-based features, it is still difficult to objectively categorize and analyze spines based on 3D morphology. Here, we propose a unified visualization framework for an interactive 3D dendritic spine analysis system, DXplorer, that displays 3D rendering of spines and plots the high-dimensional features extracted from the 3D mesh of spines. With this system, users can perform the clustering of spines interactively and explore and analyze dendritic spines based on high-dimensional features. We propose a series of high-dimensional morphological features extracted from a 3D mesh of dendritic spines. In addition, an interactive machine learning classifier with visual exploration and user feedback using an interactive 3D mesh grid view ensures a more precise classification based on the spine phenotype. A user study and two case studies were conducted to quantitatively verify the performance and usability of the DXplorer. We demonstrate that the system performs the entire analytic process effectively and provides high-quality, accurate, and objective analysis.
C1 [Choi, JunYoung] Ulsan Natl Inst Sci & Technol, Ulsan 44919, South Korea.
   [Lee, Sang-Eun; Cho, Eunji; Chang, Sunghoe] Seoul Natl Univ, Coll Med, Seoul 08826, South Korea.
   [Lee, YeIn; Jeong, Won-Ki] Korea Univ, Seoul 02841, South Korea.
C3 Ulsan National Institute of Science & Technology (UNIST); Seoul National
   University (SNU); Korea University
RP Jeong, WK (corresponding author), Korea Univ, Seoul 02841, South Korea.
EM juny0603@unist.ac.kr; sangeun45@snu.ac.kr; yeati1086@korea.ac.kr;
   eunji0623@snu.ac.kr; sunghoe@snu.ac.kr; wkjeong@korea.ac.kr
RI Lee, Sang-Eun/HJH-1132-2023; choi, junyoung/T-4389-2019; Jeong,
   Won-Ki/F-8171-2011
OI Jeong, Won-Ki/0000-0002-9393-6451; Choi, JunYoung/0000-0002-4255-4402;
   Lee, Sang-Eun/0000-0001-7371-8556; cho, eunji/0000-0002-8486-3641
FU National Research Foundation of Korea [NRF-2017M3C7A1047904,
   NRF-2019M3E5D2A01063819, NRF-2021R1A6A1A13044830]; Institute for
   Information & Communications Technology Planning Evaluation
   [IITP-2021-2020-0-01819]
FX This work was supported in part by the National Research Foundation of
   Korea under Grants NRF-2017M3C7A1047904, NRF-2019M3E5D2A01063819, and
   NRF-2021R1A6A1A13044830 and in part by the Institute for Information &
   Communications Technology Planning & Evaluation under Grant
   IITP-2021-2020-0-01819.
CR [Anonymous], 2011, P 44 HAW INT C SYST, DOI DOI 10.1109/HICSS.2011.339
   Attig C, 2017, LECT NOTES ARTIF INT, V10276, P3, DOI 10.1007/978-3-319-58475-1_1
   Basu S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21753-8
   Bertling E, 2012, METHOD ENZYMOL, V506, P391, DOI 10.1016/B978-0-12-391856-7.00043-3
   Blanchette J., 2006, C GUI PROGRAMMINGWIT
   Bourne J, 2007, CURR OPIN NEUROBIOL, V17, P381, DOI 10.1016/j.conb.2007.04.009
   Brancato A, 2017, NEUROSCIENCE, V350, P180, DOI 10.1016/j.neuroscience.2017.03.014
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Dickstein D. L., 2010, ALZHEIMERS DEMENT, V4, pS410
   Eblenkamp M, 2015, IFMBE PROC, V45, P138, DOI 10.1007/978-3-319-11128-5_35
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   HEIDEN W, 1993, J COMPUT CHEM, V14, P246, DOI 10.1002/jcc.540140212
   Hoffmann NA, 2013, ACTA NEUROPATHOL COM, V1, DOI 10.1186/2051-5960-1-82
   Jolliffe I., 2011, INT ENCY STAT SCI, P1094, DOI [10.1007/978-3-642-04898-2_455, DOI 10.1007/978-3-642-04898-2_455, https://doi.org/10.1007/978-3-642-04898-2455]
   Kashiwagi Y, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09337-0
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Lee SE, 2016, P NATL ACAD SCI USA, V113, P6749, DOI 10.1073/pnas.1600944113
   Levet F, 2020, METHODS, V174, P49, DOI 10.1016/j.ymeth.2020.01.020
   Luengo-Sanchez S, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006221
   Maiti P, 2015, NEUROSCI BIOBEHAV R, V59, P208, DOI 10.1016/j.neubiorev.2015.09.020
   MBF Bioscience, MICR
   MBF Bioscience, AUT
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nimchinsky EA, 2002, ANNU REV PHYSIOL, V64, P313, DOI 10.1146/annurev.physiol.64.081501.160008
   O'Reilly K, 2018, EUR NEUROPSYCHOPHARM, V28, pS43, DOI 10.1016/j.euroneuro.2017.12.071
   Parsons G., 1998, 2306 RFC
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Penzes P, 2011, NAT NEUROSCI, V14, P285, DOI 10.1038/nn.2741
   Qiao H, 2016, NEURAL PLAST, V2016, DOI 10.1155/2016/8056370
   Rao A, 2000, HIPPOCAMPUS, V10, P527, DOI 10.1002/1098-1063(2000)10:5<527::AID-HIPO3>3.0.CO;2-B
   Rincel M, 2018, BRAIN STRUCT FUNCT, V223, P883, DOI 10.1007/s00429-017-1526-8
   Risher WC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107591
   Sacha D, 2018, IEEE T VIS COMPUT GR, V24, P120, DOI 10.1109/TVCG.2017.2744805
   Son J, 2011, J MICROSC-OXFORD, V241, P261, DOI 10.1111/j.1365-2818.2010.03427.x
   Spiga S, 2014, P NATL ACAD SCI USA, V111, pE3745, DOI 10.1073/pnas.1406768111
   Sun SY, 2014, NEURON, V82, P79, DOI 10.1016/j.neuron.2014.02.019
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Swanger SA, 2011, MOL BRAIN, V4, DOI 10.1186/1756-6606-4-38
   Tackenberg C, 2009, CURR ALZHEIMER RES, V6, P261, DOI 10.2174/156720509788486554
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   von Bohlen und Halbach O, 2009, ANN ANAT, V191, P518, DOI 10.1016/j.aanat.2009.08.006
   Zhang Y, 2007, NEUROIMAGE, V36, P346, DOI 10.1016/j.neuroimage.2007.02.044
NR 43
TC 5
Z9 5
U1 4
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1424
EP 1437
DI 10.1109/TVCG.2021.3116656
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100011
PM 34591770
DA 2024-11-06
ER

PT J
AU Zhang, CX
   Ni, SF
   Fan, ZP
   Li, HB
   Zeng, M
   Budagavi, M
   Guo, XH
AF Zhang, Chenxu
   Ni, Saifeng
   Fan, Zhipeng
   Li, Hongbo
   Zeng, Ming
   Budagavi, Madhukar
   Guo, Xiaohu
TI 3D Talking Face With Personalized Pose Dynamics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Audio-driven generation; 3D talking face; personalized pose; generative
   adversarial network
ID DRIVEN
AB Recently, we have witnessed a boom in applications for 3D talking face generation. However, most existing 3D face generation methods can only generate 3D faces with a static head pose, which is inconsistent with how humans perceive faces. Only a few articles focus on head pose generation, but even these ignore the attribute of personality. In this article, we propose a unified audio-driven approach to endow 3D talking faces with personalized pose dynamics. To achieve this goal, we establish an original person-specific dataset, providing corresponding head poses and face shapes for each video. Our framework is composed of two separate modules: PoseGAN and PGFace. Given an input audio, PoseGAN first produces a head pose sequence for the 3D head, and then, PGFace utilizes the audio and pose information to generate natural face models. With the combination of these two parts, a 3D talking head with dynamic head movement can be constructed. Experimental evidence indicates that our method can generate person-specific head pose sequences that are in sync with the input audio and that best match with the human experience of talking heads.
C1 [Zhang, Chenxu; Li, Hongbo; Guo, Xiaohu] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
   [Ni, Saifeng; Budagavi, Madhukar] Samsung Res Amer, Mountain View, CA 94043 USA.
   [Fan, Zhipeng] NYU, Tandon Sch Engn, New York, NY 10003 USA.
   [Zeng, Ming] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
C3 University of Texas System; University of Texas Dallas; Samsung; New
   York University; New York University Tandon School of Engineering;
   Xiamen University
RP Guo, XH (corresponding author), Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75083 USA.
EM chenxu.zhang@utdallas.edu; saifeng.ni@sam-sung.com; zf606@nyu.edu;
   hongbo.li@utdallas.edu; zengming@xmu.edu.cn; m.budagavi@sam-sung.com;
   xguo@utdallas.edu
RI li, hongbo/B-1525-2010; Zeng, Ming/GXF-3628-2022; Fan,
   Zhipeng/JVN-1598-2024
OI Fan, Zhipeng/0000-0001-9386-717X; Li, Hongbo/0009-0005-9072-1489
FU National Science Foundation [2007661]; Samsung Research America; NSFC
   [20720190003]; Fundamental Research Funds for the Central Universities,
   China [62072382]; Direct For Computer & Info Scie & Enginr; Office of
   Advanced Cyberinfrastructure (OAC) [2007661] Funding Source: National
   Science Foundation
FX The work of Zhang, Li, and Guo was supported in part by the National
   Science Foundation under Grant 2007661 and research gifts from Samsung
   Research America. The work of Zeng was supported in part by the NSFC
   under Grant 62072382 and in part by the Fundamental Research Funds for
   the Central Universities, China under Grant 20720190003.
CR Agarwal S., 2019, P IEEE C COMPUTER VI, P38
   Alashkar T., 2014, Proceedings of 5th International Conference on 3D Body Scanning Technologies, P357
   Jalalifar SA, 2018, Arxiv, DOI arXiv:1803.07461
   Amos B., 2016, CMU School Comput. Sci., V6, P20
   Anderson R, 2013, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR.2013.434
   Beskow J., 2020, PROC 20 ACM INT C IN, P1
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bregler C., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P353, DOI 10.1145/258734.258880
   Busso C, 2007, IEEE T AUDIO SPEECH, V15, P1075, DOI 10.1109/TASL.2006.885910
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Chen LL, 2018, LECT NOTES COMPUT SC, V11211, P538, DOI 10.1007/978-3-030-01234-2_32
   Cheng SY, 2018, PROC CVPR IEEE, P5117, DOI 10.1109/CVPR.2018.00537
   Chung J. S., 2017, P BRIT MACH VIS C
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Cosker D, 2011, IEEE I CONF COMP VIS, P2296, DOI 10.1109/ICCV.2011.6126510
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Fan B, 2015, INT CONF ACOUST SPEE, P4884, DOI 10.1109/ICASSP.2015.7178899
   Fanelli G, 2010, IEEE T MULTIMEDIA, V12, P591, DOI 10.1109/TMM.2010.2052239
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hannun A, 2014, Arxiv, DOI arXiv:1412.5567
   Hong P., 2001, International Journal of Image and Graphics, V1, P19
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kingma DP, 2014, ADV NEUR IN, V27
   Kumar R., 2017, arXiv
   Lele Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P35, DOI 10.1007/978-3-030-58545-7_3
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liu YL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818122
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadoughi N, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6169, DOI 10.1109/ICASSP.2018.8461967
   Sadoughi N, 2017, SPEECH COMMUN, V95, P87, DOI 10.1016/j.specom.2017.07.004
   Sadoughi N, 2016, INTERSPEECH, P52, DOI 10.21437/Interspeech.2016-419
   Sako S., 2000, ICSLP, P25
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Sinha S, 2021, IEEE T IND INFORM, V17, P6676, DOI 10.1109/TII.2020.3043226
   Song Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P919
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Vougioukas K., 2019, CVPR WORKSHOPS, P37
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   [张醒 Zhang Xing], 2013, [火工品, Initiators & Pyrotechnics], P1
   Zhang YN, 2012, NEUROCOMPUTING, V89, P21, DOI 10.1016/j.neucom.2012.01.019
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
NR 61
TC 15
Z9 15
U1 1
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1438
EP 1449
DI 10.1109/TVCG.2021.3117484
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100012
PM 34606458
DA 2024-11-06
ER

PT J
AU Kang, KZ
   Gu, MY
   Xie, CH
   Yang, XD
   Wu, HZ
   Zhou, K
AF Kang, Kaizhang
   Gu, Minyi
   Xie, Cihui
   Yang, Xuanda
   Wu, Hongzhi
   Zhou, Kun
TI Neural Reflectance Capture in the View-Illumination Domain
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multi-view illumination multiplexing; neural acquisition
ID APPEARANCE; REPRESENTATION
AB We propose a novel framework to efficiently capture the unknown reflectance on a non-planar 3D object, by learning to probe the 4D view-lighting domain with a high-performance illumination multiplexing setup. The core of our framework is a deep neural network, specifically tailored to exploit the multi-view coherence for efficiency. It takes as input the photometric measurements of a surface point under learned lighting patterns at different views, automatically aggregates the information and reconstructs the anisotropic reflectance. We also evaluate the impact of different sampling parameters over our network. The effectiveness of our framework is demonstrated on high-quality reconstructions of a variety of physical objects, with an acquisition efficiency outperforming state-of-the-art techniques.
C1 [Kang, Kaizhang; Gu, Minyi; Xie, Cihui; Yang, Xuanda; Wu, Hongzhi; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
   [Yang, Xuanda] Univ Calif San Diego, San Diego, CA 92093 USA.
   [Zhou, Kun] Zhejiang Univ, FaceUnity Joint Lab Intelligent Graph, Hangzhou 310058, Peoples R China.
C3 Zhejiang University; University of California System; University of
   California San Diego; Zhejiang University
RP Wu, HZ (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
EM cocoa_kang@zju.edu.cn; 3140104738@zju.edu.cn; 752936985@qq.com;
   xuandayang@gmail.com; hwu@acm.org; kunzhou@acm.org
RI Kang, Kaizhang/JPX-6645-2023; Zhou, Kun/ITT-3967-2023
FU NSF China [61772457, 62022072, 61890954]
FX This work was supported by NSF China under Grants 61772457, 62022072,and
   61890954.
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978
   Bi S, 2020, PROC CVPR IEEE, P5959, DOI 10.1109/CVPR42600.2020.00600
   Chen Guojun, 2014, ACM T GRAPH TOG, V33, P1
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Den Brok D., 2015, PROC SPIE INT SOC OP, P116
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong Y, 2019, VIS INFORM, V3, P59, DOI 10.1016/j.visinf.2019.07.003
   Dong Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778835
   Fiala M, 2005, PROC CVPR IEEE, P590
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Ghosh A, 2009, COMPUT GRAPH FORUM, V28, P1161, DOI 10.1111/j.1467-8659.2009.01493.x
   Guarnera D, 2016, COMPUT GRAPH FORUM, V35, P625, DOI 10.1111/cgf.12867
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   Holroyd M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778836
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Kang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323046
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kingma D. P., 2017, P INT C LEARNING REP, P1
   Lawrence J, 2006, ACM T GRAPHIC, V25, P735, DOI 10.1145/1141911.1141949
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275055
   Morales JL, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049669
   Ma XH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459679
   Matusik W., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P241
   Meka A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323027
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Nielsen JB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818085
   Ren PR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964940
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Schwartz C., 2011, P 12 INT C VIRT REAL, P25
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Walter B, 2007, P 18 EUR C REND TECH, p18th
   Wang JP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360640
   Weinmann M., 2015, PROC SIGGRAPHASIA CO, P1
   Weyrich T, 2008, FOUND TRENDS COMPUT, V4, P75, DOI 10.1561/0600000022
   Wu HZ, 2015, COMPUT GRAPH FORUM, V34, P289, DOI 10.1111/cgf.12600
   Xu ZX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323007
   Xu ZX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982396
   Zickler Todd., 2005, RENDERING TECHNIQUES, P253, DOI 10.2312/EGWR/EGSR05/253-264
NR 48
TC 3
Z9 3
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1450
EP 1462
DI 10.1109/TVCG.2021.3117370
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100013
PM 34606457
DA 2024-11-06
ER

PT J
AU Dhanoa, V
   Walchshofer, C
   Hinterreiter, A
   Gröller, E
   Streit, M
AF Dhanoa, Vaishali
   Walchshofer, Conny
   Hinterreiter, Andreas
   Groeller, Eduard
   Streit, Marc
TI Fuzzy Spreadsheet: Understanding and Exploring Uncertainties in Tabular
   Calculations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; tabular data; spreadsheet augmentation
ID VISUALIZATION; PLOTS; FLOW
AB Spreadsheet-based tools provide a simple yet effective way of calculating values, which makes them the number-one choice for building and formalizing simple models for budget planning and many other applications. A cell in a spreadsheet holds one specific value and gives a discrete, overprecise view of the underlying model. Therefore, spreadsheets are of limited use when investigating the inherent uncertainties of such models and answering what-if questions. Existing extensions typically require a complex modeling process that cannot easily be embedded in a tabular layout. In Fuzzy Spreadsheet, a cell can hold and display a distribution of values. This integrated uncertainty-handling immediately conveys sensitivity and robustness information. The fuzzification of the cells enables calculations not only with precise values but also with distributions, and probabilities. We conservatively added and carefully crafted visuals to maintain the look and feel of a traditional spreadsheet while facilitating what-if analyses. Given a user-specified reference cell, Fuzzy Spreadsheet automatically extracts and visualizes contextually relevant information, such as impact, uncertainty, and degree of neighborhood, for the selected and related cells. To evaluate its usability and the perceived mental effort required, we conducted a user study. The results show that our approach outperforms traditional spreadsheets in terms of answer correctness, response time, and perceived mental effort in almost all tasks tested.
C1 [Dhanoa, Vaishali] Pro2Future GmbH, A-4040 Linz, Austria.
   [Dhanoa, Vaishali; Walchshofer, Conny; Hinterreiter, Andreas; Streit, Marc] Johannes Kepler Univ Linz, A-4040 Linz, Austria.
   [Groeller, Eduard] TU Wien, A-1040 Vienna, Austria.
   [Groeller, Eduard] VRVis Res Ctr, A-1220 Vienna, Austria.
C3 Johannes Kepler University Linz; Technische Universitat Wien
RP Dhanoa, V (corresponding author), Pro2Future GmbH, A-4040 Linz, Austria.
EM vaishali.dhanoa@pro2future.at; conny.walchshofer@jku.at;
   andreas.hinterreiter@jku.at; groeller@cg.tuwien.ac.at;
   marc.streitj@jku.at
OI Streit, Marc/0000-0001-9186-2092; Reis, Conny/0000-0003-3942-8445;
   Dhanoa, Vaishali/0000-0002-0493-8616
FU FFG [881844]; Austrian COMET Program Competence Centers for Excellent
   Technologies under Austrian Federal Ministry for Climate Action,
   Environment, Energy, Mobility, Innovation and Technolog; Austrian
   Federal Ministry for Digital and Economic Affairs; Province of Upper
   Austria; Province of Styria; State of Upper Austria; Austrian Federal
   Ministry of Education, Science and Research via the LIT - Linz Institute
   of Technology [LIT-2019-7-SEE-117]; Federal State of Upper Austria
   (Human-Interpretable Machine Learning); BMVIT; BMWFW; Styria; SFG;
   Vienna Business Agency
FX This work was supported in part by the FFG under Grant 881844.
   "Pro2Futureis funded within the Austrian COMET Program Competence
   Centers for Excellent Technologies under the auspices of the Austrian
   Federal Ministry for Climate Action, Environment, Energy, Mobility,
   Innovation and Technology, the Austrian Federal Ministry for Digital and
   Economic Affairs and of the Provinces of Upper Austria and Styria. COMET
   is managed by the Austrian Research Promotion Agency FFG." Additional
   support was granted by the State of Upper Austria and the Austrian
   Federal Ministry of Education, Science and Research via the LIT - Linz
   Institute of Technology under Grant LIT-2019-7-SEE-117, and by the
   Federal State of Upper Austria (Human-Interpretable Machine Learning).
   This article was partly written in collaboration with the VRV is
   Competence Center. VRV is is funded by BMVIT, BMWFW, Styria, SFG and
   Vienna Business Agency in the scope of COMET-Competence Centers for
   Excellent Technologies under Grant 854174 which is managed by FFG.
CR Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   [Anonymous], 1999, NAGA ICLARMQUARTERLY
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bilcke J, 2011, MED DECIS MAKING, V31, P675, DOI 10.1177/0272989X11409240
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Borgo R., 2012, P EUR STAT ART REP, P36
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Charts API, GOOGLE CHARTS
   Chen HD, 2015, IEEE T VIS COMPUT GR, V21, P1072, DOI 10.1109/TVCG.2015.2410278
   Chen Y., 2000, PROC EUR SPREADSHEET
   Dhanoa V., 2021, SUPPLEMENTARY MAT FU
   Feng D, 2010, IEEE T VIS COMPUT GR, V16, P980, DOI 10.1109/TVCG.2010.176
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fisher D, 2010, IEEE T VIS COMPUT GR, V16, P1157, DOI 10.1109/TVCG.2010.222
   French N, 2005, J PROP INVEST FINANC, V23, P76, DOI 10.1108/14635780510575102
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Goldstein DG, 2014, JUDGM DECIS MAK, V9, P1
   Google LLC, Google Sheets
   Guesstimate Inc, GUESST
   Hermans F, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P451, DOI 10.1145/1985793.1985855
   Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478
   Holzh_uter C., 2012, PROC SPIE C VIS DATA
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Jannach D, 2014, J SYST SOFTWARE, V94, P129, DOI 10.1016/j.jss.2014.03.058
   Jordan P.W., 1996, Usability Evaluation in Industry
   Knauff M, 2010, COGN PROCESS, V11, P99, DOI 10.1007/s10339-010-0362-z
   Kohlhase A, 2013, LECT NOTES COMPUT SC, V8120, P571
   Lex A, 2013, IEEE T VIS COMPUT GR, V19, P2536, DOI 10.1109/TVCG.2013.154
   LimeSurvey GmbH, PROF ONL UMFR LIM SU
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   Menick J., SAMPLING JAVASCRIPT
   Microsoft Corporation, UND OFF JAVASCRIPT A
   Microsoft Corporation, Microsoft Excel
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   Oracle Corporation, OR CRYST BALL
   PAAS FGWC, 1994, PERCEPT MOTOR SKILL, V79, P419, DOI 10.2466/pms.1994.79.1.419
   Palisade, RISK
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Parush A, 2007, COMPUT IND ENG, V52, P133, DOI 10.1016/j.cie.2006.11.002
   Phillips Carl V, 2003, BMC Med Res Methodol, V3, P9, DOI 10.1186/1471-2288-3-9
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   ProB, US
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Sanyal J, 2009, IEEE T VIS COMPUT GR, V15, P1209, DOI 10.1109/TVCG.2009.114
   Spiegelhalter D, 2011, SCIENCE, V333, P1393, DOI 10.1126/science.1191181
   Streit A, 2008, IEEE T VIS COMPUT GR, V14, P61, DOI 10.1109/TVCG.2007.70426
   TeamViewer Germany GmbH, TEAMVIEWER
   The Apache Software Foundation, AP OPENOFFICE CALC
   Thorndike K., 1992, FUZICALC USERS GUIDE, V1st
   van der Laan D. Jan, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P225
   Vosough Z., 2017, P 10 INT S VISUAL IN, P1, DOI DOI 10.1145/3105971.3105972
   Williams M., JSTAT JAVASCRIPT STA
   Wolfram Alpha LLC, 2021, WOLFRAMALPHA
   Wu YC, 2012, IEEE T VIS COMPUT GR, V18, P2526, DOI 10.1109/TVCG.2012.285
   Zhang X, 2017, NAT COMMUN, V8, P1, DOI [10.1038/ncomms15280, 10.1038/ncomms14542]
   Zoom Video Communications Inc, ZOOM
NR 58
TC 0
Z9 0
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1463
EP 1477
DI 10.1109/TVCG.2021.3119212
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100014
PM 34633930
DA 2024-11-06
ER

PT J
AU Matthews, BJ
   Thomas, BH
   Von Itzstein, GS
   Smith, RT
AF Matthews, Brandon J. J.
   Thomas, Bruce H. H.
   Von Itzstein, G. Stewart
   Smith, Ross T. T.
TI Adaptive Reset Techniques for Haptic Retargeted Interaction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic retargeting; redirection; interaction; perception; user
   interfaces; virtual reality
ID HAND; CONTROLLER
AB This article presents a set of adaptive reset techniques for use with haptic retargeting systems focusing on interaction with hybrid virtual reality interfaces that align with a physical interface. Haptic retargeting between changing physical and virtual targets requires a reset where the physical and virtual hand positions are re-aligned. We present a modified Point technique to guide the user in the direction of their next interaction such that the remaining distance to the target is minimized upon completion of the reset. This, along with techniques drawn from existing work are further modified to consider the angular and translational gain of each redirection and identify the optimal position for the reset to take place. When the angular and translational gain is within an acceptable range, the reset can be entirely omitted. This enables continuous retargeting between targets removing interruptions from a sequence of retargeted interactions. These techniques were evaluated in a user study which showed that adaptive reset techniques can provide a significant decrease in task completion time, travel distance, and the number of user errors.
C1 [Matthews, Brandon J. J.; Thomas, Bruce H. H.; Von Itzstein, G. Stewart; Smith, Ross T. T.] Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA 5001, Australia.
C3 University of South Australia
RP Matthews, BJ (corresponding author), Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Wearable Comp Lab, Adelaide, SA 5001, Australia.
EM brandon.matthews@mymail.unisa.edu.au; bruce.thomas@unisa.edu.au;
   gsa@vonitzstein.com; ross.smith@unisa.edu.au
RI Von Itzstein, Stewart/GMW-8722-2022; Matthews, Brandon/AAX-4910-2021;
   Thomas, Bruce/A-1470-2008; Smith, Ross/L-4790-2016
OI Thomas, Bruce/0000-0002-9148-085X; Von Itzstein, G
   Stewart/0000-0003-1173-4424; Matthews, Brandon J./0000-0002-8673-2434;
   Smith, Ross/0000-0002-9044-9199
FU Australian Government Research Training Program Scholarship, Department
   of Education, Skills and Employment
FX This work was supported by an Australian Government Research Training
   Program Scholarship, Department of Education, Skills and Employment.
CR Abtahi P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173724
   Achibet M, 2017, IEEE SYMP 3D USER, P103, DOI 10.1109/3DUI.2017.7893325
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Brooke J, 1995, USABILITY EVALUATION, P1
   Burdea GC, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P295, DOI 10.1109/CGI.2000.852345
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Burns E, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P295
   Chan LW, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2625
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Elbehery Mostafa, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P245, DOI 10.1145/3428361.3428388
   Gibson JJ, 1933, J EXP PSYCHOL, V16, P1, DOI 10.1037/h0074626
   Hale KS, 2004, IEEE COMPUT GRAPH, V24, P33, DOI 10.1109/MCG.2004.1274059
   Han DT, 2018, IEEE T VIS COMPUT GR, V24, P1467, DOI 10.1109/TVCG.2018.2794659
   Insko B. E, 2001, 0493172866 U N CAR
   Kohli L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P105, DOI 10.1109/3DUI.2012.6184193
   Kohli L., 2005, Proceedings of Graphics Interface, P1
   Kohli L, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P79, DOI 10.1109/3DUI.2013.6550201
   Kohli L, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P129, DOI 10.1109/3DUI.2010.5444703
   Lindeman R.W., 1999, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P64
   Lohse AL, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809587
   Matthews B, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P13, DOI 10.1145/3355355.3361883
   Matthews BJ, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P19, DOI [10.1109/VR.2019.8797974, 10.1109/vr.2019.8797974]
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P759, DOI 10.1145/3126594.3126605
   Nakamura T, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P37, DOI 10.1109/WHC.2013.6548381
   Niechwiej-Szwedo E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193639
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Speicher M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312927
   Suhail M, 2017, IEEE SYMP 3D USER, P245, DOI 10.1109/3DUI.2017.7893363
   Tung JY, 2015, PHYSIOL MEAS, V36, P1025, DOI 10.1088/0967-3334/36/5/1025
   Zenner A, 2021, IEEE T VIS COMPUT GR, V27, P2627, DOI 10.1109/TVCG.2021.3067777
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zhao YW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174118
NR 34
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1478
EP 1490
DI 10.1109/TVCG.2021.3120410
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100015
PM 34653001
DA 2024-11-06
ER

PT J
AU Sicat, R
   Ibrahim, M
   Ageeli, A
   Mannuss, F
   Rautek, P
   Hadwiger, M
AF Sicat, Ronell
   Ibrahim, Mohamed
   Ageeli, Amani
   Mannuss, Florian
   Rautek, Peter
   Hadwiger, Markus
TI Real-Time Visualization of Large-Scale Geological Models With Nonlinear
   Feature-Preserving Levels of Detail
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geological models; structured hexahedral meshes; multiresolution
   representations; interactive visualization
ID WAVELET; SIMULATION; MESHES
AB The rapidly growing size and complexity of 3D geological models has increased the need for level-of-detail techniques and compact encodings to facilitate interactive visualization. For large-scale hexahedral meshes, state-of-the-art approaches often employ wavelet schemes for level of detail as well as for data compression. Here, wavelet transforms serve two purposes: (1) they achieve substantial compression for data reduction; and (2) the multiresolution encoding provides levels of detail for visualization. However, in coarser detail levels, important geometric features, such as geological faults, often get too smoothed out or lost, due to linear translation-invariant filtering. The same is true for attribute features, such as discontinuities in porosity or permeability. We present a novel, integrated approach addressing both purposes above, while preserving critical data features of both model geometry and its attributes. Our first major contribution is that we completely decouple the computation of levels of detail from data compression, and perform nonlinear filtering in a high-dimensional data space jointly representing the geological model geometry with its attributes. Computing detail levels in this space enables us to jointly preserve features in both geometry and attributes. While designed in a general way, our framework specifically employs joint bilateral filters, computed efficiently on a high-dimensional permutohedral grid. For data compression, after the computation of all detail levels, each level is separately encoded with a standard wavelet transform. Our second major contribution is a compact GPU data structure for the encoded mesh and attributes that enables direct real-time GPU visualization without prior decoding.
C1 [Sicat, Ronell; Ibrahim, Mohamed; Ageeli, Amani; Rautek, Peter; Hadwiger, Markus] King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
   [Mannuss, Florian] Saudi Aramco, Dhahran 31311, Saudi Arabia.
C3 King Abdullah University of Science & Technology
RP Sicat, R (corresponding author), King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
EM ronell.sicat@kaust.edu.sa; moeizle@gmail.com; amani.ageeli@kaust.edu.sa;
   florian.mannuss@aramco.com; peter.rautek@gmail.com;
   markus.hadwiger@kaust.edu.sa
OI Ageeli, Amani/0000-0001-6627-503X; Rautek, Peter/0000-0003-4821-7404;
   Ibrahim, Mohamed/0000-0002-3559-3761
FU Saudi Aramco [3879]
FX This work was supported in part by a grant from Saudi Aramco 3879.
CR Aarnes JE, 2005, ADV WATER RESOUR, V28, P257, DOI 10.1016/j.advwatres.2004.10.007
   Abraham F, 2019, VISUAL COMPUT, V35, P837, DOI 10.1007/s00371-019-01674-x
   Adams A, 2010, COMPUT GRAPH FORUM, V29, P753, DOI 10.1111/j.1467-8659.2009.01645.x
   Adams A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531327
   Beyer J., 2008, Volume Graphics, P163
   Brown P., VULKAN SPECIFICATION
   Caraffa L, 2015, IEEE T IMAGE PROCESS, V24, P1199, DOI 10.1109/TIP.2015.2389617
   Ceetron and Equinor, RESINSIGHT
   Chen J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239554, 10.1109/SARNOF.2007.4567317, 10.1145/1276377.1276506]
   Cho Y, 2007, IEEE T IMAGE PROCESS, V16, P2005, DOI 10.1109/TIP.2007.901247
   Cignoni P, 1999, VISUAL COMPUT, V15, P519, DOI 10.1007/s003710050197
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fogal Thomas, 2013, Proc IEEE Symp Large Scale Data Anal Vis, V2013, P43, DOI 10.1109/LDAV.2013.6675157
   Gribb G., FAST EXTRACTION VIEW
   Gross MH, 1997, COMPUT GRAPH-UK, V21, P237, DOI 10.1016/S0097-8493(96)00087-8
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Hadwiger M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366152
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Kim JK, 2004, VISUAL COMPUT, V20, P67, DOI 10.1007/s00371-003-0233-z
   Kim T., 1999, Proceedings. Seventh Pacific Conference on Computer Graphics and Applications (Cat. No.PR00293), P147, DOI 10.1109/PCCGA.1999.803358
   Kubisch Christoph., Introduction to turing mesh shaders
   LaMar E., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P355, DOI 10.1109/VISUAL.1999.809908
   Li X, 2018, COMPUTAT GEOSCI, V22, P1561, DOI 10.1007/s10596-018-9774-0
   Li XY, 2002, IEEE/ACM SIGGRAPH SYMPOSIUM ON VOLUME VISUALIZATION AND GRAPHICS 2002, PROCEEDINGS, P29, DOI 10.1109/SWG.2002.1226507
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Peyrot JL, 2019, COMPUTAT GEOSCI, V23, P723, DOI 10.1007/s10596-019-9816-2
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SAID A, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P279, DOI 10.1109/ISCAS.1993.393712
   Scheirer A. H., US GEOLOGICAL SURVEY
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Shusen Liu, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P73, DOI 10.1109/LDAV.2012.6378978
   Sicat R, 2014, IEEE T VIS COMPUT GR, V20, P2417, DOI 10.1109/TVCG.2014.2346324
   Stocker TF, 2014, CLIMATE CHANGE 2013: THE PHYSICAL SCIENCE BASIS, P1, DOI 10.1017/cbo9781107415324
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Thompson D., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P23, DOI 10.1109/LDAV.2011.6092313
   Tian J, 1998, SPRING INT SER ENG C, V450, P289
   Walker J. S., 2001, The Transform and Data Compression Handbook, P267
   Walker JS, 2000, OPT ENG, V39, P1891, DOI 10.1117/1.602573
   Westermann Rudiger., 1994, Proceedings of the 1994 Symposium on Volume Visualization, VVS '94, P51
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Xia JC, 1997, IEEE T VIS COMPUT GR, V3, P171, DOI 10.1109/2945.597799
   Younesy Hamid., 2006, Proc. EuroVis 2006, P251
   Zhang H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P77, DOI 10.1145/258734.258781
   Zimmermann K., 2000, 2000 IEEE Symposium on Volume Visualization (VV 2000), P7
NR 48
TC 0
Z9 0
U1 4
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1491
EP 1505
DI 10.1109/TVCG.2021.3120372
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100016
PM 34653000
OA Green Published
DA 2024-11-06
ER

PT J
AU Liu, GX
   Iuricich, F
   Fellegara, R
   De Floriani, L
AF Liu, Guoxi
   Iuricich, Federico
   Fellegara, Riccardo
   De Floriani, Leila
TI TopoCluster: A Localized Data Structure for Topology-Based Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Terms-Data visualization; data structures; topological data analysis;
   simplicial meshes; tetrahedral meshes
ID DISCRETE MORSE COMPLEXES; COMPACT REPRESENTATION
AB Unstructured data are collections of points with irregular topology, often represented through simplicial meshes, such as triangle and tetrahedral meshes. Whenever possible such representations are avoided in visualization since they are computationally demanding if compared with regular grids. In this work, we aim at simplifying the encoding and processing of simplicial meshes. The article proposes TopoCluster, a new localized data structure for tetrahedral meshes. TopoCluster provides efficient computation of the connectivity of the mesh elements with a low memory footprint. The key idea of TopoCluster is to subdivide the simplicial mesh into clusters. Then, the connectivity information is computed locally for each cluster and discarded when it is no longer needed. We define two instances of TopoCluster. The first instance prioritizes time efficiency and provides only a modest savings in memory, while the second instance drastically reduces memory consumption up to an order of magnitude with respect to comparable data structures. Thanks to the simple interface provided by TopoCluster, we have been able to integrate both data structures into the existing Topological Toolkit (TTK) framework. As a result, users can run any plugin of TTK using TopoCluster without changing a single line of code.
C1 [Liu, Guoxi; Iuricich, Federico] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
   [Fellegara, Riccardo] German Aerosp Ctr DLR, Inst Software Technol, Braunschweig, Germany.
   [De Floriani, Leila] Univ Maryland, College Pk, MD 20742 USA.
C3 Clemson University; Helmholtz Association; German Aerospace Centre
   (DLR); University System of Maryland; University of Maryland College
   Park
RP Liu, GX (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
EM guoxil@clemson.edu; fiurici@clemson.edu; riccardo.fellegara@dlr.de;
   deflo@umd.edu
RI Liu, Guoxi/J-4618-2014; Fellegara, Riccardo/AEN-0183-2022
OI DE FLORIANI, Leila/0000-0002-1361-2888; Iuricich,
   Federico/0000-0003-1782-9715; Liu, Guoxi/0000-0002-8164-7185; Fellegara,
   Riccardo/0000-0002-8758-2802
FU U.S. National Science Foundation [IIS-1910766]; German Aerospace Center
   (DLR) [DLR-SC-2467209]
FX This work was supported in part by the U.S. National Science Foundation
   under Grant IIS-1910766 and in part by the auspices of the German
   Aerospace Center (DLR) under Grant DLR-SC-2467209.
CR Boissonnat JD, 2014, ALGORITHMICA, V70, P406, DOI 10.1007/s00453-014-9887-3
   Canino D., 2014, P 22 INT MESHING ROU, P465, DOI DOI 10.1007/978-3-319-02335-9_262
   Canino D, 2011, COMPUT GRAPH-UK, V35, P747, DOI 10.1016/j.cag.2011.03.009
   Childs H., 2012, HIGH PERFORMANCE VIS, P395
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   De Floriani L., 2005, S GEOM PROC, P119
   De Floriani L., 2010, P 19 INT MESHING ROU, P403, DOI [10.1007/978-3-642-15414-0_24, DOI 10.1007/978-3-642-15414-0_24]
   De Floriani L., 2004, P 2004 EUROGRAPHICSA, P83, DOI [10.1145/1057432.10574442, DOI 10.1145/1057432.10574442]
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Edelsbrunner H., 1987, EATCS MONOGRAPHS THE, V10
   Fellegara R, 2021, COMPUT GRAPH-UK, V98, P322, DOI 10.1016/j.cag.2021.05.002
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   FREDKIN E, 1960, COMMUN ACM, V3, P490, DOI 10.1145/367390.367400
   Fugacci U, 2019, GRAPH MODELS, V103, DOI 10.1016/j.gmod.2019.101023
   Gurung T, 2011, COMPUT GRAPH FORUM, V30, P355, DOI 10.1111/j.1467-8659.2011.01866.x
   Gurung Topraj, 2009, P SIAM ACM GEOM PHYS, P79, DOI [10.1145/1629255.1629266, DOI 10.1145/1629255.1629266]
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hu YX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201353
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Luffel M, 2014, IEEE T VIS COMPUT GR, V20, P84, DOI 10.1109/TVCG.2013.81
   Mantyla M., 1988, INTRO SOLID MODELING
   Nielson G.M., 1997, SCI VISUALIZATION OV
   PAOLUZZI A, 1993, ACM T GRAPHIC, V12, P56, DOI 10.1145/169728.169719
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Rossignac J, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P278
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Schaling B., 2014, The boost C++libraries
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Toye H, 2017, OCEAN DYNAM, V67, P915, DOI 10.1007/s10236-017-1064-1
   Utkarsh Ayachit, 2015, The ParaView Guide: A Parallel Visualization Application
   Weiss K., 2011, P 19 ACM SIGSPATIAL, P92, DOI DOI 10.1145/2093973.20939871,2,3,4
   Weiss K, 2013, COMPUT GRAPH FORUM, V32, P361, DOI 10.1111/cgf.12123
NR 33
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1506
EP 1517
DI 10.1109/TVCG.2021.3121229
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100017
PM 34673490
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Sridharamurthy, R
   Natarajan, V
AF Sridharamurthy, Raghavendra
   Natarajan, Vijay
TI Comparative Analysis of Merge Trees Using Local Tree Edit Distance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Merge tree; scalar field; local distance measure; persistence; edit
   distance; symmetry detection; feature tracking
ID SCALAR FIELDS; REEB GRAPHS; SYMMETRY; PERSISTENCE; STABILITY
AB Comparative analysis of scalar fields is an important problem with various applications including feature-directed visualization and feature tracking in time-varying data. Comparing topological structures that are abstract and succinct representations of the scalar fields lead to faster and meaningful comparison. While there are many distance or similarity measures to compare topological structures in a global context, there are no known measures for comparing topological structures locally. While the global measures have many applications, they do not directly lend themselves to fine-grained analysis across multiple scales. We define a local variant of the tree edit distance and apply it towards local comparative analysis of merge trees with support for finer analysis. We also present experimental results on time-varying scalar fields, 3D cryo-electron microscopy data, and other synthetic data sets to show the utility of this approach in applications like symmetry detection and feature tracking.
C1 [Sridharamurthy, Raghavendra; Natarajan, Vijay] Indian Inst Sci, Dept Comp Sci & Automation, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Sridharamurthy, R (corresponding author), Indian Inst Sci, Dept Comp Sci & Automation, Bangalore 560012, Karnataka, India.
EM raghavendrag@iisc.ac.in; vijayn@iisc.ac.in
RI Sridharamurthy, Raghavendra/JNS-6719-2023
OI Sridharamurthy, Raghavendra/0000-0001-8463-0488; Natarajan,
   Vijay/0000-0002-7956-1470
FU Department of Science and Technology, India [DST/SJF/ETA-02/2015-16];
   MHRD, Government of India; Mindtree Chair Research Grant
FX This work was supported in part by a Swarnajayanti Fellowship from the
   Department of Science and Technology, India under Grant
   DST/SJF/ETA-02/2015-16, in part by, a scholarship from MHRD, Government
   of India and in part by a Mindtree Chair Research Grant.
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Bauer U, 2014, COMPUTATIONAL GEOMET, P464
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Bille P, 2005, THEOR COMPUT SCI, V337, P217, DOI 10.1016/j.tcs.2004.12.030
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Chiu Wah, 2002, EMDB
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Dey T. K., 2015, P 31 INT S COMP GEOM, P491
   Di Fabio B, 2012, ELECTRON NOTES THEOR, V283, P71, DOI 10.1016/j.entcs.2012.05.006
   Di Fabio B, 2016, DISCRETE COMPUT GEOM, V55, P423, DOI 10.1007/s00454-016-9758-6
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Gueunet C, 2017, SYMP LARG DATA ANAL, P6, DOI 10.1109/LDAV.2017.8231846
   Guibas L, 2013, DISCRETE COMPUT GEOM, V49, P22, DOI 10.1007/s00454-012-9465-x
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Narayanan V, 2015, IEEE PAC VIS SYMP, P263, DOI 10.1109/PACIFICVIS.2015.7156386
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Saikia H., 2015, TOPOLOGICAL METHODS, P121, DOI [10.1007/978-3-319-44684-4_7, DOI 10.1007/978-3-319-44684-4_7]
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Soler M, 2018, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis.2018.00015
   Sridharamurthy R., 2017, PROC IEEE SCIVIS POS
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Tao J, 2019, IEEE T VIS COMPUT GR, V25, P1236, DOI 10.1109/TVCG.2018.2864808
   Thomas DM, 2014, IEEE T VIS COMPUT GR, V20, P2427, DOI 10.1109/TVCG.2014.2346332
   Thomas DM, 2013, IEEE T VIS COMPUT GR, V19, P2663, DOI 10.1109/TVCG.2013.148
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   ZHANG KZ, 1992, INFORM PROCESS LETT, V42, P133, DOI 10.1016/0020-0190(92)90136-J
   Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866
NR 32
TC 4
Z9 4
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1518
EP 1530
DI 10.1109/TVCG.2021.3122176
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100018
PM 34699362
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Nguyen, DB
   Wu, PR
   Monico, RO
   Chen, GN
AF Nguyen, Duong B.
   Wu, Panruo
   Monico, Rodolfo Ostilla
   Chen, Guoning
TI Dynamic Mode Decomposition for Large-Scale Coherent Structure Extraction
   in Shear Flows
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Flow visualization; shear flows; dynamic mode decomposition
ID PROPER ORTHOGONAL DECOMPOSITION; OF-THE-ART; VISUALIZATION
AB Large-scale structures have been observed in many shear flows which are the fluid generated between two surfaces moving with different velocity. A better understanding of the physics of the structures (especially large-scale structures) in shear flows will help explain a diverse range of physical phenomena and improve our capability of modeling more complex turbulence flows. Many efforts have been made in order to capture such structures; however, conventional methods have their limitations, such as arbitrariness in parameter choice or specificity to certain setups. To address this challenge, we propose to use Multi-Resolution Dynamic Mode Decomposition (mrDMD), for large-scale structure extraction in shear flows. In particular, we show that the slow motion DMD modes are able to reveal large-scale structures in shear flows that also have slow dynamics. In most cases, we find that the slowest DMD mode and its reconstructed flow can sufficiently capture the large-scale dynamics in the shear flows, which leads to a parameter-free strategy for large-scale structure extraction. Effective visualization of the large-scale structures can then be produced with the aid of the slowest DMD mode. To speed up the computation of mrDMD, we provide a fast GPU-based implementation. We also apply our method to some non-shear flows that need not behave quasi-linearly to demonstrate the limitation of our strategy of using the slowest DMD mode. For non-shear flows, we show that multiple modes from different levels of mrDMD may be needed to sufficiently characterize the flow behavior.
C1 [Nguyen, Duong B.; Wu, Panruo; Monico, Rodolfo Ostilla; Chen, Guoning] Univ Houston, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Nguyen, DB (corresponding author), Univ Houston, Houston, TX 77004 USA.
EM duongnguyenbinh@gmail.com; pwu7@uh.edu; rostilla@central.uh.edu;
   chengu@cs.uh.edu
OI Wu, Panruo/0000-0003-1859-3580; Chen, Guoning/0000-0003-0581-6415
FU NSF [IIS 1553329, OAC 2102761]
FX This work was in part supported by NSF under Grants IIS 1553329 and OAC
   2102761.
CR [Anonymous], 1985, HYDRODYNAMIC INSTABI
   [Anonymous], 2019, CUDA Toolkit Documentation
   Avsarkisov V, 2014, J FLUID MECH, V751, DOI 10.1017/jfm.2014.323
   Berenjkoub M, 2019, IEEE T VIS COMPUT GR, V25, P1246, DOI 10.1109/TVCG.2018.2864817
   Bhatia H, 2013, IEEE T VIS COMPUT GR, V19, P1386, DOI 10.1109/TVCG.2012.316
   Bodenschatz E, 2000, ANNU REV FLUID MECH, V32, P709, DOI 10.1146/annurev.fluid.32.1.709
   Boyce W.E., 2017, Elementary Differential Equations and Boundary Value Problems, V11th
   Carnecky R., 2014, PROC EUROGRAPHICS C, P128
   CHONG MS, 1990, PHYS FLUIDS A-FLUID, V2, P765, DOI 10.1063/1.857730
   Edmunds M, 2012, COMPUT GRAPH-UK, V36, P974, DOI 10.1016/j.cag.2012.07.006
   Farooq S, 2020, J FLUID MECH, V884, DOI 10.1017/jfm.2019.840
   Garth C, 2008, COMPUT GRAPH FORUM, V27, P1007, DOI 10.1111/j.1467-8659.2008.01236.x
   Garth C, 2007, IEEE T VIS COMPUT GR, V13, P1464, DOI 10.1109/TVCG.2007.70551
   Gavish M, 2014, IEEE T INFORM THEORY, V60, P5040, DOI 10.1109/TIT.2014.2323359
   Gilka G., 2010, PROC 5 EUR C COMPUT, P1557
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Guo HQ, 2016, IEEE T VIS COMPUT GR, V22, P1672, DOI 10.1109/TVCG.2016.2534560
   Haller G, 2005, J FLUID MECH, V525, P1, DOI 10.1017/S0022112004002526
   Haller G, 2001, PHYS FLUIDS, V13, P3365, DOI 10.1063/1.1403336
   Haller G, 2000, PHYSICA D, V147, P352, DOI 10.1016/S0167-2789(00)00142-1
   Hunt J.C.R., 1988, 1988 SUMM PROGR CTR, P193
   Jovanovic MR, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4863670
   Kerschen G, 2005, NONLINEAR DYNAM, V41, P147, DOI 10.1007/s11071-005-2803-2
   Krake T, 2021, VIS INFORM, V5, P15, DOI 10.1016/j.visinf.2021.06.003
   Kutz JN, 2016, OTHER TITL APPL MATH, V149
   Kutz JN, 2016, SIAM J APPL DYN SYST, V15, P713, DOI 10.1137/15M1023543
   Laramee RS, 2007, MATH VIS, P1, DOI 10.1007/978-3-540-70823-0_1
   Marston JB, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.214501
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Ostilla-Mónico R, 2016, J FLUID MECH, V788, P95, DOI 10.1017/jfm.2015.675
   Ostilla-Mónico R, 2015, PHYS FLUIDS, V27, DOI 10.1063/1.4913231
   Pascarella G, 2019, FLUIDS, V4, DOI 10.3390/fluids4040202
   Peikert R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P263, DOI 10.1109/VISUAL.1999.809896
   Pendergrass S. D., 2016, Streaming GPU singular value and dynamic mode decompositions, DOI [10.48550/ARXIV.1612.07875, DOI 10.48550/ARXIV.1612.07875]
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P771, DOI 10.1111/j.1467-8659.2011.01926.x
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P1789, DOI 10.1111/j.1467-8659.2011.01901.x
   Robertson ED, 2018, INT J COMPUT FLUID D, V32, P261, DOI 10.1080/10618562.2018.1508657
   Sacco F, 2019, J FLUID MECH, V870, P970, DOI 10.1017/jfm.2019.317
   Sadarjoen I. A., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P53
   Sadarjoen IA, 2000, COMPUT GRAPH-UK, V24, P333, DOI 10.1016/S0097-8493(00)00029-7
   SADDOUGHI SG, 1994, J FLUID MECH, V268, P333, DOI 10.1017/S0022112094001370
   Sadlo F, 2007, IEEE T VIS COMPUT GR, V13, P1456, DOI 10.1109/TVCG.2007.70554
   Salzbrunn T., 2008, Proceedings of Simulation and Visualization Conference, P75
   Sayadi T, 2016, THEOR COMP FLUID DYN, V30, P415, DOI 10.1007/s00162-016-0385-x
   Schmid PJ, 2010, J FLUID MECH, V656, P5, DOI 10.1017/S0022112010001217
   Shadden SC, 2012, TRANSPORT AND MIXING IN LAMINAR FLOWS: FROM MICROFLUIDICS TO OCEANIC CURRENTS, P59
   Sillero JA, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4899259
   Strogatz S., 2014, Studies in Nonlinearity
   Taylor GI, 1923, PHILOS T R SOC LOND, V223, P289, DOI 10.1098/rsta.1923.0008
   Tobias SM, 2017, J FLUID MECH, V810, P412, DOI 10.1017/jfm.2016.727
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Tu J.H., 2013, Dynamic Mode Decomposition: Theory and Applications
   Wang Y, 2014, J VISUAL-JAPAN, V17, P363, DOI 10.1007/s12650-014-0214-5
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   Wiebel A, 2011, MATH VIS, P193
   Wu Z, 2019, NUCL ENG DES, V344, P54, DOI 10.1016/j.nucengdes.2019.01.015
   Zhang QS, 2014, J FLUID STRUCT, V49, P53, DOI 10.1016/j.jfluidstructs.2014.04.002
NR 57
TC 5
Z9 6
U1 2
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1531
EP 1544
DI 10.1109/TVCG.2021.3124729
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100019
PM 34727033
DA 2024-11-06
ER

PT J
AU Liu, T
   Yang, ZH
   Hu, SJ
   Zhang, ZY
   Xiao, CX
   Guo, XH
   Yang, L
AF Liu, Tong
   Yang, Zhenhua
   Hu, Shaojun
   Zhang, Zhiyi
   Xiao, Chunxia
   Guo, Xiaohu
   Yang, Long
TI Neighbor Reweighted Local Centroid for Geometric Feature Identification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature identification; local centroid; convexity and concavity; surface
   boundary points; assimilation and dissimilation
ID OBJECT RECOGNITION; POINT; EXTRACTION; PROJECTION; IMAGES
AB Identifying geometric features from sampled surfaces is a significant and fundamental task. The existing curvature-based methods that can identify ridge and valley features are generally sensitive to noise. Without requiring high-order differential operators, most statistics-based methods sacrifice certain extents of the feature descriptive powers in exchange for robustness. However, neither of these types of methods can treat the surface boundary features simultaneously. In this paper, we propose a novel neighbor reweighted local centroid (NRLC) computational algorithm to identify geometric features for point cloud models. It constructs a feature descriptor for the considered point via decomposing each of its neighboring vectors into two orthogonal directions. A neighboring vector starts from the considered point and ends with the corresponding neighbor. The decomposed neighboring vectors are then accumulated with different weights to generate the NRLC. With the defined NRLC, we design a probability set for each candidate feature point so that the convex, concave and surface boundary points can be recognized concurrently. In addition, we introduce a pair of feature operators, including assimilation and dissimilation, to further strengthen the identified geometric features. Finally, we test NRLC on a large body of point cloud models derived from different data sources. Several groups of the comparison experiments are conducted, and the results verify the validity and efficiency of our NRLC method.
C1 [Liu, Tong; Yang, Zhenhua; Hu, Shaojun; Zhang, Zhiyi; Yang, Long] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Xiao, Chunxia] Wuhan Univ, Comp Sch, Wuhan 430072, Hubei, Peoples R China.
   [Guo, Xiaohu] Univ Texas Dallas, Dept Comp Sci, Richardson, TX 75080 USA.
C3 Northwest A&F University - China; Wuhan University; University of Texas
   System; University of Texas Dallas
RP Yang, L (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM tliu@nwafu.edu.cn; zhyang1999@nwafu.edu.cn; hsj@nwafu.edu.cn;
   zhangzhiyi@nwafu.edu.cn; cxxiao@whu.edu.cn; xguo@utdallas.edu;
   yl@nwafu.edu.cn
RI Zhang, Xiangyang/ABC-7380-2022
OI HU, Shaojun/0000-0002-4686-7633
FU NSFC [61702422]; Chinese Universities Scientific Fund [2452018146]
FX This work was supported by the NSFC under Grant 61702422 and the Chinese
   Universities Scientific Fund under Grant 2452018146.
CR Ahmed SM, 2018, IEEE INT C INT ROBOT, P7350, DOI 10.1109/IROS.2018.8593910
   Bazazian D, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P358
   Bendels GH, 2006, JOURNAL WSCG, V14, P89
   Boulch A, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12983
   Chalmoviansky P, 2003, LECT NOTES COMPUT SC, V2768, P196
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Cohen-Or Daniel, 2015, A Sampler of Useful Computational Tools for Applied Geometry, Computer Graphics, and Image Processing, V1st
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   DeCarlo D, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P63
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kalogerakis E, 2009, COMPUT AIDED DESIGN, V41, P282, DOI 10.1016/j.cad.2008.12.004
   Kalogerakis E, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477937
   Kolomenkin M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409110
   Lai YK, 2007, IEEE T VIS COMPUT GR, V13, P34, DOI 10.1109/TVCG.2007.19
   Lengagne R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P847, DOI 10.1109/ICIP.1996.561037
   Li MY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081782
   Lin YB, 2015, ISPRS J PHOTOGRAMM, V102, P172, DOI 10.1016/j.isprsjprs.2014.12.027
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Lu X., 2019, arXiv
   Mérigot Q, 2011, IEEE T VIS COMPUT GR, V17, P743, DOI 10.1109/TVCG.2010.261
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   MONGA O, 1995, COMPUT VIS IMAGE UND, V61, P171, DOI 10.1006/cviu.1995.1014
   Nguyen WLK, 2018, PR INT C PROGR ADD M, P595, DOI 10.25341/D45C7S
   Ni H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8090710
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Ohtake Y, 2004, ACM T GRAPHIC, V23, P609, DOI 10.1145/1015706.1015768
   Ohtake Y., 2005, ACM SIGGRAPH 2005 CO, P173, DOI [10.1145/1198555.1198649, DOI 10.1145/1198555.1198649]
   Pauly M, 2003, COMPUT GRAPH FORUM, V22, P281, DOI 10.1111/1467-8659.00675
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Pottmann H, 2009, COMPUT AIDED GEOM D, V26, P37, DOI 10.1016/j.cagd.2008.01.002
   Rusinkiewicz S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P486, DOI 10.1109/TDPVT.2004.1335277
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Singh K., 2007, P S GEOM PROC BARC S, VVolume 13, P110
   Stein SC, 2014, PROC CVPR IEEE, P304, DOI 10.1109/CVPR.2014.46
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Tyler C. W, 2011, COMPUTER VISION SURF
   Wang RM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2835488
   Xia SB, 2017, IEEE GEOSCI REMOTE S, V14, P1288, DOI 10.1109/LGRS.2017.2707467
   Yang L, 2018, IEEE T VIS COMPUT GR, V24, P1190, DOI 10.1109/TVCG.2017.2657766
   Yang L, 2017, VISUAL COMPUT, V33, P385, DOI 10.1007/s00371-016-1208-1
   Yang Y.-L., 2006, EUROGRAPHICS S GEOME, P223
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
NR 53
TC 3
Z9 6
U1 3
U2 47
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1545
EP 1558
DI 10.1109/TVCG.2021.3124911
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100020
PM 34735345
DA 2024-11-06
ER

PT J
AU Espadoto, M
   Appleby, G
   Suh, A
   Cashman, D
   Li, MW
   Scheidegger, C
   Anderson, EW
   Chang, RM
   Telea, AC
AF Espadoto, Mateus
   Appleby, Gabriel
   Suh, Ashley
   Cashman, Dylan
   Li, Mingwei
   Scheidegger, Carlos
   Anderson, Erik W. W.
   Chang, Remco
   Telea, Alexandru C. C.
TI UnProjection: Leveraging Inverse-Projections for Visual Analytics of
   High-Dimensional Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multidimensional data; multidimensional projection; inverse-projection;
   back-projection
ID DATA VISUALIZATION; REDUCTION; SYSTEM
AB Projection techniques are often used to visualize high-dimensional data, allowing users to better understand the overall structure of multi-dimensional spaces on a 2D screen. Although many such methods exist, comparably little work has been done on generalizable methods of inverse-projection - the process of mapping the projected points, or more generally, the projection space back to the original high-dimensional space. In this article we present NNInv, a deep learning technique with the ability to approximate the inverse of any projection or mapping. NNInv learns to reconstruct high-dimensional data from any arbitrary point on a 2D projection space, giving users the ability to interact with the learned high-dimensional representation in a visual analytics system. We provide an analysis of the parameter space of NNInv, and offer guidance in selecting these parameters. We extend validation of the effectiveness of NNInv through a series of quantitative and qualitative analyses. We then demonstrate the method's utility by applying it to three visualization tasks: interactive instance interpolation, classifier agreement, and gradient visualization.
C1 [Espadoto, Mateus] Univ Sao Paulo, BR-05508070 Sao Paulo, Brazil.
   [Appleby, Gabriel; Suh, Ashley; Chang, Remco] Tufts Univ, Medford, MA 02155 USA.
   [Cashman, Dylan; Anderson, Erik W. W.] Novartis, CH-4056 Basel, Switzerland.
   [Li, Mingwei; Scheidegger, Carlos] Univ Arizona, Tucson, AZ 85721 USA.
   [Telea, Alexandru C. C.] Univ Utrecht, NL-3584 CS Utrecht, Netherlands.
C3 Universidade de Sao Paulo; Tufts University; University of Arizona;
   Utrecht University
RP Appleby, G (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM mespadot@ime.usp.br; Gabriel.Appleby@tufts.edu; ashleysuh1@gmail.com;
   dylancash88@yahoo.com; mwli@email.arizona.edu;
   cscheid@email.arizona.edu; erik.anderson@novartis.com;
   remco@cs.tufts.edu; a.c.telea@rug.nl
RI Cashman, Dylan/ABC-6776-2021
OI Telea, Alexandru Cristian/0000-0003-0750-0502; Cashman,
   Dylan/0000-0003-4853-5701; Anderson, Erik/0000-0002-0334-8497; Espadoto,
   Mateus/0000-0002-1922-4309; Suh, Ashley/0000-0001-6513-8447; Chang,
   Remco/0000-0002-6484-6430
FU National Science Foundation [IIS1452977, OAC-1940175, OAC-1939945,
   DGE-1855886]; DARPA [FA8750-17-2-0107]; DOD [HQ0860-20-C-7137]
FX This work was supported by National Science Foundation under Grants
   IIS1452977, OAC-1940175, OAC-1939945, DGE-1855886, in part by DARPA
   under Grant FA8750-17-2-0107, and DOD under Grant HQ0860-20-C-7137.
CR Abadi M., 2015, Tensorflow: Large-scale machine learning on heterogeneous distributed systems, DOI DOI 10.48550/ARXIV.1603.04467
   Amorim E, 2015, COMPUT GRAPH-UK, V48, P35, DOI 10.1016/j.cag.2015.02.009
   Amorim EPD, 2012, IEEE CONF VIS ANAL, P53, DOI 10.1109/VAST.2012.6400489
   ANDREWS DF, 1972, BIOMETRICS, V28, P125, DOI 10.2307/2528964
   Angelini M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P226, DOI [10.1109/visual.2019.8933775, 10.1109/VISUAL.2019.8933775]
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Balasubramanian M, 2002, SCIENCE, V295
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Bühlmann P, 2011, SPRINGER SER STAT, P1, DOI 10.1007/978-3-642-20192-9
   Bunte K, 2012, NEURAL COMPUT, V24, P771, DOI 10.1162/NECO_a_00250
   Cavallo M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174209
   Chatzimparmpas A, 2020, IEEE T VIS COMPUT GR, V26, P2696, DOI 10.1109/TVCG.2020.2986996
   Chollet F., 2015, KERAS
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Dowling M, 2019, IEEE T VIS COMPUT GR, V25, P172, DOI 10.1109/TVCG.2018.2865047
   Elsken T, 2019, J MACH LEARN RES, V20
   Espadoto M., 2019, PROC EUR VIS WORKSHO
   Espadoto M, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P29, DOI 10.5220/0008877200290041
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   G. LLC, 2019, KER TUN
   Garcia R, 2018, COMPUT GRAPH-UK, V77, P30, DOI 10.1016/j.cag.2018.09.018
   Geng JS, 2013, ADV OPT PHOTONICS, V5, P456, DOI 10.1364/AOP.5.000456
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gorban A., 2008, Principal Manifolds for Data Visualization and Dimension Reduction, V58, DOI 10.1007/978-3-540-73750-6
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Hamel L, 2006, PROCEEDINGS OF THE 2006 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P148
   Higgins I, 2016, BETA VAE LEARNING BA
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hoffman P, 2002, Inf Vis Data Min Knowl Discov, V104, P47
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kim H, 2019, Arxiv, DOI arXiv:1802.05983
   Kingma DP, 2014, ADV NEUR IN, V27
   Kriegeskorte N, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00245
   Kusner MJ, 2017, PR MACH LEARN RES, V70
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lespinats S, 2011, COMPUT GRAPH FORUM, V30, P113, DOI 10.1111/j.1467-8659.2010.01835.x
   Li WT, 2017, J BIOINF COMPUT BIOL, V15, DOI 10.1142/S0219720017500172
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Mamani GMH, 2013, COMPUT GRAPH FORUM, V32, P291, DOI 10.1111/cgf.12116
   Martins R., 2015, P CGVC, P121
   Martins RM, 2014, COMPUT GRAPH-UK, V41, P26, DOI 10.1016/j.cag.2014.01.006
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Migut MA, 2015, DATA MIN KNOWL DISC, V29, P273, DOI 10.1007/s10618-013-0342-x
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pagliosa LD, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020016
   Paszke A, 2019, ADV NEUR IN, V32
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Paulovich FV, 2012, COMPUT SCI ENG, V14, P74, DOI 10.1109/MCSE.2012.85
   Paulovich FV, 2006, INFORMATION VISUALIZATION-BOOK, P245
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Rodrigues FCM, 2019, INFORMATION, V10, DOI 10.3390/info10090280
   Rodrigues FCM, 2018, SIBGRAPI, P353, DOI 10.1109/SIBGRAPI.2018.00052
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Schulz A, 2015, NEURAL PROCESS LETT, V42, P27, DOI 10.1007/s11063-014-9394-1
   ScikitLearn.org, CLASS COMP
   Seifert C., 2010, P EUROVAST 2010 INT, P13, DOI [10.2312/PE/EuroVAST/EuroVAST10/013-018, DOI 10.2312/PE/EUROVAST/EUROVAST10/013-018]
   Sorzano COS, 2014, Arxiv, DOI [arXiv:1403.2877, 10.48550/arXiv.1403.2877]
   Spinner T., 2018, PROC WORKSHOP VIS EX
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Chen RTQ, 2019, Arxiv, DOI arXiv:1802.04942
   Van Der Maaten L., 2009, Technical report, V10, P1, DOI 10.1080/13506280444000102
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2010, J MACH LEARN RES, V11, P451
   Vernier EF, 2020, COMPUT GRAPH FORUM, V39, P241, DOI 10.1111/cgf.13977
   Xiao H, 2017, Arxiv, DOI arXiv:1708.07747
   Yin HJ, 2007, INT J AUTOM COMPUT, V4, P294, DOI 10.1007/s11633-007-0294-y
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
NR 75
TC 8
Z9 8
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1559
EP 1572
DI 10.1109/TVCG.2021.3125576
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100021
PM 34748493
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Pont, M
   Vidal, J
   Tierny, J
AF Pont, Mathieu
   Vidal, Jules
   Tierny, Julien
TI Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topological data analysis; ensemble data; merge trees; persistence
   diagrams
ID NONPARAMETRIC MODELS; MORSE COMPLEXES; VISUAL ANALYSIS; CRITICAL-POINTS;
   REEB GRAPHS; UNCERTAINTY; VISUALIZATION; VARIABILITY; ENSEMBLES;
   INTERPOLATION
AB This article presents a computational framework for the Principal Geodesic Analysis of merge trees (MT-PGA), a novel adaptation of the celebrated Principal Component Analysis (PCA) framework (K. Pearson 1901) to the Wasserstein metric space of merge trees (Pont et al. 2022). We formulate MT-PGA computation as a constrained optimization problem, aiming at adjusting a basis of orthogonal geodesic axes, while minimizing a fitting energy. We introduce an efficient, iterative algorithm which exploits shared-memory parallelism, as well as an analytic expression of the fitting energy gradient, to ensure fast iterations. Our approach also trivially extends to extremum persistence diagrams. Extensive experiments on public ensembles demonstrate the efficiency of our approach - with MT-PGA computations in the orders of minutes for the largest examples. We show the utility of our contributions by extending to merge trees two typical PCA applications. First, we apply MT-PGA to data reduction and reliably compress merge trees by concisely representing them by their first coordinates in the MT-PGA basis. Second, we present a dimensionality reduction framework exploiting the first two directions of the MT-PGA basis to generate two-dimensional layouts of the ensemble. We augment these layouts with persistence correlation views, enabling global and local visual inspections of the feature variability in the ensemble. In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.
C1 [Pont, Mathieu; Vidal, Jules; Tierny, Julien] CNRS, Paris, France.
   [Pont, Mathieu; Vidal, Jules; Tierny, Julien] Sorbonne Univ, Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne Universite
RP Pont, M (corresponding author), CNRS, Paris, France.; Pont, M (corresponding author), Sorbonne Univ, Paris, France.
EM mathieu.pont@lip6.fr; jules.vidal@lip6.fr;
   julien.tierny@sorbonne-universite.fr
OI Vidal, Jules/0000-0002-1154-4391; Pont, Mathieu/0000-0002-0037-0314
FU European Commission [863464]; European Research Council (ERC) [863464]
   Funding Source: European Research Council (ERC)
FX This work was supported by European Commission under Grant
   ERC-2019-COG"TORI" (ref. 863464, https://erc-tori.github.io/).
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Adams H, 2017, J MACH LEARN RES, V18
   Anderson KL, 2018, LECT NOTES COMPUT SC, V11083, P67, DOI 10.1007/978-3-030-00755-3_8
   Anirudh R, 2016, IEEE COMPUT SOC CONF, P1023, DOI 10.1109/CVPRW.2016.132
   [Anonymous], 2009, HDB RES MACHINE LEAR
   Athawale T, 2019, IEEE T VIS COMPUT GR, V25, P1163, DOI 10.1109/TVCG.2018.2864505
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Athawale TM, 2022, IEEE T VIS COMPUT GR, V28, P1955, DOI 10.1109/TVCG.2020.3022359
   Ayachit U., 2015, P 1 WORKSH IN SIT IN, P25, DOI [10.1145/2828612. 2828624, DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   Banchoff T. F., 1967, The American Mathematical Monthly, V1, P245, DOI DOI 10.1080/00029890.1970.119925231
   Bauer U, 2014, COMPUTATIONAL GEOMET, P464
   Bauer U., 2014, P 16 WORKSH ALG ENG, P31, DOI [10.1137/1.9781611973198.4, DOI 10.1137/1.9781611973198.4]
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   BERTSEKAS DP, 1981, MATH PROGRAM, V21, P152, DOI 10.1007/BF01584237
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bhatia H, 2012, IEEE T VIS COMPUT GR, V18, P1383, DOI 10.1109/TVCG.2011.265
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bin Masood T., 2019, P TOP METH DAT AN VI, VVI, P327
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Bollen B, 2022, Arxiv, DOI arXiv:2110.05631
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P139, DOI 10.1109/VISUAL.2003.1250365
   Brown N, 2021, PROCEEDINGS OF URGENTHPC 2021: THE THIRD INTERNATIONAL WORKSHOP ON HPC FOR URGENT DECISION MAKING, P36, DOI 10.1109/UrgentHPC54802.2021.00010
   Bubenik P, 2015, J MACH LEARN RES, V16, P77
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Cazelles E, 2018, SIAM J SCI COMPUT, V40, pB429, DOI 10.1137/17M1143459
   Cheney W., 2009, Linear algebra: Theory and applications
   Cuturi M., 2013, Advances in Neural Information Processing Systems, V2, P2292
   Cuturi M, 2014, PR MACH LEARN RES, V32, P685
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Diggle P., 2002, Analysis of longitudinal data
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H, 2009, Computational Topology An Introduction
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Favelier G., 2016, IEEE SCIVIS CONTEST
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Forman R., 1998, Advances in mathematics
   Gasparovic E., PREPRINT
   Gorban A., 2008, Principal Manifolds for Data Visualization and Dimension Reduction, V58, DOI 10.1007/978-3-540-73750-6
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Joint Committee for Guides in Metrology, 2008, UNC MEAS 3
   KANTOROVITCH L, 1958, MANAGE SCI, V5, P1, DOI 10.1287/mnsc.5.1.1
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Kerber Michael, 2017, Journal of Experimental Algorithmics (JEA), V22, P1, DOI 10.1145/3064175
   Kruskal J. B., 1978, Multidimensional scaling, V11
   Lacombe T, 2018, ADV NEUR IN, V31
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Li MZ, 2021, Arxiv, DOI arXiv:2101.03196
   Liebmann T, 2016, COMPUT GRAPH FORUM, V35, P361, DOI 10.1111/cgf.12912
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Maadasamy S, 2012, INT C HIGH PERFORM
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   Maljovec D, 2016, IEEE PAC VIS SYMP, P64, DOI 10.1109/PACIFICVIS.2016.7465252
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Monge G., 1781, MEMOIRE THEORIE DEBL, P666
   Morozov D., 2014, PROC TOPOLOGICAL MET, VIII, P22
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Organizers, 2004, The IEEE SciVis Contest
   Otto M, 2011, IEEE PAC VIS SYMP, P67, DOI 10.1109/PACIFICVIS.2011.5742374
   Otto M, 2010, COMPUT GRAPH FORUM, V29, P347, DOI 10.1111/j.1467-8659.2009.01604.x
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Parsa S., 2012, P 28 ANN S COMP GEOM, P269
   Pascucci V., 2004, PROC C VIS IMAG IMAG, P19
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Petz C, 2012, COMPUT GRAPH FORUM, V31, P1045, DOI 10.1111/j.1467-8659.2012.03097.x
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Pfaffelmoser T, 2012, COMPUT GRAPH FORUM, V31, P1025, DOI 10.1111/j.1467-8659.2012.03095.x
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pöthkow K, 2013, INT J UNCERTAIN QUAN, V3, P101, DOI 10.1615/Int.J.UncertaintyQuantification.2012003958
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Pont M., 2021, Wasserstein Distances, Geodesics and Barycenters of Merge Trees - Ensemble Benchmark
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Potter K, 2013, IEEE COMPUT GRAPH, V33, P75, DOI 10.1109/MCG.2013.14
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Robins V, 2016, PHYSICA D, V334, P99, DOI 10.1016/j.physd.2016.03.007
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schlegel S, 2012, IEEE T VIS COMPUT GR, V18, P2305, DOI 10.1109/TVCG.2012.249
   Seguy V., 2015, Advances in Neural Information Processing Systems, V28, P3312
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   SINKHORN R, 1974, P AM MATH SOC, V45, P195, DOI 10.2307/2040061
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P384, DOI 10.1111/j.1365-2966.2011.18395.x
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Szymczak A, 2013, IEEE T VIS COMPUT GR, V19, P799, DOI 10.1109/TVCG.2012.147
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Turner K, 2014, DISCRETE COMPUT GEOM, V52, P44, DOI 10.1007/s00454-014-9604-7
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Woodruff DP, 2014, FOUND TRENDS THEOR C, V10, P1, DOI 10.1561/0400000060
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866
NR 123
TC 4
Z9 4
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1573
EP 1589
DI 10.1109/TVCG.2022.3215001
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100022
PM 36251893
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Macedo, MCF
   Apolinario, AL
AF Macedo, Marcio C. F.
   Apolinario, Antonio L.
TI Occlusion Handling in Augmented Reality: Past, Present and Future
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computer graphics; augmented reality; mutual occlusion; X-ray vision;
   computational displays; depth maps
ID TIME-OF-FLIGHT; RESOLVING OCCLUSION; VISUALIZATION TECHNIQUES; MUTUAL
   OCCLUSION; GHOSTED VIEWS; DISPLAY; TAXONOMY; OBJECTS
AB One of the main goals of many augmented reality applications is to provide a seamless integration of a real scene with additional virtual data. To fully achieve that goal, such applications must typically provide high-quality real-world tracking, support real-time performance and handle the mutual occlusion problem, estimating the position of the virtual data into the real scene and rendering the virtual content accordingly. In this survey, we focus on the occlusion handling problem in augmented reality applications and provide a detailed review of 161 articles published in this field between January 1992 and August 2020. To do so, we present a historical overview of the most common strategies employed to determine the depth order between real and virtual objects, to visualize hidden objects in a real scene, and to build occlusion-capable visual displays. Moreover, we look at the state-of-the-art techniques, highlight the recent research trends, discuss the current open problems of occlusion handling in augmented reality, and suggest future directions for research.
C1 [Macedo, Marcio C. F.; Apolinario, Antonio L.] Univ Fed Bahia, Dept Comp Sci, BR-40170110 Salvador, BA, Brazil.
C3 Universidade Federal da Bahia
RP Macedo, MCF (corresponding author), Univ Fed Bahia, Dept Comp Sci, BR-40170110 Salvador, BA, Brazil.
EM marciocfmacedo@gmail.com; antonio.apolinario@ufba.br
RI Apolinário, Antonio/R-2106-2019
OI Apolinario Jr., Antonio Lopes/0000-0002-2592-5048; Macedo,
   Marcio/0000-0003-2729-7193
FU Postdoctoral National Program of the Coordination for the Improvement of
   Higher Education Personnel (PNPD/CAPES) [88882.306277/2018-01]
FX The work of Marcio C. F. Macedo was supported in part by the
   Postdoctoral National Program of the Coordination for the Improvement of
   Higher Education Personnel (PNPD/CAPES) under Grant 88882.306277/2018-01
CR Abate Andrea F., 2014, Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments. 6th International Conference, VAMR 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8525, P319, DOI 10.1007/978-3-319-07458-0_30
   Akenine-Moller T., 2018, Real-Time Rendering, V4th
   [Anonymous], 2011, PROC INT C ARTIF REA
   [Anonymous], 2004, PROC 2004 ACM SIGGRA
   [Anonymous], 2007, PROC 6 IEEE ACM INT
   Aukstakalnis S., 2017, Practical augmented reality: a guide to the technologies, applications, and human factors for AR and VR
   Avery B., 2007, PROC ISMAR, DOI [10.1109/ISMAR.2007.4538869, DOI 10.1109/ISMAR.2007.4538869]
   Avery B, 2008, INT SYM MIX AUGMENT, P69, DOI 10.1109/ISMAR.2008.4637327
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Avveduto G., 2017, PROC 23 ACM S VIRT R, P1
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Barnum P, 2009, INT SYM MIX AUGMENT, P111, DOI 10.1109/ISMAR.2009.5336483
   Bartczak B., 2008, PROC 4 INT S 3D DATA
   Bastian M, 2009, P INT AAAI C WEBL SO, V3, P361, DOI 10.13140/2.1.1341.1520
   Battisti C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P198, DOI 10.1109/ISMAR-Adjunct.2018.00066
   Berger MO, 1997, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.1997.609304
   Bichlmeier C., 2007, Bildverarbeitung fur die Medizin 2007, P217
   Bichlmeier C., 2009, PROC INT WORKSHOP AU
   Bichlmeier C., 2007, INT S MIX AUGM REAL, P129, DOI DOI 10.1109/ISMAR.2007.4538837
   Bichlmeier C., 2006, INT WORKSHOP AUGMENT, P1
   Bier E. A., 1993, Computer Graphics Proceedings, P73, DOI 10.1145/166117.166126
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bimber O, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P186, DOI 10.1109/ISMAR.2002.1115088
   Borji A, 2021, IEEE T PATTERN ANAL, V43, P679, DOI 10.1109/TPAMI.2019.2935715
   Bouaziz Sofien., 2016, SIGGRAPH ASIA 2016 Courses, P1
   Boun Vinh Lu, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P109, DOI 10.1109/ISMAR.2010.5643558
   Breen DE, 1996, COMPUT GRAPH FORUM, V15, pC11, DOI 10.1111/1467-8659.1530011
   Cakmakci O, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P16, DOI 10.1109/ISMAR.2004.2
   Cakmakci O., 2005, P SPIE INT SOC OPT E, P122
   Chen J., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology (VRST), P167, DOI [10.1145/1889863.1889898, DOI 10.1145/1889863.1889898]
   Corbett-Davies S., 2012, 2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH), P95, DOI 10.1109/ISMAR-AMH.2012.6483998
   Corbett-Davies S, 2013, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2013.6549351
   Cordes K., 2012, P INT C COMP VIS THE, P173
   Cruz L., 2012, 2012 XXV SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T), P36, DOI 10.1109/SIBGRAPI-T.2012.13
   Dey A, 2014, INT J HUM-COMPUT ST, V72, P704, DOI 10.1016/j.ijhcs.2014.04.001
   Dey A, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P127, DOI 10.1109/3DUI.2010.5444706
   dos Santos Artur Lira, 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P131, DOI 10.1109/SVR.2012.8
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Duchesne C, 2000, INT C PATT RECOG, P261, DOI 10.1109/ICPR.2000.905315
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elmqvist N, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P51
   Eren MT, 2018, VISUAL COMPUT, V34, P405, DOI 10.1007/s00371-016-1346-5
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   Feng Q., 2018, P 24 ACM S VIRT REAL
   Fischer J., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P153, DOI 10.1145/769953.769971
   Fischer J., 2004, Proceedings of the ACM symposium on Virtual reality software and technology, P174
   Fischer J., 2007, IPT EGVE, P109
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Fortin P, 2006, 3 CANADIAN C COMPUTE, P54
   Frikha R., 2016, PROC IEEEACS 13 INT, P1
   Fuhrmann A, 1999, COMPUT GRAPH-UK, V23, P809, DOI 10.1016/S0097-8493(99)00107-7
   Fujimoto Y, 2015, 2015 IEEE International Symposium on Mixed and Augmented Reality, P174, DOI 10.1109/ISMAR.2015.51
   Fukiage T, 2012, INT SYM MIX AUGMENT, P129, DOI 10.1109/ISMAR.2012.6402549
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gao CY, 2013, PROC SPIE, V8735, DOI 10.1117/12.2015937
   Gao CY, 2012, INT SYM MIX AUGMENT, P281, DOI 10.1109/ISMAR.2012.6402574
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gimeno Jesus, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P377
   Gimeno J, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P21, DOI 10.1109/ISMAR-Adjunct.2018.00024
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   Hahne U, 2009, LECT NOTES COMPUT SC, V5742, P70, DOI 10.1007/978-3-642-03778-8_6
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Hansen C, 2010, INT J COMPUT ASS RAD, V5, P133, DOI 10.1007/s11548-009-0365-3
   Hayashi K., 2005, P 2005 INT C AUGMENT, P180
   Hebborn AK, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P62, DOI 10.1109/ISMAR.2017.23
   Holynski A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275083
   Howlett ID, 2017, J SOC INF DISPLAY, V25, P185, DOI 10.1002/jsid.545
   Hua H, 2002, P IEEE VIRT REAL ANN, P81, DOI 10.1109/VR.2002.996508
   Ikeuchi K., 2010, P 9 ACM SIGGRAPH C V, P361
   Inami M., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P233, DOI 10.1109/VR.2000.840503
   Itoh Y, 2017, IEEE T VIS COMPUT GR, V23, P2463, DOI 10.1109/TVCG.2017.2734427
   Izadi S., 2011, UIST, P559
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Ju YG, 2020, OPT LETT, V45, P3361, DOI 10.1364/OL.393194
   Kakeya H, 2014, OPT EXPRESS, V22, P24491, DOI 10.1364/OE.22.024491
   Kakuta T., 2008, PROC ACM S VIRT REAL, P219
   Kalkofen D, 2013, INT SYM MIX AUGMENT, P1
   Kalkofen D, 2011, HANDBOOK OF AUGMENTED REALITY, P65, DOI 10.1007/978-1-4614-0064-6_3
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kalkofen D, 2009, IEEE T VIS COMPUT GR, V15, P193, DOI 10.1109/TVCG.2008.96
   Kalkofen Denis, 2007, P 6 IEEE ACM INT S M, P1, DOI [DOI 10.1109/ISMAR.2007.4538846, 10.1109/ISMAR.2007.4538846]
   Kameda Y, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P151, DOI 10.1109/ISMAR.2004.45
   Kanbara M., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P255, DOI 10.1109/VR.2000.840506
   Kanbara M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P213, DOI 10.1109/MMCS.1999.779195
   Kasperi J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139159
   Kersten-Oertel M, 2015, INT J COMPUT ASS RAD, V10, P1823, DOI 10.1007/s11548-015-1163-8
   Kilimann JE, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365712
   Kim H, 2003, P SOC PHOTO-OPT INS, V5006, P544, DOI 10.1117/12.473879
   Kim K., 2010, P VRCAI 2010 ACM SIG, P161, DOI [10.1145/1900179.1900214, DOI 10.1145/1900179.1900214]
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Kiyokawa K, 2001, COMPUT GRAPH-UK, V25, P765, DOI 10.1016/S0097-8493(01)00119-4
   Kiyokawa K, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P60, DOI 10.1109/ISAR.2000.880924
   Kiyokawa K, 2012, HANDBOOK OF VISUAL DISPLAY TECHNOLOGY, VOLS 1-4, P2251, DOI 10.1007/978-3-540-79567-4_10.6.2
   Klein G, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P38, DOI 10.1109/ISMAR.2004.54
   Koch R, 2009, LECT NOTES COMPUT SC, V5742, P126, DOI 10.1007/978-3-642-03778-8_10
   Kojima Y, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P463, DOI 10.1109/VSMM.2001.969701
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   Kurz Daniel., 2008, VRST 08, P227
   Kutter O, 2008, PROC INT WORKSHOP AU
   Ladikos A, 2009, LECT NOTES COMPUT SC, V5875, P480, DOI 10.1007/978-3-642-10331-5_45
   Leal-Melendrez J. A., 2013, CIARP 13 P PROGR PAT, P447, DOI [10.1007/978-3-642-41827-3561, DOI 10.1007/978-3-642-41827-3561]
   Lee W, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P106
   Lepetit V, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P137, DOI 10.1109/ISAR.2000.880937
   Lepetit V, 2000, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2000.854794
   Lerotic M, 2007, LECT NOTES COMPUT SC, V4792, P102
   Li LJ, 2007, LECT NOTES COMPUT SC, V4551, P634
   Livingston M.A., 2013, Pursuit of "X-ray vision" for augmented reality, P67
   Livingston MA, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P56, DOI 10.1109/ISMAR.2003.1240688
   Lu R, 2019, IEEE I CONF COMP VIS, P10342, DOI 10.1109/ICCV.2019.01044
   Luo X, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392377
   Macedo MCF, 2015, COMPUT GRAPH-UK, V53, P196, DOI 10.1016/j.cag.2015.09.007
   Macedo MCF, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P149, DOI 10.1109/SIBGRAPI.2014.33
   Maia LF, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P111, DOI 10.1145/2993369.2993370
   Maimone A, 2013, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2013.6671761
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Malik S, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P117, DOI 10.1109/ISMAR.2002.1115080
   Marques B., 2015, PROC SPECIAL INTERES
   McDonald C., 2003, PROC INT C VIS INTER
   Mendez Erick, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P209, DOI 10.1109/ISMAR.2006.297816
   Mendez E., 2009, P VRST, P247, DOI [DOI 10.1145/1643928.1643988, 10.1145/1643928.1643988]
   Mulder JD, 2006, PRESENCE-TELEOP VIRT, V15, P93, DOI 10.1162/pres.2006.15.1.93
   Mulder JD, 2005, P IEEE VIRT REAL ANN, P203
   Murase K., 2008, PROC INT C ADDITIVE, P12
   Narita G., 2015, Proceedings of the 21st ACM symposium on virtual reality software and technology, P149, DOI DOI 10.1145/2821592.2821618
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   Ohta Y, 2002, PRESENCE-TELEOP VIRT, V11, P176, DOI 10.1162/105474602317396048
   Ong KC, 1998, VISUAL COMPUT, V14, P153, DOI 10.1007/s003710050131
   Özgür E, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P46, DOI 10.1109/ISMAR-Adjunct.2017.30
   Padilha A, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY WORKSHOPS, P60, DOI 10.1109/ISMARW.2015.20
   Padilha A, 2014, INT SYM MIX AUGMENT, P291, DOI 10.1109/ISMAR.2014.6948455
   Pilet J., 2007, PROC 6 IEEE ACM INT, P249
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rong Wang, 2016, Medical Imaging and Augmented Reality. 7th International Conference, MIAR 2016. Proceedings: LNCS 9805, P129, DOI 10.1007/978-3-319-43775-0_12
   Roxas M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281546
   Sanches S. R. R., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P49, DOI 10.1109/WACV.2012.6163037
   Sandor C., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P27, DOI 10.1109/ISMAR.2010.5643547
   Sandor C, 2010, P IEEE VIRT REAL ANN, P47, DOI 10.1109/VR.2010.5444815
   Sandor C, 2009, INT SYM MIX AUGMENT, P211, DOI 10.1109/ISMAR.2009.5336461
   Santos MEC, 2013, IEEE INT CONF ADV LE, P141, DOI 10.1109/ICALT.2013.45
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   Schmidt J, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P225, DOI 10.1109/ACV.2002.1182186
   Schöps T, 2014, INT SYM MIX AUGMENT, P145, DOI 10.1109/ISMAR.2014.6948420
   Schumann H., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P290
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Smithwick QYJ, 2014, PROC SPIE, V9011, DOI 10.1117/12.2035091
   State A., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P364, DOI 10.1109/VISUAL.1994.346295
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P439, DOI 10.1145/237170.237283
   Tian Y, 2010, SENSORS-BASEL, V10, P2885, DOI 10.3390/s100402885
   Tsuda Takahiro, 2005, P 2005 INT C AUGM TE, P62, DOI [10.1145/1152399, DOI 10.1145/1152399]
   Valentin J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275041
   Vallino J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P195, DOI 10.1109/MMCS.1999.779146
   Van Krevelen D., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10.20870/ijvr.2010.9.2.2767
   Ventura J., 2008, PROC SIGGRAPH POSTER
   Ventura J, 2009, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2009.5336493
   Viega John, 1996, P 9 ANN ACM S USER I, P51, DOI DOI 10.1145/237091.237098
   Walairacht S, 2002, PRESENCE-TELEOP VIRT, V11, P134, DOI 10.1162/105474602317396011
   Walton DR, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139153
   Wang HL, 2005, PRESENCE-VIRTUAL AUG, V14, P264, DOI 10.1162/105474605323384636
   Wang JF, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P57, DOI 10.1109/ISMAR-Adjunct.2018.00034
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Wetzstein G., 2020, STATE ART PERCEPTUAL, P221
   Wilson A, 2017, OPT EXPRESS, V25, P30539, DOI 10.1364/OE.25.030539
   Wither J, 2008, INT SYM MIX AUGMENT, P65, DOI 10.1109/ISMAR.2008.4637326
   Wloka M. W., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P5, DOI 10.1145/199404.199405
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
   Xiao Tang, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P697, DOI 10.1145/3379337.3415835
   Ya Zhou, 2007, Technologies for E-Learning and Digital Entertainment. Second International Conference, Edutainment 2007, P56
   Yamaguchi Y, 2016, APPL OPTICS, V55, pA144, DOI 10.1364/AO.55.00A144
   Yang CK, 2020, VIRTUAL REAL-LONDON, V24, P527, DOI 10.1007/s10055-019-00415-8
   Yii W, 2012, INT SYM MIX AUGMENT, P41, DOI 10.1109/ISMAR.2012.6402536
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhou Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P781, DOI 10.1145/2858036.2858329
   Zhu J., 2008, PROC 7 ACM SIGGRAPH
   Zhu JJ, 2010, COMPUT ANIMAT VIRT W, V21, P509, DOI 10.1002/cav.326
   Zollh ofer M., COMPUT GRAPH FORUM, V37, P625
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
   Zollmann S., 2012, 18 ACM S VIRT REAL S, P53
   Zollmann S, 2021, IEEE T VIS COMPUT GR, V27, P3808, DOI 10.1109/TVCG.2020.2986247
   Zollmann Stefanie, 2014, P 26 AUSTR COMP HUM, P194, DOI DOI 10.1145/2686612.2686642
NR 190
TC 19
Z9 20
U1 2
U2 35
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB 1
PY 2023
VL 29
IS 2
BP 1590
EP 1609
DI 10.1109/TVCG.2021.3117866
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M2HO
UT WOS:000906475100023
PM 34613916
DA 2024-11-06
ER

PT J
AU Wang, SD
   Zeng, W
   Chen, X
   Ye, Y
   Qiao, Y
   Fu, CW
AF Wang, Shidong
   Zeng, Wei
   Chen, Xi
   Ye, Yu
   Qiao, Yu
   Fu, Chi-Wing
TI ActFloor-GAN: Activity-Guided Adversarial Networks for Human-Centric
   Floorplan Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Generative adversarial networks; Buildings; Predictive models;
   Computer architecture; Topology; Optimization; Floorplan design; room
   layout; human-centric; GAN
ID LAYOUT DESIGN; CONFIGURATION; REGISTRATION
AB We present a novel two-stage approach for automated floorplan design in residential buildings with a given exterior wall boundary. Our approach has the unique advantage of being human-centric, that is, the generated floorplans can be geometrically plausible, as well as topologically reasonable to enhance resident interaction with the environment. From the input boundary, we first synthesize a human-activity map that reflects both the spatial configuration and human-environment interaction in an architectural space. We propose to produce the human-activity map either automatically by a pre-trained generative adversarial network (GAN) model, or semi-automatically by synthesizing it with user manipulation of the furniture. Second, we feed the human-activity map into our deep framework ActFloor-GAN to guide a pixel-wise prediction of room types. We adopt a re-formulated cycle-consistency constraint in ActFloor-GAN to maximize the overall prediction performance, so that we can produce high-quality room layouts that are readily convertible to vectorized floorplans. Experimental results show several benefits of our approach. First, a quantitative comparison with prior methods shows superior performance of leveraging the human-activity map in predicting piecewise room types. Second, a subjective evaluation by architects shows that our results have compelling quality as professionally-designed floorplans and much better than those generated by existing methods in terms of the room layout topology. Last, our approach allows manipulating the furniture placement, considers the human activities in the environment, and enables the incorporation of user-design preferences.
C1 [Wang, Shidong; Chen, Xi; Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Wang, Shidong] Shandong Univ, Jinan 250100, Shandong, Peoples R China.
   [Zeng, Wei] Hong Kong Univ Sci & Technol, Guangzhou, Peoples R China.
   [Chen, Xi] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Ye, Yu] Tongji Univ, Shanghai, Peoples R China.
   [Fu, Chi-Wing] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Shandong University; Hong Kong University of Science & Technology;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Tongji University; Chinese University of Hong Kong
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol, Guangzhou, Peoples R China.
EM sdwang96@gmail.com; weizeng@ust.hk; xi.chen2@siat.ac.cn;
   yye@tongji.edu.cn; yu.qiao@siat.ac.cn; cwfu@cse.cuhk.edu.hk
RI Qiao, Yu/ABD-5787-2021; Fu, Chi-Wing/X-4703-2019
OI Zeng, Wei/0000-0002-5600-8824; Fu, Chi Wing/0000-0002-5238-593X; Wang,
   Shidong/0000-0003-2850-8319
FU Fundamental Research Funds for the Central Universities [22120210540];
   Research Grants Council of the Hong Kong Special Administrative Region
   [CUHK 14206320]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities under Grant 22120210540 and in part by the
   Research Grants Council of the Hong Kong Special Administrative Region
   under Grant CUHK 14206320.
CR [Anonymous], 2017, P IEEE C COMP VIS PA
   Arvin SA, 2002, AUTOMAT CONSTR, V11, P213, DOI 10.1016/S0926-5805(00)00099-6
   Bao F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461977
   Benevolo Leonardo, 1977, History of Modern Architecture. Volume 1: The Tradition of Modern Architecture, V1
   Berseth G, 2021, IEEE T VIS COMPUT GR, V27, P111, DOI 10.1109/TVCG.2019.2938961
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chaillou S., 2019, Master's Thesis
   Chen Q, 2020, PROC CVPR IEEE, P12622, DOI 10.1109/CVPR42600.2020.01264
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Corbusier L., 1927, Vers Une Architecture. Towards a New Architecture
   Feng T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925894
   Franz G, 2008, ENVIRON PLANN B, V35, P574, DOI 10.1068/b33050
   Goodfellow I.J., 2014, 27 INT C NEURAL INF, P2672
   Hertzberger H., 2005, Lessons for Students in Architecture, VVolume 1
   HILLIER B, 1993, ENVIRON PLANN B, V20, P29, DOI 10.1068/b200029
   Hillier B., 1976, Environ. Plan. B Plan. Des, V3, P147, DOI DOI 10.1068/B030147
   Hu KD, 2020, COMPUT GRAPH-UK, V88, P83, DOI 10.1016/j.cag.2020.03.005
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu RZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392391
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jenkinson M, 2002, NEUROIMAGE, V17, P825, DOI 10.1006/nimg.2002.1132
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalervo A, 2019, LECT NOTES COMPUT SC, V11482, P28, DOI 10.1007/978-3-030-20205-7_3
   Karras T., 2018, P 6 INT C LEARN REPR, P1, Patent No. [1710.10196, 171010196]
   Kingma D. P., 2017, P INT C LEARNING REP, P1
   LaValle S, 1998, Tech. Rep. 9811
   Lee C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376327
   Levin P.H., 1964, The Architects' Journal, V7, P809
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li JN, 2021, IEEE T VIS COMPUT GR, V27, P4039, DOI 10.1109/TVCG.2020.2999335
   Li JN, 2021, IEEE T PATTERN ANAL, V43, P2388, DOI 10.1109/TPAMI.2019.2963663
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Li MY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3303766
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Merrell P, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866203
   Michalek JJ, 2002, ENG OPTIMIZ, V34, P461, DOI 10.1080/03052150214016
   Mirza M., 2014, arXiv preprint arXiv:1411.1784, DOI 10.48550/arXiv.1411.1784
   Nauata K.-H., 2020, P EUR C COMP VIS, P162, DOI [DOI 10.1007/978-3-030-58452-810, 10.1007/978-3-030-58452-8_10]
   Ook Kim Young, 1999, THESIS U LONDON LOND
   Patil AG, 2020, IEEE COMPUT SOC CONF, P2316, DOI 10.1109/CVPRW50498.2020.00280
   Pelechano N, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P99
   Peng CH, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925935
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Radford A., 2015, Unsupervised representation learning with deep convolutional generative adversarial networks. CoRR abs/1511.06434, DOI DOI 10.1109/AIAR.2018.8769811
   Reynolds C., 1987, ACM SIGGRAPH COMPUTE, V21, P25, DOI [10.1145/37401.37406, https://doi.org/10.1145/37402.37406]
   Rodrigues E, 2013, AUTOMAT CONSTR, V35, P482, DOI 10.1016/j.autcon.2013.06.005
   Swearngin A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174078
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Wu WM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356556
   Wu WM, 2018, COMPUT GRAPH FORUM, V37, P511, DOI 10.1111/cgf.13380
   Yang YL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508405
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zeng W, 2019, COMPUT GRAPH FORUM, V38, P581, DOI 10.1111/cgf.13712
   Zeng ZL, 2019, IEEE I CONF COMP VIS, P9095, DOI 10.1109/ICCV.2019.00919
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 57
TC 9
Z9 9
U1 12
U2 61
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1610
EP 1624
DI 10.1109/TVCG.2021.3126478
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900001
PM 34752396
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Boorboor, S
   Mathew, S
   Ananth, M
   Talmage, D
   Role, LW
   Kaufman, AE
AF Boorboor, Saeed
   Mathew, Shawn
   Ananth, Mala
   Talmage, David
   Role, Lorna W.
   Kaufman, Arie E.
TI NeuRegenerate: A Framework for Visualizing Neurodegeneration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Microscopy; Data visualization; Image reconstruction; Visualization;
   Neurites; Training; Three-dimensional displays; Neuron visualization;
   volume visualization; volume transformation; wide-field microscopy;
   machine learning
ID MICROSCOPY; TOOL; 3D
AB Recent advances in high-resolution microscopy have allowed scientists to better understand the underlying brain connectivity. However, due to the limitation that biological specimens can only be imaged at a single timepoint, studying changes to neural projections over time is limited to observations gathered using population analysis. In this article, we introduce NeuRegenerate, a novel end-to-end framework for the prediction and visualization of changes in neural fiber morphology within a subject across specified age-timepoints. To predict projections, we present neuReGANerator, a deep-learning network based on cycle-consistent generative adversarial network (GAN) that translates features of neuronal structures across age-timepoints for large brain microscopy volumes. We improve the reconstruction quality of the predicted neuronal structures by implementing a density multiplier and a new loss function, called the hallucination loss. Moreover, to alleviate artifacts that occur due to tiling of large input volumes, we introduce a spatial-consistency module in the training pipeline of neuReGANerator. Finally, to visualize the change in projections, predicted using neuReGANerator, NeuRegenerate offers two modes: (i) neuroCompare to simultaneously visualize the difference in the structures of the neuronal projections, from two age domains (using structural view and bounded view), and (ii) neuroMorph, a vesselness-based morphing technique to interactively visualize the transformation of the structures from one age-timepoint to the other. Our framework is designed specifically for volumes acquired using wide-field microscopy. We demonstrate our framework by visualizing the structural changes within the cholinergic system of the mouse brain between a young and old specimen.
C1 [Boorboor, Saeed; Mathew, Shawn; Kaufman, Arie E.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Ananth, Mala; Talmage, David; Role, Lorna W.] NIH, Bethesda, MD 20814 USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   National Institutes of Health (NIH) - USA
RP Boorboor, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM sboorboor@cs.stonybrook.edu; shawmathew@cs.stonybrook.edu;
   mala.ananth@nih.gov; david.talmage@nih.gov; lorna.role@nih.gov;
   ari@cs.stonybrook.edu
RI Boorboor, Saeed/ABI-7739-2020; Role, Lorna/JQX-1231-2023; Role,
   Lorna/Q-7371-2018
OI Boorboor, Saeed/0000-0001-6644-5983; Role, Lorna/0000-0001-5851-212X;
   Kaufman, Arie/0000-0002-0796-6196; Mathew, Shawn/0000-0002-1344-4853;
   Talmage, David/0000-0003-4627-3007; Ananth, Mala/0000-0003-1736-2350
FU NSF [CNS1650499, OAC1919752, ICER1940302, IIS2107224]; NIH, NINDS; NIH,
   NIMH
FX This research was supported in part by NSF under Grants CNS1650499,
   OAC1919752, ICER1940302, and IIS2107224 and by the Intramural Research
   Program of the NIH, NINDS, and NIMH.
CR Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Bai B, 2014, PROC SPIE, V9038, DOI 10.1117/12.2043744
   Ballinger EC, 2019, ENEURO, V6, DOI 10.1523/ENEURO.0134-19.2019
   Boorboor S, 2019, IEEE T VIS COMPUT GR, V25, P1018, DOI 10.1109/TVCG.2018.2864852
   Chen Hanbo, 2015, Brain Inform, V2, P135
   Chu CS, 2017, Arxiv, DOI [arXiv:1712.02950, DOI 10.48550/ARXIV.1712.02950, 10.48550/arXiv.1712.02950]
   Cohen JP, 2018, LECT NOTES COMPUT SC, V11070, P529, DOI 10.1007/978-3-030-00928-1_60
   Correa CD, 2010, COMPUT GRAPH-UK, V34, P370, DOI 10.1016/j.cag.2010.01.007
   Costa P, 2018, IEEE T MED IMAGING, V37, P781, DOI 10.1109/TMI.2017.2759102
   Emami H, 2018, MED PHYS, V45, P3627, DOI 10.1002/mp.13047
   Fang SF, 2000, COMPUT AIDED GEOM D, V17, P59, DOI 10.1016/S0167-8396(99)00039-4
   Frey S, 2017, IEEE T VIS COMPUT GR, V23, P921, DOI 10.1109/TVCG.2016.2599042
   Gala R, 2014, FRONT NEUROANAT, V8, DOI 10.3389/fnana.2014.00037
   Goodfellow L., 2014, ADV NEUR IN, V2, P2672, DOI DOI 10.1145/3422622
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Janoos F, 2008, COMPUT GRAPH FORUM, V27, P879, DOI 10.1111/j.1467-8659.2008.01220.x
   Jerman T, 2016, IEEE T MED IMAGING, V35, P2107, DOI 10.1109/TMI.2016.2550102
   Kim T, 2017, PR MACH LEARN RES, V70
   Li RJ, 2017, IEEE T MED IMAGING, V36, P1533, DOI 10.1109/TMI.2017.2679713
   Li ZY, 2018, NEUROINFORMATICS, V16, P339, DOI 10.1007/s12021-018-9361-5
   Liu Y, 2017, Arxiv, DOI arXiv:1703.02442
   Lu AD, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P143
   Mathew S, 2020, PROC CVPR IEEE, P4695, DOI [10.1109/cvpr42600.2020.00475, 10.1109/CVPR42600.2020.00475]
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Mosaliganti K, 2008, IEEE T VIS COMPUT GR, V14, P863, DOI 10.1109/TVCG.2008.30
   Nakao M, 2014, COMPUT BIOL MED, V53, P85, DOI 10.1016/j.compbiomed.2014.07.007
   Nie Dong, 2017, Med Image Comput Comput Assist Interv, V10435, P417, DOI 10.1007/978-3-319-66179-7_48
   Pfister H., 2014, Scientific Visualization, P221
   Schroeder WJ, 2000, IEEE COMPUT GRAPH, V20, P20, DOI 10.1109/38.865875
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Skibbe H, 2019, IEEE T MED IMAGING, V38, P69, DOI 10.1109/TMI.2018.2855736
   Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042
   Taosong He, 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P85, DOI 10.1109/VISUAL.1994.346333
   Turaga SC, 2010, NEURAL COMPUT, V22, P511, DOI 10.1162/neco.2009.10-08-881
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   Wan Y, 2012, IEEE PAC VIS SYMP, P201, DOI 10.1109/PacificVis.2012.6183592
   Wang H, 2019, I S BIOMED IMAGING, P228, DOI [10.1109/ISBI.2019.8759326, 10.1109/isbi.2019.8759326]
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
   Wilson M., 2017, INTRO WIDEFIELD MICR
   Wu YC, 2019, NAT METHODS, V16, P1323, DOI 10.1038/s41592-019-0622-5
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhe Fang, 2007, Proceedings Graphics Interface 2007, P281, DOI 10.1145/1268517.1268563
   Zhou Zhi, 2018, Brain Inform, V5, P3, DOI 10.1186/s40708-018-0081-2
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 3
Z9 3
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1625
EP 1637
DI 10.1109/TVCG.2021.3127132
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900002
PM 34757909
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yang, LN
   Xiong, C
   Wong, JK
   Wu, AY
   Qu, HM
AF Yang, Leni
   Xiong, Cindy
   Wong, Jason K. K.
   Wu, Aoyu
   Qu, Huamin
TI Explaining With Examples: Lessons Learned From Crowdsourced Introductory
   Description of Information Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Encoding; Education; Task analysis;
   Annotations; Design methodology; Narrative visualization; oral
   presentation; introduction
ID GRAPH LITERACY; TEXT; COMPREHENSION; CONCRETENESS; RECALL; FAMILIARITY;
   ATTENTION
AB Data visualizations have been increasingly used in oral presentations to communicate data patterns to the general public. Clear verbal introductions of visualizations to explain how to interpret the visually encoded information are essential to convey the takeaways and avoid misunderstandings. We contribute a series of studies to investigate how to effectively introduce visualizations to the audience with varying degrees of visualization literacy. We begin with understanding how people are introducing visualizations. We crowdsource 110 introductions of visualizations and categorize them based on their content and structures. From these crowdsourced introductions, we identify different introduction strategies and generate a set of introductions for evaluation. We conduct experiments to systematically compare the effectiveness of different introduction strategies across four visualizations with 1,080 participants. We find that introductions explaining visual encodings with concrete examples are the most effective. Our study provides both qualitative and quantitative insights into how to construct effective verbal introductions of visualizations in presentations, inspiring further research in data storytelling.
C1 [Yang, Leni; Wong, Jason K. K.; Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn CSE, Hong Kong, Peoples R China.
   [Wu, Aoyu] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Xiong, Cindy] Univ Massachusetts, Amherst, MA 01003 USA.
C3 Hong Kong University of Science & Technology; Hong Kong University of
   Science & Technology; University of Massachusetts System; University of
   Massachusetts Amherst
RP Yang, LN (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn CSE, Hong Kong, Peoples R China.
EM lyangbb@cse.ust.hk; cindy.xiong@cs.umass.edu; kkwongar@cse.ust.hk;
   awuac@cse.ust.hk; huamin@cse.ust.hk
OI Wu, Aoyu/0000-0001-9187-9265; Yang, Leni/0000-0003-4527-4905; Xiong
   Bearfield, Cindy/0000-0002-1451-4083; WONG, Kam Kwai/0000-0002-2813-1972
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2014, WE CAME WE WENT STAT
   [Anonymous], NEW YORK TIMES
   [Anonymous], 2019, FACEBOOK POLITICAL A
   Bergen L, 2005, HUM COMMUN RES, V31, P311, DOI 10.1093/hcr/31.3.311
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Bolkan S, 2019, COMMUN EDUC, V68, P287, DOI 10.1080/03634523.2019.1602275
   Bostock M, D3 EXAMPLE GALLERY
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bremer N, 2014, USING DATA STORYTELL
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Fox AR, 2018, LECT NOTES ARTIF INT, V10871, P441, DOI 10.1007/978-3-319-91376-6_40
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Garcia-Retamero R, 2016, MED DECIS MAKING, V36, P854, DOI 10.1177/0272989X16655334
   github, CONNECTED SCATTER PL
   github, WATERFALL CHART MONT
   github, VEGA EXAMPLE GALLERY
   Haroz S, 2016, IEEE T VIS COMPUT GR, V22, P2174, DOI 10.1109/TVCG.2015.2502587
   Hinds PJ, 2001, J APPL PSYCHOL, V86, P1232, DOI 10.1037/0021-9010.86.6.1232
   informationisbeautiful, INFORM IS BEAUTIFUL
   ISAACS EA, 1987, J EXP PSYCHOL GEN, V116, P26, DOI 10.1037/0096-3445.116.1.26
   Kerby HW, 2018, INT J SCI EDUC, V40, P1774, DOI 10.1080/09500693.2018.1512172
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300280
   Kong HK, 2017, COMPUT GRAPH FORUM, V36, P515, DOI 10.1111/cgf.13207
   Kosara R, 2016, IEEE COMPUT GRAPH, V36, P80, DOI 10.1109/MCG.2016.2
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kwon BC, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P993, DOI 10.1145/2858036.2858101
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   LeFevre Jo-Anne, 1986, Cognition and Instruction, V3, P1, DOI [DOI 10.1207/S1532690XCI0301_, 10.1207/s1532690xci0301_1]
   LORCH RF, 1985, J EDUC PSYCHOL, V77, P137, DOI 10.1037/0022-0663.77.2.137
   Lorch RF, 1996, CONTEMP EDUC PSYCHOL, V21, P261
   Mensink MC, 2021, DISCOURSE PROCESS, V58, P491, DOI 10.1080/0163853X.2021.1904754
   Prolific, About us
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   SADOSKI M, 1993, J READING BEHAV, V25, P5, DOI 10.1080/10862969309547799
   Sadoski M, 2000, J EDUC PSYCHOL, V92, P85, DOI 10.1037/0022-0663.92.1.85
   Sadoski M, 2001, EDUC PSYCHOL REV, V13, P263, DOI 10.1023/A:1016675822931
   Sadoski M., 2013, IMAGERY TEXT DUAL CO
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   SCHWARZ MNK, 1981, J VERB LEARN VERB BE, V20, P61, DOI 10.1016/S0022-5371(81)90301-7
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   SHIMODA TA, 1993, J EXP EDUC, V61, P93, DOI 10.1080/00220973.1993.9943854
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Stoiber C., 2019, PREPRINT, DOI [10.31219/osf.io/c38ab, DOI 10.31219/OSF.IO/C38AB]
   Surowiecki J., 2005, The wisdom of crowds
   Tanahashi Y, 2016, COMPUT GRAPH FORUM, V35, P117, DOI 10.1111/cgf.13009
   Vega, PARALLEL COORDINATES
   Wang Z., 2020, 2020 IEEE 91 VEHICUL, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9128938
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
   FINANC TIMES
NR 55
TC 12
Z9 12
U1 5
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1638
EP 1650
DI 10.1109/TVCG.2021.3128157
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900003
PM 34780329
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Jadhav, S
   Torkaman, M
   Tannenbaum, A
   Nadeem, S
   Kaufman, AE
AF Jadhav, Shreeraj
   Torkaman, Mahsa
   Tannenbaum, Allen
   Nadeem, Saad
   Kaufman, Arie E.
TI Volume Exploration Using Multidimensional Bhattacharyya Flow
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Active contours; Semantics; Tools; Three-dimensional displays;
   Histograms; Biomedical optical imaging; Optical feedback; Volume
   exploration; geometric active contours; Bhattacharyya flow; hierarchical
   decomposition; multi-GPU
ID INTELLIGENT SYSTEM APPROACH; ACTIVE CONTOURS; SEGMENTATION;
   CLASSIFICATION; VISUALIZATION; DRIVEN; 2D
AB We present a novel approach for volume exploration that is versatile yet effective in isolating semantic structures in both noisy and clean data. Specifically, we describe a hierarchical active contours approach based on Bhattacharyya gradient flow which is easier to control, robust to noise, and can incorporate various types of statistical information to drive an edge-agnostic exploration process. To facilitate a time-bound user-driven volume exploration process that is applicable to a wide variety of data sources, we present an efficient multi-GPU implementation that (1) is approximately 400 times faster than a single thread CPU implementation, (2) allows hierarchical exploration of 2D and 3D images, (3) supports customization through multidimensional attribute spaces, and (4) is applicable to a variety of data sources and semantic structures. The exploration system follows a 2-step process. It first applies active contours to isolate semantically meaningful subsets of the volume. It then applies transfer functions to the isolated regions locally to produce clear and clutter-free visualizations. We show the effectiveness of our approach in isolating and visualizing structures-of-interest without needing any specialized segmentation methods on a variety of data sources, including 3D optical microscopy, multi-channel optical volumes, abdominal and chest CT, micro-CT, MRI, simulation, and synthetic data. We also gathered feedback from a medical trainee regarding the usefulness of our approach and discussion on potential applications in clinical workflows.
C1 [Jadhav, Shreeraj; Kaufman, Arie E.] SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
   [Torkaman, Mahsa] Univ Calif San Francisco UCSF, Dept Radiol & Biomed Imaging, San Francisco, CA 94143 USA.
   [Tannenbaum, Allen] SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
   [Tannenbaum, Allen] SUNY Stony Brook, Appl Math & Stat Dept, Stony Brook, NY 11794 USA.
   [Nadeem, Saad] Mem Sloan Kettering Canc Ctr, Dept Med Phys & Pathol, New York, NY 10065 USA.
C3 State University of New York (SUNY) System; Stony Brook University;
   University of California System; University of California San Francisco;
   State University of New York (SUNY) System; Stony Brook University;
   State University of New York (SUNY) System; Stony Brook University;
   Memorial Sloan Kettering Cancer Center
RP Jadhav, S (corresponding author), SUNY Stony Brook, Comp Sci Dept, Stony Brook, NY 11794 USA.
EM sdjadhav@cs.stonybrook.edu; mahsa.torkaman@ucsf.edu;
   arobertan@cs.stonybrook.edu; nadeems@mskcc.org; ari@cs.stonybrook.edu
OI Kaufman, Arie/0000-0002-0796-6196; Jadhav, Shreeraj/0000-0003-0520-4857
FU NSF [CNS1650499, OAC1919752, ICER1940302, IIS2107224]; AFOSR
   [FA9550-20-1-0029]; NIA [R01-AG048769]; MSKCC [P30 CA008748]; Breast
   Cancer Research Foundation [BCRF-17-193]
FX This research was supported by NSF CNS1650499, OAC1919752, ICER1940302
   and IIS2107224, AFOSR FA9550-20-1-0029, NIA R01-AG048769, MSKCC
   support/core Grant P30 CA008748, and Breast Cancer Research Foundation
   BCRF-17-193
CR Ahmed E, 2019, Arxiv, DOI arXiv:1808.01462
   [Anonymous], 2007, 2007 IEEE C COMPUTER
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Birkeland Å, 2012, COMPUT GRAPH FORUM, V31, P905, DOI 10.1111/j.1467-8659.2012.03083.x
   BLAKE A., 1998, Active Contours
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   Correa CD, 2009, IEEE T VIS COMPUT GR, V15, P1465, DOI 10.1109/TVCG.2009.189
   Dmitriev K, 2019, PROC CVPR IEEE, P9493, DOI 10.1109/CVPR.2019.00973
   Dunn KW, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54244-5
   Farhangi MM, 2017, IEEE T MED IMAGING, V36, P2239, DOI 10.1109/TMI.2017.2720119
   Gao Y, 2012, MED IMAGE ANAL, V16, P1216, DOI 10.1016/j.media.2012.06.002
   Goldman R, 2005, COMPUT AIDED GEOM D, V22, P632, DOI 10.1016/j.cagd.2005.06.005
   Guha S, 2006, ACM T DATABASE SYST, V31, P396, DOI 10.1145/1132863.1132873
   Guo HQ, 2013, IEEE PAC VIS SYMP, P65, DOI 10.1109/PacificVis.2013.6596129
   Hadwiger M, 2008, IEEE T VIS COMPUT GR, V14, P1507, DOI 10.1109/TVCG.2008.147
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Huang RZ, 2003, 11TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P355
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Jadhav S, 2019, IEEE T VIS COMPUT GR, V25, P2725, DOI 10.1109/TVCG.2018.2856744
   Jaouen V, 2019, IEEE T BIO-MED ENG, V66, P920, DOI 10.1109/TBME.2018.2865428
   Ka-Wai Ng, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2392, DOI 10.1109/CISP.2010.5646288
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537
   Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Ma B, 2018, IEEE T VIS COMPUT GR, V24, P3253, DOI 10.1109/TVCG.2017.2776935
   Maciejewski R, 2009, IEEE T VIS COMPUT GR, V15, P1473, DOI 10.1109/TVCG.2009.185
   Mesquita R, 2019, SIBGRAPI, P92, DOI 10.1109/SIBGRAPI.2019.00021
   Meziou L., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3077, DOI 10.1109/ICIP.2011.6116315
   Michailovich O, 2007, IEEE T IMAGE PROCESS, V16, P2787, DOI 10.1109/TIP.2007.908073
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Osher S., 2004, Geometric Level Set Methods in Imaging
   Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001
   Pham D.D., 2017, VCBM, P113, DOI DOI 10.2312/VCBM.20171243
   Pieper S, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P632
   Ponciano D, 2016, COMPUT GRAPH-UK, V60, P55, DOI 10.1016/j.cag.2016.06.007
   Reh A, 2013, IEEE T VIS COMPUT GR, V19, P2906, DOI 10.1109/TVCG.2013.177
   Riaz F, 2019, IEEE J BIOMED HEALTH, V23, P489, DOI 10.1109/JBHI.2018.2832455
   Roettger S., 2005, Eurographics IEEE VGTC Symposium on Visualization, P271, DOI [10.2312/VisSym/EuroVis05/271-278, DOI 10.2312/VISSYM/EUROVIS05/271-278]
   Roth H.R., 2017, arXiv
   Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214
   Rowe S.P., 2019, Image Processing from 2D to 3D BT, P103, DOI [DOI 10.1007/174_2017_136, 10.1007/978-3-319-42586-3]
   Sakas G, 2002, COMPUT GRAPH-UK, V26, P577, DOI 10.1016/S0097-8493(02)00103-6
   Sapiro G., 2000, Geometric Partial Differential Equations and Image Analysis
   Sereda P, 2006, IEEE T VIS COMPUT GR, V12, P208, DOI 10.1109/TVCG.2006.39
   Sereda P., 2006, Proceedings of Eurographics/IEEE VGTC Symp on Visualization, P243
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Sharma O, 2020, COMPUT GRAPH FORUM, V39, P76, DOI 10.1111/cgf.13663
   Shen EY, 2015, VISUAL COMPUT, V31, P441, DOI 10.1007/s00371-014-0940-7
   Soundararajan KP, 2015, COMPUT GRAPH FORUM, V34, P111, DOI 10.1111/cgf.12623
   Thota R, 2016, ADV INTELL SYST, V390, P11, DOI 10.1007/978-81-322-2625-3_2
   Quan TM, 2018, IEEE T VIS COMPUT GR, V24, P964, DOI 10.1109/TVCG.2017.2744078
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Tzeng F.-Y., 2004, S DATA VISUALISATION, P17, DOI DOI 10.2312/VISSYM/VISSYM04/017-024
   Tzeng FY, 2005, IEEE T VIS COMPUT GR, V11, P273, DOI 10.1109/TVCG.2005.38
   Wang L, 2012, IEEE T VIS COMPUT GR, V18, P121, DOI 10.1109/TVCG.2011.23
   Wang YH, 2012, COMPUT GRAPH FORUM, V31, P1295, DOI 10.1111/j.1467-8659.2012.03122.x
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P330, DOI 10.1109/TVCG.2007.47
   Woo I, 2012, IEEE T VIS COMPUT GR, V18, P1731, DOI 10.1109/TVCG.2012.24
   Xiang DH, 2011, IEEE T VIS COMPUT GR, V17, P1295, DOI 10.1109/TVCG.2010.239
   Yu LN, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139306
NR 66
TC 0
Z9 0
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1651
EP 1663
DI 10.1109/TVCG.2021.3127918
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900004
PM 34780328
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Chao, QW
   Liu, PF
   Han, Y
   Lin, YY
   Li, CE
   Miao, QG
   Jin, XG
AF Chao, Qianwen
   Liu, Pengfei
   Han, Yi
   Lin, Yingying
   Li, Chaoneng
   Miao, Qiguang
   Jin, Xiaogang
TI A Calibrated Force-Based Model for Mixed Traffic Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Roads; Force; Solid modeling; Microscopy; Data
   models; Trajectory; Traffic simulation; simulator; detailed traffic
   flow; heterogeneous; social force
ID ANIMATION; WAVES; FLOW
AB Virtual traffic benefits a variety of applications, including video games, traffic engineering, autonomous driving, and virtual reality. To date, traffic visualization via different simulation models can reconstruct detailed traffic flows. However, each specific behavior of vehicles is always described by establishing an independent control model. Moreover, mutual interactions between vehicles and other road users are rarely modeled in existing simulators. An all-in-one simulator that considers the complex behaviors of all potential road users in a realistic urban environment is urgently needed. In this work, we propose a novel, extensible, and microscopic method to build heterogeneous traffic simulation using the force-based concept. This force-based approach can accurately replicate the sophisticated behaviors of various road users and their interactions in a simple and unified manner. We calibrate the model parameters using real-world traffic trajectory data. The effectiveness of this approach is demonstrated through many simulation experiments, as well as comparisons to real-world traffic data and popular microscopic simulators for traffic animation.
C1 [Chao, Qianwen; Li, Chaoneng; Miao, Qiguang] Xidian Univ, Dept Comp Sci, Xian 710038, Shaanxi, Peoples R China.
   [Liu, Pengfei; Han, Yi; Lin, Yingying; Jin, Xiaogang] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Xidian University; Zhejiang University
RP Chao, QW (corresponding author), Xidian Univ, Dept Comp Sci, Xian 710038, Shaanxi, Peoples R China.; Jin, XG (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM chaoqianwen15@gmail.com; lpengfei@zju.edu.cn; hany28@mail2.sysu.edu.cn;
   missup109@163.com; xdchaonengli@163.com; qgmiao@mail.xidian.edu.cn;
   jin@cad.zju.edu.cn
RI Liu, Pengfei/A-9352-2016
OI Jin, Xiaogang/0000-0001-7339-2920; Han, Yi/0000-0002-9548-7979; li,
   chaoneng/0000-0002-2781-4683; Miao, Qiguang/0000-0002-2872-388X; Liu,
   Pengfei/0000-0003-1160-1242
FU National Natural Science Foundation of China [62036010, 61772396,
   61772392, 61902296]; Key Research and Development Program of Zhejiang
   Province [2020C03096]; National Key R&D Program of China
   [2018YFC0807500]; Xian Key Laboratory of Big Data and Intelligent Vision
   [201805053ZD4CG37]
FX The work of Xiaogang Jin was supported in part by the National Natural
   Science Foundation of China under Grant 62036010 and in part by the Key
   Research and Development Program of Zhejiang Province under Grant
   2020C03096. Qiguang Miao was supported in part by the National Key R & D
   Program of China under Grant 2018YFC0807500, in part by the National
   Natural Science Foundations of China under Grants 61772396, 61772392,and
   61902296, and in part by the Xian Key Laboratory of Big Data and
   Intelligent Vision under Grant 201805053ZD4CG37
CR Adnan M, 2016, PROC 95 ANN M TRANSP
   Aeberhard M, 2015, IEEE INTEL TRANSP SY, V7, P42, DOI 10.1109/MITS.2014.2360306
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Amirian J, 2019, PROCEEDINGS OF THE 32ND INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2019), P7, DOI 10.1145/3328756.3328769
   Anderson SJ, 2011, SPRINGER TRAC ADV RO, V70, P39
   [Anonymous], 2018, AP SIM
   [Anonymous], 2017, NEXT GEN SIM
   [Anonymous], 2018, VISS
   Aw A, 2000, SIAM J APPL MATH, V60, P916, DOI 10.1137/S0036139997332099
   BANDO M, 1995, PHYS REV E, V51, P1035, DOI 10.1103/PhysRevE.51.1035
   Berseth G., 2016, SIMULATING HETEROGEN, P229
   Best A, 2018, IEEE COMPUT SOC CONF, P1161, DOI 10.1109/CVPRW.2018.00152
   Bi H., 2016, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P149
   Chao QW, 2018, IEEE T VIS COMPUT GR, V24, P1167, DOI 10.1109/TVCG.2017.2648790
   Chao QW, 2015, COMPUT ANIMAT VIRT W, V26, P405, DOI 10.1002/cav.1654
   Chao QW, 2013, GRAPH MODELS, V75, P305, DOI 10.1016/j.gmod.2013.07.003
   Cheu RL, 1998, J TRANSP ENG-ASCE, V124, P526, DOI 10.1061/(ASCE)0733-947X(1998)124:6(526)
   Chu LY, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 & 2, P1574
   Cosgun A, 2016, IEEE ROMAN, P562, DOI 10.1109/ROMAN.2016.7745174
   Dosovitskiy G., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Erdmann J, 2015, LECT N MOBIL, P105, DOI 10.1007/978-3-319-15024-6_7
   Garcia-Dorado I, 2014, COMPUT GRAPH FORUM, V33, P411, DOI 10.1111/cgf.12329
   Gerlough D. L., 1955, THESIS U CALIFORNIA
   Guy S.J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA'09, P177
   Guy S.J., 2011, P 2011 ACM SIGGRAPH, P43, DOI DOI 10.1145/2019406.2019413
   Guy SJ, 2012, PHYS REV E, V85, DOI 10.1103/PhysRevE.85.016110
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hourdakis J, 2003, TRANSPORT RES REC, P130
   Huang XY, 2020, IEEE T PATTERN ANAL, V42, P2702, DOI 10.1109/TPAMI.2019.2926463
   Jordao K, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12316
   Ju E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866162
   Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10
   Kesting A, 2009, TRAFFIC AND GRANULAR FLOW '07, P117, DOI 10.1007/978-3-540-77074-9_10
   Kesting A, 2008, TRANSPORT RES REC, P148, DOI 10.3141/2088-16
   Kim Manmyung, 2012, P ACM SIGGRAPH EUROG, P117
   Kim S, 2016, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2016.7504685
   Kim Sujeong, 2012, P ACM SIGGRAPH S INT, P55, DOI [DOI 10.1145/2159616.2159626, 10.1145/2159616.2159626]
   Koh PP, 2014, ACCIDENT ANAL PREV, V62, P178, DOI 10.1016/j.aap.2013.09.020
   Krajzewicz D., 2012, International journal on advances in systems and measurements, V5
   Lebacque JP, 2007, Transportation and Traffic Theory 2007, V2007, P755
   Lee J, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274510
   Lee KH, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P109
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li WZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130847
   Li Y., 2012, Eurographics Symposium on Computer Animation, P201
   LIGHTHILL MJ, 1955, PROC R SOC LON SER-A, V229, P317, DOI 10.1098/rspa.1955.0089
   Likhachev M, 2009, INT J ROBOT RES, V28, P933, DOI 10.1177/0278364909340445
   Ngoduy D, 2011, TRANSPORTMETRICA, V7, P111, DOI 10.1080/18128600903251334
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Payne H. J., 1971, Model of freeway Traffic and Control, P51
   Pelechano N., 2016, Simulating heterogeneous crowds with interactive behaviors
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Rahman M, 2013, IEEE T INTELL TRANSP, V14, P1942, DOI 10.1109/TITS.2013.2272074
   Ren JP, 2021, IEEE T VIS COMPUT GR, V27, P1953, DOI 10.1109/TVCG.2019.2946769
   RICHARDS PI, 1956, OPER RES, V4, P42, DOI 10.1287/opre.4.1.42
   Sewall J, 2010, COMPUT GRAPH FORUM, V29, P439, DOI 10.1111/j.1467-8659.2009.01613.x
   Sewall J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024169
   Sewall J, 2011, IEEE T VIS COMPUT GR, V17, P26, DOI 10.1109/TVCG.2010.27
   Shen JJ, 2012, GRAPH MODELS, V74, P265, DOI 10.1016/j.gmod.2012.04.002
   Toledo T, 2003, TRANSPORT RES REC, P30
   Treiber M., 2001, Automatisierungstechnik, V49, P478, DOI 10.1524/auto.2001.49.11.478
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Wan BH, 2004, TRANSPORT RES REC, P58
   Wang H, 2014, 2014 IEEE VIRTUAL REALITY (VR), P123, DOI 10.1109/VR.2014.6802082
   Whitham G.B., 1974, Pure and Applied Mathematics
   Wilkie D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462021
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Yersin Barbara, 2009, Proceedings of the 2009 symposium on interactive 3d graphics and games, P207, DOI [DOI 10.1145/1507149.1507184, 10.1145/1507149.1507184]
   Zhang HM, 2002, TRANSPORT RES B-METH, V36, P275, DOI 10.1016/S0191-2615(00)00050-3
   Zhao M, 2018, COMPUT GRAPH FORUM, V37, P184, DOI 10.1111/cgf.13259
NR 71
TC 6
Z9 6
U1 2
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1664
EP 1677
DI 10.1109/TVCG.2021.3128286
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900005
PM 34784277
DA 2024-11-06
ER

PT J
AU Perez, D
   Shen, YZ
   Li, J
AF Perez, Daniel
   Shen, Yuzhong
   Li, Jiang
TI Mesh Convolutional Networks With Face and Vertex Feature Operators
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Conferences; Portable document format; Indexes; Typesetting; Loading;
   Web sites; Warranties; Geometric deep learning; mesh; classification;
   segmentation; feature selection
AB Deep learning techniques have proven effective in many applications, but these implementations mostly apply to data in one or two dimensions. Handling 3D data is more challenging due to its irregularity and complexity, and there is a growing interest in adapting deep learning techniques to the 3D domain. A recent successful approach called MeshCNN consists of a set of convolutional and pooling operators applied to the edges of triangular meshes. While this approach produced superb results in classification and segmentation of 3D shapes, it can only be applied to edges of a mesh, which can constitute a disadvantage for applications where the focuses are other primitives of the mesh. In this study, we propose face-based and vertex-based operators for mesh convolutional networks. We design two novel architectures based on the MeshCNN network that can operate on faces and vertices of a mesh, respectively. We demonstrate that the proposed face-based architecture outperforms the original MeshCNN implementation in mesh classification and mesh segmentation, setting the new state of the art on benchmark datasets. In addition, we extend the vertex-based operator to fit in the Point2Mesh model for mesh reconstruction from clean, noisy, and incomplete point clouds. While no statistically significant performance improvements are observed, the model training and inference time are reduced by the proposed approach by 91% and 20%, respectively, as compared with the original Point2Mesh model.
C1 [Perez, Daniel; Shen, Yuzhong] Old Dominion Univ, Dept Computat Modeling & Simulat Engn, Norfolk, VA 23529 USA.
   [Li, Jiang] Old Dominion Univ, Dept Elect & Comp Engn, Norfolk, VA 23529 USA.
C3 Old Dominion University; Old Dominion University
RP Perez, D (corresponding author), Old Dominion Univ, Dept Computat Modeling & Simulat Engn, Norfolk, VA 23529 USA.
EM dpere013@odu.edu; yshen@odu.edu; jli@odu.edu
CR Afrose Z, 2016, ADV ENG SOFTW, V91, P36, DOI 10.1016/j.advengsoft.2015.09.003
   [Anonymous], 2017, ACM Trans. Graph, DOI DOI 10.1145/3072959.3073616
   Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652
   Boscaini D, 2016, ADV NEUR IN, V29
   Botsch Mario., 2010, POLYGON MESH PROCESS
   Brock A., 2016, GENERATIVE DISCRIMIN
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2014, PROC 2 INT C LEARN R
   Cao WM, 2020, IEEE ACCESS, V8, P35929, DOI 10.1109/ACCESS.2020.2975067
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   He WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2214, DOI 10.1145/3394486.3403272
   Henaff M, 2015, Arxiv, DOI arXiv:1506.05163
   Hertz A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392471
   Hoppe H., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P189, DOI 10.1145/258734.258843
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Li YY, 2016, ADV NEUR IN, V29
   Lian Z., 2011, EUR WORKSH 3D OBJ RE
   Liu HTD, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392418
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Milano F., 2020, PROC C NEURAL INF PR
   Muzahid AAM, 2021, IEEE-CAA J AUTOMATIC, V8, P1177, DOI 10.1109/JAS.2020.1003324
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Rosenberg S., 1997, The Laplacian on a Riemannian manifold: an introduction to analysis on manifolds, V31
   Sharp N, 2022, Arxiv, DOI arXiv:2012.00888
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Spreemann G, 2020, P TOP DAT AN WORKSH
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Wang S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2231816.2231818
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wiersma R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392437
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu Z, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392379
NR 37
TC 1
Z9 2
U1 0
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1678
EP 1690
DI 10.1109/TVCG.2021.3129156
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900006
PM 34793303
DA 2024-11-06
ER

PT J
AU Kesavan, SP
   Bhatia, H
   Bhatele, A
   Brink, S
   Pearce, O
   Gamblin, T
   Bremer, PT
   Ma, KL
AF Kesavan, Suraj P. P.
   Bhatia, Harsh
   Bhatele, Abhinav
   Brink, Stephanie
   Pearce, Olga
   Gamblin, Todd
   Bremer, Peer-Timo
   Ma, Kwan-Liu
TI Scalable Comparative Visualization of Ensembles of Call Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Codes; Measurement; Tools; Runtime; Libraries; Task analysis; Data
   visualization; Performance analysis; software visualization; visual
   analytics; hierarchical data; coordinated and multiple views
ID PERFORMANCE ANALYSIS; FLOW
AB Optimizing the performance of large-scale parallel codes is critical for efficient utilization of computing resources. Code developers often explore various execution parameters, such as hardware configurations, system software choices, and application parameters, and are interested in detecting and understanding bottlenecks in different executions. They often collect hierarchical performance profiles represented as call graphs, which combine performance metrics with their execution contexts. The crucial task of exploring multiple call graphs together is tedious and challenging because of the many structural differences in the execution contexts and significant variability in the collected performance metrics (e.g., execution runtime). In this paper, we present Ensemble CallFlow to support the exploration of ensembles of call graphs using new types of visualizations, analysis, graph operations, and features. We introduce ensemble-Sankey, a new visual design that combines the strengths of resource-flow (Sankey) and box-plot visualization techniques. Whereas the resource-flow visualization can easily and intuitively describe the graphical nature of the call graph, the box plots overlaid on the nodes of Sankey convey the performance variability within the ensemble. Our interactive visual interface provides linked views to help explore ensembles of call graphs, e.g., by facilitating the analysis of structural differences, and identifying similar or distinct call graphs. We demonstrate the effectiveness and usefulness of our design through case studies on large-scale parallel codes.
C1 [Kesavan, Suraj P. P.; Ma, Kwan-Liu] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Bhatia, Harsh; Brink, Stephanie; Pearce, Olga; Gamblin, Todd; Bremer, Peer-Timo] Lawrence Livermore Natl Lab, Ctr Appl Sci Comp, Livermore, CA 94551 USA.
   [Bhatele, Abhinav] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
C3 University of California System; University of California Davis; United
   States Department of Energy (DOE); Lawrence Livermore National
   Laboratory; University System of Maryland; University of Maryland
   College Park
RP Kesavan, SP (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
EM spkesavan@ucdavis.edu; hbhatia@llnl.gov; bhatele@cs.umd.edu;
   brink2@llnl.gov; pearce8@llnl.gov; tgamblin@llnl.gov; ptbremer@llnl.gov;
   ma@cs.ucdavis.edu
RI Kesavan, Suraj/AAU-1377-2021
OI Kesavan, Suraj/0000-0001-8524-6648; Bhatele,
   Abhinav/0000-0003-3069-3701; Ma, Kwan-Liu/0000-0001-8086-0366; Brink,
   Stephanie/0000-0002-1458-8453; Bremer, Peer-Timo/0000-0003-4107-3831
FU U.S. Department of Energy by Lawrence Livermore National Laboratory
   (LLNL) [DE-AC52-07NA27344]; Department of Energy [DE-SC0014917]; U.S.
   Department of Energy (DOE) [DE-SC0014917] Funding Source: U.S.
   Department of Energy (DOE)
FX This work was supported under the auspices of the U.S. Department of
   Energy by Lawrence Livermore National Laboratory (LLNL) under Grant
   DE-AC52-07NA27344. The UC Davis researchers were also supported in part
   by the Department of Energy under Grant DE-SC0014917. Release No.
   LLNL-JRNL-809459.
CR Adamoli A, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P73
   Adhianto L, 2010, CONCURR COMP-PRACT E, V22, P685, DOI 10.1002/cpe.1553
   Ahn DH, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Amenta N, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P71, DOI 10.1109/INFVIS.2002.1173150
   Ammons G, 1997, ACM SIGPLAN NOTICES, V32, P85, DOI 10.1145/258916.258924
   Andrews K, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P62, DOI 10.1109/IV.2009.108
   Bach B., 2015, COMPUT GRAPH FORUM
   Bergel A., 2017, Programming and Performance Visualization Tools, P233
   Bhatele A, 2020, INT PARALL DISTRIB P, P896, DOI 10.1109/IPDPS47924.2020.00096
   Bhatele A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356219
   Bhatele A, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503247
   Bhatia H, 2022, Arxiv, DOI arXiv:2007.15219
   Boehme David, 2021, High Performance Computing. 36th International Conference, ISC High Performance 2021. Lecture Notes in Computer Science (LNCS 12728), P431, DOI 10.1007/978-3-030-78713-4_23
   Boehme D, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P550, DOI 10.1109/SC.2016.46
   Bremm S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P31, DOI 10.1109/VAST.2011.6102439
   Brink S, 2020, PROCEEDINGS OF 2020 IEEE/ACM INTERNATIONAL WORKSHOP ON HPC USER SUPPORT TOOLS (HUST) AND THE WORKSHOP ON PROGRAMMING AND PERFORMANCE VISUALIZATION TOOLS (PROTOOLS), P49, DOI 10.1109/HUSTProtools51951.2020.00013
   DeRose L, 2007, LECT NOTES COMPUT SC, V4641, P150
   Devkota S, 2018, COMPUT GRAPH FORUM, V37, P453, DOI 10.1111/cgf.13433
   Di Natale F, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356197
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Ellson J, 2004, MATH VIS, P127
   Fu SW, 2018, IEEE T VIS COMPUT GR, V24, P205, DOI 10.1109/TVCG.2017.2744080
   Geimer M, 2010, CONCURR COMP-PRACT E, V22, P702, DOI 10.1002/cpe.1556
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Graham M, 2010, INFORM VISUAL, V9, P235, DOI 10.1057/ivs.2009.29
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   Gregg B, 2016, COMMUN ACM, V59, P48, DOI 10.1145/2909476
   Groves T, 2017, IEEE INT C CL COMP, P809, DOI 10.1109/CLUSTER.2017.76
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Holten D, 2008, COMPUT GRAPH FORUM, V27, P759, DOI 10.1111/j.1467-8659.2008.01205.x
   Hong J. Y., 2003, IEEE S INFOVIS POST
   Huang W, 2006, SIXTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P43
   Nguyen HT, 2021, IEEE T VIS COMPUT GR, V27, P2455, DOI 10.1109/TVCG.2019.2953746
   Huu Tan Nguyen, 2016, 2016 Third Workshop on Visual Performance Analysis (VPA), P25, DOI 10.1109/VPA.2016.009
   Isaacs K.E., 2014, EuroVis
   Isaacs KE, 2019, IEEE T VIS COMPUT GR, V25, P2804, DOI 10.1109/TVCG.2018.2859974
   Costello IJ, 2020, Arxiv, DOI arXiv:2007.03451
   Karlin I., 2012, LULESH Programming Model and Performance Ports Overview, P1
   Kesavan S. P, 2020, PROC INT C HIGH PERF
   Knüpfer A, 2008, TOOLS FOR HIGH PERFORMANCE COMPUTING, P139, DOI 10.1007/978-3-540-68564-7_9
   Kruskal J. B, 1983, AM STAT
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   Liu ZP, 2020, IEEE T VIS COMPUT GR, V26, P2732, DOI 10.1109/TVCG.2019.2898186
   Lockwood GK, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Malik MM, 2010, IEEE T VIS COMPUT GR, V16, P829, DOI 10.1109/TVCG.2010.20
   McKinney W., 2010, P 9 PYTH SCI C, DOI 10.25080/majora-92bf1922-00a
   Meyer M, 2009, IEEE T VIS COMPUT GR, V15, P897, DOI 10.1109/TVCG.2009.167
   Mohr B, 2003, LECT NOTES COMPUT SC, V2790, P1301
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Norman ML, 2018, FRONT ASTRON SPACE, V5, DOI 10.3389/fspas.2018.00034
   Petrini Fabrizio, 2003, P 2003 ACM IEEE C SU, P55, DOI DOI 10.1109/SC.2003.10010
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Shende SS, 2006, INT J HIGH PERFORM C, V20, P287, DOI 10.1177/1094342006064482
   Smith J. C, 2020, REPURPOSING THERAPEU, DOI [DOI 10.26434/CHEMRXIV.11871402.V4, 10.26434/chemrxiv.11871402.v3]
   Telea A, 2008, COMPUT GRAPH FORUM, V27, P831, DOI 10.1111/j.1467-8659.2008.01214.x
   Trümper J, 2013, CONF PROC INT SYMP C, P53, DOI 10.1109/ICPC.2013.6613833
   van Beusekom N, 2022, IEEE T VIS COMPUT GR, V28, P1, DOI 10.1109/TVCG.2021.3114773
   Vosough Z, 2019, J COMPUT LANG, V52, P44, DOI 10.1016/j.cola.2019.03.002
   Williams K., 2019, Visualizing a Moving Target: A Design Study on Task Parallel Programs in the Presence of Evolving Data and Concerns
   Wright N. J., 2009, Proceedings of the 2009 DoD High Performance Computing Modernization Program Users Group Conference (HPCMP-UGC 2009), P438, DOI 10.1109/HPCMP-UGC.2009.72
   Zhao J, 2012, IEEE T VIS COMPUT GR, V18, P2639, DOI 10.1109/TVCG.2012.226
NR 65
TC 4
Z9 8
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1691
EP 1704
DI 10.1109/TVCG.2021.3129414
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900007
PM 34797765
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lin, J
   Cai, Y
   Wu, X
   Lu, JW
AF Lin, Jie
   Cai, Yi
   Wu, Xin
   Lu, Jianwei
TI Graph-Based Information Block Detection in Infographic With Gestalt
   Organization Principles
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature extraction; Visualization; Data visualization; Semantics;
   Organizations; Layout; Task analysis; Infographic; deep learning;
   graph-based approach; information block detection
ID RECOGNITION; PSYCHOLOGY
AB An infographic is a type of visualization chart that displays pieces of information through information blocks. Existing information block detection work utilizes spatial proximity to group elements into several information blocks. However, prior studies ignore the chromatic and structural features of the infographic, resulting in incorrect omissions when detecting information blocks. To alleviate this kind of error, we use a scene graph to represent an infographic and propose a graph-based information block detection model to group elements based on Gestalt Organization Principles (spatial proximity, chromatic similarity, and structural similarity principle). We also construct a new dataset for information block detection. Quantitative and qualitative experiments show that our model can detect the information blocks in the infographic more effectively compared with the spatial proximity-based method.
C1 [Lin, Jie; Cai, Yi; Wu, Xin; Lu, Jianwei] South China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Lin, Jie; Cai, Yi; Wu, Xin; Lu, Jianwei] SouthChina Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou 510641, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology
RP Cai, Y (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.; Cai, Y (corresponding author), SouthChina Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou 510641, Guangdong, Peoples R China.
EM se_jielin@mail.scut.edu.cn; ycai@scut.edu.cn; sexinwu@mail.scut.edu.cn;
   jianweilu@mail.scut.edu.cn
FU National Natural Science Foundation of China [62076100, 61802130];
   National Key Research and Development Program of China; Guang-dong
   Natural Science Foundation [2019A1515012152]; Fundamental Research Funds
   for the Central Universities, SCUT [D2201300, D2210010]; Science and
   Technology Programs of Guangzhou [201902010046]; Science and Technology
   Planning Project of Guangdong Province [2020B0101100002]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62076100 and 61802130, National Key Research and
   Development Program of China (Standard knowledge graph for epidemic
   prevention and production recovering intelligent service platform and
   its applications), Guang-dong Natural Science Foundation under Grant
   2019A1515012152, the Fundamental Research Funds for the Central
   Universities, SCUT under Grants D2201300 and D2210010, the Science and
   Technology Programs of Guangzhou under Grant 201902010046, and the
   Science and Technology Planning Project of Guangdong Province under
   Grant 2020B0101100002.
CR Agarwal A, 2020, Arxiv, DOI arXiv:2005.08045
   [Anonymous], 2016, 5 INT C LEARN REPR
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Bresler M, 2016, INT J DOC ANAL RECOG, V19, P253, DOI 10.1007/s10032-016-0269-z
   Bylinskii Z, 2017, Arxiv, DOI arXiv:1709.09215
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chen L, 2019, IEEE I CONF COMP VIS, P4612, DOI 10.1109/ICCV.2019.00471
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   de Koning BB, 2009, EDUC PSYCHOL REV, V21, P113, DOI 10.1007/s10648-009-9098-7
   Desolneux A, 2004, THEORY DECIS LIB A, V38, P71
   Fu X, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P126, DOI [10.1109/visual.2019.8933570, 10.1109/VISUAL.2019.8933570]
   Gaur M, 2021, IEEE INTERNET COMPUT, V25, P51, DOI 10.1109/MIC.2020.3031769
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Li K, 2018, LECT NOTES COMPUT SC, V11212, P593, DOI 10.1007/978-3-030-01237-3_36
   Li YK, 2018, LECT NOTES COMPUT SC, V11205, P346, DOI 10.1007/978-3-030-01246-5_21
   Lin T.-Y., 2017, P IEEE C COMPUTER VI, P2117
   Liu TF, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P569, DOI 10.1145/3242587.3242650
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Madan S, 2018, Arxiv, DOI arXiv:1807.10441
   Oyama T., 1961, Perceptual and Motor Skills, V13, P305, DOI DOI 10.2466/PMS.1961.13.3.305
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sakuragi Yuki, 2016, International Journal of Computer Theory and Engineering, V8, P74, DOI 10.7763/IJCTE.2016.V8.1023
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Tong W., 2020, PROC CHI C HUM FACTO, P1
   Velickovic Petar, 2018, ICLR 2018
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wagemans J, 2012, PSYCHOL BULL, V138, P1218, DOI 10.1037/a0029334
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Williams Robin, 2015, NONDESIGNERS DESIGN
   Xia Xide, 2017, ARXIV171108506
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang J., 2019, PROC IEEE C COMPUT V, p11 535
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhuo Li, 2014, Natural Language Processing and Information Systems. 19th International Conference on Applications of Natural Language to Information Systems, NLDB 2014. Proceedings: LNCS 8455, P101
NR 55
TC 3
Z9 3
U1 5
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1705
EP 1718
DI 10.1109/TVCG.2021.3130071
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900008
PM 34813475
DA 2024-11-06
ER

PT J
AU Lan, J
   Zhou, Z
   Wang, JC
   Zhang, H
   Xie, X
   Wu, YC
AF Lan, Ji
   Zhou, Zheng
   Wang, Jiachen
   Zhang, Hui
   Xie, Xiao
   Wu, Yingcai
TI SimuExplorer: Visual Exploration of Game Simulation in Table Tennis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports; Markov processes; Visualization; Analytical models; Tools; Task
   analysis; Software; Sports visualization; game simulation; model
   interpretation; etc
ID INTERACTIVE VISUALIZATION; ANALYTICS; MOVEMENT; MODEL; VIDEO
AB We propose SimuExplorer, a visualization system to help analysts explore how player behaviors impact scoring rates in table tennis. Such analysis is indispensable for analysts and coaches, who aim to formulate training plans that can help players improve. However, it is challenging to identify the impacts of individual behaviors, as well as to understand how these impacts are generated and accumulated gradually over the course of a game. To address these challenges, we worked closely with experts who work for a top national table tennis team to design SimuExplorer. The SimuExplorer system integrates a Markov chain model to simulate individual and cumulative impacts of particular behaviors. It then provides flow and matrix views to help users visualize and interpret these impacts. We demonstrate the usefulness of the system with case studies and expert interviews. The experts think highly of the system and have obtained insights into players' behaviors using it.
C1 [Lan, Ji; Wang, Jiachen; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhou, Zheng; Zhang, Hui; Xie, Xiao] Zhejiang Univ, Dept Sport Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.; Xie, X (corresponding author), Zhejiang Univ, Dept Sport Sci, Hangzhou 310027, Zhejiang, Peoples R China.
EM lanjizju@zju.edu.cn; zhouzhengzju@zju.edu.cn; wangjiachen@zju.edu.cn;
   zhang_hui@zju.edu.cn; xxie@zju.edu.cn; ycwu@zju.edu.cn
RI wang, yixuan/JGM-3893-2023; Wang, Jiachen/KIK-8161-2024; 张,
   智浩/KIC-8136-2024; LAN, JI/M-2006-2018
OI Wang, Jiachen/0000-0001-9630-9958; LAN, JI/0000-0002-8658-8620; ,
   Hui/0000-0003-0601-3905
FU NSFC [62072400]; Zhejiang Provincial Natural Science Foundation
   [LR18F020001]; Collaborative Innovation Center of Artificial
   Intelligence by MOE; Zhejiang Provincial Government (ZJU); Key Research
   Projectof Zhejiang Lab [2021KE0AC02]
FX The work was supported by NSFC under Grant 62072400 Zhejiang Provincial
   Natural Science Foundation under Grant LR18F020001 and the Collaborative
   Innovation Center of Artificial Intelligence by MOE and Zhejiang
   Provincial Government (ZJU). This work was also supported by the Key
   Research Projectof Zhejiang Lab under Grant 2021KE0AC02
CR Andrienko N, 2021, VIS INFORM, V5, P23, DOI 10.1016/j.visinf.2020.12.002
   [Anonymous], 2011, IEEE VISWEEK WORKSH
   Cao RC, 2020, VIS INFORM, V4, P8, DOI 10.1016/j.visinf.2019.12.002
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Franks A., 2015, SLOAN SPORTS ANALYTI
   Ishikawa Y, 2018, VIS INFORM, V2, P60, DOI 10.1016/j.visint2018.04.007
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Jin LQ, 1996, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION '96, PROCEEDINGS, P108, DOI 10.1109/INFVIS.1996.559229
   Kim W, 2021, J VISUAL-JAPAN, V24, P1033, DOI 10.1007/s12650-021-00758-y
   Lage M, 2016, IEEE COMPUT GRAPH, V36, P28, DOI 10.1109/MCG.2016.101
   Lames M., 2007, International Journal of Performance Analysis in Sport, V7, P62, DOI DOI 10.1080/24748668.2007.11868388
   Lan J, 2022, J VISUAL-JAPAN, V25, P143, DOI 10.1007/s12650-021-00772-0
   Lanzoni IM, 2014, EUR J SPORT SCI, V14, P309, DOI 10.1080/17461391.2013.819382
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Leite RA, 2020, VIS INFORM, V4, P11, DOI 10.1016/j.visinf.2020.09.006
   Loh TzeChien., 2015, Journal of Physical Education Sport, V15, P829
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   Lu JH, 2019, VIS INFORM, V3, P87, DOI 10.1016/j.visinf.2019.06.002
   Parry ML, 2011, IEEE T VIS COMPUT GR, V17, P1747, DOI 10.1109/TVCG.2011.208
   Perin C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P887, DOI 10.1145/2556288.2557379
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pfeiffer M, 2010, INT J SPORTS SCI COA, V5, P205, DOI 10.1260/1747-9541.5.2.205
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Pretorius AJ, 2008, COMPUT GRAPH FORUM, V27, P967, DOI 10.1111/j.1467-8659.2008.01231.x
   Pretorius AJ, 2006, IEEE T VIS COMPUT GR, V12, P685, DOI 10.1109/TVCG.2006.192
   Robinson A.H., 1955, Geogr. J, V121, P440, DOI DOI 10.2307/1791753
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Tan DS, 2007, IEEE T VIS COMPUT GR, V13, P1113, DOI 10.1109/TVCG.2007.70537
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   van Ham F, 2002, IEEE T VIS COMPUT GR, V8, P319, DOI 10.1109/TVCG.2002.1044518
   Voorhees AM, 2013, TRANSPORTATION, V40, P1105, DOI 10.1007/s11116-013-9487-0
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P475, DOI 10.1109/TVCG.2021.3114790
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wenninger S., 2016, Int J Comput Sci Sport, V15, P22, DOI [10.1515/ijcss-2016-0002, DOI 10.1515/IJCSS-2016-0002]
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zhang H, 2013, J SPORT SCI, V31, P1526, DOI [10.1080/02640414.2013.792948, 10.1080/02640414.2013.805885]
   Zhang Y, 2021, J VISUAL-JAPAN, V24, P117, DOI 10.1007/s12650-020-00694-3
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
NR 54
TC 1
Z9 1
U1 5
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1719
EP 1732
DI 10.1109/TVCG.2021.3130422
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900009
PM 34818191
DA 2024-11-06
ER

PT J
AU Kouril, D
   Strnad, O
   Mindek, P
   Halladjian, S
   Isenberg, T
   Gröller, ME
   Viola, I
AF Kouril, David
   Strnad, Ondrej
   Mindek, Peter
   Halladjian, Sarkis
   Isenberg, Tobias
   Groller, M. Eduard
   Viola, Ivan
TI Molecumentary: Adaptable Narrated Documentaries Using Molecular
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Cameras; Three-dimensional displays;
   Animation; Real-time systems; Solid modeling; Virtual tour; audio;
   biological data; storytelling; illustrative visualization
ID EXPLORANATION; TOOL
AB We present a method for producing documentary-style content using real-time scientific visualization. We introduce molecumentaries, i.e., molecular documentaries featuring structural models from molecular biology, created through adaptable methods instead of the rigid traditional production pipeline. Our work is motivated by the rapid evolution of scientific visualization and it potential in science dissemination. Without some form of explanation or guidance, however, novices and lay-persons often find it difficult to gain insights from the visualization itself. We integrate such knowledge using the verbal channel and provide it along an engaging visual presentation. To realize the synthesis of a molecumentary, we provide technical solutions along two major production steps: (1) preparing a story structure and (2) turning the story into a concrete narrative. In the first step, we compile information about the model from heterogeneous sources into a story graph. We combine local knowledge with external sources to complete the story graph and enrich the final result. In the second step, we synthesize a narrative, i.e., story elements presented in sequence, using the story graph. We then traverse the story graph and generate a virtual tour, using automated camera and visualization transitions. We turn texts written by domain experts into verbal representations using text-to-speech functionality and provide them as a commentary. Using the described framework, we synthesize fly-throughs with descriptions: automatic ones that mimic a manually authored documentary or semi-automatic ones which guide the documentary narrative solely through curated textual input.
C1 [Kouril, David] Masaryk Univ, Brno 60177, Czech Republic.
   [Kouril, David] TU Wien, A-040 Vienna, Austria.
   [Strnad, Ondrej; Viola, Ivan] King Abdullah Univ Sci & Technol KAUST, Thuwal 23955, Saudi Arabia.
   [Mindek, Peter] TU Wien, A-1040 Vienna, Austria.
   [Mindek, Peter] Nanograph GmbH, A-1040 Vienna, Austria.
   [Halladjian, Sarkis; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LISN, F-91190 Gif Sur Yvette, France.
   [Groller, M. Eduard] TU Wien, A-1220 Vienna, Austria.
   [Groller, M. Eduard] VRVis Res Ctr, A-1220 Vienna, Austria.
C3 Masaryk University Brno; Technische Universitat Wien; King Abdullah
   University of Science & Technology; Technische Universitat Wien;
   Universite Paris Saclay; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS); Inria; Technische Universitat Wien
RP Kouril, D (corresponding author), Masaryk Univ, Brno 60177, Czech Republic.; Kouril, D (corresponding author), TU Wien, A-040 Vienna, Austria.
EM dvdkouril@cg.tuwien.ac.at; ondrej.strnad@kaust.edu.sa;
   mindek@cg.tuwien.ac.at; sarkis.halladjian@inria.fr;
   tobias.isenberg@inria.fr; groeller@cg.tuwien.ac.at;
   ivan.viola@kaust.edu.sa
RI Strnad, Ondřej/GXV-9172-2022; Isenberg, Tobias/A-7575-2008; Viola,
   Ivan/O-8944-2014
OI Isenberg, Tobias/0000-0001-7953-8644; Strnad,
   Ondrej/0000-0002-8077-4692; Kouril, David/0000-0003-4043-3487; Viola,
   Ivan/0000-0003-4248-6574
FU ILLUSTRARE grant; Austrian Science Fund (FWF) [I 2953-N31]; French
   National Research Agency (ANR) [ANR-16-CE91-0011-01]; King Abdullah
   University of Science and Technology [BAS/1/1680-01-01]; LLVISATION
   grant; WWTF [VRG11-010]; COMET [879730]; FFG; Agence Nationale de la
   Recherche (ANR) [ANR-16-CE91-0011] Funding Source: Agence Nationale de
   la Recherche (ANR)
FX This work was supported in part by the ILLUSTRARE grant by both the
   Austrian Science Fund (FWF): I 2953-N31 and the French National Research
   Agency (ANR): ANR-16-CE91-0011-01 in part by the King Abdullah
   University of Science and Technology under Grant BAS/1/1680-01-01 and
   the ILLVISATION grant by WWTF (VRG11-010). This paper was partly written
   in collaboration with VRVis funded in COMET under Grant 879730 a program
   managed by FFG.
CR Akiba H, 2010, IEEE COMPUT GRAPH, V30, P61, DOI 10.1109/MCG.2009.107
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2009, P INT C SMART CIT AP, DOI DOI 10.1145/1599470.1599478
   [Anonymous], 2015, P 31 SPRING C COMPUT, DOI DOI 10.1145/2788539.2788549
   Autin L, 2020, MolVa (2020), V2020, P23, DOI 10.2312/molva.20201098
   Birkeland Å, 2012, COMPUT GRAPH FORUM, V31, P905, DOI 10.1111/j.1467-8659.2012.03083.x
   BLINN J, 1988, IEEE COMPUT GRAPH, V8, P76, DOI 10.1109/38.7751
   Bock A, 2020, IEEE T VIS COMPUT GR, V26, P633, DOI 10.1109/TVCG.2019.2934259
   Burtnyk N., 2006, Proc. of Symposium on Interactive 3D Graphics and Games, P167
   Burtnyk N., 2002, P 15 ANN ACM S US IN, P101, DOI [10.1145/571985.572000, DOI 10.1145/571985.572000]
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Christie M, 2005, LECT NOTES COMPUT SC, V3638, P40
   Christie M, 2008, COMPUT GRAPH FORUM, V27, P2197, DOI 10.1111/j.1467-8659.2008.01181.x
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Daly C, 2014, MICROSC ANAL, V28, P7
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Fujiwara T, 2018, VIS INFORM, V2, P213, DOI 10.1016/j.visinf.2018.12.002
   Galvane Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181975
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Glassner Andrew., 2001, Vir- tual Storytelling Using Virtual Reality Technologies for Storytelling, P51, DOI [10.1007/3-540-45420-97, DOI 10.1007/3-540-45420-97]
   Google, CLOUD TEXT TO SPEECH
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Höst G, 2020, IEEE COMPUT GRAPH, V40, P32, DOI 10.1109/MCG.2020.2973120
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iwasa J, 2014, MOL BIOL CELL, V25, P2891, DOI 10.1091/mbc.E14-01-0699
   Johnson GT, 2015, NAT METHODS, V12, P85, DOI [10.1038/NMETH.3204, 10.1038/nmeth.3204]
   Johnson GT, 2014, FARADAY DISCUSS, V169, P23, DOI 10.1039/c4fd00017j
   Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27
   Karpe R., 2018, INT J RES APPL SCI E, V6, P351, DOI DOI 10.22214/IJRASET.2018.3054
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kouril D, 2021, IEEE T VIS COMPUT GR, V27, P3493, DOI 10.1109/TVCG.2020.2975583
   Kwon B. C., 2014, P COMP JOURN S, P1
   LCL, 2010, ACM SIGGRAPH EUROGRA, P139, DOI [DOI 10.2312/SCA/SCA10/139-148, 10.2312/SCA/SCA10/139-148]
   Le Muzic M, 2016, COMPUT GRAPH FORUM, V35, P161, DOI 10.1111/cgf.12892
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Li W, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239482
   Liao Isaac, 2014, Smart Graphics. 12th International Symposium (SG 2014). Proceedings: LNCS 8698, P1, DOI 10.1007/978-3-319-11650-1_1
   Lidal E. M., 2012, P INT S SKETCH BAS I, P11, DOI DOI 10.2312/SBM/SBM12/011-020
   Lorensen W. E., 1993, Proceedings Visualization '93. (Cat. No.93CH3354-8), P268, DOI 10.1109/VISUAL.1993.398878
   Ma J, 2012, IEEE T VIS COMPUT GR, V18, P2799, DOI 10.1109/TVCG.2012.244
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   MADHYASTHA TM, 1995, IEEE SOFTWARE, V12, P45, DOI 10.1109/52.368264
   McCrae James., 2009, P 2009 S INT 3D GRAP, P7, DOI [10.1145/1507149.1507151, DOI 10.1145/1507149.1507151]
   Mindek P, 2018, IEEE T VIS COMPUT GR, V24, P883, DOI 10.1109/TVCG.2017.2744518
   Munzner T., 2014, AK Peters Visualization Series
   Nägeli T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073712
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   Perlin K, 2005, LECT NOTES COMPUT SC, V3805, P135, DOI 10.1007/11590361_16
   Preim B, 1997, PROC GRAPH INTERF, P105
   Preim B, 2020, COMPUT GRAPH-UK, V90, P145, DOI 10.1016/j.cag.2020.06.003
   Q. Company, QT SPEECH
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   Salomon B., 2003, Proceedings of the 2003 symposium on Interactive 3D graphics, P41
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Siddhi D., 2017, INT J COMPUT APPL, V165, P26, DOI [DOI 10.5120/IJCA2017913891, 10.5120/ijca2017913891]
   Sorger J., 2017, PROC SPRING C COMPUT, P27, DOI DOI 10.1145/3154353.3154364
   Thöny M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030123
   TIEDE U, 1993, AM J NEURORADIOL, V14, P551
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   van Wijk JJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P15, DOI 10.1109/INFVIS.2003.1249004
   Varner J, 2014, BIOSCIENCE, V64, P333, DOI 10.1093/biosci/biu021
   Vázquez PP, 2008, INT J COMPUT ASS RAD, V3, P511, DOI 10.1007/s11548-008-0251-4
   Viola I, 2005, Computational aesthetics in graphics, visualization and imaging, P209, DOI DOI 10.2312/COMPAESTH/COMPAESTH05/209-216
   Wernert E.A., 1997, SCI VISUALIZATION C, P95
   Wilson C. M., 1996, PROC ANN INT C AUDIT
   Wohlfart Michael., 2007, P JOINT EUROGRAPHICS, P91, DOI [DOI 10.2312/VISSYM/EUROVIS07/091-098, 10.2312/VisSym/EuroVis07/091-098]
   Ynnerman A, 2018, IEEE COMPUT GRAPH, V38, P13, DOI 10.1109/MCG.2018.032421649
   Zhang XL, 2009, VIRTUAL REAL-LONDON, V13, P101, DOI 10.1007/s10055-009-0114-5
NR 70
TC 11
Z9 11
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1733
EP 1747
DI 10.1109/TVCG.2021.3130670
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900010
PM 34822330
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Hashemian, AM
   Adhikari, A
   Kruijff, E
   von der Heyde, M
   Riecke, BE
AF Hashemian, Abraham M. M.
   Adhikari, Ashu
   Kruijff, Ernst
   von der Heyde, Markus
   Riecke, Bernhard E. E.
TI Leaning-Based Interfaces Improve Ground-Based VR Locomotion in
   Reach-the-Target, Follow-the-Path, and Racing Tasks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Legged locomotion; Navigation; User experience;
   Usability; Throughput; Brakes; 3D user interface; motion sickness;
   cybersickness; locomotion; travel techniques; virtual reality
ID ORIENTATION; TRAVEL
AB Using standard handheld interfaces for VR locomotion may not provide a believable self-motion experience and can contribute to unwanted side effects such as motion sickness, disorientation, or increased cognitive load. This paper demonstrates how using a seated leaning-based locomotion interface -HeadJoystick- in VR ground-based navigation affects user experience, usability, and performance. In three within-subject studies, we compared controller (touchpad/thumbstick) with a more embodied interface ( "HeadJoystick ") where users moved their head and/or leaned in the direction of desired locomotion. In both conditions, users sat on a regular office chair and used it to control virtual rotations. In the first study, 24 participants used HeadJoystick versus Controller in three complementary tasks including reach-the-target, follow-the-path, and racing (dynamic obstacle avoidance). In the second study, 18 participants repeatedly used HeadJoystick versus Controller (8 one-minute trials each) in a reach-the-target task. To evaluate potential benefits of different brake mechanisms, in the third study 18 participants were asked to stop within each target area for one second. All three studies consistently showed advantages of HeadJoystick over Controller: we observed improved performance in all tasks, as well as higher user ratings for enjoyment, spatial presence, immersion, vection intensity, usability, ease of learning, ease of use, and rated potential for daily and long-term use, while reducing motion sickness and task load. Overall, our results suggest that leaning-based interfaces such as HeadJoystick provide an interesting and more embodied alternative to handheld interfaces in driving, reach-the-target, and follow-the-path tasks, and potentially a wider range of scenarios.
C1 [Hashemian, Abraham M. M.; Adhikari, Ashu; Kruijff, Ernst; von der Heyde, Markus; Riecke, Bernhard E. E.] Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, D-53757 Bonn, Germany.
   [von der Heyde, Markus] Simon Fraser Univ, VdH IT, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University; Hochschule Bonn Rhein Sieg; Simon Fraser
   University
RP Hashemian, AM (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
EM hashemia@sfu.ca; ashua@sfu.ca; ernst.kruijff@h-brs.de; info@vdh-it.de;
   ber1@sfu.ca
RI von der Heyde, Markus/HJA-0319-2022; Riecke, Bernhard/C-6399-2011
OI Kruijff, Ernst/0000-0003-1625-0955; von der Heyde,
   Markus/0000-0002-6026-082X; Hashemian, Abraham M./0000-0001-8385-4332;
   Riecke, Bernhard/0000-0001-7974-0850; Adhikari, Ashu/0000-0002-2540-6344
CR Accot Johnny, 1997, P ACM SIGCHI C HUM F, P295, DOI [10.1145/258549.258760, DOI 10.1145/258549.258760]
   Adhikari A., 2021, PROC 8 INT SPATIAL C
   Adhikari A., 2021, THESIS S FRASER U
   Adhikari A., 2021, FRONT VIRTUAL REALIT
   Aloraini SM, 2020, J MOTOR BEHAV, V52, P97, DOI 10.1080/00222895.2019.1582472
   [Anonymous], 2014, P 2 ACM S SPAT US IN
   Anthes C, 2016, IEEE AEROSPACE C IEE
   Badcock DR, 2015, HUM FACTORS ERGON, P39
   Beckhaus S., 2005, P COMPUT SCI MAGIC
   Beckhaus Steffi., 2005, New Directions in 3D User Interfaces Workshop of IEEE VR, P57
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Bowman D. A., 1999, Ph.D. dissertation
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cardoso JCS, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P319, DOI 10.1145/2993369.2996327
   Carifio J, 2008, MED EDUC, V42, P1150, DOI 10.1111/j.1365-2923.2008.03172.x
   Carraro G. U., 1998, Proceedings. VRML 98 Third Symposium on the Virtual Reality Modeling Language, P63, DOI 10.1145/271897.274372
   Chester MR, 2002, INT J IND ERGONOM, V29, P289, DOI 10.1016/S0169-8141(01)00069-5
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   FAIRCHILD KM, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P47, DOI 10.1109/VRAIS.1993.380799
   Farrell MJ, 1998, J EXP PSYCHOL LEARN, V24, P227, DOI 10.1037/0278-7393.24.1.227
   Feng Changyong, 2014, Shanghai Arch Psychiatry, V26, P105, DOI 10.3969/j.issn.1002-0829.2014.02.009
   Fikkert W, 2010, INT J ARTS TECHNOL, V3, P357, DOI 10.1504/IJART.2010.035827
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Freiberg J., 2015, THESIS S FRASER U CA
   Fuhrmann A., 1998, Virtual Environments '98. Proceedings of the Eurographics Workshop, P216
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Hale K., 2015, HDB VIRTUAL ENV DESI
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hashemian A. M., 2017, Swivel-chair: Evaluating seated full-rotational interfaces for virtual reality navigation
   Hashemian AM, 2022, IEEE T VIS COMPUT GR, V28, P1792, DOI 10.1109/TVCG.2020.3025084
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Jerald J., 2016, VR BOOK HUMAN CENTER, VFirst
   Jia Wang, 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P31, DOI 10.1109/3DUI.2012.6184181
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kruijff E., 2016, P ACM S SPAT US INT, P149
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lee WS, 1998, IEEE INT CONF ROBOT, P71, DOI 10.1109/ROBOT.1998.676264
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   McKenzie S., 2018, Handbook of Human-Computer Interaction, V1, P349, DOI [DOI 10.1002/9781118976005.CH17, 10.1002/9781118976005.ch17]
   McMahan R. P., 2011, THESIS STATE U US
   McMahan RP, 2015, HUM FACTORS ERGON, P285
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Miehlbradt J, 2018, P NATL ACAD SCI USA, V115, P7913, DOI 10.1073/pnas.1718648115
   Mine M. R, 1995, TR95018 U N CAR CHAP
   Nehaoua L, 2008, IEEE T VEH TECHNOL, V57, P736, DOI 10.1109/TVT.2007.905336
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Nguyen-Vo T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P415, DOI 10.1109/VR.2018.8446383
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Norman G, 2010, ADV HEALTH SCI EDUC, V15, P625, DOI 10.1007/s10459-010-9222-y
   Otte M., 2011, J VIRTUAL WORLDS RES, V4
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Ramcharitar Adrian, 2017, P 2017 CHI C HUM FAC, P2860, DOI [10.1145/3027063.3053213, DOI 10.1145/3027063.3053213]
   Reason J.T., 1975, Motion Sickness
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2012, vection") in virtual reality?, P17
   Riecke B. E., 2015, P 3 S SPAT US INT LO, P123, DOI DOI 10.1145/2788940.2788956
   Riecke B.E., 2006, P ACM S VIRTUAL REAL, P104, DOI [10.1145/1180495.1180517, DOI 10.1145/1180495.1180517, 10.1145/ 1180495.1180517]
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00713
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Rognon C, 2018, IEEE ROBOT AUTOM LET, V3, P2362, DOI 10.1109/LRA.2018.2810955
   Roig-Maimo M. F., 2017, P 18 INT C HUMAN COM, P1
   Ruddle R.A., 2013, HUMAN WALKING VIRTUA, P99, DOI [10.1007/978-1-4419-8432-6_5, DOI 10.1007/978-1-4419-8432-6_5]
   Schärli AM, 2013, EXP BRAIN RES, V227, P523, DOI 10.1007/s00221-013-3528-y
   Silva MaraG., 2009, CHI'09 Extended Abstracts on Human Factors in Computing Systems (CHI EA'09), P4249, DOI DOI 10.1145/1520340.1520648
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Steinicke F, 2013, Human Walking in Virtual Environments
   Suma EA, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P147
   Suma EA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P245, DOI 10.1109/VR.2009.4811037
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Tudor S, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769593
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Wilson PrestonTunnell., 2014, P 13 ACM SIGGRAPH IN, P27, DOI DOI 10.1145/2670473.2670492
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P281, DOI [10.1109/VRW50115.2020.00059, 10.1109/VRW50115.2020.0-217]
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P297, DOI [10.1109/VRW50115.2020.0-209, 10.1109/VRW50115.2020.00067]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 89
TC 5
Z9 5
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1748
EP 1768
DI 10.1109/TVCG.2021.3131422
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900011
PM 34847032
DA 2024-11-06
ER

PT J
AU Gosala, N
   Wang, FJH
   Cui, ZP
   Liang, HX
   Glauser, O
   Wu, SH
   Sorkine-Hornung, O
AF Gosala, Nikhil
   Wang, Fangjinhua
   Cui, Zhaopeng
   Liang, Hanxue
   Glauser, Oliver
   Wu, Shihao
   Sorkine-Hornung, Olga
TI Self-Calibrated Multi-Sensor Wearable for Hand Tracking and Modeling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Heating systems; Cameras; Computational
   modeling; Calibration; Solid modeling; Wearable sensors; Hand tracking;
   wearable sensors
ID SENSOR FUSION; 3D HAND
AB We present a multi-sensor system for consistent 3D hand pose tracking and modeling that leverages the advantages of both wearable and optical sensors. Specifically, we employ a stretch-sensing soft glove and three IMUs in combination with an RGB-D camera. Different sensor modalities are fused based on the availability and confidence estimation, enabling seamless hand tracking in challenging environments with partial or even complete occlusion. To maximize the accuracy while maintaining high ease-of-use, we propose an automated user calibration that uses the RGB-D camera data to refine both the glove mapping model and the multi-IMU system parameters. Extensive experiments show that our setup outperforms the wearable-only approaches when the hand is in the field-of-view and outplays the camera-only methods when the hand is occluded.
C1 [Gosala, Nikhil] Univ Freiburg, Dept Comp Sci, D-79085 Freiburg, Germany.
   [Wang, Fangjinhua; Liang, Hanxue; Glauser, Oliver; Wu, Shihao; Sorkine-Hornung, Olga] Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland.
   [Cui, Zhaopeng] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 University of Freiburg; Swiss Federal Institutes of Technology Domain;
   ETH Zurich; Zhejiang University
RP Wu, SH (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland.
EM gosalan@cs.uni-freiburg.de; fangjinhua.wang@inf.ethz.ch;
   zhpcui@gmail.com; haliang@student.ethz.ch; oli.glauser@gmail.com;
   shihao.wu312@gmail.com; olga.sorkine@inf.ethz.ch
RI Wu, Shihao/ADU-7023-2022; Zheng, Zhaoyu/IUO-8001-2023
OI Wang, Fangjinhua/0000-0003-4582-2123; Sorkine-Hornung,
   Olga/0000-0002-8089-3974
FU Personalized Health and Related Technologies (PHRT) Swiss Heart Grant;
   European Research Council (ERC), European Union's Horizon 2020 Research
   and Innovation programme [101003104]; European Research Council (ERC)
   [101003104] Funding Source: European Research Council (ERC)
FX This work was supported in part by the Personalized Health and Related
   Technologies (PHRT) Swiss Heart Grant and in part by the European
   Research Council (ERC), European Union's Horizon 2020 Research and
   Innovation programme under Grant 101003104 (MYCLOTH).
CR [Anonymous], 2020, HOLOLENS 2
   [Anonymous], 2020, MANUSVR GLOVE
   [Anonymous], 2020, 5DT GLOVE
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Baek S, 2018, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR.2018.00869
   Chen C, 2016, IEEE SENS J, V16, P773, DOI 10.1109/JSEN.2015.2487358
   Chengde Wan, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P5147, DOI 10.1109/CVPR.2018.00540
   Chossat JB, 2015, IEEE INT CONF ROBOT, P2568, DOI 10.1109/ICRA.2015.7139544
   CyberGlove, 2020, US
   de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33
   Doosti B, 2019, Arxiv, DOI arXiv:1903.01013
   Ester M., 1996, P KDD, P226
   Fang B, 2017, SCI PROGRAMMING-NETH, V2017, DOI 10.1155/2017/7594763
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Gilbert A, 2019, INT J COMPUT VISION, V127, P381, DOI 10.1007/s11263-018-1118-y
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322957
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311972
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   Hammond FL, 2014, IEEE INT C INT ROBOT, P4000, DOI 10.1109/IROS.2014.6943125
   He CY, 2015, SENSORS-BASEL, V15, P16448, DOI 10.3390/s150716448
   Helten T, 2013, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2013.141
   Huang YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275108
   Hughes J, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000002
   Kim JH, 2009, PROC IEEE INT SYMP, P1002
   Malik J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19173784
   Malleson C, 2020, INT J COMPUT VISION, V128, P1594, DOI 10.1007/s11263-019-01270-5
   Moon G, 2017, Arxiv, DOI arXiv:1706.04758
   Moon G, 2018, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2018.00533
   Mueller F, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322958
   Mueller F, 2018, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2018.00013
   Mueller F, 2017, IEEE INT CONF COMP V, P1284, DOI 10.1109/ICCVW.2017.82
   Muth JT, 2014, ADV MATER, V26, P6307, DOI 10.1002/adma.201400334
   Zhang JO, 2020, Arxiv, DOI arXiv:1912.13503
   O'Brien B, 2014, PROC SPIE, V9056, DOI 10.1117/12.2046143
   O'Connor TF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179766
   Oberweger M, 2016, Arxiv, DOI arXiv:1502.06807
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Oculus Quest, 2020, About Us
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Olson E, 2011, IEEE INT CONF ROBOT
   Park G, 2020, INT SYM MIX AUGMENT, P588, DOI 10.1109/ISMAR50242.2020.00086
   Park G, 2020, IEEE T VIS COMPUT GR, V26, P1891, DOI 10.1109/TVCG.2020.2973057
   Park W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020420
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Peppoloni Lorenzo, 2013, 2013 IEEE 11th International Symposium on Intelligent Systems and Informatics (SISY), P105, DOI 10.1109/SISY.2013.6662551
   Ponraj G, 2018, IEEE SENS J, V18, P2042, DOI 10.1109/JSEN.2018.2790801
   Rashid A, 2019, MICROELECTRON J, V88, P173, DOI 10.1016/j.mejo.2018.01.014
   Robot Operating System (ROS), 2020, US
   Roetenberg D., 2009, Xsens Motion Technologies Bv
   Saggio G, 2016, SMART MATER STRUCT, V25, DOI 10.1088/0964-1726/25/1/013001
   Shen Z, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P88, DOI [10.1186/s40638-016-0051-1, 10.1109/RCAR.2016.7784006]
   Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305
   StretchSense, 2020, US
   Tan DJ, 2016, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR.2016.605
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Taylor J, 2014, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2014.88
   Tkach A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130830
   Tkach A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980226
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   UltraLeap, 2020, US
   Unity, 2020, About us
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wu JY, 2014, 2014 19TH IEEE-NPSS REAL TIME CONFERENCE (RT), DOI 10.1109/RTC.2014.7097534
   Xiao X, 2018, P IEEE RAS-EMBS INT, P1144, DOI 10.1109/BIOROB.2018.8487858
   Xu RZ, 2012, IEEE SENS J, V12, P1166, DOI 10.1109/JSEN.2011.2166953
   Zhang ZQ, 2011, IEEE T INSTRUM MEAS, V60, P3709, DOI 10.1109/TIM.2011.2135070
   Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24
   Zhou HY, 2010, IEEE T INSTRUM MEAS, V59, P575, DOI 10.1109/TIM.2009.2025065
   Zhou SL, 2014, IEEE SENS J, V14, P1160, DOI 10.1109/JSEN.2013.2288094
   Zhou YX, 2020, PROC CVPR IEEE, P5345, DOI 10.1109/CVPR42600.2020.00539
NR 71
TC 6
Z9 6
U1 5
U2 30
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1769
EP 1784
DI 10.1109/TVCG.2021.3131230
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900012
PM 34847031
OA hybrid, Green Published
DA 2024-11-06
ER

PT J
AU Mao, AH
   Dai, CL
   Liu, Q
   Yang, J
   Gao, L
   He, Y
   Liu, YJ
AF Mao, Aihua
   Dai, Canglan
   Liu, Qing
   Yang, Jie
   Gao, Lin
   He, Ying
   Liu, Yong-Jin
TI STD-Net: Structure-Preserving and Topology-Adaptive Deformation Network
   for Single-View 3D Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Image reconstruction; Solid modeling;
   Topology; Periodic structures; Deep learning; Single-view
   reconstruction; deformation driven method; structure preservation;
   topology adaptivity
AB 3D reconstruction from single-view images is a long-standing research problem. There have been various methods based on point clouds and volumetric representations. In spite of success in 3D models generation, it is quite challenging for these approaches to deal with models with complex topology and fine geometric details. Thanks to the recent advance of deep shape representations, learning the structure and detail representation using deep neural networks is a promising direction. In this article, we propose a novel approach named STD-Net to reconstruct 3D models utilizing mesh representation that is well suited for characterizing complex structures and geometry details. Our method consists of (1) an auto-encoder network for recovering the structure of an object with bounding box representation from a single-view image; (2) a topology-adaptive GCN for updating vertex position for meshes of complex topology; and (3) a unified mesh deformation block that deforms the structural boxes into structure-aware meshes. Evaluation on ShapeNet and PartNet shows that STD-Net has better performance than state-of-the-art methods in reconstructing complex structures and fine geometric details.
C1 [Mao, Aihua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Dai, Canglan] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Liu, Qing] South China Univ Technol, Sch Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Yang, Jie] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing, Peoples R China.
   [Gao, Lin] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, Key Lab Pervas Comp, BNRist, Beijing, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; South China University of Technology; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Nanyang Technological
   University; Tsinghua University
RP Mao, AH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM ahmao@scut.edu.cn; 201821033708@scut.edu.cn;
   202021045838@mail.scut.edu.cn; yangjie01@ict.ac.cn; gaolin@ict.ac.cn;
   yhe@ntu.edu.sg; liuyongjin@tsinghua.edu.cn
RI Gao, Lin/JNF-0375-2023; He, Ying/A-3708-2011; Yang, Jie/IAO-3586-2023
OI Aihua, Mao/0000-0001-6861-9414; He, Ying/0000-0002-6749-4485
FU Tsinghua University Initiative Scientific Research Program; Natural
   Science Foundation of Guangdong Province [2019A1515010833]; Fundamental
   Research Funds for the Central Universities [2020ZYGXZR089]; Singapore
   Ministry of Education [RG20/20, T2EP20220-0014]; Natural Science
   Foundation of China [61725204]
FX This work was supported in part by Tsinghua University Initiative
   Scientific Research Program, the Natural Science Foundation of Guangdong
   Province under Grant 2019A1515010833 and the Fundamental Research Funds
   for the Central Universities under Grant 2020ZYGXZR089, Singapore
   Ministry of Education under Grants RG20/20 and T2EP20220-0014, and the
   Natural Science Foundation of China under Grant 61725204.
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du J, 2018, Arxiv, DOI arXiv:1710.10370
   Gao J, 2020, Arxiv, DOI arXiv:2011.01437
   Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Groueix T, 2018, LECT NOTES COMPUT SC, V11206, P235, DOI 10.1007/978-3-030-01216-8_15
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   Hanocka R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392415
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Huang Q, 2015, PROC NAECON IEEE NAT, P1, DOI 10.1109/NAECON.2015.7443030
   Huang Z, 2018, LECT NOTES COMPUT SC, V11220, P351, DOI 10.1007/978-3-030-01270-0_21
   Jiahui Lei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P121, DOI 10.1007/978-3-030-58523-5_8
   Kanazawa A., 2018, P EUR C COMP VIS, P371
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M, 2019, Arxiv, DOI arXiv:1901.06802
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Mo KC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356527
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, 10.48550/arXiv.1609.02907]
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Smith EJ, 2019, PR MACH LEARN RES, V97
   Sun CY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356529
   Sun XY, 2018, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2018.00314
   Tan QY, 2018, AAAI CONF ARTIF INTE, P2452
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang WY, 2019, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2019.00113
   Wu JJ, 2016, ADV NEUR IN, V29
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xu K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964975
   Xu Qiangeng, 2019, Advances in Neural Information Processing Systems
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yariv L, 2020, ADV NEUR IN, V33
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
NR 53
TC 3
Z9 3
U1 2
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1785
EP 1798
DI 10.1109/TVCG.2021.3131712
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900013
PM 34851826
DA 2024-11-06
ER

PT J
AU Shin, D
   Jo, J
   Kim, B
   Song, H
   Cho, SH
   Seo, J
AF Shin, DongHwa
   Jo, Jaemin
   Kim, Bohyoung
   Song, Hyunjoo
   Cho, Shin-Hyung
   Seo, Jinwook
TI RCMVis: A Visual Analytics System for Route Choice Modeling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Analytical models; Visual analytics; Roads; Data models; Trajectory;
   Computational modeling; Data visualization; Route choice modeling; urban
   planning; trajectory data; origin-destination; visual analytics
ID VISUALIZATION; PERSPECTIVE; MOVEMENT
AB We present RCMVis, a visual analytics system to support interactive Route Choice Modeling analysis. It aims to model which characteristics of routes, such as distance and the number of traffic lights, affect travelers' route choice behaviors and how much they affect the choice during their trips. Through close collaboration with domain experts, we designed a visual analytics framework for Route Choice Modeling. The framework supports three interactive analysis stages: exploration, modeling, and reasoning. In the exploration stage, we help analysts interactively explore trip data from multiple origin-destination (OD) pairs and choose a subset of data they want to focus on. To this end, we provide coordinated multiple OD views with different foci that allow analysts to inspect, rank, and compare OD pairs in terms of their multidimensional attributes. In the modeling stage, we integrate a $k$k-medoids clustering method and a path-size logit model into our system to enable analysts to model route choice behaviors from trips with support for feature selection, hyperparameter tuning, and model comparison. Finally, in the reasoning stage, we help analysts rationalize and refine the model by selectively inspecting the trips that strongly support the modeling result. For evaluation, we conducted a case study and interviews with domain experts. The domain experts discovered unexpected insights from numerous modeling results, allowing them to explore the hyperparameter space more effectively to gain better results. In addition, they gained OD- and road-level insights into which data mainly supported the modeling result, enabling further discussion of the model.
C1 [Shin, DongHwa; Seo, Jinwook] Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 08826, South Korea.
   [Jo, Jaemin] Sungkyunkwan Univ, Coll Comp & Informat, Suwon 16419, Gyeonggi Do, South Korea.
   [Kim, Bohyoung] Hankuk Univ Foreign Studies, Div Biomed Engn, Seoul 02450, South Korea.
   [Song, Hyunjoo] Soongsil Univ, Sch Comp Sci & Engn, Seoul 06978, South Korea.
   [Cho, Shin-Hyung] Georgia Inst Technol, Sch Civil & Environm Engn, Atlanta, GA 30332 USA.
C3 Seoul National University (SNU); Sungkyunkwan University (SKKU); Hankuk
   University Foreign Studies; Soongsil University; University System of
   Georgia; Georgia Institute of Technology
RP Seo, J (corresponding author), Seoul Natl Univ, Dept Comp Sci & Engn, Seoul 08826, South Korea.; Jo, J (corresponding author), Sungkyunkwan Univ, Coll Comp & Informat, Suwon 16419, Gyeonggi Do, South Korea.
EM dhshin@hcil.snu.ac.kr; jmjo@skku.edu; bkim@hufs.ac.kr; hsong@ssu.ac.kr;
   scho370@gatech.edu; jseo@snu.ac.kr
RI Cho, Shin-Hyung/ABH-3915-2020
OI Cho, Shin-Hyung/0000-0001-6499-1497; Seo, Jinwook/0000-0002-7734-822X;
   Shin, DongHwa/0000-0001-9460-809X
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2019R1A2C2089062, NRF-2019R1A2C1088900]; Hankuk University of
   Foreign Studies Research Fund
FX This work was supported in part by the National Research Foundation of
   Korea(NRF) grants funded by the Korea government (MSIT) under Grants
   NRF-2019R1A2C2089062 and NRF-2019R1A2C1088900, and in part by the Hankuk
   University of Foreign Studies Research Fund.
CR Andrienko G., 2007, ACM SIGKDD Explor. Newsl., V9, P38, DOI DOI 10.1145/1345448.1345455
   Andrienko G, 2017, IEEE T INTELL TRANSP, V18, P2232, DOI 10.1109/TITS.2017.2683539
   Andrienko N, 2020, IEEE T INTELL TRANSP, V21, P3196, DOI 10.1109/TITS.2019.2924796
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   [Anonymous], 2020, ArcGIS
   ARNOLD BC, 1995, AM STAT, V49, P34, DOI 10.2307/2684808
   BELLMAN R, 1960, J SOC IND APPL MATH, V8, P582, DOI 10.1137/0108044
   Ben-Akiva M., 1999, Handbook of Transportation Science, P5, DOI [10.1007/978-1-4615-5203-12, DOI 10.1007/978-1-4615-5203-12]
   Bierlaire M., 2018, 181219 TRANSP OR
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Broach J, 2010, TRANSPORT RES REC, P89, DOI 10.3141/2197-11
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Emme, 2020, US
   Fekete J.-D., 2003, Posters compendium of InfoVis, P82
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   He Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P171, DOI 10.1109/VAST.2011.6102455
   Kamw F, 2020, IEEE T INTELL TRANSP, V21, P104, DOI 10.1109/TITS.2018.2888994
   Lee C, 2020, IEEE T VIS COMPUT GR, V26, P3133, DOI 10.1109/TVCG.2019.2922597
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Lou Yin, 2009, P 17 ACM SIGSPATIAL, P352, DOI DOI 10.1145/1653771.1653820
   Lu M, 2017, IEEE T BIG DATA, V3, P234, DOI 10.1109/TBDATA.2017.2667700
   Markovic N, 2019, IEEE T INTELL TRANSP, V20, P1858, DOI 10.1109/TITS.2018.2843298
   Munzner T., 2014, AK Peters Visualization Series
   NLOGIT, 2020, US
   OpenStreetMap contributors, 2017, PLAN DUMP RETR PLAN
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Prato CG, 2009, J CHOICE MODEL, V2, P65
   Pu JS, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 1, P127, DOI 10.1109/MDM.2013.23
   QGIS, 2020, about us
   ROSSI R. J., 2018, Mathematical statistics: an introduction to likelihood based inference
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Seoul Bike, 2020, US
   Ton D, 2018, TRAVEL BEHAV SOC, V13, P105, DOI 10.1016/j.tbs.2018.07.001
   Ton D, 2017, TRANSPORT RES REC, P75, DOI 10.3141/2662-09
   Train KE, 2009, DISCRETE CHOICE METHODS WITH SIMULATION, 2ND EDITION, P1, DOI 10.1017/CBO9780511805271
   Wang F, 2014, IEEE CONF VIS ANAL, P103, DOI 10.1109/VAST.2014.7042486
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wood J., 2011, Cartographica, V46, P239, DOI [DOI 10.3138/CARTO.46.4.239, 10.3138/carto.46.4.239]
   Yixian Zheng, 2016, IEEE Transactions on Big Data, V2, P276, DOI 10.1109/TBDATA.2016.2586447
   Zeng W, 2013, COMPUT GRAPH FORUM, V32, P271, DOI 10.1111/cgf.12114
NR 43
TC 4
Z9 4
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1799
EP 1817
DI 10.1109/TVCG.2021.3131824
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900014
PM 34851827
OA hybrid
DA 2024-11-06
ER

PT J
AU Rodriguez-Pardo, C
   Garces, E
AF Rodriguez-Pardo, Carlos
   Garces, Elena
TI Neural Photometry-Guided Visual Attribute Transfer
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Lighting; Training; Semantics; Image segmentation; Image
   color analysis; Geometry; Artificial intelligence; artificial neural
   network; machine vision; image texture; graphics; computational
   photography
ID STYLE TRANSFER; SINGLE IMAGE; APPEARANCE; TEXTURE; EXAMPLE; STEREO;
   SHAPE
AB We present a deep learning-based method for propagating spatially-varying visual material attributes (e.g., texture maps or image stylizations) to larger samples of the same or similar materials. For training, we leverage images of the material taken under multiple illuminations and a dedicated data augmentation policy, making the transfer robust to novel illumination conditions and affine deformations. Our model relies on a supervised image-to-image translation framework and is agnostic to the transferred domain; we showcase a semantic segmentation, a normal map, and a stylization. Following an image analogies approach, the method only requires the training data to contain the same visual structures as the input guidance. Our approach works at interactive rates, making it suitable for material edit applications. We thoroughly evaluate our learning methodology in a controlled setup providing quantitative measures of performance. Last, we demonstrate that training the model on a single material is enough to generalize to materials of the same type without the need for massive datasets.
C1 [Rodriguez-Pardo, Carlos; Garces, Elena] SEDDI, Madrid 28007, Spain.
   [Rodriguez-Pardo, Carlos] Univ Carlos III Madrid, Madrid 28005, Spain.
   [Garces, Elena] Univ Rey Juan Carlos, Madrid 28933, Spain.
C3 Universidad Carlos III de Madrid; Universidad Rey Juan Carlos
RP Rodriguez-Pardo, C (corresponding author), SEDDI, Madrid 28007, Spain.; Rodriguez-Pardo, C (corresponding author), Univ Carlos III Madrid, Madrid 28005, Spain.
EM carlos.rodriguezpardo.jimenez@gmail.com; elena.garces@seddi.com
RI Pardo, Carlos/AAE-6838-2021; Rodriguez - Pardo, Carlos/IWM-4608-2023
OI Rodriguez - Pardo, Carlos/0000-0001-6121-7738; Garces,
   Elena/0000-0003-3509-8485
FU Torres Quevedo Fellowship [PTQ2018-009868]
FX Elena Garces was supported in part by a Torres Quevedo Fellowship under
   Grant PTQ2018-009868.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Alcain R, 2019, PHOTOPTICS: PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PHOTONICS, OPTICS AND LASER TECHNOLOGY, P111, DOI 10.5220/0007356201140119
   An XB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360639
   [Anonymous], 2014, Advances in Neural Information Processing Systems
   [Anonymous], 2015, ACM T GRAPHIC
   Antoniou A, 2018, Arxiv, DOI [arXiv:1711.04340, DOI 10.48550/ARXIV.1711.04340]
   Benaim S, 2021, COMPUT GRAPH FORUM, V40, P249, DOI 10.1111/cgf.14186
   Bénard P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461929
   Benton G., 2020, PROC INT C NEURAL IN
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Castillo C, 2019, COMPUT GRAPH-UK, V84, P103, DOI 10.1016/j.cag.2019.07.007
   Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126
   Chen DD, 2017, PROC CVPR IEEE, P2770, DOI 10.1109/CVPR.2017.296
   Chen T, 2020, PR MACH LEARN RES, V119
   Cook RL., 1982, ACM T GRAPHIC, V1, P7, DOI [DOI 10.1145/357290.357293, 10.1145/357290.357293]
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deschaintre V, 2020, COMPUT GRAPH FORUM, V39, P91, DOI 10.1111/cgf.14056
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Diamanti O., 2015, ACM Transactions on Graphics (TOG), V34, P1
   DONG Y, 2010, ACM T GRAPHIC, V29, P1, DOI DOI 10.HTTPS://D0I.0RG/10.1145/1778765.1778799
   Dong Y, 2019, VIS INFORM, V3, P59, DOI 10.1016/j.visinf.2019.07.003
   Elad M, 2017, IEEE T IMAGE PROCESS, V26, P2338, DOI 10.1109/TIP.2017.2678168
   Endo Y, 2016, COMPUT GRAPH FORUM, V35, P189, DOI 10.1111/cgf.12822
   Fiser J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925948
   Fruhstuck A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322993
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Georgiev I, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182160
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu SY, 2018, PROC CVPR IEEE, P8222, DOI 10.1109/CVPR.2018.00858
   Guarnera D, 2016, COMPUT GRAPH FORUM, V35, P625, DOI 10.1111/cgf.12867
   Guehl P, 2020, COMPUT GRAPH FORUM, V39, P159, DOI 10.1111/cgf.14061
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   He MM, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3292482
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   Hertzmann A, 2005, IEEE T PATTERN ANAL, V27, P1254, DOI 10.1109/TPAMI.2005.158
   Hertzmann A, 2003, PROC CVPR IEEE, P533
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jamriska O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323006
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kampouris C, 2016, LECT NOTES COMPUT SC, V9909, P778, DOI 10.1007/978-3-319-46454-1_47
   Karras T., 2020, ARXIV
   Kauderer-Abrams E, 2017, Arxiv, DOI arXiv:1801.01450
   Kingma D.P., 2014, P INT C LEARNING REP
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P541, DOI 10.1145/1141911.1141921
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   Li Y, 2008, COMPUT GRAPH FORUM, V27, P1255, DOI 10.1111/j.1467-8659.2008.01264.x
   Li YJ, 2017, ADV NEUR IN, V30
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Lin Y, 2019, COMPUT GRAPH FORUM, V38, P15, DOI 10.1111/cgf.13766
   Liu M.-Y., 2019, PROC IEEE INT C COMP, p10 551
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   Mazlov Ilya., 2019, Workshop on Material Appearance Modeling, DOI DOI 10.2312/MAM.20191311
   Melendez F., 2012, PROC 9 EUR C VIS MED, P40, DOI 10.1145/2414688.2414694
   Merzbach S, 2019, COMPUT GRAPH FORUM, V38, P193, DOI 10.1111/cgf.13782
   Merzbach S., 2017, P WORKSHOP MAT APPEA, P11
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Nielsen JB, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818085
   Park T., 2020, EUR C COMP VIS, P319, DOI DOI 10.1007/978-3-030-58545-7_19
   Paszke A, 2019, ADV NEUR IN, V32
   Rainer G, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13921
   Rainer G, 2019, COMPUT GRAPH FORUM, V38, P235, DOI 10.1111/cgf.13633
   Reed S.E., 2015, Advances in neural information processing systems, P1252
   Riviere J, 2016, COMPUT GRAPH FORUM, V35, P191, DOI 10.1111/cgf.12719
   Rodriguez-Pardo C, 2019, COMPUT GRAPH-UK, V83, P33, DOI 10.1016/j.cag.2019.06.010
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K., 2015, C TRACK P
   Sitzmann V., 2020, PROC INT C NEURAL IN
   Steinhausen H. C., 2014, J WSCG, V22
   Steinhausen H. C, 2015, Vision, Modeling & Visualization, P143
   Steinhausen HC, 2015, PROC SPIE, V9398, DOI 10.1117/12.2075717
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Tancik M., 2020, Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains
   Texler O, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392453
   Texler O, 2020, COMPUT GRAPH-UK, V87, P62, DOI 10.1016/j.cag.2020.01.002
   Theis L., 2016, INT C LEARN REPR
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Wang T.-C., 2019, ADV NEURAL INFORM PR, P5013
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Weinmann M, 2014, LECT NOTES COMPUT SC, V8691, P156, DOI 10.1007/978-3-319-10578-9_11
   Ye WJ, 2018, COMPUT GRAPH FORUM, V37, P201, DOI 10.1111/cgf.13560
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201285
   Zhou YZ, 2019, PROC CVPR IEEE, P4041, DOI 10.1109/CVPR.2019.00417
   Zhu JY, 2017, ADV NEUR IN, V30
NR 100
TC 4
Z9 4
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1818
EP 1830
DI 10.1109/TVCG.2021.3133081
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900015
PM 34874860
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lin, TC
   Yang, YL
   Beyer, J
   Pfister, H
AF Lin, Tica
   Yang, Yalong
   Beyer, Johanna
   Pfister, Hanspeter
TI Labeling Out-of-View Objects in Immersive Analytics to Support Situated
   Visual Searching
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Object labeling; mixed / augmented reality; immersive analytics;
   situated analytics; data visualization
ID AUGMENTED REALITY; VISUALIZATION; STRATEGIES; MANAGEMENT; NAVIGATION
AB Augmented Reality (AR) embeds digital information into objects of the physical world. Data can be shown in-situ, thereby enabling real-time visual comparisons and object search in real-life user tasks, such as comparing products and looking up scores in a sports game. While there have been studies on designing AR interfaces for situated information retrieval, there has only been limited research on AR object labeling for visual search tasks in the spatial environment. In this article, we identify and categorize different design aspects in AR label design and report on a formal user study on labels for out-of-view objects to support visual search tasks in AR. We design three visualization techniques for out-of-view object labeling in AR, which respectively encode the relative physical position (height-encoded), the rotational direction (angle-encoded), and the label values (value-encoded) of the objects. We further implement two traditional in-view object labeling techniques, where labels are placed either next to the respective objects (situated) or at the edge of the AR FoV (boundary). We evaluate these five different label conditions in three visual search tasks for static objects. Our study shows that out-of-view object labels are beneficial when searching for objects outside the FoV, spatial orientation, and when comparing multiple spatially sparse objects. Angle-encoded labels with directional cues of the surrounding objects have the overall best performance with the highest user satisfaction. We discuss the implications of our findings for future immersive AR interface design.
C1 [Lin, Tica; Beyer, Johanna; Pfister, Hanspeter] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Yang, Yalong] Virginia Tech, Dept Comp Sci, Blacksburg, VA 24060 USA.
C3 Harvard University; Virginia Polytechnic Institute & State University
RP Lin, TC (corresponding author), Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM mlin@g.harvard.edu; yalongyang@vt.edu; jbeyer@g.harvard.edu;
   pfister@g.harvard.edu
OI Pfister, Hanspeter/0000-0002-3620-2582; Lin, Tica/0000-0002-2860-0871;
   Yang, Yalong/0000-0001-9414-9911; Beyer, Johanna/0000-0002-3505-9171
FU National Science Foundation (NSF) [III-2107328]; Harvard Physical
   Sciences and Engineering Accelerator Award
FX This work was supported in part by the National Science Foundation (NSF)
   under Grant III-2107328 and a Harvard Physical Sciences and Engineering
   Accelerator Award.
CR Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bach Benjamin, 2017, WORKSH IMM AN IEEE V
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baudisch P., 2003, P SIGCHI C HUM FACT, P481, DOI 10.1145/642611.642695
   Bekos MA, 2019, COMPUT GRAPH FORUM, V38, P833, DOI 10.1111/cgf.13729
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Büschel W, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P171, DOI 10.1145/3176349.3176384
   Burigat S., 2006, P 8 C HUM COMP INT M, P239
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Carpendale M. S. T., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P61, DOI 10.1145/502348.502358
   Chittaro L., Proceedings of the Working Conference on Advanced Visual Interfaces, ser. AVI '04. New York, NY, USA: ACM, P267
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Coelho EM, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P6, DOI 10.1109/ISMAR.2004.44
   CourtVision, 2020, US
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   Field A., 2013, Discovering statistics using IBM SPSS statistics, V4th ed.
   Ghani S, 2011, COMPUT GRAPH FORUM, V30, P861, DOI 10.1111/j.1467-8659.2011.01935.x
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Gruenefeld U, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229438
   Gruenefeld U, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P742, DOI [10.1109/vr.2019.8797725, 10.1109/VR.2019.8797725]
   Gruenefeld U, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P109, DOI 10.1145/3131277.3132175
   Gustafson S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P787
   Gustafson Sean., 2007, EXTENDED ABSTRACTS H, P2399, DOI DOI 10.1145/1240866.1241014
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Horvitz E, 2003, COMMUN ACM, V46, P52, DOI 10.1145/636772.636798
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Julier S, 2002, IEEE COMPUT GRAPH, V22, P12, DOI 10.1109/MCG.2002.1028721
   Jung J, 2018, INT SYM MIX AUGMENT, P70, DOI 10.1109/ISMAR.2018.00032
   Lam H, 2008, IEEE T VIS COMPUT GR, V14, P1149, DOI 10.1109/TVCG.2008.109
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lekschas F, 2020, IEEE T VIS COMPUT GR, V26, P611, DOI 10.1109/TVCG.2019.2934555
   Lenth RV, 2016, J STAT SOFTW, V69, P1, DOI 10.18637/jss.v069.i01
   Lin T., 2020, PROC 4 WORKSHOP IMME
   Maass S, 2006, LECT NOTES COMPUT SC, V4073, P1
   Maass S, 2006, WSCG 2006: FULL PAPERS PROCEEDINGS, P327
   Madsen JB, 2016, IEEE T VIS COMPUT GR, V22, P1415, DOI 10.1109/TVCG.2016.2518318
   Makita K, 2009, IEEE INT CON MULTI, P982, DOI 10.1109/ICME.2009.5202661
   Marquardt A, 2020, IEEE T VIS COMPUT GR, V26, P3389, DOI 10.1109/TVCG.2020.3023605
   Marriott K., 2018, IMMERSIVE ANAL, V11190, DOI 10/kt9x
   Microsoft, 2021, TOOLT MIX REAL TOOLK
   Microsoft, 2021, MIX REAL TOOLK
   Miyashita T, 2008, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2008.4637334
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Orlosky Jason, 2015, P 20 INT C INT US IN, P369, DOI DOI 10.1145/2678025.2701375
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pascoal RM, 2017, ADV INF QUAL MANAGE, P271, DOI 10.4018/978-1-5225-2061-0.ch012
   Petford J., 2019, PROC CHI C HUM FACTO, P1
   Ragan E, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P287, DOI 10.1109/VR.2009.4811058
   Redelmeier DA, 1997, NEW ENGL J MED, V336, P453, DOI 10.1056/NEJM199702133360701
   Sarkar M., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P83, DOI 10.1145/142750.142763
   Satriadi KA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P593, DOI [10.1109/vr.2019.8798340, 10.1109/VR.2019.8798340]
   Schinke Torben, 2010, P 12 INT C HUM COMP, DOI [DOI 10.1145/1851600.1851655, 10.1145/1851600.1851655, DOI 10.1145/1851600]
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siu Teresa., 2013, Em: Proceedings of the 2013 Chilean Conference on Human-Computer Interaction, P36, DOI [10.1145/2535597, DOI 10.1145/2535597]
   Stein T Decoret., 2008, Proceedings of the 6th international symposium on Non-photorealistic animation and rendering, P15, DOI DOI 10.1145/1377980.1377986
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tönnis M, 2006, INT SYM MIX AUGMENT, P207
   Trapp M, 2011, J LOCAT BASED SERV, V5, P79, DOI 10.1080/17489725.2011.579579
   Unity Technologies, 2021, Unity Real-Time Development Platform | 3D, 2D VR and AR Engine
   Vertegaal R., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P23, DOI 10.1145/507072.507077
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wolfe JM, 2011, TRENDS COGN SCI, V15, P77, DOI 10.1016/j.tics.2010.12.001
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yoo ByungIn., 2010, CHI EXTENDED ABSTRAC, P3709
   Zanella A., 2002, Proceedings of the NordiCHI Conference on Human-Computer Interaction, P119
   Zellweger P.T., 2003, Extended Abstracts of the ACM CHI Conference on Human Factors in Computing Systems, P838, DOI DOI 10.1145/765891.766022
NR 74
TC 13
Z9 14
U1 2
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1831
EP 1844
DI 10.1109/TVCG.2021.3133511
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900016
PM 34882554
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Fu, YP
   Yan, QA
   Liao, J
   Zhou, HJ
   Tang, J
   Xiao, CX
AF Fu, Yanping
   Yan, Qingan
   Liao, Jie
   Zhou, Huajian
   Tang, Jin
   Xiao, Chunxia
TI Seamless Texture Optimization for RGB-D Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Cameras; Image color analysis; Three-dimensional
   displays; Geometry; Color; Solid modeling; 3D reconstruction; RGB-D
   reconstruction; texture mapping; texture optimization
AB Restoring high-fidelity textures for 3D reconstructed models are an increasing demand in AR/VR, cultural heritage protection, entertainment, and other relevant fields. Due to geometric errors and camera pose drifting, existing texture mapping algorithms are either plagued by blurring and ghosting or suffer from undesirable visual seams. In this paper, we propose a novel tri-directional similarity texture synthesis method to eliminate the texture inconsistency in RGB-D 3D reconstruction and generate visually realistic texture mapping results. In addition to RGB color information, we incorporate a novel color image texture detail layer serving as an additional context to improve the effectiveness and robustness of the proposed method. First, we select an optimal texture image for each triangle face of the reconstructed model to avoid texture blurring and ghosting. During the selection procedure, the texture details are weighted to avoid generating texture chart partitions across high-frequency areas. Then, we optimize the camera pose of each texture image to align with the reconstructed 3D shape. Next, we propose a tri-directional similarity function to resynthesize the image context within the boundary stripe of texture charts, which can significantly diminish the occurrence of texture seams. Finally, we introduce a global color harmonization method to address the color inconsistency between texture images captured from different viewpoints. The experimental results demonstrate that the proposed method outperforms state-of-the-art texture mapping methods and effectively overcomes texture tearing, blurring, and ghosting artifacts.
C1 [Fu, Yanping] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Anhui, Peoples R China.
   [Yan, Qingan] InnoPeak Technol Inc, Palo Alto, CA 94303 USA.
   [Liao, Jie; Zhou, Huajian; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Tang, Jin] Anhui Univ, Sch Comp Sci & Technol, Anhui Prov Key Lab Multimodal Cognit Computat, Hefei 230601, Anhui, Peoples R China.
C3 Anhui University; Wuhan University; Anhui University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM ypfu@ahu.edu.cn; yanqinganssg@gmail.com; liaojie@whu.edu.cn;
   eagle_zhou@foxmail.com; tangJin@ahu.edu.cn; cxxiao@whu.edu.cn
RI Fu, Yanping/AAE-4921-2022
OI Fu, Yanping/0000-0002-4191-4779
CR Aganj Ehsan, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P468
   Alldieck T, 2018, INT CONF 3D VISION, P98, DOI 10.1109/3DV.2018.00022
   Allène C, 2008, INT C PATT RECOG, P2539
   [Anonymous], 2017, ACM Transactions on Graphics (TOG)
   Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346
   Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Callieri M, 2008, COMPUT GRAPH-UK, V32, P464, DOI 10.1016/j.cag.2008.05.004
   Cao YP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182157
   Chuang M, 2009, COMPUT GRAPH FORUM, V28, P1475, DOI 10.1111/j.1467-8659.2009.01524.x
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Dellepiane M, 2012, IEEE T VIS COMPUT GR, V18, P463, DOI 10.1109/TVCG.2011.75
   Do L., 2014, P INT C COMP VIS THE, V2, P739
   Du RF, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190843
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Eisemann M, 2008, COMPUT GRAPH FORUM, V27, P409, DOI 10.1111/j.1467-8659.2008.01138.x
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2020, VISUAL COMPUT, V36, P2215, DOI 10.1007/s00371-020-01899-1
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x
   Halber M, 2017, PROC CVPR IEEE, P6660, DOI 10.1109/CVPR.2017.705
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hedman P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201384
   Huang JW, 2020, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR42600.2020.00163
   Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824
   Jeon J, 2016, VISUAL COMPUT, V32, P955, DOI 10.1007/s00371-016-1249-5
   Kim J, 2019, COMPUT GRAPH FORUM, V38, P697, DOI 10.1111/cgf.13872
   Lee JH, 2020, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR42600.2020.00135
   Lempitsky V, 2007, PROC CVPR IEEE, P829
   Li W, 2019, IEEE WINT CONF APPL, P1413, DOI 10.1109/WACV.2019.00155
   Li W, 2019, IEEE T VIS COMPUT GR, V25, P2296, DOI 10.1109/TVCG.2018.2831220
   Li YW, 2019, PROC CVPR IEEE, P9663, DOI 10.1109/CVPR.2019.00990
   Maier R., 2017, P BRIT MACH VIS C
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Maier R, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P536, DOI 10.1109/3DV.2015.66
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Prada F, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201317
   Rouhani M, 2018, INT CONF 3D VISION, P71, DOI 10.1109/3DV.2018.00019
   Simakov D., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587842
   Tsiminaki V, 2014, PROC CVPR IEEE, P1502, DOI 10.1109/CVPR.2014.195
   Waechter M, 2014, LECT NOTES COMPUT SC, V8693, P836, DOI 10.1007/978-3-319-10602-1_54
   Wang C, 2018, INT CONF 3D VISION, P533, DOI 10.1109/3DV.2018.00067
   Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232
   Yang L, 2018, IEEE T VIS COMPUT GR, V24, P1190, DOI 10.1109/TVCG.2017.2657766
   Ye XD, 2017, LECT NOTES COMPUT SC, V10636, P198, DOI 10.1007/978-3-319-70090-8_21
   Zhou K, 2005, ACM T GRAPHIC, V24, P1148, DOI 10.1145/1073204.1073325
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
NR 51
TC 7
Z9 9
U1 10
U2 34
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1845
EP 1859
DI 10.1109/TVCG.2021.3134105
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900017
PM 34882557
DA 2024-11-06
ER

PT J
AU Alharbi, R
   Strnad, O
   Luidolt, LR
   Waldner, M
   Kouril, D
   Bohak, C
   Klein, T
   Gröller, E
   Viola, I
AF Alharbi, Ruwayda
   Strnad, Ondrej
   Luidolt, Laura R.
   Waldner, Manuela
   Kouril, David
   Bohak, Ciril
   Klein, Tobias
   Groeller, Eduard
   Viola, Ivan
TI Nanotilus: Generator of Immersive Guided-Tours in Crowded 3D
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE VR immersive; visibility management; path planning; storytelling;
   visualization
ID VIRTUAL-REALITY; VISUALIZATION; TAXONOMY
AB Immersive virtual reality environments are gaining popularity for studying and exploring crowded three-dimensional structures. When reaching very high structural densities, the natural depiction of the scene produces impenetrable clutter and requires visibility and occlusion management strategies for exploration and orientation. Strategies developed to address the crowdedness in desktop applications, however, inhibit the feeling of immersion. They result in nonimmersive, desktop-style outside-in viewing in virtual reality. This article proposes Nanotilus-a new visibility and guidance approach for very dense environments that generates an endoscopic inside-out experience instead of outside-in viewing, preserving the immersive aspect of virtual reality. The approach consists of two novel, tightly coupled mechanisms that control scene sparsification simultaneously with camera path planning. The sparsification strategy is localized around the camera and is realized as a multi-scale, multi-shell, variety-preserving technique. When Nanotilus dives into the structures to capture internal details residing on multiple scales, it guides the camera using depth-based path planning. In addition to sparsification and path planning, we complete the tour generation with an animation controller, textual annotation, and text-to-visualization conversion. We demonstrate the generated guided tours on mesoscopic biological models - SARS-CoV-2 and HIV. We evaluate the Nanotilus experience with a baseline outside-in sparsification and navigational technique in a formal user study with 29 participants. While users can maintain a better overview using the outside-in sparsification, the study confirms our hypothesis that Nanotilus leads to stronger engagement and immersion.
C1 [Alharbi, Ruwayda; Strnad, Ondrej; Bohak, Ciril; Viola, Ivan] King Abdullah Univ Sci & Technol KAUST, Thuwal 23955, Saudi Arabia.
   [Luidolt, Laura R.; Waldner, Manuela; Kouril, David; Groeller, Eduard] TU Wien, A-1040 Vienna, Austria.
   [Kouril, David] Masaryk Univ, Brno 60177, Czech Republic.
   [Klein, Tobias] Nanograph, A-1040 Vienna, Austria.
C3 King Abdullah University of Science & Technology; Technische Universitat
   Wien; Masaryk University Brno
RP Alharbi, R (corresponding author), King Abdullah Univ Sci & Technol KAUST, Thuwal 23955, Saudi Arabia.
EM ruwayda.alharbi@kaust.edu.sa; ondrej.strnad@kaust.edu.sa;
   laura@cg.tuwien.ac.at; waldner@cg.tuwien.ac.at;
   dvdkouril@cg.tuwien.ac.at; ciril.bohak@kaust.edu.sa;
   tobias@nanographics.at; groeller@cg.tuwien.ac.at;
   ivan.viola@kaust.edu.sa
RI Waldner, Manuela/JZC-9267-2024; Strnad, Ondřej/GXV-9172-2022; Viola,
   Ivan/O-8944-2014
OI Viola, Ivan/0000-0003-4248-6574; Klein, Tobias/0000-0001-9455-7587;
   Strnad, Ondrej/0000-0002-8077-4692; Kouril, David/0000-0003-4043-3487
FU King Abdullah University of Science and Technology [BAS/1/1680-01-01];
   KAUST Visualization Core Lab
FX The work was supported in part by the King Abdullah University of
   Science and Technology under Grant BAS/1/1680-01-01 and in part by KAUST
   Visualization Core Lab.
CR Agrawala M, 2003, ACM T GRAPHIC, V22, P828, DOI 10.1145/882262.882352
   Akiba H, 2010, IEEE COMPUT GRAPH, V30, P61, DOI 10.1109/MCG.2009.107
   Ament M, 2017, IEEE T VIS COMPUT GR, V23, P1767, DOI 10.1109/TVCG.2016.2569080
   [Anonymous], 2007, INT J VIRTUAL REALIT
   Asmund Birkeland., 2009, Proceedings of the 25th Spring Conference on Computer Graphics, P121, DOI DOI 10.1145/1980462.1980487
   Autin L., 2020, P WORKSH MOL GRAPH V, P23
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Birkeland Å, 2012, COMPUT GRAPH FORUM, V31, P905, DOI 10.1111/j.1467-8659.2012.03083.x
   Boges D, 2020, COMPUT GRAPH-UK, V91, P12, DOI 10.1016/j.cag.2020.05.024
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bruckner S, 2006, IEEE T VIS COMPUT GR, V12, P1559, DOI 10.1109/TVCG.2006.96
   Calomeni A., 2006, PROC S INTERACTIVE 3, P175
   Christie M., 2009, ACM SIGGRAPH ASIA 2009 Courses, SIGGRAPH ASIA '09
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cremer J., 1994, PROC IMAGE 7 C, P141
   Díaz J, 2012, COMPUT GRAPH FORUM, V31, P2155, DOI 10.1111/j.1467-8659.2012.03208.x
   Dooley K, 2017, STUD AUSTRALAS CINE, V11, P161, DOI 10.1080/17503175.2017.1387357
   Elmqvist N., 2005, P ACM S VIRT REAL SO, P134, DOI [10.1145/1101616.1101643, DOI 10.1145/1101616.1101643]
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Feiner S. K., 1992, Visual Computer, V8, P292, DOI 10.1007/BF01897116
   Galvane Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181975
   Hawick KA, 2010, PARALLEL COMPUT, V36, P655, DOI 10.1016/j.parco.2010.07.002
   Hsu WH, 2013, IEEE T VIS COMPUT GR, V19, P2792, DOI 10.1109/TVCG.2013.123
   Johnson GT, 2015, NAT METHODS, V12, P85, DOI [10.1038/NMETH.3204, 10.1038/nmeth.3204]
   Johnson GT, 2014, FARADAY DISCUSS, V169, P23, DOI 10.1039/c4fd00017j
   Keiriz J. J., 2017, arXiv:1706.10297
   Knöbelreiter P, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P335
   Kouril D, 2023, IEEE T VIS COMPUT GR, V29, P1733, DOI 10.1109/TVCG.2021.3130670
   Kouril D, 2021, IEEE T VIS COMPUT GR, V27, P3493, DOI 10.1109/TVCG.2020.2975583
   Kouril D, 2019, IEEE T VIS COMPUT GR, V25, P977, DOI 10.1109/TVCG.2018.2864491
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Krüger J, 2006, IEEE T VIS COMPUT GR, V12, P941, DOI 10.1109/TVCG.2006.124
   Le Muzic M, 2016, COMPUT GRAPH FORUM, V35, P161, DOI 10.1111/cgf.12892
   Le Muzic Mathieu, 2015, Eurographics Workshop Vis Comput Biomed, V2015, P61, DOI 10.2312/vcbm.20151209
   Lengyel E., 2012, Mathematics for 3D Game Programming and Computer Graphics
   Lessells S, 2005, PRESENCE-TELEOP VIRT, V14, P580, DOI 10.1162/105474605774918778
   Li W, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239482
   Li W, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360700
   Lidal E. M., 2012, P INT S SKETCH BAS I, P11, DOI DOI 10.2312/SBM/SBM12/011-020
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Mackinlay J. D., 1990, Computer Graphics, V24, P171, DOI 10.1145/97880.97898
   Maier D, 2012, IEEE-RAS INT C HUMAN, P692, DOI 10.1109/HUMANOIDS.2012.6651595
   McCrae James., 2009, P 2009 S INT 3D GRAP, P7, DOI [10.1145/1507149.1507151, DOI 10.1145/1507149.1507151]
   Mindek P, 2018, IEEE T VIS COMPUT GR, V24, P883, DOI 10.1109/TVCG.2017.2744518
   Mindek P, 2017, COMPUT GRAPH-UK, V67, P77, DOI 10.1016/j.cag.2017.05.012
   Nägeli T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073712
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   OSKAM T., 2009, ACM SIGGRAPH EUR S C, P55
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pettersen EF, 2021, PROTEIN SCI, V30, P70, DOI 10.1002/pro.3943
   Playne DP, 2018, IEEE T PARALL DISTR, V29, P1217, DOI 10.1109/TPDS.2018.2799216
   Ponder M., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P97, DOI 10.1145/769953.769965
   Ragan ED, 2015, IEEE T VIS COMPUT GR, V21, P794, DOI 10.1109/TVCG.2015.2403312
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Salomon B., 2003, Proceedings of the 2003 symposium on Interactive 3D graphics, P41
   Sigg S, 2012, IEEE PAC VIS SYMP, P185, DOI 10.1109/PacificVis.2012.6183590
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Sommer B., 2016, P INT S EL IM SCI TE
   Sorger J., 2017, PROC SPRING C COMPUT, P27, DOI DOI 10.1145/3154353.3154364
   Sorger J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P144, DOI 10.1109/AIVR46125.2019.00030
   Thöny M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030123
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Trellet M, 2015, 2015 IEEE 1ST INTERNATIONAL WORKSHOP ON VIRTUAL AND AUGMENTED REALITY FOR MOLECULAR SCIENCE (VARMS@IEEEVR), P31, DOI 10.1109/VARMS.2015.7151726
   Viola I, 2005, Computational aesthetics in graphics, visualization and imaging, P209, DOI DOI 10.2312/COMPAESTH/COMPAESTH05/209-216
   Viola I, 2006, IEEE T VIS COMPUT GR, V12, P933, DOI 10.1109/TVCG.2006.152
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wohlfart Michael., 2007, P JOINT EUROGRAPHICS, P91, DOI [DOI 10.2312/VISSYM/EUROVIS07/091-098, 10.2312/VisSym/EuroVis07/091-098]
   Yan F, 2013, INT J AUTOM COMPUT, V10, P525, DOI 10.1007/s11633-013-0750-9
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Zhang L, 2019, INT CONF GAMES VIRTU, P33, DOI [10.1109/vs-games.2019.8864531, 10.1109/TCC.2019.2903254]
NR 70
TC 7
Z9 7
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1860
EP 1875
DI 10.1109/TVCG.2021.3133592
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900018
PM 34882555
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Meuschke, M
   Niemann, U
   Behrendt, B
   Gutberlet, M
   Preim, B
   Lawonn, K
AF Meuschke, Monique
   Niemann, Uli
   Behrendt, Benjamin
   Gutberlet, Matthias
   Preim, Bernhard
   Lawonn, Kai
TI <i>GUCCI</i>- Guided Cardiac Cohort Investigation of Blood Flow Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Blood; Biomedical imaging; Visual analytics; Heart;
   Valves; Pathology; Medical visualization; cohort analysis; measured
   blood flow data; cardiac diseases
ID PC-MRI DATA; VISUALIZATION; GUIDANCE; PATTERNS; DISPLAY; SYSTEM; MAPS
AB We present the framework GUCCI (Guided Cardiac Cohort Investigation), which provides a guided visual analytics workflow to analyze cohort-based measured blood flow data in the aorta. In the past, many specialized techniques have been developed for the visual exploration of such data sets for a better understanding of the influence of morphological and hemodynamic conditions on cardiovascular diseases. However, there is a lack of dedicated techniques that allow visual comparison of multiple data sets and defined cohorts, which is essential to characterize pathologies. GUCCI offers visual analytics techniques and novel visualization methods to guide the user through the comparison of predefined cohorts, such as healthy volunteers and patients with a pathologically altered aorta. The combination of overview and glyph-based depictions together with statistical cohort-specific information allows investigating differences and similarities of the time-dependent data. Our framework was evaluated in a qualitative user study with three radiologists specialized in cardiac imaging and two experts in medical blood flow visualization. They were able to discover cohort-specific characteristics, which supports the derivation of standard values as well as the assessment of pathology-related severity and the need for treatment.
C1 [Meuschke, Monique; Preim, Bernhard] Univ Magdeburg, Dept Simulat & Graph, D-39106 Magdeburg, Germany.
   [Niemann, Uli; Behrendt, Benjamin] Univ Magdeburg, D-39106 Magdeburg, Germany.
   [Gutberlet, Matthias] Univ Leipzig, Heart Ctr, D-04289 Leipzig, Germany.
   [Lawonn, Kai] Univ Jena, Dept Theoret Comp Sci, D-07743 Jena, Germany.
C3 Otto von Guericke University; Otto von Guericke University; Heart Center
   Leipzig GMBH; Leipzig University; Friedrich Schiller University of Jena
RP Meuschke, M (corresponding author), Univ Magdeburg, Dept Simulat & Graph, D-39106 Magdeburg, Germany.
EM meuschke@isg.cs.uni-magdeburg.de; uli.niemann@ovgu.de;
   behrendt@isg.cs.uni-magdeburg.de;
   matthias.gutberlet@helios-gesundheit.de;
   bernhard@isg.cs.uni-magdeburg.de; kai.lawonn@uni-jena.de
RI Gutberlet, Matthias/AAL-2699-2021
OI Niemann, Uli/0000-0001-9634-2248
FU Carl Zeiss Foundation
FX This work was supported in part by Carl Zeiss Foundation.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alemzadeh S., 2017, P EUROVIS WORKSHOP V, P43
   Boyandin I, 2011, COMPUT GRAPH FORUM, V30, P971, DOI 10.1111/j.1467-8659.2011.01946.x
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CARR DB, 1992, CARTOGR GEOGR INFORM, V19, P228, DOI 10.1559/152304092783721231
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cheam ASM, 2020, PATTERN RECOGN LETT, V135, P360, DOI 10.1016/j.patrec.2020.04.024
   Corouge I, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P344
   Doleisch H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P239
   Doleisch H., 2004, P 2004 EUROGRAPHICSI, P91, DOI 10.2312/VisSym/VisSym04/091-096
   Ebel S., 2020, SCI REP-UK, P1
   Ebel S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45196-x
   François CJ, 2012, J CARDIOVASC MAGN R, V14, DOI 10.1186/1532-429X-14-16
   Frydrychowicz A, 2011, INVEST RADIOL, V46, P317, DOI 10.1097/RLI.0b013e3182034fc2
   Gresh DL, 2000, IEEE VISUAL, P489, DOI 10.1109/VISUAL.2000.885739
   Harris R. L., 2000, Information Graphics: A Comprehensive Illustrated Reference
   Havre S, 2002, IEEE T VIS COMPUT GR, V8, P9, DOI 10.1109/2945.981848
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Heiberg E., 2012, J CARDIOVASCULAR S1, V14, pW14, DOI [DOI 10.1186/1532-429X-14-S1-W14, 10.1186/1532-429X-14-S1-W14]
   Heinrich J., 2013, EUROGRAPHICS STATE A, P95, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/CONF/EG2013/STARS/095-116]
   Hope TA, 2007, J MAGN RESON IMAGING, V26, P1471, DOI 10.1002/jmri.21082
   Hurley CB, 2010, J COMPUT GRAPH STAT, V19, P861, DOI 10.1198/jcgs.2010.09136
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   KILNER PJ, 1993, CIRCULATION, V88, P2235, DOI 10.1161/01.CIR.88.5.2235
   Köhler B, 2019, COMPUT GRAPH-UK, V82, P32, DOI 10.1016/j.cag.2019.05.004
   Köhler B, 2017, COMPUT GRAPH FORUM, V36, P5, DOI 10.1111/cgf.12803
   Köhler B, 2015, BILDVERARBEITUNG FUR DIE MEDIZIN 2015: ALGORITHMEN - SYSTEME - ANWENDUNGEN, P257, DOI 10.1007/978-3-662-46224-9_45
   Krause J, 2016, IEEE T VIS COMPUT GR, V22, P91, DOI 10.1109/TVCG.2015.2467622
   Lorenz R, 2014, MAGN RESON MED, V71, P1542, DOI 10.1002/mrm.24802
   Markl M, 2012, J MAGN RESON IMAGING, V36, P1015, DOI 10.1002/jmri.23632
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meuschke M, 2016, COMPUT GRAPH FORUM, V35, P351, DOI 10.1111/cgf.12911
   Meuschke M, 2021, COMPUT GRAPH-UK, V99, P22, DOI 10.1016/j.cag.2021.05.005
   Meuschke M, 2019, IEEE T VIS COMPUT GR, V25, P997, DOI 10.1109/TVCG.2018.2864509
   Mood AM., 1950, Introduction to the theory of statistics
   Niemann U, 2020, Arxiv, DOI arXiv:2010.05612
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   Packer E, 2013, IEEE T VIS COMPUT GR, V19, P2179, DOI 10.1109/TVCG.2013.224
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Potters WV, 2014, CURR CARDIOVASC IMAG, V7, DOI 10.1007/s12410-014-9257-1
   Preim B, 2020, COMPUT GRAPH-UK, V90, P145, DOI 10.1016/j.cag.2020.06.003
   Preim B, 2020, COMPUT GRAPH FORUM, V39, P543, DOI 10.1111/cgf.13891
   Reijner H., 2008, P VIS08 WORKSH THEOR
   Rocha A, 2017, IEEE T VIS COMPUT GR, V23, P821, DOI 10.1109/TVCG.2016.2598866
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Schulz-Menger J, 2013, J CARDIOVASC MAGN R, V15, DOI 10.1186/1532-429X-15-35
   Seifert C., 2010, P EUROVAST 2010 INT, P13, DOI [10.2312/PE/EuroVAST/EuroVAST10/013-018, DOI 10.2312/PE/EUROVAST/EUROVAST10/013-018]
   Semaan E. M., 2014, P INT SOC MAGN RESON, P3948
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Steenwijk M. D., 2010, PROC IEEE WORKSHOP V
   Suwa K, 2020, J MAGN RESON IMAGING, V51, P481, DOI 10.1002/jmri.26804
   Turkay C, 2014, IEEE COMPUT GRAPH, V34, P38, DOI 10.1109/MCG.2014.1
   Tyszka J M, 2000, J Magn Reson Imaging, V12, P321, DOI 10.1002/1522-2586(200008)12:2<321::AID-JMRI15>3.0.CO;2-2
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Pelt R, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12369
   Völzke H, 2011, INT J EPIDEMIOL, V40, P294, DOI 10.1093/ije/dyp394
   Ware C., 2019, Information Visualization: Perception for Design
   Zhang ZY, 2015, INFORM VISUAL, V14, P289, DOI 10.1177/1473871614526077
NR 59
TC 3
Z9 3
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1876
EP 1892
DI 10.1109/TVCG.2021.3134083
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900019
PM 34882556
DA 2024-11-06
ER

PT J
AU Huang, DY
   Stavness, I
AF Huang, Danny
   Stavness, Ian
TI Large Growth Deformations of Thin Tissue Using Solid-Shells
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Finite element analysis; Strain; Plastics; Solid modeling; Bending;
   Adaptation models; Deformable models; Animation; applications; computer
   graphics; finite element methods; physically based modelling
ID ELEMENT; MORPHOGENESIS; CONTACT; STRESS; ENERGY; SHAPE
AB Simulating large scale expansion of thin structures, such as in growing leaves, is challenging. Solid-shells have a number of potential advantages over conventional thin-shell methods, but have thus far only been investigated for small plastic deformation cases. In response, we present a new general-purpose FEM growth framework for handling a wide range of challenging growth scenarios using the solid-shell element. Solid-shells are a middle-ground between traditional volume and thin-shell elements where volumetric characteristics are retained while being treatable as a 2D manifold much like thin-shells. These elements are adaptable to accommodate the many techniques that are required for simulating large and intricate plastic deformations, including morphogen diffusion, plastic embedding, strain-aware adaptive remeshing, and collision handling. We demonstrate the capabilities of growing solid-shells in reproducing buckling, rippling, curling, and collision deformations, relevant towards animating growing leaves, flowers, and other thin structures. Solid-shells are compared side-by-side with thin-shells to examine their bending behavior and runtime performance. The experiments demonstrate that solid-shells are a viable alternative to thin-shells for simulating large and intricate growth deformations.
C1 [Huang, Danny; Stavness, Ian] Univ Saskatchewan, Saskatoon, SK S7N5A2, Canada.
C3 University of Saskatchewan
RP Huang, DY (corresponding author), Univ Saskatchewan, Saskatoon, SK S7N5A2, Canada.
EM danny.huang@usask.ca; ian.stavness@usask.ca
FU Canada First Research Excellence Fund (CFREF); Natural Sciences and
   Engineering Research Council of Canada (NSERC)
FX This work was supported in part by the Canada First Research Excellence
   Fund (CFREF) and in part by the Natural Sciences and Engineering
   Research Council of Canada (NSERC)
CR Akin J.E., 2005, Finite element analysis with error estimators
   Ambrosi D, 2011, J MECH PHYS SOLIDS, V59, P863, DOI 10.1016/j.jmps.2010.12.011
   [Anonymous], 2007, GPU GEMS
   Betsch P, 1996, COMPUT METHOD APPL M, V130, P57, DOI 10.1016/0045-7825(95)00920-5
   Bridson R, 2002, ACM T GRAPHIC, V21, P594, DOI 10.1145/566570.566623
   CANHAM PB, 1970, J THEOR BIOL, V26, P61, DOI 10.1016/S0022-5193(70)80032-7
   Chen HY, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201395
   Couturier E, 2011, J THEOR BIOL, V289, P47, DOI 10.1016/j.jtbi.2011.08.020
   Dong SB, 2016, COMPUT METHOD BIOMEC, V19, P807, DOI 10.1080/10255842.2015.1065319
   Dvorkin E. N., 1984, ENG COMPUT, V1, P77, DOI [DOI 10.1108/EB023562, 10.1108/eb023562, DOI 10.1108/eb023562]
   Efrati E, 2009, J MECH PHYS SOLIDS, V57, P762, DOI 10.1016/j.jmps.2008.12.004
   Gingras Charles, 2019, P 45 GRAPH INT 2019, P1
   Goriely A, 2007, BIOMECH MODEL MECHAN, V6, P289, DOI 10.1007/s10237-006-0065-7
   Harmon D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360622
   Irving G., 2004, P ACM SIGGRAPH EUR S, P131, DOI DOI 10.1145/1028523.1028541
   Kennaway R, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002071
   Kierzkowski D, 2019, CELL, V177, P1405, DOI 10.1016/j.cell.2019.05.011
   Li MC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392425
   Lloyd John E, 2012, SOFT ISSUE BIOMECHAN, V355, DOI [10.1007/8415_2012_126, DOI 10.1007/8415_2012_126]
   Maas S., 2014, FEBIO THEORY MANUAL
   Matoz-Fernandez DA, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.013165
   Matthews M. J., 2002, THESIS U CALGARY CAL
   Müller M, 2004, PROC GRAPH INTERF, P239
   Narain R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462010
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   Omori T, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.041918
   Otaduy MA, 2009, COMPUT GRAPH FORUM, V28, P559, DOI 10.1111/j.1467-8659.2009.01396.x
   Owens A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925982
   Prusinkiewicz P, 2010, J EXP BOT, V61, P2117, DOI 10.1093/jxb/erq081
   Rosenkrantz Jessica., 2018, Nervous systems
   Solomon J., 2014, S GEOM PROC GRAD SCH
   Taber LA, 2001, J BIOMECH ENG-T ASME, V123, P528, DOI 10.1115/1.1412451
   Takeda S, 2013, PLANT PHYSIOL, V161, P1242, DOI 10.1104/pp.112.212084
   Tang XH, 2013, INT J NUMER METH ENG, V95, P529, DOI 10.1002/nme.4537
   TURING AM, 1990, B MATH BIOL, V52, P153, DOI 10.1016/S0092-8240(05)80008-4
   Valente RAF, 2004, COMPUT MECH, V34, P38, DOI 10.1007/s00466-004-0551-7
   Vetter R., 2015, Growth, interaction and packing of thin objects
   Vetter R, 2013, INT J NUMER METH ENG, V95, P791, DOI 10.1002/nme.4536
   Weischedel C., 2012, THESIS U GOETTINGEN
   Wicke M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778786
   Yin J, 2008, P NATL ACAD SCI USA, V105, P19132, DOI 10.1073/pnas.0810443105
   Zheng YG, 2019, INT J SOLIDS STRUCT, V163, P87, DOI 10.1016/j.ijsolstr.2018.12.024
   Zöllner AM, 2013, J MECH BEHAV BIOMED, V28, P495, DOI 10.1016/j.jmbbm.2013.03.018
NR 43
TC 0
Z9 0
U1 0
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR 1
PY 2023
VL 29
IS 3
BP 1893
EP 1909
DI 10.1109/TVCG.2022.3217008
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8N3OW
UT WOS:000925059900020
PM 36279346
DA 2024-11-06
ER

PT J
AU Wang, L
   Huang, MJ
   Yang, R
   Liang, HN
   Han, J
   Sun, Y
AF Wang, Liu
   Huang, Mengjie
   Yang, Rui
   Liang, Hai-Ning
   Han, Ji
   Sun, Ying
TI Survey of Movement Reproduction in Immersive Virtual Rehabilitation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Resists; Electromagnetic compatibility; User experience; Virtual
   environments; Modulation; Tracking; Real-time systems; Virtual reality;
   movement reproduction; rehabilitation; movement representation; user
   experience
ID UPPER-LIMB REHABILITATION; UPPER EXTREMITY FUNCTION; MOTOR IMAGERY;
   ERROR AUGMENTATION; OPTIC FLOW; REALITY; STROKE; INDIVIDUALS;
   PERFORMANCE; AVATAR
AB Virtual reality (VR) has emerged as a powerful tool for rehabilitation. Many effective VR applications have been developed to support motor rehabilitation of people affected by motor issues. Movement reproduction, which transfers users' movements from the physical world to the virtual environment, is commonly used in VR rehabilitation applications. Three major components are required for movement reproduction in VR: (1) movement input, (2) movement representation, and (3) movement modulation. Until now, movement reproduction in virtual rehabilitation has not yet been systematically studied. This article aims to provide a state-of-the-art review on this subject by focusing on existing literature on immersive motor rehabilitation using VR. In this review, we provided in-depth discussions on the rehabilitation goals and outcomes, technology issues behind virtual rehabilitation, and user experience regarding movement reproduction. Similarly, we present good practices and highlight challenges and opportunities that can form constructive suggestions for the design and development of fit-for-purpose VR rehabilitation applications and can help frame future research directions for this emerging area that combines VR and health.
C1 [Wang, Liu; Huang, Mengjie] Xian Jiaotong Liverpool Univ, Design Sch, Suzhou 215000, Peoples R China.
   [Wang, Liu; Han, Ji] Univ Liverpool, Dept Civil Engn & Ind Design, Liverpool L69 3BX, England.
   [Yang, Rui; Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou 215000, Peoples R China.
   [Sun, Ying] Kunshan Rehabil Hosp, Occupat Therapy Dept, Suzhou 215335, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an
   Jiaotong-Liverpool University
RP Huang, MJ (corresponding author), Xian Jiaotong Liverpool Univ, Design Sch, Suzhou 215000, Peoples R China.
EM liu.wang19@student.xjtlu.edu.cn; mengjie.huang@xjtlu.edu.cn;
   r.yang@xjtlu.edu.cn; haining.liang@xjtlu.edu.cn; Ji.Han@liverpool.ac.uk;
   443969838@qq.com
RI Yang, Rui/AFN-1679-2022
OI Han, Ji/0000-0003-3240-4942; Liang, Hai-Ning/0000-0003-3600-8955; YANG,
   RUI/0000-0002-5634-5476; Wang, Liu/0000-0002-0635-6054; Huang,
   Mengjie/0000-0001-8163-8679
FU Key Program Special Fund in XJTLU [KSF-E-34]; Research Development Fund
   of XJTLU [RDF-18-02-30]; Natural Science Foundation of theJiangsu Higher
   Education Institutions of China [20KJB520034]
FX This work was supported in part by Key Program Special Fund in XJTLU
   under Grant KSF-E-34, in part by Research Development Fund of XJTLU
   underGrant RDF-18-02-30 and in part by the Natural Science Foundation of
   theJiangsu Higher Education Institutions of China under Grant
   20KJB520034
CR Abbruzzese G, 2015, PARKINSONS DIS-US, V2015, DOI 10.1155/2015/124214
   Abdollahi F, 2014, NEUROREHAB NEURAL RE, V28, P120, DOI 10.1177/1545968313498649
   Achanccaray D, 2018, IEEE SYS MAN CYBERN, P1006, DOI 10.1109/SMC.2018.00179
   Ahn S, 2019, J EXERC REHABIL, V15, P358, DOI 10.12965/jer.1938174.087
   AlMousa Maram, 2020, Computers Helping People with Special Needs. 17th International Conference, ICCHP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12376), P184, DOI 10.1007/978-3-030-58796-3_23
   Aminov A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0370-2
   Aoyagi K, 2019, IEEE ENG MED BIO, P118, DOI [10.1109/EMBC.2019.8856796, 10.1109/embc.2019.8856796]
   Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   Baqai A, 2019, WIRELESS PERS COMMUN, V106, P1719, DOI 10.1007/s11277-018-5382-5
   Barton GJ, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-101
   Biffi E, 2017, METHOD INFORM MED, V56, P119, DOI 10.3414/ME16-02-0020
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Borrego A, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.01061
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Calabro RS, 2020, NEUROL SCI, V41, P933, DOI 10.1007/s10072-019-04194-7
   Camporesi C, 2016, IEEE T VIS COMPUT GR, V22, P1592, DOI 10.1109/TVCG.2015.2440231
   Canning CG, 2020, NAT REV NEUROL, V16, P409, DOI 10.1038/s41582-020-0370-2
   Charbonneau P., 2017, INT C VIRT REH ICVR, P1, DOI [DOI 10.1109/ICVR.2017.8007535, 10.1109/ICVR.2017.8007535]
   Chen KY, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1829
   Choi JW, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104079
   Choi JW, 2020, IEEE T NEUR SYS REH, V28, P1614, DOI 10.1109/TNSRE.2020.2998123
   Cikajlo I, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0601-1
   D'Antonio E, 2020, HUM MOVEMENT SCI, V70, DOI 10.1016/j.humov.2020.102569
   Dallaire-Côté M, 2016, P IEEE VIRT REAL ANN, P167, DOI 10.1109/VR.2016.7504706
   Oña ED, 2019, IEEE INT CONF SERIOU, DOI 10.1109/SeGAH.2019.8882472
   De Keersmaecker E, 2020, IEEE T NEUR SYS REH, V28, P221, DOI 10.1109/TNSRE.2019.2955804
   Deutsch JE, 2007, IEEE T NEUR SYS REH, V15, P30, DOI 10.1109/TNSRE.2007.891384
   Dias P, 2019, IEEE COMPUT GRAPH, V39, P64, DOI 10.1109/MCG.2018.2875630
   Corrêa AGD, 2019, IEEE SYMP COMP COMMU, P1097, DOI 10.1109/iscc47284.2019.8969586
   dos Santos LF, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0289-4
   Elor A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1448, DOI [10.1109/VR.2019.8798014, 10.1109/vr.2019.8798014]
   Elor A, 2018, ACM T ACCESS COMPUT, V11, DOI 10.1145/3265755
   Fernández-Vargas J, 2017, IEEE ACCESS, V5, P23736, DOI 10.1109/ACCESS.2017.2766174
   Ferreira Bruno, 2019, 2019 5th Experiment@ International Conference (exp.at'19). Proceedings, P383, DOI 10.1109/EXPAT.2019.8876493
   Ferreira B, 2020, INFORMATION, V11, DOI 10.3390/info11020088
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gladstone DJ, 2002, NEUROREHAB NEURAL RE, V16, P232, DOI 10.1177/154596802401105171
   Hatem SM, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00442
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Howard MC, 2017, COMPUT HUM BEHAV, V70, P317, DOI 10.1016/j.chb.2017.01.013
   Huang MJ, 2020, IFAC PAPERSONLINE, V53, P16010, DOI 10.1016/j.ifacol.2020.12.399
   Inamura T, 2017, ADV ROBOTICS, V31, P97, DOI 10.1080/01691864.2016.1264885
   Juliano JM, 2020, J NEUROENG REHABIL, V17, DOI 10.1186/s12984-020-00678-2
   Kalawsky RS, 1999, APPL ERGON, V30, P11, DOI 10.1016/S0003-6870(98)00047-7
   Kang HK, 2012, CLIN REHABIL, V26, P246, DOI 10.1177/0269215511419383
   Kellmeyer P, 2018, CAMB Q HEALTHC ETHIC, V27, P610, DOI 10.1017/S0963180118000129
   Kern F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P500, DOI [10.1109/VR.2019.8797828, 10.1109/vr.2019.8797828]
   Khan O, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229641
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim WS, 2020, J CLIN MED, V9, DOI 10.3390/jcm9103369
   de Araújo AVL, 2019, BIOMED RES INT-UK, V2019, DOI 10.1155/2019/7106951
   Lamontagne A, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-22
   Lee SH, 2020, PM&R, V12, P257, DOI 10.1002/pmrj.12206
   Levin MF, 2015, PHYS THER, V95, P415, DOI 10.2522/ptj.20130579
   Liao Kai-Lun, 2021, 2021 IEEE 9 INT C SE, P1
   Lin PJ, 2020, PROCEEDINGS OF THE 2ND IEEE EURASIA CONFERENCE ON BIOMEDICAL ENGINEERING, HEALTHCARE AND SUSTAINABILITY 2020 (IEEE ECBIOS 2020): BIOMEDICAL ENGINEERING, HEALTHCARE AND SUSTAINABILITY, P68, DOI 10.1109/ECBIOS50299.2020.9203759
   Lin PJ, 2018, 2018 15TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS AND NETWORKS (I-SPAN 2018), P253, DOI 10.1109/I-SPAN.2018.00048
   Liu H, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1676, DOI [10.1109/itnec48623.2020.9084847, 10.1109/ITNEC48623.2020.9084847]
   Liu LY, 2020, IEEE T NEUR SYS REH, V28, P878, DOI 10.1109/TNSRE.2020.2979830
   Liu XY, 2019, IEEE T NEUR SYS REH, V27, P984, DOI 10.1109/TNSRE.2019.2909287
   Lloréns R, 2015, SENSORS-BASEL, V15, P6586, DOI 10.3390/s150306586
   Luis MAVS, 2016, 2016 10TH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPLICATIONS, SECURITY AND TECHNOLOGIES (NGMAST), P47, DOI 10.1109/NGMAST.2016.13
   Lupu RG, 2016, INT CONF SYST THEO, P295, DOI 10.1109/ICSTCC.2016.7790681
   Luque-Moreno C, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/342529
   Alonso-Valerdi LM, 2015, NEUROPSYCHOLOGIA, V79, P354, DOI 10.1016/j.neuropsychologia.2015.09.012
   Monteiro D, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1830
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Mulder T, 2007, J NEURAL TRANSM, V114, P1265, DOI 10.1007/s00702-007-0763-z
   Naranjo Jose E., 2019, 2019 Sixth International Conference on eDemocracy & eGovernment (ICEDEG), P328, DOI 10.1109/ICEDEG.2019.8734389
   Nataraj R, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233175
   Nataraj R, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00126
   Nielsen J., 1994, USABILITY ENG
   Oagaz H, 2018, INT CONF WEARAB IMPL, P5, DOI 10.1109/BSN.2018.8329645
   Ögün MN, 2019, ARQ NEURO-PSIQUIAT, V77, P681, DOI [10.1590/0004-282X20190129, 10.1590/0004-282x20190129]
   Olade I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102944
   Otten P, 2015, SENSORS-BASEL, V15, P20097, DOI 10.3390/s150820097
   Ozkul C., 2020, Eur. J. Integr. Med, V35, P101092, DOI [10.1016/j.eujim.2020.101092, DOI 10.1016/J.EUJIM.2020.101092]
   Palastanga N., 1994, Anatomy and Human Movement, V2nd
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Pereira MF, 2020, IEEE INT CONF SERIOU, DOI 10.1109/segah49190.2020.9201789
   Perez-Marcos Daniel, 2012, Front Neurol, V3, P110, DOI 10.3389/fneur.2012.00110
   Platz T, 2005, CLIN REHABIL, V19, P404, DOI 10.1191/0269215505cr832oa
   Roosink M, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/1743-0003-12-2
   Rutkowski S, 2020, J REHABIL MED, V52, DOI 10.2340/16501977-2755
   Salinas MM, 2017, GAIT POSTURE, V57, P15, DOI 10.1016/j.gaitpost.2017.05.002
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Shum LC, 2020, IEEE T NEUR SYS REH, V28, P541, DOI 10.1109/TNSRE.2019.2959621
   Tay EL, 2018, TECHNOL DISABILITY, V30, P1, DOI [DOI 10.3233/TAD-170184, 10.3233/TAD-170184]
   Tieri G, 2018, EXPERT REV MED DEVIC, V15, P107, DOI 10.1080/17434440.2018.1425613
   Trombetta M, 2017, COMPUT METH PROG BIO, V151, P15, DOI 10.1016/j.cmpb.2017.08.008
   van der Veen SM, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/18888
   Vourvopoulos A, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00210
   Wan ZT, 2021, NEUROCOMPUTING, V421, P1
   Wang L, 2021, PROC IEEE 9 INT C SE, P1
   Wei Y, 2005, INT C REHAB ROBOT, P505
   Wenge Xu, 2020, CHI PLAY '20: Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play, P98, DOI 10.1145/3383668.3419958
   Xiao S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P258, DOI [10.1109/VR46266.2020.1580775954370, 10.1109/VR46266.2020.00-59]
   Xu W., 2021, P 2021 CHI C HUM FAC, DOI [DOI 10.1145/3411764.3445801, 10.1145/3411764.3445801pages#3, DOI 10.1145/3411764.3445801PAGES#3]
   Xu WG, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/17972
   Xu WG, 2020, GAMES HEALTH J, V9, P405, DOI 10.1089/g4h.2019.0102
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 101
TC 22
Z9 24
U1 5
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2184
EP 2202
DI 10.1109/TVCG.2022.3142198
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900020
PM 35015645
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Shen, HW
AF Shen, Han-Wei
TI Editorial A Message from the New Editor-in-Chief
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Shen, HW (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012
OI Shen, Han-Wei/0000-0002-1211-2320
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1918
EP 1919
DI 10.1109/TVCG.2023.3241463
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900001
OA Bronze
DA 2024-11-06
ER

PT J
AU Seebacher, D
   Polk, T
   Janetzko, H
   Keim, DA
   Schreck, T
   Stein, M
AF Seebacher, Daniel
   Polk, Tom
   Janetzko, Halldor
   Keim, Daniel A.
   Schreck, Tobias
   Stein, Manuel
TI Investigating the Sketchplan: A Novel Way of Identifying Tactical
   Behavior in Massive Soccer Datasets
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports; Visualization; Data visualization; Magnetic domains; Trajectory;
   Europe; Data analysis; Sport analytics; soccer analytics; visual
   analytics
ID VISUALIZATION; DESIGN
AB Coaches and analysts prepare for upcoming matches by identifying common patterns in the positioning and movement of the competing teams in specific situations. Existing approaches in this domain typically rely on manual video analysis and formation discussion using whiteboards; or expert systems that rely on state-of-the-art video and trajectory visualization techniques and advanced user interaction. We bridge the gap between these approaches by contributing a light-weight, simplified interaction and visualization system, which we conceptualized in an iterative design study with the coaching team of a European first league soccer team. Our approach is walk-up usable by all domain stakeholders, and at the same time, can leverage advanced data retrieval and analysis techniques: a virtual magnetic tactic-board. Users place and move digital magnets on a virtual tactic-board, and these interactions get translated to spatio-temporal queries, used to retrieve relevant situations from massive team movement data. Despite such seemingly imprecise query input, our approach is highly usable, supports quick user exploration, and retrieval of relevant results via query relaxation. Appropriate simplified result visualization supports in-depth analyses to explore team behavior, such as formation detection, movement analysis, and what-if analysis. We evaluated our approach with several experts from European first league soccer clubs. The results show that our approach makes the complex analytical processes needed for the identification of tactical behavior directly accessible to domain experts for the first time, demonstrating our support of coaches in preparation for future encounters.
C1 [Seebacher, Daniel; Polk, Tom; Keim, Daniel A.] Univ Konstanz, D-78464 Constance, Germany.
   [Janetzko, Halldor] Lucerne Univ Appl Sci & Arts, CH-6002 Luzern, Switzerland.
   [Schreck, Tobias] Graz Univ Technol, A-8010 Graz, Austria.
   [Stein, Manuel] Subsequent GmbH, Constance, Germany.
C3 University of Konstanz; Graz University of Technology
RP Seebacher, D (corresponding author), Univ Konstanz, D-78464 Constance, Germany.
EM Daniel.Seebacher@uni-konstanz.de; thomas.polk@uni-konstanz.de;
   halldor.janetzko@hslu.ch; keim@uni-konstanz.de;
   tobias.schreck@cgv.tugraz.at; manuel.stein@subsequent.ai
OI Stein, Manuel/0000-0002-7198-1438; Schreck, Tobias/0000-0003-0778-8665;
   Seebacher, Daniel/0000-0003-0097-5855
FU Subsequent GmbH; German Research Foundation
FX This work was partially supported by the Subsequent GmbH and partially
   supported by the German Research Foundation as part of the priority
   programme 1894 "Volunteered Geographic Information: Interpretation,
   Visu-alisation and Social Computing".
CR Agile Sports Technologies Inc., 2020, SPORTSC PERF AN SYST
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Andrienko G., Visual Analytics of Movement
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Angular Team at Google, 2020, ANG
   [Anonymous], 2014, PROC EUROVA INT WORK
   [Anonymous], 2016, Electronic Imaging, Visualization and Data Analysis
   Arbu A., 2019, PROC 2 BARCA SPORTS
   Ba V., 2019, QUAEST GEOGR, V37, P5
   Bernard J, 2015, INT J DIGIT LIBRARIE, V16, P37, DOI 10.1007/s00799-014-0134-y
   Boren MT, 2000, IEEE T PROF COMMUN, V43, P261, DOI 10.1109/47.867942
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bradley P.S., 2000, Microsoft Res. Redmond, V20, P0
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carling C., 2005, HDB SOCCER MATCH ANA
   Castellano J, 2019, FOOTBAL ANAL NOW BAR
   Cintia P, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1095, DOI 10.1109/ASONAM.2016.7752377
   Dartfish, 2020, DARTF VID DAT AN SYS
   Delibas E, 2019, INFOR, V57, P141, DOI 10.1080/03155986.2018.1533204
   Deutsche Fussball Liga GmbH, 2020, SOCC POS EXPL
   ERICSSON KA, 1980, PSYCHOL REV, V87, P215, DOI 10.1037/0033-295X.87.3.215
   Fernandez J., 2018, Sloan Sports Analytics Conference, V2018, P1
   Goes FR, 2021, EUR J SPORT SCI, V21, P481, DOI 10.1080/17461391.2020.1747552
   Google, 2020, SIMPLEMINCOSTFLOW
   Gudmundsson J, 2014, COMPUT ENVIRON URBAN, V47, P16, DOI 10.1016/j.compenvurbsys.2013.09.004
   Horton M., 2018, THESIS U SYDNEY SYDN
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Lee J., 2008, P EUROGRAPHICS WORKS, P97, DOI [10.2312/SBM/SBM08/097-104, DOI 10.2312/SBM/SBM08/097-104]
   Levy-Kramer J., 2020, K-Means-Constrained in Python v0.7.1
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Lucey P., 2014, MIT sloan sports analyticsconference
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Memmert D., 2017, REVOLUTION PROFIFUSS, DOI DOI 10.1007/978-3-662-59218-2
   Memmert Daniel., 2018, Deutsche Zeitschrift fur Sportmedizin, V69, P65, DOI [DOI 10.5960/DZSM.2018.322, 10.5960/dzsm.2018.322]
   Mutschler C., 2013, Proceedings of the 7th ACM international conference on Distributed event-based systems, P289, DOI DOI 10.1145/2488222.2488283
   Pelekis N, 2012, J INTELL INF SYST, V38, P343, DOI 10.1007/s10844-011-0159-2
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   PostGIS Project Steering Committee, 2020, POSTGIS
   PostgreSQL Global Development Group, 2020, POSTGRESQL
   Probst L., 2017, P 11 ACM INT C DISTR, P319
   Probst L, 2018, IEEE INT CONF BIG DA, P548, DOI 10.1109/BigData.2018.8622592
   Ronacher Armin., 2020, Flask
   Saavedra JM, 2014, MULTIMED TOOLS APPL, V73, P2033, DOI 10.1007/s11042-013-1689-0
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sha L., 2018, ACM T COMPUT-HUM INT, V25, P1
   Sha L, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P336, DOI 10.1145/2856767.2856772
   Shih HC, 2018, IEEE T CIRC SYST VID, V28, P1212, DOI 10.1109/TCSVT.2017.2655624
   Shihn P, 2020, ROUGH JS
   Spearman W., 2017, P MIT SLOAN SPORTS A
   Stein M., 2016, 12th European International Farming Systems Association (IFSA) Symposium, Social and technological transformation of farming systems: Diverging and converging pathways, 12-15 July 2016, Harper Adams University, Newport, Shropshire, UK, P1
   Stein M., 2019, FOOTBALL ANALYTICS N, V1, P146
   Stein M, 2019, IEEE COMPUT GRAPH, V39, P60, DOI 10.1109/MCG.2019.2922224
   Stein M, 2019, LECT NOTES COMPUT SC, V11295, P130, DOI 10.1007/978-3-030-05710-7_11
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2017, DATA, V2, DOI 10.3390/data2010002
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Stein M, 2015, ISPRS INT J GEO-INF, V4, P2159, DOI 10.3390/ijgi4042159
   Sulser F., 2014, P 2014 INT ACM WORKS, P63, DOI DOI 10.1145/2660114
   Sumpter David J. T., 2016, Soccermatics: Mathematical Adventures in the Beautiful Game
   Tovinkere V., 2001, PROC IEEE INT C MULT, P833, DOI 10.1109/ICME.2001.1237851
   Wikipedia, 2021, ASS FOOTB TACT
   Wood J, 2012, IEEE T VIS COMPUT GR, V18, P2749, DOI 10.1109/TVCG.2012.262
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Xia LM, 2012, J CENT SOUTH UNIV, V19, P2142, DOI 10.1007/s11771-012-1257-1
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yongduek Seo, 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P196
   Zeng L, 2014, COMPUT GRAPH-UK, V38, P69, DOI 10.1016/j.cag.2013.10.017
NR 79
TC 3
Z9 3
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1920
EP 1936
DI 10.1109/TVCG.2021.3134814
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900002
PM 34898435
DA 2024-11-06
ER

PT J
AU Zhu, HY
   Chen, HT
   Lin, CT
AF Zhu, Howe Yuan
   Chen, Hsiang-Ting
   Lin, Chin-Teng
TI The Effects of Virtual and Physical Elevation on Physiological Stress
   During Virtual Reality Height Exposure
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Stress; Physiology; Haptic interfaces; Visualization; Virtual
   environments; In vivo; Reliability; Virtual reality; physiological
   stress; walking at heights; height exposure
ID ANXIETY; FEAR; ACROPHOBIA; ENVIRONMENTS; DEPRESSION; IMMERSION; EMOTION
AB Advances in virtual reality technology have greatly benefited the acrophobia research field. Virtual reality height exposure is a reliable method of inducing stress with low variance across ages and demographics. When creating a virtual height exposure environment, researchers have often used haptic feedback elements to improve the sense of realism of a virtual environment. While the quality of the rendered for the virtual environment increases over time, the physical environment is often simplified to a conservative passive haptic feedback platform. The impact of the increasing disparity between the virtual and physical environment on the induced stress levels is unclear. This article presents an experiment that explored the effect of combining an elevated physical platform with different levels of virtual heights to induce stress. Eighteen participants experienced four different conditions of varying physical and virtual heights. The measurements included gait parameters, heart rate, heart rate variability, and electrodermal activity. The results show that the added physical elevation at a low virtual height shifts the participant's walking behaviour and increases the perception of danger. However, the virtual environment still plays an essential role in manipulating height exposure and inducing physiological stress. Another finding is that a person's behaviour always corresponds to the more significant perceived threat, whether from the physical or virtual environment.
C1 [Zhu, Howe Yuan; Lin, Chin-Teng] Univ Technol Sydney, Ultimo, NSW 2007, Australia.
   [Chen, Hsiang-Ting] Univ Adelaide, Adelaide, SA 5005, Australia.
C3 University of Technology Sydney; University of Adelaide
RP Zhu, HY (corresponding author), Univ Technol Sydney, Ultimo, NSW 2007, Australia.
EM howe.zhu@uts.edu.au; tim.chen@adelaide.edu.au; chin-teng.lin@uts.edu.au
RI Zhu, Howe/KOD-3801-2024; Chen, Hsiang-Ting/W-9252-2019; Lin, Chin-Teng
   (CT)/G-8129-2017
OI Lin, Chin-Teng (CT)/0000-0001-8371-8197; Zhu, Howe/0000-0003-0775-887X
FU Australian Research Council (ARC) [DP180100656, DP210101093]; Australia
   Defence Innovation Hub [P18-650825]; AFOSR -DST Australian Autonomy
   Initiative [ID10134]; NSW Defence Innovation Network; NSW State
   Government of Australia [DINPP2019 S1-03/09, PP21-22.03.02]
FX This work was supported in part by the Australian Research Council (ARC)
   under discovery Grants DP180100656 and DP210101093, in part by Australia
   Defence Innovation Hub under Grant P18-650825, in part by AFOSR-DST
   Australian Autonomy Initiative Grant ID10134, and in part by NSW Defence
   Innovation Network and NSW State Government of Australia under Grants
   DINPP2019 S1-03/09 and PP21-22.03.02.
CR Allen AP, 2017, NEUROBIOL STRESS, V6, P113, DOI 10.1016/j.ynstr.2016.11.001
   Asjad NS, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225171
   Asl Aminabadi Naser, 2012, J Dent Res Dent Clin Dent Prospects, V6, P117, DOI 10.5681/joddd.2012.025
   Avila L, 2014, IEEE COMPUT GRAPH, V34, P103, DOI 10.1109/MCG.2014.103
   BAKER BL, 1973, BEHAV RES THER, V11, P79, DOI 10.1016/0005-7967(73)90071-5
   BIRAN M, 1981, J CONSULT CLIN PSYCH, V49, P886, DOI 10.1037/0022-006X.49.6.886
   Botella C, 2000, BEHAV THER, V31, P583, DOI 10.1016/S0005-7894(00)80032-5
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Brouwer AM, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00224
   Brown LA, 2006, GAIT POSTURE, V24, P397, DOI 10.1016/j.gaitpost.2005.04.013
   Burdea G. C., 1999, P INT WORKSH VIRT PR, V2, P17
   Juan MC, 2009, PRESENCE-VIRTUAL AUG, V18, P232, DOI 10.1162/pres.18.3.232
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Cleworth TW, 2012, GAIT POSTURE, V36, P172, DOI 10.1016/j.gaitpost.2012.02.010
   Cohen S., 1998, Measuring stress: a guide for health and social scientists
   Cortes CAT, 2021, IEEE T VIS COMPUT GR, V27, P204, DOI 10.1109/TVCG.2019.2927477
   Debattista K, 2018, IEEE T HUM-MACH SYST, V48, P30, DOI 10.1109/THMS.2017.2762632
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Diemer J, 2016, J ANXIETY DISORD, V37, P30, DOI 10.1016/j.janxdis.2015.10.007
   Emmelkamp PMG, 2002, BEHAV RES THER, V40, P509, DOI 10.1016/S0005-7967(01)00023-7
   Folkman S, 2013, STRESS APPRAISAL COP, DOI [10.1007/978-1-4419-1005-9215, DOI 10.1007/978-1-4419-1005-9215]
   Freeman D, 2014, PSYCHIAT RES, V218, P348, DOI 10.1016/j.psychres.2013.12.014
   Gromer D, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00141
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P290, DOI 10.1162/pres.1996.5.3.290
   HENDRIX C, 1995, VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM '95, PROCEEDINGS, P74
   Henry JD, 2005, BRIT J CLIN PSYCHOL, V44, P227, DOI 10.1348/014466505X29657
   HODGES LF, 1995, COMPUTER, V28, P27, DOI 10.1109/2.391038
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Johnson LR, 2011, FRONT BEHAV NEUROSCI, V5, DOI 10.3389/fnbeh.2011.00023
   Krijn M, 2004, BEHAV RES THER, V42, P229, DOI 10.1016/S0005-7967(03)00139-6
   Larsson Pontus., 2007, Proceedings of the 10th Annual International Workshop on Presence, P11
   LeDoux J, 2003, CELL MOL NEUROBIOL, V23, P727, DOI 10.1023/A:1025048802629
   Lee M, 2017, J VIRTUAL REAL BROAD, V14, P1
   LOVIBOND PF, 1995, BEHAV RES THER, V33, P335, DOI 10.1016/0005-7967(94)00075-U
   Lupien SJ, 2009, NAT REV NEUROSCI, V10, P434, DOI 10.1038/nrn2639
   McCarthy Cameron, 2016, 2016 IEEE EMBS International Student Conference (ISC), DOI 10.1109/EMBSISC.2016.7508621
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Nazari G, 2018, BMC SPORTS SCI MED R, V10, DOI 10.1186/s13102-018-0094-4
   Pertaub DP, 2002, PRESENCE-TELEOP VIRT, V11, P68, DOI 10.1162/105474602317343668
   Peterson SM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200306
   RootMotion, HOM ROOTMOTION
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schniepp R, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00963
   Schubert C, 2009, BIOL PSYCHOL, V80, P325, DOI 10.1016/j.biopsycho.2008.11.005
   Setz C, 2010, IEEE T INF TECHNOL B, V14, P410, DOI 10.1109/TITB.2009.2036164
   Shilton AL, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00567
   Simeonov PI, 2005, HUM FACTORS, V47, P430, DOI 10.1518/0018720054679506
   Slater M, 2003, Presence Conn, V3, P1
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Starcke K, 2012, NEUROSCI BIOBEHAV R, V36, P1228, DOI 10.1016/j.neubiorev.2012.02.003
   Steinman SA, 2011, J ANXIETY DISORD, V25, P896, DOI 10.1016/j.janxdis.2011.05.001
   Stone RJ, 2001, LECT NOTES COMPUT SC, V2058, P1
   Taelman J, 2009, IFMBE PROC, V22, P1366
   Wuehr M, 2019, J NEUROL, V266, P80, DOI 10.1007/s00415-019-09370-5
   Yuan Zhu Howe, 2021, 2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P468, DOI 10.1109/VRW52623.2021.00116
   Zadra JR, 2011, WIRES COGN SCI, V2, P676, DOI 10.1002/wcs.147
   Zephyranywhere, 2016, BIOH LOG DAT DESCR
   Zhu Howe Yuan, 2021, A Drone Nearly Hit Me! A Reflection on the Human Factors of Drone Collisions, P6, DOI [10.1145/3411763.3451614, DOI 10.1145/3411763.3451614]
NR 62
TC 6
Z9 6
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1937
EP 1950
DI 10.1109/TVCG.2021.3134412
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900003
PM 34898434
DA 2024-11-06
ER

PT J
AU Yuan, N
   Wang, PH
   Meng, WL
   Chen, SM
   Xu, J
   Xin, SQ
   He, Y
   Wang, WP
AF Yuan, Na
   Wang, Peihui
   Meng, Wenlong
   Chen, Shuangmin
   Xu, Jian
   Xin, Shiqing
   He, Ying
   Wang, Wenping
TI A Variational Framework for Curve Shortening in Various Geometric
   Domains
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Heating systems; Three-dimensional displays; Point cloud compression;
   Shortest path problem; Costs; Approximation algorithms; Surface waves;
   Variational method; shortest paths; geodesics; least-cost paths
ID COMPUTATION; PATHS; GRAPH
AB Geodesics measure the shortest distance (either locally or globally) between two points on a curved surface and serve as a fundamental tool in digital geometry processing. Suppose that we have a parameterized path (gamma)(t) = x(u(t),v(t)) on a surface x = x(u,v) with gamma(0)=p and gamma(1)=q . We formulate the two-point geodesic problem into a minimization problem integral H-1(0)(?xu(u ')(t)+xv(v ')(t)?)dt , where H(s) satisfies H(0)=0,H '(s) > 0 and H ''(s) >= 0 for s > 0 . In our implementation, we choose H(s)=(e)s(2)-1 and show that it has several unique advantages over other choices such as H (s) = s(2) and H(s) = s. It is also a minimizer of the traditional geodesic length variational and able to guarantee the uniqueness and regularity in terms of curve parameterization. In the discrete setting, we construct the initial path by a sequence of moveable points {xi}(n)(i=1) and minimize n-expressionry sumexpressiontion H-n(i=1)(?x(i)-x(i+1)?) . The resulting points are evenly spaced along the path. It's obvious that our algorithm can deal with parametric surfaces. Considering that meshes, point clouds and implicit surfaces can be transformed into a signed distance function (SDF), we also discuss its implementation on a general SDF. Finally, we show that our method can be extended to solve a general least-cost path problem. We validate the proposed algorithm in terms of accuracy, performance and scalability, and demonstrate the advantages by extensive comparisons.
C1 [Yuan, Na; Meng, Wenlong; Xin, Shiqing] Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Shan Dong, Peoples R China.
   [Wang, Peihui] ArcSoft, Hangzhou 310012, Zhejiang, Peoples R China.
   [Chen, Shuangmin] Qingdao Univ Sci & Technol, Sch Informat & Technol, Qingdao 266101, Shandong, Peoples R China.
   [Xu, Jian] Chinese Acad Sci, Ningbo Inst Mat Technol & Engn, Beijing 100045, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
   [Wang, Wenping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Shandong University; Qingdao University of Science & Technology; Chinese
   Academy of Sciences; Ningbo Institute of Materials Technology and
   Engineering, CAS; Nanyang Technological University; University of Hong
   Kong
RP Xin, SQ (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan 250100, Shan Dong, Peoples R China.
EM yuanna_sdu@163.com; peihui_wang@163.com; longwuya@163.com;
   csmqq@163.com; xujian@nimte.ac.cn; xinshiqing@sdu.edu.cn;
   yhe@ntu.edu.sg; wenping@cs.hku.hk
RI Wang, Pei-Hui/F-7682-2014; He, Ying/A-3708-2011
OI Xin, Shiqing/0000-0001-8452-8723; He, Ying/0000-0002-6749-4485
FU National Key R&D Program of China [2021YFB1715900]; National Natural
   Science Foundation of China [62002190, 62272277, 52075526, 91860204];
   NSF of Shandong Province [ZR2020MF036]; Singapore Ministry of Education
   [RG20/20, T2EP20220-0014]; Strategic Priority Research Program of the
   Chinese Academy of Sciences [XDA21010205]
FX This work was supported in part by the National Key R & D Program of
   China under Grant 2021YFB1715900, in part by the National Natural
   Science Foundation of China under Grants 62002190, 62272277, 52075526,
   and 91860204, in part by the NSF of Shandong Province under Grant
   ZR2020MF036, in part by the Singapore Ministry of Education under Grants
   RG20/20 and T2EP20220-0014, and in part by the Strategic Priority
   Research Program of the Chinese Academy of Sciences under Grant
   XDA21010205
CR Adikusuma YY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3144567
   Aleksandrov L, 2005, J ACM, V52, P25, DOI 10.1145/1044731.1044733
   Aleksandrov L, 1998, LECT NOTES COMPUT SC, V1432, P11, DOI 10.1007/BFb0054351
   Aleksandrov L, 2010, DISCRETE COMPUT GEOM, V44, P762, DOI 10.1007/s00454-009-9204-0
   [Anonymous], 2006, PROC 3 EUROGRAPH IEE
   Beck J. M., 1986, IEEE Computer Graphics and Applications, V6, P18, DOI 10.1109/MCG.1986.276587
   Bougleux S, 2008, LECT NOTES COMPUT SC, V5303, P129, DOI 10.1007/978-3-540-88688-4_10
   Cao LM, 2020, COMPUT AIDED DESIGN, V127, DOI 10.1016/j.cad.2020.102879
   CHEN JD, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P360, DOI 10.1145/98524.98601
   Cheng P, 2016, COMPUT AIDED DESIGN, V70, P144, DOI 10.1016/j.cad.2015.07.012
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Dey TK, 2007, 2007 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P357, DOI 10.1109/CW.2007.12
   Dey TK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462017
   Dey TK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360644
   Dijkstra E. W., 1959, Numer. Math, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/BF01386390]
   Du J, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102943
   Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Gorodski C, 2014, INTRO RIEMANNIAN GEO
   Hofer M, 2004, ACM T GRAPHIC, V23, P284, DOI 10.1145/1015706.1015716
   Hotz I, 2000, IEEE VISUAL, P311, DOI 10.1109/VISUAL.2000.885710
   Jha S. K., 2011, PROC INDIA INT C POW, P1
   JIN M., 2007, ACM symposium on Solid and physical modeling, P387
   Kanai T., 2000, Proceedings Geometric Modeling and Processing 2000. Theory and Applications, P241, DOI 10.1109/GMAP.2000.838256
   Lanthier M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P274, DOI 10.1145/262839.262984
   Larsen E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3719, DOI 10.1109/ROBOT.2000.845311
   Lavalle S. M, 1999, 9811 IOW STAT U
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Liu BQ, 2017, COMPUT AIDED DESIGN, V90, P105, DOI 10.1016/j.cad.2017.05.022
   Liu YJ, 2013, COMPUT AIDED DESIGN, V45, P695, DOI 10.1016/j.cad.2012.11.005
   Martínez D, 2005, COMPUT GRAPH-UK, V29, P667, DOI 10.1016/j.cag.2005.08.003
   Mémoli F, 2005, SIAM J APPL MATH, V65, P1227, DOI 10.1137/S003613990342877X
   MITCHELL JSB, 1987, SIAM J COMPUT, V16, P647, DOI 10.1137/0216045
   Peyré G, 2009, FOUND TRENDS COMPUT, V5, DOI 10.1561/0600000029
   Polthier Konrad, 2006, ACM SIGGRAPH 2006 CO, P30
   Qin YP, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925930
   Sahar G., 1985, PROC IEEE INT C ROBO, P751
   Seong JK, 2009, VISUAL COMPUT, V25, P743, DOI 10.1007/s00371-009-0362-0
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Sharir M, 1995, COMMUN PUR APPL MATH, V48, P1173, DOI 10.1002/cpa.3160480910
   Sharp N, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417839
   SHILOV G, 1965, MATH ANAL, P78
   Sneyd J., 1990, COMPUTATION GEODESIC
   Solomon J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601175
   Tao J, 2021, IEEE T PATTERN ANAL, V43, P579, DOI 10.1109/TPAMI.2019.2933209
   Vekhter J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323043
   Wang XN, 2017, COMPUT AIDED GEOM D, V52-53, P262, DOI 10.1016/j.cagd.2017.03.010
   Wu CL, 2010, IEEE T VIS COMPUT GR, V16, P647, DOI 10.1109/TVCG.2009.103
   Xin S Q., 2012, Proc. - I3D: ACM SIGGRAPH Symp. Interact. 3D Graph. Games, P31
   Xin SQ, 2007, COMPUT AIDED DESIGN, V39, P1081, DOI 10.1016/j.cad.2007.08.001
   Xin SQ, 2014, COMPUT GRAPH-UK, V38, P392, DOI 10.1016/j.cag.2013.10.037
   Xin SQ, 2012, IEEE T VIS COMPUT GR, V18, P879, DOI 10.1109/TVCG.2011.119
   Xin SQ, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559761
   Xu CX, 2015, IEEE T VIS COMPUT GR, V21, P822, DOI 10.1109/TVCG.2015.2407404
   Ye ZP, 2019, COMPUT AIDED DESIGN, V114, P73, DOI 10.1016/j.cad.2019.05.025
   Ying X, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2534161
   Ying X, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508379
   Yu H., 2010, Int. J. Inf. Sci. Comput. Math, V2, P33
   Yu H., 2014, MATH PROBLEMS ENG, P1
   Zhang P, 2015, COMPUT AIDED GEOM D, V38, P24, DOI 10.1016/j.cagd.2015.08.001
NR 61
TC 2
Z9 2
U1 2
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1951
EP 1963
DI 10.1109/TVCG.2021.3135021
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900004
PM 34905492
DA 2024-11-06
ER

PT J
AU Fang, XZ
   Huang, J
   Tong, YY
   Bao, HJ
AF Fang, Xianzhong
   Huang, Jin
   Tong, Yiying
   Bao, Hujun
TI Metric-Driven 3D Frame Field Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Three-dimensional displays; Strain; Visualization; Shape;
   Tensors; Solid modeling; Frame field; Riemannian metric; covariant
   derivative; connection
ID PARAMETERIZATION; DESIGN
AB Controlling the size and shear of elements is crucial in pure hex or hex-dominant meshing. To this end, non-orthonormal frame fields that are almost everywhere integrable (except for the singularities) can play a key role. However, it is often challenging or impossible to generate such a frame field under the tight control of a general Riemannian metric field. Therefore, we propose to solve a relatively weaker problem, i.e., generating such a frame field for a Riemannian metric field that is flat away from singularities. Such a metric field admits a local isometry to 3D Euclidean space. Applying Cartans first structural equation to the associated rotation field, i.e., the rotation part of the frame field, we show that the rotation field must have zero covariant derivatives under the 3D connection induced by the metric field. This observation leads to a metric-aware smoothness measure, equivalent to local integrability. The use of such a measure can be justified on meshes associated with locally flat metric fields. We also propose a method to generate smooth metric fields under a few intuitive constraints. On cuboid shapes, our method generates singularities aware of the metric fields, which makes the parameterization match the input metric fields better than the conventional methods. For generic shapes, while our method generates visually similar results to those using boundary frame fields to guide the metric field generation, the integrability and consistency of the metric fields are still improved, as reflected by the statistics.
C1 [Fang, Xianzhong; Huang, Jin; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Fang, Xianzhong] Ningbo Univ, Ningbo 315104, Peoples R China.
   [Tong, Yiying] Michigan State Univ, E Lansing, MI 48824 USA.
C3 Zhejiang University; Ningbo University; Michigan State University
RP Bao, HJ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM xzfang@zju.edu.cn; hj@cad.zju.edu.cn; ytong@msu.edu; bao@cad.zju.edu.cn
RI Fang, Xianzhong/CAA-4352-2022
OI Fang, Xianzhong/0000-0003-1409-5365; Bao, Hujun/0000-0002-2662-0334
FU National Key R&D Program of China [2020AAA0108901]; NSFC [61732016];
   Zhejiang Provincial Natural Science Foundation [LQ22F020025]; Zhejiang
   Provincial Science and Technology Program in China [2021C01108]; China
   Postdoctoral Science Foundation [2019M662054]
FX This work was supported in part by the National Key R & D Program of
   China under Grant 2020AAA0108901, in part by NSFC under Grant 61732016,
   in part by Zhejiang Provincial Natural Science Foundation under Grant
   LQ22F020025, in part Zhejiang Provincial Science and Technology Program
   in China under Grant 2021C01108, and in part by China Postdoctoral
   Science Foundation under Grant 2019M662054.
CR [Anonymous], 2021, ALGL
   Beaufort PA, 2020, Arxiv, DOI arXiv:1910.06240
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Cartan E., 2001, Riemannian Geometry in an Orthogonal Frame
   Chemin Alexandre, 2019, 27 INT MESH ROUNDT, V127, P89
   Corman E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323029
   Crane K, 2010, COMPUT GRAPH FORUM, V29, P1525, DOI 10.1111/j.1467-8659.2010.01761.x
   de Goes Fernando, 2016, ACM SIGGRAPH 2016 CO
   Desobry D, 2021, COMPUT AIDED DESIGN, V139, DOI 10.1016/j.cad.2021.103081
   Fang XZ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925957
   Gao XF, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073676
   Gregson J, 2011, COMPUT GRAPH FORUM, V30, P1407, DOI 10.1111/j.1467-8659.2011.02015.x
   Guo HX, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392378
   He Y, 2009, COMPUT GRAPH-UK, V33, P369, DOI 10.1016/j.cag.2009.03.024
   Huang J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602141
   Huang J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024177
   Jakob W, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818078
   Jiang TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766927
   Jiang TF, 2014, IEEE T VIS COMPUT GR, V20, P1189, DOI 10.1109/TVCG.2013.250
   Kälberer F, 2007, COMPUT GRAPH FORUM, V26, P375, DOI 10.1111/j.1467-8659.2007.01060.x
   Knöppel F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462005
   Lai YK, 2010, IEEE T VIS COMPUT GR, V16, P95, DOI 10.1109/TVCG.2009.59
   Leok M, 2005, Arxiv, DOI arXiv:math/0508338
   Li YF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366196
   Liu H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201344
   Livesu M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508388
   Nieser M, 2011, COMPUT GRAPH FORUM, V30, P1397, DOI 10.1111/j.1467-8659.2011.02014.x
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Paillé GP, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766900
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Palacios J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130844
   Palmer D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3366786
   Panozzo D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601179
   Ray N, 2006, ACM T GRAPHIC, V25, P1460, DOI 10.1145/1183287.1183297
   Ray N, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982408
   Ray N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356683
   Ray N, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640444
   Sokolov D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2930662
   Solomon J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3065254
   Tarini M, 2004, ACM T GRAPHIC, V23, P853, DOI 10.1145/1015706.1015810
   Vaxman A, 2016, COMPUT GRAPH FORUM, V35, P545, DOI 10.1111/cgf.12864
   Vyas V, 2009, PROCEEDINGS OF THE 18TH INTERNATIONAL MESHING ROUNDTABLE, P377, DOI 10.1007/978-3-642-04319-2_22
   Xu KJ, 2017, COMPUT GRAPH FORUM, V36, P540, DOI 10.1111/cgf.13100
   Yu WY, 2014, COMPUT AIDED DESIGN, V46, P58, DOI 10.1016/j.cad.2013.08.018
   Zhang E, 2006, ACM T GRAPHIC, V25, P1294, DOI 10.1145/1183287.1183290
   Zhang MY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778855
NR 46
TC 0
Z9 0
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1964
EP 1976
DI 10.1109/TVCG.2021.3136199
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900005
PM 34919519
DA 2024-11-06
ER

PT J
AU Huang, SS
   Chen, HX
   Huang, JH
   Fu, HB
   Hu, SM
AF Huang, Shi-Sheng
   Chen, Haoxiang
   Huang, Jiahui
   Fu, Hongbo
   Hu, Shi-Min
TI Real-Time Globally Consistent 3D Reconstruction With Semantic Priors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Semantics; Cameras; Pose estimation;
   Real-time systems; Geometry; Simultaneous localization and mapping; 3D
   reconstruction; semantic fusion; semantic tracker; semantic pose graph
AB Maintaining global consistency continues to be critical for online 3D indoor scene reconstruction. However, it is still challenging to generate satisfactory 3D reconstruction in terms of global consistency for previous approaches using purely geometric analysis, even with bundle adjustment or loop closure techniques. In this article, we propose a novel real-time 3D reconstruction approach which effectively integrates both semantic and geometric cues. The key challenge is how to map this indicative information, i.e., semantic priors, into a metric space as measurable information, thus enabling more accurate semantic fusion leveraging both the geometric and semantic cues. To this end, we introduce a semantic space with a continuous metric function measuring the distance between discrete semantic observations. Within the semantic space, we present an accurate frame-to-model semantic tracker for camera pose estimation, and semantic pose graph equipped with semantic links between submaps for globally consistent 3D scene reconstruction. With extensive evaluation on public synthetic and real-world 3D indoor scene RGB-D datasets, we show that our approach outperforms the previous approaches for 3D scene reconstruction both quantitatively and qualitatively, especially in terms of global consistency.
C1 [Huang, Shi-Sheng] Beijing Normal Univ, Sch Artificial Intelligence, Beijing 100875, Peoples R China.
   [Chen, Haoxiang; Huang, Jiahui; Hu, Shi-Min] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100190, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Beijing Normal University; Tsinghua University; City University of Hong
   Kong
RP Hu, SM (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100190, Peoples R China.
EM huangss@bnu.edu.cn; chx20@mails.tsinghua.edu.cn;
   huang-jh18@mails.tsinghua.edu.cn; hongbofu@cityu.edu.hk;
   shimin@tsinghua.edu.cn
RI Huang, Jiahui/AAN-1773-2021; Hu, Shi-Min/AAW-1952-2020
OI FU, Hongbo/0000-0002-0284-726X; Hu, Shi-Min/0000-0001-7507-6542; Huang,
   Jiahui/0000-0001-6320-2636
FU Natural Science Foundation of China [61521002, 61902210]; Research Grant
   of Beijing Higher Institution Engineering Research Center;
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology;
   City University of Hong Kong [7005729]; Fundamental Research Funds for
   the Central Universities
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 61521002 and 61902210 and in part by the Research
   Grant of Beijing Higher Institution Engineering Research Center and
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology.
   Hongbo Fu's work was supported in part by a Grant from City University
   of Hong Kong under Grant 7005729. Shi-Sheng Huang's work was supported
   in part by "the Fundamental Research Funds for the Central
   Universities".
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bai XY, 2020, PROC CVPR IEEE, P6358, DOI 10.1109/CVPR42600.2020.00639
   Barfoot T. D., 2017, State Estimation for Robotics, V1st, DOI [10.1017/9781316671528, DOI 10.1017/9781316671528]
   Bloesch M, 2018, PROC CVPR IEEE, P2560, DOI 10.1109/CVPR.2018.00271
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Cai JX, 2021, COMPUT GRAPH-UK, V98, P37, DOI 10.1016/j.cag.2021.04.013
   Cao YP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3182157
   CHABRA ROHAN, 2020, COMPUTER VISION ECCV, P608
   Chen JW, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461940
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Glocker B, 2015, IEEE T VIS COMPUT GR, V21, P571, DOI 10.1109/TVCG.2014.2360403
   Gojcic Z, 2020, PROC CVPR IEEE, P1756, DOI 10.1109/CVPR42600.2020.00183
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Han L, 2020, PROC CVPR IEEE, P2937, DOI 10.1109/CVPR42600.2020.00301
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Hou J, 2019, PROC CVPR IEEE, P4416, DOI 10.1109/CVPR.2019.00455
   Hu Z., 2021, P IEEECVF INT C COMP, P15488
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   Huang JH, 2021, PROC CVPR IEEE, P8928, DOI 10.1109/CVPR46437.2021.00882
   Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824
   Huang SS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3453485
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Jin YW, 2020, COMMUN INF SYST, V20, P389
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Li JX, 2019, IEEE I CONF COMP VIS, P361, DOI 10.1109/ICCV.2019.00045
   Li SK, 2019, IEEE I CONF COMP VIS, P2851, DOI 10.1109/ICCV.2019.00294
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538
   McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015
   McCormac J, 2017, IEEE I CONF COMP VIS, P2697, DOI 10.1109/ICCV.2017.292
   Mitra N. J., 2004, P 2004 EUR ACM SIGGR, P22, DOI DOI 10.1145/1057432.1057435
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Pais GD, 2020, PROC CVPR IEEE, P7191, DOI 10.1109/CVPR42600.2020.00722
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Peng S., 2020, ECCV, P523
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Pham QH, 2019, IEEE WINT CONF APPL, P1089, DOI 10.1109/WACV.2019.00121
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Schöps T, 2020, IEEE T PATTERN ANAL, V42, P2494, DOI 10.1109/TPAMI.2019.2947048
   Strecke M, 2019, IEEE I CONF COMP VIS, P5864, DOI 10.1109/ICCV.2019.00596
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Valada A, 2020, INT J COMPUT VISION, V128, P1239, DOI 10.1007/s11263-019-01188-y
   Weder S, 2021, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR46437.2021.00318
   Weder S, 2020, PROC CVPR IEEE, P4886, DOI 10.1109/CVPR42600.2020.00494
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI [10.1109/ICRA.2019.8794371, 10.1109/icra.2019.8794371]
   Yang S, 2019, IEEE INT CONF ROBOT, P7130, DOI [10.1109/ICRA.2019.8794299, 10.1109/icra.2019.8794299]
   Yang XB, 2020, IEEE T VIS COMPUT GR, V26, P3446, DOI 10.1109/TVCG.2020.3023634
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang JH, 2019, IEEE T VIS COMPUT GR, V25, P3052, DOI 10.1109/TVCG.2019.2932216
   Zhang YZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2768821
   Zhi SF, 2019, PROC CVPR IEEE, P11768, DOI 10.1109/CVPR.2019.01205
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 67
TC 9
Z9 9
U1 4
U2 39
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1977
EP 1991
DI 10.1109/TVCG.2021.3137912
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900006
PM 34941511
DA 2024-11-06
ER

PT J
AU Hu, ZM
   Bulling, A
   Li, S
   Wang, GP
AF Hu, Zhiming
   Bulling, Andreas
   Li, Sheng
   Wang, Guoping
TI EHTask: Recognizing User Tasks From Eye and Head Movements in Immersive
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Videos; Head; Visualization; Virtual reality; Magnetic
   heads; Solid modeling; Visual attention; task recognition; eye
   movements; head movements; deep learning; virtual reality
ID GAZE PREDICTION
AB Understanding human visual attention in immersive virtual reality (VR) is crucial for many important applications, including gaze prediction, gaze guidance, and gaze-contingent rendering. However, previous works on visual attention analysis typically only explored one specific VR task and paid less attention to the differences between different tasks. Moreover, existing task recognition methods typically focused on 2D viewing conditions and only explored the effectiveness of human eye movements. We first collect eye and head movements of 30 participants performing four tasks, i.e., Free viewing, Visual search, Saliency, and Track, in 15 360-degree VR videos. Using this dataset, we analyze the patterns of human eye and head movements and reveal significant differences across different tasks in terms of fixation duration, saccade amplitude, head rotation velocity, and eye-head coordination. We then propose EHTask- a novel learning-based method that employs eye and head movements to recognize user tasks in VR. We show that our method significantly outperforms the state-of-the-art methods derived from 2D viewing conditions both on our dataset (accuracy of 84.4% versus 62.8%) and on a real-world dataset (61.9% versus 44.1%). As such, our work provides meaningful insights into human visual attention under different VR tasks and guides future work on recognizing user tasks in VR.
C1 [Hu, Zhiming; Li, Sheng; Wang, Guoping] Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Bulling, Andreas] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Li, Sheng; Wang, Guoping] Peking Univ, Natl Biomed Imaging Ctr, Beijing 100871, Peoples R China.
C3 Peking University; University of Stuttgart; Peking University
RP Li, S (corresponding author), Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.; Li, S (corresponding author), Peking Univ, Natl Biomed Imaging Ctr, Beijing 100871, Peoples R China.
EM jimmyhu@pku.edu.cn; andreas.bulling@vis.uni-stuttgart.de;
   lisheng@pku.edu.cn; wgp@pku.edu.cn
RI wang, guoping/KQU-3394-2024
OI Li, Sheng/0000-0002-8901-2184; Hu, Zhiming/0000-0002-5105-9753
FU National Key R&D Program of China [2017YFB1002700]; National Natural
   Science Foundation of China [61632003, 61631001, 62172013]; European
   Research Council (ERC) [801708]
FX This work was supported in part by the National Key R & D Program of
   China under Grant 2017YFB1002700 and in part by the National Natural
   Science Foundation of China under Grants 61632003, 61631001, and
   62172013. Andreas Bulling's work was funded by the European Research
   Council (ERC; grant agreement 801708).
CR Ahn S, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391335
   Anwar MS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091530
   Balasubramanian S, 2019, INT SYM MIX AUGMENT, P169, DOI [10.1109/ISMAR.2019.00-7, 10.1109/ISMAR.2019.000-7]
   Boisvert JFG, 2016, NEUROCOMPUTING, V207, P653, DOI 10.1016/j.neucom.2016.05.047
   Borji A, 2014, J VISION, V14, DOI 10.1167/14.3.29
   Bulling A., 2013, P SIGCHI C HUM FACT, DOI [10.1145/2470654.2470697, DOI 10.1145/2470654.2470697]
   Bulling A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI 10.1109/TPAMI.2010.86
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Coco MI, 2014, J VISION, V14, DOI 10.1167/14.3.11
   Corbillon X, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P199, DOI 10.1145/3083187.3083215
   Coutrot A, 2018, BEHAV RES METHODS, V50, P362, DOI 10.3758/s13428-017-0876-8
   David B, 2021, AUST ARCHAEOL, V87, P1, DOI 10.1080/03122417.2020.1859963
   David EJ, 2019, J VISION, V19, DOI 10.1167/19.14.22
   Dell'Agnola Fabio, 2020, Virtual, Augmented and Mixed Reality. Design and Interaction. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12190), P397, DOI 10.1007/978-3-030-49695-1_26
   Fang Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121035
   Fridman L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174226
   Fuhl W, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319826
   Gandrud Jonathan, 2016, P ACM S APPL PERC, P31, DOI [10.1145/2931002.2931010, DOI 10.1145/2931002.2931010]
   Greene MR, 2012, VISION RES, V62, P1, DOI 10.1016/j.visres.2012.03.019
   Grogorick S, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119890
   Hadnett-Hunter J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3352763
   Henderson JM, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0064937
   Hild J, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204575
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Hu ZM, 2019, IEEE T VIS COMPUT GR, V25, P2002, DOI 10.1109/TVCG.2019.2899187
   Hu Zhiming., 2020, Virtual Reality Intell. Hardware, V2, P142
   Kanan Christopher, 2014, P S EYE TRACK RES AP, P287
   Keshava A, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391338
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Koehler K, 2014, J VISION, V14, DOI 10.1167/14.3.14
   Kothari R, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59251-5
   Król ME, 2020, PSYCHOL RES-PSYCH FO, V84, P245, DOI 10.1007/s00426-018-0996-5
   Kübler TC, 2017, BEHAV RES METHODS, V49, P1048, DOI 10.3758/s13428-016-0765-6
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lethaus F, 2013, NEUROCOMPUTING, V121, P108, DOI 10.1016/j.neucom.2013.04.035
   Liao H, 2019, INT J GEOGR INF SCI, V33, P739, DOI 10.1080/13658816.2018.1482554
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Pfleging B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5776, DOI 10.1145/2858036.2858117
   Salvucci Dario D, 2000, P 2000 S EYE TRACK R, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Sattar H, 2020, NEUROCOMPUTING, V387, P369, DOI 10.1016/j.neucom.2020.01.028
   Sidenmark L, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391312
   Sidenmark L, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376438
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Stahl JS, 1999, EXP BRAIN RES, V126, P41, DOI 10.1007/s002210050715
   Steil J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P75, DOI 10.1145/2750858.2807520
   Sugano Y, 2014, J EYE MOVEMENT RES, V7
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Vortmann Lisa-Marie, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382889
   Wang X., 2019, PROC CHI C HUM FACTO, P1
   Wu CL, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P193, DOI 10.1145/3083187.3083210
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Yarbus A. L., 1967, Eye movements and vision, P171, DOI DOI 10.1007/978-1-4899-5379-7
NR 56
TC 15
Z9 15
U1 8
U2 35
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 1992
EP 2004
DI 10.1109/TVCG.2021.3138902
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900007
PM 34962869
DA 2024-11-06
ER

PT J
AU Miyatake, Y
   Hiraki, T
   Iwai, D
   Sato, K
AF Miyatake, Yamato
   Hiraki, Takefumi
   Iwai, Daisuke
   Sato, Kosuke
TI HaptoMapping: Visuo-Haptic Augmented Reality by Embedding
   User-Imperceptible Tactile Display Control Signals in a Projected Image
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Visualization; Spatiotemporal phenomena; Vibrations;
   Visible light communication; Synchronization; Surface roughness;
   Visuo-haptic display; high-speed projection; social haptics
ID PERCEPTION
AB This article proposes HaptoMapping, a projection-based visuo-haptic augmented reality (VHAR) system, that can render visual and haptic content independently and present consistent visuo-haptic sensations on physical surfaces. HaptoMapping controls wearable haptic displays by embedded control signals that are imperceptible to the user in projected images using a pixel-level visible light communication technique. The prototype system is comprised of a high-speed projector and three types of haptic devices-finger worn, stylus, and arm mounted. The finger-worn and stylus devices present vibrotactile sensations to a user's fingertips. The arm-mounted device presents stroking sensations on a user's forearm using arrayed actuators with a synchronized hand projection mapping. We identified that the developed system's maximum latency of haptic from visual sensations was 93.4 ms. We conducted user studies on the latency perception of our VHAR system. The results revealed that the developed haptic devices can present haptic sensations without user-perceivable latencies, and the visual-haptic latency tolerance of our VHAR system was 100, 159, 500 ms for the finger-worn, stylus, and arm-mounted devices, respectively. Another user study with the arm-mounted device discovered that the visuo-haptic stroking system maintained both continuity and pleasantness when the spacing between each substrate was relatively sparse, such as 20 mm, and significantly improved both the continuity and pleasantness at 80 and 150 mm/s when compared to the haptic only stroking system. Lastly, we introduced four potential applications in daily scenes. Our system methodology allows for a wide range of VHAR application design without concern for latency and misalignment effects.
C1 [Miyatake, Yamato; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Suita, Osaka 5650871, Japan.
   [Hiraki, Takefumi] Univ Tsukuba, Tsukuba, Ibaraki 3058577, Japan.
C3 Osaka University; University of Tsukuba
RP Miyatake, Y (corresponding author), Osaka Univ, Suita, Osaka 5650871, Japan.
EM miyatake@sens.sys.es.osaka-u.ac.jp; hiraki@slis.tsukuba.ac.jp;
   daisuke.iwai@sys.es.osaka-u.ac.jp; sato@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Sato, Kosuke/0000-0003-1429-9990; Iwai, Daisuke/0000-0002-3493-5635;
   Miyatake, Yamato/0000-0003-1241-0114; Hiraki,
   Takefumi/0000-0002-5767-3607
FU JST ACT-X [JPMJAX190O]; JST PRESTO [JPMJPR19J2]; JSPSKAKENHI
   [JP15H05925, JP20H05958]
FX This work was supported in part by JST ACT-X under Grant JPMJAX190O,in
   part by JST PRESTO under Grant JPMJPR19J2, and in part by JSPSKAKENHI
   under Grants JP15H05925 and JP20H05958, Japan.
CR Ackerley R, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00054
   Ando H., 2007, P INT C ADV COMP ENT, P292, DOI [10.1145/1255047.1255131, DOI 10.1145/1255047.1255131]
   [Anonymous], 2012, AH 12, DOI DOI 10.1145/2160125.2160134
   Aoyama S, 2016, PROCEEDINGS OF THE 2016 WORKSHOP ON MULTIMODAL VIRTUAL AND AUGMENTED REALITY (MVAR 2016), DOI 10.1145/3001959.3001967
   Ban Y., 2018, PROC ACM SIGGRAPH AS
   Basdogan C, 2020, IEEE T HAPTICS, V13, P450, DOI 10.1109/TOH.2020.2990712
   Bau O, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185585
   Cosco F, 2013, IEEE T VIS COMPUT GR, V19, P159, DOI 10.1109/TVCG.2012.107
   Costes A, 2020, IEEE T HAPTICS, V13, P530, DOI 10.1109/TOH.2020.2984754
   Culbertson H, 2018, IEEE HAPTICS SYM, P32, DOI 10.1109/HAPTICS.2018.8357149
   Culbertson H, 2014, IEEE T HAPTICS, V7, P381, DOI 10.1109/TOH.2014.2316797
   Culbertson H, 2014, IEEE HAPTICS SYM, P319, DOI 10.1109/HAPTICS.2014.6775475
   D. Systems, TOUCH SOLD PHANTOM O
   de Tinguy X, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P81, DOI 10.1109/VR.2018.8446280
   DiSalvo C, 2003, RO-MAN 2003: 12TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P403
   Eck U, 2015, IEEE T VIS COMPUT GR, V21, P1427, DOI 10.1109/TVCG.2015.2480087
   Eichhorn E., 2008, P 10 INT C HUM COMP, P303, DOI 10.1145/1409240.1409274
   Harders M, 2009, IEEE T VIS COMPUT GR, V15, P138, DOI 10.1109/TVCG.2008.63
   He L, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P47, DOI 10.1145/2802083.2802091
   Hiraki Takefumi, 2018, SICE Journal of Control, Measurement, and System Integration, P302, DOI 10.9746/jcmsi.11.302
   Hiraki T, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875199
   Huisman G, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P211, DOI 10.1109/WHC.2013.6548410
   Inami M., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P233, DOI 10.1109/VR.2000.840503
   Israr A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188546
   Israr A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2019
   Iwai D, 2019, IEEE T VIS COMPUT GR, V25, P1707, DOI 10.1109/TVCG.2018.2820121
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Jewitt Carey., 2020, INTERDISCIPLINARY IN, DOI DOI 10.1007/978-3-030-24564-1
   Kanamori T, 2018, IEEE ACCESS, V6, P40649, DOI 10.1109/ACCESS.2018.2858268
   Kimura S., 2008, P ACM SIGGRAPH
   Knoop E., 2015, Proceedings of the ACM Conference Extended Abstracts on Human Factors in Computing Systems, P1133, DOI DOI 10.1145/2702613.2732749
   Kyung KU, 2009, IEEE COMPUT GRAPH, V29, P56, DOI 10.1109/MCG.2009.17
   Lee J.C., 2004, P 17 ANN ACM S USER, P291, DOI [10.1145/1029632, DOI 10.1145/1029632, DOI 10.1145/1029632.1029682]
   Lee Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156932
   Lu SH, 2020, IEEE T HAPTICS, V13, P94, DOI 10.1109/TOH.2020.2966192
   Maisto M, 2017, IEEE T HAPTICS, V10, P511, DOI 10.1109/TOH.2017.2691328
   Man-Systems Integration Standards, 1995, NASASTD3000
   Miyasato T., 1995, The Journal of the Institute of Television Engineers of Japan, V49, P1353
   Miyatake Yamato, 2020, Haptics: Science, Technology, Applications. 12th International Conference, EuroHaptics 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12272), P226, DOI 10.1007/978-3-030-58147-3_25
   MIYAZAKI Y, 2020, P I MECH ENG N-J NAN, P1
   Monnai Y., 2014, P 27 ANN ACM S US IN, P663, DOI [DOI 10.1145/2642918.2647407, 10.1145/2642918.2647407]
   Muthukumarana S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376491
   Nunez CM, 2020, IEEE HAPTICS SYM, P629, DOI 10.1109/HAPTICS45997.2020.ras.HAP20.35.f631355d
   Nunez CM, 2019, IEEE T HAPTICS, V12, P414, DOI 10.1109/TOH.2019.2941190
   Osama M., 2001, EUROHAPTICS, P60
   Osgouei RH, 2020, IEEE T HAPTICS, V13, P298, DOI 10.1109/TOH.2019.2932990
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Punpongsanon P, 2015, IEEE T VIS COMPUT GR, V21, P1279, DOI 10.1109/TVCG.2015.2459792
   Rahal L, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON ROBOTIC AND SENSORS ENVIRONMENTS (ROSE 2009), P86, DOI 10.1109/ROSE.2009.5355986
   Rekimoto Jun., 2009, Proceedings of the 27th international conference extended abstracts on Human factors in computing systems - CHI EA'09, page, P2519
   Romano JM, 2012, IEEE T HAPTICS, V5, P109, DOI [10.1109/TOH.2011.38, 10.1109/ToH.2011.38]
   Sandor C., 2007, 106 TECH COMM PATT R
   Sandor C, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P292
   Silva JM, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2457450.2457451
   Strese Matti, 2014, 2014 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE). Proceedings, P118, DOI 10.1109/HAVE.2014.6954342
   Talbot H. F., 1834, PHILOS MAG, V5, P321, DOI DOI 10.1080/14786443408648474
   Tanabe N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1355, DOI [10.1109/vr.2019.8798195, 10.1109/VR.2019.8798195]
   Uematsu Haruya, 2016, ACM SIGGRAPH 2016 EM, DOI [10.1145/2929464.2929479, DOI 10.1145/2929464.2929479]
   Wang D, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P303
   Wang DX, 2011, IEEE T HAPTICS, V4, P321, DOI [10.1109/TOH.2011.17, 10.1109/ToH.2011.17]
   Wang Rongrong., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, CHI '12, P139
   Wu WC, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P193, DOI [10.1109/WHC.2019.8816170, 10.1109/whc.2019.8816170]
NR 62
TC 6
Z9 6
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2005
EP 2019
DI 10.1109/TVCG.2021.3136214
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900008
PM 34965211
OA hybrid
DA 2024-11-06
ER

PT J
AU Xu, CQ
   Neuroth, T
   Fujiwara, T
   Liang, RH
   Ma, KL
AF Xu, Chaoqing
   Neuroth, Tyson
   Fujiwara, Takanori
   Liang, Ronghua
   Ma, Kwan-Liu
TI A Predictive Visual Analytics System for Studying Neurodegenerative
   Disease Based on DTI Fiber Tracts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Diseases; Data visualization; Tensors; Diffusion tensor imaging; Visual
   analytics; Rendering (computer graphics); Feature extraction; Brain
   fiber tracts; neurodegenerative disease; machine learning; predictive
   visual analytics; visualization
ID DIFFUSION-TENSOR; PARKINSONS-DISEASE; WHITE-MATTER; ALZHEIMERS-DISEASE;
   SUBSTANTIA-NIGRA; BRAIN; MRI; CLASSIFICATION; ATROPHY; IMAGES
AB Diffusion tensor imaging (DTI) has been used to study the effects of neurodegenerative diseases on neural pathways, which may lead to more reliable and early diagnosis of these diseases as well as a better understanding of how they affect the brain. We introduce a predictive visual analytics system for studying patient groups based on their labeled DTI fiber tract data and corresponding statistics. The system's machine-learning-augmented interface guides the user through an organized and holistic analysis space, including the statistical feature space, the physical space, and the space of patients over different groups. We use a custom machine learning pipeline to help narrow down this large analysis space and then explore it pragmatically through a range of linked visualizations. We conduct several case studies using DTI and T1-weighted images from the research database of Parkinson's Progression Markers Initiative.
C1 [Xu, Chaoqing; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Zhejiang, Peoples R China.
   [Neuroth, Tyson; Fujiwara, Takanori; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 Zhejiang University of Technology; University of California System;
   University of California Davis
RP Liang, RH (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Zhejiang, Peoples R China.
EM superclearxu@gmail.com; taneuroth@ucdavis.edu; tfujiwara@ucdavis.edu;
   rhliang@zjut.edu.cn; klma@ucdavis.edu
RI Fujiwara, Takanori/AAY-5045-2020
OI Ma, Kwan-Liu/0000-0001-8086-0366; Xu, Chaoqing/0000-0003-0955-5611;
   Fujiwara, Takanori/0000-0002-6382-2752
FU Michael J. Fox Foundation for Parkinson's Research; AbbVie; Allergan;
   Avid Radiopharmaceuticals; Biogen; BioLegend; Bristol-Myers Squibb;
   Celgene; Covance; GE Healthcare; Genentech; GlaxoSmithKline; Golub
   Capital; Handl Therapeutics; Insitro; Lilly; Lundbeck; Merck; Meso Scale
   Discovery; Pfizer; Piramal; Prevail; Roche; Sanofi Genzyme; Servier;
   Takeda; TEVA; UCB; Verily; Voyager
FX We thank Dr. Pauline Maillard from the Department of Neurology, the
   University of California at Davis, Dr. Xiu-fang Xu from Hangzhou Medical
   College, and Dr. Chao Lin from the Children's Hospital of Zhejiang
   University School of Medicine who provided insight and expertise that
   greatly assisted the research. We would also like to show our grati-tude
   to Dr. Shunyuan Guo and Dr. Gaoping Lin from Zhe-jiang Provincial
   People's Hospital for sharing their pearls of wisdom with us during this
   research. Data used in the prep-aration of this article were obtained
   from the Parkinson's Progression Markers Initiative (PPMI) database
   (www. ppmiinfo.org/data). For up-to-date information on the study, visit
   www.ppmiinfo.org. PPMI-a public-private partnership-is funded by the
   Michael J. Fox Foundation for Parkinson's Research and funding partners,
   including AbbVie, Allergan, Avid Radiopharmaceuticals, Biogen,
   BioLegend, Bristol-Myers Squibb, Celgene, Covance, GE Healthcare,
   Genentech, GlaxoSmithKline, Golub Capital, Handl Therapeutics, Insitro,
   Lilly, Lundbeck, Merck, Meso Scale Discovery, Pfizer, Piramal, Prevail,
   Roche, Roche, Sanofi Genzyme, Servier, Takeda, TEVA, UCB, Verily, and
   Voyager.
CR Aarabi MH, 2015, IEEE ENG MED BIO, P4310, DOI 10.1109/EMBC.2015.7319348
   Acosta-Cabronero J, 2017, BRAIN, V140, P118, DOI 10.1093/brain/aww278
   Agus M, 2019, COMPUT GRAPH FORUM, V38, P427, DOI 10.1111/cgf.13700
   Andersson JLR, 2016, NEUROIMAGE, V125, P1063, DOI 10.1016/j.neuroimage.2015.10.019
   Andersson JLR, 2003, NEUROIMAGE, V20, P870, DOI 10.1016/S1053-8119(03)00336-7
   Angelelli P, 2014, IEEE COMPUT GRAPH, V34, P70, DOI 10.1109/MCG.2014.40
   Angulo DA, 2016, FRONT NEUROINFORM, V10, DOI 10.3389/fninf.2016.00036
   Ascherio A, 2016, LANCET NEUROL, V15, P1255, DOI 10.1016/S1474-4422(16)30230-7
   Basser PJ, 2002, NMR BIOMED, V15, P456, DOI 10.1002/nbm.783
   Benjamini Y, 2010, BIOMETRICAL J, V52, P708, DOI 10.1002/bimj.200900299
   Burton EJ, 2004, BRAIN, V127, P791, DOI 10.1093/brain/awh088
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Castellazzi G, 2020, FRONT NEUROINFORM, V14, DOI 10.3389/fninf.2020.00025
   Claassen DO, 2016, BRAIN BEHAV, V6, DOI 10.1002/brb3.573
   Desikan RS, 2006, NEUROIMAGE, V31, P968, DOI 10.1016/j.neuroimage.2006.01.021
   Dinov ID, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157077
   Donetti L, 2004, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2004/10/P10012
   Dubbelink KTEO, 2014, BRAIN, V137, P197, DOI 10.1093/brain/awt316
   Dyrba M, 2015, J NEUROIMAGING, V25, P738, DOI 10.1111/jon.12214
   Eichelbaum S, 2013, IEEE T VIS COMPUT GR, V19, P433, DOI 10.1109/TVCG.2012.142
   Everts MH, 2015, IEEE T VIS COMPUT GR, V21, P808, DOI 10.1109/TVCG.2015.2403323
   Everts MH, 2009, IEEE T VIS COMPUT GR, V15, P1299, DOI 10.1109/TVCG.2009.138
   Fischl B, 2012, NEUROIMAGE, V62, P774, DOI 10.1016/j.neuroimage.2012.01.021
   Fritzsche KH, 2012, METHOD INFORM MED, V51, P441, DOI 10.3414/ME11-02-0031
   Fujiwara T, 2022, IEEE T VIS COMPUT GR, V28, P758, DOI 10.1109/TVCG.2021.3114807
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Fujiwara T, 2017, IEEE PAC VIS SYMP, P250, DOI 10.1109/PACIFICVIS.2017.8031601
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Gold BT, 2012, BBA-MOL BASIS DIS, V1822, P416, DOI 10.1016/j.bbadis.2011.07.009
   Hampton WH, 2019, DRUG ALCOHOL DEPEN, V197, P288, DOI 10.1016/j.drugalcdep.2019.02.005
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Heemels MT, 2016, NATURE, V539, P179, DOI 10.1038/539179a
   Hepp DH, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-10146-y
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hua JP, 2005, BIOINFORMATICS, V21, P1509, DOI 10.1093/bioinformatics/bti171
   Inano R, 2014, NEUROIMAGE-CLIN, V5, P396, DOI 10.1016/j.nicl.2014.08.001
   Jenkinson M, 2012, NEUROIMAGE, V62, P782, DOI 10.1016/j.neuroimage.2011.09.015
   Ji L, 2015, NEUROSCIENCE, V305, P109, DOI 10.1016/j.neuroscience.2015.07.060
   Ji XN, 2019, IEEE T VIS COMPUT GR, V25, P2181, DOI 10.1109/TVCG.2019.2903946
   Jianu R, 2012, IEEE T VIS COMPUT GR, V18, P978, DOI 10.1109/TVCG.2011.82
   Jianu R, 2009, IEEE T VIS COMPUT GR, V15, P1449, DOI 10.1109/TVCG.2009.141
   Johnson MD, 2013, IEEE T BIO-MED ENG, V60, P610, DOI 10.1109/TBME.2013.2244890
   Jonsson D., 2019, PROC EUROGRAPHICS WO
   Kamagata K, 2016, EUR RADIOL, V26, P2567, DOI 10.1007/s00330-015-4066-8
   Kikinis R., 2014, INTRAOPERATIVE IMAGI, V3, P277, DOI [DOI 10.1007/978-1-4614-7657-3_19, 10.1007/978-1-4614-7657-3_19]
   Krawczuk J, 2016, ARTIF INTELL MED, V66, P63, DOI 10.1016/j.artmed.2015.11.001
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lella E, 2017, PROC SPIE, V10396, DOI 10.1117/12.2274140
   Levy-Fix G, 2019, Arxiv, DOI arXiv:1906.02664
   Maniyar DM, 2006, PROCEEDINGS OF THE 2006 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P156
   Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005
   Mateos-Pérez JM, 2018, NEUROIMAGE-CLIN, V20, P506, DOI 10.1016/j.nicl.2018.08.019
   Mittring M., 2007, P ACM SIGGRAPH COURS, P97, DOI [DOI 10.1145/1281500.1281671, 00.1281671]
   Mollenhauer B, 2017, P NATL ACAD SCI USA, V114, P3004, DOI 10.1073/pnas.1700737114
   Mumtaz S., 2015, PROC WORKSHOP NEW CH, P114
   Murugesan S, 2017, IEEE ACM T COMPUT BI, V14, P805, DOI 10.1109/TCBB.2016.2564970
   Naghavi M, 2019, BMJ-BRIT MED J, V364, DOI [10.1136/bmj.l94, 10.1016/S1474-4422(18)30403-4]
   Norton I, 2017, CANCER RES, V77, pE101, DOI 10.1158/0008-5472.CAN-17-0332
   O'Donnell LJ, 2011, NEUROSURG CLIN N AM, V22, P185, DOI 10.1016/j.nec.2010.12.004
   Ollivier M., 2018, NEUROGRAPHICS, V8, P154
   Peng W, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P89
   Poewe W, 2017, NAT REV DIS PRIMERS, V3, DOI 10.1038/nrdp.2017.13
   Prakash BD, 2012, PARKINSONISM RELAT D, V18, P1029, DOI 10.1016/j.parkreldis.2012.05.021
   Prange S, 2019, MOVEMENT DISORD, V34, P1644, DOI 10.1002/mds.27793
   Preim B, 2020, COMPUT GRAPH FORUM, V39, P543, DOI 10.1111/cgf.13891
   Rocca WA, 2018, LANCET NEUROL, V17, P928, DOI 10.1016/S1474-4422(18)30355-7
   Saeys Y, 2008, LECT NOTES ARTIF INT, V5212, P313, DOI 10.1007/978-3-540-87481-2_21
   Scherfler C, 2012, BRAIN, V135, P3348, DOI 10.1093/brain/aws253
   Schroeder W. J., 2004, VISUALIZATION TOOL K
   Schultz T, 2019, NMR BIOMED, V32, DOI 10.1002/nbm.3902
   Siirtola H, 2003, INTERNATIONAL CONFERENCE ON COORDINATED AND MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P63, DOI 10.1109/CMV.2003.1215004
   Smith RE, 2012, NEUROIMAGE, V62, P1924, DOI 10.1016/j.neuroimage.2012.06.005
   Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051
   Steenwijk M. D., 2010, PROC IEEE WORKSHOP V
   Sundaram SK, 2008, CEREB CORTEX, V18, P2659, DOI 10.1093/cercor/bhn031
   Tanveer M, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3344998
   Thomason ME, 2011, ANNU REV CLIN PSYCHO, V7, P63, DOI 10.1146/annurev-clinpsy-032210-104507
   Tournier JD, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116137
   Varoquaux G, 2017, NEUROIMAGE, V145, P166, DOI 10.1016/j.neuroimage.2016.10.038
   Wei XB, 2016, SCI REP-UK, V6, DOI 10.1038/srep33762
   Wen MC, 2016, SCI REP-UK, V6, DOI 10.1038/srep35601
   Xu CQ, 2022, IEEE T COGN DEV SYST, V14, P1066, DOI 10.1109/TCDS.2021.3094555
   Yang XS, 2017, IEEE T VIS COMPUT GR, V23, P181, DOI 10.1109/TVCG.2016.2598472
   Yau Y, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02416-0
   Zgraggen E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174053
   Zhang CG, 2016, IEEE T VIS COMPUT GR, V22, P797, DOI 10.1109/TVCG.2015.2467435
   Zhang MX, 2014, NEUROIMAGE, V98, P435, DOI 10.1016/j.neuroimage.2014.04.080
   Zhang XY, 2021, IEEE PAC VIS SYMP, P196, DOI 10.1109/PacificVis52677.2021.00033
   Zhang Y, 2015, MOVEMENT DISORD, V30, P1229, DOI 10.1002/mds.26251
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zheng Z, 2014, HUM BRAIN MAPP, V35, P1325, DOI 10.1002/hbm.22256
NR 94
TC 3
Z9 4
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2020
EP 2035
DI 10.1109/TVCG.2021.3137174
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900009
PM 34965212
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hu, KD
   Haworth, B
   Berseth, G
   Pavlovic, V
   Faloutsos, P
   Kapadia, M
AF Hu, Kaidong
   Haworth, Brandon
   Berseth, Glen
   Pavlovic, Vladimir
   Faloutsos, Petros
   Kapadia, Mubbasir
TI Heterogeneous Crowd Simulation Using Parametric Reinforcement Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Reinforcement learning; Neural networks;
   Collision avoidance; Training; Predictive models; Navigation;
   Multi-agent navigation; crowd simulation; reinforcement learning;
   parametric policy learning
ID NEURAL-NETWORK; NAVIGATION; MODEL
AB Agent-based synthetic crowd simulation affords the cost-effective large-scale simulation and animation of interacting digital humans. Model-based approaches have successfully generated a plethora of simulators with a variety of foundations. However, prior approaches have been based on statically defined models predicated on simplifying assumptions, limited video-based datasets, or homogeneous policies. Recent works have applied reinforcement learning to learn policies for navigation. However, these approaches may learn static homogeneous rules, are typically limited in their generalization to trained scenarios, and limited in their usability in synthetic crowd domains. In this article, we present a multi-agent reinforcement learning-based approach that learns a parametric predictive collision avoidance and steering policy. We show that training over a parameter space produces a flexible model across crowd configurations. That is, our goal-conditioned approach learns a parametric policy that affords heterogeneous synthetic crowds. We propose a model-free approach without centralization of internal agent information, control signals, or agent communication. The model is extensively evaluated. The results show policy generalization across unseen scenarios, agent parameters, and out-of-distribution parameterizations. The learned model has comparable computational performance to traditional methods. Qualitatively the model produces both expected (laminar flow, shuffling, bottleneck) and unexpected (side-stepping) emergent qualitative behaviours, and quantitatively the approach is performant across measures of movement quality.
C1 [Hu, Kaidong; Pavlovic, Vladimir; Kapadia, Mubbasir] Univ Victoria, Dept Comp Sci, Victoria, BC V8P 5C2, Canada.
   [Haworth, Brandon] Univ Victoria, Dept Comp Sci, Victoria, BC V8P 5C2, Canada.
   [Berseth, Glen] Univ Montreal, Dept Comp Sci & Operat Res, MILA, Montreal, PQ H3T 1J4, Canada.
   [Faloutsos, Petros] York Univ, Dept Elect Engn & Comp Sci, Toronto, ON M3J 1P3, Canada.
   [Faloutsos, Petros] Univ Hlth Network, Toronto Rehabil Inst, Toronto, ON M5G 2A2, Canada.
C3 University of Victoria; University of Victoria; Universite de Montreal;
   York University - Canada; University of Toronto; University Health
   Network Toronto; Toronto Rehabilitation Institute
RP Haworth, B (corresponding author), Univ Victoria, Dept Comp Sci, Victoria, BC V8P 5C2, Canada.
EM hukaidonghkd@gmail.com; bhaworth@uvic.ca; gberseth@gmail.com;
   vladimir@cs.rutgers.edu; pfal@cse.yorku.ca; mk1353@cs.rutgers.edu
OI Haworth, Brandon/0000-0001-8134-0047
FU Murray Postdoctoral Fellowship, NSERC CreateDAV, Ontario Research
   Foundation [RE08-054]; NSERC Discovery [RGPIN-2021-03541]; NSF Awards
   [IIS-1703883, SAS-1723869, IIS-1955404, IIS-1955365, RETTL-2119265,
   EAGER-2122119]
FX This work was supported in part by Murray Postdoctoral Fellowship, NSERC
   CreateDAV, Ontario Research Foundation under Grant RE08-054, in part by
   NSERC Discovery under Grant RGPIN-2021-03541, and in part by NSF Awards:
   IIS-1703883, S&AS-1723869, IIS-1955404, IIS-1955365, RETTL-2119265, and
   EAGER-2122119.
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Amirian J, 2019, IEEE COMPUT SOC CONF, P2964, DOI 10.1109/CVPRW.2019.00359
   [Anonymous], P ACM SIGGRAPH
   B HAWORTH., 2015, P 8 ACM SIGGRAPH C M, P91
   Berseth G., 2015, Computer Animation and Virtual Worlds
   Berseth Glen., 2014, P ACM SIGGRAPH EUR S, P113
   Bisagno N, 2019, LECT NOTES COMPUT SC, V11751, P117, DOI 10.1007/978-3-030-30642-7_11
   Brito B, 2020, Arxiv, DOI arXiv:2010.09056
   Daniel BC, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480136
   Casadiego Bastidas L., 2014, THESIS U POLITECNICA
   Casadiego L, 2015, LECT NOTES ARTIF INT, V9238, P119, DOI 10.1007/978-3-319-21996-7_12
   Chen C., 2020, ASIA S PACIF DES AUT, P10007, DOI [DOI 10.1109/IROS45743.2020.9340705, 10.1109/IROS45743.2020.9340705]
   Chen CG, 2019, IEEE INT CONF ROBOT, P6015, DOI [10.1109/ICRA.2019.8794134, 10.1109/icra.2019.8794134]
   Cheng QR, 2018, LECT NOTES COMPUT SC, V11307, P62, DOI 10.1007/978-3-030-04239-4_6
   Chraibi M, 2016, PHYSICA A, V451, P475, DOI 10.1016/j.physa.2016.01.058
   Curtis S., 2014, Pedestrian and Evacuation Dynamics 2012, P875
   Dogan Timur., 2015, Proceedings of Building Simulation 2015, P1853
   Donikian S., 2010, P ACM SIGGRAPH, P1
   Faloutsos P, 2001, COMP GRAPH, P251, DOI 10.1145/383259.383287
   FIORINI P, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P560, DOI 10.1109/ROBOT.1993.292038
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Geng T, 2006, NEURAL COMPUT, V18, P1156, DOI 10.1162/neco.2006.18.5.1156
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Haworth B, 2020, PROCEEDINGS OF THE 13TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2020, DOI 10.1145/3424636.3426894
   Haworth B, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1783
   Haworth M. B., 2019, THESIS YORK U TORONT
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Henry P, 2010, IEEE INT CONF ROBOT, P981, DOI 10.1109/ROBOT.2010.5509772
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Hoyet L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925931
   Huang WL, 2020, PR MACH LEARN RES, V119
   Huerre S., 2010, P ACM SIGGRAPH US CO, p13:1
   Hwangbo J, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aau5872
   Kapadia Mubbasir, 2011, Motion in Games. Proceedings 4th International Conference, MIG 2011, P266, DOI 10.1007/978-3-642-25090-3_23
   Kapadia M., 2011, P 2011 ACM SIGGRAPH, P53, DOI DOI 10.1145/2019406.2019414
   Kapadia Mubbasir., 2009, SCA 09 P 2009 ACM SI, P209, DOI DOI 10.1145/1599470.1599497
   Kapadia Mubbasir, 2011, P 2011 ACM SIGGRAPH, P53, DOI DOI 10.1145/2019406.2019414
   Karamouzas I, 2009, LECT NOTES COMPUT SC, V5884, P41, DOI 10.1007/978-3-642-10347-6_4
   Kingma D.P., 2014, P INT C LEARNING REP
   Kun A, 1996, IEEE INT CONF ROBOT, P240, DOI 10.1109/ROBOT.1996.503784
   Lan XJ, 2020, NEUROCOMPUTING, V410, P410, DOI 10.1016/j.neucom.2020.06.038
   Lee J, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274510
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Li H, 2020, Arxiv, DOI arXiv:1910.10887
   Long PX, 2017, IEEE ROBOT AUTOM LET, V2, P656, DOI 10.1109/LRA.2017.2651371
   Mangalam K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15213, DOI 10.1109/ICCV48922.2021.01495
   Martinez-Gil Francisco, 2012, Adaptive and Learning Agents. International Workshop, ALA 2011 Held at AAMAS 2011. Revised Selected Papers, P54, DOI 10.1007/978-3-642-28499-1_4
   Martinez-Gil F, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3117808
   Martinez-Gil F, 2017, SIMUL MODEL PRACT TH, V74, P117, DOI 10.1016/j.simpat.2017.03.003
   Martinez-Gil F, 2015, AUTON AGENT MULTI-AG, V29, P98, DOI 10.1007/s10458-014-9252-6
   Martinez-Gil F, 2014, SIMUL MODEL PRACT TH, V47, P259, DOI 10.1016/j.simpat.2014.06.005
   McDonnell R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360625
   MILLER WT, 1994, IEEE CONTR SYST MAG, V14, P41, DOI 10.1109/37.257893
   MUBBASIR KAPADIA., 2015, SYNTHESIS LECT VISUA, V7, P1, DOI [10.2200/s00673ed1v01y201509cgr020, DOI 10.2200/S00673ED1V01Y201509CGR020]
   Niu SF, 2018, AAAI CONF ARTIF INTE, P6246
   Pelechano Nuria., 2008, Virtual Crowds: Methods, Simulation, and Control
   Pelechano Nuria., 2008, P 7 INT JOINT C AUTO, V1, P136
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Rasamoelina AD, 2020, 2020 IEEE 18TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2020), P281, DOI [10.1109/SAMI48414.2020.9108717, 10.1109/sami48414.2020.9108717]
   Reynolds C., 1987, ACM SIGGRAPH COMPUTE, V21, P25, DOI [10.1145/37401.37406, https://doi.org/10.1145/37402.37406]
   Salzmann Tim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P683, DOI 10.1007/978-3-030-58523-5_40
   Schulman J., 2016, PROC 4 INT C LEARN R
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Shao W., 2005, SCA 05 P 2005 ACM SI, P19, DOI [10.1145/1073368.1073371, DOI 10.1145/1073368.1073371]
   Singh S, 2011, COMPUT ANIMAT VIRT W, V22, P151, DOI 10.1002/cav.403
   Singh S, 2009, COMPUT ANIMAT VIRT W, V20, P533, DOI 10.1002/cav.277
   Singh Shawn., 2011, ACM SIGGRAPH I3D, P141
   Sohre N., 2020, Motion, Interaction and Games, P1
   Sun LB, 2019, IEEE ACCESS, V7, P109544, DOI 10.1109/ACCESS.2019.2933492
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   TAGA G, 1991, BIOL CYBERN, V65, P147, DOI 10.1007/BF00198086
   Tamar Aviv, 2016, Advances in Neural Information Processing Systems, P2154
   Terry JK, 2023, Arxiv, DOI arXiv:2005.13625
   Thalmann Daniel., 2013, Crowd Simulation, VSecond
   Torrey Lisa., 2010, Proc. Artificial Intelligence and Interactive Digital Entertainment, P89
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   Wang P, 2019, PHYSICA A, V525, P266, DOI 10.1016/j.physa.2019.03.057
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Wolinski D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982442
   Wolinski D, 2014, TRANSP RES PROC, V2, P228, DOI 10.1016/j.trpro.2014.09.041
   Won J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356499
   Yu WH, 2019, IEEE INT C INT ROBOT, P3503, DOI [10.1109/iros40897.2019.8968053, 10.1109/IROS40897.2019.8968053]
NR 89
TC 10
Z9 10
U1 2
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2036
EP 2052
DI 10.1109/TVCG.2021.3139031
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900010
PM 34965213
DA 2024-11-06
ER

PT J
AU Wang, C
   Chai, ML
   He, MM
   Chen, DD
   Liao, J
AF Wang, Can
   Chai, Menglei
   He, Mingming
   Chen, Dongdong
   Liao, Jing
TI Cross-Domain and Disentangled Face Manipulation With 3D Guidance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Aerospace electronics; Three-dimensional displays; Semantics;
   Lighting; Solid modeling; Codes; Face image manipulation; domain
   adaptation; 3D morphable model; disentanglement; StyleGAN2
ID RECONSTRUCTION; IMAGE; VIDEO
AB Face image manipulation via three-dimensional guidance has been widely applied in various interactive scenarios due to its semantically-meaningful understanding and user-friendly controllability. However, existing 3D-morphable-model-based manipulation methods are not directly applicable to out-of-domain faces, such as non-photorealistic paintings, cartoon portraits, or even animals, mainly due to the formidable difficulties in building the model for each specific face domain. To overcome this challenge, we propose, as far as we know, the first method to manipulate faces in arbitrary domains using human 3DMM. This is achieved through two major steps: 1) disentangled mapping from 3DMM parameters to the latent space embedding of a pre-trained StyleGAN2 [1] that guarantees disentangled and precise controls for each semantic attribute; and 2) cross-domain adaptation that bridges domain discrepancies and makes human 3DMM applicable to out-of-domain faces by enforcing a consistent latent space embedding. Experiments and comparisons demonstrate the superiority of our high-quality semantic manipulation method on a variety of face domains with all major 3D facial attributes controllable - pose, expression, shape, albedo, and illumination. Moreover, we develop an intuitive editing interface to support user-friendly control and instant feedback. Our project page is https://cassiepython.github.io/cddfm3d/index.html.
C1 [Wang, Can; Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong 999077, Peoples R China.
   [Chai, Menglei] Snap Inc, Creat Vis Team, Santa Monica, CA 90405 USA.
   [He, Mingming] Univ Southern Calif, Inst Creat Technol, Los Angeles, CA 90007 USA.
   [Chen, Dongdong] Microsoft Cloud AI, Redmond, WA 98052 USA.
C3 City University of Hong Kong; University of Southern California
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong 999077, Peoples R China.
EM cwang355-c@my.cityu.edu.hk; cmlatsim@gmail.com; hmm.lillian@gmail.com;
   cddlyf@gmail.com; jingliao@cityu.edu.hk
RI He, Mingming/AAY-5609-2021; Chen, Dongdong/AAR-4481-2020
OI Chen, Dongdong/0000-0002-4642-4373; wang, can/0000-0002-5102-1464; LIAO,
   Jing/0000-0001-7014-5377
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [9048148
   (CityU 21209119)]; RMGS of CityU Hong Kong [9229064]
FX This work was supported in part by the Hong Kong Research Grants Council
   (RGC) Early Career Scheme under Grant 9048148 (CityU 21209119) and
   inpart by the Donation-RMGS of CityU Hong Kong under Grant 9229064.
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   [Anonymous], 2021, Danbooru2020: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
   Asthana A, 2012, IEEE T VIS COMPUT GR, V18, P1511, DOI 10.1109/TVCG.2011.157
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen DD, 2017, IEEE I CONF COMP VIS, P1114, DOI 10.1109/ICCV.2017.126
   Choi Y, 2020, PROC CVPR IEEE, P8185, DOI 10.1109/CVPR42600.2020.00821
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Erik Harkonen, 2020, Advances in Neural Information Processing Systems, V33, P9841
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Fried O, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925933
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Gecer B, 2018, LECT NOTES COMPUT SC, V11215, P230, DOI 10.1007/978-3-030-01252-6_14
   Geng JH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275043
   Geng ZL, 2019, PROC CVPR IEEE, P9813, DOI 10.1109/CVPR.2019.01005
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Ha S, 2020, AAAI CONF ARTIF INTE, V34, P10893
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35
   Justin Pinkney P, TOONIFY YOURSELF
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356500
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Kwong Sam, 2021, IEEE T MULTIMEDIA
   Lattas A, 2020, PROC CVPR IEEE, P757, DOI 10.1109/CVPR42600.2020.00084
   Mikolov I., 2013, P ADV NEURAL INFORM, V26, P1
   Pinkney JNM, 2020, Arxiv, DOI arXiv:2010.05334
   Natsume R, 2019, LECT NOTES COMPUT SC, V11366, P117, DOI 10.1007/978-3-030-20876-9_8
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Pinkney J.N.M., 2020, Aligned ukiyo-e faces dataset
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, 10.48550/ARXIV.1511.06434]
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Siarohin A, 2019, ADV NEUR IN, V32
   Siarohin A, 2019, PROC CVPR IEEE, P2372, DOI 10.1109/CVPR.2019.00248
   Smith WAP, 2020, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR42600.2020.00506
   Song GX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459771
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tewari A, 2017, IEEE I CONF COMP VIS, P3735, DOI 10.1109/ICCV.2017.401
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Wu ZZ, 2021, PROC CVPR IEEE, P12858, DOI 10.1109/CVPR46437.2021.01267
   Xiang ST, 2020, Arxiv, DOI arXiv:2004.12452
   Xu S., 2020, P IEEE C COMP VIS PA, P7707
   Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 59
TC 5
Z9 5
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2053
EP 2066
DI 10.1109/TVCG.2021.3139913
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900011
PM 34982684
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, MD
   Li, Q
   Chen, L
   Yuan, XR
   Yong, JH
AF Zhang, Mingdong
   Li, Quan
   Chen, Li
   Yuan, Xiaoru
   Yong, Junhai
TI <i>EnConVis:</i> A Unified Framework for Ensemble Contour Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Uncertainty; Data models; Computational modeling;
   Feature extraction; Visualization; Analytical models; Uncertainty
   visualization; ensemble visualization; visualization framework; contour
   visualization
ID VISUAL ANALYSIS; NONPARAMETRIC MODELS; GEOPOTENTIAL HEIGHT; UNCERTAINTY;
   VARIABILITY; EXPLORATION; SIMILARITY; GRAPH; SETS
AB Ensemble simulation is a crucial method to handle potential uncertainty in modern simulation and has been widely applied in many disciplines. Many ensemble contour visualization methods have been introduced to facilitate ensemble data analysis. On the basis of deep exploration and summarization of existing techniques and domain requirements, we propose a unified framework of ensemble contour visualization, EnConVis (Ensemble Contour Visualization), which systematically combines state-of-the-art methods. We model ensemble contour visualization as a four-step pipeline consisting of four essential procedures: member filtering, point-wise modeling, uncertainty band extraction, and visual mapping. For each of the four essential procedures, we compare different methods they use, analyze their pros and cons, highlight research gaps, and attempt to fill them. Specifically, we add Kernel Density Estimation in the point-wise modeling procedure and multi-layer extraction in the uncertainty band extraction procedure. This step shows the ensemble data's details accurately and provides abstract levels. We also analyze existing methods from a global perspective. We investigate their mechanisms and compare their effects, on the basis of which, we offer selection guidelines for them. From the overall perspective of this framework, we find choices and combinations that have not been tried before, which can be well compensated by our method. Synthetic data and real-world data are leveraged to verify the efficacy of our method. Domain experts' feedback suggests that our approach helps them better understand ensemble data analysis.
C1 [Zhang, Mingdong; Chen, Li; Yong, Junhai] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Sch AI, Key Lab Machine Percept MoE, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Tsinghua University; ShanghaiTech University; Peking University; Peking
   University
RP Chen, L (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM zhangmd14@mails.tsinghua.edu.cn; liquan@shanghaitech.edu.cn;
   chenlee@tsinghua.edu.cn; xiaoru.yuan@pku.edu.cn;
   yongjunhai@tsinghua.edu.cn
RI Yuan, Xiaoru/E-1798-2013
OI , Mingdong/0000-0003-2536-9456
FU National Natural Science Foundation of China [62021002, 61572274,
   61972221]; National Key R&D Program of China [2019YFB1405703,
   TC190A4DA/3]
FX Manuscript received 1 Sept. 2021; revised 29 Dec. 2021; accepted 30 Dec.
   2021. Date of publication 4 Jan. 2022; date of current version 28 Feb.
   2023.This work was supported in part by the National Natural Science
   Foundation of China under Grants 62021002, 61572274, and 61972221, and
   the National Key R & D Program of China under Grants 2019YFB1405703 and
   TC190A4DA/3.
CR Ahmed AGM, 2017, IEEE T VIS COMPUT GR, V23, P2496, DOI 10.1109/TVCG.2016.2641963
   Alsallakh B, 2017, IEEE T VIS COMPUT GR, V23, P361, DOI 10.1109/TVCG.2016.2598496
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Bensema K, 2016, IEEE T VIS COMPUT GR, V22, P2289, DOI 10.1109/TVCG.2015.2507569
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Fofonov A, 2016, IEEE T VIS COMPUT GR, V22, P2037, DOI 10.1109/TVCG.2015.2498554
   Gosink L, 2013, IEEE T VIS COMPUT GR, V19, P2703, DOI 10.1109/TVCG.2013.138
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P1716, DOI 10.1109/TVCG.2018.2879866
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Karniadakis GE, 2006, J COMPUT PHYS, V217, P1, DOI 10.1016/j.jcp.2006.06.009
   Kumpf A, 2018, IEEE T VIS COMPUT GR, V24, P109, DOI 10.1109/TVCG.2017.2745178
   Leutbecher M, 2008, J COMPUT PHYS, V227, P3515, DOI 10.1016/j.jcp.2007.02.014
   Lewis JM, 2005, MON WEATHER REV, V133, P1865, DOI 10.1175/MWR2949.1
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Liu L, 2019, IEEE T VIS COMPUT GR, V25, P882, DOI 10.1109/TVCG.2018.2865193
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Liu P, 2018, CLIM DYNAM, V51, P701, DOI 10.1007/s00382-017-3950-0
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Ma B, 2019, IEEE T VIS COMPUT GR, V25, P1091, DOI 10.1109/TVCG.2018.2864815
   Mirzargar M, 2018, COMPUT GRAPH FORUM, V37, P13, DOI 10.1111/cgf.13397
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Mitchell SA, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3194657
   Montgomery JM, 2012, POLIT ANAL, V20, P271, DOI 10.1093/pan/mps002
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Pfaffelmoser T., 2013, PROC 15 EUROGRAPHICS
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Qiao SB, 2020, CLIM DYNAM, V54, P1591, DOI 10.1007/s00382-019-05074-8
   Quinan PS, 2016, IEEE T VIS COMPUT GR, V22, P389, DOI 10.1109/TVCG.2015.2467754
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shu QY, 2016, IEEE PAC VIS SYMP, P56, DOI 10.1109/PACIFICVIS.2016.7465251
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Weyn JA, 2019, J ADV MODEL EARTH SY, V11, P2680, DOI 10.1029/2019MS001705
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Yalçin MA, 2016, IEEE T VIS COMPUT GR, V22, P688, DOI 10.1109/TVCG.2015.2467051
   Yan DM, 2015, J COMPUT SCI TECH-CH, V30, P439, DOI 10.1007/s11390-015-1535-0
   Zhang MD, 2021, IEEE T VIS COMPUT GR, V27, P1808, DOI 10.1109/TVCG.2020.3030377
NR 53
TC 4
Z9 4
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2067
EP 2079
DI 10.1109/TVCG.2021.3140153
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900012
PM 34982686
DA 2024-11-06
ER

PT J
AU Zhang, SH
   Chen, CH
   Zheng, F
   Yang, YL
   Hu, SM
AF Zhang, Song-Hai
   Chen, Chia-Hao
   Zheng, Fu
   Yang, Yong-Liang
   Hu, Shi-Min
TI Adaptive Optimization Algorithm for Resetting Techniques in
   Obstacle-Ridden Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Optimization; Heuristic algorithms; Navigation; Space
   vehicles; Layout; Space exploration; Redirected walking; resetting;
   adaptive optimization; obstacle-ridden area; redirection
AB Redirected Walking (RDW) algorithms aim to impose several types of gains on users immersed in Virtual Reality and distort their walking paths in the real world, thus enabling them to explore a larger space. Since collision with physical boundaries is inevitable, a reset strategy needs to be provided to allow users to reset when they hit the boundary. However, most reset strategies are based on simple heuristics by choosing a seemingly suitable solution, which may not perform well in practice. In this article, we propose a novel optimization-based reset algorithm adaptive to different RDW algorithms. Inspired by the approach of finite element analysis, our algorithm splits the boundary of the physical world by a set of endpoints. Each endpoint is assigned a reset vector to represent the optimized reset direction when hitting the boundary. The reset vectors on the edge will be determined by the interpolation between two neighbouring endpoints. We conduct simulation-based experiments for three RDW algorithms with commonly used reset algorithms to compare with. The results demonstrate that the proposed algorithm significantly reduces the number of resets.
C1 [Zhang, Song-Hai; Hu, Shi-Min] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRist, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
   [Chen, Chia-Hao; Zheng, Fu] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
   [Yang, Yong-Liang] Univ Bath, Dept Comp Sci, Bath BA2 7AY, England.
C3 Tsinghua University; Tsinghua University; University of Bath
RP Zhang, SH (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRist, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
EM shz@tsinghua.edu.cn; shimin@tsinghua.edu.cn; accplusjh@gmail.com;
   y.yang@cs.bath.ac.uk; gynyfyt2012@hotmail.com
RI Hu, Shi-Min/AAW-1952-2020; Chen, Chao-Jung/E-5481-2011
OI Yang, Yong-Liang/0000-0002-8071-5756; Hu, Shi-Min/0000-0001-7507-6542
FU National Key Technology RD Program [2017YFB1002604]; National Natural
   Science Foundation of China [61521002, 62132012]; Research Grant of
   Beijing Higher Institution Engineering Research Center; Tsinghua-Tencent
   Joint Laboratory for Internet Innovation Technology; RCUK Grant CAMERA
   [EP/M023281/1, EP/T022523/1]; EPSRC [EP/M023281/1, EP/T022523/1] Funding
   Source: UKRI
FX This work was supported in part by National Key Technology R & D Program
   under Grant 2017YFB1002604, in part by the National Natural Science
   Foundation of China under Grants 61521002 and 62132012, and in part by
   the Research Grant of Beijing Higher Institution Engineering Research
   Center ,and Tsinghua-Tencent Joint Laboratory for Internet Innovation
   Technology.The work of Yong-Liang Yang was supported by RCUK Grant
   CAMERA(EP/M023281/1, EP/T022523/1), and a gift from Adobe.
CR Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen H., 2018, PROC IEEE VR WORKSHO
   Chen HW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P523
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Fajen BR, 2003, J EXP PSYCHOL HUMAN, V29, P343, DOI 10.1037/0096-1523.29.2.343
   Feng T, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925894
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hrennikoff A., 1941, J. Appl. Mech., V8, pA169, DOI [DOI 10.1115/1.4009129, 10.1115/1.4009129]
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Langbehn E, 2019, ACM SIGGRAPH 2019 EMERGING TECHNOLOGIES (SIGGRAPH '19), DOI 10.1145/3305367.3327976
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Razzaque S., 2005, Redirected Walking
   Sekiya N, 1996, J HUM MOVEMENT STUD, V30, P241
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P59, DOI 10.1145/3196709.3196792
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.00-82, 10.1109/VR46266.2020.1581503942658]
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Yu R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P313, DOI 10.1109/VR.2018.8448288
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 35
TC 7
Z9 7
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2080
EP 2092
DI 10.1109/TVCG.2021.3139990
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900013
PM 34982685
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Covaci, A
   Saleme, EB
   Mesfin, G
   Comsa, IS
   Trestian, R
   Santos, CAS
   Ghinea, G
AF Covaci, Alexandra
   Saleme, Estevao B.
   Mesfin, Gebremariam
   Comsa, Ioan-Sorin
   Trestian, Ramona
   Santos, Celso A. S.
   Ghinea, George
TI Multisensory 360° Videos Under Varying Resolution Levels Enhance
   Presence
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multisensory; 360-degree videos; encoding quality; presence; mulsemedia
ID EXPERIENCE; QUESTIONNAIRES
AB Omnidirectional videos have become a leading multimedia format for Virtual Reality applications. While live 360 degrees videos offer a unique immersive experience, streaming of omnidirectional content at high resolutions is not always feasible in bandwidth-limited networks. While in the case of flat videos, scaling to lower resolutions works well, 360 degrees video quality is seriously degraded because of the viewing distances involved in head-mounted displays. Hence, in this article, we investigate first how quality degradation impacts the sense of presence in immersive Virtual Reality applications. Then, we are pushing the boundaries of 360 degrees technology through the enhancement with multisensory stimuli. 48 participants experimented both 360 degrees scenarios (with and without multisensory content), while they were divided randomly between four conditions characterised by different encoding qualities (HD, FullHD, 2.5K, 4K). The results showed that presence is not mediated by streaming at a higher bitrate. The trend we identified revealed however that presence is positively and significantly impacted by the enhancement with multisensory content. This shows that multisensory technology is crucial in creating more immersive experiences.
C1 [Covaci, Alexandra] Univ Kent, Canterbury CT2 7NZ, England.
   [Saleme, Estevao B.; Santos, Celso A. S.] Fed Inst Espirito St, BR-29075910 Vitoria, Brazil.
   [Mesfin, Gebremariam] Kristiania Univ Coll, N-0107 Oslo, Norway.
   [Comsa, Ioan-Sorin] Swiss Distance Univ Appl Sci, CH-3900 Brig, Switzerland.
   [Trestian, Ramona] Middlesex Univ, London NW4 4BT, England.
   [Ghinea, George] Brunel Univ London, Uxbridge UB8 3PH, England.
C3 University of Kent; Kristiania University College; Middlesex University;
   Brunel University
RP Covaci, A (corresponding author), Univ Kent, Canterbury CT2 7NZ, England.
EM a.covaci@kent.ac.uk; estevaobissoli@gmail.com;
   gebremariam.assres@kristiania.no; ioansorin.comsa@gmail.com;
   r.trestian@mdx.ac.uk; saibel@inf.ufes.br; george.ghinea@brunel.ac.uk
RI Ghinea, Gheorghita/AAG-6770-2020; Saleme, Estevao/AAZ-7161-2020;
   Trestian, Ramona/AAC-9309-2021; Santos, Celso/M-9733-2014
OI Bissoli Saleme, Estevao/0000-0003-1856-3824; Assres, Gebremariam
   Mesfin/0000-0002-6760-690X; Santos, Celso/0000-0002-3287-5843; Covaci,
   Alexandra/0000-0002-3205-2273
FU Horizon 2020 project NEWTON [ICT-688503]; Federal Institute of Santo
FX This work has been performed in the framework of the Horizon 2020
   project NEWTON (ICT-688503). Estevao B. Saleme also acknowledges support
   from the Federal Institute of Santo.
CR Ademoye OA, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2957753
   Ademoye OA, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487270
   Ademoye OA, 2009, IEEE T MULTIMEDIA, V11, P561, DOI 10.1109/TMM.2009.2012927
   Alcañiz M, 2009, PRESENCE-TELEOP VIRT, V18, P97, DOI 10.1162/pres.18.2.97
   Bao YN, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P1161, DOI 10.1109/BigData.2016.7840720
   Cisco V., 2018, Cisco visual networking index: Forecast and trends, 2017-2022
   Comsa IS, 2020, IEEE MULTIMEDIA, V27, P27, DOI 10.1109/MMUL.2019.2954405
   Covaci A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2378, DOI 10.1145/3343031.3350954
   Covaci A, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3233774
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   Egan D., 2017, 2nd International Workshop on Multimedia Alternate Realities, P15
   Fiedler M., 2018, PROC 10 INT C QUAL M, P1
   Ghinea G, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071398
   Ghinea G, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2617994
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Guedes ALV, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901743
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.0028, 10.1109/ISM.2016.45]
   Ikei Y., 2012, 2012 18th International Conference on Virtual Systems and Multimedia (VSMM 2012). Proceedings, P71, DOI 10.1109/VSMM.2012.6365909
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality
   Jones S., 2017, Journal of Media Practice, V18, P171, DOI DOI 10.1080/14682753.2017.1374677
   Le Callet P., 2012, European Network on Quality of Experience in Multimedia Systems and Services (COST Action IC 1003), V3
   Liu X, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P50, DOI 10.1145/3152434.3152443
   Meehan M, 2005, APPL PSYCHOPHYS BIOF, V30, P239, DOI 10.1007/s10484-005-6381-3
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Murray N, 2013, IEEE INT CON MULTI
   Murray N, 2017, INT WORK QUAL MULTIM
   Paudyal P., 2016, MULTIMEDIA TOOLS APP, V75, p16 461
   Perfecto C, 2020, IEEE T COMMUN, V68, P2491, DOI 10.1109/TCOMM.2020.2965527
   Ranasinghe N, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418451
   Ranasinghe N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174151
   Saleme EB, 2019, MULTIMEDIA SYST, V25, P421, DOI 10.1007/s00530-019-00618-8
   Santos Marcio Carneiro dos, 2019, Intercom, Rev. Bras. Ciênc. Comun., V42, P133, DOI 10.1590/1809-5844201937
   Schatz R, 2017, INT WORK QUAL MULTIM
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Singla A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1163, DOI [10.1109/VR.2019.8798291, 10.1109/vr.2019.8798291]
   Skupin R, 2016, IEEE INT SYM MULTIM, P399, DOI [10.1109/ISM.2016.137, 10.1109/ISM.2016.0089]
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Timmerer C, 2015, COMPUTER, V48, P108, DOI 10.1109/MC.2015.89
   Tran H.T., 2017, IEEE INT WORKSH MULT, P1
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Valjamae A., 2005, THESIS CHALMERS TEKN
   Van Damme K, 2019, JOURNALISM STUD, V20, P2053, DOI 10.1080/1461670X.2018.1561208
   Van den Broeck M, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P762, DOI 10.1145/3123266.3123347
   Wiederhold B. K., 2001, CYBERPSYCHOL MIND CO
   Wilberz A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376481
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Xie L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P315, DOI 10.1145/3123266.3123291
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1080/17445302.2018.1558727, 10.1109/TCSVT.2018.2886277]
   Yuan ZH, 2014, INT WIREL COMMUN, P1142, DOI 10.1109/IWCMC.2014.6906515
   Yuan ZH, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2661329
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
   Zhao TS, 2017, IEEE COMMUN SURV TUT, V19, P285, DOI 10.1109/COMST.2016.2619982
   Zhou C, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P27, DOI 10.1145/3083187.3083190
   Zink M, 2019, P IEEE, V107, P639, DOI 10.1109/JPROC.2019.2894817
NR 56
TC 3
Z9 3
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2093
EP 2101
DI 10.1109/TVCG.2022.3140875
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900014
PM 34990363
OA Green Published
DA 2024-11-06
ER

PT J
AU Lehman, SM
   Elezovikj, S
   Ling, HB
   Tan, CC
AF Lehman, Sarah M.
   Elezovikj, Semir
   Ling, Haibin
   Tan, Chiu C.
TI ARCHIE plus plus : A Cloud-Enabled Framework for Conducting AR System
   Testing in the Wild
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Testing; Usability; System testing; Market research; User experience;
   Task analysis; System performance; Augmented reality; testing and
   debugging; mobile applications; human-centered computing
ID AUGMENTED REALITY; USABILITY; EDUCATION
AB In this paper, we present ARCHIE++, a testing framework for conducting AR system testing and collecting user feedback in the wild. Our system addresses challenges in AR testing practices by aggregating usability feedback data (collected in situ) with system performance data from that same time period. These data packets can then be leveraged to identify edge cases encountered by testers during unconstrained usage scenarios. We begin by presenting a set of current trends in performing human testing of AR systems, identified by reviewing a selection of recent work from leading conferences in mixed reality, human factors, and mobile and pervasive systems. From the trends, we identify a set of challenges to be faced when attempting to adopt these practices to testing in the wild. These challenges are used to inform the design of our framework, which provides a cloud-enabled and device-agnostic way for AR systems developers to improve their knowledge of environmental conditions and to support scalability and reproducibility when testing in the wild. We then present a series of case studies demonstrating how ARCHIE++ can be used to support a range of AR testing scenarios, and demonstrate the limited overhead of the framework through a series of evaluations. We close with additional discussion on the design and utility of ARCHIE++ under various edge conditions.
C1 [Lehman, Sarah M.; Elezovikj, Semir; Tan, Chiu C.] Temple Univ, Philadelphia, PA 19122 USA.
   [Ling, Haibin] SUNY Stony Brook, Stony Brook, NY 11794 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple
   University; State University of New York (SUNY) System; Stony Brook
   University
RP Lehman, SM (corresponding author), Temple Univ, Philadelphia, PA 19122 USA.
EM smlehman@temple.edu; semir@temple.edu; hling@cs.stonybrook.edu;
   cctan@temple.edu
OI Lehman, Sarah/0000-0002-9466-0688; Ling, Haibin/0000-0003-4094-8413
FU NSF [2006665, 2128350, 2128187]
FX Dr. Haibin Ling's work was supported in part by NSF under Grants 2006665
   , 2128350, and 2128187.
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   An J, 2020, J CHEM EDUC, V97, P97, DOI 10.1021/acs.jchemed.9b00453
   Apple Developer, REAL COMP AUGM REAL
   Barbieri S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6596
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bonetti F, 2018, PROGR IS, P119, DOI 10.1007/978-3-319-64027-3_9
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chen P, 2017, LECT N EDUC TECHNOL, P13, DOI 10.1007/978-981-10-2419-1_2
   Costa L, 2020, CHIIR'20: PROCEEDINGS OF THE 2020 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P462, DOI 10.1145/3343413.3377985
   Dacko SG, 2017, TECHNOL FORECAST SOC, V124, P243, DOI 10.1016/j.techfore.2016.09.032
   Ewais A, 2019, J EDUC COMPUT RES, V57, P1643, DOI 10.1177/0735633119855609
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Google, FIR
   Hughes CL, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.602954
   Ivory MY, 2001, ACM COMPUT SURV, V33, P470, DOI 10.1145/503112.503114
   Joseph B, 2016, OXF MED CASE REP, P265, DOI 10.1093/omcr/omw080
   Kelly RM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300515
   Kim S, 2019, APPL ERGON, V74, P186, DOI 10.1016/j.apergo.2018.08.026
   Kolasinski E. M., 1995, 1027 I BEH SOC SCI U
   Lehman SM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P903, DOI [10.1109/VR46266.2020.00115, 10.1109/VR46266.2020.1581006269928]
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Microsoft Docs, TEST YOUR APP HOL MI
   Microsoft Docs, PERC SIM MIX REAL
   Microsoft Docs, US WIND MIX REAL SIM
   Microsoft Docs, US HOL EM MIX REAL
   Mottelson A, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139141
   National Aeronautics and Space Administration, TLX @ NASA AmesHome
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376330
   Oculus Documentation, PERF HEADS UP DISPL
   Oculus Documentation, COMP MIRR
   Oculus Documentation, VR PERF OPT GUID
   OculusDocumentation, OC DEB TOOL
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Poretski L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300921
   Radu I, 2016, PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC2016), P288, DOI 10.1145/2930674.2930726
   Roberto P, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311748
   Rochlen LR, 2017, SIMUL HEALTHC, V12, P57, DOI 10.1097/SIH.0000000000000185
   Snapchat Inc, SNAPCH APPS GOOGL PL
   Tetnpleman R, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23014
   Unity3D, UNITY3D GAM ENG
   Unity3D, PLATF DEV
   Unity3D, XR SUGG PLATF
   Unreal Engine Documentation, PROF TOOL REF
   Usability.gov, SYST US SCAL SUS
   V ~avra P., 2017, J HEALTHCARE ENG, V2017
   Vovk A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173783
   Zarepour E, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS)
NR 49
TC 2
Z9 2
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2102
EP 2116
DI 10.1109/TVCG.2022.3141029
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900015
PM 34990364
DA 2024-11-06
ER

PT J
AU Wang, SD
   Wang, WC
   Zhao, H
AF Wang, Shaodong
   Wang, Wencheng
   Zhao, Hui
TI Using Foliation Leaves to Extract Reeb Graphs on Surfaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Harmonic analysis; Surface treatment; Shape; Level set; Task analysis;
   Skeleton; Manifolds; Reeb graph; topology; foliation
ID 3D SHAPE RETRIEVAL; TOPOLOGICAL SIMPLIFICATION; MESH
AB For Reeb graph extraction on surfaces, existing methods always use the isolines of a function defined on the surface to detect the surface components and the neighboring relationships between them. Since such detection is unstable, it is still a challenge for the extracted Reeb graphs to stably and concisely encode the topological information of the surface. In this article, we address this challenge by using foliation leaves to extract Reeb graphs. In particular, we employ a method for generating measured harmonic foliations by defining loops for foliation initialization and diffusing leaves from loops over the surface. We demonstrate that when the loops are determined, the neighboring relationships between the leaves from different loops are fixed. Thus, we can use loops to represent surface components for robustly detecting the interrelationships between surface components. As a result, we are able to extract stable and concise Reeb graphs. We developed novel measures for loop determination and improved foliation generation, and our method allows the user to manually prescribe loops for generating Reeb graphs with desired structures. Therefore, the potential of Reeb graphs for representing surfaces is enhanced, including conveniently representing the symmetries of the surface and ignoring topological noise. This is verified by our experimental results which indicate that our Reeb graphs are compact and expressive, promoting shape analysis.
C1 [Wang, Wencheng] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100045, Peoples R China.
   Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, WC (corresponding author), Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing 100045, Peoples R China.
EM wangsd@ios.ac.cn; whn@ios.ac.cn; huizhao@ios.ac.cn
RI Wang, Wencheng/A-3828-2009
OI Zhao, Hui/0000-0003-4442-043X; Wang, Shaodong/0000-0002-7982-6600; wang,
   wen cheng/0000-0001-5094-4606
FU National Natural Science Foundation of China [62072446]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62072446.
CR [Anonymous], 2004, SCG'04: Proceedings of the twentieth annual symposium on Computational geometry, (New York, NY, USA)
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Barra V, 2013, PATTERN RECOGN, V46, P2985, DOI 10.1016/j.patcog.2013.03.019
   Bauer U, 2012, DISCRETE COMPUT GEOM, V47, P347, DOI 10.1007/s00454-011-9350-z
   Biasotti S, 2000, LECT NOTES COMPUT SC, V1953, P185
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Campen M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925890
   Cole-McLaughlin K, 2004, DISCRETE COMPUT GEOM, V32, P231, DOI 10.1007/s00454-004-1122-6
   Crane K, KEENAN CRANE 3DMODEL
   Dey TK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462017
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   Doraiswamy H, 2012, IEEE T VIS COMPUT GR, V18, P146, DOI 10.1109/TVCG.2011.37
   Dyer R., 2007, SGP 07, P273
   Eppstein D, 2003, SIAM PROC S, P599
   Erickson J, 2005, PROCEEDINGS OF THE SIXTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1038
   Erickson J, 2013, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS (SODA 2013), P1646
   Fathi A., 2012, Mathematical Notes, V48
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   Gupta S, 2017, CONTEMP MATH, V696, P153, DOI 10.1090/conm/696/14021
   Hajij M, 2020, ALGORITHMS, V13, DOI 10.3390/a13100258
   Hajij M, 2016, GRAPH MODELS, V88, P12, DOI 10.1016/j.gmod.2016.09.003
   Harvey W, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P267, DOI 10.1145/1810959.1811005
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Hildebrandt K., 2005, S GEOM PROC, P85, DOI 10.2312/SGP/SGP05/085-090
   Junyi Tu, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P99, DOI 10.1007/978-3-030-33720-9_8
   Khoury R. E., 2012, PROC SPIE THE INT SO, V8290, P157
   Lei N, 2017, COMPUT METHOD APPL M, V321, P406, DOI 10.1016/j.cma.2017.04.012
   Lei N, 2017, COMPUT METHOD APPL M, V316, P758, DOI 10.1016/j.cma.2016.09.044
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Myles A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601154
   Ni XL, 2004, ACM T GRAPHIC, V23, P613, DOI 10.1145/1015706.1015769
   Nikolaev I., 2001, FOLIATIONS SURFACES
   Palmer D. R., 2016, THESIS HARVARD COLL
   Parsa S., 2014, THESIS DUKE U DURHAM
   Parsa S, 2013, DISCRETE COMPUT GEOM, V49, P864, DOI 10.1007/s00454-013-9511-3
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Patanè G, 2009, COMPUT GRAPH-UK, V33, P399, DOI 10.1016/j.cag.2009.03.014
   Patanè G, 2009, IEEE T VIS COMPUT GR, V15, P583, DOI 10.1109/TVCG.2009.22
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P44, DOI 10.1109/38.103393
   Sorgente T, 2018, COMPUT AIDED GEOM D, V65, P13, DOI 10.1016/j.cagd.2018.07.001
   Springborn B, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360676
   Strebel K., 1984, Quadratic Differentials, P16, DOI [10.1007/978-3-662-02414-02, DOI 10.1007/978-3-662-02414-02]
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   threedscans, ABOUT US
   Tierny J, 2008, VISUAL COMPUT, V24, P155, DOI 10.1007/s00371-007-0181-0
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P1650, DOI 10.1109/TVCG.2011.270
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Vekhter J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323043
   Wang CL, 2017, COMPUT GRAPH FORUM, V36, P263, DOI 10.1111/cgf.12800
   Wang S., COMPUT GRAPHICS-US
   Wardetzky Max, 2007, P 5 EUR S GEOM PROC, P33, DOI [10.2312/SGP/SGP07/033-037, DOI 10.2312/SGP/SGP07/033-037]
   Zhao H, 2022, IEEE T VIS COMPUT GR, V28, P1529, DOI 10.1109/TVCG.2020.3016574
NR 59
TC 0
Z9 0
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2117
EP 2131
DI 10.1109/TVCG.2022.3141764
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900016
PM 35015643
DA 2024-11-06
ER

PT J
AU Liu, CL
   Wang, LY
   Li, Z
   Quan, SX
   Xu, Y
AF Liu, Celong
   Wang, Lingyu
   Li, Zhong
   Quan, Shuxue
   Xu, Yi
TI Real-Time Lighting Estimation for Augmented Reality via Differentiable
   Screen-Space Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Rendering (computer graphics); Real-time systems; Estimation;
   Probes; Image reconstruction; Geometry; Mixed/augmented reality;
   rendering; scene understanding; light estimation; real time
ID ILLUMINATION
AB Augmented Reality (AR) applications aim to provide realistic blending between the real-world and virtual objects. One of the important factors for realistic AR is the correct lighting estimation. In this article, we present a method that estimates the real-world lighting condition from a single image in real time, using information from an optional support plane provided by advanced AR frameworks (e.g., ARCore, ARKit, etc.). By analyzing the visual appearance of the real scene, our algorithm can predict the lighting condition from the input RGB photo. In the first stage, we use a deep neural network to decompose the scene into several components: lighting, normal, and Bidirectional Reflectance Distribution Function (BRDF). Then we introduce differentiable screen-space rendering, a novel approach to providing the supervisory signal for regressing lighting, normal, and BRDF jointly. We recover the most plausible real-world lighting condition using Spherical Harmonics and the main directional lighting. Through a variety of experimental results, we demonstrate that our method can provide improved results than prior works quantitatively and qualitatively, and it can enhance the real-time AR experiences.
C1 [Liu, Celong] Bytedance Inc, Mountain View, CA 94041 USA.
   [Wang, Lingyu] OPPO US Res Ctr, Augmented Real, Palo Alto, CA 94303 USA.
   [Li, Zhong; Quan, Shuxue; Xu, Yi] InnoPeak Technol Inc, OPPO US Res Ctr, Palo Alto, CA 94303 USA.
RP Liu, CL (corresponding author), Bytedance Inc, Mountain View, CA 94041 USA.
EM celong.liu@bytedance.com; lingyu.wang@oppo.com; zhong.li@oppo.com;
   shuxue.quan@oppo.com; yi.xu@oppo.com
RI Li, Zhong/GYU-9049-2022; Liu, Celong/AAE-2562-2019; Wang,
   lingyu/JLM-2013-2023
OI Li, Zhong/0000-0002-7416-1216
CR Azinovic D, 2019, PROC CVPR IEEE, P2442, DOI 10.1109/CVPR.2019.00255
   Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10
   Calian DA, 2018, COMPUT GRAPH FORUM, V37, P51, DOI 10.1111/cgf.13341
   Chalmers A, 2021, IEEE T VIS COMPUT GR, V27, P4073, DOI 10.1109/TVCG.2020.3001917
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891
   Gardner MA, 2019, IEEE I CONF COMP VIS, P7174, DOI 10.1109/ICCV.2019.00727
   Garon M, 2019, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2019.00707
   Georgoulis S, 2018, IEEE T PATTERN ANAL, V40, P1932, DOI 10.1109/TPAMI.2017.2742999
   Georgoulis S, 2017, IEEE I CONF COMP VIS, P5180, DOI 10.1109/ICCV.2017.553
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Gruber L, 2012, INT SYM MIX AUGMENT, P119, DOI 10.1109/ISMAR.2012.6402548
   Janner M, 2017, ADV NEUR IN, V30
   Kajiya James T., 1986, P ANN C COMP GRAPH I, DOI 10.1145/15886.15902
   Karis Brian, 2013, Proc. Physically Based Shading Theory Practice, V4, P1
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Knorr SB, 2014, INT SYM MIX AUGMENT, P113, DOI 10.1109/ISMAR.2014.6948416
   LeGendre C, 2019, PROC CVPR IEEE, P5911, DOI 10.1109/CVPR.2019.00607
   LeGendre Chloe, 2020, PROC SIGGRAPH ASIA T, P1
   Li TM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275109
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Li ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275055
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Mandl D, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P82, DOI 10.1109/ISMAR.2017.25
   Maximov M, 2019, IEEE I CONF COMP VIS, P8728, DOI 10.1109/ICCV.2019.00882
   Monroy R., 2018, PROC C VIS MODEL VIS, P21
   Murmann L, 2019, IEEE I CONF COMP VIS, P4079, DOI 10.1109/ICCV.2019.00418
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Park J, 2020, IEEE T VIS COMPUT GR, V26, P2002, DOI 10.1109/TVCG.2020.2973050
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Rematas K, 2016, PROC CVPR IEEE, P4508, DOI 10.1109/CVPR.2016.488
   Ritschel T., 2009, P S INT 3D GRAPH GAM, P75, DOI [10.1145/1507149.1507161, DOI 10.1145/1507149.1507161, 10.1145/1507149.1507161.5,7]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Sloan Peter-Pike, 2008, GAM DEV C, V9, P42
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   Srinivasan PP, 2020, PROC CVPR IEEE, P8077, DOI 10.1109/CVPR42600.2020.00810
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Weber H, 2018, INT CONF 3D VISION, P199, DOI 10.1109/3DV.2018.00032
   Wu Y., 2019, Detectron2
   Xu Y, 2010, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2010.5539825
   Yu Y, 2019, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2019.00327
   Zhang C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356522
   Zhang E, 2018, PROC CVPR IEEE, P6635, DOI 10.1109/CVPR.2018.00694
   Zhang E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982432
NR 52
TC 3
Z9 4
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2132
EP 2145
DI 10.1109/TVCG.2022.3141943
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900017
PM 35015644
DA 2024-11-06
ER

PT J
AU Pillette, L
   Moreau, G
   Normand, JM
   Perrier, M
   Lécuyer, A
   Cogné, M
AF Pillette, Lea
   Moreau, Guillaume
   Normand, Jean-Marie
   Perrier, Manon
   Lecuyer, Anatole
   Cogne, Melanie
TI A Systematic Review of Navigation Assistance Systems for People With
   Dementia
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Navigation; Dementia; Data mining; Systematics; Timing; Statistics;
   Sociology; Information interfaces and representation (HCI); health care;
   navigation; dementia; Alzheimer; augmented reality
ID MODERATE ALZHEIMERS-DISEASE; MILD COGNITIVE IMPAIRMENT; AUGMENTED
   REALITY; VIRTUAL-REALITY; COLOR; PERFORMANCE; ABILITY; CUES;
   DISORIENTATION; ORIENTATION
AB Technological developments provide solutions to alleviate the tremendous impact on the health and autonomy due to the impact of dementia on navigation abilities. We systematically reviewed the literature on devices tested to provide assistance to people with dementia during indoor, outdoor and virtual navigation (PROSPERO ID number: 215585). Medline and Scopus databases were searched from inception. Our aim was to summarize the results from the literature to guide future developments. Twenty-three articles were included in our study. Three types of information were extracted from these studies. First, the types of navigation advice the devices provided were assessed through: (i) the sensorial modality of presentation, e.g., visual and tactile stimuli, (ii) the navigation content, e.g., landmarks, and (iii) the timing of presentation, e.g., systematically at intersections. Second, we analyzed the technology that the devices were based on, e.g., smartphone. Third, the experimental methodology used to assess the devices and the navigation outcome was evaluated. We report and discuss the results from the literature based on these three main characteristics. Finally, based on these considerations, recommendations are drawn, challenges are identified and potential solutions are suggested. Augmented reality-based devices, intelligent tutoring systems and social support should particularly further be explored.
C1 [Pillette, Lea; Normand, Jean-Marie] Ecole Cent Nantes, AAU, UMR CNRS 1563, F-44300 Nantes, France.
   [Moreau, Guillaume] IMT Atlantique, Lab STICC, UMR CNRS 6285, F-2923 Brest, France.
   [Moreau, Guillaume; Lecuyer, Anatole; Cogne, Melanie] Univ Rennes, Inria, CNRS, IRISA, Campus Beaulieu, F-35042 Rennes, France.
   [Perrier, Manon; Cogne, Melanie] Univ Hosp Rennes, Phys & Rehabil Med Unit, F-35033 Rennes, France.
C3 Nantes Universite; Ecole Centrale de Nantes; Universite de Bretagne
   Occidentale; IMT - Institut Mines-Telecom; IMT Atlantique; Universite de
   Rennes; Centre National de la Recherche Scientifique (CNRS); Inria; CHU
   Rennes; Universite de Rennes
RP Pillette, L (corresponding author), Ecole Cent Nantes, AAU, UMR CNRS 1563, F-44300 Nantes, France.
EM lea.pillette@ensc.fr; guillaume.moreau@imt-atlantique.fr;
   jean-marie.normand@ec-nantes.fr; manon.perrier@chu-rennes.fr;
   anatole.lecuyer@inria.fr; melanie.cogne@chu-rennes.fr
RI Cogne, Melanie/JVN-4300-2024; Pillette, Léa/ABH-7329-2020; Moreau,
   Guillaume/I-3153-2013
OI Normand, Jean-Marie/0000-0003-0557-4356; Moreau,
   Guillaume/0000-0003-2215-1865; Pillette, Lea/0000-0002-1197-6792
FU Institute of Clinical Neurosciences of Rennes (INCR) in 2019; University
   Hospital of Rennes (ARIADE project)
FX This work was supported in part by the Institute of Clinical
   Neurosciences of Rennes (INCR) in 2019 as well as the Corect from the
   University Hospital of Rennes (ARIADE project)
CR Allen G.L., 1999, Wayfinding Behavior: Cognitive Mapping and Other Spatial Processes
   Alsaqer M, 2015, PROCEDIA ENGINEER, V107, P337, DOI 10.1016/j.proeng.2015.06.090
   [Anonymous], 1990, P HUM FACT SOC ANN M
   [Anonymous], 2014, PROC INT C SPATIAL C
   Baca J, 2005, SPEECH COMMUN, V45, P187, DOI 10.1016/j.specom.2004.09.006
   Bark K, 2014, AUTOMOTIVEUI'14: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P3, DOI 10.1145/2667317.2667329
   Bjerva T, 2017, J NAVIGATION, V70, P263, DOI 10.1017/S0373463316000643
   Blackman T, 2007, AGEING SOC, V27, P811, DOI 10.1017/S0144686X07006253
   Bowden JL, 2013, AGE, V35, P1077, DOI 10.1007/s11357-012-9429-3
   Brawley E.C., 1997, Designing for Alzheimer's disease: Strategies for creating better care environments, V1
   Bright A. K., 2013, 6th international conference on pervasive technologies related to assistive environments, P1, DOI [10.1145/2504335.2504344, DOI 10.1145/2504335.2504344]
   Caduff D, 2008, COGN PROCESS, V9, P249, DOI 10.1007/s10339-007-0199-2
   Caffò AO, 2018, AGING MENT HEALTH, V22, P1372, DOI 10.1080/13607863.2017.1354973
   Cerman J, 2018, CURR ALZHEIMER RES, V15, P219, DOI 10.2174/1567205014666171120145349
   Chang Y.-J., 2008, P 10 INT ACM SIGACCE
   Chang YJ, 2010, PERS UBIQUIT COMPUT, V14, P737, DOI 10.1007/s00779-010-0285-9
   Chen K, 2014, ERGONOMICS, V57, P635, DOI 10.1080/00140139.2014.895855
   Cherrier MM, 2001, NEUROPSY NEUROPSY BE, V14, P159
   Chou CY, 2003, COMPUT EDUC, V40, P255, DOI 10.1016/S0360-1315(02)00130-6
   Cm R., 2020, MALAYSIAN J PUBLIC H, V20, P128
   Cogné M, 2018, NEUROPSYCHOLOGY, V32, P385, DOI 10.1037/neu0000435
   COOPER BA, 1985, AM J OCCUP THER, V39, P253, DOI 10.5014/ajot.39.4.253
   Cushman LA, 2008, NEUROLOGY, V71, P888, DOI 10.1212/01.wnl.0000326262.67613.fe
   D'Onofrio G, 2017, J ALZHEIMERS DIS, V57, P927, DOI 10.3233/JAD-161145
   Davis R, 2020, DEMENT GERIATR COGN, V49, P91, DOI 10.1159/000506859
   Davis R, 2017, ENVIRON BEHAV, V49, P1038, DOI 10.1177/0013916516677341
   Davis RL, 2012, RES GERONTOL NURS, V5, P138, DOI 10.3928/19404921-20111004-01
   Ebert S., 2015, PROC WORKSHOP POSTER, V1528, P1
   Evans Joanna, 2015, Human-Computer Interaction. Interaction Technologies. 17th International Conference, HCI International 2015. Proceedings: LNCS 9170, P406, DOI 10.1007/978-3-319-20916-6_38
   Fenech E.P., 2010, Human Factors and Ergonomics Society Annual Meeting Proceedings, V54, P1926, DOI [DOI 10.1177/154193121005402, DOI 10.1177/154193121005402305]
   Fernandes H, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON SOFTWARE DEVELOPMENT AND TECHNOLOGIES FOR ENHANCING ACCESSIBILITY AND FIGHTING INFO-EXCLUSION (DSAI 2018), P117, DOI 10.1145/3218585.3218601
   Firouzian A, 2017, L N INST COMP SCI SO, V181, P17, DOI 10.1007/978-3-319-49655-9_3
   Foster JK, 1999, NEUROPSYCHOLOGY, V13, P223, DOI 10.1037/0894-4105.13.2.223
   Fozard J. L, 2001, HDB PSYCHOL AGING
   Gardony AL, 2013, SPAT COGN COMPUT, V13, P319, DOI 10.1080/13875868.2013.792821
   Gibson Margaret C, 2004, Am J Alzheimers Dis Other Demen, V19, P45, DOI 10.1177/153331750401900110
   Goodman J, 2005, BEHAV INFORM TECHNOL, V24, P3, DOI 10.1080/01449290512331319021
   Grierson LEM, 2011, ASSIST TECHNOL, V23, P108, DOI 10.1080/10400435.2011.567375
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Haklay M, 2008, IEEE PERVAS COMPUT, V7, P12, DOI 10.1109/MPRV.2008.80
   Hayhurst J, 2018, PROGR IS, P295, DOI 10.1007/978-3-319-64027-3_20
   HENDERSON VW, 1989, ARCH NEUROL-CHICAGO, V46, P391, DOI 10.1001/archneur.1989.00520400045018
   Hettinga M, 2009, STUD HEALTH TECHNOL, V150, P428, DOI 10.3233/978-1-60750-044-5-428
   Huang HK, 2018, IEEE T VIS COMPUT GR, V24, P2516, DOI 10.1109/TVCG.2017.2761820
   Iftikhar H, 2021, ARCHIT SCI REV, V64, P452, DOI 10.1080/00038628.2020.1777386
   Izuma K, 2008, NEURON, V58, P284, DOI 10.1016/j.neuron.2008.03.020
   Joddrell Phil, 2016, JMIR Rehabil Assist Technol, V3, pe10, DOI 10.2196/rehab.5788
   Kavcic V, 2006, BRAIN, V129, P736, DOI 10.1093/brain/awh727
   Kessels RPC, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0018611
   Kim S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P133
   Konishi K, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00001
   Kulyukin V, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON RFID, P303, DOI 10.1109/RFID.2008.4519363
   Kwan RYC, 2020, DEMENTIA-LONDON, V19, P721, DOI 10.1177/1471301218785461
   Lancioni GE, 2013, RES DEV DISABIL, V34, P286, DOI 10.1016/j.ridd.2012.08.016
   Lanza C, 2014, J ALZHEIMERS DIS, V42, P879, DOI 10.3233/JAD-140063
   Lin FR, 2013, JAMA INTERN MED, V173, P293, DOI 10.1001/jamainternmed.2013.1868
   Liu A.L., 2009, Cognition, V9, P1
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   Me RC, 2017, Technol. Disabil, V29, P35
   Mega MS, 1996, NEUROLOGY, V46, P130, DOI 10.1212/WNL.46.1.130
   Merenda C, 2018, IEEE T VIS COMPUT GR, V24, P2875, DOI 10.1109/TVCG.2018.2868531
   Morganti F, 2013, COGN NEUROSCI-UK, V4, P171, DOI 10.1080/17588928.2013.854762
   Nkambou R, 2010, STUD COMPUT INTELL, V308, P1, DOI 10.1007/978-3-642-14363-2
   Nolan B A, 2001, Am J Alzheimers Dis Other Demen, V16, P251, DOI 10.1177/153331750101600413
   Oderud T, 2015, STUD HEALTH TECHNOL, V217, P212, DOI 10.3233/978-1-61499-566-1-212
   Ou YK, 2013, J IND PROD ENG, V30, P397, DOI 10.1080/21681015.2013.846944
   Pai MC, 2012, AM J ALZHEIMERS DIS, V27, P65, DOI 10.1177/1533317512436805
   Parizkova M, 2018, NEUROBIOL AGING, V64, P107, DOI 10.1016/j.neurobiolaging.2017.12.019
   Passini R, 2000, ENVIRON BEHAV, V32, P684, DOI 10.1177/00139160021972748
   PATE DS, 1994, COGN NEUROPSYCHOL, V11, P321, DOI 10.1080/02643299408251978
   PAUZIE A, 1989, IEEE CONF R, P61, DOI 10.1109/VNIS.1989.98741
   Pazzaglia F, 2013, COGN PROCESS, V14, P391, DOI 10.1007/s10339-013-0572-2
   Perneczky R, 2006, AM J GERIAT PSYCHIAT, V14, P139, DOI 10.1097/01.JGP.0000192478.82189.a8
   Pillette L., 2019, Redefining and Adapting Feedback for Mental-Imagery based Brain-Computer Interface User Training to the Learners' Traits and States [master's thesis]
   Pillette L, 2020, INT J HUM-COMPUT ST, V136, DOI 10.1016/j.ijhcs.2019.102380
   Preiser Wolfgang F. E., 2001, UNIVERSAL DESIGN HDB
   Provencher V, 2008, AM J ALZHEIMERS DIS, V23, P47, DOI 10.1177/1533317507307228
   Randhavane T, 2019, IEEE T VIS COMPUT GR, V25, P3135, DOI 10.1109/TVCG.2019.2932235
   Rassmus-Gröhn K, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P247, DOI 10.1145/2639189.2639233
   Reiner AJ, 2020, ERGONOMICS, V63, P548, DOI 10.1080/00140139.2020.1737738
   Risacher SL, 2013, NEUROBIOL AGING, V34, P1133, DOI 10.1016/j.neurobiolaging.2012.08.007
   Rizzo M, 2000, NEUROLOGY, V54, P1954, DOI 10.1212/WNL.54.10.1954
   Schaat S, 2020, GERONTOLOGY, V66, P85, DOI 10.1159/000500971
   Sejunaite K, 2017, J FRALITY AGING, V6, P206, DOI 10.14283/jfa.2017.25
   Shoulson A, 2014, IEEE T VIS COMPUT GR, V20, P1035, DOI 10.1109/TVCG.2013.251
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Sohlberg MM, 2007, BRAIN INJURY, V21, P531, DOI 10.1080/02699050701311000
   Sorri L., 2011, PROC 19 EUR C INF SY
   Stein B E, 1989, J Cogn Neurosci, V1, P12, DOI 10.1162/jocn.1989.1.1.12
   Teipel S, 2016, ALZHEIMERS DEMENT, V12, P695, DOI 10.1016/j.jalz.2015.11.003
   Tervonen J, 2014, INT ICE CONF ENG
   Vaez S., 2016, PROC AUSTRALAS TRANS, P1
   Vlcek K, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00089
   Wijk H, 2002, SCAND J CARING SCI, V16, P91, DOI 10.1046/j.1471-6712.2002.00063.x
   Willemsen P, 2006, IEEE T VIS COMPUT GR, V12, P331, DOI 10.1109/TVCG.2006.53
   Wood S, 1997, ARCH CLIN NEUROPSYCH, V12, P483
   World Health Organization and others, 2017, GLOB ACT PLAN PUBL H
   Yassin A, 2017, IEEE COMMUN SURV TUT, V19, P1327, DOI 10.1109/COMST.2016.2632427
   Yazidi A, 2020, COGN NEURODYNAMICS, V14, P675, DOI 10.1007/s11571-020-09624-3
   Yi J, 2015, GERONTOLOGY, V61, P79, DOI 10.1159/000365922
NR 100
TC 5
Z9 5
U1 2
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2146
EP 2165
DI 10.1109/TVCG.2022.3141383
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900018
PM 35007194
OA Green Published
DA 2024-11-06
ER

PT J
AU Woodward, J
   Ruiz, J
AF Woodward, Julia
   Ruiz, Jaime
TI Analytic Review of Using Augmented Reality for Situational Awareness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Headphones; Augmented reality; Bibliographies; Visualization;
   Systematics; Surgery; Planning; human computer interaction; situational
   awareness; systematic literature review
ID HEAD-MOUNTED DISPLAYS; VIRTUAL-REALITY; BUILDING INFORMATION; WORN
   DISPLAYS; MIXED REALITY; SYSTEM; SAFETY; TEXT; COLLABORATION;
   MAINTENANCE
AB Situational awareness is the perception and understanding of the surrounding environment. Maintaining situational awareness is vital for performance and error prevention in safety critical domains. Prior work has examined applying augmented reality (AR) to the context of improving situational awareness, but has mainly focused on the applicability of using AR rather than on information design. Hence, there is a need to investigate how to design the presentation of information, especially in AR headsets, to increase users' situational awareness. We conducted a Systematic Literature Review to research how information is currently presented in AR, especially in systems that are being utilized for situational awareness. Comparing current presentations of information to existing design recommendations aided in identifying future areas of design. In addition, this survey further discusses opportunities and challenges in applying AR to increasing users' situational awareness.
C1 [Woodward, Julia; Ruiz, Jaime] Univ Florida, Dept Comp & Informat Sci & Engn CISE, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Woodward, J (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn CISE, Gainesville, FL 32611 USA.
EM julia.woodward@ufl.edu; jaime.ruiz@ufl.edu
RI Woodward, Julia/KYP-3436-2024
OI Ruiz, Jaime/0000-0002-9139-6172; Woodward, Julia/0000-0002-8753-2792
CR Al-Issa H, 2012, PHYS THER REV, V17, P16, DOI 10.1179/1743288X11Y.0000000051
   Alam MF, 2017, J NETW COMPUT APPL, V89, P109, DOI 10.1016/j.jnca.2017.03.022
   Albarelli A., 2015, P BIANN C IT SIGCHI, P58, DOI [10.1145/2808435.2808455, DOI 10.1145/2808435.2808455]
   Alnabhan A, 2014, P 6 ACM SIGSPATIAL I, P36
   [Anonymous], 2018, How augmented reality is changing the way we shop
   Arce Terek, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2115, DOI 10.1177/1541931213602010
   Aschenbrenner D, 2016, IFAC PAPERSONLINE, V49, P204, DOI 10.1016/j.ifacol.2016.11.168
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bai Z, 2012, INTERACT COMPUT, V24, P450, DOI 10.1016/j.intcom.2012.07.004
   Barsom EZ, 2016, SURG ENDOSC, V30, P4174, DOI 10.1007/s00464-016-4800-6
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Blanco-Novoa O, 2018, IEEE ACCESS, V6, P8201, DOI 10.1109/ACCESS.2018.2802699
   Blankemeyer S, 2018, PROC CIRP, V76, P155, DOI 10.1016/j.procir.2018.02.028
   Blattgerste J, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P75, DOI 10.1145/3056540.3056547
   Brandao WL, 2017, P IEEE VIRT REAL ANN, P297, DOI 10.1109/VR.2017.7892294
   Khuong BM, 2014, 2014 IEEE VIRTUAL REALITY (VR), P57, DOI 10.1109/VR.2014.6802051
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Carretta TR, 1996, INT J AVIAT PSYCHOL, V6, P21, DOI 10.1207/s15327108ijap0601_2
   Chen CJ, 2015, INT J ADV MANUF TECH, V76, P753, DOI 10.1007/s00170-014-6321-6
   Chua Soon Hau., 2016, INT S CHINESE CHI CH, P1, DOI DOI 10.1145/2948708.2948713
   Cidota M., 2016, Augmented Human Research, P1, DOI DOI 10.1007/S41133-016-0003-X
   Condino S, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5435097
   Datcu D., 2013, P IEEE ISMAR WORKSHO, P6
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Dunston PS, 2011, J INF TECHNOL CONSTR, V16, P433
   ElSayed NAM, 2016, J VISUAL LANG COMPUT, V36, P13, DOI 10.1016/j.jvlc.2016.07.006
   Endsley M.R., 2001, P 2 INT WORKSHOP SYM, P14
   Endsley Mica, 1988, P HUM FACT SOC ANN M, V32, P97, DOI 10.1177/154193128803200221
   Endsley MR, 2021, HUM FACTORS, V63, P124, DOI 10.1177/0018720819875376
   Endsley MR, 2015, J COGN ENG DECIS MAK, V9, P4, DOI 10.1177/1555343415572631
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Endsley MR, 2000, SITUATION AWARENESS ANALYSIS AND MEASUREMENT, P147
   Endsley MR, 2000, INT J IND ERGONOM, V26, P301, DOI 10.1016/S0169-8141(99)00073-6
   ENDSLEY MR, 1995, HUMAN FACTORS IN AVIATION OPERATIONS - PROCEEDINGS OF THE 21ST CONFERENCE OF THE EUROPEAN ASSOCIATION FOR AVIATION PSYCHOLOGY (EAAP), VOL 3, P287
   Endsley MR, 1999, HUM FAC TRANSP, P257
   Fiorentino M, 2013, PRESENCE-TELEOP VIRT, V22, P171, DOI 10.1162/PRES_a_00146
   Fore AM, 2013, J ADV NURS, V69, P2613, DOI 10.1111/jan.12130
   Gabbard JL, 2014, P IEEE, V102, P124, DOI 10.1109/JPROC.2013.2294642
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Ganapathy S., 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P75, DOI 10.1109/ISVRI.2011.5759606
   Ganapathy S., 2013, Human factors in augmented reality environments, P165, DOI DOI 10.1007/978-1-4614-4205-9_7
   Gans E, 2015, PROC SPIE, V9470, DOI 10.1117/12.2177086
   Gavish N, 2015, INTERACT LEARN ENVIR, V23, P778, DOI 10.1080/10494820.2013.815221
   Google, GLASS DISC GLASS ENT
   Graafland M, 2015, BRIT J SURG, V102, P16, DOI 10.1002/bjs.9643
   Grabowski M, 2015, J NAVIGATION, V68, P453, DOI 10.1017/S0373463314000873
   Green SA, 2008, INT J ADV ROBOT SYST, V5, P1, DOI 10.5772/5664
   Gruenefeld U, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P109, DOI 10.1145/3131277.3132175
   Guhl J, 2017, IEEE INT C EMERG
   Hanna MG, 2018, ARCH PATHOL LAB MED, V142, P638, DOI 10.5858/arpa.2017-0189-OA
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Herron Jennifer, 2016, Journal of Electronic Resources in Medical Libraries, V13, P51, DOI 10.1080/15424065.2016.1175987
   Hervás R, 2014, IEEE J BIOMED HEALTH, V18, P368, DOI 10.1109/JBHI.2013.2266480
   Hong T. C., 2015, P HUMAN FACTORS ERGO, V59, P1722
   Horejsí P, 2015, PROCEDIA ENGINEER, V100, P699, DOI 10.1016/j.proeng.2015.01.422
   Hou L, 2013, AUTOMAT CONSTR, V32, P38, DOI 10.1016/j.autcon.2012.12.007
   Incekara F, 2018, WORLD NEUROSURG, V118, pE422, DOI 10.1016/j.wneu.2018.06.208
   Irizarry J, 2013, AUTOMAT CONSTR, V33, P11, DOI 10.1016/j.autcon.2012.09.002
   Ishiguro Yoshio., 2011, P 2 AUGMENTED HUMAN, P8, DOI DOI 10.1145/1959826.1959834
   Ivaschenko Anton, 2018, P IEEE IND CYB PHY S, P519, DOI [10.1109/ICPHYS.2018.8390759, DOI 10.1109/ICPHYS.2018.8390759]
   Jones DG, 1996, AVIAT SPACE ENVIR MD, V67, P507
   Jozef NM, 2014, APPL MECH MATER, V616, P19, DOI 10.4028/www.scientific.net/AMM.616.19
   Jyh-Horng Lin, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P316, DOI 10.1109/IBICA.2011.84
   Kalkofen D, 2011, HANDBOOK OF AUGMENTED REALITY, P65, DOI 10.1007/978-1-4614-0064-6_3
   Katic D, 2015, INT J COMPUT ASS RAD, V10, P101, DOI 10.1007/s11548-014-1005-0
   Kim H, 2022, HUM FACTORS, V64, P852, DOI 10.1177/0018720819844845
   Kim H, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P294, DOI 10.1145/2856767.2856815
   Kim Hyungil, 2013, P 5 INT C AUT US INT, P224, DOI DOI 10.1145/2516540.2516566
   Kim KH, 2011, IEICE T INF SYST, VE94D, P1051, DOI 10.1587/transinf.E94.D.1051
   Kim S, 2018, KSII T INTERNET INF, V12, P6034
   Kitchenham B., 2007, Technical Report EBSE-2007-01, DOI DOI 10.1145/1134285.1134500
   Kitchenham B, 2013, INFORM SOFTWARE TECH, V55, P2049, DOI 10.1016/j.infsof.2013.07.010
   Koritsas E., 1991, P HUM FACT SOC 35, P62
   Kourouthanassis PE, 2015, MULTIMED TOOLS APPL, V74, P1045, DOI 10.1007/s11042-013-1710-7
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kruijff E, 2019, IEEE T VIS COMPUT GR, V25, P2821, DOI 10.1109/TVCG.2018.2854737
   Kuzhagaliyev T, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293671
   Langlois S, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1571, DOI 10.1109/ITSC.2016.7795767
   Le Roux W., 2011, Scientia Militaria - South African Journal of Military Studies, V38, DOI DOI 10.5787/38-1-82
   Lebeck K, 2016, HOTMOBILE'16: PROCEEDINGS OF THE 17TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P45, DOI 10.1145/2873587.2873595
   Lee JW, 2015, INT CONF ADV COMMUN, P263, DOI 10.1109/ICACT.2015.7224799
   Liang S, 2015, PROCEDIA MANUF, V3, P219, DOI 10.1016/j.promfg.2015.07.132
   Liu D, 2010, ANESTH ANALG, V110, P1032, DOI 10.1213/ANE.0b013e3181d3e647
   Livingston MA, 2011, VIRTUAL REAL-LONDON, V15, P175, DOI 10.1007/s10055-010-0179-1
   Livingston MarkA., 2013, Human Factors in Augmented Reality Environments, P35, DOI [10.1007/978-1-4614-4205-93, DOI 10.1007/978-1-4614-4205-93]
   Lorenz L., 2014, P HUMAN FACTORS ERGO, V58, P1681, DOI https://doi.org/10.1177/1541931214581351
   Lucero Andres, 2014, P 11 C ADV COMP ENT, P1, DOI DOI 10.1145/2663806.2663824
   Lukosch S, 2015, COMPUT SUPP COOP W J, V24, P613, DOI 10.1007/s10606-015-9235-4
   Mariette Nicholas, 2013, Human Factors Research in Audio Augmented Reality, P11, DOI [10.1007/978-1-4614-4205-92, DOI 10.1007/978-1-4614-4205-92]
   McKendrick R, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00216
   Merenda C, 2018, IEEE T VIS COMPUT GR, V24, P2875, DOI 10.1109/TVCG.2018.2868531
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Phan MT, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1298, DOI 10.1109/ITSC.2016.7795724
   Mitaritonna A., 2015, PROC INT C CENTRAL E, P53
   Muller T., 2019, AIMS Electron. Elect. Eng., V3, P71, DOI 10.3934/ElectrEng.2019.1.71
   Mulloni Alessandro, 2010, P 12 INT C HUM COMP, P161, DOI [10.1145/1851600.1851629, DOI 10.1145/1851600.1851629]
   Neuhöfer JA, 2012, WORK, V41, P2187, DOI 10.3233/WOR-2012-0441-2187
   Ng-Thow-Hing V, 2013, INT SYM MIX AUGMENT, P13, DOI 10.1109/ISMAR-AMH.2013.6671262
   Onal E., 2013, PROC INT S AUTOMAT R, P1517, DOI [10.22260/ISARC2013/0171, DOI 10.22260/ISARC2013/0171]
   Orlosky J, 2014, MOB COMPUT COMMUN RE, V18, P20, DOI 10.1145/2636242.2636246
   Orlosky Jason, 2015, P 20 INT C INT US IN, P369, DOI DOI 10.1145/2678025.2701375
   Park BJ, 2015, INT CONF ADV COMMUN, P593, DOI 10.1109/ICACT.2015.7224865
   Pascale MT, 2019, HUM FACTORS, V61, P537, DOI 10.1177/0018720818814969
   Pascale MT, 2018, APPL ERGON, V73, P167, DOI 10.1016/j.apergo.2018.06.002
   Pratt P, 2018, EUR RADIOL EXP, V2, DOI 10.1186/s41747-017-0033-2
   Rabbi I., 2013, ACTA GRAPH, V24, P29, DOI DOI 10.9790/0661-0222329
   Rane P., 2016, Proceedings of the Human Factors and Ergonomics Society, V60, P1748, DOI [DOI 10.1177/1541931213601401, 10.1177/1541931213601401]
   Reader TW, 2014, J RISK RES, V17, P405, DOI 10.1080/13669877.2013.815652
   Rodrigues DaniloGasques., 2017, P 2017 CHI C HUM FAC, P2591, DOI DOI 10.1145/3027063.3053273
   Ruano S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17020297
   Rzayev R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173619
   Salmon PM, 2009, INT J IND ERGONOM, V39, P490, DOI 10.1016/j.ergon.2008.10.010
   Sand Oliver, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P643, DOI 10.1007/978-3-319-39907-2_61
   Sauer M., 2010, 2 IFAC S TEL APPL RO, P83
   Scholtz J., 2004, Proceedings of the 37th Annual Hawaii International Conference on System Sciences
   Schulz CM, 2016, BMC ANESTHESIOL, V16, DOI 10.1186/s12871-016-0172-7
   Schwarz F, 2017, ACCIDENT ANAL PREV, V101, P55, DOI 10.1016/j.aap.2017.01.019
   Sebillo M, 2016, MULTIMED TOOLS APPL, V75, P9609, DOI 10.1007/s11042-015-2955-0
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Simons DJ, 1997, TRENDS COGN SCI, V1, P261, DOI 10.1016/S1364-6613(97)01080-2
   Singh G, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P165, DOI 10.1109/VR.2012.6180933
   Sonnenwald DH, 2000, INFORM PROCESS MANAG, V36, P461, DOI 10.1016/S0306-4573(99)00039-4
   Stanton NA, 2001, SAFETY SCI, V39, P189, DOI 10.1016/S0925-7535(01)00010-8
   Strzys MP, 2018, EUR J PHYS, V39, DOI 10.1088/1361-6404/aaa8fb
   Swan J. E., 2005, PROC INT C VIRTUAL R
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tepper OM, 2017, PLAST RECONSTR SURG, V140, P1066, DOI 10.1097/PRS.0000000000003802
   Tönnis M, 2013, COMPUT GRAPH-UK, V37, P997, DOI 10.1016/j.cag.2013.09.002
   Toyama T., 2015, P 20 INT C INT US IN, P322, DOI DOI 10.1145/2678025.2701384
   Tran C, 2013, P 5 INT C AUTOMOTIVE, P300
   Van Krevelen D., 2010, INT J VIRTUAL REALIT, V9, P1, DOI 10.20870/ijvr.2010.9.2.2767
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Velamkayala Eswara Rao, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P2110, DOI 10.1177/1541931213602009
   VIDULICH MA, 1994, AVIAT SPACE ENVIR MD, V65, pA7
   Wallmyr M, 2019, LECT NOTES COMPUT SC, V11746, P743, DOI 10.1007/978-3-030-29381-9_44
   Wang S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102294
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Yeh KC, 2012, J COMPUT CIVIL ENG, V26, P342, DOI 10.1061/(ASCE)CP.1943-5487.0000156
   You X, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7020046
   Zarraonandia T, 2014, INT J HUM-COMPUT INT, V30, P829, DOI 10.1080/10447318.2014.927283
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhou J., 2012, The International Journal of Virtual Reality, V11, P33, DOI [10.20870/IJVR.2012.11.1.2835, DOI 10.20870/IJVR.2012.11.1.2835]
   Zhu EG, 2014, PEERJ, V2, DOI 10.7717/peerj.469
   Zhu ZW, 2014, INT SYM MIX AUGMENT, P17, DOI 10.1109/ISMAR.2014.6948404
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
   Zollmann S, 2014, P IEEE, V102, P137, DOI 10.1109/JPROC.2013.2294314
   Zollmann Stefanie, 2014, P 26 AUSTR COMP HUM, P194, DOI DOI 10.1145/2686612.2686642
NR 153
TC 17
Z9 17
U1 18
U2 62
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2166
EP 2183
DI 10.1109/TVCG.2022.3141585
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900019
PM 35007195
DA 2024-11-06
ER

PT J
AU Ye, ZP
   Xia, MF
   Sun, YA
   Yi, R
   Yu, MJ
   Zhang, JY
   Lai, YK
   Liu, YJ
AF Ye, Zipeng
   Xia, Mengfei
   Sun, Yanan
   Yi, Ran
   Yu, Minjing
   Zhang, Juyong
   Lai, Yu-Kun
   Liu, Yong-Jin
TI 3D-CariGAN: An End-to-End Solution to 3D Caricature Generation From
   Normal Face Photos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Faces; Solid modeling; Shape; Principal
   component analysis; Image reconstruction; Parametric statistics; Face
   reconstruction; 3D caricature; PCA representation; caricature shape
   space
ID RECONSTRUCTION
AB Caricature is a type of artistic style of human faces that attracts considerable attention in the entertainment industry. So far a few 3D caricature generation methods exist and all of them require some caricature information (e.g., a caricature sketch or 2D caricature) as input. This kind of input, however, is difficult to provide by non-professional users. In this paper, we propose an end-to-end deep neural network model that generates high-quality 3D caricatures directly from a normal 2D face photo. The most challenging issue for our system is that the source domain of face photos (characterized by normal 2D faces) is significantly different from the target domain of 3D caricatures (characterized by 3D exaggerated face shapes and textures). To address this challenge, we: (1) build a large dataset of 5,343 3D caricature meshes and use it to establish a PCA model in the 3D caricature shape space; (2) reconstruct a normal full 3D head from the input face photo and use its PCA representation in the 3D caricature shape space to establish correspondences between the input photo and 3D caricature shape; and (3) propose a novel character loss and a novel caricature loss based on previous psychological studies on caricatures. Experiments including a novel two-level user study show that our system can generate high-quality 3D caricatures directly from normal face photos.
C1 [Ye, Zipeng; Xia, Mengfei; Sun, Yanan; Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, Key Lab Pervas Comp, BNRist, Beijing 100084, Peoples R China.
   [Yi, Ran] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Yu, Minjing] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
   [Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Anhui, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
C3 Tsinghua University; Shanghai Jiao Tong University; Tianjin University;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Cardiff University
RP Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Key Lab Pervas Comp, BNRist, Beijing 100084, Peoples R China.; Yi, R (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.; Yu, MJ (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300072, Peoples R China.
EM yezp17@mails.tsinghua.edu.cn; xmf20@mails.tsinghua.edu.cn;
   sunyn20@mails.tsinghua.edu.cn; ranyi@sjtu.edu.cn; minjingyu@tju.edu.cn;
   juyong@ustc.edu.cn; laiy4@cardiff.ac.uk; liuyongjin@tsinghua.edu.cn
RI SUN, YANAN/L-8071-2019; Lai, Yu-Kun/D-2343-2010; Yi, Ran/AAU-6636-2021
OI Yi, Ran/0000-0003-1858-3358; Ye, Zipeng/0000-0002-4322-7550; Lai,
   Yukun/0000-0002-2094-5680
FU Natural Science Foundation of China [61725204, 62002258]
FX This work was supported by the Natural Science Foundation of China under
   Grants 61725204 and 62002258.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   BENSON P J, 1991, European Journal of Cognitive Psychology, V3, P105, DOI 10.1080/09541449108406222
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Brennan SE, 2007, LEONARDO, V40, P392, DOI 10.1162/leon.2007.40.4.392
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen Y, 2017, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2017.504
   Clarke L, 2011, IEEE T VIS COMPUT GR, V17, P808, DOI 10.1109/TVCG.2010.76
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Dai H, 2017, IEEE I CONF COMP VIS, P3104, DOI 10.1109/ICCV.2017.335
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Han XG, 2020, IEEE T VIS COMPUT GR, V26, P2349, DOI 10.1109/TVCG.2018.2886007
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hill MQ, 2019, NAT MACH INTELL, V1, P522, DOI 10.1038/s42256-019-0111-7
   Huo J., 2018, PROC BRIT MACHINE VI, P1
   Huo J, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P340, DOI 10.1145/3126686.3126736
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Kaidi Cao, 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3272127.3275046
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lee CH, 2020, Arxiv, DOI arXiv:1907.11922
   Li WB, 2018, Arxiv, DOI arXiv:1811.00445
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Ploumpis S, 2019, PROC CVPR IEEE, P10926, DOI 10.1109/CVPR.2019.01119
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Rhodes G, 1997, PERCEPTION, V26, P207, DOI 10.1068/p260207
   Romdhani S., 2007, PROC IEEE C COMPUT V, P1
   Sadimon SB, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P383, DOI 10.1109/CW.2010.33
   Sela M, 2015, COMPUT VIS IMAGE UND, V141, P1, DOI 10.1016/j.cviu.2015.05.013
   Shi YC, 2019, PROC CVPR IEEE, P10754, DOI 10.1109/CVPR.2019.01102
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wu QY, 2018, PROC CVPR IEEE, P7336, DOI 10.1109/CVPR.2018.00766
   Ye ZP, 2020, COMPUT AIDED DESIGN, V126, DOI 10.1016/j.cad.2020.102851
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 38
TC 6
Z9 6
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR 1
PY 2023
VL 29
IS 4
BP 2203
EP 2210
DI 10.1109/TVCG.2021.3126659
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D9DT5
UT WOS:000971666900021
PM 34752397
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Son, H
   Wang, H
   Singhal, Y
   Kim, JR
AF Son, Hyungki
   Wang, Haokun
   Singhal, Yatharth
   Kim, Jin Ryong
TI Upper Body Thermal Referral and Tactile Masking for Localized Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Thermal referral; thermal vest; tactile masking; localized feedback;
   haptic vest
ID HEAT-PAIN; COLD PAIN; TEMPERATURE; VIBROTACTILE; SENSATIONS; SUMMATION;
   LASER; WARM; HAND; COOL
AB This paper investigates the effects of thermal referral and tactile masking illusions to achieve localized thermal feedback on the upper body. Two experiments are conducted. The first experiment uses a 2D array of sixteen vibrotactile actuators (4 x 4) with four thermal actuators to explore the thermal distribution on the user's back. A combination of thermal and tactile sensations is delivered to establish the distributions of thermal referral illusions with different numbers of vibrotactile cues. The result confirms that localized thermal feedback can be achieved through cross-modal thermo-tactile interaction on the user's back of the body. The second experiment is conducted to validate our approach by comparing it with thermal-only conditions with an equal and higher number of thermal actuators in VR. The results show that our thermal referral with a tactile masking approach with a lesser number of thermal actuators achieves higher response time and better location accuracy than thermal-only conditions. Our findings can contribute to thermal-based wearable design to achieve greater user performance and experiences.
C1 [Son, Hyungki] ETRI, Daejeon, South Korea.
   [Wang, Haokun; Singhal, Yatharth; Kim, Jin Ryong] Univ Texas Dallas, Dallas, TX USA.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   University of Texas System; University of Texas Dallas
RP Son, H (corresponding author), ETRI, Daejeon, South Korea.
EM hagonhk@etri.re.kr; Haokun.Wang@utdallas.edu;
   Yatharth.Singhal@utdallas.edu; Jin.Kim@utdallas.edu
OI Kim, Jin Ryong/0000-0002-5182-6617; Singhal,
   Yatharth/0000-0002-4939-9601; Wang, Haokun/0000-0001-9764-0896
FU UT Dallas Startup Grant [40037051]; Institute of Information &
   communications Technology Planning &Evaluation (IITP) grant - Korea
   government (MSIP) [2019-0-01347]
FX We thank Ayush Bhardwaj for his help in making a video. This work was
   supported by the UT Dallas Startup Grant (No. 40037051) and the
   Institute of Information & communications Technology Planning
   &Evaluation (IITP) grant funded by the Korea government (MSIP)
   (2019-0-01347, Development of Realistic Fire Training Content Technology
   to Help Simulate Fire Sites and Improve Command Capabilities).
CR Arai K., 2017, HCI INT 2017, P281
   Averbeck B, 2013, EUR J PAIN, V17, P724, DOI 10.1002/j.1532-2149.2012.00239.x
   Cai SY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P248, DOI [10.1109/VR46266.2020.00-60, 10.1109/VR46266.2020.1580801081068]
   CAIN WS, 1973, AM J PSYCHOL, V86, P169, DOI 10.2307/1421858
   Cataldo A, 2016, SCI REP-UK, V6, DOI 10.1038/srep35286
   DARIANSMITH I, 1977, J INVEST DERMATOL, V69, P146, DOI 10.1111/1523-1747.ep12497936
   Delazio A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173894
   DYCK PJ, 1993, NEUROLOGY, V43, P1500, DOI 10.1212/WNL.43.8.1500
   El Ali A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376682
   Gescheider G. A., 2010, INFORM PROCESSING CH, V2
   Gescheider GA, 2002, SOMATOSENS MOT RES, V19, P114, DOI 10.1080/08990220220131505
   GESCHEIDER GA, 1983, J ACOUST SOC AM, V74, P474, DOI 10.1121/1.389813
   GESCHEIDER GA, 1982, J ACOUST SOC AM, V72, P1421, DOI 10.1121/1.388449
   GREEN BG, 1978, SENS PROCESS, V2, P220
   GREEN BG, 1977, PERCEPT PSYCHOPHYS, V22, P331, DOI 10.3758/BF03199698
   Guenther S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376195
   HAMER RD, 1983, J ACOUST SOC AM, V73, P1293, DOI 10.1121/1.389278
   Han T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P913, DOI 10.1145/3242587.3242667
   Hayward V, 2018, SPRINGER SER TOUCH, P29, DOI 10.1007/978-3-319-58316-7_3
   Ho HN, 2011, J NEUROSCI, V31, P208, DOI 10.1523/JNEUROSCI.2640-10.2011
   Hulsmann F, 2014, LAVAL VIRTUAL VRIC 1, DOI [10.1145/2617841.2620712, DOI 10.1145/2617841.2620712]
   Israr A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2019
   Ivanov KP, 1999, J THERM BIOL, V24, P415, DOI 10.1016/S0306-4565(99)00060-1
   Iwai D, 2019, IEEE T VIS COMPUT GR, V25, P1707, DOI 10.1109/TVCG.2018.2820121
   Jin Ryong Kim, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P247, DOI 10.1007/978-3-642-31401-8_23
   Jones LA, 2008, IEEE T HAPTICS, V1, P53, DOI 10.1109/ToH.2008.2
   Liu Y., 2021, P 2021 CHI C HUMAN F, DOI [10.1145/3411764.34457771,2,8, DOI 10.1145/3411764.34457771,2,8]
   Mackevicius EL, 2012, J NEUROSCI, V32, P15309, DOI 10.1523/JNEUROSCI.2161-12.2012
   McKemy DD, 2013, ACS CHEM NEUROSCI, V4, P238, DOI 10.1021/cn300193h
   MEYER RA, 1976, IEEE T BIO-MED ENG, V23, P54, DOI 10.1109/TBME.1976.324616
   Morin C, 1998, PAIN, V74, P67, DOI 10.1016/S0304-3959(97)00152-8
   Park J, 2022, LECT NOTES COMPUT SC, V13235, P75, DOI 10.1007/978-3-031-06249-0_9
   Peiris RL, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5452, DOI 10.1145/3025453.3025824
   Plaghki L, 2003, NEUROPHYSIOL CLIN, V33, P269, DOI 10.1016/j.neucli.2003.10.003
   Ranasinghe N, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186513
   Saal HP, 2017, P NATL ACAD SCI USA, V114, pE5693, DOI 10.1073/pnas.1704856114
   Singhal A, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P90, DOI 10.1109/WHC.2017.7989882
   Singhal Y., 2021, P 27 ACM S VIRTUAL R, DOI [10.1145/3489849.34898892, DOI 10.1145/3489849.34898892]
   Singhal Y., 2021, P 27 ACM S VIRTUAL R, DOI [10.1145/3489849.34898891, DOI 10.1145/3489849.34898891]
   STEVENS JC, 1982, PERCEPT PSYCHOPHYS, V31, P577, DOI 10.3758/BF03204192
   STEVENS JC, 1989, SOMATOSENS MOT RES, V6, P275, DOI 10.3109/08990228909144677
   Tan CL, 2018, NEURON, V98, P31, DOI 10.1016/j.neuron.2018.02.022
   Tan HZ, 2003, J ACOUST SOC AM, V114, P3295, DOI 10.1121/1.1623788
   TAUS RH, 1975, PERCEPT PSYCHOPHYS, V17, P194, DOI 10.3758/BF03203885
   Vardar Y, 2018, IEEE T HAPTICS, V11, P623, DOI 10.1109/TOH.2018.2855124
   Vellei M, 2021, BUILD ENVIRON, V205, DOI 10.1016/j.buildenv.2021.108269
   Waldman S., 2009, Pain Review, P190, DOI [10.1016/B978-1-4160-5893-9.00109-X, DOI 10.1016/B978-1-4160-5893-9.00109-X]
   Watanabe R, 2014, IEEE HAPTICS SYM, P299, DOI 10.1109/HAPTICS.2014.6775471
   Xiao R, 2021, ANNU REV PHYSIOL, V83, P205, DOI 10.1146/annurev-physiol-031220-095215
   Yang GH, 2009, ATTEN PERCEPT PSYCHO, V71, P156, DOI 10.3758/APP.71.1.156
   Zhu KN, 2019, INT J HUM-COMPUT ST, V130, P234, DOI 10.1016/j.ijhcs.2019.07.003
NR 51
TC 6
Z9 7
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2211
EP 2219
DI 10.1109/TVCG.2023.3247068
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1YW5
UT WOS:000966756000001
PM 37027721
DA 2024-11-06
ER

PT J
AU Eisentrager, K
   Haubner, J
   Brade, J
   Einhauser, W
   Bendixen, A
   Winkler, S
   Klimant, P
   Jahn, G
AF Eisentrager, Karl
   Haubner, Judith
   Brade, Jennifer
   Einhauser, Wolfgang
   Bendixen, Alexandra
   Winkler, Sven
   Klimant, Philipp
   Jahn, Georg
TI Evaluating the Effects of Virtual Reality Environment Learning on
   Subsequent Robot Teleoperation in an Unfamiliar Building
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Navigation; Buildings; Task analysis; Robots; Avatars; Floors; Virtual
   environments; Human computer interaction (HCI); human-centered
   computing; virtual reality; human factors; teleoperation; robot
ID ROUTE; PERSPECTIVE; DEPENDENCE
AB Using a map in an unfamiliar environment requires identifying correspondences between elements of the map's allocentric representation and elements in egocentric views. Aligning the map with the environment can be challenging. Virtual reality (VR) allows learning about unfamiliar environments in a sequence of egocentric views that correspond closely to the perspectives and views that are experienced in the actual environment. We compared three methods to prepare for localization and navigation tasks performed by teleoperating a robot in an office building: studying a floor plan of the building and two forms of VR exploration. One group of participants studied a building plan, a second group explored a faithful VR reconstruction of the building from a normal-sized avatar's perspective, and a third group explored the VR from a giant-sized avatar's perspective. All methods contained marked checkpoints. The subsequent tasks were identical for all groups. The self-localization task required indication of the approximate location of the robot in the environment. The navigation task required navigation between checkpoints. Participants took less time to learn with the giant VR perspective and with the floorplan than with the normal VR perspective. Both VR learning methods significantly outperformed the floorplan in the orientation task. Navigation was performed quicker after learning in the giant perspective compared to the normal perspective and the building plan. We conclude that the normal perspective and especially the giant perspective in VR are viable options for preparing for teleoperation in unfamiliar environments when a virtual model of the environment is available.
C1 [Eisentrager, Karl] Humboldt Univ, Berlin, Germany.
   [Haubner, Judith; Brade, Jennifer; Einhauser, Wolfgang; Bendixen, Alexandra; Winkler, Sven; Klimant, Philipp; Jahn, Georg] Tech Univ Chemnitz, Chemnitz, Germany.
C3 Humboldt University of Berlin; Technische Universitat Chemnitz
RP Eisentrager, K (corresponding author), Humboldt Univ, Berlin, Germany.
EM karl.eisentraeger@protonmail.de;
   judith.haubner@psychologie.tu-chemnitz.de;
   jennifer.brade@mb.tu-chemnitz.de;
   wolfgang.einhaeuser-treyer@physik.tu-chemnitz.de;
   alexandra.bendixen@physik.tu-chemnitz.de;
   sven.winkler@mb.tu-chemnitz.de; philipp.klimant@mb.tu-chemnitz.de;
   georg.jahn@psychologie.tu-chemnitz.de
RI Bendixen, Alexandra/B-3922-2010; Einhäuser, Wolfgang/A-3041-2012; Jahn,
   Georg/G-8931-2013
OI Jahn, Georg/0000-0002-4940-3404; Haubner, Judith/0000-0003-2511-7435;
   Bendixen, Alexandra/0000-0001-8211-9619; Klimant,
   Philipp/0000-0001-7819-8473; Einhauser, Wolfgang/0000-0001-7516-9589
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [416228727 - SFB 1410]
FX We thank Jenny Rettstatt for supporting data acquisition. This work was
   funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
   Foundation) - Project-ID 416228727 - SFB 1410.
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Ammar A, 2022, FRONT BUILT ENVIRON, V8, DOI 10.3389/fbuil.2022.834671
   [Anonymous], 2021, UNITY           0103
   Argelaguet F, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P269, DOI 10.1145/2993369.2993391
   Basañez L, 2009, SPRINGER HANDBOOK OF AUTOMATION, P449, DOI 10.1007/978-3-540-78831-7_27
   Boboc H., B TRANSILVANIA U BRA
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Brockmole JR, 2003, COGNITION, V87, pB59, DOI 10.1016/S0010-0277(02)00231-7
   Brown P, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.945800
   Brunyé TT, 2012, COMPUT HUM BEHAV, V28, P257, DOI 10.1016/j.chb.2011.09.008
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen JYC, 2007, IEEE T SYST MAN CY C, V37, P1231, DOI 10.1109/TSMCC.2007.905819
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P4685, DOI 10.1109/TVCG.2021.3099012
   Cheng LB, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.594673
   Cheng-Li Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P334, DOI 10.1109/FSKD.2012.6234149
   Cmentowski S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P287, DOI 10.1145/3311350.3347183
   Dai RZ, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0130-7
   Diwadkar VA, 1997, PSYCHOL SCI, V8, P302, DOI 10.1111/j.1467-9280.1997.tb00442.x
   Doublerobotics, DOUBL ROB TEL ROB HY
   Drewes J, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.656913
   Du J., 2022, AUTOMAT CONSTR, V140, DOI [10.1016/j.autcon.2022.104369[15]D, DOI 10.1016/J.AUTCON.2022.104369[15]D]
   Du JH, 2021, INT J SOC ROBOT, V13, P1295, DOI 10.1007/s12369-020-00718-w
   Duer Z, 2018, IEEE COMPUT GRAPH, V38, P33, DOI 10.1109/MCG.2018.032421652
   Englmeier D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P345, DOI 10.1109/VR50410.2021.00057
   Gomez AV, 2009, COGN PROCESS, V10, pS338, DOI 10.1007/s10339-009-0299-2
   Harley D, 2020, CONVERGENCE-US, V26, P1144, DOI 10.1177/1354856519860237
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Hirschmanner M, 2019, IEEE-RAS INT C HUMAN, P259, DOI [10.1109/Humanoids43949.2019.9035064, 10.1109/humanoids43949.2019.9035064]
   Hirzle T, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445361
   Käser DP, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085094
   Kato Y, 2015, IEEE INT C INT ROBOT, P4524, DOI 10.1109/IROS.2015.7354020
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lewandowicz E, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14194687
   Lopez M. D., 2020, THESIS AALBORG U DEN
   McCauley Michael E, 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI [10.1162/pres.1992.1.3.311, DOI 10.1162/PRES.1992.1.3.311]
   Olshannikova E., 2015, J BIG DATA-GER, V2, P22
   Opiyo S, 2021, INT J CONTROL AUTOM, V19, P1384
   Pazzaglia F., 2007, SPAT COGN COMPUT, V7, P349, DOI DOI 10.1080/13875860701663223
   Santos D.S., 2011, International Journal of Interactive Worlds, V2011, P1, DOI DOI 10.5171/2011.897069
   Schneider LF, 1999, APPL COGNITIVE PSYCH, V13, P415, DOI 10.1002/(SICI)1099-0720(199910)13:5<415::AID-ACP602>3.0.CO;2-N
   Shelton AL, 2004, J EXP PSYCHOL LEARN, V30, P158, DOI 10.1037/0278-7393.30.1.158
   SHERIDAN TB, 1989, AUTOMATICA, V25, P487, DOI 10.1016/0005-1098(89)90093-9
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   TAYLOR HA, 1992, J MEM LANG, V31, P261, DOI 10.1016/0749-596X(92)90014-O
   Taylor HA, 1999, MEM COGNITION, V27, P309, DOI 10.3758/BF03211414
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   Tikanmäki A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1526, DOI 10.1109/ICMA.2017.8016043
   Wang LL, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P708, DOI [10.1109/VR.2019.8798025, 10.1109/vr.2019.8798025]
   Whitney D, 2020, SPR PROC ADV ROBOT, V10, P335, DOI 10.1007/978-3-030-28619-4_28
   Wingrave CA, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P11, DOI 10.1109/TRIDUI.2006.1618264
   Wonsick M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10249051
   Zheng M. Pan, 2020, P 37 INT S AUT ROB C, V37, P16, DOI [10.22260/ISARC2020/0004[37]F, DOI 10.22260/ISARC2020/0004]
NR 56
TC 0
Z9 0
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2220
EP 2229
DI 10.1109/TVCG.2023.3247052
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1KP9
UT WOS:000966383200001
PM 37027735
DA 2024-11-06
ER

PT J
AU Matsumuro, M
   Mori, S
   Kataoka, Y
   Igarashi, F
   Shibata, F
   Kimura, A
AF Matsumuro, Miki
   Mori, Shohei
   Kataoka, Yuta
   Igarashi, Fumiaki
   Shibata, Fumihisa
   Kimura, Asako
TI Modified Egocentric Viewpoint for Softer Seated Experience in Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Softness-perception; pseudo-haptics; virtual-viewpoint; chair
ID PERCEPTION; VISION; DISCRIMINATION; SOFTNESS; SYSTEM; COLOR; SWAY
AB Users in a prolonged experience of virtual reality adopt a sitting position according to their task, as they do in the real world. However, inconsistencies in the haptic feedback from a chair they sit on in the real world and that which is expected in the virtual world decrease the feeling of presence. We aimed to change the perceived haptic features of a chair by shifting the position and angle of the users' viewpoints in the virtual reality environment. The targeted features in this study were seat softness and backrest flexibility. To enhance the seat softness, we shifted the virtual viewpoint using an exponential formula soon after a user's bottom contacted the seat surface. The flexibility of the backrest was manipulated by moving the viewpoint, which followed the tilt of the virtual backrest. These shifts make users feel as if their body moves along with the viewpoint; as a result, they would perceive pseudo-softness or flexibility consistently with the body movement. Based on subjective evaluations, we confirmed that the participants perceived the seat as being softer and the backrest as being more flexible than the actual ones. These results demonstrated that only shifting the viewpoint could change the participants' perceptions of the haptic features of their seats, although significant changes created strong discomfort.
C1 [Matsumuro, Miki; Kataoka, Yuta; Igarashi, Fumiaki; Shibata, Fumihisa; Kimura, Asako] Ritsumeikan Univ, Tokyo, Japan.
   [Mori, Shohei] Graz Univ Technol, Graz, Austria.
C3 Ritsumeikan University; Graz University of Technology
RP Matsumuro, M (corresponding author), Ritsumeikan Univ, Tokyo, Japan.
EM m-muro@fc.ritsumei.ac.jp; s.mori.jp@ieee.org;
   y-katao@rm2c.ise.ritsumei.ac.jp
RI Matsumuro, Miki/KRQ-0548-2024; Mori, Shohei/AAL-6642-2020
OI Matsumuro, Miki/0000-0002-0647-1263; Mori, Shohei/0000-0003-0540-7312
FU JSPS KAKENHI [20K19853]; Grants-in-Aid for Scientific Research
   [20K19853, 20H04235] Funding Source: KAKEN
FX This work was supported by JSPS KAKENHI Grant-in-Aid for YoungScientists
   Number 20K19853
CR Argelaguet F, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2501599
   Ban Y, 2014, IEEE HAPTICS SYM, P557, DOI 10.1109/HAPTICS.2014.6775516
   Bell Stuart., 2017, International Encyclopedia of the First World War, P1
   Bicchi A, 2000, IEEE T ROBOTIC AUTOM, V16, P496, DOI 10.1109/70.880800
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Brade J, 2021, MENSCH AND COMPUTER 2021 (MUC 21), P270, DOI 10.1145/3473856.3473991
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Cheng X., 2020, PROC ACM C HUMAN FAC, P1
   Costes A., 2019, Front. ICT, V6, DOI DOI 10.3389/FICT.2019.00001
   Cullen KE, 2004, J NEUROPHYSIOL, V91, P1919, DOI 10.1152/jn.00988.2003
   D'Amour S, 2017, EXP BRAIN RES, V235, P2811, DOI 10.1007/s00221-017-5009-1
   Danieau F, 2014, IEEE MULTIMEDIA, V21, P11, DOI 10.1109/MMUL.2013.64
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Erol T., 2016, CELEBRATION CONTEMPL, P172
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   FITZPATRICK R, 1994, J PHYSIOL-LONDON, V478, P173, DOI 10.1113/jphysiol.1994.sp020240
   Friedman RM, 2008, EXP BRAIN RES, V191, P133, DOI 10.1007/s00221-008-1507-5
   Gall D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P73, DOI 10.1109/VR.2018.8446153
   Golding JF, 2006, AUTON NEUROSCI-BASIC, V129, P67, DOI 10.1016/j.autneu.2006.07.019
   Hansson EE, 2010, ACTA OTO-LARYNGOL, V130, P1358, DOI 10.3109/00016489.2010.498024
   HELLER MA, 1992, PERCEPTION, V21, P655, DOI 10.1068/p210655
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   JOHANSSON G, 1977, PERCEPTION, V6, P365, DOI 10.1068/p060365
   JONES LA, 1994, CAN J PHYSIOL PHARM, V72, P484, DOI 10.1139/y94-071
   Kawabe T, 2020, IEEE T HAPTICS, V13, P18, DOI 10.1109/TOH.2019.2961883
   Kayawari T., 2014, PROC INT C KANSEI EN, V100, P245
   Keshavarz Behrang, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P147, DOI 10.1007/978-3-319-39907-2_14
   Knörlein B, 2009, INT SYM MIX AUGMENT, P49, DOI 10.1109/ISMAR.2009.5336501
   Kuschel F., 2007, P PRESENCE 2007 10 A
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Leib R, 2018, J NEUROPHYSIOL, V120, P781, DOI 10.1152/jn.00822.2017
   Li M, 2014, MECHATRONICS, V24, P1092, DOI 10.1016/j.mechatronics.2014.07.004
   Ludwig VU, 2013, CORTEX, V49, P1089, DOI 10.1016/j.cortex.2012.04.004
   Massie Thomas H., 1994, P ASME WINT ANN M S, V55, P295
   Matsumoto K., 2017, P ACM SIGGRAPH, P1
   Matsumuro H., 2021, P ANN M COGN SCI SOC, V43, P2
   Mori S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P703, DOI 10.1109/VR51125.2022.00091
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Palmisano S, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00193
   Palmisano S, 2014, EXP BRAIN RES, V232, P1185, DOI 10.1007/s00221-014-3835-y
   Punpongsanon P, 2015, IEEE T VIS COMPUT GR, V21, P1279, DOI 10.1109/TVCG.2015.2459792
   Pusch A., 2011, P 13 INT C MULT INT, P57
   Rajapakse R.P.C Janaka, 2012, KANSEI ENG INT J, V11, P199
   Razzaque S., 2001, Eurographics 2001-Short Presentations
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Scilingo EP, 2010, IEEE T HAPTICS, V3, P109, DOI [10.1109/TOH.2010.2, 10.1109/ToH.2010.2]
   Sherrington C. S, 1947, INTEGRATIVE ACTION N, V1906, P1
   Slobodenyuk N, 2015, ATTEN PERCEPT PSYCHO, V77, P1379, DOI 10.3758/s13414-015-0837-1
   SRINIVASAN MA, 1995, J NEUROPHYSIOL, V73, P88, DOI 10.1152/jn.1995.73.1.88
   Tada S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P674, DOI 10.1109/VRW50115.2020.00188
   Tanino G., 2019, JAPANESE J COMPREHEN, V10, P65, DOI 10.11336/jjcrs.10.65
   Tiest WMB, 2008, LECT NOTES COMPUT SC, V5024, P255, DOI 10.1007/978-3-540-69057-3_30
   Ujitoko T., 2022, SCI REP-UK, V12, P1
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wu W., 1999, P AM SOC MECH ENG DY, V67, P19
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
NR 59
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2230
EP 2238
DI 10.1109/TVCG.2023.3247056
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2NK7
UT WOS:000967139600001
PM 37027737
DA 2024-11-06
ER

PT J
AU Qu, Q
   Chen, XM
   Chung, YY
   Cai, WD
AF Qu, Qiang
   Chen, Xiaoming
   Chung, Yuk Ying
   Cai, Weidong
TI LFACon: Introducing Anglewise Attention to No-Reference Quality
   Assessment in Light Field Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Kernel; Measurement; Feature extraction; Light fields; Image quality;
   Convolution; Computational efficiency; No-reference Image Quality
   Assessment; Quality of Experience; Light Field Imaging; Immersive Media;
   Attention Mechanism; Deep Learning
AB Light field imaging can capture both the intensity information and the direction information of light rays. It naturally enables a six-degrees-of-freedom viewing experience and deep user engagement in virtual reality. Compared to 2D image assessment, light field image quality assessment (LFIQA) needs to consider not only the image quality in the spatial domain but also the quality consistency in the angular domain. However, there is a lack of metrics to effectively reflect the angular consistency and thus the angular quality of a light field image (LFI). Furthermore, the existing LFIQA metrics suffer from high computational costs due to the excessive data volume of LFIs. In this paper, we propose a novel concept of "anglewise attention" by introducing a multihead self-attention mechanism to the angular domain of an LFl. This mechanism better reflects the LFI quality. In particular, we propose three new attention kernels, including anglewise self-attention, anglewise grid attention, and anglewise central attention. These attention kernels can realize angular self-attention, extract multiangled features globally or selectively, and reduce the computational cost of feature extraction. By effectively incorporating the proposed kernels, we further propose our light field attentional convolutional neural network (LFACon) as an LFIQA metric. Our experimental results show that the proposed LFACon metric significantly outperforms the state-of-the-art LFIQA metrics. For the majority of distortion types, LFACon attains the best performance with lower complexity and less computational time.
C1 [Qu, Qiang; Chung, Yuk Ying; Cai, Weidong] Univ Sydney, Sydney, Australia.
   [Chen, Xiaoming] Beijing Technol & Business Univ, Beijing, Peoples R China.
C3 University of Sydney; Beijing Technology & Business University
RP Chen, XM (corresponding author), Beijing Technol & Business Univ, Beijing, Peoples R China.
EM vincent.qu@sydney.edu.au; xiaoming.chen@btbu.edu.cn;
   vera.chung@sydney.edu.au; tom.cai@sydney.edu.au
RI Cai, Tingwei/AAJ-8822-2020
OI Qu, Qiang/0000-0002-6648-5050; Chen, Xiaoming/0000-0002-7503-3021; Cai,
   Weidong/0000-0003-3706-8896
FU Beijing Natural Science Foundation [4222003]; National Natural Science
   Foundation of China [62177001]
FX This work was supported in part by Beijing Natural Science Foundation
   under Grant 4222003 and National Natural Science Foundation of China
   under Grant 62177001.
CR Adhikarla VK, 2017, PROC CVPR IEEE, P3720, DOI 10.1109/CVPR.2017.396
   [Anonymous], 2005, MODERN INTRO PROBABI
   Ba J.L., 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06450
   Chen G., 2022, IEEE T VIS COMPUT GR
   Chen J., 2018, IEEE T IMAGE PROCESS
   Date M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1297, DOI [10.1109/VR.2019.8797796, 10.1109/vr.2019.8797796]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Han W., 2021, IEEE T PATTERN ANAL
   Huang HL, 2020, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2020), P348, DOI 10.1109/MIPR49039.2020.00077
   Ihrke I, 2016, IEEE SIGNAL PROC MAG, V33, P59, DOI 10.1109/MSP.2016.2582220
   Itoh Y, 2016, IEEE T VIS COMPUT GR, V22, P2368, DOI 10.1109/TVCG.2016.2593779
   Jin J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P193, DOI 10.1145/3394171.3413585
   Koniaris C, 2019, IEEE T VIS COMPUT GR, V25, P1666, DOI 10.1109/TVCG.2018.2818156
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu ZC, 2019, MULTIMED TOOLS APPL, V78, P29211, DOI 10.1007/s11042-018-6597-x
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Lv XQ, 2021, IEEE T VIS COMPUT GR, V27, P3597, DOI 10.1109/TVCG.2020.2982158
   Ma L., 2022, IEEE SYST J
   Meng XX, 2021, IEEE T VIS COMPUT GR, V27, P3350, DOI 10.1109/TVCG.2020.2975801
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Paudyal P, 2017, IEEE T BROADCAST, V63, P507, DOI 10.1109/TBC.2017.2704430
   Qu Q, 2021, IEEE T BROADCAST, V67, P837, DOI 10.1109/TBC.2021.3099737
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shi LK, 2020, IEEE T CIRC SYST VID, V30, P4114, DOI 10.1109/TCSVT.2019.2955011
   Shi LK, 2019, IEEE IMAGE PROC, P3781, DOI [10.1109/ICIP.2019.8803559, 10.1109/icip.2019.8803559]
   Shi LK, 2018, IEEE IMAGE PROC, P41, DOI 10.1109/ICIP.2018.8451077
   Tsai YJ, 2020, AAAI CONF ARTIF INTE, V34, P12095
   Tukey J. W., 1977, EXPLORATORY DATA ANA, V2
   Vaswani A, 2017, ADV NEUR IN, V30
   Wald L., 2000, 3 C FUS EARTH DAT ME, P99
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Yang R, 2008, IEEE T VIS COMPUT GR, V14, P84, DOI 10.1109/70410
   Yeung H.W.F., 2018, P EUR C COMP VIS, P137
   Yeung HWF, 2019, IEEE T IMAGE PROCESS, V28, P2319, DOI 10.1109/TIP.2018.2885236
   Yim C, 2011, IEEE T IMAGE PROCESS, V20, P88, DOI 10.1109/TIP.2010.2061859
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhou W, 2020, IEEE T IMAGE PROCESS, V29, P4070, DOI 10.1109/TIP.2020.2969777
   Zwillinger S., 1999, CRC Standard Probability and StatisticsTables and Formulae
NR 47
TC 11
Z9 11
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2239
EP 2248
DI 10.1109/TVCG.2023.3247069
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2SN8
UT WOS:000967273500001
PM 37027711
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Raveendranath, B
   Pagano, CC
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Roshan
   Venkatakrishnan, Rohith
   Raveendranath, Balagopal
   Pagano, Christopher C. C.
   Robb, Andrew C. C.
   Lin, Wen-Chieh
   Babu, Sabarish V. V.
TI How Virtual Hand Representations Affect the Perceptions of Dynamic
   Affordances in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; End effectors; Affordances; Tracking; Visualization;
   Grasping; Cameras; Affordance; Passability; Self-Avatar; Virtual Reality
ID PERCEIVING AFFORDANCES; VISUAL GUIDANCE; SELF-AVATAR; BODY; EMBODIMENT;
   TIME; CONTROLLERS; OWNERSHIP; CHILDREN; OBJECTS
AB User representations are critical to the virtual experience, and involve both the input device used to support interactions as well as how the user is virtually represented in the scene. Inspired by previous work that has shown effects of user representations on the perceptions of relatively static affordances, we attempt to investigate how end-effector representations affect the perceptions of affordances that dynamically change over time. Towards this end, we empirically evaluated how different virtual hand representations affect users' perceptions of dynamic affordances in an object retrieval task wherein users were tasked with retrieving a target from a box for a number of trials while avoiding collisions with its moving doors. We employed a 3 (virtual end-effector representation) X 13 (frequency of moving doors) X 2 (target object size) multi-factorial design, manipulating the input modality and its concomitant virtual end-effector representation as a between-subjects factor across three experimental conditions: (1) Controller (using a controller represented as a virtual controller); (2) Controller-hand (using a controller represented as a virtual hand); (3) Glove (using a hand tracked hi-fidelity glove represented as a virtual hand). Results indicated that the controller-hand condition produced lower levels of performance than both the other conditions. Furthermore, users in this condition exhibited a diminished ability to calibrate their performance over trials. Overall, we find that representing the end-effector as a hand tends to increase embodiment but can also come at the cost of performance, or an increased workload due to a discordant mapping between the virtual representation and the input modality used. It follows that VR system designers should carefully consider the priorities and target requirements of the application being developed when choosing the type of end-effector representation for users to embody in immersive virtual experiences.
C1 [Venkatakrishnan, Roshan; Venkatakrishnan, Rohith; Robb, Andrew C. C.; Babu, Sabarish V. V.] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
   [Raveendranath, Balagopal; Pagano, Christopher C. C.] Clemson Univ, Dept Psychol, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 Clemson University; Clemson University; National Yang Ming Chiao Tung
   University
RP Venkatakrishnan, R (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM rvenkat@g.clemson.edu; rohithv@g.clemson.edu; braveen@g.clemson.edu;
   cpagano@clemson.edu; arobb@clemson.edu; wclin@cs.nctu.edu.tw;
   sbabu@clemson.edu
RI Venkatakrishnan, Roshan/JDC-3508-2023; Venkatakrishnan,
   Rohith/JCE-8736-2023
OI Pagano, Christopher/0000-0002-0110-2055; Venkatakrishnan,
   Rohith/0000-0002-8484-3915; Venkatakrishnan, Roshan/0000-0002-6538-627X;
   Babu, Sabarish/0000-0002-8348-0534; Robb, Andrew/0000-0002-0398-5576
FU US National Science Foundation (CISE IIS HCC) [2007435]
FX The authors would like to thank the participants of our studies for
   theirtime and effort. This work was supported in part by the US National
   Science Foundation (CISE IIS HCC) under Grant No. 2007435.
CR Adkins A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486582
   Alzayat M., 2019, P 2019 CHI C HUMAN F, P1
   Arbib MA, 2009, PSYCHOL RES-PSYCH FO, V73, P441, DOI 10.1007/s00426-009-0242-2
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Bhargava R., 2021, IEEE T VIS COMPUT GR, V3
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Blau J. B., 2022, TAYLOR AND FRANCIS, V2
   Borst CW, 2005, P IEEE VIRT REAL ANN, P91
   Buekers M, 1999, NEUROSCI LETT, V275, P171, DOI 10.1016/S0304-3940(99)00750-8
   Caggianese Giuseppe, 2019, Intelligent Interactive Multimedia Systems and Services. Proceedings of 2018 Conference. Smart Innovation, Systems and Technologies (SIST 98), P24, DOI 10.1007/978-3-319-92231-7_3
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Castro-Alonso J.C., 2014, Handbook of human centric visualization, P551, DOI [DOI 10.1007/978-1-4614-7485-2_22, 10.1007/978-1-4614-7485-2_22]
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Chihak BJ, 2010, J EXP PSYCHOL HUMAN, V36, P1535, DOI 10.1037/a0020560
   Cinelli ME, 2009, Q J EXP PSYCHOL, V62, P483, DOI 10.1080/17470210802168583
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Fajen BR, 2011, J EXP PSYCHOL HUMAN, V37, P1442, DOI 10.1037/a0023510
   Fajen BR, 2011, HUM MOVEMENT SCI, V30, P504, DOI 10.1016/j.humov.2010.07.016
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gibson JJ., 1979, ECOLOGICAL APPROACH
   Grechkin TY, 2014, IEEE T VIS COMPUT GR, V20, P596, DOI 10.1109/TVCG.2014.18
   Hale Kelly S., 2014, Handbook of virtual environments: Design, implementation, and applications
   HART S G, 1988, P139
   Heinrichs WL, 2008, WORLD J SURG, V32, P161, DOI 10.1007/s00268-007-9354-2
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Ishak S, 2008, J EXP PSYCHOL HUMAN, V34, P1501, DOI 10.1037/a0011393
   Jankowski Jacek., 2013, EUROGRAPHICS 2013 ST
   Joy T, 2022, VIRTUAL REAL-LONDON, V26, P615, DOI 10.1007/s10055-021-00511-8
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Khundam C, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8030060
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kry P.G., 2008, P ACM S VIRTUAL REAL, P53
   Laver B., 2017, COCHRANE DB SYST REV, V2
   Leyrer M., 2011, P ACM SIGGRAPH S APP, P67, DOI [10.1145/2077451.20774642, DOI 10.1145/2077451.20774642, 10.1145/2077451.2077464]
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Liu HX, 2019, IEEE INT CONF ROBOT, P5180, DOI [10.1109/icra.2019.8794230, 10.1109/ICRA.2019.8794230]
   Liu HM, 2020, INT SYM MIX AUGMENT, P566, DOI 10.1109/ISMAR50242.2020.00084
   Lok B, 2003, PRESENCE-VIRTUAL AUG, V12, P615, DOI 10.1162/105474603322955914
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Lucaites KM, 2020, ECOL PSYCHOL, V32, P95, DOI 10.1080/10407413.2020.1741323
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Manus, 2022, WEAR MAN GLOV
   Matsas E, 2017, INT J INTERACT DES M, V11, P139, DOI 10.1007/s12008-015-0259-2
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Moehring M, 2011, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2011.5759451
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Noitom, 2022, NOIT HI5 GLOV
   O'Neal EE, 2018, J EXP PSYCHOL HUMAN, V44, P18, DOI 10.1037/xhp0000378
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ossmy O, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0168520
   Pagano C C., 2019, Perception as Information Detection, P37
   Peck M., 2021, FRONTIERS VIRTUAL RE, V1
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Plumert JM, 2014, CHILD DEV PERSPECT, V8, P207, DOI 10.1111/cdep.12089
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Ricca A, 2020, INT SYM MIX AUGMENT, P260, DOI 10.1109/ISMAR50242.2020.00049
   RUNESON S, 1983, J EXP PSYCHOL GEN, V112, P585, DOI 10.1037/0096-3445.112.4.585
   Schafer A., 2022, ARXIV
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Seinfeld T., 2020, IEEE T VIS COMPUT GR, P1
   Simpson G, 2003, ACCIDENT ANAL PREV, V35, P787, DOI 10.1016/S0001-4575(02)00081-7
   Skalski P, 2011, NEW MEDIA SOC, V13, P224, DOI 10.1177/1461444810370949
   Snijders T. A. B., 2012, Multilevel Analysis, V2nd
   Sreng J, 2006, IEEE T VIS COMPUT GR, V12, P1013, DOI 10.1109/TVCG.2006.189
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Tran H., 2017, P 23 ACM S VIRTUAL R, P1
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Wald J, 2000, J BEHAV THER EXP PSY, V31, P249, DOI 10.1016/S0005-7916(01)00009-X
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
NR 82
TC 10
Z9 12
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2258
EP 2268
DI 10.1109/TVCG.2023.3247041
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1JM6
UT WOS:000966353800001
PM 37027700
DA 2024-11-06
ER

PT J
AU Fernandes, AS
   Murdison, TS
   Proulx, MJ
AF Fernandes, Ajoy S.
   Murdison, T. Scott
   Proulx, Michael J.
TI Leveling the Playing Field: A Comparative Reevaluation of Unmodified Eye
   Tracking as an Input and Interaction Modality for VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Gaze tracking; Target tracking; Task analysis; Visualization;
   Throughput; Performance evaluation; Three-dimensional displays; Eye
   tracking; User experience; Input devices; 3D user interaction; Human
   factors and ergonomics; Gaze targeting
ID INTERVAL; MOVEMENTS; SEARCH; MOTION; SCALES; TARGET; ANOVA
AB In this study, we establish a much-needed baseline for evaluating eye tracking interactions using an eye tracking enabled Meta Quest 2 VR headset with 30 participants. Each participant went through 1098 targets using multiple conditions representative of AR/VR targeting and selecting tasks, including both traditional standards and those more aligned with AR/VR interactions today. We use circular white world-locked targets, and an eye tracking system with sub-1-degree mean accuracy errors running at approximately 90Hz. In a targeting and button press selection task, we, by design, compare completely unadjusted, cursor-less, eye tracking with controller and head tracking, which both had cursors. Across all inputs, we presented targets in a configuration similar to the ISO 9241-9 reciprocal selection task and another format with targets more evenly distributed near the center. Targets were laid out either flat on a plane or tangent to a sphere and rotated toward the user. Even though we intended this to be a baseline study, we see unmodified eye tracking, without any form of a cursor, or feedback, outperformed the head by 27.9% and performed comparably to the controller (5.63% decrease) in throughput. Eye tracking had improved subjective ratings relative to head in Ease of Use, Adoption, and Fatigue (66.4%, 89.8%, and 116.1 % improvements, respectively) and had similar ratings relative to the controller (reduction by 4.2%, 8.9%, and 5.2% respectively). Eye tracking had a higher miss percentage than controller and head (17.3% vs 4.7% vs 7.2% respectively). Collectively, the results of this baseline study serve as a strong indicator that eye tracking, with even minor sensible interaction design modifications, has tremendous potential in reshaping interactions in next-generation AR/VR head mounted displays.
C1 [Fernandes, Ajoy S.; Proulx, Michael J.] Meta Real Labs Res, Seattle, WA 07809 USA.
   [Murdison, T. Scott] Meta Real Labs, Seattle, WA USA.
RP Fernandes, AS (corresponding author), Meta Real Labs Res, Seattle, WA 07809 USA.
EM ajoyferns@meta.com; smurdison@meta.com; michaelproulx@meta.com
RI Proulx, Michael/A-1045-2008; Fernandes, Ajoy/LCE-3156-2024
CR Ahn Junyoung, 2017, [Journal of the ergonomics society of Korea, 대한인간공학회지], V36, P267, DOI 10.5143/JESK.2017.36.4.267
   Allen M., 2019, WELLCOME OPEN RES, V4, P7
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/VR.2019.8797975, 10.1109/vr.2019.8797975]
   Batmaz Anil Ufuk, 2022, CHI C HUMAN FACTORS, P1, DOI DOI 10.1145/3491102.3502067
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bolt R. A., 1981, Computer Graphics, V15, P109, DOI 10.1145/965161.806796
   Bowman D. A., 1998, J VISUAL LANG COMPUT, V10, P2
   Clark LD, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102413
   de Vries S, 2018, EXP BRAIN RES, V236, P3181, DOI 10.1007/s00221-018-5369-1
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Fitts P. M., 1949, EYE FIXATIONS AIRCRA, P2
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FULLER JH, 1992, EXP BRAIN RES, V92, P152
   Girden E.R., 1992, ANOVA REPEATED MEASU, P7
   Gopal A, 2017, J NEUROPHYSIOL, V118, P1664, DOI 10.1152/jn.00329.2017
   Hadnett-Hunter J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3352763
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Hansen JP, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206344
   Jacob R.J, 1995, Virtual Environ. Adv. Interface Des., V258, P2, DOI [10.1093/oso/9780195075557.003.0015, DOI 10.1093/OSO/9780195075557.003.0015]
   JACOB RJK, 1991, ACM T INFORM SYST, V9, P152, DOI 10.1145/123078.128728
   Jota R., 2010, P GRAPH INT 2010, DOI [DOI 10.11575/PRISM/35537, 10.5555/1839214.18392612,3, DOI 10.5555/1839214.18392612,3]
   Kim Cheonhong, 2022, SID Symposium Digest of Technical Papers, V53, P40, DOI 10.1002/sdtp.15410
   KNAPP TR, 1990, NURS RES, V39, P121
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Land MF, 1999, J COMP PHYSIOL A, V185, P341, DOI 10.1007/s003590050393
   Luro FL, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318153
   MACKENZIE IS, 1989, J MOTOR BEHAV, V21, P323
   Majaranta P., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P15, DOI 10.1145/507072.507076
   McDonnell GP, 2015, PSYCHOL RES-PSYCH FO, V79, P183, DOI 10.1007/s00426-014-0546-8
   Minakata K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3317956.3318150
   Miniotas Darius., 2004, CHIOF EXTENDED ABSTR, P1255, DOI DOI 10.1145/985921.986037
   Montagnini A, 2007, J PHYSIOL-PARIS, V101, P64, DOI 10.1016/j.jphysparis.2007.10.013
   Pai YS, 2019, VIRTUAL REAL-LONDON, V23, P119, DOI 10.1007/s10055-018-0371-2
   Pfeuffer K., 2014, P 27 ANN ACM S USER, P509
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Plamondon R, 1997, BEHAV BRAIN SCI, V20, P279, DOI 10.1017/S0140525X97001441
   Proulx MJ, 2008, PSYCHOL RES-PSYCH FO, V72, P106, DOI 10.1007/s00426-006-0077-z
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Räihä KJ, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1411
   RASHBASS C, 1961, J PHYSIOL-LONDON, V159, P326, DOI 10.1113/jphysiol.1961.sp006811
   ROBINSON DA, 1968, SCIENCE, V161, P1219, DOI 10.1126/science.161.3847.1219
   Sailer U, 2000, EXP BRAIN RES, V134, P163, DOI 10.1007/s002210000457
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Schuetz I, 2022, J EYE MOVEMENT RES, V15, DOI 10.16910/jemr.15.3.3
   Schuetz I, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391336
   Schuetz I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300765
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Thaler L, 2013, VISION RES, V76, P31, DOI 10.1016/j.visres.2012.10.012
   VELLEMAN PF, 1993, AM STAT, V47, P65, DOI 10.2307/2684788
   Wang R. Y., 2008, ACM S US INT SOFTW T
   Wang Robert, 2011, P 24 ANN ACM S US IN, P549, DOI DOI 10.1145/2047196.2047269
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Ware C., 1986, P SIGCHIGI C HUMAN F, P2
   Wu HP, 2017, J SOC SERV RES, V43, P527, DOI 10.1080/01488376.2017.1329775
   Wu Xiuyun, 2022, SID Symposium Digest of Technical Papers, V53, P910, DOI 10.1002/sdtp.15642
   Yarbus A. L., 1967, Eye movements and vision, P171, DOI DOI 10.1007/978-1-4899-5379-7
   Zhang XA, 2007, LECT NOTES COMPUT SC, V4552, P779
NR 59
TC 18
Z9 18
U1 4
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2269
EP 2279
DI 10.1109/TVCG.2023.3247058
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1OJ1
UT WOS:000966480700001
PM 37027619
OA hybrid
DA 2024-11-06
ER

PT J
AU Hiratani, K
   Iwai, D
   Kageyama, Y
   Punpongsanon, P
   Hiraki, T
   Sato, K
AF Hiratani, Kosuke
   Iwai, Daisuke
   Kageyama, Yuta
   Punpongsanon, Parinya
   Hiraki, Takefumi
   Sato, Kosuke
TI Shadowless Projection Mapping using Retrotransmissive Optics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optical imaging; Optics; Apertures; Shape; Optical sensors; Adaptive
   optics; Image quality; Projection mapping; retrotransmissive optics;
   augmented reality
ID SPATIAL AUGMENTED REALITY; 3D DISPLAY; REMOVAL; DESIGN; SYSTEM; LAMPS
AB This paper presents a shadowless projection mapping system for interactive applications in which a target surface is frequently occluded from a projector with a user's body. We propose a delay-free optical solution for this critical problem. Specifically, as the primary technical contribution, we apply a large format retrotransmissive plate to project images onto the target surface from wide viewing angles. We also tackle technical issues unique to the proposed shadowless principle. First, the retrotransmissive optics inevitably suffer from stray light, which leads to significant contrast degradation of the projected result. We propose to block the stray light by covering the retrotransmissive plate with a spatial mask. Because the mask reduces not only the stray light but the achievable luminance of the projected result, we develop a computational algorithm that determines the shape of the mask to balance the image quality. Second, we propose a touch sensing technique by leveraging the optically bidirectional property of the retrotransmissive plate to support interaction between the user and the projected contents on the target object. We implement a proof-of-concept prototype and validate the above-mentioned techniques through experiments.
C1 [Hiratani, Kosuke; Iwai, Daisuke; Kageyama, Yuta; Punpongsanon, Parinya; Hiraki, Takefumi; Sato, Kosuke] Osaka Univ, Osaka, Japan.
C3 Osaka University
RP Hiratani, K (corresponding author), Osaka Univ, Osaka, Japan.
EM hiratani@sens.sys.es.osaka-u.ac.jp; daisuke.iwai@sys.es.osaka-u.ac.jp;
   kageyama@sens.sys.es.osaka-u.ac.jp; parinya@sys.es.osaka-u.ac.jp;
   hiraki@sens.sys.es.osaka-u.ac.jp; sato@sys.es.osaka-u.ac.jp
RI PUNPONGSANON, PARINYA/B-4884-2013; Iwai, Daisuke/R-8174-2019
OI Punpongsanon, Parinya/0000-0003-2720-7768; Hiraki,
   Takefumi/0000-0002-5767-3607; Sato, Kosuke/0000-0003-1429-9990; Iwai,
   Daisuke/0000-0002-3493-5635
FU JSPS KAKENHI [JP20H05958]; JST, PRESTO, Japan [JPMJPR19J2]
FX This work was supported by JSPS KAKENHI Grant Numbers JP20H05958 and
   JST, PRESTO Grant Number JPMJPR19J2, Japan
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Aliaga DG, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409102
   [Anonymous], 2005, P 18 ANN ACM S US IN, DOI DOI 10.1145/1095034.1095054
   Audet S., 2007, COMPUTER VISION PATT, P1, DOI [DOI 10.1109/CVPR.2007.383470, 10.1109/CVPR.2007.383470]
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Benko H, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P77, DOI 10.1145/1449715.1449729
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O, 2005, IEEE MULTIMEDIA, V12, P16, DOI 10.1109/MMUL.2005.9
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Cascini G, 2020, COMPUT IND, V123, DOI 10.1016/j.compind.2020.103308
   Chita E., 2015, P 2015 ACM INT JOINT, P69, DOI 10.1145
   Choi S, 2020, OPT EXPRESS, V28, P15691, DOI 10.1364/OE.392036
   Flagg Matthew, 2006, UIST'06, P235, DOI DOI 10.1145/1166253.1166290
   Grady P, 2022, LECT NOTES COMPUT SC, V13666, P328, DOI 10.1007/978-3-031-20068-7_19
   Hiratani K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1309, DOI [10.1109/VR.2019.8798245, 10.1109/vr.2019.8798245]
   Hochreiter J, 2015, P IEEE VIRT REAL ANN, P69, DOI 10.1109/VR.2015.7223326
   Hoshi A, 2022, OPT REV, V29, P106, DOI 10.1007/s10043-022-00729-0
   Isogawa M, 2014, IEEE T VIS COMPUT GR, V20, P1293, DOI 10.1109/TVCG.2014.2316002
   Iwai D., 2006, P ACM S VIRT REAL SO, P112, DOI [10.1145/1180495.1180519, DOI 10.1145/1180495.1180519]
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Iwai D, 2014, VIRTUAL REAL-LONDON, V18, P245, DOI 10.1007/s10055-014-0250-4
   Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728
   Jaynes C, 2001, IEEE VISUAL, P175, DOI 10.1109/VISUAL.2001.964509
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Kageyama Y, 2020, OPT EXPRESS, V28, P20391, DOI 10.1364/OE.396159
   Kim H, 2014, ENTERTAIN COMPUT, V5, P233, DOI 10.1016/j.entcom.2014.10.008
   Kim J, 2019, COMPUT GRAPH FORUM, V38, P443, DOI 10.1111/cgf.13541
   Kitajima Y, 2017, IEEE T VIS COMPUT GR, V23, P2419, DOI 10.1109/TVCG.2017.2734478
   Kiuchi S, 2021, COMPUT GRAPH-UK, V96, P14, DOI 10.1016/j.cag.2021.02.007
   Kiyokawa M., 2019, SIGGRAPH AS 2019 POS, DOI [10.1145/3355056.3364551, DOI 10.1145/3355056.33645513,9]
   Kiyokawa M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P597, DOI 10.1109/VRW52623.2021.00181
   Krueger Myron W., 1985, Proceedings of the SIGCHI conference on Human factors in computing systems, P35, DOI [10.1145/317456.317463, 10.1145/1165385.317463, DOI 10.1145/1165385.317463]
   Levoy M, 2004, ACM T GRAPHIC, V23, P825, DOI 10.1145/1015706.1015806
   Maekawa S, 2006, PROC SPIE, V6392, DOI 10.1117/12.690574
   Makino Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1980, DOI 10.1145/2858036.2858481
   Marner MR, 2014, IEEE COMPUT GRAPH, V34, P74, DOI 10.1109/MCG.2014.117
   Martschinke J., 2021, EUR WORKSH VIS COMP, DOI 10.2312/vcbm.20211354
   Matsushita K., 2011, P 2 AUGM HUM INT C
   Menk C, 2011, COMPUT GRAPH FORUM, V30, P2354, DOI 10.1111/j.1467-8659.2011.02066.x
   Minomo Y., 2005, P 2005 ACM SIGCHI IN, P61, DOI [10.1145/1178477.1178485, DOI 10.1145/1178477.1178485]
   Nagase M, 2011, VIRTUAL REAL-LONDON, V15, P119, DOI 10.1007/s10055-010-0168-4
   Niikura T, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P337, DOI 10.1145/2992154.2996777
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Niwa Y, 2018, SA'18: SIGGRAPH ASIA 2018 POSTERS, DOI 10.1145/3283289.3283317
   Nomoto T., 2020, SIGGRAPH AS 2020 EM
   Okuda S., 2021, SPIE, V11766, P334, DOI [10.1117/12.25910299, DOI 10.1117/12.25910299]
   Otao K, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174911
   Otsubo M., 2014, US Patent, Patent No. [8,702,252, 8702252]
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Peterka T, 2008, IEEE T VIS COMPUT GR, V14, P487, DOI 10.1109/TVCG.2007.70627
   Pinhanez Claudio., 2001, CHI 01, P369
   Raskar R, 2004, ACM T GRAPHIC, V23, P406, DOI 10.1145/1015706.1015738
   Raskar R., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P179, DOI 10.1145/280814.280861
   Raskar R., 2002, P 2 INT S NONPHOTORE, P7, DOI [10.1145/508530.508532, DOI 10.1145/508530.5085322]
   Rivers A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366176
   Schmidt S, 2019, COMPUT GRAPH-UK, V83, P1, DOI 10.1016/j.cag.2019.06.002
   Shoemaker G, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P53
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Sugaya Y., 2010, 2010 IEEE COMP SOC C, P96
   Sugita Naoki, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1520, DOI 10.1109/SICE.2008.4654901
   Sukthankar R, 2001, PROC CVPR IEEE, P151
   Summet Jay., 2005, CHI'05 Extended Abstracts, P1997
   Takezawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI [10.1109/vr.2019.8797923, 10.1109/VR.2019.8797923]
   Tsukamoto J, 2017, COMPUT GRAPH FORUM, V36, P369, DOI 10.1111/cgf.13085
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   Underkofer John, 1999, P SIGCHI C HUM FACT, P386, DOI DOI 10.1145/302979.303114
   Watanabe T, 2021, SIGGRAPH '21: ACM SIGGRAPH 2021 POSTERS, DOI 10.1145/3450618.3469142
   Wilson Andrew D., 2005, P 18 ANN ACM S US IN, P83, DOI DOI 10.1145/1095034.1095047
   Xu HC, 2006, 2006 SICE-ICASE INTERNATIONAL JOINT CONFERENCE, VOLS 1-13, P2457
   Yamamoto H., 2015, P 2015 INT C INT TAB, P397, DOI [10.1145/2817721.2823476, DOI 10.1145/2817721.2823476]
   Yamamoto H, 2014, OPT EXPRESS, V22, P26919, DOI 10.1364/OE.22.026919
   Yamamoto H, 2013, PROC SPIE, V8648, DOI 10.1117/12.2005674
   Yasui M, 2019, APPL OPTICS, V58, pA209, DOI 10.1364/AO.58.00A209
   Zhang HL, 2020, OPT LETT, V45, P351, DOI 10.1364/OL.45.000351
NR 75
TC 5
Z9 5
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2280
EP 2290
DI 10.1109/TVCG.2023.3247104
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2SF8
UT WOS:000967265500001
PM 37027738
OA hybrid
DA 2024-11-06
ER

PT J
AU Fidalgo, CG
   Yan, YK
   Cho, HYS
   Sousa, M
   Lindlbauer, D
   Jorge, J
AF Fidalgo, Catarina G. G.
   Yan, Yukang
   Cho, Hyunsung
   Sousa, Mauricio
   Lindlbauer, David
   Jorge, Joaquim
TI A Survey on Remote Assistance and Training in Mixed Reality Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Virtual reality; Collaboration; Mixed reality; Task analysis;
   Maintenance engineering; Visualization; Mixed Reality; Virtual Reality;
   Augmented Reality; Extended Reality; Remote; Assistance
ID AUGMENTED REALITY; COLLABORATION; DESIGN; SYSTEM; USER
AB The recent pandemic, war, and oil crises have caused many to reconsider their need to travel for education, training, and meetings. Providing assistance and training remotely has thus gained importance for many applications, from industrial maintenance to surgical telemonitoring. Current solutions such as video conferencing platforms lack essential communication cues such as spatial referencing, which negatively impacts both time completion and task performance. Mixed Reality (MR) offers opportunities to improve remote assistance and training, as it opens the way to increased spatial clarity and large interaction space. We contribute a survey of remote assistance and training in MR environments through a systematic literature review to provide a deeper understanding of current approaches, benefits and challenges. We analyze 62 articles and contextualize our findings along a taxonomy based on degree of collaboration, perspective sharing, MR space symmetry, time, input and output modality, visual display, and application domain. We identify the main gaps and opportunities in this research area, such as exploring collaboration scenarios beyond one-expert-to-one-trainee, enabling users to move across the reality-virtuality spectrum during a task, or exploring advanced interaction techniques that resort to hand or eye tracking. Our survey informs and helps researchers in different domains, including maintenance, medicine, engineering, or education, build and evaluate novel MR approaches to remote training and assistance. All supplemental materials are available at https://augmented-perception.org/publications/2023-training-survey.html.
C1 [Fidalgo, Catarina G. G.] Univ Lisbon, INESC ID, Inst Super Tecn, Lisbon, Portugal.
   [Fidalgo, Catarina G. G.; Yan, Yukang; Cho, Hyunsung; Lindlbauer, David] Carnegie Mellon Univ, Pittsburgh, PA USA.
   [Sousa, Mauricio] Univ Toronto, Toronto, ON, Canada.
   [Jorge, Joaquim] INESC ID, Lisbon, Portugal.
   [Jorge, Joaquim] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.
C3 Universidade de Lisboa; INESC-ID; Carnegie Mellon University; University
   of Toronto; INESC-ID; Universidade de Lisboa; Universidade de Lisboa
RP Fidalgo, CG (corresponding author), Univ Lisbon, INESC ID, Inst Super Tecn, Lisbon, Portugal.
EM cfidalgo@andrew.cmu.edu; yukangy@andrew.cmu.edu;
   hyunsung@andrew.cmu.edu; mauricio.sousa@utoronto.ca;
   dlindlba@andrew.cmu.edu; jorgej@tecnico.ulisboa.pt
RI ; Jorge, Joaquim/C-5596-2008
OI Lindlbauer, David/0000-0002-0809-9696; Sousa,
   Antonio/0000-0003-1438-2882; Cho, Hyunsung/0000-0002-4521-2766; Fidalgo,
   Catarina/0000-0003-1621-1999; Jorge, Joaquim/0000-0001-5441-4637; Yan,
   Yukang/0000-0001-7515-3755
FU Fundacao para a Ciencia e a Tecnologia (Portuguese Foundation for
   Science and Technology) [2022.09212.PTDC, UIDB/50021/2020]; Carnegie
   Mellon/Portugal Program fellowship under the UNESCO Chair on AIXR
   [SFRH/BD/151465/2021]
FX This work is co-financed by Fundacao para a Ciencia e a Tecnologia
   (Portuguese Foundation for Science and Technology) partially through
   grants 2022.09212.PTDC (XAVIER), UIDB/50021/2020 and the Carnegie
   Mellon/Portugal Program fellowship SFRH/BD/151465/2021, under the UNESCO
   Chair on AI&XR.
CR Abtahi P., 2022, P 2022 CHI C HUMAN F, DOI [10.1145/3491102.35177067, DOI 10.1145/3491102.35177067]
   Adcock M., 2013, P 12 ACM SIGGRAPH IN
   Adcock M., 2014, P 2 ACM S SPAT US IN, P113, DOI DOI 10.1145/2659766.2659768
   Ansar A, 2001, COMPUT GRAPH-UK, V25, P789, DOI 10.1016/S0097-8493(01)00121-2
   Aschenbrenner D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P509, DOI 10.1109/VR.2018.8446533
   Auda J., 2021, S SPATIAL USER INTER, P1
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bai Z, 2012, INTERACT COMPUT, V24, P450, DOI 10.1016/j.intcom.2012.07.004
   Bednarz T., 2011, P 10 INT C VIRT REAL, P459, DOI [DOI 10.1145/2087756, 10.1145/2087756.2087845, DOI 10.1145/2087756.2087845]
   Bottecchia S., 2010, Proceedings of the 1st Augmented Human International Conference, P1
   Brudy F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300792
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chen XM, 2019, J VIS COMMUN IMAGE R, V58, P416, DOI 10.1016/j.jvcir.2018.11.039
   Cidota M, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875204
   Clergeaud D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139165
   Davis MC, 2016, WORLD NEUROSURG, V86, P103, DOI 10.1016/j.wneu.2015.08.053
   de Freitas S, 2009, BRIT J EDUC TECHNOL, V40, P980, DOI 10.1111/j.1467-8535.2008.00887.x
   Domova Veronika., 2014, Proceedings of the Ninth ACM International Conference on Interactive Tabletops and Surfaces, P229
   Feick M., 2018, P 2018 CHI C HUMAN F, P281
   Funk M., 2017, HOLOCOLLAB SHARED VI, P1, DOI [10.1145/3131542.31315593, DOI 10.1145/3131542.31315593]
   Gasques D  ..., 2021, P CHI, DOI [DOI 10.1145/3411764.3445576, 10.1145/3411764.3445576]
   Gauglitz S., 2014, P 27 ANN ACM S US IN, P449
   Gauglitz Steffen, 2014, P 20 ACM S VIRT REAL, P197, DOI 10.1145/2671015.2671016
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich P, 2015, COMPUT SUPP COOP W J, V24, P527, DOI 10.1007/s10606-015-9232-7
   Gurevich Pavel, 2012, P SIGCHI C HUM FACT, P619, DOI DOI 10.1145/2207676.2207763
   Herder J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P968, DOI 10.1109/VR.2019.8798132
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   Hoang TN, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971521
   Holstein K, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P257, DOI 10.1145/3027385.3027451
   Hoppe Adrian H., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432950
   ISHII H, 1994, COMMUN ACM, V37, P83, DOI 10.1145/179606.179687
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Johnson JanetG., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, P1
   Jones Brennan, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449133
   Kasahara S, 2017, IEEE T VIS COMPUT GR, V23, P1222, DOI 10.1109/TVCG.2016.2642947
   Kenoui M., 2020, 2020 4 INT S INFORMA, P1
   Kervegant C, 2021, ISS '21 COMPANION: COMPANION PROCEEDINGS OF THE 2021 CONFERENCE ON INTERACTIVE SURFACES AND SPACES SPONSORED, P8, DOI 10.1145/3447932.3490520
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim S, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.053491733
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Kolkmeier J, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281542
   Komiyama Ryohei, 2017, P 8 AUGM HUM INT C S, DOI [10.1145/3041164.3041183, DOI 10.1145/3041164.3041183]
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Lapointe Jean-Francois, 2020, Virtual, Augmented and Mixed Reality. Industrial and Everyday Life Applications. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12191), P111, DOI 10.1007/978-3-030-49698-2_8
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P9, DOI 10.1109/3DCVE.2016.7563559
   Lee G, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P343, DOI [10.1109/VR46266.2020.1581166222244, 10.1109/VR46266.2020.00-50]
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lei Gao, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P629, DOI 10.1145/3441000.3441038
   Lin CY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P212, DOI [10.1109/VR46266.2020.1580934001692, 10.1109/VR46266.2020.00-64]
   Marion TJ, 2021, J PROD INNOVAT MANAG, V38, P192, DOI 10.1111/jpim.12547
   Marques B., 2022, P 2022 INT C ADV VIS, P1
   Marriott Kim, 2018, Immersive Analytics, V11190, DOI DOI 10.1007/978-3-030-01388-2
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Minatani S., 2007, 2007 6 IEEE ACM INT, P14
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.1136/bmj.i4086, 10.1186/2046-4053-4-1, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1371/journal.pmed.1000097]
   Mohr P., 2020, P 2020 CHI C HUMAN F, P1
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Müller J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6481
   Nuernberger B, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P129, DOI 10.1145/2993369.2993371
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Phan H., 2011, COLLABORATION LIT RE
   Pidel C, 2020, LECT NOTES COMPUT SC, V12242, P141, DOI 10.1007/978-3-030-58465-8_10
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Rhee T, 2020, IEEE T VIS COMPUT GR, V26, P1923, DOI 10.1109/TVCG.2020.2973065
   Santos -Torres A., 2022, IEEE ACCESS
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Sousa Mauricio., 2019, The 17th International Conference on Virtual-Reality Continuum and its Applications in Industry, P1
   Speicher Maximilian, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229091
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P85, DOI 10.1145/3196709.3196788
   Sun HL, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010975
   Sun L, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3429285
   Tait M, 2015, COMPUT SUPP COOP W J, V24, P563, DOI 10.1007/s10606-015-9231-8
   Tecchia F., 2012, P 11 ACM SIGGRAPH IN, P323
   Teo T, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364238
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Teo T, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P406, DOI 10.1145/3292147.3292200
   Thanyadit S, 2019, INT SYM MIX AUGMENT, P258, DOI 10.1109/ISMAR.2019.00023
   van der Kleij R, 2009, SMALL GR RES, V40, P355, DOI 10.1177/1046496409333724
   Vaughan N, 2016, COMPUT SCI REV, V22, P65, DOI 10.1016/j.cosrev.2016.09.001
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Wang P, 2020, INTERACT COMPUT, V32, P153, DOI 10.1093/iwcomp/iwaa012
   Whittaker S, 2003, HUM-COMPUT INTERACT, V18, P149, DOI 10.1207/S15327051HCI1812_6
   Wolff R, 2007, INT J COMPUT APPL T, V29, P11, DOI 10.1504/IJCAT.2007.014056
   Yamada S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P727, DOI 10.1109/VR.2018.8446287
   Yamamoto S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P71
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
   Young J, 2019, IEEE T VIS COMPUT GR, V25, P1908, DOI 10.1109/TVCG.2019.2898737
   Yu K, 2021, IEEE T VIS COMPUT GR, V27, P4129, DOI 10.1109/TVCG.2021.3106480
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 96
TC 7
Z9 7
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2291
EP 2303
DI 10.1109/TVCG.2023.3247081
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0KT0
UT WOS:000965708600001
PM 37027742
DA 2024-11-06
ER

PT J
AU Kodama, D
   Mizuho, T
   Hatada, Y
   Narumi, T
   Hirose, M
AF Kodama, Daiki
   Mizuho, Takato
   Hatada, Yuji
   Narumi, Takuji
   Hirose, Michitaka
TI Effects of Collaborative Training Using Virtual Co-embodiment on Motor
   Skill Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Task analysis; Training; Quaternions; Virtual environments;
   Trajectory; Stars; Collaborative training; Virtual co-embodiment; Motor
   skill learning; Sense of agency
ID BODY SCHEMA; ACQUISITION; SENSE; PERFORMANCE; IMAGE; MODEL
AB Virtual reality (VR) is a promising tool for motor skill learning. Previous studies have indicated that observing and following a teacher's movements from a first-person perspective using VR facilitates motor skill learning. Conversely, it has also been pointed out that this learning method makes the learner so strongly aware of the need to follow that it weakens their sense of agency (SoA) for motor skills and prevents them from updating the body schema, thereby preventing long-term retention of motor skills. To address this problem, we propose applying "virtual co-embodiment" to motor skill learning. Virtual co-embodiment is a system in which a virtual avatar is controlled based on the weighted average of the movements of multiple entities. Because users in virtual co-embodiment overestimate their SoA, we hypothesized that learning using virtual co-embodiment with a teacher would improve motor skill retention. In this study, we focused on learning a dual task to evaluate the automation of movement, which is considered an essential element of motor skills. As a result, learning in virtual co-embodiment with the teacher improves motor skill learning efficiency compared with sharing the teacher's first-person perspective or learning alone.
C1 [Kodama, Daiki; Mizuho, Takato; Hatada, Yuji; Narumi, Takuji; Hirose, Michitaka] Univ Tokyo, Tokyo 1138654, Japan.
C3 University of Tokyo
RP Kodama, D (corresponding author), Univ Tokyo, Tokyo 1138654, Japan.
EM d_kodama@cyber.t.u-tokyo.ac.jp; takato@cyber.t.u-tokyo.ac.jp;
   hatada@cyber.t.u-tokyo.ac.jp; narumi@cyber.t.u-tokyo.ac.jp;
   hirose@cyber.t.u-tokyo.ac.jp
RI ; Narumi, Takuji/K-3925-2014
OI Kodama, Daiki/0000-0002-0779-4881; Mizuho, Takato/0000-0002-9821-8889;
   Hatada, Yuji/0000-0002-1202-8559; Narumi, Takuji/0000-0002-9010-1491
FU JST Moonshot Research & Development Program [19H05661];  [JPMJMS2013];
   Grants-in-Aid for Scientific Research [22KJ0940] Funding Source: KAKEN
FX This work was partially supported by Grant-in-Aid for Scientific
   Research (S) (19H05661) and JST Moonshot Research & Development Program
   (JPMJMS2013).
CR ALLPORT DA, 1972, Q J EXP PSYCHOL, V24, P225, DOI 10.1080/00335557243000102
   ANDERSON JR, 1982, PSYCHOL REV, V89, P369, DOI 10.1037/0033-295X.89.4.369
   Atmaca S, 2011, EXP BRAIN RES, V211, P371, DOI 10.1007/s00221-011-2709-9
   Bartel AP, 1998, J LABOR ECON, V16, P718, DOI 10.1086/209904
   Bjork I T, 1997, Nurs Inq, V4, P184
   Braun N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00535
   Burton A. W., 1998, HUMAN KINETICS, V9
   Cardinali L, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00272
   Cardinali L, 2009, BRAIN TOPOGR, V21, P252, DOI 10.1007/s10548-009-0092-7
   Carruthers G, 2012, CONSCIOUS COGN, V21, P30, DOI 10.1016/j.concog.2010.08.005
   Cauraugh JH, 1999, AM J SURG, V177, P331, DOI 10.1016/S0002-9610(99)00057-4
   D'Angelo M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32238-z
   de Vignemont F, 2010, NEUROPSYCHOLOGIA, V48, P669, DOI 10.1016/j.neuropsychologia.2009.09.022
   Desmurget M, 2009, TRENDS COGN SCI, V13, P411, DOI 10.1016/j.tics.2009.08.001
   Dumais S. T., 1981, COGNITIVE SKILLS THE, P2
   Ewolds HE, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02241
   Fitts PM., 1967, Human performance
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Gabbett T, 2011, J SPORT SCI, V29, P7, DOI 10.1080/02640414.2010.514280
   Gabbett TJ, 2012, J SPORT SCI, V30, P1735, DOI 10.1080/02640414.2012.713979
   GALLAGHER S, 1986, J MIND BEHAV, V7, P541
   Gallotti M, 2013, TRENDS COGN SCI, V17, P160, DOI 10.1016/j.tics.2013.02.002
   Ganesh G, 2014, Sci Rep, V4, P3824, DOI 10.1038/srep03824
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Hagiwara T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101732
   Hagiwara T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P954, DOI [10.1109/vr.2019.8798222, 10.1109/VR.2019.8798222]
   Handford C, 1997, J SPORT SCI, V15, P621, DOI 10.1080/026404197367056
   Hapuarachchi H., 2022, KNOWING INTENTION LI, DOI [10.1038/s41598-022-15932-x2, DOI 10.1038/S41598-022-15932-X2]
   Hapuarachchi H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P793, DOI 10.1109/VRW55335.2022.00252
   HAYES NA, 1988, COGNITION, V28, P249, DOI 10.1016/0010-0277(88)90015-7
   Higgins J, 2021, REV PHILOS PSYCHOL, V12, P803, DOI 10.1007/s13164-020-00509-2
   Hikosaka O, 2002, EXP BRAIN RES, V147, P494, DOI 10.1007/s00221-002-1258-7
   Hiyama A., 2011, P 24 ANN ACM S ADJ U, P81, DOI 10.1145/2046396.2046433
   Iriki A, 1996, NEUROREPORT, V7, P2325
   Ito M, 2000, BRAIN RES, V886, P237, DOI 10.1016/S0006-8993(00)03142-5
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Jung JK, 2018, COMPUT ANIMAT VIRT W, V29, DOI 10.1002/cav.1812
   Kager S, 2019, INT C REHAB ROBOT, P824, DOI [10.1109/ICORR.2019.8779485, 10.1109/icorr.2019.8779485]
   Kal E, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203591
   KAWATO M, 1987, BIOL CYBERN, V57, P169, DOI 10.1007/BF00364149
   KEATING JG, 1995, J NEUROPHYSIOL, V73, P1329, DOI 10.1152/jn.1995.73.4.1329
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   KLAPP ST, 1985, J EXP PSYCHOL HUMAN, V11, P814, DOI 10.1037/0096-1523.11.6.814
   Kodama D, 2022, INT SYM MIX AUGMENT, P278, DOI 10.1109/ISMAR55827.2022.00043
   Kojima T, 2014, LECT NOTES COMPUT SC, V8522, P51, DOI 10.1007/978-3-319-07863-2_6
   Latash ML, 2002, EXERC SPORT SCI REV, V30, P26, DOI 10.1097/00003677-200201000-00006
   Lefcourt H. M., 1991, LOCUS OF CONTROL, P9
   Llorensa R, 2017, NEUROPSYCHOLOGIA, V96, P61, DOI 10.1016/j.neuropsychologia.2017.01.007
   Maravita A, 2004, TRENDS COGN SCI, V8, P79, DOI 10.1016/j.tics.2003.12.008
   Mireles EJA, 2017, IEEE T NEUR SYS REH, V25, P832, DOI 10.1109/TNSRE.2017.2700839
   Mireles EJA, 2016, IEEE ENG MED BIO, P2149, DOI 10.1109/EMBC.2016.7591154
   O'Shea H, 2019, J MOTOR BEHAV, V51, P371, DOI 10.1080/00222895.2018.1485010
   Parmar PN, 2015, EXP BRAIN RES, V233, P1, DOI 10.1007/s00221-014-4034-6
   PASHLER H, 1994, PSYCHOL BULL, V116, P220, DOI 10.1037/0033-2909.116.2.220
   Poeck K, 1971, Cortex, V7, P254
   Reed C. L., 2002, WHAT IS BODY SCHEMA, DOI [10.1017/CBO9780511489969.0142, DOI 10.1017/CBO9780511489969.0142]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salembier P., 2005, P HCI INT C JULY, P2
   Schneider W., 1983, Memory and control of action, P119, DOI DOI 10.1016/S0166-4115(08)61989-5
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Sebanz N, 2003, COGNITION, V88, pB11, DOI 10.1016/S0010-0277(03)00043-X
   SHUELL TJ, 1990, REV EDUC RES, V60, P531, DOI 10.3102/00346543060004531
   Tombu M, 2003, J EXP PSYCHOL HUMAN, V29, P3, DOI 10.1037/0096-1523.29.1.3
   Wen W, 2017, CONSCIOUS COGN, V53, P89, DOI 10.1016/j.concog.2017.06.008
   Wen W, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125226
   Willingham DB, 1998, PSYCHOL REV, V105, P558, DOI 10.1037/0033-295X.105.3.558
   Wulf G, 2010, MED EDUC, V44, P75, DOI 10.1111/j.1365-2923.2009.03421.x
   Yang U., 1999, P INT C VIRT SYST MU, P435
   Yang UY, 2002, PRESENCE-VIRTUAL AUG, V11, P304, DOI 10.1162/105474602317473240
   Yun K, 2012, SCI REP-UK, V2, DOI 10.1038/srep00959
NR 70
TC 13
Z9 13
U1 4
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2304
EP 2314
DI 10.1109/TVCG.2023.3247112
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1AN5
UT WOS:000966120100001
PM 37027734
OA hybrid
DA 2024-11-06
ER

PT J
AU Dong, TY
   Gao, TQ
   Dong, YY
   Wang, LM
   Hu, KF
   Fan, J
AF Dong, Tianyang
   Gao, Tieqi
   Dong, Yinyan
   Wang, Liming
   Hu, Kefan
   Fan, Jing
TI FREE-RDW: A Multi-user Redirected Walking Method for Supporting
   Non-forward Steps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Prediction algorithms; Collision avoidance;
   Distortion; Optimized production technology; Gain measurement; Force;
   Virtual reality; redirected walking; Index Terms; multiple users;
   non-forward steps; collision avoidance
ID VIRTUAL-REALITY; ENVIRONMENTS; LOCOMOTION
AB Multi-user redirected walking (RDW) is widely used in large-scale virtual scenes because it allows more users to move synchronously in both virtual and physical environments. To ensure the freedom of virtual roaming, which can be used in various situations, some redirected algorithms have been dedicated to non-forward movements, such as vertical movement and jumping. However, the existing RDW methods still mainly focus on forward steps, ignoring sideward and backward steps, which are also common and necessary in virtual reality. RDW algorithms for non-forward steps can enrich the movement direction of users' virtual roaming and improve the realism of VR roaming. In addition, the non-forward motions have a larger curvature gain, which can be used to better reduce resets in RDW. Therefore, this paper presents a new method of multi-user redirected walking for supporting non-forward steps (FREE-RDW), which adds the options of sideward and backward steps to extend the VR locomotion. Our method adopts a user collision avoidance strategy based on optimal reciprocal collision avoidance (ORCA) and optimizes it into a linear programming problem to obtain the optimal velocity for users. Furthermore, our method uses APF to expose the user to repulsive forces from other users and walls, thus further reducing potential collisions and improving the utilization of physical space. The experiments show that our method performs well in virtual scenes with forward and non-forward steps. In addition, our method can significantly reduce the number of resets compared with reactive RDW algorithms such as DDB-RDW and APF-RDW in multi-user forward-step virtual scenes.
C1 [Dong, Tianyang; Gao, Tieqi; Dong, Yinyan; Wang, Liming; Hu, Kefan; Fan, Jing] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
C3 Zhejiang University of Technology
RP Fan, J (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
EM phylioras@foxmail.com; fanjing@zjut.edu.cn
RI fan, jing/KHX-6210-2024
FU National Natural Science Foundation of China [62072405]; Zhejiang
   Provincial Natural Science Foundation of China [LGF20F020017]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 62072405 and the Zhejiang Provincial Natural
   Science Foundation of China under Grant No. LGF20F020017.
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bremer G, 2021, 2021 4TH IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2021), P19, DOI 10.1109/AIVR52153.2021.00013
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Dong TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P894, DOI [10.1109/vr.2019.8798319, 10.1109/VR.2019.8798319]
   Ehrlich JA, 1997, P SOC PHOTO-OPT INS, V3206, P170, DOI 10.1117/12.295582
   Fiorini P, 1998, INT J ROBOT RES, V17, P760, DOI 10.1177/027836499801700706
   Grechkin T., 2016, ACM S APPL PERC, P113
   Hakkinen J., 2002, IEEE International Conference on Systems, Man and Cybernetics, V4, P147, DOI [DOI 10.1109/ICSMC.2002.1167964, 10.1109/ICSMC.2002.1167964]
   Hayashi D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P386, DOI [10.1109/VR.2019.8797989, 10.1109/vr.2019.8797989]
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hoshikawa Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P464, DOI 10.1109/VR51125.2022.00066
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP02012, 10.1207/s15327108ijap02012]
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P1379, DOI 10.1109/TVCG.2017.2657139
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Langbehn E, 2018, P IEEE WORKSH EV VIR
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Marwecki S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173815
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   Mehlitz M.A., 2004, THESIS GEORG AUGUST
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Mizutani J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1090, DOI [10.1109/VR.2019.8797976, 10.1109/vr.2019.8797976]
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Razzaque Sharif, 2005, THESIS
   Razzaque Sharif, 2001, Redirected Walking, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Schmidt D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2157, DOI 10.1145/2702123.2702253
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Stein N, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P493, DOI 10.1109/VR51125.2022.00069
   Steinicke F., 2008, Proc. Virtual Reality International Conference (VRIC), P15
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Takala TM, 2014, 2014 IEEE VIRTUAL REALITY (VR), P157, DOI 10.1109/VR.2014.6802099
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Williams N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1229, DOI [10.1109/VR.2019.8798117, 10.1109/vr.2019.8798117]
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
NR 52
TC 1
Z9 1
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2315
EP 2325
DI 10.1109/TVCG.2023.3247107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1QR3
UT WOS:000966541300001
PM 37027710
DA 2024-11-06
ER

PT J
AU Kourtesis, P
   Amir, R
   Linnell, J
   Argelaguet, F
   MacPherson, SE
AF Kourtesis, Panagiotis
   Amir, Rayaan
   Linnell, Josie
   Argelaguet, Ferran
   MacPherson, Sarah E. E.
TI Cybersickness, Cognition, & Motor Skills: The Effects of Music, Gender,
   and Gaming Experience
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cybersickness; Motion sickness; Cognition; Task analysis; Pupils;
   Visualization; Tracking; virtual reality; mitigation; cognition;
   reaction time; reading; eye-tracking; gender; gaming experience
ID MOTION SICKNESS; VIRTUAL-REALITY; WORKING-MEMORY; EXPOSURE; THERAPY
AB Recent research has attempted to identify methods to mitigate cybersickness and examine its aftereffects. In this direction, this paper examines the effects of cybersickness on cognitive, motor, and reading performance in VR. Also, this paper evaluates the mitigating effects of music on cybersickness, as well as the role of gender, and the computing, VR, and gaming experience of the user. This paper reports two studies. In the 1st study, 92 participants selected the music tracks considered most calming (low valence) or joyful (high valence) to be used in the 2nd study. In the 2nd study, 39 participants performed an assessment four times, once before the rides (baseline), and then once after each ride (3 rides). In each ride either Calming, or Joyful, or No Music was played. During each ride, linear and angular accelerations took place to induce cybersickness in the participants. In each assessment, while immersed in VR, the participants evaluated their cybersickness symptomatology and performed a verbal working memory task, a visuospatial working memory task, and a psychomotor task. While responding to the cybersickness questionnaire (3D UI), eye-tracking was conducted to measure reading time and pupillometry. The results showed that Joyful and Calming music substantially decreased the intensity of nausea-related symptoms. However, only Joyful music significantly decreased the overall cybersickness intensity. Importantly, cybersickness was found to decrease verbal working memory performance and pupil size. Also, it significantly decelerated psychomotor (reaction time) and reading abilities. Higher gaming experience was associated with lower cybersickness. When controlling for gaming experience, there were no significant differences between female and male participants in terms of cybersickness. The outcomes indicated the efficiency of music in mitigating cybersickness, the important role of gaming experience in cybersickness, and the significant effects of cybersickness on pupil size, cognition, psychomotor skills, and reading ability.
C1 [Kourtesis, Panagiotis; Argelaguet, Ferran] Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
   [Amir, Rayaan; Linnell, Josie; MacPherson, Sarah E. E.] Univ Edinburgh, Dept Psychol, Edinburgh EH8 9YL, Scotland.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Inria; University of Edinburgh
RP Kourtesis, P (corresponding author), Univ Rennes, INRIA, IRISA, CNRS, F-35042 Rennes, France.
EM Panagiotis.Kourtesis@inria.fr; Rayaan.Amir@ed.ac.uk;
   Josie.Linnell@ed.ac.uk; Ferran.Argelaguet@inria.fr;
   Sarah.E.MacPherson@ed.ac.uk
RI MacPherson, Sarah/G-8524-2013; Kourtesis, Panagiotis/ABA-9356-2020
OI Kourtesis, Panagiotis/0000-0002-2914-1064; MacPherson, Sarah
   E./0000-0001-8676-6514
CR [Anonymous], 1972, HUMAN MEMORY MEDIAL
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Bebko AO, 2020, I-PERCEPTION, V11, DOI 10.1177/2041669520938400
   Bernardi NF, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00785
   Chattha UA, 2020, IEEE ACCESS, V8, P130486, DOI 10.1109/ACCESS.2020.3007076
   Cheung B, 2005, AVIAT SPACE ENVIR MD, V76, P1099
   Cowan N, 2014, EDUC PSYCHOL REV, V26, P197, DOI 10.1007/s10648-013-9246-y
   Cruz-Neira M., 2018, MULTIMODAL TECHNOLOG, V2, DOI [10.3390/mti20100081[9]J., DOI 10.3390/MTI20100081[9]J]
   Dahlman J, 2009, HUM FACTORS, V51, P56, DOI 10.1177/0018720809332848
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Deary IJ, 2011, BEHAV RES METHODS, V43, P258, DOI 10.3758/s13428-010-0024-1
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   DIXON P, 1988, J EDUC PSYCHOL, V80, P465, DOI 10.1037/0022-0663.80.4.465
   Emmelkamp PMG, 2021, ANNU REV CLIN PSYCHO, V17, P495, DOI 10.1146/annurev-clinpsy-081219-115923
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Freedman D, 1997, ADV APPL MATH, V18, P59, DOI 10.1006/aama.1996.0501
   Golding JF, 2006, PERS INDIV DIFFER, V41, P237, DOI 10.1016/j.paid.2006.01.012
   Golding JF, 2015, CURR OPIN NEUROL, V28, P83, DOI 10.1097/WCO.0000000000000163
   Graff V, 2019, REGION ANESTH PAIN M, V44, P796, DOI 10.1136/rapm-2018-100251
   Grassini S, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5030007
   Himmels C, 2022, ADJUNCT PROCEEDINGS OF THE 14TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, AUTOMOTIVEUI 2022 ADJUNCT, P149, DOI 10.1145/3544999.3552532
   Karagozoglu S, 2013, J CLIN NURS, V22, P39, DOI 10.1111/jocn.12030
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Kim S., 2021, FRONT VIRTUAL REAL, V2, DOI [10.3389/frvir.2021.5821561[25]P, DOI 10.3389/FRVIR.2021.582156]
   Kourtesis P., 2023, VIRTUAL WORLDS, V2, P16, DOI [DOI 10.3390/VIRTUALWORLDS2010002, 10.3390/virtualworlds2010002]
   Kourtesis P, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100151
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Kourtesis P, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00417
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lenth R., 2018, Emmeans: Estimated Marginal Means, Aka Least-Squares Means
   Melo M, 2018, COMPUT GRAPH-UK, V71, P159, DOI 10.1016/j.cag.2017.11.007
   Mittelstaedt JM, 2019, VIRTUAL REAL-LONDON, V23, P143, DOI 10.1007/s10055-018-0370-3
   Nalivaiko E, 2015, PHYSIOL BEHAV, V151, P583, DOI 10.1016/j.physbeh.2015.08.043
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Partala T, 2003, INT J HUM-COMPUT ST, V59, P185, DOI 10.1016/S1071-5819(03)00017-X
   Peck K, 2020, EXP BRAIN RES, V238, P2347, DOI 10.1007/s00221-020-05871-2
   Peterson RA, 2020, J APPL STAT, V47, P2312, DOI 10.1080/02664763.2019.1630372
   Petri K., 2020, Amer. J. Biomed. Sci., V12, P107, DOI [10.5099/aj200200107, DOI 10.5099/AJ200200107]
   R Core Team, 2022, R LANG ENV STAT COMP, P6
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rebenitsch L, 2021, VIRTUAL REAL-LONDON, V25, P165, DOI 10.1007/s10055-020-00446-6
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Sang FDYP, 2003, J TRAVEL MED, V10, P108, DOI 10.2310/7060.2003.31768
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Singmann H., 2021, afex: Analysis of factorial experiments Computer software
   Smith SR, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P3, DOI 10.1109/3DUI.2009.4811198
   Somrak A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041185
   Stanglmeier MJ, 2020, APPL ERGON, V86, DOI 10.1016/j.apergo.2020.103103
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stanney KM, 2003, HUM FACTORS, V45, P504, DOI 10.1518/hfes.45.3.504.27254
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Tso ITH, 2022, PERCEPT MOTOR SKILL, V129, P120, DOI 10.1177/00315125211050629
   Varmaghani S, 2022, VIRTUAL REAL-LONDON, V26, P659, DOI 10.1007/s10055-021-00535-0
   Wechsler D, 1939, WECHSLER BELLEVUE AD, P5
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Wickham H., 2016, GGPLOT2 ELEGANT GRAP, P6
   WOOD C D, 1988, Clinical Research Practices and Drug Regulatory Affairs, V6, P129, DOI 10.3109/10601338809031990
   Xie H., 2021, FRONTIERS VIRTUAL RE, V2, DOI [10.3389/frvir.2021.6451531\n[1]D, DOI 10.3389/FRVIR.2021.6451531]
NR 62
TC 8
Z9 9
U1 5
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2326
EP 2336
DI 10.1109/TVCG.2023.3247062
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C9RO5
UT WOS:000965209000001
PM 37027703
OA Green Accepted, Green Submitted, Green Published
DA 2024-11-06
ER

PT J
AU Ren, YM
   Zhao, CF
   He, YN
   Cong, PS
   Liang, H
   Yu, JY
   Xu, L
   Ma, YX
AF Ren, Yiming
   Zhao, Chengfeng
   He, Yannan
   Cong, Peishan
   Liang, Han
   Yu, Jingyi
   Xu, Lan
   Ma, Yuexin
TI LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse
   Inertial and LiDAR Sensors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Motion capture; Laser radar; Point cloud compression; Three-dimensional
   displays; Cameras; Trajectory; Optical sensors; Human motion capture;
   shape modeling; virtual reality; sensor fusion
ID VIDEO
AB We propose a multi-sensor fusion method for capturing challenging 3D human motions with accurate consecutive local poses and global trajectories in large-scale scenarios, only using single LiDAR and 4 IMUs, which are set up conveniently and worn lightly. Specifically, to fully utilize the global geometry information captured by LiDAR and local dynamic motions captured by IMUs, we design a two-stage pose estimator in a coarse-to-fine manner, where point clouds provide the coarse body shape and IMU measurements optimize the local actions. Furthermore, considering the translation deviation caused by the view-dependent partial point cloud, we propose a pose-guided translation corrector. It predicts the offset between captured points and the real root locations, which makes the consecutive movements and trajectories more precise and natural. Moreover, we collect a LiDAR-IMU multi-modal mocap dataset, LIPD, with diverse human actions in long-range scenarios. Extensive quantitative and qualitative experiments on LIPD and other open datasets all demonstrate the capability of our approach for compelling motion capture in large-scale scenarios, which outperforms other methods by an obvious margin. We will release our code and captured dataset to stimulate future research.
C1 [Ren, Yiming; Zhao, Chengfeng; He, Yannan; Cong, Peishan; Liang, Han; Yu, Jingyi; Xu, Lan; Ma, Yuexin] ShanghaiTech Univ, Shanghai, Peoples R China.
   [Yu, Jingyi] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
C3 ShanghaiTech University
RP Xu, L (corresponding author), ShanghaiTech Univ, Shanghai, Peoples R China.
EM renym2022@shanghaitech.edu.cn; zhaochf2022@shanghaitech.edu.cn;
   heyn@shanghaitech.edu.cn; congpsh@shanghaitech.edu.cn;
   lianghan@shanghaitech.edu.cn; yujingyi@shanghaitech.edu.cn;
   xulan1@shanghaitech.edu.cn; mayuexin@shanghaitech.edu.cn
RI Cong, Peishan/JED-3079-2023; zhang, quan/KHY-9180-2024
OI Zhao, Chengfeng/0000-0002-8649-7470
FU NSFC [62206173]; Shanghai Sailing Program [22YF1428700]; Shanghai
   Frontiers Science Center of Human-centered Artificial Intelligence
   (ShangHAI)
FX This work was supported by NSFC (No.62206173), Shanghai Sailing Program
   (No.22YF1428700), and Shanghai Frontiers Science Center of
   Human-centered Artificial Intelligence (ShangHAI).
CR Amin S, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.45
   Andrilli S., 2016, P 13 EUR C VIS MED P, P1
   [Anonymous], 2019, RS LIDAR M1 LEADING
   [Anonymous], 2021, OUSTER HIGH PERF DIG
   [Anonymous], 2010, Vicon Motion Capture Systems
   [Anonymous], 2015, NOIT MOT CAPT SYST
   [Anonymous], 2009, OPTITRACK MOT CAPT S
   Baak A, 2011, IEEE I CONF COMP VIS, P1092, DOI 10.1109/ICCV.2011.6126356
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Cong P., 2022, P IEEECVF C COMPUTER, P19608
   Dai Y, 2022, P IEEE CVF C COMP VI, P6792
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Elhayek A, 2015, PROC CVPR IEEE, P3810, DOI 10.1109/CVPR.2015.7299005
   Gilbert A, 2019, INT J COMPUT VISION, V127, P381, DOI 10.1007/s11263-018-1118-y
   Guo KW, 2018, INT CONF 3D VISION, P596, DOI 10.1109/3DV.2018.00074
   Habermann M, 2020, PROC CVPR IEEE, P5051, DOI 10.1109/CVPR42600.2020.00510
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   He YN, 2021, PROC CVPR IEEE, P11395, DOI 10.1109/CVPR46437.2021.01124
   Helten T, 2013, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2013.141
   Holte MB, 2012, IEEE J-STSP, V6, P538, DOI 10.1109/JSTSP.2012.2196975
   Huang YH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275108
   Huang YH, 2017, INT CONF 3D VISION, P421, DOI 10.1109/3DV.2017.00055
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang JX, 2022, LECT NOTES COMPUT SC, V13665, P443, DOI 10.1007/978-3-031-20065-6_26
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kaichi T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195453
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kim W, 2019, IEEE ROBOT AUTOM LET, V4, P1940, DOI 10.1109/LRA.2019.2896705
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kocabas Muhammed, 2021, PROC INT C COMPUTER, P11127
   Kolotouros N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11585, DOI 10.1109/ICCV48922.2021.01140
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Li Ruilong, 2021, P IEEE CVF INT C COM, P13401
   Liang H, 2023, Arxiv, DOI arXiv:2203.09287
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Loshchilov I, 2019, Arxiv, DOI [arXiv:1711.05101, DOI 10.48550/ARXIV.1711.05101, 10.48550/arXiv.1711.05101]
   Luo Zhengyi, 2021, Advances in Neural Information Processing Systems, V34
   Ma Y, 2022, P IEEECVF C COMPUTER, P20502
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Malleson C, 2020, INT J COMPUT VISION, V128, P1594, DOI 10.1007/s11263-019-01270-5
   Malleson C, 2017, INT CONF 3D VISION, P449, DOI 10.1109/3DV.2017.00058
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Patil AK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185342
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pons-Moll G, 2010, PROC CVPR IEEE, P663, DOI 10.1109/CVPR.2010.5540153
   Qi Charles R, P IEEE C COMPUTER VI, P652
   Rempe D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11468, DOI 10.1109/ICCV48922.2021.01129
   Rhodin H, 2015, IEEE I CONF COMP VIS, P765, DOI 10.1109/ICCV.2015.94
   Robertini N, 2016, INT CONF 3D VISION, P166, DOI 10.1109/3DV.2016.25
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338
   Theobalt C, 2010, GEOM COMPUT, V5, P127, DOI 10.1007/978-3-642-12392-4_6
   Trumble M., 2017, P BRIT MACH VIS C, P1, DOI 10.5244/C.31.14
   Vlasic D, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276421
   von Marcard T, 2017, COMPUT GRAPH FORUM, V36, P349, DOI 10.1111/cgf.13131
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   von Marcard T, 2016, IEEE T PATTERN ANAL, V38, P1533, DOI 10.1109/TPAMI.2016.2522398
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Winkler A., 2022, SIGGRAPH ASIA 2022 C, P1
   Xinge Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P581, DOI 10.1007/978-3-030-58595-2_35
   Xsens Technologies B.V, 2011, US
   Xu L, 2020, PROC CVPR IEEE, P4967, DOI 10.1109/CVPR42600.2020.00502
   Xu L, 2020, IEEE T PATTERN ANAL, V42, P2508, DOI 10.1109/TPAMI.2019.2915229
   Xu L, 2018, IEEE T VIS COMPUT GR, V24, P2284, DOI 10.1109/TVCG.2017.2728660
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yi XY, 2022, PROC CVPR IEEE, P13157, DOI 10.1109/CVPR52688.2022.01282
   Yi XY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459786
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Yuan Y., 2020, Advances in Neural Information Processing Systems, V33, P21763, DOI 10.48550/arXiv.2006.07364
   Zanfir A, 2021, PROC CVPR IEEE, P14479, DOI 10.1109/CVPR46437.2021.01425
   Zhang Z, 2020, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR42600.2020.00227
   Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
   Zhu XG, 2022, IEEE T PATTERN ANAL, V44, P6807, DOI 10.1109/TPAMI.2021.3098789
   Ziegler J, 2011, IEEE INT C INT ROBOT, P86, DOI 10.1109/IROS.2011.6048040
NR 82
TC 9
Z9 9
U1 10
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2337
EP 2347
DI 10.1109/TVCG.2023.3247088
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2GP9
UT WOS:000966961100001
PM 37027736
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bhargava, A
   Venkatakrishnan, R
   Venkatakrishnan, R
   Lucaites, K
   Solini, H
   Robb, AC
   Pagano, CC
   Babu, SV
AF Bhargava, Ayush
   Venkatakrishnan, Rohith
   Venkatakrishnan, Roshan
   Lucaites, Kathryn
   Solini, Hannah
   Robb, Andrew C. C.
   Pagano, Christopher C. C.
   Babu, Sabarish V. V.
TI Can I Squeeze Through? Effects of Self-Avatars and Calibration in a
   Person-Plus-Virtual-Object System on Perceived Lateral Passability in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Affordances; Apertures; Calibration; Visualization; Training; Task
   analysis; Propioception; Affordance; Passability; Self-Avatar; Virtual
   Reality
ID DISTANCE PERCEPTION; AFFORDANCES; ENVIRONMENTS
AB With the popularity of Virtual Reality (VR) on the rise, creators from a variety of fields are building increasingly complex experiences that allow users to express themselves more naturally. Self-avatars and object interaction in virtual worlds are at the heart of these experiences. However, these give rise to several perception based challenges that have been the focus of research in recent years. One area that garners most interest is understanding the effects of self-avatars and object interaction on action capabilities or affordances in VR. Affordances have been shown to be influenced by the anthropometric and anthropomorphic properties of the self-avatar embodied. However, self-avatars cannot fully represent real world interaction and fail to provide information about the dynamic properties of surfaces in the environment. For example, pressing against a board to feel its rigidity. This lack of accurate dynamic information can be further amplified when interacting with virtual handheld objects as the weight and inertial feedback associated with them is often mismatched. To investigate this phenomenon, we looked at how the absence of dynamic surface properties affect lateral passability judgments when carrying virtual handheld objects in the presence or absence of gender matched body-scaled self-avatars. Results suggest that participants can calibrate to the missing dynamic information in the presence of self-avatars to make lateral passability judgments, but rely on their internal body schema of a compressed physical body depth in the absence of self-avatars.
C1 [Bhargava, Ayush; Venkatakrishnan, Rohith; Venkatakrishnan, Roshan; Robb, Andrew C. C.; Babu, Sabarish V. V.] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
   [Lucaites, Kathryn; Solini, Hannah; Pagano, Christopher C. C.] Clemson Univ, Dept Psychol, Clemson, SC USA.
C3 Clemson University; Clemson University
RP Bhargava, A (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM ayush.bhargava92@gmail.com; rohithv@g.clemson.edu;
   rvenkat@g.clemson.edu; arobb@clemson.edu; cpagano@clemson.edu;
   sbabu@clemson.edu
RI Bhargava, Ayush/AAJ-2387-2021; Venkatakrishnan, Rohith/JCE-8736-2023;
   Venkatakrishnan, Roshan/JDC-3508-2023
OI Robb, Andrew/0000-0002-0398-5576; Pagano,
   Christopher/0000-0002-0110-2055; Venkatakrishnan,
   Roshan/0000-0002-6538-627X; Bhargava, Ayush/0000-0001-8957-1317; Babu,
   Sabarish/0000-0002-8348-0534; Venkatakrishnan,
   Rohith/0000-0002-8484-3915
FU Clemson University Dissertation Completion Grant; CECAS TIGER seed grant
   programs
FX This work was partly supported by the Clemson University Dissertation
   Completion Grant and CECAS TIGER seed grant programs. We would also like
   to thank all our participants for their time.
CR Adolph K.E., 2009, LEARNING INFANT MIND, P172, DOI DOI 10.1093/ACPROF:OSO/9780195301151.003.0007
   [Anonymous], 2012, P ACM S APPL PERCEPT
   [Anonymous], 2018, Proceedings of the 15th ACM Symposium on Applied Perception, page
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Berti A, 2000, J COGNITIVE NEUROSCI, V12, P415, DOI 10.1162/089892900562237
   Bhargava A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P519, DOI [10.1109/VR46266.2020.1581293987781, 10.1109/VR46266.2020.00-31]
   Bhargava K. M., 2020, VIRTUAL REAL-LONDON, P1
   Bhargava R., 2021, IEEE T VIS COMPUT GR
   Bingham GP, 1998, J EXP PSYCHOL HUMAN, V24, P145, DOI 10.1037/0096-1523.24.1.145
   Blau J. B., 2022, TAYLOR AND FRANCIS, V1, P2
   Buck LE, 2019, IEEE T VIS COMPUT GR, V25, P2123, DOI 10.1109/TVCG.2019.2899232
   Cohen S. G., 2014, APPL MULTIPLE REGRES, V5
   Comalli D, 2013, EXP BRAIN RES, V228, P183, DOI 10.1007/s00221-013-3550-0
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Day B, 2017, ACTA PSYCHOL, V181, P27, DOI 10.1016/j.actpsy.2017.09.014
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Fajen BR, 2007, ECOL PSYCHOL, V19, P383, DOI 10.1080/10407410701557877
   Franchak J, 2014, ECOL PSYCHOL, V26, P109, DOI 10.1080/10407413.2014.874923
   Franchak JM, 2020, Q J EXP PSYCHOL, V73, P1311, DOI 10.1177/1747021820926884
   Franchak JM, 2017, ATTEN PERCEPT PSYCHO, V79, P1816, DOI 10.3758/s13414-017-1339-0
   Franchak JM, 2014, ATTEN PERCEPT PSYCHO, V76, P460, DOI 10.3758/s13414-013-0578-y
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI 10.1145/1836248.1836259
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Hackney AL, 2014, J MOTOR BEHAV, V46, P319, DOI 10.1080/00222895.2014.913002
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   Ishak S, 2008, J EXP PSYCHOL HUMAN, V34, P1501, DOI 10.1037/a0011393
   Joh AS, 2006, PERCEPT PSYCHOPHYS, V68, P339, DOI 10.3758/BF03193681
   Joh AS, 2006, CHILD DEV, V77, P89, DOI 10.1111/j.1467-8624.2006.00858.x
   Jun E, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2811266
   Kim Jangyoon, 2017, P 27 INT C ART REAL, P153
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   LIN Q., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P7
   LIN Q., 2013, P ACM S APPL PERCEPT, P107, DOI DOI 10.1145/2492494.2492511
   Lin QF, 2015, ACM T APPL PERCEPT, V12, DOI 10.1145/2720020
   Lin Qiufeng., 2011, P ACM SIGGRAPH S APP, P75
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Lok B, 2003, P IEEE VIRT REAL ANN, P125, DOI 10.1109/VR.2003.1191130
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Lucaites H., 2021, 2021 IEEE VIRTUAL RE, P1
   Lucaites R., 2020, ECOL PSYCHOL, P1
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Mine D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232290
   Pagano C C., 2019, Perception as Information Detection, P37
   PAGANO CC, 1992, PERCEPT PSYCHOPHYS, V52, P617, DOI 10.3758/BF03211699
   Pagano CC, 2021, TECHNOL ARCHIT DES, V5, P31, DOI 10.1080/24751448.2021.1863665
   Peng CYJ, 2002, J EDUC RES, V96, P3, DOI 10.1080/00220670209598786
   Petrucci MN, 2016, ECOL PSYCHOL, V28, P108, DOI 10.1080/10407413.2016.1163987
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Stefanucci JK, 2015, J EXP PSYCHOL-APPL, V21, P215, DOI 10.1037/xap0000051
   Stefanucci JK, 2009, PERCEPTION, V38, P1782, DOI 10.1068/p6437
   Stevens S. S., 2017, PSYCHOPHYSICS INTRO, P6
   Tom S., 2000, MULTILEVEL ANAL INTR, P6
   Wagman JB, 2005, ECOL PSYCHOL, V17, P105, DOI 10.1207/s15326969eco1702_3
   Warren W. H., 2005, PHILOS TOPICS, V33, P355
   Warren WH, 2006, PSYCHOL REV, V113, P358, DOI 10.1037/0033-295X.113.2.358
   WARREN WH, 1987, J EXP PSYCHOL HUMAN, V13, P371, DOI 10.1037/0096-1523.13.3.371
   Watson G, 2011, HUM MOVEMENT SCI, V30, P942, DOI 10.1016/j.humov.2010.08.004
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 61
TC 3
Z9 5
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2348
EP 2357
DI 10.1109/TVCG.2023.3247067
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2NZ6
UT WOS:000967154500001
PM 37027739
DA 2024-11-06
ER

PT J
AU Mal, D
   Wolf, E
   Dollinger, N
   Wienrich, C
   Latoschik, ME
AF Mal, David
   Wolf, Erik
   Dollinger, Nina
   Wienrich, Carolin
   Latoschik, Marc Erich
TI The Impact of Avatar and Environment Congruence on Plausibility,
   Embodiment, Presence, and the Proteus Effect in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Congruence; Plausibility; Virtual Reality; Avatar; Virtual Human;
   Proteus Effect; Virtual Body Ownership
ID PHYSICAL-ACTIVITY; SELF-REPRESENTATION; OWNERSHIP
AB Many studies show the significance of the Proteus effect for serious virtual reality applications. The present study extends the existing knowledge by considering the relationship (congruence) between the self-embodiment (avatar) and the virtual environment. We investigated the impact of avatar and environment types and their congruence on avatar plausibility, sense of embodiment, spatial presence, and the Proteus effect. In a 2 x 2 between-subjects design, participants embodied either an avatar in sports-or business wear in a semantic congruent or incongruent environment while performing lightweight exercises in virtual reality. The avatar-environment congruence significantly affected the avatar's plausibility but not the sense of embodiment or spatial presence. However, a significant Proteus effect emerged only for participants who reported a high feeling of (virtual) body ownership, indicating that a strong sense of having and owning a virtual body is key to facilitating the Proteus effect. We discuss the results assuming current theories of bottom-up and top-down determinants of the Proteus effect and thus contribute to understanding its underlying mechanisms and determinants.
C1 [Mal, David; Wolf, Erik; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Dollinger, Nina; Wienrich, Carolin] Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Mal, D (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
EM david.mal@uni-wuerzburg.de; erik.wolf@uni-wuerzburg.de;
   nina.doellinger@uni-wuerzburg.de; carolin.wienrich@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
RI Latoschik, Marc/HLG-5348-2023
OI Dollinger, Nina/0000-0002-0609-8841; Mal, David/0000-0002-0254-7275;
   Wienrich, Carolin/0000-0003-3052-7172
FU German Federal Ministry of Education and Research (ViTraS project)
   [16SV8219]; European Union's Horizon 2020 research and innovation
   program, Marie Sklodowska-Curie grant agreement (PriMa project) [860315]
FX We thank Marie Fiedler who is with HCI and PIIS Group, University of
   Wuerzburg. This research has been funded by the German Federal Ministry
   of Education and Research (ViTraS project, 16SV8219) and the European
   Union's Horizon 2020 research and innovation program, Marie
   Sklodowska-Curie grant agreement (PriMa project, 860315).
CR [Anonymous], 2021, clinicaltrial
   Aristidou A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13310
   Baguley T, 2004, APPL ERGON, V35, P73, DOI 10.1016/j.apergo.2004.01.002
   Bailenson J.N., 2004, Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bao Han-Wu-Shuang, 2023, CRAN
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   Dollinger N., 2019, P MUC, P1, DOI DOI 10.18420/MUC2019-WS-633
   Dollinger N., 2022, CHI C HUMAN FACTORS, P7, DOI 10.1145/3491101
   Dollinger Nina, 2022, arXiv, DOI [10.48550/arXiv.2203.05060, DOI 10.48550/ARXIV.2203.05060]
   Emaus A, 2010, SCAND J PUBLIC HEALT, V38, P105, DOI 10.1177/1403494810378919
   Eubanks JC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647896
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fiedler M. L., 2023, 2023 IEEE C VIRTUAL, P1
   Field A., 2013, Discovering statistics using IBM SPSS statistics, V4th ed.
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gonzalez -Franco M., 2020, FRONTIERS VIRTUAL RE, V1, DOI [10.3389/frvir.2020 561558 4, DOI 10.3389/FRVIR.20205615584]
   HTC Corporation, 2021, VIVE TRACK 3 0
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kocur Martin, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P193, DOI 10.1145/3410404.3414261
   Kocur M., 2020, ACM, P1, DOI DOI 10.1145/3385956.3418969
   Kocur M, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565628
   Kocur M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445160
   Latoschik M. E., 2022, FRONT VIRTUAL REAL, DOI [10.3389/frvir.2022.6944331,2,3,9, DOI 10.3389/FRVIR.2022.694433]
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   LimeSurvey GmbH, 2020, LIMESURVEY OP SOURC
   Lin JHT, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.693543
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   Mal D., 2022, 29 IEEE C VIRTUAL RE, DOI [10.1109/VRW55335.2022.002451,2,4, DOI 10.1109/VRW55335.2022.002451,2,4]
   Navarro J, 2022, HEALTH COMMUN, V37, P222, DOI 10.1080/10410236.2020.1834194
   ONolan K., 1960, HERMES-PARIS, V88, P1
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Peck T. C., 2021, FRONT VIRTUAL REAL, V1, DOI [10.3389/frvir.2020.5759439, DOI 10.3389/FRVIR.2020.5759439]
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Peña J, 2014, COMPUT HUM BEHAV, V41, P262, DOI 10.1016/j.chb.2014.09.038
   Peña J, 2016, J COMPUT-MEDIAT COMM, V21, P195, DOI 10.1111/jcc4.12151
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Praetorius A S., 2020, International Conference on the Foundations of Digital Games, P1, DOI [10.1145/3402942.3403019, DOI 10.1145/3402942.3403019]
   Preacher KJ, 2006, J EDUC BEHAV STAT, V31, P437, DOI 10.3102/10769986031004437
   R Core Team, 2020, R: a language and environment for statistical computing
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Reinhard R, 2020, MEDIA PSYCHOL, V23, P293, DOI 10.1080/15213269.2019.1598435
   Rootmotion, 2019, FinalIK
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Stauffert J. -P., 2020, FRONTIERS VIRTUAL RE, V1, DOI 10.3389/frvir.2020.582204 3
   Stauffert JP, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3450379
   Unity Technologies, 2019, ABOUT US
   Valve Corporation, 2022, IND
   Valve Corporation, 2021, ABOUT US
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   WHO Consultation, 2000, WHO TECH REP SER, V894, P1
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Wilcox RR., 2022, Introduction to robust Estimation and Hypothesis Testing, V5th ed
   Wolf E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1031093
   Wolf E, 2022, INT SYM MIX AUGMENT, P489, DOI 10.1109/ISMAR55827.2022.00065
   Wolf E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P350, DOI 10.1109/VR51125.2022.00054
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, MEDIA PSYCHOL, V12, P195, DOI 10.1080/15213260902849943
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
NR 74
TC 16
Z9 16
U1 13
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2358
EP 2368
DI 10.1109/TVCG.2023.3247089
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C9WO7
UT WOS:000965339200001
PM 37027615
OA hybrid
DA 2024-11-06
ER

PT J
AU Ganias, G
   Lougiakis, C
   Katifori, A
   Roussou, M
   Ioannidis, Y
   Ioannidis, IP
AF Ganias, Giorgos
   Lougiakis, Christos
   Katifori, Akrivi
   Roussou, Maria
   Ioannidis, Yannis
   Ioannidis, Ioannis Panagiotis
TI Comparing Different Grasping Visualizations for Object Manipulation in
   VR using Controllers
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Grasping; Visualization; Virtual environments; User experience; Rubber;
   Humanoid robots; Task analysis; Virtual Reality; User studies; Grasping
   Visualization; Controllers; Performance; Sense of Embodiment
ID VIRTUAL-REALITY; EMBODIMENT; OWNERSHIP; BODY
AB Virtual grasping is one of the most common and important interactions performed in a Virtual Environment (VE). Even though there has been substantial research using hand tracking methods exploring different ways of visualizing grasping, there are only a few studies that focus on handheld controllers. This gap in research is particularly crucial, since controllers remain the most used input modality in commercial Virtual Reality (VR). Extending existing research, we designed an experiment comparing three different grasping visualizations when users are interacting with virtual objects in immersive VR using controllers. We examine the following visualizations: the Auto-Pose (AP), where the hand is automatically adjusted to the object upon grasping; the Simple-Pose (SP), where the hand closes fully when selecting the object; and the Disappearing-Hand (DH), where the hand becomes invisible after selecting an object, and turns visible again after positioning it on the target. We recruited 38 participants in order to measure if and how their performance, sense of embodiment, and preference are affected. Our results show that while in terms of performance there is almost no significant difference in any of the visualizations, the perceived sense of embodiment is stronger with the AP, and is generally preferred by the users. Thus, this study incentivizes the inclusion of similar visualizations in relevant future research and VR experiences.
C1 [Ganias, Giorgos; Lougiakis, Christos; Katifori, Akrivi; Roussou, Maria; Ioannidis, Yannis; Ioannidis, Ioannis Panagiotis] Natl & Kapodistrian Univ Athens, Athens, Greece.
   [Katifori, Akrivi; Ioannidis, Yannis] ATHENA Res Ctr, Maroussi, Greece.
C3 National & Kapodistrian University of Athens
RP Ganias, G (corresponding author), Natl & Kapodistrian Univ Athens, Athens, Greece.
EM sdi1500028@di.uoa.gr; chrislou@di.uoa.gr; vivi@di.uoa.gr;
   mroussou@di.uoa.gr; yannis@di.uoa.gr; ioannisio28@gmail.com
RI Ioannidis, Ioannis/LLK-5458-2024
OI Lougiakis, Christos/0000-0003-1841-0756; Ioannidis,
   Yannis/0000-0002-1705-8247; Ganias, Giorgos/0000-0002-1014-2331;
   Roussou, Maria/0000-0002-2826-162X
FU European Union [952043]; H2020 - Industrial Leadership [952043] Funding
   Source: H2020 - Industrial Leadership
FX This research is part of the BRIDGES project, which has received funding
   from the European Union's Horizon 2020 research and innovation program
   under grant agreement No 952043.
CR Adkins A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486582
   Alexandrovsky D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376260
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Bergström J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445193
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Boulic R., 1996, PROC ACM S VIRTUAL R, P67
   Bowman D. A., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P35, DOI 10.1145/253284.253301
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   de Sá AG, 1999, COMPUT GRAPH-UK, V23, P389, DOI 10.1016/S0097-8493(99)00047-3
   de Vignemont F, 2011, CONSCIOUS COGN, V20, P82, DOI 10.1016/j.concog.2010.09.004
   Dewez D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445379
   Durlach PJ, 2005, PRESENCE-TELEOP VIRT, V14, P450, DOI 10.1162/105474605774785299
   Games S., 2017, EXPECT YOU
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Lin Lorraine, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P510, DOI 10.1109/VR.2019.8797787
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI DOI 10.1145/2931002.2931006
   Lindeman RW, 2001, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2001.913780
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Ma K, 2015, CONSCIOUS COGN, V36, P75, DOI 10.1016/j.concog.2015.06.003
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Mendes D, 2019, COMPUT GRAPH FORUM, V38, P21, DOI 10.1111/cgf.13390
   Moehring M, 2011, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2011.5759451
   O. Labs, 2016, JOB SIMULATOR
   Peck T. C., 2021, FRONT VIRTUAL REAL, V1, DOI [10.3389/frvir.2020.5759435, DOI 10.3389/FRVIR.2020.5759435]
   Poupyrev I., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P21, DOI 10.1145/261135.261141
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Prachyabrued M, 2012, INT J HUM-COMPUT ST, V70, P828, DOI 10.1016/j.ijhcs.2012.06.002
   Rusak Z., 2009, P 17 INT C ENG DESIG
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Ullmann T, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P373, DOI 10.1109/PCCGA.2000.883961
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
NR 38
TC 4
Z9 5
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2369
EP 2378
DI 10.1109/TVCG.2023.3247039
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0DG9
UT WOS:000965513700001
PM 37027612
OA Green Published
DA 2024-11-06
ER

PT J
AU Yu, PP
   Guo, J
   Huang, F
   Chen, ZY
   Wang, C
   Zhang, Y
   Guo, YW
AF Yu, Piaopiao
   Guo, Jie
   Huang, Fan
   Chen, Zhenyu
   Wang, Chen
   Zhang, Yan
   Guo, Yanwen
TI ShadowMover: Automatically Projecting Real Shadows onto Virtual Object
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Three-dimensional displays; Training; Manuals; Geometry;
   Rendering (computer graphics); Estimation; Shifted shadow map; virtual
   object; outdoor; neural network
ID REMOVAL
AB Inserting 3D virtual objects into real-world images has many applications in photo editing and augmented reality. One key issue to ensure the reality of the composite whole scene is to generate consistent shadows between virtual and real objects. However, it is challenging to synthesize visually realistic shadows for virtual and real objects without any explicit geometric information of the real scene or manual intervention, especially for the shadows on the virtual objects projected by real objects. In view of this challenge, we present, to our knowledge, the first end-to-end solution to fully automatically project real shadows onto virtual objects for outdoor scenes. In our method, we introduce the Shifted Shadow Map, a new shadow representation that encodes the binary mask of shifted real shadows after inserting virtual objects in an image. Based on the shifted shadow map, we propose a CNN-based shadow generation model named ShadowMover which first predicts the shifted shadow map for an input image and then automatically generates plausible shadows on any inserted virtual object. A large-scale dataset is constructed to train the model. Our ShadowMover is robust to various scene configurations without relying on any geometric information of the real scene and is free of manual intervention. Extensive experiments validate the effectiveness of our method.
C1 [Yu, Piaopiao; Guo, Jie; Huang, Fan; Chen, Zhenyu; Wang, Chen; Zhang, Yan; Guo, Yanwen] Nanjing Univ, Nanjing, Peoples R China.
C3 Nanjing University
RP Guo, J; Guo, YW (corresponding author), Nanjing Univ, Nanjing, Peoples R China.
EM dz1833033@smail.nju.edu.cn; guojie@nju.edu.cn;
   mf20330031@smail.nju.edu.cn; mf21330012@smail.nju.edu.cn;
   502022330045@smail.nju.edu.cn; zhangyannju@nju.edu.cn; ywguo@nju.edu.cn
RI Huang, Fan/E-1592-2017; Wang, Chen/H-3715-2018
FU National Natural Science Foundation of China [62032011]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62032011)
CR [Anonymous], BLEND SCEN
   Blender, About us
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Chang Angel X., CoRR
   Chen Z, 2021, P IEEE CVF INT C COM, P4743
   Choy C. B., 2016, P EUROPEAN C COMPUTE
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Ding B, 2019, IEEE I CONF COMP VIS, P10212, DOI 10.1109/ICCV.2019.01031
   Einabadi F, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.14283
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z
   Gardner MA, 2019, IEEE I CONF COMP VIS, P7174, DOI 10.1109/ICCV.2019.00727
   Garon M, 2019, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2019.00707
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo RQ, 2011, PROC CVPR IEEE
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Hold-Geoffroy Y, 2019, PROC CVPR IEEE, P6920, DOI 10.1109/CVPR.2019.00709
   Hold-Geoffroy Y, 2017, PROC CVPR IEEE, P2373, DOI 10.1109/CVPR.2017.255
   Hu XW, 2021, IEEE T IMAGE PROCESS, V30, P1925, DOI 10.1109/TIP.2021.3049331
   Hu XW, 2020, IEEE T PATTERN ANAL, V42, P2795, DOI 10.1109/TPAMI.2019.2919616
   Huang X, 2011, IEEE I CONF COMP VIS, P898, DOI 10.1109/ICCV.2011.6126331
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kingma D. P., 2015, 3 INT C LEARN REPR I, P4
   Kronander J, 2015, COMPUT GRAPH FORUM, V34, P643, DOI 10.1111/cgf.12591
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Lalonde J. -F., 2015, LAVAL HDR SKY DATABA, V3, P9
   Li Junxuan, 2021, P IEEE CVF C COMP VI, P10591
   Li M., 2019, P ACM MULTIMEDIA ASI, V1, P2
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Liao S, 2019, PROC CVPR IEEE, P9751, DOI 10.1109/CVPR.2019.00999
   Liu DQ, 2020, PROC CVPR IEEE, P8136, DOI 10.1109/CVPR42600.2020.00816
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Lyu JF, 2022, PROC CVPR IEEE, P3419, DOI 10.1109/CVPR52688.2022.00342
   Niu CJ, 2018, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2018.00475
   Paszke A, 2019, ADV NEUR IN, V32
   Pharr M., 2016, Physically based rendering: From theory to implementation, V3rd, P3
   Popov Stefan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P366, DOI 10.1007/978-3-030-58536-5_22
   Qu LQ, 2017, PROC CVPR IEEE, P2308, DOI 10.1109/CVPR.2017.248
   Rhee T, 2017, IEEE T VIS COMPUT GR, V23, P1302, DOI 10.1109/TVCG.2017.2657178
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Scherzer D., 2010, EUROGRAPHICS 2010 ST
   Sheng Y., 2021, P IEEE CVF C COMP VI, P4380
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   Srinivasan PP, 2020, PROC CVPR IEEE, P8077, DOI 10.1109/CVPR42600.2020.00810
   Tan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4166, DOI 10.1109/ICCV48922.2021.00415
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tulsiani S, 2017, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2017.160
   Vicente TFY, 2016, PROC CVPR IEEE, P3783, DOI 10.1109/CVPR.2016.411
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang LL, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P170, DOI 10.1109/VR50410.2021.00038
   Wei JJ, 2019, COMPUT GRAPH FORUM, V38, P381, DOI 10.1111/cgf.13845
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu W, 2022, VISUAL COMPUT, V38, P1677, DOI 10.1007/s00371-021-02096-4
   Xiao CX, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12250
   Yu PP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15293, DOI 10.1109/ICCV48922.2021.01503
   Yu PP, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-021-3282-4
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zhang SY, 2019, COMPUT VIS MEDIA, V5, P105, DOI 10.1007/s41095-019-0136-1
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
NR 62
TC 1
Z9 1
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2379
EP 2389
DI 10.1109/TVCG.2023.3247066
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1RP0
UT WOS:000966565000001
PM 37027714
DA 2024-11-06
ER

PT J
AU Wilson, G
   McGill, M
   Medeiros, D
   Brewster, S
AF Wilson, Graham
   McGill, Mark
   Medeiros, Daniel
   Brewster, Stephen
TI A Lack of Restraint: Comparing Virtual Reality Interaction Techniques
   for Constrained Transport Seating
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Interaction; Constrained Spaces; Transport
AB Standalone Virtual Reality (VR) headsets can be used when travelling in cars, trains and planes. However, the constrained spaces around transport seating can leave users with little physical space in which to interact using their hands or controllers, and can increase the risk of invading other passengers' personal space or hitting nearby objects and surfaces. This hinders transport VR users from using most commercial VR applications, which are designed for unobstructed 1-2m 360 degrees home spaces. In this paper, we investigated whether three at-a-distance interaction techniques from the literature could be adapted to support common commercial VR movement inputs and so equalise the interaction capabilities of at-home and on-transport users: Linear Gain, Gaze-Supported Remote Hand, and AlphaCursor. First, we analysed commercial VR experiences to identify the most common movement inputs so that we could create gamified tasks based on them. We then investigated how well each technique could support these inputs from a constrained 50x50cm space (representative of an economy plane seat) through a user study (N=16), where participants played all three games with each technique. We measured task performance, unsafe movements (play boundary violations, total arm movement) and subjective experience and compared results to a control 'at-home' condition (with unconstrained movement) to determine how similar performance and experience were. Results showed that Linear Gain was the best technique, with similar performance and user experience to the 'at-home' condition, albeit at the expense of a high number of boundary violations and large arm movements. In contrast, AlphaCursor kept users within bounds and minimised arm movement, but suffered from poorer performance and experience. Based on the results, we provide eight guidelines for the use of, and research into, at-a-distance techniques and constrained spaces.
C1 [Wilson, Graham; McGill, Mark; Medeiros, Daniel; Brewster, Stephen] Univ Glasgow, Sch Comp Sci, Glasgow G128QQ, Scotland.
C3 University of Glasgow
RP Wilson, G (corresponding author), Univ Glasgow, Sch Comp Sci, Glasgow G128QQ, Scotland.
EM graham.wilson@glasgow.ac.uk; mark.mcgill@glasgow.ac.uk;
   daniel.piresdesamedeiros@glasgow.ac.uk; stephen.brewster@glasgow.ac.uk
RI Brewster, Stephen/J-9003-2017
OI Wilson, Graham/0000-0003-2664-1634
FU European Research Council (ERC) under the European Union [835197];
   European Research Council (ERC) [835197] Funding Source: European
   Research Council (ERC)
FX This research received funding from the European Research Council (ERC)
   under the European Union's Horizon 2020 research and innovation
   programme (#835197, ViAjeRo).
CR Adequate, 2022, SPAC DROID
   [Anonymous], 2022, ARTOOL
   Assets C. G., 2022, LOWPOLY UNIVERSAL CH
   B. Airways, 2019, BRIT AIRW TRIAL VIRT
   Bajorunaite L, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519696
   Bajorunaite L, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P432, DOI 10.1109/VRW52623.2021.00098
   Bergström J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445193
   Comeback, 2022, STON BUR TREAS
   Dewez D, 2022, IEEE T VIS COMPUT GR, V28, P2047, DOI 10.1109/TVCG.2022.3150501
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Goedicke D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173739
   Goedicke David, 2022, P CHI 2022
   Google, 2022, YOUTUBE
   HART S G, 1988, P139
   Heckfricker F., 2022, FAIRGROUND AMBIENCE
   Hock P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4034, DOI 10.1145/3025453.3025665
   Holoride, 2022, ABOUT US
   Justiplay, 2022, LOW POL LUN PARK
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Li JL, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P120, DOI 10.1145/3267782.3267797
   Li JY, 2021, AUTOMOTIVEUI '21: 13TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P28, DOI [10.1145/3409118.3475137, 10.1145/34091183475137]
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Li Jingyi, 2020, 12 INT C AUT US INT, P92, DOI [10.1145/3409251.3411732, DOI 10.1145/3409251.3411732]
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Lusth A., 2022, RPG SWORDS
   McGill M, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545657
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2020, VIRTUAL REAL-LONDON, V24, P583, DOI 10.1007/s10055-019-00420-x
   McGill M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5655, DOI 10.1145/3025453.3026046
   Medeiros D, 2022, IEEE T VIS COMPUT GR, V28, P3640, DOI 10.1109/TVCG.2022.3203002
   Mendes D, 2017, COMPUT GRAPH-UK, V67, P95, DOI 10.1016/j.cag.2017.06.003
   Mendes D, 2017, IEEE SYMP 3D USER, P154, DOI 10.1109/3DUI.2017.7893332
   Meta, 2022, MET QUEST
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   Nitacawo, 2022, DOG BEAGL
   Oculus, 2022, OC STOR
   Oculus, 2022, OC GUARD SYST
   Paredes Pablo E., 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287062
   Pheasant S., 2006, Bodyspace: Anthropometry, Ergonomics and the Design of Work, V3rd
   Pico, 2022, PIC NEOVR
   PlayStation, 2022, PLAYSTATION VR ULT F
   Poupyrev I., 1996, UIST 1996 P 9 ANN AC, P2
   Qantas, 2022, QANT VIRT REAL APP
   Riegler A, 2021, FRONT HUM DYNAM, V3, DOI 10.3389/fhumd.2021.689856
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Schjerlund Jonas, 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445759
   Schmelter T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P279, DOI [10.1109/VRW50115.2020.0-218, 10.1109/VRW50115.2020.00058]
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Scout V., 2022, APPLE CAR COULD FEAT
   SeatGuru, 2022, AIRL SEAT COMP CHART
   Sherry JL, 2006, LEA COMMUN SER, P213
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Steam, 2022, STEAM VALV CORP
   Togwell H, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519741
   Tseng WJ, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451573
   Virtual M., 2022, SCI FI GUN
   Wentzel J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376687
   Williamson JR, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300310
   Wilson G, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173673
   Yu D., 2020, IEEE T VIS COMPUT GR, V26, P12
   Yu DF, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445343
NR 63
TC 4
Z9 4
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2390
EP 2400
DI 10.1109/TVCG.2023.3247084
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1TZ8
UT WOS:000966627800001
PM 37028078
DA 2024-11-06
ER

PT J
AU Lin, JH
   Cronje, J
   Kathner, I
   Pauli, P
   Latoschik, ME
AF Lin, Jinghuai
   Cronje, Johrine
   Kathner, Ivo
   Pauli, Paul
   Latoschik, Marc Erich
TI Measuring Interpersonal Trust towards Virtual Humans with a Virtual Maze
   Paradigm
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Psychology; Games; Particle measurements; Atmospheric
   measurements; Investment; Task analysis; virtual human; specific
   interpersonal trust; trustworthiness; social VR; behavioural measurement
   paradigm; virtual reality
ID CONSTRUCTION; COMMITMENT; TESTIMONY; ATTITUDES; BEHAVIOR; SCALE
AB Virtual humans, including virtual agents and avatars, play an increasingly important role as VR technology advances. For example, virtual humans are used as digital bodies of users in social VR or as interfaces for AI assistants in online financing. Interpersonal trust is an essential prerequisite in real-life interactions, as well as in the virtual world. However, to date, there are no established interpersonal trust measurement tools specifically for virtual humans in virtual reality. This study fills the gap, by contributing a novel validated behavioural tool to measure interpersonal trust towards a specific virtual social interaction partner in social VR. This validated paradigm is inspired by a previously proposed virtual maze task that measures trust towards virtual characters. In the current study, a variant of this paradigm was implemented. The task of the users (the trustors) is to navigate through a maze in virtual reality, where they can interact with a virtual human (the trustee). They can choose to 1) ask for advice and 2) follow the advice from the virtual human if they want to. These measures served as behavioural measures of trust. We conducted a validation study with 70 participants in a between-subject design. The two conditions did not differ in the content of the advice but in the appearance, tone of voice and engagement of the trustees (alleged as avatars controlled by other participants). Results indicate that the experimental manipulation was successful, as participants rated the virtual human as more trustworthy in the trustworthy condition than in the untrustworthy condition. Importantly, this manipulation affected the trust behaviour of our participants, who, in the trustworthy condition, asked for advice more often and followed advice more often, indicating that the paradigm is sensitive to assessing interpersonal trust towards virtual humans. Thus, our paradigm can be used to measure differences in interpersonal trust towards virtual humans and may serve as a valuable research tool to study trust in virtual reality.
C1 [Lin, Jinghuai; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Cronje, Johrine; Kathner, Ivo; Pauli, Paul] Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Wurzburg, Germany.
   [Kathner, Ivo] Univ Bamberg, Dept Physiol Psychol, Bamberg, Germany.
   [Pauli, Paul] Univ Wurzburg, Ctr Mental Hlth, Med Fac, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; Otto Friedrich
   University Bamberg; University of Wurzburg
RP Lin, JH (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
EM jinghuai.lin@uni-wuerzburg.de; johrine.cronje@uni-wuerzburg.de;
   ivo.kaethner@uni-wuerzburg.de; pauli@psychologie.uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
RI Latoschik, Marc/HLG-5348-2023; Lin, Jinghuai/JRW-7309-2023; Kaethner,
   Ivo/AFD-9016-2022
OI Kathner, Ivo/0000-0003-0528-907X; Cronje, Johrine/0000-0002-7764-4678;
   Pauli, Paul/0000-0003-0692-6720; Lin, Jinghuai/0000-0003-4205-3170
FU European Union [860315]; Marie Curie Actions (MSCA) [860315] Funding
   Source: Marie Curie Actions (MSCA)
FX This work is part of the Privacy Matters (PriMa) project. The PriMa
   project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No 860315
CR Armitage CJ, 2003, CURR PSYCHOL, V22, P187, DOI 10.1007/s12144-003-1015-5
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bachmann R, 2006, HANDBOOK OF TRUST RESEARCH, P1
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Beierlein C., 2012, KURZSKALA MESSUNG ZW, V6, P6
   Ben-Ner A, 2010, J ECON PSYCHOL, V31, P64, DOI 10.1016/j.joep.2009.10.001
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   BERG J, 1995, GAME ECON BEHAV, V10, P122, DOI 10.1006/game.1995.1027
   Blomqvist K., 1997, Scandinavian Journal of Management, V13, P271, DOI [10.1016/S0956-5221(97)84644-1, DOI 10.1016/S0956-5221(97)84644-1]
   Chan D., 2008, STAT METHODOLOGICAL, P28
   Clément F, 2004, MIND LANG, V19, P360, DOI 10.1111/j.0268-1064.2004.00263.x
   Couch LL, 1997, J RES PERS, V31, P319, DOI 10.1006/jrpe.1997.2186
   de Visser EJ, 2016, J EXP PSYCHOL-APPL, V22, P331, DOI 10.1037/xap0000092
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Eagly Alice H., 2012, HDB THEORIES SOCIAL, VVol. 2, P458, DOI [DOI 10.4135/9781446249222.N49, 10.4135/9781446249222.n49, 10.1002/9781118663219.wbegss183, DOI 10.1002/9781118663219.WBEGSS183]
   Eisenberg N, 2010, SOC ISS POLICY REV, V4, P143, DOI 10.1111/j.1751-2409.2010.01020.x
   Foerster K., 2021, INNOVATE LEARNING SU, P95
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Freeman G, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382923
   Freitag M, 2009, EUR J POLIT RES, V48, P782, DOI 10.1111/j.1475-6765.2009.00849.x
   Glaeser EL, 2000, Q J ECON, V115, P811, DOI 10.1162/003355300554926
   Gonzalez -Franco M., 2020, FRONTIERS VIRTUAL RE, V1
   Graber MA, 2010, J MED INTERNET RES, V12, DOI 10.2196/jmir.1299
   Halbig A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.837616
   Hale J, 2018, Q J EXP PSYCHOL, V71, P989, DOI 10.1080/17470218.2017.1307865
   Ahmad MI, 2019, Arxiv, DOI arXiv:1909.05160
   JOHNSONGEORGE C, 1982, J PERS SOC PSYCHOL, V43, P1306, DOI 10.1037/0022-3514.43.6.1306
   Jung S, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P3, DOI 10.1145/3131277.3132186
   KAHNEMAN D, 1986, J BUS, V59, pS285, DOI 10.1086/296367
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   King MF, 2000, PSYCHOL MARKET, V17, P79, DOI 10.1002/(SICI)1520-6793(200002)17:2<79::AID-MAR2>3.0.CO;2-0
   Koenig MA, 2005, CHILD DEV, V76, P1261, DOI 10.1111/j.1467-8624.2005.00849.x
   Koenig MA, 2004, PSYCHOL SCI, V15, P694, DOI 10.1111/j.0956-7976.2004.00742.x
   Koenig MA, 2003, COGNITION, V87, P179, DOI 10.1016/S0010-0277(03)00002-7
   Koenig MA, 2007, EPISTEME-J INDIV SOC, V4, P264, DOI 10.3366/E1742360007000081
   Kreps D.M., 1990, PERSPECTIVES POSITIV, V90, P109, DOI [DOI 10.1017/CBO9780511571657.006, 10.1017/cbo9780511571657.006, 10.1017/CBO9780511571657.006]
   Lang B., 2022, RES SHOW FULL BODY V
   Latoschik M. E., 2022, FRONT VIRTUAL REAL, V3, DOI [10.3389/frvir.2022.6944338, DOI 10.3389/FRVIR.2022.6944338]
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Liew TW, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0123-4
   Lin JH, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.974652
   Lohle MF, 2014, QUAL REP, V19
   Machneva M, 2022, COMPUT HUM BEHAV, V126, DOI 10.1016/j.chb.2021.107017
   McCambridge J, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0039116
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Melnick K., 2022, VR SOCIAL PLATFORM V
   MILLER LC, 1983, J PERS SOC PSYCHOL, V44, P1234, DOI 10.1037/0022-3514.44.6.1234
   MOORMAN C, 1993, J MARKETING, V57, P81, DOI 10.2307/1252059
   Moradinezhad R, 2021, INT J SOC ROBOT, V13, P2103, DOI 10.1007/s12369-021-00747-z
   MORGAN RM, 1994, J MARKETING, V58, P20, DOI 10.2307/1252308
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Pan Y, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00012
   Pasquini ES, 2007, DEV PSYCHOL, V43, P1216, DOI 10.1037/0012-1649.43.5.1216
   Peña J, 2014, PRESENCE-VIRTUAL AUG, V23, P18, DOI 10.1162/PRES_a_00166
   Rau HA., 2012, Psychology of gender differences, P205
   Reeskens T, 2008, SOC INDIC RES, V85, P515, DOI 10.1007/s11205-007-9100-z
   Ripka G., 2020, P SITE INTERACTIVE 2, P549
   Robbins B. G., 2019, Sociological Methods and Research, V51, P1, DOI [10.1177/0049124119852371, DOI 10.1177/0049124119852371]
   Rosenberger LA, 2020, J EXP SOC PSYCHOL, V90, DOI 10.1016/j.jesp.2020.104001
   Roth D., 2018, REPLICATION AUGMENTI, DOI [10.1109/VR.2018.8447550, DOI 10.1109/VR.2018.8447550]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Roth D, 2017, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2017.7892275
   ROTTER JB, 1967, J PERS, V35, P651, DOI 10.1111/j.1467-6494.1967.tb01454.x
   Salanitri D, 2016, P EUROPEAN C COGNITI, DOI DOI 10.1145/2970930.29709473
   Samson K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127680
   Schubert Thomas W., 2003, Zeitschrift fur Medienpsychologie, V15, P69
   Shao D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12229345
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Surprenant A., 2012, THESIS, V2, P8
   Thalmann D, 2001, FRONTIERS OF HUMAN-CENTRED COMPUTING, ONLINE COMMUNITIES AND VIRTUAL ENVIRONMENTS, P27
   Torre I., 2017, THESIS
   Tsankova E., 2013, FACIAL VOCAL CUES PE, V7729, DOI [10.1007/978-3-642-37484-5_26, DOI 10.1007/978-3-642-37484-5_26]
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang MH, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012032
   Wu Y, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00225
   YAMAGISHI T, 1994, MOTIV EMOTION, V18, P129, DOI 10.1007/BF02249397
   Zanbaka C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1561
NR 78
TC 8
Z9 8
U1 9
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2401
EP 2411
DI 10.1109/TVCG.2023.3247095
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2FN8
UT WOS:000966932900001
PM 37027704
OA hybrid
DA 2024-11-06
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Raveendranath, B
   Pagano, CC
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Roshan
   Venkatakrishnan, Rohith
   Raveendranath, Balagopal
   Pagano, Christopher C.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI Give Me a Hand: Improving the Effectiveness of Near-field Augmented
   Reality Interactions By Avatarizing Users' End Effectors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Avatars; Three-dimensional displays; End effectors;
   Visualization; Hardware; Cameras; Interactions in AR; End-effector
   representation; Augmented Reality
ID INTERFACE; HOLOLENS; GESTURES
AB Inspired by previous works showing promise for AR self-avatarization - providing users with an augmented self avatar, we investigated whether avatarizing users' end-effectors (hands) improved their interaction performance on a near-field, obstacle avoidance, object retrieval task wherein users were tasked with retrieving a target object from a field of non-target obstacles for a number of trials. We employed a 3 (Augmented hand representation) X 2 (density of obstacles) X 2 (size of obstacles) X 2 (virtual light intensity) multi-factorial design, manipulating the presence/absence and anthropomorphic fidelity of augmented self-avatars overlaid on the user's real hands, as a between subjects factor across three experimental conditions: (1) No-Augmented Avatar (using only real hands); (2) Iconic-Augmented Avatar; (3) Realistic Augmented Avatar. Results indicated that self-avatarization improved interaction performance and was perceived as more usable regardless of the anthropomorphic fidelity of avatar. We also found that the virtual light intensity used in illuminating holograms affects how visible one's real hands are. Overall, our findings seem to indicate that interaction performance may improve when users are provided with a visual representation of the AR system's interacting layer in the form of an augmented self-avatar.
C1 [Venkatakrishnan, Roshan; Venkatakrishnan, Rohith] Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
   [Raveendranath, Balagopal; Pagano, Christopher C.; Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 Clemson University; Clemson University; National Yang Ming Chiao Tung
   University
RP Venkatakrishnan, R (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29631 USA.
EM rvenkat@g.clemson.edu; rohithv@g.clemson.edu; braveen@g.clemson.edu;
   cpagano@clemson.edu; arobb@clemson.edu; wclin@cs.nctu.edu.tw;
   sbabu@clemson.edu
RI Venkatakrishnan, Roshan/JDC-3508-2023; Venkatakrishnan,
   Rohith/JCE-8736-2023
OI Robb, Andrew/0000-0002-0398-5576; Venkatakrishnan,
   Roshan/0000-0002-6538-627X; Babu, Sabarish/0000-0002-8348-0534;
   Venkatakrishnan, Rohith/0000-0002-8484-3915; Pagano,
   Christopher/0000-0002-0110-2055
FU US National Science Foundation (CISE IIS HCC) [2007435]
FX The authors would like to thank the participants of our studies for
   their time and effort. This work was supported in part by the US
   National Science Foundation (CISE IIS HCC) under Grant No. 2007435.
CR Anderson R, 2019, IEEE SOUTHEASTCON, DOI 10.1109/southeastcon42311.2019.9020354
   [Anonymous], 2003, P 5 INT C MULT INT
   [Anonymous], 2017, 2 WORKSH IMM AN
   Arbib MA, 2009, PSYCHOL RES-PSYCH FO, V73, P441, DOI 10.1007/s00426-009-0242-2
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Asgary A, 2020, IEEE T ENG MANAGE, V67, P545, DOI 10.1109/TEM.2019.2932291
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Buchmann V., 2004, VIRTUAL REAL-LONDON, V1, P212
   Buchmann Volkert., 2005, Interaction with partially transparent hands and objects
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Cheng KY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1155
   Coxe S, 2009, J PERS ASSESS, V91, P121, DOI 10.1080/00223890802634175
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Ehnes J., 2009, 2009 2 C HUM SYST IN, P306
   Fajen Brett R., 2021, Visual control of locomotion
   Feiner A.O.S., 2003, P UIST, P81
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Genay A. C. S., 2021, IEEE Transactions on Visualization and Computer Graphics, P2021, DOI 10.1109/TVCG.2021.3099290
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Hoang TN, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P46
   Hoermann S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050942
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Hoover M., 2018, THESIS IOWA STATE U
   Irawati S., 2006, Proc. ISMAR, P183
   Ishiyama H, 2016, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2016.7504716
   Johnson Adrian S., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P169, DOI 10.1007/978-3-642-39405-8_20
   Kaneko F, 2019, FRONT SYST NEUROSCI, V13, DOI 10.3389/fnsys.2019.00076
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   Lamounier E A., 2012, Journal of Bioengineering  Biomedical Science, V1, P010, DOI [DOI 10.4172/2155-9538.S1-010, 10.4172/2155-9538.S1-010]
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Lewis JR, 2002, INT J HUM-COMPUT INT, V14, P463, DOI 10.1080/10447318.2002.9669130
   Lougiakis C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P510, DOI [10.1109/VR46266.2020.1581086151885, 10.1109/VR46266.2020.00-32]
   Lu G, 2012, VIRTUAL REAL-LONDON, V16, P243, DOI 10.1007/s10055-011-0195-9
   Macaranas A, 2015, INTERACT COMPUT, V27, P357, DOI 10.1093/iwc/iwv003
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Merrill D, 2007, LECT NOTES COMPUT SC, V4480, P1
   Mifsud D.M., 2022, 2022 IEEE C VIRTUAL, P590, DOI [10.1109/VRW55335.2022.00146, DOI 10.1109/VRW55335.2022.00146]
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Munsinger B., 2019, P 11 INT C VIRT WORL, P1
   Nagel T., 2011, GEOVIZ 2011, P10
   Ness Steven R., 2010, Sonophenology: a tangible interface for sonification of geo-spatial phenological data at multiple time-scales
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Noh S., 2015, P INT C ART REAL TEL, P61
   O'Connor TF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179766
   Otono R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P721, DOI 10.1109/VRW55335.2022.00216
   Piekarski W., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P19, DOI 10.1145/769953.769956
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Piumsomboon Thammathip., 2011, Proc. Image and Vision Computing New Zealand (IVCNZ-2011), P161
   Poelman R., 2012, P ACM 2012 C COMP SU, P1267, DOI [10.1145/2145204.2145394, DOI 10.1145/2145204.2145394]
   Prilla Michael., 2019, AIS Transactions on Human-Computer Interaction, V11, P157, DOI DOI 10.17705/1THCI.00118
   Quandt M., 2020, DELBA EC TEL
   Radkowski R., 2012, P 2012 INT C ADV COM, P303
   Regenbrecht H, 2014, P IEEE, V102, P170, DOI 10.1109/JPROC.2013.2294178
   Rosa N, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P550, DOI 10.1145/2993148.2997618
   Schiettecatte B., 2008, Proceedings of the 2nd international conference on Tangible and embedded interaction, P3
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Seinfeld Sofia., 2020, IEEE transactions on visualization and computer graphics, P1
   Seo DW, 2013, EXPERT SYST APPL, V40, P3784, DOI 10.1016/j.eswa.2012.12.091
   Serrano R, 2022, MULTIMED TOOLS APPL, V81, P31657, DOI 10.1007/s11042-022-12864-6
   Snijders T. A. B., 2012, Multilevel Analysis, V2nd
   Soares Alcimar Barbosa., 2012, Computational Intelligence in Electromyography Analysis-A Perspective on Current Applications and Future Challenges, P409
   Sorensen S, 2019, PROC EUR CONF GAME, P649
   Steed A, 2016, P IEEE VIRT REAL ANN, P67, DOI 10.1109/VR.2016.7504689
   Tran TQ, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139149
   Valentini PP, 2018, INT J INTERACT DES M, V12, P1157, DOI 10.1007/s12008-018-0461-0
   Vuletic T, 2019, INT J HUM-COMPUT ST, V129, P74, DOI 10.1016/j.ijhcs.2019.03.011
   Wang K, 2017, IEEE ACCESS, V5, P10700, DOI 10.1109/ACCESS.2017.2711058
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Whitlock M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P41, DOI 10.1109/VR.2018.8446381
   Wither J, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P124, DOI 10.1109/ISWC.2004.18
   Wolf E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P350, DOI 10.1109/VR51125.2022.00054
   Xue H, 2019, COMPUTERS, V8, DOI 10.3390/computers8010009
   Zhang W, 2020, IOP CONF SER-MAT SCI, V751, DOI 10.1088/1757-899X/751/1/012020
   Zhao HY, 2015, VISION RES, V110, P190, DOI 10.1016/j.visres.2014.10.008
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 82
TC 1
Z9 3
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2412
EP 2422
DI 10.1109/TVCG.2023.3247105
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0LX7
UT WOS:000965739500001
PM 37027732
DA 2024-11-06
ER

PT J
AU Weidner, F
   Maier, JE
   Broll, W
AF Weidner, Florian
   Maier, Jana E.
   Broll, Wolfgang
TI Eating, Smelling, and Seeing: Investigating Multisensory Integration and
   (In)congruent Stimuli while Eating in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Olfactory; Image color analysis; Visualization; Multisensory
   integration; Fans; Containers; Chemicals; Virtual reality; gustatory
   interfaces; olfactory interfaces; multisensory interfaces
ID TASTE; SPECIFICATION; FAMILIARITY; EXPOSURE; REALITY; SENSES
AB Integrating taste in AR/VR applications has various promising use cases - from social eating to the treatment of disorders. Despite many successful AR/VR applications that alter the taste of beverages and food, the relationship between olfaction, gustation, and vision during the process of multisensory integration (MSI) has not been fully explored yet. Thus, we present the results of a study in which participants were confronted with congruent and incongruent visual and olfactory stimuli while eating a tasteless food product in VR. We were interested (1) if participants integrate bi-modal congruent stimuli and (2) if vision guides MSI during congruent/incongruent conditions. Our results contain three main findings: First, and surprisingly, participants were not always able to detect congruent visual-olfactory stimuli when eating a portion of tasteless food. Second, when confronted with tri-modal incongruent cues, a majority of participants did not rely on any of the presented cues when forced to identify what they eat; this includes vision which has previously been shown to dominate MSI. Third, although research has shown that basic taste qualities like sweetness, saltiness, or sourness can be influenced by congruent cues, doing so with more complex flavors (e.g., zucchini or carrot) proved to be harder to achieve. We discuss our results in the context of multimodal integration, and within the domain of multisensory AR/VR. Our results are a necessary building block for future human-food interaction in XR that relies on smell, taste, and vision and are foundational for applied applications such as affective AR/VR.
C1 [Weidner, Florian; Maier, Jana E.; Broll, Wolfgang] Tech Univ Ilmenau, Virtual Worlds & Digital Games Grp, Ilmenau, Germany.
C3 Technische Universitat Ilmenau
RP Weidner, F (corresponding author), Tech Univ Ilmenau, Virtual Worlds & Digital Games Grp, Ilmenau, Germany.
EM florian.weidner@tu-ilmenau.de; jana.maier@tu-ilmenau.de;
   wolfgang.broll@tu-ilmenau.de
RI Weidner, Florian/JHU-6915-2023; Broll, Wolfgang/AAB-5897-2022
OI Broll, Wolfgang/0000-0001-7483-1550
FU CYTEMEX project by Free State of Thuringia, Germany [FKZ: 2018-FGI-0019]
FX This work has partially been funded by the CYTEMEX project funded by the
   Free State of Thuringia, Germany (FKZ: 2018-FGI-0019).
CR Aisala H, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P322, DOI 10.1145/3395035.3425650
   Ammann J, 2020, FOOD QUAL PREFER, V86, DOI 10.1016/j.foodqual.2020.103998
   Benson K, 2014, EAT BEHAV, V15, P331, DOI 10.1016/j.eatbeh.2014.01.007
   Brooks J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445300
   Chen Y, 2020, FOODS, V9, DOI 10.3390/foods9040465
   CHIFALA WM, 1995, J GEN PSYCHOL, V122, P287, DOI 10.1080/00221309.1995.9921240
   Choi I, 2018, CURR OPIN NEUROBIOL, V52, P115, DOI 10.1016/j.conb.2018.05.002
   Chrea C, 2004, FOOD QUAL PREFER, V15, P669, DOI 10.1016/j.foodqual.2003.10.005
   Dalton P, 2000, NAT NEUROSCI, V3, P431, DOI 10.1038/74797
   Dalton P, 2000, CHEM SENSES, V25, P487, DOI 10.1093/chemse/25.4.487
   Dozio N, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.671470
   F. Inc, 2022, FEELREAL MULT VR MAS
   Fouque F, 1999, ECOL PSYCHOL, V11, P1, DOI 10.1207/s15326969eco1101_1
   FRANK RA, 1988, CHEM SENSES, V13, P445, DOI 10.1093/chemse/13.3.445
   Gottfried JA, 2003, NEURON, V39, P375, DOI 10.1016/S0896-6273(03)00392-1
   H. Shop, 2021, OBST AROMEN
   Hadidi KA, 2004, SAUDI MED J, V25, P912
   Herbs M, 2021, MAKE GLYCERINE EXTRA
   Hilditch T. P., 1953, NATURE, V172, P1066, DOI [10.1038/1721066b0, DOI 10.1038/1721066B0]
   Hirst RJ, 2018, NEUROSCI BIOBEHAV R, V94, P286, DOI 10.1016/j.neubiorev.2018.07.012
   Jakubowski L, 2021, 10 GR AROMA TYP RADI
   Jones L, 2004, HUMAN PERFORMANCE, SITUATION AWARENESS AND AUTOMATION: CURRENT RESEARCH AND TRENDS, VOL 2, P282
   Karunanayaka K, 2018, IEEE T VIS COMPUT GR, V24, P1496, DOI 10.1109/TVCG.2018.2794073
   Klasnja-Milicevic A, 2019, ADV INTELL SYST, V804, P213, DOI 10.1007/978-3-319-98872-6_25
   Li BJ, 2017, PRESENCE-TELEOP VIRT, V26, P337, DOI [10.1162/pres_a_00300, 10.1162/PRES_a_00300]
   Lin YL, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281560
   Mantel B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120025
   Maynes-aminzade D., 2005, P 2005 ACM C HUMAN F
   Nakano K, 2019, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR.2019.000-1
   Nambu A, 2010, P IEEE VIRT REAL ANN, P39, DOI 10.1109/VR.2010.5444817
   Nandal P., 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1257), P321, DOI 10.1007/978-981-15-7907-3_24
   Narumi Takuji, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P260, DOI 10.1007/978-3-642-22021-0_29
   Narumi T., 2010, ACM SIGGRAPH 2010 Posters p, P143, DOI [DOI 10.1145/1836821.1836839, 10.1145/1836821.1836839]
   Narumi T., 2012, Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems (CHI '12), P109, DOI [DOI 10.1145/2207676.2207693, 10.1145/2207676.2207693]
   Narumi T, 2011, P IEEE VIRT REAL ANN, P127, DOI 10.1109/VR.2011.5759450
   Niedenthal S, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON OLFACTION AND ELECTRONIC NOSE (ISOEN 2019), P114
   OptiTrack, 2022, MOTION CAPTURE SYSTE
   Pallavicini F, 2016, CYBERPSYCH BEH SOC N, V19, P107, DOI 10.1089/cyber.2015.0235
   Persky S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571812
   RABIN MD, 1984, J EXP PSYCHOL LEARN, V10, P316, DOI 10.1037/0278-7393.10.2.316
   Ranasinghe N., 2011, Proceedings of the 6th International Conference on Body Area Networks, DOI [10.4108/ICST.BODYNETS.2011.247067, DOI 10.4108/ICST.BODYNETS.2011.247067]
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1139, DOI 10.1145/3123266.3123440
   Ranasinghe N, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P737, DOI 10.1145/2647868.2654878
   Ranasinghe Nimesha., 2020, INT C MULTIMODAL INT, P296
   Schroeder PA, 2016, CYBERPSYCH BEH SOC N, V19, P120, DOI 10.1089/cyber.2015.0311
   Seo HS, 2008, J FOOD SCI, V73, pS273, DOI 10.1111/j.1750-3841.2008.00818.x
   Seo HS, 2013, HUM BRAIN MAPP, V34, P62, DOI 10.1002/hbm.21414
   Shankar M, 2010, ATTEN PERCEPT PSYCHO, V72, P1981, DOI 10.3758/APP.72.7.1981
   Shankar MU, 2010, CONSCIOUS COGN, V19, P380, DOI 10.1016/j.concog.2009.08.008
   Spence C, 2011, ATTEN PERCEPT PSYCHO, V73, P971, DOI 10.3758/s13414-010-0073-7
   Spence C, 2020, MULTISENSORY PERCEPTION: FROM LABORATORY TO CLINIC, P221, DOI 10.1016/B978-0-12-812492-5.00010-3
   Stein BE, 2008, NAT REV NEUROSCI, V9, P255, DOI 10.1038/nrn2331
   Stein BE, 2009, HEARING RES, V258, P4, DOI 10.1016/j.heares.2009.03.012
   Stoffregen TA, 2001, BEHAV BRAIN SCI, V24, P195, DOI 10.1017/S0140525X01003946
   Stoffregen TA, 2001, BEHAV BRAIN SCI, V24, P246, DOI 10.1017/S0140525X0157394X
   Stoffregen TA, 2017, ECOL PSYCHOL, V29, P165, DOI 10.1080/10407413.2017.1331116
   Tanikawa Tomohiro, 2011, Virtual and Mixed Reality - New Trends. Proceedings International Conference, Virtual and Mixed Reality 2011. Held as Part of HCI International 2011, P280, DOI 10.1007/978-3-642-22021-0_31
   Technology O., 2022, OVR TECHN
   Vi C.T., 2017, Proceedings of the 2nd ACM SIGCHI International Workshop on Multisensory Approaches to Human-Food Interaction, P29, DOI DOI 10.1145/3141788.3141794
   Vrticka P, 2014, EMOTION, V14, P161, DOI 10.1037/a0034619
   Weidner F., 2023, EATING SMELLING SEEI, DOI [10.5281/zenodo.7524934, DOI 10.5281/ZENODO.7524934]
   Xu CY, 2021, TRENDS FOOD SCI TECH, V116, P533, DOI 10.1016/j.tifs.2021.07.015
   Zhou W, 2010, CURR BIOL, V20, P1356, DOI 10.1016/j.cub.2010.05.059
   Zybura M., 1999, IND ENG, V543
NR 64
TC 5
Z9 5
U1 6
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2423
EP 2433
DI 10.1109/TVCG.2023.3247099
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0MF5
UT WOS:000965747300001
PM 37027726
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Benmahdjoub, M
   Thabit, A
   van Veelen, MLC
   Niessen, WJ
   Wolvius, EB
   van Walsum, T
AF Benmahdjoub, Mohamed
   Thabit, Abdullah
   van Veelen, Marie-Lise C.
   Niessen, Wiro J.
   Wolvius, Eppo B.
   van Walsum, Theo
TI Evaluation of AR visualization approaches for catheter insertion into
   the ventricle cavity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surgery; Visualization; Three-dimensional displays; Needles; Task
   analysis; Catheters; Solid modeling; Computer-assisted surgery; Surgical
   navigation systems; Augmented reality; Augmented reality visualization;
   Needle guidance; External ventricular drain; Ventricular shunt; User
   study
ID AUGMENTED REALITY; GUIDED NEUROSURGERY; SURGERY; ACCURACY;
   HYDROCEPHALUS; NAVIGATION; PLACEMENT; DISPLAYS; DRAIN
AB Augmented reality (AR) has shown potential in computer-aided surgery. It allows for the visualization of hidden anatomical structures as well as assists in navigating and locating surgical instruments at the surgical site. Various modalities (devices and/or visualizations) have been used in the literature, but few studies investigated the adequacy/superiority of one modality over the other. For instance, the use of optical see-through (OST) HMDs has not always been scientifically justified. Our goal is to compare various visualization modalities for catheter insertion in external ventricular drain and ventricular shunt procedures. We investigate two AR approaches: (1) 2D approaches consisting of a smartphone and a 2D window visualized through an OST (Microsoft HoloLens 2), and (2) 3D approaches consisting of a fully aligned patient model and a model that is adjacent to the patient and is rotationally aligned using an OST. 32 participants joined this study. For each visualization approach, participants were asked to perform five insertions after which they filled NASA-TLX and SUS forms. Moreover, the position and orientation of the needle with respect to the planning during the insertion task were collected. The results show that participants achieved a better insertion performance significantly under 3D visualizations, and the NASA-TLX and SUS forms reflected the preference of participants for these approaches compared to 2D approaches.
C1 [Benmahdjoub, Mohamed; Thabit, Abdullah; Niessen, Wiro J.; van Walsum, Theo] Erasmus MC, Dept Radiol & Nucl Med, Biomed Imaging Grp Rotterdam, NL-0026 GE Rotterdam, Netherlands.
   [Benmahdjoub, Mohamed; Thabit, Abdullah; Wolvius, Eppo B.] Erasmus MC, Dept Oral & Maxillofacial Surg, NL-3015 GE Rotterdam, Netherlands.
   [van Veelen, Marie-Lise C.] Erasmus MC, Dept Neurosurg, NL-3015 GE Rotterdam, Netherlands.
   [Niessen, Wiro J.] Delft Univ Technol, Fac Appl Sci, Dept Imaging Phys, Delft, Netherlands.
C3 Erasmus University Rotterdam; Erasmus MC; Erasmus University Rotterdam;
   Erasmus MC; Erasmus University Rotterdam; Erasmus MC; Delft University
   of Technology
RP Benmahdjoub, M (corresponding author), Erasmus MC, Dept Radiol & Nucl Med, Biomed Imaging Grp Rotterdam, NL-0026 GE Rotterdam, Netherlands.; Benmahdjoub, M (corresponding author), Erasmus MC, Dept Oral & Maxillofacial Surg, NL-3015 GE Rotterdam, Netherlands.
EM benmahdjoub@erasmusmc.nl
RI Benmahdjoub, Mohamed/HNS-5612-2023; van Walsum, Theo/ABM-1912-2022; van
   veelen, marie-lise/KHU-7942-2024
OI van Walsum, Theo/0000-0001-8257-7759; Benmahdjoub,
   Mohamed/0000-0003-1830-2480; van veelen, marie-lise/0000-0001-8507-2676
CR AlAzri A, 2017, ACTA NEUROCHIR, V159, P1399, DOI 10.1007/s00701-017-3201-5
   Azimi Ehsan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P65, DOI 10.1007/978-3-030-59716-0_7
   Badiali G, 2014, J CRANIO MAXILL SURG, V42, P1970, DOI 10.1016/j.jcms.2014.09.001
   Benmahdjoub M, 2021, INT J ORAL MAX SURG, V50, P969, DOI 10.1016/j.ijom.2020.11.015
   Benmahdjoub M, 2022, VIRTUAL REAL-LONDON, V26, P1637, DOI 10.1007/s10055-022-00653-3
   Benmahdjoub M, 2021, IEEE T VIS COMPUT GR, V27, P4332, DOI 10.1109/TVCG.2021.3106506
   Blender, About us
   BRADLEY JV, 1958, J AM STAT ASSOC, V53, P525, DOI 10.2307/2281872
   Butaslac IM III, 2023, IEEE T VIS COMPUT GR, V29, P5062, DOI 10.1109/TVCG.2022.3201120
   Chai FY, 2013, TURK NEUROSURG, V23, P561, DOI 10.5137/1019-5149.JTN.5724-12.1
   Cleary K, 2010, ANNU REV BIOMED ENG, V12, P119, DOI 10.1146/annurev-bioeng-070909-105249
   López WOC, 2019, CLIN NEUROL NEUROSUR, V177, P6, DOI 10.1016/j.clineuro.2018.11.018
   Debenham P., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P249, DOI 10.1109/ISMAR.2011.6092400
   Deng WW, 2014, STEREOT FUNCT NEUROS, V92, P17, DOI 10.1159/000354816
   Doughty M, 2022, J IMAGING, V8, DOI 10.3390/jimaging8070203
   García-Mato D, 2021, COMP M BIO BIO E-IV, V9, P392, DOI 10.1080/21681163.2020.1834876
   Gavaghan K, 2012, INT J COMPUT ASS RAD, V7, P547, DOI 10.1007/s11548-011-0660-7
   Halbig A, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.837616
   HART S G, 1988, P139
   Heinrich F, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P260, DOI 10.1109/VR51125.2022.00045
   Heinrich F, 2020, IEEE T VIS COMPUT GR, V26, P3568, DOI 10.1109/TVCG.2020.3023637
   Hersh A, 2021, HSS J, V17, P351, DOI 10.1177/15563316211028595
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Incekara F, 2018, WORLD NEUROSURG, V118, pE422, DOI 10.1016/j.wneu.2018.06.208
   Ingrassia PL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14910
   Iqbal H, 2021, J BIOMED INFORM, V120, DOI 10.1016/j.jbi.2021.103841
   Jiang TR, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36457-2
   Jones A, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P267
   Jordan P.W., 1996, Usability Evaluation in Industry
   Kahle KT, 2016, LANCET, V387, P788, DOI 10.1016/S0140-6736(15)60694-8
   Kandasamy J, 2011, WORLD NEUROSURG, V75, P155, DOI 10.1016/j.wneu.2010.10.025
   Kenngott HG, 2015, LANGENBECK ARCH SURG, V400, P273, DOI 10.1007/s00423-015-1289-8
   Kolstee Y., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P49, DOI 10.1109/ISMAR-AMH.2011.6093656
   Konik D., US
   Kwon HB, 2018, ACTA ODONTOL SCAND, V76, P497, DOI 10.1080/00016357.2018.1441437
   Larsen CR, 2009, BMJ-BRIT MED J, V338, DOI 10.1136/bmj.b1802
   Lewis J. R., 2011, ALIGNING INTERPUPILL
   Li Y, 2019, J NEUROSURG, V131, P1599, DOI 10.3171/2018.4.JNS18124
   Lin CY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P3, DOI 10.1109/ISMAR-Adjunct.2018.00021
   Liu K, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-88860-x
   Long DJ, 2021, CARDIOVASC INTER RAD, V44, P774, DOI 10.1007/s00270-020-02760-7
   Mahan M, 2013, J CLIN NEUROSCI, V20, P1718, DOI 10.1016/j.jocn.2013.03.005
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P217, DOI [10.1109/ISMAR50242.2020.00045, 10.1109/1SMA1R50242.2020.00045]
   Martin-Gomez A, 2020, INT SYM MIX AUGMENT, P207, DOI [10.1109/1SMA1R50242.2020.00044, 10.1109/ISMAR50242.2020.00044]
   Meola A, 2017, NEUROSURG REV, V40, P537, DOI 10.1007/s10143-016-0732-9
   mevislab, about us
   Meyerbröker K, 2021, CLIN PSYCHOL PSYCHOT, V28, P466, DOI 10.1002/cpp.2623
   Palumbo MC, 2022, LECT NOTES COMPUT SC, V13437, P147, DOI 10.1007/978-3-031-16449-1_15
   Park BJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75676-4
   Peillard E, 2019, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2019.00-13
   Pellegrino G, 2019, BMC ORAL HEALTH, V19, DOI 10.1186/s12903-019-0853-y
   Preece D. A., 2014, AM CANC SOC, DOI [10.1002/9781118445112.stat00867, DOI 10.1002/9781118445112.STAT00867]
   Qian L, 2017, INT J COMPUT ASS RAD, V12, P901, DOI 10.1007/s11548-017-1564-y
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Rae E, 2018, PROC SPIE, V10576, DOI 10.1117/12.2293680
   Reinschluessel AV, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.821060
   Scavo G, 2015, AMB INTELL SMART ENV, V19, P236, DOI 10.3233/978-1-61499-530-2-236
   Sielhorst T, 2008, J DISP TECHNOL, V4, P451, DOI 10.1109/JDT.2008.2001575
   Suess O, 2001, ACTA NEUROCHIR, V143, P927, DOI 10.1007/s007010170023
   Sveistrup Heidi, 2004, J Neuroeng Rehabil, V1, P10, DOI 10.1186/1743-0003-1-10
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Tabrizi LB, 2015, J NEUROSURG, V123, P206, DOI 10.3171/2014.9.JNS141001
   Tang ZN, 2022, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.715484
   Thabit A, 2022, INT J COMPUT ASS RAD, V17, P1453, DOI 10.1007/s11548-022-02634-y
   Tully HM, 2014, EUR J MED GENET, V57, P359, DOI 10.1016/j.ejmg.2014.06.002
   van de Woestijne PC, 2021, WORLD J PEDIATR CONG, V12, P765, DOI 10.1177/21501351211045064
   Van Gestel F, 2021, NEUROSURG FOCUS, V51, DOI 10.3171/2021.5.FOCUS21215
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   Vuforia, About us
   Webel S., 2011, BIO Web of Conferences, V1, P97, DOI DOI 10.1051/BIOCONF/20110100097
   Woll R., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH 2011), P37, DOI 10.1109/ISMAR-AMH.2011.6093654
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Xuetong Sun, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3365678
   Yasuda J, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1921
   Zinser MJ, 2013, BRIT J ORAL MAX SURG, V51, P827, DOI 10.1016/j.bjoms.2013.06.014
NR 76
TC 5
Z9 5
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2434
EP 2445
DI 10.1109/TVCG.2023.3247042
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1GV3
UT WOS:000966284100001
PM 37027733
OA Green Published
DA 2024-11-06
ER

PT J
AU Martin, D
   Sun, X
   Gutierrez, D
   Masia, B
AF Martin, Daniel
   Sun, Xin
   Gutierrez, Diego
   Masia, Belen
TI A Study of Change Blindness in Immersive Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Blindness; Visualization; Complexity theory; Three-dimensional displays;
   Observers; Systematics; Media; Virtual reality; change blindness; visual
   working memory; attention
ID SHORT-TERM-MEMORY; VISUAL MEMORY; ATTENTION; CAPACITY
AB Human performance is poor at detecting certain changes in a scene, a phenomenon known as change blindness. Although the exact reasons of this effect are not yet completely understood, there is a consensus that it is due to our constrained attention and memory capacity: We create our own mental, structured representation of what surrounds us, but such representation is limited and imprecise. Previous efforts investigating this effect have focused on 2D images; however, there are significant differences regarding attention and memory between 2D images and the viewing conditions of daily life. In this work, we present a systematic study of change blindness using immersive 3D environments, which offer more natural viewing conditions closer to our daily visual experience. We devise two experiments; first, we focus on analyzing how different change properties (namely type, distance, complexity, and field of view) may affect change blindness. We then further explore its relation with the capacity of our visual working memory and conduct a second experiment analyzing the influence of the number of changes. Besides gaining a deeper understanding of the change blindness effect, our results may be leveraged in several VR applications such as redirected walking, games, or even studies on saliency or attention prediction.
C1 [Martin, Daniel; Gutierrez, Diego; Masia, Belen] Univ Zaragoza, I3A, Zaragoza, Spain.
   [Sun, Xin] Adobe Res, San Jose, CA USA.
C3 University of Zaragoza; Adobe Systems Inc.
RP Martin, D (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM danims@unizar.es
RI Martin, Daniel/KLZ-9356-2024
OI Martin, Daniel/0000-0002-0073-6398; Masia, Belen/0000-0003-0060-7278
FU European Research Council (ERC) under the EU's Horizon 2020 research and
   innovation programme (project CHAMELEON) [682080]; PRIME project
   (MSCA-ITN) [956585]; Spain's Agencia Estatal de Investigacion
   [PID2019-105004GB-I00]; Gobierno de Aragon (2020-2024) predoctoral grant
FX This work has received funding from the European Research Council (ERC)
   under the EU's Horizon 2020 research and innovation programme (project
   CHAMELEON, Grant no. 682080). This project has also received funding
   from the PRIME project (MSCA-ITN, grant agreement No. 956585), and from
   the Spain's Agencia Estatal de Investigacion (project
   PID2019-105004GB-I00). Additionally, Daniel Martin was supported by a
   Gobierno de Aragon (2020-2024) predoctoral grant.
CR Alghofaili R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P464, DOI [10.1109/vr.2019.8797816, 10.1109/VR.2019.8797816]
   Alvarez GA, 2004, PSYCHOL SCI, V15, P106, DOI 10.1111/j.0963-7214.2004.01502006.x
   Attwood JE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00151
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Bays PM, 2009, J VISION, V9, DOI 10.1167/9.10.7
   Berdun EB, 2022, COMPUT GRAPH-UK, V106, P200, DOI 10.1016/j.cag.2022.06.002
   Bergmann K, 2016, PSYCHOL RES-PSYCH FO, V80, P660, DOI 10.1007/s00426-015-0669-6
   Bionumbers, AV DUR SINGL EYE BLI
   Brady TF, 2011, J VISION, V11, DOI 10.1167/11.5.4
   Escamilla JC, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10080552
   Chrastil ER, 2012, PSYCHON B REV, V19, P1, DOI 10.3758/s13423-011-0182-x
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Fatt Irving, 2013, PHYSL EYE INTRO VEGE
   H. Taschenbuch Verlag Schiffman, 2001, SENSATION PERCEPTION
   Halford GS, 2007, TRENDS COGN SCI, V11, P236, DOI 10.1016/j.tics.2007.04.001
   Hayhoe MM, 2011, WIRES COGN SCI, V2, P158, DOI 10.1002/wcs.113
   Hollingworth A, 2006, J EXP PSYCHOL LEARN, V32, P58, DOI 10.1037/0278-7393.32.1.58
   Hollingworth A, 2002, J EXP PSYCHOL HUMAN, V28, P113, DOI 10.1037//0096-1523.28.1.113
   Hollingworth A, 2007, J EXP PSYCHOL HUMAN, V33, P31, DOI 10.1037/0096-1523.33.1.31
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim D., 2022, PREPRINT
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Li CL, 2016, J VISION, V16, DOI 10.1167/16.8.9
   Lohse AL, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809587
   Luck SJ, 1997, NATURE, V390, P279, DOI 10.1038/36846
   Ma LQ, 2013, IEEE T VIS COMPUT GR, V19, P1808, DOI 10.1109/TVCG.2013.99
   Malpica S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69135-3
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Mazza V, 2005, PSYCHOL RES-PSYCH FO, V69, P201, DOI 10.1007/s00426-004-0174-9
   Moses R. A., 1975, ADLERS PHYSL EYE CLI
   Perera SL, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401052
   Pertzov Y, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048214
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Simons DJ, 1997, TRENDS COGN SCI, V1, P261, DOI 10.1016/S1364-6613(97)01080-2
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Smith DT, 2008, PERCEPT PSYCHOPHYS, V70, P489, DOI 10.3758/PP.70.3.489
   Steinicke F, 2011, IEEE T VIS COMPUT GR, V17, P1223, DOI 10.1109/TVCG.2011.41
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Turatto M, 2002, COGNITION, V84, pB1, DOI 10.1016/S0010-0277(02)00016-1
   Ungerleider LG, 1998, P NATL ACAD SCI USA, V95, P883, DOI 10.1073/pnas.95.3.883
   Vasser M., 2015, PREPRINT
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 48
TC 5
Z9 5
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2446
EP 2455
DI 10.1109/TVCG.2023.3247102
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1ZQ8
UT WOS:000966776600001
PM 37027712
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Zhou, KL
   Cai, RZ
   Ma, Y
   Tan, QQ
   Wang, XN
   Li, JG
   Shum, HPH
   Li, FWB
   Jin, S
   Liang, XH
AF Zhou, Kanglei
   Cai, Ruizhi
   Ma, Yue
   Tan, Qingqing
   Wang, Xinning
   Li, Jianguo
   Shum, Hubert P. H.
   Li, Frederick W. B.
   Jin, Song
   Liang, Xiaohui
TI A Video-Based Augmented Reality System for Human-in-the-Loop Muscle
   Strength Assessment of Juvenile Dermatomyositis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Muscles; Medical services; Animation; Visualization; Pediatrics; Medical
   diagnostic imaging; Human in the loop; Action Quality Assessment;
   Augmented Reality; Human-in-the-Loop System; Juvenile Dermatomyositis
ID CHILDREN
AB As the most common idiopathic inflammatory myopathy in children, juvenile dermatomyositis (JDM) is characterized by skin rashes and muscle weakness. The childhood myositis assessment scale (CMAS) is commonly used to measure the degree of muscle involvement for diagnosis or rehabilitation monitoring. On the one hand, human diagnosis is not scalable and may be subject to personal bias. On the other hand, automatic action quality assessment (AQA) algorithms cannot guarantee 100% accuracy, making them not suitable for biomedical applications. As a solution, we propose a video-based augmented reality system for human-in-the-loop muscle strength assessment of children with JDM. We first propose an AQA algorithm for muscle strength assessment of JDM using contrastive regression trained by a JDM dataset. Our core insight is to visualize the AQA results as a virtual character facilitated by a 3D animation dataset, so that users can compare the real-world patient and the virtual character to understand and verify the AQA results. To allow effective comparisons, we propose a video-based augmented reality system. Given a feed, we adapt computer vision algorithms for scene understanding, evaluate the optimal way of augmenting the virtual character into the scene, and highlight important parts for effective human verification. The experimental results confirm the effectiveness of our AQA algorithm, and the results of the user study demonstrate that humans can more accurately and quickly assess the muscle strength of children using our system.
C1 [Liang, Xiaohui] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Liang, Xiaohui] Zhongguancun Lab, Beijing, Peoples R China.
   [Zhou, Kanglei; Cai, Ruizhi; Ma, Yue] Beihang Univ, Beijing, Peoples R China.
   [Tan, Qingqing; Wang, Xinning; Li, Jianguo] Capital Inst Pediat, Childrens Hosp, Beijing, Peoples R China.
   [Shum, Hubert P. H.; Li, Frederick W. B.] Univ Durham, Durham, England.
   [Jin, Song] Beijing Diannaite Med Technol Co Ltd, Beijing, Peoples R China.
C3 Beihang University; Zhongguancun Laboratory; Beihang University; Capital
   Institute of Pediatrics (CIP); Durham University
RP Liang, XH (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Liang, XH (corresponding author), Zhongguancun Lab, Beijing, Peoples R China.
EM zhoukanglei@qq.com; liang_xiaohui@buaa.edu.cn
RI Li, Frederick/AAM-6662-2021; Tan, Qing-Qing/L-3360-2018; Shum, Hubert P.
   H./E-8060-2015
OI Li, Frederick W. B./0000-0002-4283-4228; Zhou,
   Kanglei/0000-0002-4660-581X; Shum, Hubert P. H./0000-0001-5651-6039;
   liang, xiaohui/0000-0001-6351-2538
FU National Natural Science Foundation of China [62272019]
FX This work was supported by the National Natural Science Foundation of
   China (Project Number: 62272019).
CR Antunes M, 2016, LECT NOTES COMPUT SC, V9914, P115, DOI 10.1007/978-3-319-48881-3_9
   Bai Yang, 2022, arXiv
   Batthish M, 2011, CURR RHEUMATOL REP, V13, P216, DOI 10.1007/s11926-011-0167-9
   Buchanan E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P797, DOI 10.1109/VRW55335.2022.00254
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LY, 2022, EXPERT SYST APPL, V210, DOI 10.1016/j.eswa.2022.118361
   Chen T, 2020, PR MACH LEARN RES, V119
   Cidota MA, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P144, DOI 10.1109/ISMAR.2017.31
   Dhar P, 2021, MED EDUC ONLINE, V26, DOI 10.1080/10872981.2021.1953953
   Doughty H, 2019, PROC CVPR IEEE, P7854, DOI 10.1109/CVPR.2019.00805
   Doughty H, 2018, PROC CVPR IEEE, P6057, DOI 10.1109/CVPR.2018.00634
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fu Y, 2022, NEUROCOMPUTING
   Gorgos D., 2004, DERMATOL NURS, V16, P461
   Hochreiter J, 2015, P IEEE VIRT REAL ANN, P69, DOI 10.1109/VR.2015.7223326
   Hombeck J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P514, DOI 10.1109/VR51125.2022.00071
   Hutchinson C., 2020, WORLD J PEDIATR, V16
   Jain H, 2021, IEEE T CIRC SYST VID, V31, P2260, DOI 10.1109/TCSVT.2020.3017727
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Liu DC, 2021, PROC CVPR IEEE, P9517, DOI 10.1109/CVPR46437.2021.00940
   Lovell DJ, 1999, ARTHRITIS RHEUM-US, V42, P2213, DOI 10.1002/1529-0131(199910)42:10<2213::AID-ANR25>3.0.CO;2-8
   Lugaresi C, 2019, Arxiv, DOI [arXiv:1906.08172, 10.48550/arXiv.1906.08172, DOI 10.48550/ARXIV.1906.08172]
   McCann LJ, 2006, RHEUMATOLOGY, V45, P1255, DOI 10.1093/rheumatology/kel099
   Mentis H.M., 2022, 2022 IEEE C VIRT REA, P437
   ODDIS CV, 1990, J RHEUMATOL, V17, P1329
   Pachman LM, 2021, CURR TREAT OPT RHEUM, V7, P39, DOI 10.1007/s40674-020-00168-5
   Paiement Adeline., 2014, British Machine Vision Conference, P153
   Parmar P, 2019, PROC CVPR IEEE, P304, DOI 10.1109/CVPR.2019.00039
   Parmar P, 2017, IEEE COMPUT SOC CONF, P76, DOI 10.1109/CVPRW.2017.16
   Parmar P, 2016, IEEE ENG MED BIO, P2241, DOI 10.1109/EMBC.2016.7591175
   Pears M, 2020, SCOT MED J, V65, P112, DOI 10.1177/0036933020956317
   PELKONEN PM, 1994, J RHEUMATOL, V21, P2143
   Phelan I, 2015, P IEEE VIRT REAL ANN, P353, DOI 10.1109/VR.2015.7223441
   Ramanan AV, 2002, RHEUM DIS CLIN N AM, V28, P833, DOI 10.1016/S0889-857X(02)00024-8
   Renu N., 2021, J. Market. Manag., V9, DOI 10.15640/jmm.v9n2a5
   Robles M, 2022, IEEE T VIS COMPUT GR, V28, P2168, DOI 10.1109/TVCG.2022.3150489
   Singla A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P198, DOI 10.1109/VR50410.2021.00041
   Tang YS, 2020, PROC CVPR IEEE, P9836, DOI 10.1109/CVPR42600.2020.00986
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang QS, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P504, DOI 10.1109/VR51125.2022.00070
   Wang SL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4902, DOI 10.1145/3474085.3475438
   Wang YY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P373, DOI 10.1109/VR50410.2021.00060
   Wetzel R, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P412, DOI 10.1109/ISMAR-Adjunct.2019.00044
   Xu AC, 2022, PROC CVPR IEEE, P3222, DOI 10.1109/CVPR52688.2022.00323
   Xu J., 2022, arXiv
   Xu W, 2014, PEDIATRICS, V134, P1045, DOI 10.1542/peds.2014-1377
   Yu X., 2021, P IEEECVF INT C COMP, P7919
   Zafar A., 2021, AUGMENTED REALITY HE
   Zhou KL, 2022, NEURAL PROCESS LETT, V54, P5457, DOI 10.1007/s11063-022-10870-1
NR 50
TC 10
Z9 10
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2456
EP 2466
DI 10.1109/TVCG.2023.3247092
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1SV9
UT WOS:000966597900001
PM 37027743
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Weissker, T
   Bimberg, P
   Gokhale, AS
   Kuhlen, T
   Froehlich, B
AF Weissker, Tim
   Bimberg, Pauline
   Gokhale, Aalok Shashidhar
   Kuhlen, Torsten
   Froehlich, Bernd
TI Gaining the High Ground: Teleportation to Mid-Air Targets in Immersive
   Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; 3D User Interfaces; 3D Navigation; Head-Mounted
   Display; Flying; Mid-Air Navigation
AB Most prior teleportation techniques in virtual reality are bound to target positions in the vicinity of selectable scene objects. In this paper, we present three adaptations of the classic teleportation metaphor that enable the user to travel to mid-air targets as well. Inspired by related work on the combination of teleports with virtual rotations, our three techniques differ in the extent to which elevation changes are integrated into the conventional target selection process. Elevation can be specified either simultaneously, as a connected second step, or separately from horizontal movements. A user study with 30 participants indicated a trade-off between the simultaneous method leading to the highest accuracy and the two-step method inducing the lowest task load as well as receiving the highest usability ratings. The separate method was least suitable on its own but could serve as a complement to one of the other approaches. Based on these findings and previous research, we define initial design guidelines for mid-air navigation techniques.
C1 [Weissker, Tim; Kuhlen, Torsten] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
   [Bimberg, Pauline] Univ Trier, Human Comp Interact Grp, Trier, Germany.
   [Gokhale, Aalok Shashidhar; Froehlich, Bernd] Bauhaus Univ Weimar, Virtual Real & Visualizat Res Grp, Weimar, Germany.
C3 RWTH Aachen University; Universitat Trier; Bauhaus-Universitat Weimar
RP Weissker, T (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM me@tim-weissker.de; bimberg@uni-trier.de; aaloksg@gmail.com;
   kuhlen@vr.rwth-aachen.de; bernd.froehlich@uni-weimar.de
RI ; Kuhlen, Torsten/A-1059-2017
OI Weissker, Tim/0000-0001-9119-811X; Kuhlen, Torsten/0000-0003-2144-4367;
   Froehlich, Bernd/0000-0002-9439-1959
FU Ministry of Economic Affairs, Industry, Climate Action and Energy of the
   State of North Rhine-Westphalia [005-2108-0055]; German Ministry of
   Education and Research (BMBF) [16SV8716]; Thuringian Ministry of
   Economic Affairs, Science and Digital Society (TMWDDG) [5575/10-5]
FX We would like to thank Daniel Ruppfor his diligent assistance in
   conducting a large part of the user studies for this paper. This work
   has mainly received funding from the Ministry of Economic Affairs,
   Industry, Climate Action and Energy of the State of North
   Rhine-Westphalia under grant 005-2108-0055 (projectVITAMINE_5G). This
   work was also partially funded by the German Ministry of Education and
   Research (BMBF) under grant 16SV8716 (projectGoethe-Live-3D)and the
   Thuringian Ministry of Economic Affairs, Science and Digital Society
   (TMWDDG) under grant 5575/10-5 (project MetaReal)
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.0-178, 10.1109/VRW50115.2020.00098]
   Bimberg T., 2021, P 27 ACM S VIRT REAL, DOI [10.1145/3489849.34898931,2,9[4]D.A., DOI 10.1145/3489849.34898931,2,9[4]D.A]
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Carruth DW, 2017, 2017 15TH IEEE INTERNATIONAL CONFERENCE ON EMERGING ELEARNING TECHNOLOGIES AND APPLICATIONS (ICETA 2017), P75
   Chen F., 2021, IEEE T VIS COMPUT GR, DOI 10.1109/TVCG.2021.30990122
   Chengyuan Lai, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P15, DOI 10.1109/3DUI.2015.7131719
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cmentowski S, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P287, DOI 10.1145/3311350.3347183
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Dorado JL, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P47, DOI 10.1109/3DUI.2014.6798841
   Drogemuller A., 2018, 2018 International Symposium on Big Data Visual and Immersive Analytics (BDVA), P1, DOI DOI 10.1109/BDVA.2018.8533895
   Elvezio C, 2017, P IEEE VIRT REAL ANN, P475, DOI 10.1109/VR.2017.7892386
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Griffin NN, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364243
   Grossman Tovi, 2006, P 19 ANN ACM S US IN, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Hachet Martin., 2008, Proceedings ACM symposium on Virtual Reality Software and Technology, P47
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Kuliga SF, 2015, COMPUT ENVIRON URBAN, V54, P363, DOI 10.1016/j.compenvurbsys.2015.09.006
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee P., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189612[30]A., DOI 10.1145/3385956.3418961]
   Matviienko F., 2022, P 2022 CHI C HUM FAC, DOI [10.1145/3491102.35019832,9[31]D, DOI 10.1145/3491102.35019832,9[31]D]
   Medeiros D, 2020, IEEE T VIS COMPUT GR, V26, P2793, DOI 10.1109/TVCG.2019.2905200
   Pausch R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P193, DOI 10.1145/237170.237257
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riecke Bernhard E., 2022, SIGGRAPH '22 Immersive Pavilion: Special Interest Group on Computer Graphics and Interactive Techniques Conference Immersive Pavilion, DOI 10.1145/3532834.3536211
   Robinett W., 1992, P 1992 S INT 3D GRAP, P189, DOI DOI 10.1145/147156.147201
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Slater M., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P45
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Suma S., 2007, 2007 IEEE S 3D US IN, DOI [10.1109/3DUI.2007.3407882[42]M, DOI 10.1109/3DUI.2007.3407882[42]M]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vasylevska K., 2014, CHALLENGING PRESENCE, P205
   Weissker Tim, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2524, DOI 10.1109/TVCG.2021.3067756
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wolf D, 2021, Arxiv, DOI arXiv:2106.04257
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zhang N., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189493[49]D, DOI 10.1145/3385956.3418949]
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
NR 47
TC 6
Z9 6
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2467
EP 2477
DI 10.1109/TVCG.2023.3247114
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0KN8
UT WOS:000965703400001
PM 37027708
DA 2024-11-06
ER

PT J
AU Wang, JL
   Shi, RK
   Zheng, WX
   Xie, WJ
   Kao, DMN
   Liang, HN
AF Wang, Jialin
   Shi, Rongkai
   Zheng, Wenxuan
   Xie, Weijie
   Kao, Dominic
   Liang, Hai-Ning
TI Effect of Frame Rate on User Experience, Performance, and Simulator
   Sickness in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Games; User experience; Visualization; Task analysis; Monitoring;
   Hardware; Virtual reality
AB The refresh rate of virtual reality (VR) head-mounted displays (HMDs) has been growing rapidly in recent years because of the demand to provide higher frame rate content as it is often linked with a better experience. Today's HMDs come with different refresh rates ranging from 20Hz to 180Hz, which determines the actual maximum frame rate perceived by users' naked eyes. VR users and content developers often face a choice because having high frame rate content and the hardware that supports it comes with higher costs and other trade-offs (such as heavier and bulkier HMDs). Both VR users and developers can choose a suitable frame rate if they are aware of the benefits of different frame rates in user experience, performance, and simulator sickness (SS). To our knowledge, limited research on frame rate in VR HMDs is available. In this paper, we aim to fill this gap and report a study with two VR application scenarios that compared four of the most common and highest frame rates currently available (60, 90, 120, and 180 frames per second (fps)) to explore their effect on users' experience, performance, and SS symptoms. Our results show that 120fps is an important threshold for VR. After 120fps, users tend to feel lower SS symptoms without a significant negative effect on their experience. Higher frame rates (e.g., 120 and 180fps) can ensure better user performance than lower rates. Interestingly, we also found that at 60fps and when users are faced with fast-moving objects, they tend to adopt a strategy to compensate for the lack of visual details by predicting or filling the gaps to try to meet the performance needs. At higher fps, users do not need to follow this compensatory strategy to meet the fast response performance requirements.
C1 [Wang, Jialin; Shi, Rongkai; Zheng, Wenxuan; Xie, Weijie; Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
   [Kao, Dominic] Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN USA.
C3 Xi'an Jiaotong-Liverpool University; Purdue University System; Purdue
   University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
EM haining.liang@xjtlu.edu.cn
RI Wang, Jialin/KFS-9745-2024
OI Wang, Jialin/0000-0002-1990-1293; Liang, Hai-Ning/0000-0003-3600-8955
FU Key Program Special Fund at XJTLU [KSF-A-03]; National Natural Science
   Foundation of China [62272396]; XJTLU Research Development Fund
   [RDF-17-01-54, RDF-19-02-47]
FX The authors thank the participants who volunteered their time to join
   the experiment. We also thank the reviewers whose insightful comments
   and suggestions helped improve our paper. This work was partially funded
   by the Key Program Special Fund at XJTLU (#KSF-A-03), National Natural
   Science Foundation of China (#62272396), and XJTLU Research Development
   Fund (#RDF-17-01-54; #RDF-19-02-47).
CR ADAM JA, 1993, IEEE SPECTRUM, V30, P22, DOI 10.1109/6.237580
   Aker Ç, 2016, LECT NOTES COMPUT SC, V9747, P229, DOI 10.1007/978-3-319-40355-7_22
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   APTEKER RT, 1995, IEEE MULTIMEDIA, V2, P32, DOI 10.1109/93.410510
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   BRYSON S, 1993, P SOC PHOTO-OPT INS, V1915, P155, DOI 10.1117/12.157034
   Chaplin P Kay Nottingham, 2011, NASN Sch Nurse, V26, P221
   Chen H, 2022, IEEE CONF COMPU INTE, P80, DOI 10.1109/CoG51982.2022.9893678
   Chen JYC, 2007, IEEE T SYST MAN CY A, V37, P1063, DOI 10.1109/TSMCA.2007.904779
   Claypool M, 2006, PROC SPIE, V6071, DOI 10.1117/12.648609
   Coutu Y., 2020, MON NOT R ASTRON SOC, P437
   Davis J, 2015, SCI REP-UK, V5, DOI 10.1038/srep07861
   Duinkharjav P., 2022, ACM T GRAPHIC, V41, DOI [10.1145/3528223.3530055[13]H.W., DOI 10.1145/3528223.3530055[13]H.W]
   FROWEIN HW, 1991, IEEE J SEL AREA COMM, V9, P611, DOI 10.1109/49.81956
   IJsselsteijn W. A., 2013, Eindhoven: Technische Universiteit Eindhoven, V46
   Johnson D, 2018, INT J HUM-COMPUT ST, V118, P38, DOI 10.1016/j.ijhcs.2018.05.003
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Khademi M., 2014, Conference on Human Factors in Computing Systems - Proceedings, (February 2015), P1663, DOI [10.1145/2559206.2581203, DOI 10.1145/2559206.2581203]
   Knoche H., 2005, CHI 05 EXTENDED ABST, P1553
   Law ELC, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P257, DOI 10.1145/3242671.3242683
   Liu SC, 2020, PSYCHOL SPORT EXERC, V51, DOI 10.1016/j.psychsport.2020.101759
   Lum Heather C., 2018, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V62, P1474, DOI 10.1177/1541931218621334
   Mankowska ND, 2021, MEDICINA-LITHUANIA, V57, DOI 10.3390/medicina57101096
   McKenna D., 1992, Presence: Teleoperators and Virtual Environments, V1, P421
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Monteiro D, 2020, INT SYM MIX AUGMENT, P713, DOI 10.1109/ISMAR50242.2020.00102
   Monteiro Diego., 2021, 2021 IEEE Conference on Games (CoG), P1
   Murakami H., 2021, INT C NETWORK BASED, P283
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Sabet S.S., 2019, Proceedings of the 11th ACM Workshop on Immersive Mixed and Virtual Environment Systems, P22
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Shi RK, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451255
   Sousa A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01030
   Spjut J, 2021, Arxiv, DOI arXiv:2105.10498
   Spjut J, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P110, DOI 10.1145/3355088.3365170
   Wang JL, 2023, IEEE T GAMES, V15, P252, DOI 10.1109/TG.2022.3178539
   Wang R. Shi, 2022, P ACM COMPUT GRAPH, V5, DOI [10.1145/3522610[38]C, DOI 10.1145/3522610[38]C]
   Ware C., 1994, ACM T COMPUT-HUM INT, V4, P331, DOI [10.1145/198425.198426, DOI 10.1145/198425.198426[39]B, DOI 10.1145/198425.198426]
   Watson B, 1998, HUM FACTORS, V40, P403, DOI 10.1518/001872098779591287
   Weber LF, 2006, IEEE T PLASMA SCI, V34, P268, DOI 10.1109/TPS.2006.872440
   Xiao L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392376
   Yoo S, 2017, P 2017 CHI C HUM FAC, P3050, DOI [10.1145/3027063.3053203doi:10.1145/3027063.305320380, DOI 10.1145/3027063.3053203DOI:10.1145/3027063.305320380, 10.1145/3027063, DOI 10.1145/3027063.3053203]
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 43
TC 27
Z9 27
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2478
EP 2488
DI 10.1109/TVCG.2023.3247057
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C9ZH7
UT WOS:000965410300001
PM 37027727
DA 2024-11-06
ER

PT J
AU Zytko, D
   Chan, J
AF Zytko, Douglas
   Chan, Jonathan
TI The Dating Metaverse: Why We Need to Design for Consent in Social VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Metaverse; Mobile applications; Social factors; Safety; Avatars; X
   reality; Planets; Consent; dating; social VR; social virtual reality;
   metaverse; harm; harassment; participatory design
AB This paper presents a participatory design study about how consent to interaction and observation of other users can be supported in social VR. We use emerging VR dating applications, colloquially called the dating metaverse, as context for study of harm-mitigative design structures in social VR given the evidence of harms that occur through dating apps and general social VR applications individually, and the harms that may occur through their convergence. Through design workshops with potential dating metaverse users in the Midwest United States (n=18) we elucidate nonconsensual experiences that should be prevented and participant-created designs for informing and exchanging consent in VR. We position consent as a valuable lens for which to design preventative solutions to harm in social VR by reframing harm as unwanted experiences that happen because of the absence of mechanics to support users in giving and denying agreement to a virtual experience before it occurs.
C1 [Zytko, Douglas; Chan, Jonathan] Oakland Univ, Rochester, MI 48309 USA.
C3 Oakland University
RP Zytko, D (corresponding author), Oakland Univ, Rochester, MI 48309 USA.
EM zytko@oakland.edu
FU U.S. National Science Foundation [IIS-2211896]
FX The authors wish to thank Jesse Brown and Rachel Yang for their
   contributions to data collection. This work is partially supported by
   the U.S. National Science Foundation under Grant No. IIS-2211896.
CR Albury K., 2019, Safety, risk and wellbeing on dating apps: Final report, DOI DOI 10.25916/5DD324C1B33BB
   AltspaceVR, 2022, ALTSP
   Anderson M., 2020, VIRTUES DOWNSIDES ON, P2
   [Anonymous], R ROOM REC ROOM 123
   [Anonymous], 2021, REUTERS, P2
   Athnasious M., 2021, BUCKLE SINGLES TINDE, P1
   Bailey, 2017, AUSTR J TELECOMMUNIC, V5, P125, DOI DOI 10.18080/AJTDE.V5N4.1301,2,6
   Baker Steven, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359251
   Bardzell S., 2007, DOCILE AVATARS AESTH, P2
   Basile K., SEXUAL VIOLENCE SURV
   Belamire J., MY 1 VIRTUAL REALITY, V1, P2
   Bizouati-Kennedy Y., 2021, TINDER BUMBLE ENTER, P2
   Blackwell C, 2015, NEW MEDIA SOC, V17, P1117, DOI 10.1177/1461444814521595
   Blackwell L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P854, DOI [10.1109/vr.2019.8798165, 10.1109/VR.2019.8798165]
   Chevi D., 2021, MATCH GROUP UNVEILS, P1
   Choi EPH, 2018, SEX ABUSE-J RES TR, V30, P343, DOI 10.1177/1079063216672168
   Cortese M., 2020, DESIGNING SAFE SPACE, V1, P8
   DiFurio D., 2022, MATCH DIPS METAVERSE, P1
   Ellison N, 2006, J COMPUT-MEDIAT COMM, V11
   Fernandez Julia R., 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359328
   Freeman Guo, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512932
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Freeman G, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502082
   Frost JH, 2008, J INTERACT MARK, V22, P51, DOI 10.1002/dir.20107
   Furlo N., 2021, RETHINKING DATING AP, P1, DOI [10.1145/3462204.34817701, DOI 10.1145/3462204.34817701]
   Gilbert L, 2019, J WOMENS HEALTH, V28, P185, DOI 10.1089/jwh.2018.7191
   Gillett R, 2018, WOMEN STUD INT FORUM, V69, P212, DOI 10.1016/j.wsif.2018.04.005
   Haimson OL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376669
   HBO, 2022, WE MET VIRT REAL, P2
   Heise L, 1996, SIECUS Rep, V24, P12
   Im J, 2021, APPL COMPUTATIONAL M, DOI [10.1145/3411764.3445778, DOI 10.1145/3411764.34457781,8]
   Jonas M, 2019, CHI PLAY'19: EXTENDED ABSTRACTS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P437, DOI 10.1145/3341215.3356271
   Kolesnichenko A, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P241, DOI 10.1145/3322276.3322352
   Lang B., 2022, DATING APP M AVATARS, V1, P2
   Lee U., 2017, BUILDING CONSENTFUL, P1
   Licoppe C, 2016, NEW MEDIA SOC, V18, P2540, DOI 10.1177/1461444815589702
   Maloney Divine, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P472, DOI 10.1145/3410404.3414268
   Maloney D, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P271, DOI 10.1109/VRW52623.2021.00056
   Maloney D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P343, DOI [10.1109/VRW50115.2020.0-201, 10.1109/VRW50115.2020.00075]
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   McVeigh-Schultz J, 2018, DIS 2018: COMPANION PUBLICATION OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P289
   Miro, TAKE IDEAS BETTER BE, P3
   Morrow M. J., 2021, WHITE PAPER IEEE GLO, P2
   Muehlenhard CL, 2016, J SEX RES, V53, P457, DOI 10.1080/00224499.2016.1146651
   Muller M. J., 2007, HUMAN COMPUTER INTER, P3
   Nguyen J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376827
   Ochanji S., 2022, VR DATING APP NEVERM, P2
   Outlaw J., 2018, EXTENDED MIND BLOG, V4, P2
   Perin A, 2021, ACTA NEUROCHIR, V163, P301, DOI 10.1007/s00701-020-04303-y
   Perry TS, 2016, IEEE SPECTRUM, V53, P56, DOI 10.1109/MSPEC.2016.7367470
   Porter John R., 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134722
   Powell A, 2019, J INTERPERS VIOLENCE, V34, P3637, DOI 10.1177/0886260516672055
   Rowse J, 2020, FORENSIC SCI MED PAT, V16, P71, DOI 10.1007/s12024-019-00201-7
   Shanker S. S., 2022, arXiv
   Shapiro GK, 2017, CYBERPSYCH BEH SOC N, V20, P727, DOI 10.1089/cyber.2017.0279
   Shriram K, 2017, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2017.7892258
   Smith S., 2010, National intimate partner and sexual violence survey (NISVS)
   Strauss A.L., 1990, BASICS QUALITATIVE R
   Strengers Y., 2021, ACM, P1, DOI DOI 10.1145/3411764.34451071,8
   Sun J., 2021 IEEE C VIRTUAL, P484
   Sykownik P, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P546, DOI 10.1109/VR50410.2021.00079
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Tuerkheimer D, 2015, OHIO ST J CRIM L, V13, P8
   U. N. C. Agency, 2016, EMERGING NEW THREAT, V1, P2
   VRChat, INTR VRCHAT PLUS
   Whitlock D., 2021, GDI PODCAST VR PLATF, V1, P2
   Wiederhold BK, 2016, CYBERPSYCH BEH SOC N, V19, P297, DOI 10.1089/cyber.2016.29036.bkw
   Zamanifard S, 2019, CONFERENCE COMPANION PUBLICATION OF THE 2019 COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'19 COMPANION), P438, DOI 10.1145/3311957.3359453
   Zong J, 2022, SOC MEDIA SOC, V8, DOI 10.1177/20563051221077021
   Zytko D, 2015, ENHANCING EVALUATION, P1849, DOI [10.1145/2957276.29970301,2, DOI 10.1145/2957276.29970301,2]
   Zytko D., 2021, PROC ACM HUM COMPUT, V5, P4, DOI [10.1145/34492881,2,8, DOI 10.1145/34492881,2,8]
   Zytko D., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, P1, DOI [DOI 10.1145/341520, 10.1145/341520]
NR 72
TC 12
Z9 12
U1 6
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2489
EP 2498
DI 10.1109/TVCG.2023.3247065
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0KD9
UT WOS:000965693300001
PM 37027706
DA 2024-11-06
ER

PT J
AU Xu, XC
   Zhou, Y
   Shao, BC
   Feng, GH
   Yu, C
AF Xu, Xinchi
   Zhou, Yang
   Shao, Bingchan
   Feng, Guihuan
   Yu, Chun
TI GestureSurface: VR Sketching through Assembling Scaffold Surface with
   Non-Dominant Hand
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; gestural input; sketching
AB 3D sketching in virtual reality (VR) provides an immersive drawing experience for designs. However, due to the lack of depth perception cues in VR, scaffolding surfaces that constrain strokes to 2D are usually used as visual guides to reduce the difficulty of drawing accurate strokes. When the dominant hand is occupied by the pen tool, the efficiency of scaffolding-based sketching can be improved by using gesture input to reduce the idleness of the non-dominant hand. This paper presents GestureSurface, a bi-manual interface that uses non-dominant hand performing gestures to operate scaffolding and the other hand drawing with controller. We designed a set of non-dominant gestures to create and manipulate scaffolding surfaces, which are assembled by automatic combination based on five predefined primitive surfaces. We evaluated GestureSurface through a 20-person user study and found that the method of scaffolding-based sketching using non-dominant hand has the advantages of high efficiency and low fatigue.
C1 [Xu, Xinchi; Zhou, Yang; Shao, Bingchan; Feng, Guihuan] Nanjing Univ, Software Inst, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
   [Yu, Chun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Nanjing University; Tsinghua University
RP Feng, GH (corresponding author), Nanjing Univ, Software Inst, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM xinchi@smail.nju.edu.cn; zhouyang1997@smail.nju.edu.cn;
   bingchanshao@smail.nju.edu.cn; fenggh@nju.edu.cn; chunyu@tsinghua.edu.cn
OI Xu, Xinchi/0000-0001-8628-0418; Yu, Chun/0000-0003-2591-7993
FU National Key RD Program [2018YFB1004900]; Dandan Wang of Nanjing
   University of Information Science and Technology
FX This work is supported by National Key R&D Program (2018YFB1004900). The
   authors thank Dandan Wang of Nanjing University of Information Science
   and Technology for providing design and support for the study.
   Participants in the experiment andanonymous reviewers also contributed
   to the publication of this paper.
CR Anjul Jain A. R., 2013, INT J ADV RES COMPUT, V1, P2
   Arora R., 2018, HUMAN FACTORS COMPUT
   Arora R., 2019, USER INTERFACE SOFTW
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Barrera-Machuca Mayra D., 2020, UIST '20: 33rd Annual ACM Symposium on User Interface Software and Technology, P73, DOI 10.1145/3379350.3416190
   Blake J, 2009, IEEE-ASME T MECH, V14, P606, DOI 10.1109/TMECH.2008.2010934
   Boulabiar MI, 2011, LECT NOTES COMPUT SC, V6762, P214
   Brooke J., 2006, SUS QUICK DIRTY USAB
   De Ara'ujo BrunoR., 2012, P GRAPHICS INTERFACE, P173, DOI DOI 10.5555/2305276.2305305
   Drey T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376628
   ElKoura G., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P110
   Elsayed H., 2020, 26 ACM S VIRT REAL S, P1
   Epps J., 2006, CHI 06 EXTENDED ABST, P748, DOI 10.1145/1125451.1125601
   F. Inc, 2019, QUILL VR ILL AN TOOL
   Fuge M, 2012, COMPUT AIDED DESIGN, V44, P1020, DOI 10.1016/j.cad.2011.05.009
   Google, 2016, Tilt Brush
   Grandhi SA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P821
   HART S G, 1988, P139
   Hennessey JamesW., 2017, P I3D 17
   Holz C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P811
   Huang JM, 2018, J COMPUT INF SCI ENG, V18, DOI 10.1115/1.4040982
   Jackson B, 2016, IEEE T VIS COMPUT GR, V22, P1442, DOI 10.1109/TVCG.2016.2518099
   Jiang Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445302
   Keefe D.F., 2001, P S INT 3D GRAPH NEW, P85
   Keefe DF, 2007, IEEE T VIS COMPUT GR, V13, P1067, DOI 10.1109/TVCG.2007.1060
   Kim Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173812
   Kim Y, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P797, DOI 10.1145/2984511.2984567
   Kwan KC, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300406
   Laidlaw D. H., 1986, Computer Graphics, V20, P161, DOI 10.1145/15886.15904
   Lapides P, 2006, FIRST IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, P167
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Li Wayne, 2017, P S SKETCH BAS INT M, DOI [10.1145/3092907.3092911, DOI 10.1145/3092907.3092911]
   Li Y.X., 2019, VRIH, V56, P84, DOI DOI 10.3724/SP.J.2096-5796.2018.0006
   Liverani Alfredo, 2013, International Journal of Computer Aided Engineering and Technology, V5, P188
   Machuca MDB, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364254
   Machuca MDB, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P36, DOI 10.1145/3267782.3267786
   MCINTIRE ML, 1979, LANGUAGE, V55, P734, DOI 10.2307/413345
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Mohanty RR, 2020, J COMPUT INF SCI ENG, V20, DOI 10.1115/1.4045142
   Motion L., 2016, LEAP MOTION CONTROLL
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Pei SY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501898
   Saidinejad H, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P379, DOI 10.1145/2598153.2600049
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Schmidt R., 2009, P 6 EUR S SKETCH BAS, P133, DOI [10.1145/1572741.1572765, DOI 10.1145/1572741.1572765]
   sketch G., 2019, G SKETCH
   Stern Helman I., 2008, 2008 Second IEEE International Conference on Semantic Computing (ICSC), P96, DOI 10.1109/ICSC.2008.29
   Tianyi Wang, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P552, DOI 10.1145/3472749.3474769
   Tramper JJ, 2011, J NEUROSCI, V31, P7857, DOI 10.1523/JNEUROSCI.0486-11.2011
   VR P., PAINTL VT PAINT SCUL
   Wiese J. H., 2010, P 7 SKETCH BAS INT, P135
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Xia HJ, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3503537
   Xin Min, 2008, P 2008 ACM S VIRT RE, P223, DOI DOI 10.1145/1450579.1450627
   Xu PF, 2019, IEEE T VIS COMPUT GR, V25, P2927, DOI 10.1109/TVCG.2018.2860016
NR 56
TC 6
Z9 6
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2499
EP 2507
DI 10.1109/TVCG.2023.3247059
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0PW0
UT WOS:000965842400001
PM 37027702
DA 2024-11-06
ER

PT J
AU Groth, C
   Fricke, S
   Castillo, S
   Magnor, M
AF Groth, Colin
   Fricke, Sascha
   Castillo, Susana
   Magnor, Marcus
TI Wavelet-Based Fast Decoding of 360<SUP>?</SUP>° Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Wavelet transforms; Decoding; Image coding; Transform coding;
   Video codecs; Encoding; Video Compression; Video Codec; Wavelets;
   Virtual Reality; VR; 360 Videos
AB In this paper, we propose a wavelet-based video codec specifically designed for VR displays that enables real-time playback of high-resolution 360(?)degrees videos. Our codec exploits the fact that only a fraction of the full 360(?)degrees video frame is visible on the display at any time. To load and decode the video viewport-dependently in real time, we make use of the wavelet transform for intra- as well as inter-frame coding. Thereby, the relevant content is directly streamed from the drive, without the need to hold the entire frames in memory. With an average of 193 frames per second at 8192 x 8192 -pixel full-frame resolution, the conducted evaluation demonstrates that our codec's decoding performance is up to 272% higher than that of the state-of-the-art video codecs H.265 and AV1 for typical VR displays. By means of a perceptual study, we further illustrate the necessity of high frame rates for a better VR experience. Finally, we demonstrate how our wavelet-based codec can also directly be used in conjunction with foveation for further performance increase.
C1 [Groth, Colin; Fricke, Sascha; Castillo, Susana; Magnor, Marcus] TU, Inst Comp Graph, Braunschweig, Germany.
RP Groth, C (corresponding author), TU, Inst Comp Graph, Braunschweig, Germany.
EM groth@cg.cs.tu-bs.de; fricke@cg.cs.tu-bs.de; castillo@cg.cs.tu-bs.de;
   magnor@cg.cs.tu-bs.de
RI Castillo, Susana/U-6432-2019
OI Castillo, Susana/0000-0003-1245-4758; Groth, Colin/0000-0001-6445-5563
FU German Science Foundation [DFG MA2555/15-1, 390833453]
FX The authors gratefully acknowledge funding by the German Science
   Foundation (DFG MA2555/15-1 "Immersive Digital Reality"), and under
   Germany's Excellence Strategy within the Cluster of Excellence PhoenixD
   (EXC 2122, Project ID 390833453).
CR [Anonymous], STARVR ONE
   Banitalebi-Dehkordi A, 2015, 3D RES, V6, DOI 10.1007/s13319-014-0034-3
   BBC Research, DIR SPEC VERS 223
   Bjontegaard G., 2001, VCEG-M33
   Boopathi G, 2012, ANNU IEEE IND CONF, P340
   Castillo S., 2011, P APGV, P7
   Choi B., 2018, INFORM TECHNOLOGY CO, P2
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Corbillon X, 2017, IEEE ICC, DOI 10.1109/ICC.2017.7996611
   Groth C, 2022, IEEE T VIS COMPUT GR, V28, P2234, DOI 10.1109/TVCG.2022.3150506
   Groth C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P169, DOI 10.1109/VRW52623.2021.00039
   Haar A., 1911, Mathematische Annalen, V71, P38, DOI DOI 10.1007/BF01456927
   Hannuksela MM, 2019, IEEE DATA COMPR CONF, P418, DOI 10.1109/DCC.2019.00050
   Heisenberg W., 1927, Zeitschrift fr Physik, V43, P172, DOI DOI 10.1007/BF01397280
   ISO, 2019, ISOIEC1544412019 ISO, V642, P2
   Kammachi-Sreedhar K, 2016, IEEE INT SYM MULTIM, P583, DOI [10.1109/ISM.2016.0126, 10.1109/ISM.2016.143]
   Kolb H., 2020, WEBVISION ORG RETINA
   Le Gall D., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P761, DOI 10.1109/ICASSP.1988.196696
   Leigh R., 2015, CONT NEUROLOGY SERIE, P5
   Leng Y, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P91, DOI 10.1145/3307650.3322264
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   MORAN PAP, 1947, BIOMETRIKA, V34, P363, DOI 10.2307/2332449
   Muhlhausen M., 2020, ACM S VIRTUAL REALIT, DOI [10.1145/3385956.34189655, DOI 10.1145/3385956.34189655]
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Setyawan I, 2004, P SOC PHOTO-OPT INS, V5306, P256, DOI 10.1117/12.526726
   Siegel S., 1988, NONPARAMETRIC STAT B, V2, P7
   Silverstein LD., 2008, COLOR RES APPL, V21, P142, DOI [10.1002/col.5080210213, DOI 10.1002/COL.5080210213]
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Sun QY, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P97, DOI 10.1145/3373087.3375317
   Taubman D., 2012, JPEG2000: Image Compression Funda- mentals, Standards and Practice, V642
   Unser M, 2003, IEEE T IMAGE PROCESS, V12, P1080, DOI 10.1109/TIP.2003.812329
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zare A., 2016, P 24 ACM INT C MULT, P601, DOI DOI 10.1145/2964284.2967292
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao SL, 2020, ANN I S COM, P241, DOI 10.1109/ISCA45697.2020.00030
   Zhewei H., 2020, arXiv
NR 38
TC 2
Z9 2
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2508
EP 2516
DI 10.1109/TVCG.2023.3247080
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0LY8
UT WOS:000965740600001
PM 37027730
DA 2024-11-06
ER

PT J
AU Rieger, MB
   Risch, B
AF Rieger, Marc Bastian
   Risch, Bjoern
TI How to Maximise Spatial Presence: Design Guidelines for a Virtual
   Learning Environment for School Use
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Solid modeling; Learning systems; Media; Hardware;
   Distributed Bragg reflectors; Guidelines; Virtual Reality; VR Design
   Guidelines; Spatial Presence
ID REALITY; MODEL
AB Research on learning with and in immersive virtual reality (VR) continues to grow, yielding more insights into how immersive learning works. However, the actual use of VR learning environments in schools is still in its infancy. A major hurdle that hinders the use of immersive digital media in schools is the lack of guidelines for designing VR learning environments for practical use in schools. Such guidelines need to consider how students interact and learn in VR learning environments and how teachers can use such environments on a day-to-day basis. Using a design-based research approach, we explored the guidelines for creating VR learning content for tenth-grade students in a German secondary school and recreated a real-world, out-of-school VR learning space which can be used for hands-on instruction. This paper investigated how to maximise the experience of spatial presence by creating a VR learning environment in several microcycles. Furthermore, it took a closer look at the influence of the spatial situation model and cognitive involvement on this process. The results were evaluated with ANOVAs and path analyses, showing, for example, that involvement does not influence spatial presence in highly immersive and realistic VR learning environments.
C1 [Rieger, Marc Bastian; Risch, Bjoern] RPTU, Kaiserslautern, Germany.
RP Rieger, MB (corresponding author), RPTU, Kaiserslautern, Germany.
EM m.rieger@rptu.de; b.risch@rptu.de
CR Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Biocca F, 2001, PRESENCE-VIRTUAL AUG, V10, P247, DOI 10.1162/105474601300343595
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Dengel A., 2022, 2022 8 INT C IMM LEA, P1, DOI [DOI 10.23919/ILRN55037.2022.9815941, 10.23919/iLRN55037.2022.9815941]
   Dengel A, 2018, PR IEEE INT CONF TEA, P608, DOI 10.1109/TALE.2018.8615281
   Edler D., 2019, KN - Journal of Cartography and Geographic Information, V69, P5, DOI [DOI 10.1007/S42489-019-00004-4, 10.1007/s42489-019-00004-4]
   Euler D., 2014, DESIGNBASED RES, P97
   Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685
   Forkel A., 2009, DISSERTATION
   Gilbert SB, 2016, PRESENCE-TELEOP VIRT, V25, P322, DOI 10.1162/PRES_a_00276
   Hartman Tilo., 2015, IMMERSED MEDIA TELEP, P115, DOI [DOI 10.1007/978-3-319-10190-3_7, 10.1007/978-3-319-10190-3_7]
   Hartmann S., 2005, RAUMLICHE PRASENZ AL, P21
   Hofer M, 2016, PRESENCE INVOLVEMENT, V15
   Hofer M., 2013, HDB MEDIENWIRKUNGSFO, P279, DOI 10.1007/978-3-531-18967-3_14
   Huppauf Bernd., 2007, Heimat, P109
   Johnson-Glenberg MC, 2019, SMART COMPUT INTELL, P83, DOI 10.1007/978-981-13-8265-9_5
   Kuhne O., 2018, Landscape and power in geographical space as a social-aesthetic construct
   Lee S, 2008, INTERACT COMPUT, V20, P491, DOI 10.1016/j.intcom.2008.07.003
   Makransky G, 2021, EDUC PSYCHOL REV, V33, P937, DOI 10.1007/s10648-020-09586-2
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Moore JW, 2012, CONSCIOUS COGN, V21, P59, DOI 10.1016/j.concog.2011.08.010
   Pellas N, 2020, IEEE T LEARN TECHNOL, V13, P748, DOI 10.1109/TLT.2020.3019405
   Poeschl S, 2013, ANN REV CYBERTHERAPY, V11, P33
   Rheinberg F, 2001, DIAGNOSTICA, V47, P57, DOI 10.1026//0012-1924.47.2.57
   Slater M., 2003, PRESENCE CONNECT, P3
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Vergara D., 2017, Multimod. Technol. Interact., V1, P11, DOI [10.3390/mti1020011, DOI 10.3390/MTI1020011, https://doi.org/10.3390/mti1020011]
   Vorderer W., REPORT EUROPEAN COMM
   Wirth S., 2006, EMPIRISCHE UNTERHALT, P107
   Wirth W, 2012, UNTERHALTUNG NEUEN M, V7, P100
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Zender M., 2018, DELFI 2018 DIE 16 E, P275
   Zhang S. Jiang, 2017, BEHAV INFORM TECHNOL, DOI [10.1080/014492X.2016.1268647, DOI 10.1080/014492X.2016.1268647]
NR 33
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2517
EP 2526
DI 10.1109/TVCG.2023.3247111
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2MD2
UT WOS:000967105500001
PM 37027705
DA 2024-11-06
ER

PT J
AU Pan, Y
   Zhang, RS
   Cheng, SR
   Tan, S
   Ding, Y
   Mitchell, K
   Yang, XB
AF Pan, Ye
   Zhang, Ruisi
   Cheng, Shengran
   Tan, Shuai
   Ding, Yu
   Mitchell, Kenny
   Yang, Xubo
TI Emotional Voice Puppetry
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Mouth; Three-dimensional displays; Lips; Facial animation;
   Videos; Training; Virtual reality; audio; emotion; character animation
AB The paper presents emotional voice puppetry, an audio-based facial animation approach to portray characters with vivid emotional changes. The lips motion and the surrounding facial areas are controlled by the contents of the audio, and the facial dynamics are established by category of the emotion and the intensity. Our approach is exclusive because it takes account of perceptual validity and geometry instead of pure geometric processes. Another highlight of our approach is the generalizability to multiple characters. The findings showed that training new secondary characters when the rig parameters are categorized as eye, eyebrows, nose, mouth, and signature wrinkles is significant in achieving better generalization results compared to joint training. User studies demonstrate the effectiveness of our approach both qualitatively and quantitatively. Our approach can be applicable in AR/VR and 3DUI, namely, virtual reality avatars/self-avatars, teleconferencing and in-game dialogue.
C1 [Pan, Ye; Cheng, Shengran; Tan, Shuai; Yang, Xubo] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Zhang, Ruisi] Univ Calif San Diego, San Diego, CA USA.
   [Ding, Yu] Netease Fuxi I Lab, Virtual Human Grp, Beijing, Peoples R China.
   [Mitchell, Kenny] Edinburgh Napier Univ, Edinburgh, Scotland.
C3 Shanghai Jiao Tong University; University of California System;
   University of California San Diego; Edinburgh Napier University
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM whitneypanye@sjtu.edu.cn; ruz032@ucsd.edu; SR-Cheng@sjtu.edu.cn;
   tanshuai0219@sjtu.edu.cn; dingyu01@corp.netease.com;
   k.mitchell2@napier.ac.uk; yangxubo@sjtu.edu.cn
RI Mitchell, Kenny/AAZ-3421-2020; Zhang, Ruisi/HMP-7396-2023
OI Cheng, Shengran/0000-0003-4044-0185; Mitchell, Kenny/0000-0003-2420-7447
FU Shanghai Sailing Program [20YF1421200]; National Natural Science
   Foundation of China (NSFC) [62102255]; CAROUSEL+ (EU FET PROACT)
   [101017779]; Hangzhou Key Science and Technology Innovation Program
   [2022AIZD0054]
FX This work was supported by Shanghai Sailing Program (No.20YF1421200),
   National Natural Science Foundation of China (NSFC,NO. 62102255),
   CAROUSEL+ (EU FET PROACT, NO.101017779)and Hangzhou Key Science and
   Technology Innovation Program (No.2022AIZD0054)
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   Aneja D., 2021, P 2021 CHI C HUM FAC, P1
   Aneja D, 2018, IEEE WINT CONF APPL, P160, DOI 10.1109/WACV.2018.00024
   Baloup T., 2021, P 2021 IEEE PES IAS, P1
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen LL, 2018, LECT NOTES COMPUT SC, V11211, P538, DOI 10.1007/978-3-030-01234-2_32
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Faigin Gary, 2012, The artist's complete guide to facial expression
   Gafni Guy, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P8645, DOI 10.1109/CVPR46437.2021.00854
   Guo K., 2021, P IEEECVF INT C COMP, P5784
   Hyde J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1719, DOI 10.1145/2702123.2702465
   Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386
   Jiaqi Hao, 2021, SA '21 Technical Communications: SIGGRAPH Asia 2021 Technical Communications, DOI 10.1145/3478512.3488610
   Kaisiyuan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P700, DOI 10.1007/978-3-030-58589-1_42
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Lasseter J., 1987, Computer Graphics, DOI [DOI 10.1145/37402.37407, DOI 10.1145/37401.37407]
   Lele Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P35, DOI 10.1007/978-3-030-58545-7_3
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li LC, 2021, AAAI CONF ARTIF INTE, V35, P1911
   Liu F. Xu, 2015, ACM Transactions on Graphics, V34, P1
   Liu S., 2022, IEEE Transactions on Visualization and Computer Graphics, P1
   Logan B., 2000, P INT SOC MUS INF RE
   Lu YX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480484
   Ma S., 2023, P AAAI C ART INT
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Thies J, 2018, Arxiv, DOI arXiv:1610.03151
   Thomas O., 1995, ILLUSION LIFE DISNEY, P34
   Wang SZ, 2021, PROCEEDINGS OF THE THIRTIETH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2021, P1098
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2531
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Wisessing P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3383195
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Zhang C., 2021, P IEEECVF INT C COMP, P3867
   Zhang S., 2021, IEEE T VIS COMPUT GR
   Zhang W, 2021, IEEE INT CONF COMP V, P3532, DOI 10.1109/ICCVW54120.2021.00394
   Zhang Zhimeng, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P1167, DOI 10.1145/3503161.3548330
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
NR 47
TC 9
Z9 9
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2527
EP 2535
DI 10.1109/TVCG.2023.3247101
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2HX8
UT WOS:000966995800001
PM 37027720
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Mullen, JF Jr
   Manocha, D
AF Mullen Jr, James F. F.
   Manocha, Dinesh
TI PACE: Data-Driven Virtual Agent Interaction in Dense and Cluttered
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Measurement; Solid modeling; Animation;
   Videos; Geometry; Affordances; Embodied agents; Virtual humans; Human
   Factors
AB We present PACE, a novel method for modifying motion-captured virtual agents to interact with and move throughout dense, cluttered 3D scenes. Our approach changes a given motion sequence of a virtual agent as needed to adjust to the obstacles and objects in the environment. We first take the individual frames of the motion sequence most important for modeling interactions with the scene and pair them with the relevant scene geometry, obstacles, and semantics such that interactions in the agents motion match the affordances of the scene (e.g., standing on a floor or sitting in a chair). We then optimize the motion of the human by directly altering the high-DOF pose at each frame in the motion to better account for the unique geometric constraints of the scene. Our formulation uses novel loss functions that maintain a realistic flow and natural-looking motion. We compare our method with prior motion generating techniques and highlight the benefits of our method with a perceptual study and physical plausibility metrics. Human raters preferred our method over the prior approaches. Specifically, they preferred our method 57.1% of the time versus the state-of-the-art method using existing motions, and 81.0% of the time versus a state-of-the-art motion synthesis method. Additionally, our method performs significantly higher on established physical plausibility and interaction metrics. Specifically, we outperform competing methods by over 1.2% in terms of the non-collision metric and by over 18% in terms of the contact metric. We have integrated our interactive system with Microsoft HoloLens and demonstrate its benefits in real-world indoor scenes. Our project website is available at https://gamma.mnd.edu/pace/
C1 [Mullen Jr, James F. F.; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Mullen, JF Jr (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM mullenj@umd.edu; dmanocha@umd.edu
OI Manocha, Dinesh/0000-0001-7047-9801; Mullen, James/0000-0002-4117-1741
FU National Science Foundation Graduate Research Fellowship Program [DGE
   1840340]; ARO [W911NF2110026]; U.S. Army Cooperative Agreement
   [W911NF2120076]; U.S. Department of Defense (DOD) [W911NF2110026]
   Funding Source: U.S. Department of Defense (DOD)
FX This material is based upon work supported by the National Science
   Foundation Graduate Research Fellowship Program under Grant No. DGE
   1840340. It is also supported by ARO Grant W911NF2110026 and U.S. Army
   Cooperative Agreement W911NF2120076. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of these funding
   agencies.
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Carnegie Mellon University, CMU MOCAP DAT, V4, P9
   Chan E. R., 2021, ARXIV
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Clegg A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275048
   Cole, 2021, ADV NEURAL INFORM PR, V34, P19326
   Cruz S, 2021, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR46437.2021.00217
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Fu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10913, DOI 10.1109/ICCV48922.2021.01075
   Gleicher M., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P33, DOI 10.1145/280814.280820
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Gu JJ, 2022, INFORM SCIENCES, V599, P25, DOI 10.1016/j.ins.2022.03.074
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Harvey FG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392480
   Hassan M, 2021, PROC CVPR IEEE, P14703, DOI 10.1109/CVPR46437.2021.01447
   Hassan M, 2019, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2019.00237
   Ho ESL, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778770
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang Y, 2013, PROC CVPR IEEE, P2993, DOI 10.1109/CVPR.2013.385
   Jingwei Xu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P178, DOI 10.1007/978-3-030-58621-8_11
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kang CG, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12468
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kovar L., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P214
   Kwon Youngjoong, 2021, Advances in Neural Information Processing Systems, V34, P24741
   Lang YN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P767, DOI [10.1109/VR.2019.8798018, 10.1109/vr.2019.8798018]
   Leimer K, 2020, COMPUT AIDED GEOM D, V79, DOI 10.1016/j.cagd.2020.101855
   Lessels S., 2005, Presence: Teleoperators & Virtual Environments, V14, P2
   Li XT, 2019, PROC CVPR IEEE, P12360, DOI 10.1109/CVPR.2019.01265
   Lin J., 2016, SIGGRAPH ASIA 2016 V
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Martin J., How to Make Immersive Game Design
   Mildenhall B., 2020, ECCV, P17
   Mullen JF Jr, 2022, Arxiv, DOI arXiv:2209.06314
   Narang S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P9, DOI 10.1109/VR.2018.8446152
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Noguchi A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5742, DOI 10.1109/ICCV48922.2021.00571
   Noguchi Atsuhiro, 2022, Unsupervised Learning of Efficient GeometryAware Neural Articulated Representations
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavlovic V, 2001, ADV NEUR IN, V13, P981
   Peng S., 2021, ICCV, P14294, DOI DOI 10.1109/ICCV48922.2021.01405
   Rempe D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11468, DOI 10.1109/ICCV48922.2021.01129
   Ruddle RA, 2004, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2004.1310067
   Ruddle RA, 2001, PRESENCE-TELEOP VIRT, V10, P511, DOI 10.1162/105474601753132687
   Savva M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661230
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simeone AL, 2017, IEEE T VIS COMPUT GR, V23, P1359, DOI 10.1109/TVCG.2017.2657038
   Sohn K, 2015, ADV NEUR IN, V28
   Starke S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356505
   Su SY, 2021, ADV NEUR IN, V34
   Tan FW, 2018, IEEE WINT CONF APPL, P1519, DOI 10.1109/WACV.2018.00170
   Urtasun R., 2008, P 25 INT C MACHINE L, P1080, DOI [DOI 10.1145/1390156.1390292, 10.1145/1390156.1390292, 10.1145/1390156]
   Vedaldi A., 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P2863
   Wang Junya, 2022, Chinese Journal of Chemical Engineering, P10, DOI 10.1016/j.cjche.2022.07.025
   Wang JS, 2021, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR46437.2021.00928
   Wang Z., 2021, Geometric Pose Affordance: 3D Human Pose with Scene Constraints, P3
   Wang Z., 2020, P ADV NEUR INF PROC, V33, P7768
   Xia F, 2018, PROC CVPR IEEE, P9068, DOI 10.1109/CVPR.2018.00945
   Xia GY, 2019, IEEE T IND INFORM, V15, P2927, DOI 10.1109/TII.2019.2894113
   Ye ZM, 2021, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR52148.2021.00039
   Zhang SW, 2020, INT CONF 3D VISION, P642, DOI 10.1109/3DV50981.2020.00074
   Zhang Y, 2020, PROC CVPR IEEE, P6193, DOI 10.1109/CVPR42600.2020.00623
   Zhao F., 2022, CVPR, P11
NR 72
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2536
EP 2546
DI 10.1109/TVCG.2023.3247054
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1CF8
UT WOS:000966164400001
PM 37027697
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Vermast, A
   Hürst, W
AF Vermast, Alissa
   Hurst, Wolfgang
TI Introducing 3D Thumbnails to Access 360-Degree Videos in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 360-degree video; video search; 360-degree video interaction; interfaces
   for video collections
AB 360 degrees videos provide an immersive experience, especially when watched in virtual reality (VR). Yet, even though the video data is inherently three-dimensional, interfaces to access datasets of such videos in VR almost always use two-dimensional thumbnails shown in a grid on a flat or curved plane. We claim that using spherical and cube-shaped 3D thumbnails may provide a better user experience and be more effective at conveying the high-level subject matter of a video or when searching for a specific item in it. A comparative study against the most used existing representation, that is, 2D equirectangular projections, showed that the spherical 3D thumbnails did indeed provide the best user experience, whereas traditional 2D equirectangular projections still performed better for high-level classification tasks. Yet, they were outperformed by spherical thumbnails when participants had to search for details within the videos. Our results thus confirm a potential benefit of 3D thumbnail representations for 360-degree videos in VR, especially with respect to user experience and detailed content search and suggest a mixed interface design providing both options to the users. Supplemental materials about the user study and used data are available at https://osf.io/5vk49/.
C1 [Vermast, Alissa; Hurst, Wolfgang] Univ Utrecht, Utrecht, Netherlands.
C3 Utrecht University
RP Hürst, W (corresponding author), Univ Utrecht, Utrecht, Netherlands.
CR Aitamurto T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174119
   Ardouin J, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2013.6550203
   Brown Chip., 2017, Bringing pixels front and center in VR video
   Nguyen C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5428, DOI 10.1145/3025453.3025675
   Elvins T. T., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P21, DOI 10.1145/263407.263504
   Elvins T. T., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P163, DOI 10.1145/274644.274669
   Elvins TT, 2001, PRESENCE-TELEOP VIRT, V10, P565, DOI 10.1162/105474601753272835
   Englmeier D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P345, DOI 10.1109/VR50410.2021.00057
   Fan CL, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329119
   Gauss KF., 2005, GEN INVESTIGATIONS C
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   Grogorick S, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119890
   He YW, 2018, PICT COD SYMP, P313, DOI 10.1109/PCS.2018.8456280
   Hosseini M, 2017, P IEEE VIRT REAL ANN, P423, DOI 10.1109/VR.2017.7892357
   Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153
   Husung M., 2019, P MENSCH COMP, P245, DOI 10.1145/3340764.3340779
   Kim, 2017, GET CLOSER LOOK STRE
   Kuperus H., THESIS
   Lee Y, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427611
   Li Jiannan, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P223, DOI 10.1145/3472749.3474746
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Li Z., 2016, ADJUNCT P 29 ANN ACM, P193, DOI [10.1145/2984751.2984765, DOI 10.1145/2984751.2984765]
   Lin YT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P255, DOI 10.1145/3126594.3126656
   Miyafuji S, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P599, DOI 10.1145/3126594.3126607
   Nassani A., 2021, 2021 CHI C HUMAN FAC, DOI [10.1145/3411763.34515552, DOI 10.1145/3411763.34515552]
   Pakkanen T, 2017, P IEEE VIRT REAL ANN, P279, DOI 10.1109/VR.2017.7892285
   Pio D., 2018, HOOD BUILDING 360 VI
   Skupin R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Stoakley R., 1995, P SIGCHI C HUM FACT, P265, DOI [10.1145/223904.223938, DOI 10.1145/223904.223938]
   Teo T, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364238
   Tomar S., 2006, LINUX J, V2006, P10
   Truong A., 2019, P 45 GRAPH INT C P G, DOI [10.20380/GI2019.142, DOI 10.20380/GI2019.14]
   Tse Audrey, 2017, P 2017 CHI C EXTENDE, P2967, DOI DOI 10.1145/3027063.3053225
   ueq-online, SHORT UEQ DATA ANAL
   Yamaguchi S, 2021, INT SYM MIX AUGMENT, P176, DOI 10.1109/ISMAR52148.2021.00032
   Ye Y., 2017, JVET H1004 ALGORITHM, V07
NR 36
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2547
EP 2556
DI 10.1109/TVCG.2023.3247462
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0UT0
UT WOS:000965969600001
PM 37027582
OA Green Published
DA 2024-11-06
ER

PT J
AU Haley, AC
   Thorpe, D
   Pelletier, A
   Yarosh, S
   Keefe, DF
AF Haley, Alexander C.
   Thorpe, Don
   Pelletier, Alex
   Yarosh, Svetlana
   Keefe, Daniel F.
TI Inward VR: Toward a Qualitative Method for Investigating Interoceptive
   Awareness in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human-centered computing; Human computer interaction (HCI); Interaction
   paradigms; Virtual reality
ID VIRTUAL-REALITY; INTERVENTIONS
AB lmmersive virtual reality (VR) technologies can produce powerful illusions of being in another place or inhabiting another body, and theories of presence and embodiment provide valuable guidance to designers of VR applications that use these illusions to "take us elsewhere." However, an increasingly common design goal for VR experiences is to develop a deeper awareness of the internal landscape of one's own body (i.e., interoceptive awareness); here, design guidelines and evaluative techniques are less clear. To address this, we present a methodology, including a reusable codebook, for adapting the five dimensions of the Multidimensional Assessment of Interoceptive Awareness (MAIA) conceptual framework to explore interoceptive awareness in VR experiences via qualitative interviews. We report results from a first exploratory study (n=21) applying this method to understand the interoceptive experiences of users in a VR environment. The environment includes a guided body scan exercise with a motion-tracked avatar visible in a virtual mirror and an interactive visualization of a biometric signal detected via a heartbeat sensor. The results provide new insights on how this example VR experience might be refined to better support interoceptive awareness and how the methodology might continue to be refined for understanding other "inward-facing" VR experiences.
C1 [Haley, Alexander C.; Thorpe, Don; Pelletier, Alex; Yarosh, Svetlana; Keefe, Daniel F.] Univ Minnesota, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Haley, AC (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM haley045@umn.edu; thorp167@umn.edu; pelle213@umn.edu; lana@umn.edu;
   dfk@umn.edu
OI Thorpe, Don/0000-0002-2390-7786; Yarosh, Svetlana/0000-0001-8389-2064;
   Keefe, Daniel/0000-0002-7039-2340; Haley, Alexander/0000-0003-2499-8162
CR Arpaia P, 2022, MINDFULNESS, V13, P556, DOI 10.1007/s12671-021-01783-6
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Blum J, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02172
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Britton E, 2020, HEALTH PROMOT INT, V35, P50, DOI 10.1093/heapro/day103
   Cikajlo I, 2017, JMIR RES PROTOC, V6, DOI 10.2196/resprot.6849
   David N, 2014, COGN AFFECT BEHAV NE, V14, P297, DOI 10.3758/s13415-013-0190-6
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Döllinger N, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519613
   Dollinger N., 2021, FRONTIERS VIRTUAL RE, V2
   Etikan I., 2016, American Journal of Theoretical and Applied Statistics, V5, P1, DOI [10.11648/J.AJTAS.20160501.11, DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.ajtas.20160501.11]
   Feng A., 2017, COMPUT ANIMAT VIRT W, V28, P4
   Filippetti ML, 2017, COGNITION, V159, P1, DOI 10.1016/j.cognition.2016.11.002
   Fissler M, 2016, MINDFULNESS, V7, P1170, DOI 10.1007/s12671-016-0559-z
   Gale NK, 2013, BMC MED RES METHODOL, V13, DOI 10.1186/1471-2288-13-117
   Gomez J, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01611
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Gromala D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P521, DOI 10.1145/2702123.2702344
   Heeter C., 2015, Journal For Virtual Worlds Research, V8
   Heeter C., 2015, Foundations of Digital Games
   Heeter C, 2020, INTERACT COMPUT, V32, P1, DOI 10.1093/iwc/iwaa001
   Heeter C, 2016, PRESENCE-TELEOP VIRT, V25, P175, DOI 10.1162/PRES_a_00256
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hoffman HG, 2000, PAIN, V85, P305, DOI 10.1016/S0304-3959(99)00275-4
   Hoffman HG, 2001, CLIN J PAIN, V17, P229, DOI 10.1097/00002508-200109000-00007
   Kabat-Zinn J., FULL CATASTROPHE LIV
   Khalsa SS, 2018, BIOL PSYCHIAT-COGN N, V3, P501, DOI 10.1016/j.bpsc.2017.12.004
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kosunen I, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P208, DOI 10.1145/2856767.2856796
   Lüddecke R, 2022, APPL PSYCHOPHYS BIOF, V47, P1, DOI 10.1007/s10484-021-09529-9
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Mehling W., 2019, 12 EUROPEAN C INTEGR, P1
   Mehling WE, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208034
   Mehling WE, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048230
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Mittelstädt JM, 2019, HUM FACTORS, V61, P322, DOI 10.1177/0018720818804382
   Navarro-Haro MV, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00055
   Oh SY, 2016, COMPUT HUM BEHAV, V60, P398, DOI 10.1016/j.chb.2016.02.007
   Pollatos O, 2007, HUM BRAIN MAPP, V28, P9, DOI 10.1002/hbm.20258
   Price C, 2016, J ADDICT NURS, V27, P32, DOI 10.1097/JAN.0000000000000109
   Price CJ, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00798
   Riva G, 2016, FRONT PSYCHIATRY, V7, DOI 10.3389/fpsyt.2016.00164
   Rosenberg RS, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0055003
   Rosenkranz MA, 2019, CURR OPIN PSYCHOL, V28, P179, DOI 10.1016/j.copsyc.2018.12.022
   Saunders B, 2018, QUAL QUANT, V52, P1893, DOI 10.1007/s11135-017-0574-8
   Schauder KB, 2015, J EXP CHILD PSYCHOL, V131, P193, DOI 10.1016/j.jecp.2014.11.002
   Schroeder D, 2013, IEEE COMPUT GRAPH, V33, P82, DOI 10.1109/MCG.2013.38
   Schwind V., 2018, INTERACTIONS, V25, P4, DOI DOI 10.1145/3236673
   Shaw ChrisD., 2007, Proc. of ENACTIVE/07, P405
   Slater M, 1999, IEEE COMPUT GRAPH, V19, P6, DOI 10.1109/38.749116
   Slater M., 2003, PRESENCE CONNECT, P3
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Todd J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231048
   Tong A, 2007, INT J QUAL HEALTH C, V19, P349, DOI 10.1093/intqhc/mzm042
   Tsakiris M, 2011, P ROY SOC B-BIOL SCI, V278, P2470, DOI 10.1098/rspb.2010.2547
   van Loon A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202442
   Vidyarthi Jay., 2012, P DESIGNING INTERACT, P408
   Weng HY, 2021, TRENDS NEUROSCI, V44, P52, DOI 10.1016/j.tins.2020.09.010
   Wong SYS, 2018, MINDFULNESS, V9, P1344, DOI 10.1007/s12671-018-0897-0
   Yee N., 2007, HUM COMMUN RES, V33, P2
NR 63
TC 4
Z9 5
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2557
EP 2566
DI 10.1109/TVCG.2023.3247074
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2QU6
UT WOS:000967228300001
PM 37027715
DA 2024-11-06
ER

PT J
AU Young, J
   Pantidi, N
   Wood, M
AF Young, Jacob
   Pantidi, Nadia
   Wood, Matthew
TI I Can't See That! Considering the Readability of Small Objects in
   Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Compass; Task analysis; Virtual environments; Usability; Geologic
   measurements; Training; Particle measurements; Virtual reality;
   usability testing; interaction techniques
AB Though virtual reality has repeatedly seen usability improvements through higher fidelity headsets, interacting with small objects has remained an issue due to a reduction in visual acuity. Given the current uptake of virtual reality platforms and the range of real world applications that they may be used for, it is worth considering how such interactions can be accounted for. We propose three techniques for improving the usability of small objects in virtual environments: i) expanding them in place, ii) showing a zoomed-in twin above the original object, and iii) showing a large readout of the object's current state. We conducted a study comparing each technique's usability, induced presence, and effect on short-term knowledge retention in a VR training scenario that simulated the common geoscience exercise of measuring strike and dip. Participant feedback highlighted the need for this research, however simply scaling the area of interest may not be enough to improve the usability of information-bearing objects, while displaying this information in large text format can make tasks faster to complete at the cost of reducing the user's ability to transfer knowledge they've learned to the real world. We discuss these results and their implications for the design of future virtual reality experiences.
C1 [Young, Jacob; Pantidi, Nadia; Wood, Matthew] Te Herenga Waka Victoria Univ Wellington, Wellington, New Zealand.
RP Young, J (corresponding author), Te Herenga Waka Victoria Univ Wellington, Wellington, New Zealand.
EM jacob.young@vuw.ac.nz; nadia.pantidi@vuw.ac.nz; matthew.wood@vuw.ac.nz
OI Young, Jacob/0000-0002-1180-4114
FU Te Herenga Waka - Victoria University ofWellington
FX The authors wish to thank Cliff Atkins, James Crampton, Jamey Stutz,and
   Dene Carroll for their help, support, knowledge, and
   enthusiasmthroughout this project.This work was supported by Te Herenga
   Waka - Victoria University ofWellington as part of the SHEADI Strategic
   Initiative
CR Baumgartner E., TECHTRENDS, V92022, DOI [10.1007/s11528-022-00753-62, DOI 10.1007/S11528-022-00753-62]
   Bursztyn H., P 2021 IEEE C VIRT R, P32021, DOI [10.1109/VRW52623.2021, DOI 10.1109/VRW52623.2021]
   Bursztyn N, 2022, GEOSCI COMMUN, V5, P29, DOI 10.5194/gc-5-29-2022
   Bursztyn N, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P303, DOI 10.1109/VRW52623.2021.00061
   da Fontoura VS, 2021, LECT NOTES COMPUT SC, V13002, P589, DOI 10.1007/978-3-030-89029-2_44
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Dewitz C., 2021, GI VRAR WORKSH
   Fussell S G., 2021, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V65, P1124, DOI [10.1177/1071181321651096, DOI 10.1177/1071181321651096]
   Gagnier KM, 2017, TOP COGN SCI, V9, P883, DOI 10.1111/tops.12233
   Grout Cameron., 2015, P 15 NZ C HUMAN COMP, P9, DOI DOI 10.1145/2808047.2808055
   Hahn B., C HUM FACT COMP SYST, V2018, P42018, DOI [10.1145/3170427.31886522[13]D.J., DOI 10.1145/3170427.31886522[13]D.J]
   Hahn J, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P395, DOI 10.1145/2836041.2841215
   Harris G., 2021, VIRTUAL REAL-LONDON, V25, P7
   Hsieh HF, 2005, QUAL HEALTH RES, V15, P1277, DOI 10.1177/1049732305276687
   Kent C., DESIGN STUD, V77, DOI [10.1016/j.destud.2021.1010462[16]T, DOI 10.1016/J.DESTUD.2021.1010462[16]T]
   Kojic D., 2020, P 2020 12 INT C QUAL
   Kojic T, 2022, LECT NOTES COMPUT SC, V13317, P199, DOI 10.1007/978-3-031-05939-1_13
   Liben LS, 2011, COGNITION INSTRUCT, V29, P45, DOI 10.1080/07370008.2010.533596
   Lucas P, 2018, IEEE INT CONF ADV LE, P380, DOI 10.1109/ICALT.2018.00097
   Mainelli J., METAS DOMINANCE VR M
   Papagiannakis G, 2018, SA'18: SIGGRAPH ASIA 2018 POSTERS, DOI 10.1145/3283289.3283291
   Pierce J. S., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P105, DOI 10.1145/503376.503396
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Pivovar J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P907, DOI 10.1109/VRW55335.2022.00307
   Roufs JAJ, 1997, DISPLAYS, V18, P37, DOI 10.1016/S0141-9382(97)00003-6
   Ruthenbeck GS, 2015, J SIMUL, V9, P16, DOI 10.1057/jos.2014.14
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Wilkes C., 2008, P 2008 ACM S VIRT RE, P23, DOI [10.1145/1450579.1450585, DOI 10.1145/1450579.1450585]
   Wingrave CA, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P11, DOI 10.1109/TRIDUI.2006.1618264
   Winn W., 1993, TECHNICAL PUBLICATIO, V93
   Winther F, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375213
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
NR 33
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2567
EP 2574
DI 10.1109/TVCG.2023.3247468
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2MI0
UT WOS:000967110300001
PM 37027613
DA 2024-11-06
ER

PT J
AU Liu, YN
   Zhang, H
   Li, YQ
   He, KJ
   Xu, D
AF Liu, Yanan
   Zhang, Hao
   Li, Yanqiu
   He, Kangjian
   Xu, Dan
TI Skeleton-based Human Action Recognition via Large-kernel Attention Graph
   Convolutional Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Skeleton; Convolution; Kernel; Adaptation models; Joints; Topology; Task
   analysis; human skeleton; action recognition; large kernels; graph
   convolution
AB The skeleton-based human action recognition has broad application prospects in the field of virtual reality, as skeleton data is more resistant to data noise such as background interference and camera angle changes. Notably, recent works treat the human skeleton as a non-grid representation, e.g., skeleton graph, then learns the spatio-temporal pattern via graph convolution operators. Still, the stacked graph convolution plays a marginal role in modeling long-range dependences that may contain crucial action semantic cues. In this work, we introduce a skeleton large kernel attention operator (SLKA), which can enlarge the receptive field and improve channel adaptability without increasing too much computational burden. Then a spatiotemporal SLKA module (ST-SLKA) is integrated, which can aggregate long-range spatial features and learn long-distance temporal correlations. Further, we have designed a novel skeleton-based action recognition network architecture called the spatiotemporal large-kernel attention graph convolution network (LKA-GCN). In addition, large-movement frames may carry significant action information. This work proposes a joint movement modeling strategy (JMM) to focus on valuable temporal interactions. Ultimately, on the NTU-RGBD 60, NTU-RGBD 120 and Kinetics-Skeleton 400 action datasets, the performance of our LKA-GCN has achieved a state-of-the-art level.
C1 [Liu, Yanan; Zhang, Hao; Li, Yanqiu; He, Kangjian; Xu, Dan] Yunnan Univ, Sch Informat Sci & Engn, Kunming, Peoples R China.
C3 Yunnan University
RP Xu, D (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming, Peoples R China.
EM danxu@ynu.edu.cn
RI He, Kangjian/CAG-0300-2022; Xu, Dan/KPA-7396-2024
OI Li, Yanqiu/0000-0003-4198-0896; Xu, Dan/0000-0003-4602-3550; Zhang,
   Hao/0000-0002-0404-6941
FU provincial major science and technology special plan projects
   [202202AD080003]; National Natural Science Foundation of China
   [62162068, 61761049, 62202416]; Yunnan Province Ten Thousand Talents
   Program; Yunling Scholars Special Project [YNWR-YLXZ-2018-022]; Yunnan
   Provincial Science and Technology Department-Yunnan University "Double
   First Class" Construction Joint Fund Project [2019FY003012]; Science
   Research Fund Project of Yunnan Provincial Department of Education
   [2021Y027]; Graduate Research and Innovation Foundation of Yunnan
   University [KC-22221726]
FX This work was supported in part by the provincial major science and
   technology special plan projects under Grant 202202AD080003, in part by
   the National Natural Science Foundation of China under Grant 62162068,
   Grant 61761049, Grant 62202416, in part by the Yunnan Province Ten
   Thousand Talents Program and Yunling Scholars Special Project under
   Grant YNWR-YLXZ-2018-022, in part by the Yunnan Provincial Science and
   Technology Department-Yunnan University "Double First Class"
   Construction Joint Fund Project under Grant No.2019FY003012, in part by
   the Science Research Fund Project of Yunnan Provincial Department of
   Education under grant 2021Y027, in part by the Graduate Research and
   Innovation Foundation of Yunnan University (KC-22221726).
CR Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chao Li, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P609, DOI 10.1109/ICMEW.2017.8026281
   Chen D., 2019, NATL C ARTIFICIAL IN
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Ciftci UA, 2017, IEEE INT CON MULTI, P715, DOI 10.1109/ICME.2017.8019545
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Duan HD, 2022, Arxiv, DOI [arXiv:2104.13586, DOI 10.48550/ARXIV.2104.13586]
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Gao X., 2018, ACM MULTIMEDIA
   Guo M., 2022, VISUAL ATTENTION NET
   He K., 2015, CVPR, DOI [DOI 10.1109/MSP.2012.2205597, 10.1109/CVPR.2016.90]
   Howard A.G., 2017, MOBILENETS EFFICIENT
   Jxa B., 2021, NEUROCOMPUTING, V440, P230
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li MS, 2022, IEEE T PATTERN ANAL, V44, P3316, DOI 10.1109/TPAMI.2021.3053765
   Liu J, 2019, Arxiv, DOI arXiv:1905.04757
   Liu MY, 2017, IEEE INT CON MULTI, P925, DOI 10.1109/ICME.2017.8019438
   Liu Y., 2016, UBIQUITOUS COMPUTING
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   LUCAS JM, 1990, TECHNOMETRICS, V32, P1, DOI 10.2307/1269835
   Ma ZS, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/3495203
   Marinoiu E, 2018, PROC CVPR IEEE, P2158, DOI 10.1109/CVPR.2018.00230
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Plizzari C., 2020, arXiv
   Rao Y., 2021, arXiv
   Sermet Y, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338550
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L., 2020, Decoupled spatial-temporal attention network for skeleton-based action recognition
   Shi L, 2019, Arxiv, DOI [arXiv:1805.07694, 10.48550/arXiv.1805.07694]
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang J., 2012, EUROPEAN C COMPUTER
   Wang M., 2021, arXiv
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang Y., 2020, COMPUTER VISION PATT
   Wei P.A., 2021, PATTERN RECOGN
   Xie CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1639
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang H., 2020, FEEDBACK GRAPH CONVO
   Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhao Borui, 2022, DECOUPLED KNOWLEDGE
NR 51
TC 31
Z9 32
U1 10
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2575
EP 2585
DI 10.1109/TVCG.2023.3247075
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2NP3
UT WOS:000967144200001
PM 37027698
DA 2024-11-06
ER

PT J
AU Pugh, B
   Chernak, D
   Jiddi, S
AF Pugh, Brian
   Chernak, Davin
   Jiddi, Salma
TI GeoSynth: A Photorealistic Synthetic Indoor Dataset for Scene
   Understanding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Annotations; Three-dimensional displays; Synthetic data;
   Semantic segmentation; Training; Rendering (computer graphics);
   Rendering; ray tracing; mesh modeling; synthetic dataset; artificial
   intelligence; semantic segmentation
AB Deep learning has revolutionized many scene perception tasks over the past decade. Some of these improvements can be attributed to the development of large labeled datasets. The creation of such datasets can be an expensive, time-consuming, and imperfect process. To address these issues, we introduce GeoSynth, a diverse photorealistic synthetic dataset for indoor scene understanding tasks. Each GeoSynth exemplar contains rich labels including segmentation, geometry, camera parameters, surface material, lighting, and more. We demonstrate that supplementing real training data with GeoSynth can significantly improve network performance on perception tasks, like semantic segmentation. A subset of our dataset will be made publicly available at https://github.com/geomagical/GeoSynth.
C1 [Pugh, Brian; Chernak, Davin; Jiddi, Salma] Geomag Labs, Mountain View, CA 94041 USA.
RP Pugh, B (corresponding author), Geomag Labs, Mountain View, CA 94041 USA.
EM bpugh@geomagical.com; davin@geomagical.com; salma@geomagical.com
CR [Anonymous], 2022, AMAZON SAGEMAKER DAT
   [Anonymous], About Blender: The Software
   Barrow H., 1978, Comput. Vis. Syst., V2, P2
   Bell Sean, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601206
   blenderkit, BLENDERKIT PLATFORM
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Dai A. X., ABS170204405 CORR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   docs.blender, CYCLES RENDERER
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fischer P, 2015, Arxiv, DOI [arXiv:1504.06852, DOI 10.48550/ARXIV.1504.06852]
   Garcia -Garcia A., 2019, ARXIV
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   He KM, 2015, Arxiv, DOI [arXiv:1502.01852, DOI 10.1109/ICCV.2015.123]
   He X., ABS151203385 CORR
   Hua BS, 2016, INT CONF 3D VISION, P92, DOI 10.1109/3DV.2016.18
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li Z., 2020, arXiv
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   McCormac J, 2017, Arxiv, DOI arXiv:1612.05079
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Roberts M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10892, DOI 10.1109/ICCV48922.2021.01073
   Shipman K., 2022, RAY NVIDIA RTX A6000
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song M., 2022, IEEE T NEUR NET LEAR, V2
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Wang W., ABS180203601 CORR
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Zhang S., 2017, IEEE C COMP VIS PATT, V2
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhou H., ABS160805442 CORR
NR 32
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2586
EP 2595
DI 10.1109/TVCG.2023.3247087
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2KR7
UT WOS:000967067800001
PM 37027722
OA hybrid
DA 2024-11-06
ER

PT J
AU Mizuho, T
   Narumi, T
   Kuzuoka, H
AF Mizuho, Takato
   Narumi, Takuji
   Kuzuoka, Hideaki
TI Effects of the Visual Fidelity of Virtual Environments on Presence,
   Context-dependent Forgetting, and Source-monitoring Error
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Monitoring; Avatars; Virtual environments; Medical
   treatment; Forestry; Cognitive science; Environmental context;
   context-dependent forgetting; source monitoring; episodic memory; visual
   quality; presence; virtual reality
ID MEMORY; REALITY; PLACE; MOOD; MODEL; TASK
AB Advances in virtual reality technology have enabled the creation of virtual environments (VEs) with significantly high visual fidelity when compared to real environments (REs). In this study, we use a high-fidelity VE to examine two effects caused by alternating VE and RE experiences: "context-dependent forgetting" and "source-monitoring errors." The former effect is that memories learned in VEs are more easily recalled in VEs than in REs, whereas memories learned in REs are more easily recalled in REs than in VEs. The source-monitoring error is that memories learned in VEs are easily confused with those learned in REs, making discriminating the source of the memory difficult. We hypothesized that the visual fidelity of VEs is responsible for these effects and conducted an experiment using two types of VEs: a high-fidelity VE created using photogrammetry techniques and low-fidelity VE created with primitive shapes and materials. The results show that the high-fidelity VE significantly improved the sense of presence. However, the level of the visual fidelity of the VEs did not show any effect on context-dependent forgetting and source-monitoring errors. Notably, the null results of the context-dependent forgetting between the VE and RE were strongly supported by Bayesian analysis. Thus, we indicate that context-dependent forgetting does not necessarily occur, which will be helpful for VR-based education and training.
C1 [Mizuho, Takato; Narumi, Takuji; Kuzuoka, Hideaki] Univ Tokyo, Tokyo, Japan.
C3 University of Tokyo
RP Mizuho, T (corresponding author), Univ Tokyo, Tokyo, Japan.
EM takato@cyber.t.u-tokyo.ac.jp; narumi@cyber.t.u-tokyo.ac.jp;
   kuzuoka@cyber.t.u-tokyo.ac.jp
RI Kuzuoka, Hideaki/KIG-7464-2024; Narumi, Takuji/K-3925-2014
OI Mizuho, Takato/0000-0002-9821-8889; Narumi, Takuji/0000-0002-9010-1491;
   Kuzuoka, Hideaki/0000-0003-1252-7814
FU JST Moonshot Research Development [JPMJMS2013, 21K19784, JPNP21501015];
   JST SPRING [JPMJSP2108]; Grants-in-Aid for Scientific Research
   [21K19784] Funding Source: KAKEN
FX This work was partially supported by JST Moonshot Research & Development
   (JPMJMS2013); Grant-in-Aid for Challenging Research(Exploratory)
   (21K19784); "Multimodal XR-AI platform development for telehabitation
   and reciprocal care coupling with health guidance" project
   (JPNP21501015-0) subsidized by NEDO; and JST SPRING(JPMJSP2108).
CR [Anonymous], 2008, Bayesian Evaluation of Informative Hypotheses
   Bailey J., 2011, P INT SOC PRESENCE R
   Chu S, 2003, PSYCHOL REC, V53, P549, DOI 10.1007/BF03395452
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dinh HQ, 1999, P IEEE VIRT REAL ANN, P222, DOI 10.1109/VR.1999.756955
   EICH E, 1995, J EXP PSYCHOL GEN, V124, P293, DOI 10.1037/0096-3445.124.3.293
   GODDEN DR, 1975, BRIT J PSYCHOL, V66, P325, DOI 10.1111/j.2044-8295.1975.tb01468.x
   Gonzalez-Franco M., 2020, FRONTIERS VIRTUAL RE, V1, DOI [10.3389/ frvir.2020.561558-3, DOI 10.3389/FRVIR.2020.561558-3]
   Gonzalez-Franco M, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P91, DOI 10.1109/AIVR50618.2020.00026
   Graf S., 2020, 26 ACM S VIRTUAL REA, DOI [10.1145/3385956.34221055,6, DOI 10.1145/3385956.34221055,6]
   Harman J, 2017, LECT NOTES COMPUT SC, V10514, P128, DOI 10.1007/978-3-319-67684-5_9
   Hoffman HG, 2001, CYBERPSYCHOL BEHAV, V4, P565, DOI 10.1089/109493101753235151
   Isarida T, 2004, MEMORY, V12, P376, DOI 10.1080/09658210344000062
   Isarida T., 2014, Advances in experimental psychology research, P115
   Isarida T, 2020, J MEM LANG, V113, DOI 10.1016/j.jml.2020.104113
   Isarida T, 2014, MEM COGNITION, V42, P421, DOI 10.3758/s13421-013-0370-1
   Isarida TK, 2017, Q J EXP PSYCHOL, V70, P533, DOI 10.1080/17470218.2016.1138975
   JOHNSON MK, 1993, PSYCHOL BULL, V114, P3, DOI 10.1037/0033-2909.114.1.3
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Lamers M. H., 2021, FRONT VIRTUAL REAL, V2, DOI [10.3389/frvir.2021.6020871,2,6, DOI 10.3389/FRVIR.2021.6020871,2,6]
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Liu XNL, 2021, PSYCHON B REV, V28, P2035, DOI 10.3758/s13423-021-01953-6
   Masicampo EJ, 2014, J EXP PSYCHOL LEARN, V40, P1772, DOI 10.1037/xlm0000007
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Rubo M, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100111
   Rutherford A, 2004, Q J EXP PSYCHOL-A, V57, P107, DOI 10.1080/02724980343000152
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Shin YS, 2021, PSYCHON B REV, V28, P574, DOI 10.3758/s13423-020-01835-3
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Smith SA, 2021, MEMORY, V29, P983, DOI 10.1080/09658211.2021.1953535
   Smith SA, 2019, PSYCHON B REV, V26, P1213, DOI 10.3758/s13423-019-01605-w
   Smith S.M., 2013, SAGE HDB APPL MEMORY, P162
   SMITH SM, 1978, MEM COGNITION, V6, P342, DOI 10.3758/BF03197465
   SMITH SM, 1984, MEM COGNITION, V12, P477, DOI 10.3758/BF03198309
   SMITH SM, 1995, J EXP PSYCHOL GEN, V124, P309, DOI 10.1037/0096-3445.124.3.309
   Smith SM, 2001, PSYCHON B REV, V8, P203, DOI 10.3758/BF03196157
   Smith SM, 2010, BEHAV RES METHODS, V42, P292, DOI 10.3758/BRM.42.1.292
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Watson P., 2021, INT C ARTIFICIAL REA, DOI [10.2312/egve.202113216, DOI 10.2312/EGVE.202113216]
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 48
TC 7
Z9 7
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2607
EP 2614
DI 10.1109/TVCG.2023.3247063
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2DF2
UT WOS:000966870600001
PM 37027723
DA 2024-11-06
ER

PT J
AU Schott, D
   Kunz, M
   Wunderling, T
   Heinrich, F
   Braun-Dullaeus, R
   Hansen, C
AF Schott, Danny
   Kunz, Matthias
   Wunderling, Tom
   Heinrich, Florian
   Braun-Dullaeus, Ruediger
   Hansen, Christian
TI CardioGenesis4D: Interactive Morphological Transitions of Embryonic
   Heart Development in a Virtual Learning Environment
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Education; Heart; Embryo; Solid modeling;
   Virtual reality; Visualization; Virtual Reality; Immersive Learning
   Environment; Embryonic Heart Development; Anatomy Education
ID ANATOMY; MULTIMEDIA
AB In the embryonic human heart, complex dynamic shape changes take place in a short period of time on a microscopic scale, making this development difficult to visualize. However, spatial understanding of these processes is essential for students and future cardiologists to properly diagnose and treat congenital heart defects. Following a user centered approach, the most crucial embryological stages were identified and translated into a virtual reality learning environment (VRLE) to enable the understanding of the morphological transitions of these stages through advanced interactions. To address individual learning types, we implemented different features and evaluated the application regarding usability, perceived task load, and sense of presence in a user study. We also assessed spatial awareness and knowledge gain, and finally obtained feedback from domain experts. Overall, students and professionals rated the application positively. To minimize distraction from interactive learning content, such VRLEs should consider features for different learning types, allow for gradual habituation, and at the same time provide enough playful stimuli. Our work previews how VR can be integrated into a cardiac embryology education curriculum.
C1 [Schott, Danny; Wunderling, Tom; Hansen, Christian] Univ Magdeburg, Fac Comp Sci, Magdeburg, Germany.
   [Kunz, Matthias; Braun-Dullaeus, Ruediger] Univ Magdeburg, Clin Cardiol & Angiol, Magdeburg, Germany.
   [Heinrich, Florian] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
C3 Otto von Guericke University; Otto von Guericke University; University
   of Wurzburg
RP Schott, D (corresponding author), Univ Magdeburg, Fac Comp Sci, Magdeburg, Germany.
EM danny.schott@ovgu.de; matthias.kunz@med.ovgu.de;
   florian.heinrich@uni-wuerzburg.de; r.braun-dullaeus@med.ovgu.de;
   hansen@isg.cs.uni-magdeburg.de
OI Heinrich, Florian/0000-0002-8169-3157; Schott,
   Danny/0000-0002-2576-7799; Hansen, Christian/0000-0002-5734-7529;
   Wunderling, Tom/0000-0002-8862-3549; Kunz, Matthias/0000-0002-0439-2254
FU German Federal Ministry for Economic Affairs and Climate Action
   [16KN093942]
FX This work was partially funded by the German Federal Ministry for
   Economic Affairs and Climate Action under Grant 16KN093942.
CR Alfalah SFM, 2019, VIRTUAL REAL-LONDON, V23, P229, DOI 10.1007/s10055-018-0359-y
   Anderson RH, 2019, CLIN ANAT, V32, P468, DOI 10.1002/ca.23306
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bork F, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P122, DOI 10.1109/ISMAR-Adjunct.2019.00-66
   Brenton H, 2007, COMPUT EDUC, V49, P32, DOI 10.1016/j.compedu.2005.06.005
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Chekrouni N, 2020, ANN ANAT, V227, DOI 10.1016/j.aanat.2019.151430
   Chen CJ, 2005, J RES TECHNOL EDUC, V38, P123, DOI 10.1080/15391523.2005.10782453
   Chen L, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P123, DOI 10.1109/ISMAR.2017.29
   de Bakker BS, 2012, REPROD TOXICOL, V34, P225, DOI 10.1016/j.reprotox.2012.05.087
   de Freitas S, 2010, BRIT J EDUC TECHNOL, V41, P69, DOI 10.1111/j.1467-8535.2009.01024.x
   Falah J, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P752, DOI 10.1109/SAI.2014.6918271
   Ganis G., 2015, J OPEN PSYCHOL DATA, V3, pe3, DOI DOI 10.5334/JOPD.AI
   Gerrelli D, 2015, DEVELOPMENT, V142, P3073, DOI 10.1242/dev.122820
   Gustilo K. S., 2022, FASEB J, V36, DOI [10.1096/fasebj.2022.36.S1.R53992,8, DOI 10.1096/FASEBJ.2022.36.S1.R53992,8]
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Huang HM, 2010, COMPUT EDUC, V55, P1171, DOI 10.1016/j.compedu.2010.05.014
   Hull A, 2021, FASEB J, V35, DOI 10.1096/fasebj.2021.35.S1.04542
   James KH, 2002, BEHAV RES METH INS C, V34, P383, DOI 10.3758/BF03195466
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Jin Q, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517542
   Kaminska D, 2019, INFORMATION, V10, DOI 10.3390/info10100318
   Kurul R, 2020, ANAT SCI EDUC, V13, P648, DOI 10.1002/ase.1959
   Lee EAL, 2010, LECT NOTES COMPUT SC, V6250, P79, DOI 10.1007/978-3-642-14484-4_8
   Lindgren R, 2013, EDUC RESEARCHER, V42, P445, DOI 10.3102/0013189X13511661
   Maresky HS, 2019, CLIN ANAT, V32, P238, DOI 10.1002/ca.23292
   Meguid EMA, 2022, ADV EXP MED BIOL, V1356, P173, DOI 10.1007/978-3-030-87779-8_8
   Moraes SG, 2010, ANN ANAT, V192, P388, DOI 10.1016/j.aanat.2010.05.005
   Patil M., 2020, NATL J CLIN ANATOMY, V9, P135, DOI [10.4103/NJCA.NJCA_67_201, DOI 10.4103/NJCA.NJCA_67_201]
   Preim B, 2021, Digital anatomy: applications of virtual, mixed and augmented reality, P299
   Preim B, 2018, COMPUT GRAPH-UK, V71, P132, DOI 10.1016/j.cag.2018.01.005
   Reyes J., 2021, PROC EUROGRAPHICS WO, DOI [10.13140/RG.2.2.28432.486452, DOI 10.13140/RG.2.2.28432.486452]
   Ripka G., 2020, SOC INFORM TECHNOLOG, P2
   Saalfeld P., 2016, PROC EUROGRAPHICS WO, P2
   Saalfeld S., 2017, PROC EUROGRAPHICS DI, P5, DOI DOI 10.2312/EGM.20171043
   Schott D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P296, DOI 10.1109/VR50410.2021.00052
   Schubert Thomas W., 2003, Zeitschrift fur Medienpsychologie, V15, P69
   Sinha S, 2023, MED SCI EDUC, V33, P287, DOI 10.1007/s40670-022-01701-y
   Smerling J, 2019, PEDIATR CARDIOL, V40, P1258, DOI 10.1007/s00246-019-02146-8
   Someren M., 1994, THINK ALOUD METHOD P, P5
   Tait K, 2020, ADV EXP MED BIOL, V1262, P19, DOI 10.1007/978-3-030-43961-3_2
   Voit A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300737
   Zhang N, 2023, IEEE T RELIAB, V72, P204, DOI 10.1109/TR.2021.3139539
NR 43
TC 4
Z9 4
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2615
EP 2625
DI 10.1109/TVCG.2023.3247110
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0XL8
UT WOS:000966040400001
PM 37027713
OA hybrid
DA 2024-11-06
ER

PT J
AU Unruh, F
   Vogel, D
   Landeck, M
   Lugrin, JL
   Latoschik, ME
AF Unruh, Fabian
   Vogel, David
   Landeck, Maximilian
   Lugrin, Jean-Luc
   Latoschik, Marc Erich
TI Body and Time: Virtual Embodiment and its Effect on Time Perception
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Psychology; Task analysis; Video games; Pacemakers; Mirrors;
   Human computer interaction; Time Perception; Virtual Reality; Virtual
   Embodiment; Avatar; Presence
ID COGNITIVE-BEHAVIOR THERAPY; INTENTIONAL BINDING; REALITY; IMMERSION;
   SENSE; REPRESENTATION; CONSCIOUSNESS; SCHIZOPHRENIA; EXPERIENCE;
   JUDGMENTS
AB This article explores the effect of one's body representation on time perception. Time Perception is modulated by a variety of factors including, e.g., the current situation or activity, it can display significant disturbances caused by psychological disorders, and it is influenced by emotional and interoceptive states, i.e., "the sense of the physiological condition of the body". We investigated this relation between one's own body and the perception of time in a novel Virtual Reality (VR) experiment explicitly fostering user activity. Forty-Eight participants randomly experienced different degrees of embodiment: i) without an avatar (low), ii) with hands (medium), and iii) with a high-quality avatar (high). Participants had to repeatedly activate a virtual lamp and estimate the duration of time intervals as well as judge the passage of time. Our results show a significant effect of embodiment on time perception: time passes slower in the low embodiment condition compared to the medium and high conditions. In contrast to prior work, the study provides missing evidence that this effect is independent of the level of activity of participants: In our task, users were prompted to repeatedly perform body actions, thereby ruling-out a potential influence of the level of activity. Importantly, duration judgements in both the millisecond and minute ranges seemed unaffected by variations in embodiment. Taken together, these results lead to a better understanding of the relationship between the body and time.
C1 [Unruh, Fabian; Landeck, Maximilian; Lugrin, Jean-Luc; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Vogel, David] Univ Cologne, Fac Med, Cologne, Germany.
   [Vogel, David] Univ Cologne, Univ Hosp Cologne, Dept Psychiat, Cologne, Germany.
C3 University of Wurzburg; University of Cologne; University of Cologne
RP Unruh, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
EM fabian.unruh@uni-wuerzburg.de; david.vogel@uk-koeln.de;
   maximilian.landeck@uni-wuerzburg.de; jean-luc.lugrin@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
RI Latoschik, Marc/HLG-5348-2023; Lugrin, Jean-Luc/KMA-1030-2024
OI Unruh, Fabian/0000-0002-9894-2156; Vogel, David H.V./0000-0003-0645-9034
FU VIRTUALTIMES project - European Union under the Horizon 2020 program
   [824128]
FX This work is funded by the VIRTUALTIMES project (ID-824128)funded by the
   European Union under the Horizon 2020 program.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Biocca Frank, 2014, Social Computing and Social Media. 6th International Conference, SCSM 2014, Held as Part of HCI International 2014. Proceedings: LNCS 8531, P421, DOI 10.1007/978-3-319-07632-4_40
   Block RA, 1996, TIME AND MIND, P171
   BLOCK RA, 1992, NATO ADV SCI INST SE, V66, P141
   Boone H.N., 2012, J EXT, V50
   Bryson S, 2013, Arxiv, DOI arXiv:1312.4322
   Carmack J., 2013, LATENCY MITIGATION S, P6
   Chen J, 2007, COMMUN ACM, V50, P31, DOI 10.1145/1232743.1232769
   Craig A. D., 2014, YOU FEEL INTEROCEPTI, DOI [10.23943/princeton/9780691156767.001.00011,3, DOI 10.23943/PRINCETON/9780691156767.001.00011,3]
   Craig AD, 2009, PHILOS T R SOC B, V364, P1933, DOI 10.1098/rstb.2009.0008
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience, V1990, P2
   de Haan S, 2010, PSYCHOPATHOLOGY, V43, P327, DOI 10.1159/000319402
   de la Peña N, 2010, PRESENCE-TELEOP VIRT, V19, P291, DOI 10.1162/PRES_a_00005
   Dirnberger G, 2012, NEUROIMAGE, V63, P591, DOI 10.1016/j.neuroimage.2012.06.041
   Droit-Volet S., 2013, TIMING TIME PERCEPT, V1, P99, DOI DOI 10.1163/22134468-00002004
   Droit-Volet S, 2011, FRONT INTEGR NEUROSC, V5, DOI 10.3389/fnint.2011.00033
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Fleisig D, 2009, NEUROQUANTOLOGY, V7, P58
   Fuchs T, 2013, PHENOMENOL COGN SCI, V12, P75, DOI 10.1007/s11097-010-9189-4
   Gall D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P73, DOI 10.1109/VR.2018.8446153
   Giersch A, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01659
   Gonçalves R, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0048469
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Gorczynski P, 2010, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004412.pub2
   Grondin S, 2010, ATTEN PERCEPT PSYCHO, V72, P561, DOI 10.3758/APP.72.3.561
   HICKS RE, 1976, AM J PSYCHOL, V89, P719, DOI 10.2307/1421469
   Hölzel BK, 2011, PERSPECT PSYCHOL SCI, V6, P537, DOI 10.1177/1745691611419671
   Igarzabal F. A., 2021, TECHNOLOGY MIND BEHA, V2
   Jokic T., 2018, Timing Time Percept, V6, P71, DOI [10.1163/22134468-00002101, DOI 10.1163/22134468-00002101]
   Jording M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12063-1
   Kennedy R. S., INT J AVIAT PSYCHOL, V3, P203
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Landeck M., 2020, 26 ACM S VIRTUAL REA, DOI [10.1145/3385956.34221113, DOI 10.1145/3385956.34221113]
   Latoschik M. E., 2022, FRONTIERS VIRTUAL RE
   Latoschik M. E., 2022, Frontiers in Virtual Reality, V3, DOI [10.3389/frvir.2022.6944332,3,8, DOI 10.3389/FRVIR.2022.6944332,3,8]
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   LaViola J. J., 2017, 3D USER INTERFACES T, V2, P3
   Lelyveld P., 2015, SMPTE Motion Imaging Journal, V124, P78, DOI [DOI 10.5594/J18599, 10.5594/j18599]
   Lindner P, 2021, INT J COGN THER, V14, P23, DOI 10.1007/s41811-020-00090-7
   Lugrin JL, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313067
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Meissner K, 2011, BIOL PSYCHOL, V86, P289, DOI 10.1016/j.biopsycho.2011.01.001
   Moore JW, 2012, CONSCIOUS COGN, V21, P546, DOI 10.1016/j.concog.2011.12.002
   Ogden RS, 2015, COGNITION EMOTION, V29, P910, DOI 10.1080/02699931.2014.954529
   OSUNA EE, 1985, J MATH PSYCHOL, V29, P82, DOI 10.1016/0022-2496(85)90020-3
   Peña J, 2009, COMMUN RES, V36, P838, DOI 10.1177/0093650209346802
   Pfeifer E., 2016, MUSIC MED, V8, P180, DOI [DOI 10.47513/MMD.V8I4.473, 10.47513/mmd.v8i4.473]
   Pollatos O, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086934
   Roseboom W, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-08194-7
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Sabat M, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18520-1
   Sackett AM, 2010, PSYCHOL SCI, V21, P111, DOI 10.1177/0956797609354832
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schatzschneider C, 2016, IEEE T VIS COMPUT GR, V22, P1387, DOI 10.1109/TVCG.2016.2518137
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   STEUER J, 1992, J COMMUN, V42, P73, DOI 10.1111/j.1460-2466.1992.tb00812.x
   Suzuki K, 2019, PSYCHOL SCI, V30, P842, DOI 10.1177/0956797619842191
   TAYLOR S, 1994, J MARKETING, V58, P56, DOI 10.2307/1252269
   Thoenes S, 2017, CLIN PSYCHOL REV, V54, P44, DOI 10.1016/j.cpr.2017.03.007
   Turkington D, 2006, AM J PSYCHIAT, V163, P365, DOI 10.1176/appi.ajp.163.3.365
   Unreal E., 2022, METAHUMAN CREATOR
   Unruh F., 2021, FRONT VIRTUAL REAL, V2, DOI [10.3389/frvir.2021.6585092,3,4,6,8, DOI 10.3389/FRVIR.2021.6585092,3,4,6,8]
   Vogel DHV, 2019, SCHIZOPHR RES-COGN, V17, DOI 10.1016/j.scog.2019.100136
   Vogel DHV, 2020, PHENOMENOL COGN SCI, V19, P235, DOI 10.1007/s11097-018-9573-z
   Vogel DHV, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00066
   Vogeley K, 2007, SCHIZOPHRENIA BULL, V33, P157, DOI 10.1093/schbul/sbl056
   Wallach HS, 2009, BEHAV MODIF, V33, P314, DOI 10.1177/0145445509331926
   Waltemate T., 2015, P 21 ACM S VIRT REAL, P139, DOI [10.1145/2821592.28216076, DOI 10.1145/2821592.28216076]
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wearden JH, 2015, CONSCIOUS COGN, V38, P165, DOI 10.1016/j.concog.2015.06.005
   Wearden JH, 2008, LANG LEARN, V58, P149, DOI 10.1111/j.1467-9922.2008.00468.x
   Wearden JH, 1998, Q J EXP PSYCHOL-B, V51, P97
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Witowska J, 2020, ACTA PSYCHOL, V205, DOI 10.1016/j.actpsy.2020.103061
   Wittmann M, 2015, CONSCIOUS COGN, V38, P172, DOI 10.1016/j.concog.2015.06.008
   Wittmann M, 2013, NAT REV NEUROSCI, V14, P217, DOI 10.1038/nrn3452
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   ZAKAY D, 1993, PERCEPT PSYCHOPHYS, V54, P656, DOI 10.3758/BF03211789
   Zakay D, 1997, CURR DIR PSYCHOL SCI, V6, P12, DOI 10.1111/1467-8721.ep11512604
   Zakay D., 1995, Time and the Dynamic Control of Behavior, P167
   Zakay D, 2015, CONSCIOUS COGN, V38, P182, DOI 10.1016/j.concog.2015.10.006
   Zakay D, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00917
   Zopf R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18492-7
NR 90
TC 6
Z9 7
U1 3
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2626
EP 2636
DI 10.1109/TVCG.2023.3247040
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2CQ8
UT WOS:000966856100001
PM 37027744
OA hybrid
DA 2024-11-06
ER

PT J
AU Congdon, BJ
   Steed, A
AF Congdon, Ben J.
   Steed, Anthony
TI Monte-Carlo Redirected Walking: Gain Selection Through Simulated Walks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual environments; Legged locomotion; Monte Carlo methods; Target
   tracking; Optimization; Solid modeling; Resists; Virtual reality; human
   computer interaction; redirected walking
AB We present Monte-Carlo Redirected Walking (MCRDW), a gain selection algorithm for redirected walking. MCRDW applies the Monte-Carlo method to redirected walking by simulating a large number of simple virtual walks, then inversely applying redirection to the virtual paths. Different gain levels and directions are applied, producing differing physical paths. Each physical path is scored and the results used to select the best gain level and direction. We provide a simple example implementation and a simulation-based study for validation. In our study, when compared with the next best technique, MCRDW reduced incidence of boundary collisions by over 50% while reducing total rotation and position gain.
C1 [Congdon, Ben J.; Steed, Anthony] UCL, London, England.
C3 University of London; University College London
RP Congdon, BJ (corresponding author), UCL, London, England.
EM ben.congdon.11@ucl.ac.uk; a.steed@ucl.ac.uk
OI Steed, Anthony/0000-0001-9034-3020
FU European Union [739578]; UK's EPSRC [EP/G037159/1]
FX This project has received funding from the European Union's Horizon2020
   Research and Innovation program under grant agreement No 739578 (RISE).
   This work was also supported in part by the UK's EPSRC under project
   number EP/G037159/1.
CR Azmandian M., 2015, EUROGRAPHICS ASS, DOI [10.2312/egve.201513152,5, DOI 10.2312/EGVE.201513152,5]
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Congdon BJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364277
   Field Tom., 2004, 2004 International Conference on Artificial Intelligence in Science and Technology, P1357
   Hicheur H, 2007, EUR J NEUROSCI, V26, P2376, DOI 10.1111/j.1460-9568.2007.05836.x
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Keppel G., 1992, INTRO DESIGN ANAL ST, V6, P7
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Nescher T., 2013, LECT NOTES COMPUTER, V7848, DOI [10.1007/978-3-642-38803-3-103, DOI 10.1007/978-3-642-38803-3-103]
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peck T. C., 2010, THESIS U N CAROLINA, P3
   Razzaque S., 2005, Redirected Walking
   Razzaque S., 2001, P EUR, P289
   Steinicke F., 2008, Proc. Virtual Reality International Conference (VRIC), P15
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Su JB, 2007, PRESENCE-VIRTUAL AUG, V16, P385, DOI 10.1162/pres.16.4.385
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
   Zank M, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P229, DOI 10.1109/CW.2015.20
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 28
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2637
EP 2646
DI 10.1109/TVCG.2023.3247093
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2JK9
UT WOS:000967035000001
PM 37027718
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yan, YK
   Liu, HH
   Shi, YT
   Wang, JY
   Guo, RC
   Li, ZS
   Xu, XH
   Yu, C
   Wang, YT
   Shi, YC
AF Yan, Yukang
   Liu, Haohua
   Shi, Yingtian
   Wang, Jingying
   Guo, Ruici
   Li, Zisu
   Xu, Xuhai
   Yu, Chun
   Wang, Yuntao
   Shi, Yuanchun
TI ConeSpeech: Exploring Directional Speech Interaction for Multi-Person
   Remote Communication in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Headphones; Collaboration; Avatars; Torso; Target
   tracking; Speech; Virtual Reality; Voice interaction; Multi-user
   conversation
AB Remote communication is essential for efficient collaboration among people at different locations. We present ConeSpeech, a virtual reality (VR) based multi-user remote communication technique, which enables users to selectively speak to target listeners without distracting bystanders. With ConeSpeech, the user looks at the target listener and only in a cone-shaped area in the direction can the listeners hear the speech. This manner alleviates the disturbance to and avoids overhearing from surrounding irrelevant people. Three featured functions are supported, directional speech delivery, size-adjustable delivery range, and multiple delivery areas, to facilitate speaking to more than one listener and to listeners spatially mixed up with bystanders. We conducted a user study to determine the modality to control the cone-shaped delivery area. Then we implemented the technique and evaluated its performance in three typical multi-user communication tasks by comparing it to two baseline methods. Results show that ConeSpeech balanced the convenience and flexibility of voice communication.
C1 [Yan, Yukang; Liu, Haohua; Shi, Yingtian; Wang, Jingying; Guo, Ruici; Li, Zisu; Yu, Chun; Wang, Yuntao; Shi, Yuanchun] Tsinghua Univ, Beijing, Peoples R China.
   [Xu, Xuhai] Univ Washington, Seattle, WA USA.
   [Shi, Yuanchun] Qinghai Univ, Xining, Peoples R China.
C3 Tsinghua University; University of Washington; University of Washington
   Seattle; Qinghai University
RP Wang, YT (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM yyk@mail.tsinghua.edu.cn; iris918919_ol@outlook.com;
   shiyingtian_thu@163.com; wangchy@umich.edu; guoruici@bupt.edu.cn;
   vespersue98@gmail.com; xuhaixu@cs.washington.edu;
   chunyu@tsinghua.edu.cn; yuntaowang@tsinghua.edu.cn;
   shiyc@tsinghua.edu.cn
RI Xu, Xuhai/JQK-5168-2023; Wang, Yuntao/AFS-4057-2022; Liu,
   Haohua/HCH-5399-2022
OI Shi, Yingtian/0000-0001-8733-7041; Wang, Yuntao/0000-0002-4249-8893; Yu,
   Chun/0000-0003-2591-7993; Xu, Xuhai/0000-0001-5930-3899; Wang,
   Jingying/0000-0001-6474-818X; Yan, Yukang/0000-0001-7515-3755
FU Natural Science Foundation of China (NSFC) [62132010, 62102221,
   62002198]; Beijing Key Lab of Networked Multimedia, Tsinghua University;
   Institute for Artificial Intelligence, Tsinghua University
FX This work is supported by the Natural Science Foundation of China (NSFC)
   under Grant No.62132010, No.62102221, and No.62002198, and Beijing Key
   Lab of Networked Multimedia, and Institute for Artificial Intelligence,
   Tsinghua University.
CR @2021Mozilla, 2021, WELC HUBS
   @2021VRChat, 2021, VRC SPAT AUD SOURC
   Ahuja K, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P453, DOI 10.1145/3332165.3347889
   [Anonymous], 2020, D V CHAT PROXIMITY C
   Bailenson J.N., 2021, Technol. Mind Behav, V1, DOI [DOI 10.1037/TMB0000030, 10.1037/tmb0000030]
   Bonsignori C, 2020, INT CONF INTEL ENVIR, P80, DOI 10.1109/IE49459.2020.9154983
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brubaker JedR., 2012, P DESIGNING INTERACT, P96, DOI DOI 10.1145/2317956.2317973
   Cai MH, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0180-y
   Chaves AP, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173765
   De Guzman Edward S., 2007, Proceedings Graphics Interface 2007, P143, DOI 10.1145/1268517.1268542
   Denby B, 2010, SPEECH COMMUN, V52, P270, DOI 10.1016/j.specom.2009.08.002
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Fukumoto M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P237, DOI 10.1145/3242587.3242603
   Funakoshi K., 2010, P 2 INT S NEW FRONT, V2
   Grandi JG, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5881, DOI 10.1145/3025453.3025935
   GREENHALGH C, 1995, INT CON DISTR COMP S, P27, DOI 10.1109/ICDCS.1995.499999
   Hagsand O, 1996, IEEE MULTIMEDIA, V3, P30, DOI 10.1109/93.486702
   Hasegawa Komei, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P350, DOI 10.1109/ROMAN.2013.6628491
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Holler J., 2016, Turn-taking in human communicative interaction
   Inkpen Kori, 2013, P 2013 C COMP SUPP C, P1329, DOI DOI 10.1145/2441776.2441926
   Jones B, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1123, DOI 10.1145/2901790.2901847
   Kimura N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300376
   Li Z., 2021, P 2021 CHI C HUMAN F, DOI [10.1145/3411764.34455379[28]A, DOI 10.1145/3411764.34455372]
   Mamuji A., 2003, EXTENDED ABSTRACTS U, V3
   @Microsoft2021, 2021, WELC ALTSP
   Nadler R., 2020, Comput. Compos, V58, P102613, DOI DOI 10.1016/J.COMPCOM.2020.102613
   Oh Alice, 2002, CHI 02 EXTENDED ABST, P650, DOI [DOI 10.1145/506443.506528, 10.1145/506443, DOI 10.1145/506443]
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Qin Y., 2021, P 2021 CHI C HUMAN F, DOI https://doi.org/10.1145/3411764.3445687
   Roider Florian, 2018, ADJ P 10 INT C AUT U, P210, DOI DOI 10.1145/3239092.3265968
   Rossano F., 2013, The handbook of conversation analysis, P308, DOI [10.1002/9781118325001.ch15, DOI 10.1002/9781118325001.CH15]
   Samrose Samiha, 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.3445615, DOI 10.1145/3411764.3445615]
   Seo JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3177761
   Shell Jeffrey S, 2003, CHI'03 extended abstracts on Human factors in computing systems, P770, DOI DOI 10.1145/765891.765981
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Sun K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P581, DOI 10.1145/3242587.3242599
   Surale F., 2019, P 2019 CHI C HUMAN F, P1
   van Braak M, 2021, LANGUAGES-BASEL, V6, DOI 10.3390/languages6020072
   Vertegaal R., 2001, P SIGCHI C HUM FACT, P301, DOI [DOI 10.1145/365024.365119, 10.1145/365024.365119]
   Vertegaal Vertegaal Roel Roel, CHI 05 EXTENDED ABST, P1861, DOI [DOI 10.1145/1056808.1057041, 10.1145/1056808.1057041 10.1145/1056808.1057041, DOI 10.1145/1056808.10570412]
   @VRChat, 2020, WELC VRCHAT
   Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852
   Williamson D. A., 2021, EXTENDED ABSTRACTS 2, P1
   Yan C., 2020, P 2020 CHI C HUMAN F, P1, DOI [10.1145/3313831.33768109[52]S, DOI 10.1145/3313831.33768109[52]S]
   Yan YK, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1013, DOI 10.1145/3332165.3347950
   Yarosh Svetlana, 2013, P 2013 C COMP SUPP C, P181, DOI [10.1145/2441776.2441798, DOI 10.1145/2441776.2441798]
   Yukang Yan, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3287076
NR 52
TC 4
Z9 4
U1 4
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2647
EP 2657
DI 10.1109/TVCG.2023.3247085
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C9UP4
UT WOS:000965287900001
PM 37027740
DA 2024-11-06
ER

PT J
AU Westermeier, F
   Brubach, L
   Latoschik, ME
   Wienrich, C
AF Westermeier, Franziska
   Brubach, Larissa
   Latoschik, Marc Erich
   Wienrich, Carolin
TI Exploring Plausibility and Presence in Mixed Reality Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Transportation; Power system reliability; X reality;
   Virtual environments; Solid modeling; Psychology; Plausibility;
   presence; congruence; mixed reality; virtual reality; augmented reality;
   spatial presence
ID VIRTUAL ENVIRONMENTS; ANOVA; MODEL; COHERENCE
AB Mixed Reality (MR) applications along Milgram's Reality-Virtuality (RV) continuum motivated a number of recent theories on potential constructs and factors describing MR experiences. This paper investigates the impact of incongruencies that are processed on different information processing layers (i.e., sensation/perception and cognition layer) to provoke breaks in plausibility. It examines the effects on spatial and overall presence as prominent constructs of Virtual Reality (VR). We developed a simulated maintenance application to test virtual electrical devices. Participants performed test operations on these devices in a counterbalanced, randomized 2x2 between-subject design in either VR as congruent or Augmented Reality (AR) as incongruent on the sensation/perception layer. Cognitive incongruence was induced by the absence of traceable power outages, decoupling perceived cause and effect after activating potentially defective devices. Our results indicate that the effects of the power outages differ significantly in the perceived plausibility and spatial presence ratings between VR and AR. Both ratings decreased for the AR condition (incongruent sensation/perception) compared to VR (congruent sensation/perception) for the congruent cognitive case but increased for the incongruent cognitive case. The results are discussed and put into perspective in the scope of recent theories of MR experiences.
C1 [Westermeier, Franziska; Brubach, Larissa] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Westermeier, Franziska; Brubach, Larissa] Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp Univ Wu, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
   [Wienrich, Carolin] Univ Wurzburg, PIIS Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg;
   University of Wurzburg
RP Westermeier, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.; Westermeier, F (corresponding author), Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp Univ Wu, Wurzburg, Germany.
EM franziska.westermeier@uni-wuerzburg.de;
   larissa.bruebach@uni-wuerzburg.de; marc.latoschik@uni-wuerzburg.de;
   carolin.wienrich@uni-wuerzburg.de
RI Latoschik, Marc/HLG-5348-2023
OI Wienrich, Carolin/0000-0003-3052-7172; Westermeier,
   Franziska/0000-0003-2534-4857; Brubach, Larissa/0000-0003-0171-7305
FU Bavarian State Ministry For Digital Affairs in the project XR Hub
   [A5-3822-2-16]
FX This research has been funded by the Bavarian State Ministry For Digital
   Affairs in the project XR Hub (project number A5-3822-2-16).
CR [Anonymous], VARJ XR 3 IND HIGH R
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Busselle R, 2008, COMMUN THEOR, V18, P255, DOI 10.1111/j.1468-2885.2008.00322.x
   Cavazza M, 2007, PRESENCE-VIRTUAL AUG, V16, P623, DOI 10.1162/pres.16.6.623
   Chertoff DB, 2008, PRESENCE-TELEOP VIRT, V17, P405, DOI 10.1162/pres.17.4.405
   Collins J, 2017, PRESENCE-TELEOP VIRT, V26, P16, DOI 10.1162/PRES_a_00284
   Connell L, 2006, COGNITIVE SCI, V30, P95, DOI 10.1207/s15516709cog0000_53
   Hamzeheinejad N, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P382, DOI 10.1109/VR50410.2021.00061
   HART S G, 1988, P139
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.2307/1165127
   Hein Rebecca, 2021, AIMS Electronics and Electrical Engineering, V5, P117
   Hofer M., 2020, FRONT VIRTUAL REAL, V1, P2, DOI DOI 10.3389/FRVIR.2020.00002
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kern F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684498
   Latoschik M. E, 2022, FRONTIERS VIRTUAL RE, V3
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Mal D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P779, DOI 10.1109/VRW55335.2022.00245
   Microsoft HoloLens, MIX REAL TECHN BUS
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Minsky Marvin, 1980, OMNIJuly, DOI DOI 10.1145/566654.566630
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Nilsson N. C., 2017, 2017 IEEE 3 WORKSH E, DOI [10.1109/WEVR.2017.7957710, DOI 10.1109/WEVR.2017.79577108]
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   philips, 2022, SMART LIGHTING
   Plabst L, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489908
   Popova L., 2010, Perceived reality of media messages: Concept explication and testing
   Pouke M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.655744
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Skarbez R., 2016, Plausibility Illusion in Virtual Environments
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Teyssier M, 2022, UNITY HUE
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.627194
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf E., 2022, PLAUSIBILITY PERCEPT, P489, DOI [10.1109/ISMAR55827.2022.00065, DOI 10.1109/ISMAR55827.2022.00065]
NR 44
TC 7
Z9 7
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2680
EP 2689
DI 10.1109/TVCG.2023.3247046
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1YV6
UT WOS:000966755100001
PM 37027719
OA hybrid
DA 2024-11-06
ER

PT J
AU Luo, ZX
   Chai, BL
   Wang, ZL
   Hu, M
   Wu, D
AF Luo, Zhenxiao
   Chai, Baili
   Wang, Zelong
   Hu, Miao
   Wu, Di
TI Masked360: Enabling Robust 360-degree Video Streaming with Ultra Low
   Bandwidth Consumption
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Streaming media; Bandwidth; Computational modeling; Packet loss;
   Training; Servers; Visualization; Multimedia streaming; Neural networks;
   360-degree video
ID SUPERRESOLUTION
AB 360-degree video streaming has gained tremendous growth over the past years. However, the delivery of 360-degree videos over the Internet still suffers from the scarcity of network bandwidth and adverse network conditions (e.g., packet loss, delay). In this paper, we propose a practical neural-enhanced 360-degree video streaming framework called Masked360, which can significantly reduce bandwidth consumption and achieve robustness against packet loss. In Masked360, instead of transmitting the complete video frame, the video server only transmits a masked low-resolution version of each video frame to reduce bandwidth significantly. When delivering masked video frames, the video server also sends a lightweight neural network model called MaskedEncoder to clients. Upon receiving masked frames, the client can reconstruct the original 360-degree video frames and start playback. To further improve the quality of video streaming, we also propose a set of optimization techniques, such as complexity-based patch selection, quarter masking strategy, redundant patch transmission and enhanced model training methods. In addition to bandwidth savings, Masked360 is also robust to packet loss during the transmission, because packet losses can be concealed by the reconstruction operation performed by the MaskedEncoder. Finally, we implement the whole Masked360 framework and evaluate its performance using real datasets. The experimental results show that Masked360 can achieve 4K 360-degree video streaming with bandwidth as low as 2.4 Mbps. Besides, video quality of Masked360 is also improved significantly, with an improvement of 5.24-16.61% in terms of PSNR and 4.74-16.15% in terms of SSIM compared to other baselines.
C1 [Luo, Zhenxiao; Chai, Baili; Wang, Zelong; Hu, Miao; Wu, Di] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Luo, Zhenxiao; Chai, Baili; Wang, Zelong; Hu, Miao; Wu, Di] Guangdong Key Lab Big Data Anal & Proc, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University
RP Hu, M; Wu, D (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM luozhx6@mail2.sysu.edu.cn; chaibli@mail2.sysu.edu.cn;
   wangzl7@mail2.sysu.edu.cn; humiao5@mail.sysu.edu.cn;
   wudi27@mail.sysu.edu.cn
RI wu, di/IYS-9217-2023; Luo, Zhenxiao/KVB-6380-2024
OI Chai, Baili/0000-0002-0569-9530
FU National Natural Science Foundation of China [U1911201, U2001209,
   62072486]; Science and Technology Planning Project of Guangdong Province
   [2021A0505110008]
FX This work was supported by the National Natural Science Foundation of
   China under Grants U1911201, U2001209, 62072486, and the Science and
   Technology Planning Project of Guangdong Province under Grant
   2021A0505110008.
CR [Anonymous], 2022, ABOUT US, P1
   [Anonymous], 2022, YOUTUBE, P1
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Cao YP, 2021, IEEE INT CONF ASAP, P69, DOI 10.1109/ASAP52443.2021.00019
   Chen JW, 2020, NOSSDAV '20: PROCEEDINGS OF THE 2020 WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P1, DOI 10.1145/3386290.3396929
   Chopra L, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2379, DOI 10.1145/3442381.3450070
   Cisco, 2022, Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 20172022
   Covaci A., 2022, IEEE T VIS COMPUT GR, P1, DOI [10.1109/TVCG.2022.31408751, DOI 10.1109/TVCG.2022.31408751]
   Dasari M, 2020, IEEE INFOCOM SER, P1977, DOI [10.1109/INFOCOM41043.2020.9155477, 10.1109/infocom41043.2020.9155477]
   Dosovitskiy Alexey, 2021, INT C LEARNING REPRE, V2, P5
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   Heyse J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P972, DOI [10.1109/vr.2019.8797830, 10.1109/VR.2019.8797830]
   Hosseini M, 2017, P IEEE VIRT REAL ANN, P423, DOI 10.1109/VR.2017.7892357
   Hosseini M, 2016, IEEE INT SYM MULTIM, P407, DOI [10.1109/ISM.2016.44, 10.1109/ISM.2016.0093]
   Hu P, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P63, DOI 10.1145/3301293.3302373
   Jiang ZQ, 2020, IEEE T BROADCAST, V66, P814, DOI 10.1109/TBC.2020.2977513
   Kellnhofer P, 2019, IEEE I CONF COMP VIS, P6911, DOI 10.1109/ICCV.2019.00701
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P107, DOI 10.1145/3387514.3405856
   Kim Y, 2019, IEEE T CIRC SYST VID, V29, P2521, DOI 10.1109/TCSVT.2018.2864321
   Kingma DP., INT C LEARNING REPRE
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee R, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3469094
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu JM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4611, DOI 10.1109/ICCV48922.2021.00459
   Liu X, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448104
   Luo Z, 2023, INDIAN J DERMATOL VE, V89, P453, DOI 10.25259/IJDVL_480_2022
   Ozcinar C, 2017, IEEE IMAGE PROC, P2174, DOI 10.1109/ICIP.2017.8296667
   Rhee T, 2017, IEEE T VIS COMPUT GR, V23, P1302, DOI 10.1109/TVCG.2017.2657178
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Twitch Interactive, 2022, TWITCH TV APR
   Wan J, 2021, IEEE T BROADCAST, V67, P372, DOI 10.1109/TBC.2020.3028356
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wightman Ross, 2023, Zenodo
   Wu CL, 2021, PROCEEDINGS OF THE 31ST ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV '21), P35, DOI 10.1145/3458306.3460995
   Yaqoob A, 2021, IEEE T BROADCAST, V67, P746, DOI 10.1109/TBC.2021.3105022
   Yeo H., 2020, P 26 ANN INT C MOBIL, DOI [10.1145/3372224.34191851, DOI 10.1145/3372224.34191851]
   Yeo H, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P645
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
NR 40
TC 6
Z9 6
U1 9
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2690
EP 2699
DI 10.1109/TVCG.2023.3247076
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2HM1
UT WOS:000966984000001
PM 37027701
DA 2024-11-06
ER

PT J
AU Zhang, Y
   Hu, XD
   Kiyokawa, K
   Yang, XB
AF Zhang, Yan
   Hu, Xiaodan
   Kiyokawa, Kiyoshi
   Yang, Xubo
TI Add-on Occlusion: Turning Off-the-Shelf Optical See-through Head-mounted
   Displays Occlusion-capable
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optical imaging; Lenses; Adaptive optics; Mirrors; Image color analysis;
   Optical polarization; Holography; Augmented reality; near-to-eye
   displays; occlusion displays; head-mounted displays; diminished reality;
   color blending
ID AUGMENTED REALITY DISPLAY; NEAR-EYE DISPLAY; MUTUAL OCCLUSION; DEPTH
   JUDGMENTS; DESIGN; COMPENSATION
AB The occlusion-capable optical see-through head-mounted display (OC-OSTHMD) is actively developed in recent years since it allows mutual occlusion between virtual objects and the physical world to be correctly presented in augmented reality (AR). However, implementing occlusion with the special type of OSTHMDs prevents the appealing feature from the wide application. In this paper, a novel approach for realizing mutual occlusion for common OSTHMDs is proposed. A wearable device with per-pixel occlusion capability is designed. OSTHMD devices are upgraded to be occlusion-capable by attaching the device before optical combiners. A prototype with HoloLens 1 is built. The virtual display with mutual occlusion is demonstrated in real-time. A color correction algorithm is proposed to mitigate the color aberration caused by the occlusion device. Potential applications, including the texture replacement of real objects and the more realistic semi-transparent objects display, are demonstrated. The proposed system is expected to realize a universal implementation of mutual occlusion in AR.
C1 [Zhang, Yan; Yang, Xubo] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Hu, Xiaodan; Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Ikoma, Japan.
C3 Shanghai Jiao Tong University; Nara Institute of Science & Technology
RP Yang, XB (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM yan-zh@sjtu.edu.cn; hu.xiaodan.ht1@is.naist.jp; kiyo@is.naist.jp;
   yangxubo@sjtu.edu.cn
RI Zhang, Yan/AEF-0238-2022
OI Hu, Xiaodan/0000-0003-0310-0907; Zhang, Yan/0000-0002-7549-4725
FU National Key Research and Development Program of China [2018YFB1004902];
   JSPS KAK-ENHI [JP22H00539]
FX This work was partially supported by the National Key Research and
   Development Program of China (2018YFB1004902) and JSPS KAK-ENHI Grant
   (JP22H00539).
CR Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   Bimber O, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P186, DOI 10.1109/ISMAR.2002.1115088
   Cakmakci O, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P16, DOI 10.1109/ISMAR.2004.2
   Cui W, 2020, OPT LETT, V45, P2808, DOI 10.1364/OL.393550
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Erickson A, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418445
   Gabbard JL, 2022, IEEE T VIS COMPUT GR, V28, P2834, DOI 10.1109/TVCG.2020.3044715
   Gabbard JL, 2013, P IEEE VIRT REAL ANN, P157, DOI 10.1109/VR.2013.6549410
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Hiroi Y., 2017, P 8 AUGM HUM INT C A, DOI [10.1145/3041164.30411782,6\n[11]M, DOI 10.1145/3041164.30411782,6]
   Inami M., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P233, DOI 10.1109/VR.2000.840503
   Itoh Y, 2019, IEEE T VIS COMPUT GR, V25, P1951, DOI 10.1109/TVCG.2019.2899229
   Itoh Y, 2017, IEEE T VIS COMPUT GR, V23, P2463, DOI 10.1109/TVCG.2017.2734427
   Ju YG, 2020, OPT LETT, V45, P3361, DOI 10.1364/OL.393194
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Kiyokawa K, 2001, COMPUT GRAPH-UK, V25, P765, DOI 10.1016/S0097-8493(01)00119-4
   Kiyokawa K, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P60, DOI 10.1109/ISAR.2000.880924
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   Langlotz T, 2016, IEEE T VIS COMPUT GR, V22, P2385, DOI 10.1109/TVCG.2016.2593781
   Maimone A, 2013, INT SYM MIX AUGMENT, P29, DOI 10.1109/ISMAR.2013.6671761
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Mori S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI 10.1109/VR.2018.8446441
   Odinokov SB, 2020, OPT EXPRESS, V28, P17581, DOI 10.1364/OE.395273
   Pan C, 2018, OPT EXPRESS, V26, P26646, DOI 10.1364/OE.26.026646
   Pascale D., 2006, RGB COORDINATES MACB, V6
   Peck J. J., 2022, IEEE T VIS COMPUT GR, V28, P1
   Polvi J, 2018, IEEE T VIS COMPUT GR, V24, P2118, DOI 10.1109/TVCG.2017.2709746
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   Swan JE, 2007, IEEE T VIS COMPUT GR, V13, P429, DOI 10.1109/TVCG.2007.1035
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   Wilson A, 2017, OPT EXPRESS, V25, P30539, DOI 10.1364/OE.25.030539
   Wilson H., 2021, IEEE T VIS COMPUT GR, V2, P9
   Zhang R., 2021, IEEE T VIS COMPUT GR, V2
   Zhang Y, 2021, OPT EXPRESS, V29, P42751, DOI 10.1364/OE.444904
   Zhang Y, 2021, OPT LETT, V46, P4208, DOI 10.1364/OL.428714
   Zhang Y, 2020, INT SYM MIX AUGMENT, P301, DOI 10.1109/ISMAR50242.2020.00056
   Zhou PC, 2018, OPT EXPRESS, V26, P22866, DOI 10.1364/OE.26.022866
NR 39
TC 3
Z9 3
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2700
EP 2709
DI 10.1109/TVCG.2023.3247064
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1EM4
UT WOS:000966223100001
PM 37027617
DA 2024-11-06
ER

PT J
AU Zhao, Y
   Stefanucci, J
   Creem-Regehr, S
   Bodenheimer, B
AF Zhao, Yu
   Stefanucci, Jeanine
   Creem-Regehr, Sarah
   Bodenheimer, Bobby
TI Evaluating Augmented Reality Landmark Cues and Frame of Reference
   Displays with Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented Reality; Virtual Reality; Spatial Information Displays
ID SPATIAL KNOWLEDGE ACQUISITION; INDIVIDUAL-DIFFERENCES;
   GENDER-DIFFERENCES; SEX-DIFFERENCES; COGNITIVE MAP; NAVIGATION;
   PERFORMANCE; STRATEGIES; DRIVERS; SCALE
AB Daily travel usually demands navigation on foot across a variety of different application domains, including tasks like search and rescue or commuting. Head-mounted augmented reality (AR) displays provide a preview of future navigation systems on foot, but designing them is still an open problem. In this paper, we look at two choices that such AR systems can make for navigation: 1) whether to denote landmarks with AR cues and 2) how to convey navigation instructions. Specifically, instructions can be given via a head-referenced display (screen-fixed frame of reference) or by giving directions fixed to global positions in the world (world-fixed frame of reference). Given limitations with the tracking stability, field of view, and brightness of most currently available head-mounted AR displays for lengthy routes outdoors, we decided to simulate these conditions in virtual reality. In the current study, participants navigated an urban virtual environment and their spatial knowledge acquisition was assessed. We experimented with whether or not landmarks in the environment were cued, as well as how navigation instructions were displayed (i.e., via screen-fixed or world-fixed directions). We found that the world-fixed frame of reference resulted in better spatial learning when there were no landmarks cued; adding AR landmark cues marginally improved spatial learning in the screen-fixed condition. These benefits in learning were also correlated with participants' reported sense of direction. Our findings have implications for the design of future cognition-driven navigation systems.
C1 [Zhao, Yu; Bodenheimer, Bobby] Vanderbilt Univ, Nashville, TN 37235 USA.
   [Stefanucci, Jeanine; Creem-Regehr, Sarah] Univ Utah, Salt Lake City, UT USA.
C3 Vanderbilt University; Utah System of Higher Education; University of
   Utah
RP Zhao, Y (corresponding author), Vanderbilt Univ, Nashville, TN 37235 USA.
EM yu.zhao@vanderbilt.edu; jeanine.stefanucci@psych.utah.edu;
   sarah.creem@psych.utah.edu; bobby.bodenheimer@vanderbilt.edu
RI Zhao, Yu/LDE-7466-2024
FU Office of Naval Research [N0014-21-1-2583]
FX This material is based upon work supported by the Office of Naval
   Research under grant N0014-21-1-2583.
CR Anandapadmanaban E., 2018, 48 INT C ENV SYSTEMS
   [Anonymous], APPL MAPS INTR NEW W
   [Anonymous], AR VR GOOGL
   [Anonymous], AV HEAD LOCK CONT
   [Anonymous], HOL FRAM CONS
   [Anonymous], LIGHTSH VPS
   [Anonymous], BUILD GLOB SCAL IMM
   [Anonymous], 1998, SPATIAL TEMPORAL REA
   Ayers JW, 2016, JAMA INTERN MED, V176, P1865, DOI 10.1001/jamainternmed.2016.6274
   Bark K, 2014, AUTOMOTIVEUI'14: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P3, DOI 10.1145/2667317.2667329
   Bauerfeind K, 2021, APPL ERGON, V94, DOI 10.1016/j.apergo.2021.103398
   Billinghurst M, 1998, IEEE COMPUT GRAPH, V18, P24, DOI 10.1109/38.734976
   Bolton A., 2015, 7 INT C AUTOMOTIVE U, DOI [DOI 10.1145/2799250.2799253, 10.1145/2799250]
   Carbon CC, 2013, J STAT SOFTW, V52, P1
   Castelli L, 2008, COMPUT HUM BEHAV, V24, P1643, DOI 10.1016/j.chb.2007.06.005
   Chai XJ, 2009, BEHAV NEUROSCI, V123, P276, DOI 10.1037/a0014722
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Chung J, 2016, TECHNOL SOC, V45, P29, DOI 10.1016/j.techsoc.2016.02.006
   Cogné M, 2017, ANN PHYS REHABIL MED, V60, P164, DOI 10.1016/j.rehab.2015.12.004
   Dahmani L, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62877-0
   Dominic J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P607, DOI [10.1109/VR46266.2020.00-21, 10.1109/VR46266.2020.1581637338566]
   Dong WH, 2022, ANN AM ASSOC GEOGR, V112, P226, DOI 10.1080/24694452.2021.1894088
   Dong WH, 2021, CARTOGR GEOGR INF SC, V48, P225, DOI 10.1080/15230406.2021.1871646
   Du AT, 2001, J NEUROL NEUROSUR PS, V71, P441, DOI 10.1136/jnnp.71.4.441
   Faria ND, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P763, DOI [10.1109/VRW50115.2020.00232, 10.1109/VRW50115.2020.00-43]
   Fukushima S, 2020, INT SYM MIX AUGMENT, P649, DOI 10.1109/ISMAR50242.2020.00093
   Gardony AL, 2013, SPAT COGN COMPUT, V13, P319, DOI 10.1080/13875868.2013.792821
   Ghasemi Yalda, 2021, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1094, DOI 10.1177/1071181321651169
   Gramann K, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00193
   Grandi JG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P23, DOI 10.1109/VRW52623.2021.00011
   Grasset R, 2011, HANDBOOK OF AUGMENTED REALITY, P379, DOI 10.1007/978-1-4614-0064-6_18
   Grinyer K, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P139, DOI 10.1109/VR51125.2022.00032
   Hamilton Matthew Allan, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P21, DOI 10.1145/3463914.3463918
   He QL, 2019, J EXP PSYCHOL LEARN, V45, P1364, DOI 10.1037/xlm0000654
   He WB, 2021, MEASUREMENT, V184, DOI 10.1016/j.measurement.2021.109973
   Hegarty M, 2006, INTELLIGENCE, V34, P151, DOI 10.1016/j.intell.2005.09.005
   Hegarty M, 2002, INTELLIGENCE, V30, P425, DOI 10.1016/S0160-2896(02)00116-2
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   Huang HS, 2012, CARTOGR GEOGR INF SC, V39, P107, DOI 10.1559/15230406392107
   Huffman DJ, 2019, SPAT COGN COMPUT, V19, P93, DOI 10.1080/13875868.2018.1531869
   Imamov S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P851, DOI [10.1109/VR46266.2020.1581435674325, 10.1109/VR46266.2020.00110]
   Ishikawa T, 2006, COGNITIVE PSYCHOL, V52, P93, DOI 10.1016/j.cogpsych.2005.08.003
   Ishikawa T, 2008, J ENVIRON PSYCHOL, V28, P74, DOI 10.1016/j.jenvp.2007.09.002
   Ishikawa T, 2019, PROF GEOGR, V71, P197, DOI 10.1080/00330124.2018.1479970
   Kerr S.J., 2011, P 10 INT C VIRT REAL, P209
   Kim H, 2018, IEEE T VIS COMPUT GR, V24, P1515, DOI 10.1109/TVCG.2018.2793680
   Kim H, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P294, DOI 10.1145/2856767.2856815
   Klose EM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P636, DOI [10.1109/vr.2019.8797992, 10.1109/VR.2019.8797992]
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174007
   Konishi K, 2013, FRONT AGING NEUROSCI, V5, DOI 10.3389/fnagi.2013.00001
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kruijff E, 2019, IEEE T VIS COMPUT GR, V25, P2821, DOI 10.1109/TVCG.2018.2854737
   Krukar J, 2020, J ENVIRON PSYCHOL, V68, DOI 10.1016/j.jenvp.2020.101407
   Lakehal A., 2021, 22 INT C HUM COMP IN, DOI [10.1145/3406324.3410722, DOI 10.1145/3406324.3410722]
   LAWTON CA, 1994, SEX ROLES, V30, P765, DOI 10.1007/BF01544230
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P802, DOI 10.1109/VR51125.2022.00102
   Lee J, 2022, APPL ECON PERSPECT P, V44, P511, DOI 10.1002/aepp.13149
   Lester AW, 2017, NEURON, V95, P1019, DOI 10.1016/j.neuron.2017.06.037
   Liu B, 2021, CARTOGR GEOGR INF SC, V48, P305, DOI 10.1080/15230406.2021.1908171
   Liu J, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10855-z
   Maguire EA, 2006, HIPPOCAMPUS, V16, P1091, DOI 10.1002/hipo.20233
   Marín-Morales J, 2019, INTERACT COMPUT, V31, P208, DOI 10.1093/iwc/iwz018
   Marquardt A, 2020, IEEE T VIS COMPUT GR, V26, P3389, DOI 10.1109/TVCG.2020.3023605
   McKendrick R, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00216
   Merenda C, 2018, IEEE T VIS COMPUT GR, V24, P2875, DOI 10.1109/TVCG.2018.2868531
   Montuwy A, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010017
   Nazareth A, 2019, PSYCHON B REV, V26, P1503, DOI 10.3758/s13423-019-01633-6
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Padilla LM, 2017, PSYCHON B REV, V24, P582, DOI 10.3758/s13423-016-1118-2
   Pazzaglia F., 2007, SPAT COGN COMPUT, V7, P349, DOI DOI 10.1080/13875860701663223
   Rehman U, 2017, IEEE T HUM-MACH SYST, V47, P140, DOI 10.1109/THMS.2016.2620106
   REITMAYR G, 2004, 3 IEEE ACM INT S MIX
   Reitmayr G., 2003, P 4 AUSTR US INT C U, V18, P65
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   Robertson CM, 2008, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2008.4637328
   Ruginski IT, 2019, J ENVIRON PSYCHOL, V64, P12, DOI 10.1016/j.jenvp.2019.05.001
   Rzayev R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173619
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Schankin A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P25, DOI 10.1109/ISMAR-Adjunct.2017.24
   Schinazi VR, 2013, HIPPOCAMPUS, V23, P515, DOI 10.1002/hipo.22111
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Smith M, 2021, APPL ERGON, V96, DOI 10.1016/j.apergo.2021.103510
   Terrier R, 2018, LECT NOTES COMPUT SC, V11162, P190, DOI 10.1007/978-3-030-01790-3_12
   Tram Thi Minh Tran, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382868
   Weisberg SM, 2014, J EXP PSYCHOL LEARN, V40, P669, DOI 10.1037/a0035261
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wiener JM, 2013, J NEUROSCI, V33, P6012, DOI 10.1523/JNEUROSCI.0717-12.2013
   Wolbers T, 2010, TRENDS COGN SCI, V14, P138, DOI 10.1016/j.tics.2010.01.001
   Wunderlich A, 2021, J ENVIRON PSYCHOL, V77, DOI 10.1016/j.jenvp.2021.101677
   Yesiltepe D, 2021, COGN PROCESS, V22, P369, DOI 10.1007/s10339-021-01012-x
   Zhang H, 2014, MEM COGNITION, V42, P1106, DOI 10.3758/s13421-014-0418-x
   Zhang JY, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101432
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zhao YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P387, DOI 10.1145/3332165.3347906
NR 97
TC 8
Z9 9
U1 4
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2710
EP 2720
DI 10.1109/TVCG.2023.3247078
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0JR8
UT WOS:000965681100001
PM 37027707
DA 2024-11-06
ER

PT J
AU Wijayanto, IA
   Babu, SV
   Pagano, CC
   Chuang, JH
AF Wijayanto, Ignatius Alex
   Babu, Sabarish V.
   Pagano, Christopher C.
   Chuang, Jung Hong
TI Comparing the Effects of Visual Realism on Size Perception in VR versus
   Real World Viewing through Physical and Verbal Judgments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Virtual environments; Size measurement; Particle
   measurements; Atmospheric measurements; Training; Solid modeling;
   Virtual reality; Size perception; Render Style; Empirical evaluation;
   User Studies
ID MONOCULAR DISTANCE PERCEPTION; EYE HEIGHT; FEEDBACK
AB Virtual Reality (VR) is well-known for its use in interdisciplinary applications and research. The visual representation of these applications could vary depending in their purpose and hardware limitation, and in those situations could require an accurate perception of size for task performance. However, the relationship between size perception and visual realism in VR has not yet been explored. In this contribution, we conducted an empirical evaluation using a between-subject design over four conditions of visual realism, namely Realistic, Local Lighting, Cartoon, and Sketch on size perception of target objects in the same virtual environment. Additionally, we gathered participants' size estimates in the real world via a within-subject session. We measured size perception using concurrent verbal reports and physical judgments. Our result showed that although participants' size perception was accurate in the realistic condition, surprisingly they could still tune into the invariant but meaningful information in the environment to accurately estimate the size of targets in the non-photorealistic conditions as well. We additionally found that size estimates in verbal and physical responses were generally different in real world and VR viewing and were moderated by trial presentation over time and target object widths.
C1 [Wijayanto, Ignatius Alex] Natl Yang Ming Chiao Tung Univ, EECS Int Grad Program, Hsinchu, Taiwan.
   [Babu, Sabarish V.] Clemson Univ, Sch Comp, Res, Clemson, SC USA.
   [Pagano, Christopher C.] Clemson Univ, Dept Psychol, Res, Clemson, SC USA.
   [Chuang, Jung Hong] Natl Yang Ming Chiao Tung Univ, Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University; Clemson University; Clemson
   University; National Yang Ming Chiao Tung University
RP Wijayanto, IA (corresponding author), Natl Yang Ming Chiao Tung Univ, EECS Int Grad Program, Hsinchu, Taiwan.
EM alex.ee07@nycu.edu.tw; sbabu@clemson.edu; cpagano@clemson.edu;
   jhchuang@cs.nctu.edu.tw
OI Pagano, Christopher/0000-0002-0110-2055; Babu,
   Sabarish/0000-0002-8348-0534
FU US National Science Foundation (CISE IIS HCC) [2007435]; MOST project
   [111-2221-E-A49-128]
FX The authors would like to thank the participants of the study for their
   time. This work was supported in part by the US National Science
   Foundation (CISE IIS HCC) under Grant No. 2007435 and MOST project under
   Grant No. 111-2221-E-A49-128
CR [Anonymous], 2013, P 40 INT C COMP GRAP
   Babu Sabarish V., 2022, 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), P404, DOI 10.1109/ISMAR55827.2022.00056
   Babu SV, 2011, IEEE T VIS COMPUT GR, V17, P14, DOI 10.1109/TVCG.2009.211
   Bertamini T. L., 1998, RELATIVE SIZE PERCEP, V4
   Bhargava A, 2018, IEEE T VIS COMPUT GR, V24, P1418, DOI 10.1109/TVCG.2018.2794639
   Bingham GP, 1998, J EXP PSYCHOL HUMAN, V24, P145, DOI 10.1037/0096-1523.24.1.145
   Cutting P. M., PERCEPTION SPACE MOT, P69, DOI [10.1016/B978-012240530-3/50005-52[7]A.G., DOI 10.1016/B978-012240530-3/50005-52[7]A.G]
   Deng ZH, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343135
   Dixon MW, 2000, J EXP PSYCHOL HUMAN, V26, P582, DOI 10.1037/0096-1523.26.2.582
   Duchon AP, 2002, PSYCHOL SCI, V13, P272, DOI 10.1111/1467-9280.00450
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Elhelw M, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279643
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI 10.1145/1836248.1836259
   Gibson JJ., 1979, ECOLOGICAL APPROACH
   Gooch A.A., 2010, NPAR 10 P 8 INT S NO, P165
   Haber RN, 2001, PERCEPT PSYCHOPHYS, V63, P1140, DOI 10.3758/BF03194530
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Holaday B. E., 1932, GROSSENKONSTANZ SEHD, P5
   Jerald J., 2015, VR BOOK HUMAN CENTER, DOI [10.1145/2792790, DOI 10.1145/2792790]
   Jerald J., 2015, The VR book: Human-centered design for virtual reality, P1
   Jung S, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P60, DOI 10.1145/3267782.3267920
   Kenyon RV, 2007, PRESENCE-TELEOP VIRT, V16, P172, DOI 10.1162/pres.16.2.172
   Kim Jangyoon, 2017, P 27 INT C ART REAL, P153
   Lake Adam, 2000, P 1 INT S NONPH REND, P13, DOI [DOI 10.1145/340916.340918, 10.1145/340916.340918]
   LANDY MS, 1995, VISION RES, V35, P389, DOI 10.1016/0042-6989(94)00176-M
   Lathan CE, 2002, PRESENCE-TELEOP VIRT, V11, P368, DOI 10.1162/105474602760204282
   Leyrer M., 2011, P ACM SIGGRAPH S APP, P67, DOI [10.1145/2077451.20774642, DOI 10.1145/2077451.20774642, 10.1145/2077451.2077464]
   Linkenauger SA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0068594
   Linkenauger SA, 2011, J EXP PSYCHOL HUMAN, V37, P1432, DOI 10.1037/a0024248
   Linkenauger SA, 2010, PSYCHOL SCI, V21, P1318, DOI 10.1177/0956797610380700
   Loomis J.M., 2008, EMBODIMENT EGO SPACE, P1, DOI DOI 10.1145/1498700.1498702
   Luo X, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P59
   MacLachlan C, 2002, OPHTHAL PHYSL OPT, V22, P175, DOI 10.1046/j.1475-1313.2002.00023.x
   Mania K, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670673
   McDonnell M., ACM T GRAPHIC, V31, P72012, DOI [10.1145/2185520.21855872,3,4[38]M, DOI 10.1145/2185520.21855872,3,4[38]M]
   Mojsilovic A, 2003, P SOC PHOTO-OPT INS, V5007, P22, DOI 10.1117/12.485415
   Nagendran M, 2013, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006575.pub3
   Napieralski B. M., ACM T APPL PERCEPT, V8, P82011, DOI [10.1145/2010325.\n20103283,4,6,9[40]N, DOI 10.1145/2010325]
   Ogawa Nami, 2019, 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR), P519, DOI 10.1109/VR.2019.8798040
   Ogawa T., 25 IEEE C VIRT REAL, P82018, DOI [10.1109/VR.2018.84463182[42]N, DOI 10.1109/VR.2018.84463182[42]N]
   Ogawa T., ACM INT C P SER ASS, V32017, DOI [10.1145/3041164.30412042,3[41]N, DOI 10.1145/3041164.30412042,3[41]N]
   Pagano CC, 1998, J EXP PSYCHOL HUMAN, V24, P1037, DOI 10.1037/0096-1523.24.4.1037
   Pagano CC, 2008, PSYCHON B REV, V15, P437, DOI 10.3758/PBR.15.2.437
   Pardo M. I., J OPT SOC AM A
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Proffitt DR, 1995, PSYCHON B REV, V2, P409, DOI 10.3758/BF03210980
   Rademacher P, 2001, SPRING EUROGRAP, P235
   Renner RS., 2013, ACM Comput Surv (Csur), V46, P1, DOI DOI 10.1145/2543581.2543590
   Rose FD, 2000, ERGONOMICS, V43, P494, DOI 10.1080/001401300184378
   ROTHBAUM BO, 1995, AM J PSYCHIAT, V152, P626
   Rudolph Bryson, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P666, DOI 10.1007/978-3-030-64556-4_52
   Siqueira De, P 2021 IEEE C VIRT R, P606
   Sperandio I, 2015, MULTISENS RES, V28, P253, DOI 10.1163/22134808-00002483
   Tajadura-Jiménez A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09497-3
   Thomas BH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10114049
   Tozawa J, 2010, PERCEPTION, V39, P641, DOI 10.1068/p6440
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Volonte M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P141, DOI 10.1145/3308532.3329461
   Weast RAT, 2018, CONSCIOUS COGN, V64, P121, DOI 10.1016/j.concog.2018.02.013
   Wenjing Xiao, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Methods and Algorithms. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 179), P179, DOI 10.1007/978-981-15-3863-6_20
   Wesp R, 2004, PERCEPT PSYCHOPHYS, V66, P1261, DOI 10.3758/BF03194996
   Withagen R, 2005, J EXP PSYCHOL HUMAN, V31, P1379, DOI 10.1037/0096-1523.31.6.1379
   Witt JK, 2005, PSYCHOL SCI, V16, P937, DOI 10.1111/j.1467-9280.2005.01640.x
   Witt JK, 2005, J EXP PSYCHOL HUMAN, V31, P880, DOI 10.1037/0096-1523.31.5.880
   Wraga M, 1999, PERCEPT PSYCHOPHYS, V61, P490, DOI 10.3758/BF03211968
   Zell E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818126
NR 67
TC 4
Z9 4
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2721
EP 2731
DI 10.1109/TVCG.2023.3247109
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0AJ6
UT WOS:000965438200001
PM 37027728
DA 2024-11-06
ER

PT J
AU Song, LC
   Chen, AP
   Li, Z
   Chen, Z
   Chen, LL
   Yuan, JS
   Xu, Y
   Geiger, A
AF Song, Liangchen
   Chen, Anpei
   Li, Zhong
   Chen, Zhang
   Chen, Lele
   Yuan, Junsong
   Xu, Yi
   Geiger, Andreas
TI NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed
   Neural Radiance Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neural rendering; free-viewpoint video; immersive video; NeRF
ID VIDEO
AB Visually exploring in a real-world 4D spatiotemporal space freely in VR has been a long-term quest. The task is especially appealing when only a few or even single RGB cameras are used for capturing the dynamic scene. To this end, we present an efficient framework capable of fast reconstruction, compact modeling, and streamable rendering. First, we propose to decompose the 4D spatiotemporal space according to temporal characteristics. Points in the 4D space are associated with probabilities of belonging to three categories: static, deforming, and new areas. Each area is represented and regularized by a separate neural field. Second, we propose a hybrid representations based feature streaming scheme for efficiently modeling the neural fields. Our approach, coined NeRFPlayer, is evaluated on dynamic scenes captured by single hand-held cameras and multi-camera arrays, achieving comparable or superior rendering performance in terms of quality and speed comparable to recent state-of-the-art methods, achieving reconstruction in 10 seconds per frame and interactive rendering. Project website: https://bit.ly/nerfplayer.
C1 [Song, Liangchen; Yuan, Junsong] SUNY Buffalo, Buffalo, NY USA.
   [Song, Liangchen; Li, Zhong; Chen, Zhang; Chen, Lele; Xu, Yi] InnoPeak Technol, OPPO US Res Ctr, Palo Alto, CA 94303 USA.
   [Chen, Anpei] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Chen, Anpei; Geiger, Andreas] Univ Tubingen, Tubingen, Germany.
C3 State University of New York (SUNY) System; University at Buffalo, SUNY;
   Swiss Federal Institutes of Technology Domain; ETH Zurich; Eberhard
   Karls University of Tubingen
RP Li, Z (corresponding author), InnoPeak Technol, OPPO US Res Ctr, Palo Alto, CA 94303 USA.
EM lsong8@buffalo.edu; zhonglee323@gmail.com
RI Li, Zhong/GYU-9049-2022; Chen, Lele/AAW-1209-2021; Song,
   Liangchen/AAZ-9431-2021; Yuan, Junsong/A-5171-2011
OI Yuan, Junsong/0000-0002-7901-8793; Chen, Zhang/0000-0001-8582-1024; Li,
   Zhong/0000-0002-7416-1216; Geiger, Andreas/0000-0002-8151-3726; Chen,
   Anpei/0000-0003-2150-2176; Chen, Lele/0000-0002-7073-0450
CR Attal B, 2023, Arxiv, DOI arXiv:2301.02238
   Bansal A, 2020, PROC CVPR IEEE, P5365, DOI 10.1109/CVPR42600.2020.00541
   Bemana M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417827
   Boss M, 2021, ADV NEUR IN, V34
   Boss M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12664, DOI 10.1109/ICCV48922.2021.01245
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Chen A., 2022, P EUROPEAN C COMPUTE
   Chibane J., 2020, Advances in Neural Information Processing Systems (NeurIPS), V33, P2
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Deng N., 2021, IEEE T VIS COMPUT GR, V28, P2
   Du YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14304, DOI 10.1109/ICCV48922.2021.01406
   Fang J., 2021, arXiv
   Fang J., 2022, arXiv
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gan WS, 2024, Arxiv, DOI arXiv:2205.14332
   Gao Hang, 2022, Neural Information Processing Systems (NeurIPS)
   Garbin SJ, 2021, P IEEECVF INT C COMP, P14346
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hedman P., 2021, Baking Neural Radiance Fields for Real-Time View Synthesis, P5875
   Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094
   Jain R., 1995, Proceedings of the International Conference on Multimedia Computing and Systems (Cat. No.95TH8066), P202, DOI 10.1109/MMCS.1995.484925
   Jang H, arXiv
   Kanade T, 1997, IEEE MULTIMEDIA, V4, P34, DOI 10.1109/93.580394
   Kobayashi Sosuke, 2022, ARXIV
   Kopf J, 2021, PROC CVPR IEEE, P1611, DOI 10.1109/CVPR46437.2021.00166
   Kosiorek Adam R, 2021, ICML, P5742
   Kurz A., 2022, EUR C COMP VIS
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li L., 2022, NEURAL INFORM PROCES
   Li T., 2022, P IEEE CVF C COMP VI, P5521
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Li Zhong, 2022, EUROGRAPHICS S RENDE
   LiaoWang Jiakai Zhang, 2022, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P13524
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu J.-W., 2022, arXiv
   Liu Lingjie, 2020, Advances in Neural Information Processing Systems, V2, P3
   Liu RH, 2022, NAT MACH INTELL, V4, P781, DOI 10.1038/s42256-022-00530-3
   Lombardi S, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459863, 10.1145/3476576.3476608]
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Lucey S., 2021, PREPRINT
   Luo X, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392377
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mildenhall B, 2022, PROC CVPR IEEE, P16169, DOI 10.1109/CVPR52688.2022.01571
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Neff T., 2021, COMPUT GRAPH FORUM, V40, DOI [10.1111/cgf.143402, DOI 10.1111/CGF.143402]
   Niemeyer M, 2019, IEEE I CONF COMP VIS, P5378, DOI 10.1109/ICCV.2019.00548
   Ost J, 2021, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR46437.2021.00288
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Paszke A, 2019, ADV NEUR IN, V32
   Piala M, 2021, INT CONF 3D VISION, P1106, DOI 10.1109/3DV53792.2021.00118
   Pumarola Albert, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P10313, DOI 10.1109/CVPR46437.2021.01018
   Rebain D, 2021, PROC CVPR IEEE, P14148, DOI 10.1109/CVPR46437.2021.01393
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Schirmacher H, 2001, COMPUT GRAPH FORUM, V20, pC165, DOI 10.1111/1467-8659.00509
   Sharma P, 2023, Arxiv, DOI arXiv:2207.11232
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538
   Takikawa T, 2022, ACM SIGGRAPH 2022 Conference Proceedings, P1
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tancik M., 2022, P IEEECVF C COMPUTER, P8248
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Tschernezki V., 2022, P INT C 3D VISION 3D
   Tschernezki V, 2021, INT CONF 3D VISION, P910, DOI 10.1109/3DV53792.2021.00099
   Wang F, 2023, Arxiv, DOI arXiv:2212.00190
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Wu L., 2022, P IEEECVF C COMPUTER, P16200
   Wu T., 2022, arXiv
   Xian WQ, 2021, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR46437.2021.00930
   Xie YH, 2022, COMPUT GRAPH FORUM, V41, P641, DOI 10.1111/cgf.14505
   Yang B., 2021, P IEEE CVF INT C COM, P13779
   Yang J. C., 2002, Rendering Techniques 2002. Eurographics Workshop Proceedings, P77
   Yu Alex, 2021, pixelnerf: Neural radiance fields from one or few images, P2
   Yuan WT, 2021, PROC CVPR IEEE, P13139, DOI 10.1109/CVPR46437.2021.01294
   Zhang JK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459756
   Zhang XS, 2022, PROC CVPR IEEE, P5439, DOI 10.1109/CVPR52688.2022.00537
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 84
TC 32
Z9 34
U1 4
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2732
EP 2742
DI 10.1109/TVCG.2023.3247082
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0JV2
UT WOS:000965684600001
PM 37027699
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bouzbib, E
   Pacchierotti, C
   Lécuyer, A
AF Bouzbib, Elodie
   Pacchierotti, Claudio
   Lecuyer, Anatole
TI When Tangibles Become Deformable: Studying Pseudo-Stiffness Perceptual
   Thresholds in a VR Grasping Task
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Force; Deformation; Visualization; Grasping; Shape;
   Rendering (computer graphics); Virtual Reality; Pseudo-Haptics;
   Pseudo-Stiffness; Grasp; Thresholds; Perception; Stiffness; Compliance;
   Consistency
AB Pseudo-Haptic techniques, or visuo-haptic illusions, leverage user's visual dominance over haptics to alter the users' perception. As they create a discrepancy between virtual and physical interactions, these illusions are limited to a perceptual threshold. Many haptic properties have been studied using pseudo-haptic techniques, such as weight, shape or size. In this paper, we focus on estimating the perceptual thresholds for pseudo-stiffness in a virtual reality grasping task. We conducted a user study (n = 15) where we estimated if compliance can be induced on a non-compressible tangible object and to what extent. Our results show that (1) compliance can be induced in a rigid tangible object and that (2) pseudo-haptics can simulate beyond 24 N/cm stiffness (k = 24N/cm, between a gummy bear and a raisin, up to rigid objects). Pseudo-stiffness efficiency is (3) enhanced by the objects' scales, but mostly (4) correlated to the user input force. Taken altogether, our results offer novel opportunities to simplify the design of future haptic interfaces, and extend the haptic properties of passive props in VR.
C1 [Bouzbib, Elodie; Pacchierotti, Claudio; Lecuyer, Anatole] Univ Rennes, Ctr Inria, IRISA, CNRS, Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes
RP Bouzbib, E (corresponding author), Univ Rennes, Ctr Inria, IRISA, CNRS, Rennes, France.
EM elodie.bouzbib@inria.fr; claudio.pacchierotti@irisa.fr;
   anatole.lecuyer@inria.fr
RI Bouzbib, Elodie/HKV-5037-2023; Pacchierotti, Claudio/G-7304-2011
OI Pacchierotti, Claudio/0000-0002-8006-9168; Bouzbib,
   Elodie/0000-0002-5221-2991
CR Abtahi P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173724
   Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   [Anonymous], 2018, P 2018 CHI C HUMAN F, DOI DOI 10.1145/3173574.3173724
   Argelaguet F, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2501599
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Ban Y., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P211, DOI 10.1109/HAPTIC.2012.6183793
   Ban Yuki, 2012, P 18 ACM S VIRT REAL, P93, DOI [DOI 10.1145/2407336.2407353[8]H, DOI 10.1145/2407336.2407353]
   Barreiro H, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P403, DOI 10.1109/WHC49131.2021.9517171
   Benko C., 2019, P 2019 CHI C HUMAN F, P1, DOI [10.1145/3290605.3300550[40]A.L., DOI 10.1145/3290605.3300550[40]A.L]
   Bergström J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1175, DOI 10.1145/3332165.3347939
   Blaga M., 2020, TOO HOT HANDLE EVALU, P16
   Bouzbib E., 2021, 32 C FRANC INT HOMM
   Bouzbib Elodie, 2020, P 33 ANN ACM S USER, P209, DOI DOI 10.1145/3379337.3415891
   Bouzbib G., 2022, VR 2022 IEEE C VIRT, P1, DOI [10.1109/VR51125.2022.00055[12]E, DOI 10.1109/VR51125.2022.00055[12]E]
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Cheymol A, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P218, DOI 10.1145/3519391.3519410
   Choi I, 2021, IEEE T VIS COMPUT GR, V27, P4387, DOI 10.1109/TVCG.2020.3002245
   Clarence A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P150, DOI 10.1109/VR50410.2021.00036
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   EuroHaptics, 2012, LECT NOTES COMPUTER
   Follmer D., 2013, P 26 ANN ACM S US IN, P417, DOI [10.1145/2501988.2502032[20]E.J., DOI 10.1145/2501988.2502032]
   Follmer S., 2013, P 26 ANN ACM S US IN, V13, P417, DOI [10.1145/2501988.2502032, DOI 10.1145/2501988.2502032]
   Gonzalez Eric J., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P732, DOI 10.1145/3472749.3474782
   Gonzalez -Franco M., 2022, PREPRINTS, DOI [10.36227/techrxiv.20182229.v1, DOI 10.36227/TECHRXIV.20182229.V1]
   Heo S, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P803, DOI 10.1145/3332165.3347941
   Insko Brent Edward, 2001, Passive haptics significantly enhances virtual environments
   Kohli L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P105, DOI 10.1109/3DUI.2012.6184193
   Lam L.-H., 2022, 3DEFORMR FREEHAND 3D, DOI [10.1145/3524273.3528180[26]F, DOI 10.1145/3524273.3528180]
   Lebrun S., TRAJECTORY MODEL DES
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   LEDERMAN SJ, 1993, ACTA PSYCHOL, V84, P29, DOI 10.1016/0001-6918(93)90070-8
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Moscatelli A, 2016, CURR BIOL, V26, P1159, DOI 10.1016/j.cub.2016.02.052
   Muender T, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519715
   Pusch O., 2009, INT J HUM-COMPUT ST, P13
   Razzaque Z., 2001, REDIRECTED WALKING
   Rietzler G., 2019, VIRTUAL MUSCLE FORCE, P10
   Rietzler M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173702
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Salazar SV, 2020, IEEE T HAPTICS, V13, P167, DOI 10.1109/TOH.2020.2967389
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Siu AF, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173865
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Tanaka Yudai, 2020, VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology, DOI 10.1145/3385956.3418964
   Ujitoko Y., 2021, IEEE T HAPTICS, P1, DOI [10.1109/TOH.2021.3077619[47]Y., DOI 10.1109/TOH.2021.3077619[47]Y]
   Williams SH, 2005, AM J PRIMATOL, V67, P329, DOI 10.1002/ajp.20189
   Yabe S, 2017, 2017 IEEE WORLD HAPTICS CONFERENCE (WHC), P557, DOI 10.1109/WHC.2017.7989962
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zhang Y., 2022, IEEE T VISUALIZATION, P1, DOI [10.1109/TVCG.2022.3203087[54]Z.A., DOI 10.1109/TVCG.2022.3203087[54]Z.A]
   Zhao YW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174118
   Zook ZA, 2022, IEEE T HAPTICS, V15, P212, DOI 10.1109/TOH.2021.3112509
NR 54
TC 5
Z9 7
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2743
EP 2752
DI 10.1109/TVCG.2023.3247083
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2LK8
UT WOS:000967087000001
PM 37028356
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, YQ
   Popescu, V
AF Zhou, Yuqi
   Popescu, Voicu
TI Dynamic Redirection for VR Haptics with a Handheld Stick
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Shape; Three-dimensional displays; Electronic mail;
   Virtual reality; Synchronization; Safety; Passive haptics; redirection;
   detection thresholds; virtual reality
AB This paper proposes a general handheld stick haptic redirection method that allows the user to experience complex shapes with haptic feedback through both tapping and extended contact, such as in contour tracing. As the user extends the stick to make contact with a virtual object, the contact point with the virtual object and the targeted contact point with the physical object are continually updated, and the virtual stick is redirected to synchronize the virtual and real contacts. Redirection is applied either just to the virtual stick, or to both the virtual stick and hand. A user study (N = 26) confirms the effectiveness of the proposed redirection method. A first experiment following a two-interval forced-choice design reveals that the offset detection thresholds are [-15cm, +15cm]. A second experiment asks participants to guess the shape of an invisible virtual object by tapping it and by tracing its contour with the handheld stick, using a real world disk as a source of passive haptic feedback. The experiment reveals that using our haptic redirection method participants can identify the invisible object with 78% accuracy.
C1 [Zhou, Yuqi; Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Zhou, YQ (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM zhou1168@purdue.edu; popescu@purdue.edu
OI Zhou, Yuqi/0000-0003-3357-7837
FU United States National Science Foundation through awards [2212200,
   2219842]
FX The authors would like to thank the anonymous reviewers for their help
   with improving this manuscript, and the members of the Computer Graphics
   and Visualization Laboratory of the Computer Science Department of
   Purdue University for their feedback. This work was supported in part by
   the United States National Science Foundation through awards 2212200 and
   2219842, by a gift from Meta, and by the Purdue University Computer
   Science Department.
CR Abtahi P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173724
   Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   [Anonymous], OC GOLF
   [Anonymous], TOUCHD
   [Anonymous], Oculus headset
   [Anonymous], UN 3D ENG
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Ban Yuki, 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P25, DOI 10.1007/978-3-642-31401-8_3
   Ban Yuki., 2014, Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, VRST'14, P191, DOI DOI 10.1145/2671015.2671028
   Beever L, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P130, DOI 10.1109/VR51125.2022.00031
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Bergström J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1175, DOI 10.1145/3332165.3347939
   Bouzbib E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P360, DOI 10.1109/VR51125.2022.00055
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   de Tinguy X, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P321, DOI [10.1109/VR.2019.8798205, 10.1109/vr.2019.8798205]
   Harley D, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1253, DOI 10.1145/3064663.3064680
   Hettiarachchi A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1957, DOI 10.1145/2858036.2858134
   Howard T, 2020, IEEE T HAPTICS, V13, P38, DOI 10.1109/TOH.2019.2963028
   Insko Brent Edward, 2001, Passive haptics significantly enhances virtual environments
   Kang H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P38, DOI [10.1109/VR.2019.8798300, 10.1109/vr.2019.8798300]
   Kohli L., 2013, Ph. D. Dissertation
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   Nilsson NC, 2021, IEEE COMPUT GRAPH, V41, P104, DOI 10.1109/MCG.2021.3097671
   Patras C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P205, DOI 10.1109/VR51125.2022.00039
   Rapp A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173654
   Razzaque S., 2005, Redirected Walking
   Rey D., 2011, Wilcoxon-signed-rank test. International encyclopedia of statistical science, P1658, DOI [DOI 10.1007/978-3-642-04898-2616, 10.1007/978-3-642-04898-2616]
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Spillmann J, 2013, IEEE T VIS COMPUT GR, V19, P626, DOI 10.1109/TVCG.2013.23
   Strandholt PL, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376303
   Sun YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300682
   Vonach E, 2017, P IEEE VIRT REAL ANN, P74, DOI 10.1109/VR.2017.7892233
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Yamaguchi K, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P43, DOI 10.1145/2983310.2985746
   Yang J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P889, DOI 10.1145/3242587.3242643
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zenner Andre., 2021, Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, P1
   Zhao L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P239, DOI [10.1109/VR46266.2020.1581066900344, 10.1109/VR46266.2020.00-61]
   Zhao YW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174118
   Zhao YW, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P82, DOI 10.1145/3132272.3134143
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
   Zhou YQ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P83, DOI 10.1109/VR51125.2022.00026
NR 49
TC 2
Z9 2
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2753
EP 2762
DI 10.1109/TVCG.2023.3247047
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1ZZ2
UT WOS:000966785200001
PM 37027709
DA 2024-11-06
ER

PT J
AU Guerreiro, J
   Kim, Y
   Nogueira, R
   Chung, SA
   Rodrigues, A
   Oh, U
AF Guerreiro, Joao
   Kim, Yujin
   Nogueira, Rodrigo
   Chung, SeungA
   Rodrigues, Andre
   Oh, Uran
TI The Design Space of the Auditory Representation of Objects and Their
   Behaviours in Virtual Reality for Blind People
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Space exploration; Blindness; Visualization; Virtual reality; Virtual
   environments; Haptic interfaces; Games; Inclusive Virtual Reality;
   Nonvisual Interaction; Blind; Auditory Feedback; Design Space
ID HEALTH-BENEFITS; FEEDBACK
AB As virtual reality (VR) is typically designed in terms of visual experience, it poses major challenges for blind people to understand and interact with the environment. To address this, we propose a design space to explore how to augment objects and their behaviours in VR with a nonvisual audio representation. It intends to support designers in creating accessible experiences by explicitly considering alternative representations to visual feedback. To demonstrate its potential, we recruited 16 blind users and explored the design space under two scenarios in the context of boxing: understanding the location of objects (the opponent's defensive stance) and their movement (opponent's punches). We found that the design space enables the exploration of multiple engaging approaches for the auditory representation of virtual objects. Our findings depicted shared preferences but no one-size-fits-all solution, suggesting the need to understand the consequences of each design choice and their impact on the individual user experience.
C1 [Guerreiro, Joao; Nogueira, Rodrigo; Rodrigues, Andre] Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
   [Kim, Yujin; Chung, SeungA; Oh, Uran] Ewha Womans Univ, Comp Sci & Engn, Seoul, South Korea.
C3 Universidade de Lisboa; Ewha Womans University
RP Guerreiro, J (corresponding author), Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
EM jpguerreiro@fc.ul.pt; komgi0715@ewhain.net; fc55721@alunos.fc.ul.pt;
   ewhacsa@ewhain.net; afrodrigues@fc.ul.pt; uran.oh@ewha.ac.kr
RI rodrigues, andre/JWP-8432-2024; Nogueira, Rodrigo/AAX-1610-2020;
   Guerreiro, João/AAD-6404-2020; Rodrigues, Andre/N-2164-2015
OI Oh, Uran/0000-0002-7832-6313; Rodrigues, Andre/0000-0002-0810-4619;
   Guerreiro, Joao/0000-0002-0952-8368
FU FCT [UIDB/00408/2020, UIDP/00408/2020]; Access VR project
   [2022.08286.PTDC]; MSIT (Ministry of Science and ICT), Korea under ITRC
   (Information Technology Research Center) [IITP-2023-2020-0-01460)]
FX The authors wish to thank the participants of the two user studies. This
   work was supported in part by FCT through the LASIGE Research Unit
   (UIDB/00408/2020, UIDP/00408/2020) and the Access VR project
   (2022.08286.PTDC). It was also supported by the MSIT (Ministry of
   Science and ICT), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2023-2020-0-01460) supervised by the IITP
   (Institute for Information Communications Technology Planning
   Evaluation).
CR Allain K., 2015, 2015 IEEE 2 VR WORKS, P1
   Alotaibi AZ, 2016, J PHYS THER SCI, V28, P1374, DOI 10.1589/jpts.28.1374
   Andrade R, 2021, ACM T ACCESS COMPUT, V14, DOI 10.1145/3448273
   Andrade R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300346
   Ariza O, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P327, DOI 10.1109/VR.2018.8446317
   Barrass S, 1999, MULTIMEDIA SYST, V7, P23, DOI 10.1007/s005300050108
   Blauert J., 1997, Spatial Hearing. The Psychophysics of Human Sound Localization, V2nd edition
   Bronkhorst AW, 2000, ACUSTICA, V86, P117
   Büttner S, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P433, DOI 10.1145/3056540.3076193
   Burkins A, 2015, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2015.7223342
   Card Stuart K., 1990, P SIGCHI C HUM FACT, P117, DOI 10. 1145/97243.97263
   Chen H., 2017, Proceedings of the 29th Australian conference on computer-human interaction, P108, DOI DOI 10.1145/3152771.3152783
   Cheng YF, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517452
   Chung S, 2021, 18TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A '21), DOI 10.1145/3430263.3452421
   Chung S, 2021, INT SYM MIX AUGMENT, P339, DOI 10.1109/ISMAR52148.2021.00050
   Chung SA, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P206, DOI 10.1109/ISMAR-Adjunct51615.2020.00061
   Cobo A, 2017, COMPUT HUM BEHAV, V77, P294, DOI 10.1016/j.chb.2017.09.007
   Colwell C., 1998, ASSETS'98. Third International ACM Conference on Assistive Technologies, P92, DOI 10.1145/274497.274515
   Connors EC, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00223
   Dadamis K., 2022, 3D CUES HUMAN CONTRO, P2
   Façanha AR, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3395769
   Gao BY, 2019, LECT NOTES COMPUT SC, V11574, P44, DOI 10.1007/978-3-030-21607-8_4
   Gao B, 2018, IEEE T HUM-MACH SYST, V48, P658, DOI 10.1109/THMS.2018.2850329
   Garner T. A., 2017, PALGRAVE STUD SOUND, P2, DOI DOI 10.1007/978-3-319-65708-0_1
   Gonçalves D, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418304
   Guerreiro J, 2020, INT J HUM-COMPUT ST, V135, DOI 10.1016/j.ijhcs.2019.102369
   Guerreiro J, 2016, ACM T ACCESS COMPUT, V8, DOI 10.1145/2822910
   Hermann T., 2011, SONIFCATION HDB, P4
   Heuten Wilko, 2006, P 4 NORD C HUM COMP, P155, DOI DOI 10.1145/1182475.1182492
   Hoeg ER, 2017, 2017 IEEE 3RD VR WORKSHOP ON SONIC INTERACTIONS FOR VIRTUAL ENVIRONMENTS (SIVE)
   Honer O., 2011, SONIFICATION HDB, V6
   Hussain I, 2014, INT J HUM-COMPUT INT, V30, P740, DOI 10.1080/10447318.2014.925381
   India G., 2021, 23 INT ACM SIGACCESS, P1
   Jain D, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P160, DOI 10.1145/3461778.3462106
   Ji T., 2022, INT ACM SIGACCESS C, P2
   Joffe H, 2011, Qualitative research in clinical and health psychology, P209, DOI [DOI 10.1037/13620-004, 10.1007/978-981-10-5251-4103, DOI 10.1007/978-981-10-5251-4103, 10.1007/978-981-10-2779-6_103-1, 10.1002/9781119973249.ch15]
   Kaul M., 2016, INPROCEEDINGS 2016 C, P2533
   Kim NW, 2021, COMPUT GRAPH FORUM, V40, P173, DOI 10.1111/cgf.14298
   Kramer G., 2010, SONIFCATION REPORT S, P4
   Kreimeier Julian, 2020, PETRA '20: Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments, DOI 10.1145/3389189.3389194
   Kreimeier J, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040079
   Lahav O, 2008, INT J HUM-COMPUT ST, V66, P23, DOI 10.1016/j.ijhcs.2007.08.001
   Lécuyer A, 2003, P IEEE VIRT REAL ANN, P251, DOI 10.1109/VR.2003.1191147
   Leplatre G., 2000, DESIGNING NON SPEECH
   Lottridge D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P93, DOI 10.1109/VR51125.2022.00027
   MacLean A., 1991, PROC ESPRIT 1991, P720
   Maidenbaum S, 2015, P IEEE VIRT REAL ANN, P341, DOI 10.1109/VR.2015.7223435
   Michalski SC, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222351
   Morelli T., 2010, P 5 INT C FDN DIG GA, P147, DOI [DOI 10.1145/1822348.1822368, 10.1145/1822348.1822368]
   Morris MR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173633
   Mott ME, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI [10.1145/3373625.3416998, 10.1145/3396956.3396969]
   Muller J., 2010, Proceedings of the international conference on Multimedia, P1285, DOI [10.1145/1873951.1874203, DOI 10.1145/1873951.1874203]
   Nair Vishnu, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P538, DOI 10.1145/3472749.3474768
   Nicolau H, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P249, DOI 10.1145/3308561.3353786
   OCallaghan C., 2009, SOUNDS EVENTS, P2
   Oh U, 2013, P 15 INT ACM SIGACCE, P1, DOI [10.1145/2513383.2513455, DOI 10.1145/2513383.2513455, 10.1145/2513383.2513455event-place]
   Oh U., 2015, ACM Trans. Access. Comput. (TACCESS), V7, P1, DOI [10.1145/2820616, DOI 10.1145/2820616]
   Pasnau R, 1999, PHILOS QUART, V49, P309, DOI 10.1111/1467-9213.00144
   Penedo FJ, 2005, CURR OPIN PSYCHIATR, V18, P189, DOI 10.1097/00001504-200503000-00013
   Phillips K. U., 2020, SCI AM, P1
   Picinali L, 2014, INT J HUM-COMPUT ST, V72, P393, DOI 10.1016/j.ijhcs.2013.12.008
   Rector K., 2013, P 15 INT ACM SIGACCE, P1, DOI [10.1145/2513383.2513392, DOI 10.1145/2513383.2513392]
   Ren G, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/4517150
   Reynaert V, 2021, LECT NOTES COMPUT SC, V12934, P182, DOI 10.1007/978-3-030-85613-7_13
   Ryan A., 2020, THOUGHTS ACCESSIBILI, P1
   Sánchez J, 2009, 2009 VIRTUAL REHABILITATION INTERNATIONAL CONFERENCE, P29, DOI 10.1109/ICVR.2009.5174201
   Senan B., 2022, INPROCEEDINGS 17 INT, P187, DOI [10.1145/3561212.3561239[71]B.A., DOI 10.1145/3561212.3561239[71]B.A]
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Siu AF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376353
   Smith BA, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174090
   Stoner G., 2022, WIRED, P1
   Su J., 2010, P 12 INT C HUM COMP, P17
   Thevin L, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3377879
   Warburton DER, 2006, CAN MED ASSOC J, V174, P801, DOI 10.1503/cmaj.051351
   Watanabe M, 2022, LECT NOTES COMPUT SC, P79, DOI 10.1007/978-3-031-08645-8_10
   Wedoff R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300371
   Yasmin S., 2018, INT J VIRTUAL REALIT, V18, P2
   Yoshida Tsubasa., 2011, Proceedings of the 2nd Augmented Human International Conference, P1, DOI DOI 10.1145/1959826.1959837
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zhao Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173690
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
   Zong Jonathan, 2022, Rich Screen Reader Experiences for Accessible Data Visualization
NR 82
TC 8
Z9 8
U1 6
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2763
EP 2773
DI 10.1109/TVCG.2023.3247094
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2PZ7
UT WOS:000967207200001
PM 37027696
DA 2024-11-06
ER

PT J
AU David-John, B
   Butler, K
   Jain, E
AF David-John, Brendan
   Butler, Kevin
   Jain, Eakta
TI Privacy-preserving datasets of eye-tracking samples with applications in
   XR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Privacy; Eye Tracking; Re-identification; Biometrics
ID AUTHENTICATION; PREDICTION; ATTENTION; UTILITY
AB Virtual and mixed-reality (XR) technology has advanced significantly in the last few years and will enable the future of work, education, socialization, and entertainment. Eye-tracking data is required for supporting novel modes of interaction, animating virtual avatars, and implementing rendering or streaming optimizations. While eye tracking enables many beneficial applications in XR, it also introduces a risk to privacy by enabling re-identification of users. We applied privacy definitions of k-anonymity and plausible deniability (PD) to datasets of eye-tracking samples and evaluated them against the state-of-the-art differential privacy (DP) approach. Two VR datasets were processed to reduce identification rates while minimizing the impact on the performance of trained machine-learning models. Our results suggest that both PD and DP mechanisms produced practical privacy-utility trade-offs with respect to re-identification and activity classification accuracy, while k-anonymity performed best at retaining utility for gaze prediction.
C1 [David-John, Brendan] Virginia Polytech Inst & State Univ, Blacksburg, VA 24060 USA.
   [Butler, Kevin; Jain, Eakta] Univ Florida, Gainesville, FL USA.
C3 Virginia Polytechnic Institute & State University; State University
   System of Florida; University of Florida
RP David-John, B (corresponding author), Virginia Polytech Inst & State Univ, Blacksburg, VA 24060 USA.
EM bmdj@vt.edu; butler@ufl.edu; ejain@cise.ufl.edu
RI David-John, Brendan/HTO-8001-2023
FU National Science Foundation [FWHTF-2026540, CNS-1815883, CNS-1562485];
   National Science Foundation GRFP [DGE-1315138, DGE-1842473]; Air Force
   Office of Scientific Research [FA9550-19-1-0169]
FX Authors acknowledge funding from National Science Foundation (Awards
   FWHTF-2026540, CNS-1815883, and CNS-1562485), the National Science
   Foundation GRFP (Awards DGE-1315138 and DGE-1842473), and the Air Force
   Office of Scientific Research (Awards FA9550-19-1-0169)
CR Agtzidis I., 2019, ARXIV
   Alghofaili R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300578
   Andres M. E., 2013, P 2013 ACM SIGSAC C, P901
   Arabadzhiyska E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073642
   Armstrong T, 2012, CLIN PSYCHOL REV, V32, P704, DOI 10.1016/j.cpr.2012.09.004
   BAHILL AT, 1979, SCI AM, V240, P108, DOI 10.1038/scientificamerican0179-108
   Berkovsky S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300451
   Bernal G, 2021, DEVELOPING GALEA OPE
   Bindschaedler V, 2017, PROC VLDB ENDOW, V10, P481, DOI 10.14778/3055540.3055542
   Bindschaedler V, 2016, P IEEE S SECUR PRIV, P546, DOI 10.1109/SP.2016.39
   Bozkir E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255979
   Bulling A, 2011, IEEE T PATTERN ANAL, V33, P741, DOI 10.1109/TPAMI.2010.86
   Chawarska K, 2009, J AUTISM DEV DISORD, V39, P1663, DOI 10.1007/s10803-009-0803-7
   Chen SY, 2022, IEEE T VIS COMPUT GR, V28, P2157, DOI 10.1109/TVCG.2022.3150522
   David-John B., 2022, ACM S EYE TRACKING R, P1
   David-John B, 2021, IEEE T VIS COMPUT GR, V27, P2555, DOI 10.1109/TVCG.2021.3067787
   Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1
   Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Eberz S, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1187, DOI 10.1145/3319535.3354233
   El Emam K, 2008, J AM MED INFORM ASSN, V15, P627, DOI 10.1197/jamia.M2716
   Fuhl W, 2021, LECT NOTES COMPUT SC, V12894, P595, DOI 10.1007/978-3-030-86380-7_48
   Galdi C, 2016, PATTERN RECOGN LETT, V84, P272, DOI 10.1016/j.patrec.2016.11.002
   George A, 2016, PATTERN RECOGN LETT, V82, P207, DOI 10.1016/j.patrec.2015.11.020
   Griffith H, 2020, 2020 10TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P18, DOI [10.1109/ccwc47524.2020.9031274, 10.1109/CCWC47524.2020.9031274]
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Harezlak K, 2018, COMPUT MED IMAG GRAP, V65, P176, DOI 10.1016/j.compmedimag.2017.04.006
   Heller B., 2020, VANDERBILT J ENTERTA, V23, P1
   Hu Z., 2021, IEEE Transactions on Visualization and Computer Graphics
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   John B., 2020, ACM S EYE TRACKING R, P1
   John B, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319816
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Karimian Nima, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P257, DOI 10.1109/TBIOM.2020.2992274
   Karpov A., ARXIV
   Kellaris G, 2014, PROC VLDB ENDOW, V7, P1155, DOI 10.14778/2732977.2732989
   Kifer D., 2011, P ACM SIGMOD INT C M, P193, DOI [DOI 10.1109/ICDE.2007.367856, 10.1145/1989323.1989345, DOI 10.1145/1989323.1989345]
   Komogortsev O, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2536764.2536774
   Lan G., 2022, P ACMIEEE IPSN
   LaRubbio K., 2022, 2022 IEEE C VIRTUAL
   Li J., 2020, 29 USENIX SEC S USEN
   Liu Ao., 2019, Proceedings of the 11th ACM Symposium on Eye Tracking Research Applications, P28
   Lohr D. J., 2020, ACM S EYE TRACKING R, P1
   Lohr D, 2022, IEEE T INF FOREN SEC, V17, P3151, DOI 10.1109/TIFS.2022.3201369
   Martin D., 2022, IEEE Transactions on Visualization and Computer Graphics, P1
   McGill M, 2021, The IEEE Global Initiative on Ethics of Extended Reality (XR) Report-Extended Reality (XR) and the Erosion of Anonymity and Privacy
   Mhaidli AH, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445253
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P409, DOI 10.1109/VR51125.2022.00060
   Nair Vivek, 2022, ARXIV
   Narayanan A, 2008, P IEEE S SECUR PRIV, P111, DOI 10.1109/SP.2008.33
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Rastogi V., 2010, P 2010 ACM SIGMOD IN, P735
   Reilly D, 2021, 2021 THIRD IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS (TPS-ISA 2021), P80, DOI 10.1109/TPSISA52974.2021.00009
   Renaud P, 2002, CYBERPSYCHOL BEHAV, V5, P1, DOI 10.1089/109493102753685836
   Robusto C. C., 1957, AM MATH MON, V64, P38, DOI [10.2307/2309088, DOI 10.2307/2309088]
   Samarati P., 1998, Technical report, DOI DOI 10.1145/275487.275508
   Schroeder C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376534
   Singel Ryan., 2009, Netflix spilled your brokeback mountain secret, lawsuit claims, Threat Level (blog)
   Skaramagkas V, 2023, IEEE REV BIOMED ENG, V16, P260, DOI 10.1109/RBME.2021.3066072
   Sohn K, 2015, ADV NEUR IN, V28
   Steil J, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319915
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Trimananda R., 2021, ARXIV
   VANOPSTAL AJ, 1987, VISION RES, V27, P731, DOI 10.1016/0042-6989(87)90071-X
   Zhang AT, 2018, IEEE IMAGE PROC, P2660, DOI 10.1109/ICIP.2018.8451219
   Zhou YZ, 2022, FRONT INFORM TECH EL, V23, P101, DOI 10.1631/FITEE.2000318
NR 68
TC 7
Z9 7
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2774
EP 2784
DI 10.1109/TVCG.2023.3247048
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D4WU6
UT WOS:000968762200001
PM 37027724
DA 2024-11-06
ER

PT J
AU Tian, HY
   Lee, GA
   Bai, HD
   Billinghurst, M
AF Tian, Huayuan
   Lee, Gun A. A.
   Bai, Huidong
   Billinghurst, Mark
TI Using Virtual Replicas to Improve Mixed Reality Remote Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Collaboration; Task analysis; Cameras; Solid
   modeling; Annotations; Resists; Mixed reality; remote collaboration;
   virtual replica
ID COMMUNICATION CUES
AB In this paper, we explore how virtual replicas can enhance Mixed Reality (MR) remote collaboration with a 3D reconstruction of the task space. People in different locations may need to work together remotely on complicated tasks. For example, a local user could follow a remote expert's instructions to complete a physical task. However, it could be challenging for the local user to fully understand the remote expert's intentions without effective spatial referencing and action demonstration. In this research, we investigate how virtual replicas can work as a spatial communication cue to improve MR remote collaboration. This approach segments the foreground manipulable objects in the local environment and creates corresponding virtual replicas of physical task objects. The remote user can then manipulate these virtual replicas to explain the task and guide their partner. This enables the local user to rapidly and accurately understand the remote expert's intentions and instructions. Our user study with an object assembly task found that using virtual replica manipulation was more efficient than using 3D annotation drawing in an MR remote collaboration scenario. We report and discuss the findings and limitations of our system and study, and present directions for future research.
C1 [Tian, Huayuan; Lee, Gun A. A.; Billinghurst, Mark] Univ South Australia, Adelaide, SA, Australia.
   [Bai, Huidong] Univ Auckland, Auckland, New Zealand.
C3 University of South Australia; University of Auckland
RP Tian, HY (corresponding author), Univ South Australia, Adelaide, SA, Australia.
EM huayuan.tian@mymail.unisa.edu.au; gun.lee@unisa.edu.au;
   huidong.bai@auckland.ac.nz; mark.billinghurst@auckland.ac.nz
RI Lee, Gun/AAS-9903-2021; Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Lee, Gun/0000-0002-1644-6934
FU University of South Australia
FX This research is supported by the University of South Australia.
CR Adcock M., 2013, P 12 ACM SIGGRAPH IN
   Alem J., 2011, ADV HUM-COMPUT INTER, V2011
   Andrew M., 2011, International Conference on Artificial reality and telexistance, P4
   [Anonymous], 2015, COGSCI
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Brooke J., 1995, USABILITY EVAL IND, P189
   Calandra F. G., 2022, DIGIT COMMUN NETW, V2
   Deng Z, 2015, IEEE I CONF COMP VIS, P1733, DOI 10.1109/ICCV.2015.202
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Fussell S. R., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P21, DOI 10.1145/358916.358947
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Fussell Susan R., 2003, P SIGCHI C HUM FACT, P513, DOI 10.1145/642611.642701
   Gao L., 2016, P IEEE 83 VEH TECHN, P1, DOI [https://doi.org/10.1145/2999508.2999531, DOI 10.1145/2999508.2999531]
   Gao L, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139204
   Gauglitz S., 2014, P 27 ANN ACM S US IN, P449
   Gauglitz Steffen, 2014, P 20 ACM S VIRT REAL, P197, DOI 10.1145/2671015.2671016
   Gauglitz Steffen, 2012, P 14 INT C HUM COMP, DOI [10.1145/2371574.2371610, DOI 10.1145/2371574.2371610]
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich Pavel, 2012, P SIGCHI C HUM FACT, P619, DOI DOI 10.1145/2207676.2207763
   Harms C., 2004, P PRES 2004, P7
   HART S G, 1988, P139
   He M., 2018, SIGGRAPH ASIA 2018 V, P1
   Hendrikus Zijlstra FerdinandRudolf., 1995, EFFICIENCY WORK BEHA
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jiang Zhenyu, 2022, IEEECVF C COMPUTVIS, P5616
   Kasahara Shunichi, 2014, P ADJ PUBL 27 ANN AC, P61, DOI [10.1145/2658779.2659114, DOI 10.1145/2658779.2659114]
   Kim S, 2018, KSII T INTERNET INF, V12, P6034
   Kim S, 2014, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2014.6948412
   Kim S, 2013, INT SYM MIX AUGMENT, P261, DOI 10.1109/ISMAR.2013.6671795
   Kirk D. S., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1191
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lee GA, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139203
   Lee GA, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132827
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Noh S., 2015, P INT C ART REAL TEL, P61
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Pierce J. S., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P141, DOI 10.1145/300523.300540
   Piumsomboon G. A., 2019, P 2019 CHI C HUMAN F, P1
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   PTC Reality Lab, 2022, VUF SPAT TOOLB VIRT
   Pu George., 2021, 2021 Winter Simulation Conference (WSC), P1
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Robertson M., 2016, HUM-COMPUT INT-SPRIN, V6
   Sauro J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2347
   Sereno X., 2020, IEEE T VIS COMPUT GR, V2
   Silvi B, 2016, CHALL ADV COMPUT CHE, V22, P1, DOI 10.1007/978-3-319-29022-5_1
   Sodhi Rajinder S., 2013, P SIGCHI C HUM FACT, P179
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Stotko P, 2019, IEEE T VIS COMPUT GR, V25, P2102, DOI 10.1109/TVCG.2019.2899231
   Tait M, 2015, COMPUT SUPP COOP W J, V24, P563, DOI 10.1007/s10606-015-9231-8
   Tecchia F., 2012, P 11 ACM SIGGRAPH IN, P323
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Vorderer W., MEC SPATIAL PRESENCE
   Wang P, 2021, MULTIMED TOOLS APPL, V80, P31059, DOI 10.1007/s11042-020-09731-7
   Wang P, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P91, DOI 10.1109/ISMAR-Adjunct.2019.00038
   Wang X., 2021, ROBOT CIM-INT MANUF, V72
   Wikipedia contributors, 2021, AZ KIN WIK FREE ENC
   Wikipedia contributors, 2022, OC QUEST WIK FREE EN
   Yu K, 2022, IEEE T VIS COMPUT GR, V28, P2190, DOI 10.1109/TVCG.2022.3150520
   Yu K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P392, DOI 10.1109/VR50410.2021.00062
   Zhang XY, 2022, INT J ADV MANUF TECH, V121, P7697, DOI 10.1007/s00170-022-09654-7
NR 64
TC 7
Z9 8
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2785
EP 2795
DI 10.1109/TVCG.2023.3247113
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0RD7
UT WOS:000965876200001
PM 37027731
DA 2024-11-06
ER

PT J
AU Bakar, MA
   Tsai, YT
   Hsueh, HH
   Li, EC
AF Bakar, Muhammad Abu
   Tsai, Yu-Ting
   Hsueh, Hao-Han
   Li, Elena Carolina
TI CrowbarLimbs: A Fatigue-Reducing Virtual Reality Text Entry Metaphor
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; text entry; selection keyboard; fatigue; metaphor
   shapes; keyboard locations
ID MUSCLE
AB Text entry remains challenging in virtual environments, where users may quickly experience physical fatigue in some body parts using existing methods. In this paper, we propose "CrowbarLimbs," a novel virtual reality (VR) text entry metaphor with two deformable extended virtual limbs. By using a crowbar-like metaphor and placing the virtual keyboard at a user-preferred location based on the user's physical stature, our method can assist the user in placing their hands and arms in a comfortable posture, thus effectively reducing the physical fatigue in various body parts, such as hands, wrists, and elbows. In an initial user study, we found that CrowbarLimbs achieved text entry speed, accuracy, and system usability comparable to those of previous VR typing methods. To investigate the proposed metaphor in more depth, we further conducted two additional user studies to explore the ergonomically user-friendly shapes of CrowbarLimbs and virtual keyboard locations. The experimental results indicate that the shapes of CrowbarLimbs have significant effects on the fatigue ratings in various body parts and text entry speed. Furthermore, placing the virtual keyboard near the user and at half their height can lead to a satisfactory text entry rate of 28.37 words per minute.
C1 [Bakar, Muhammad Abu; Tsai, Yu-Ting; Hsueh, Hao-Han] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
   [Li, Elena Carolina] Univ Taipei, Dept Visual Arts, New Taipei, Taiwan.
C3 Yuan Ze University
RP Tsai, YT (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
EM abubakar.nuaa@gmail.com; hieicis91@hotmail.com; gn01882537@gmail.com;
   elenali@utaipei.edu.tw
OI Elena Carolina, Li/0000-0001-6990-0240; Abu Bakar,
   Muhammad/0000-0003-1160-8524
FU Ministry of Science and Technology of Taiwan
   [MOST107-2221-E-155-051-MY2, MOST109-2221-E-155-039-MY3]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under Grant Numbers MOST107-2221-E-155-051-MY2 and
   MOST109-2221-E-155-039-MY3.
CR Abu Bakar M., 2020, ACM SIGGRAPH 20 POST, P1, DOI [10.1145/3388770.34073991, DOI 10.1145/3388770.34073991]
   Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Boletsis C, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020031
   Boletsis Costas, 2019, International Journal of Virtual Reality (IJVR), V19, P3
   Borg G., 1998, Borgs Perceived Exertion and Pain Scales, DOI DOI 10.1249/00005768-199809000-00018
   Brooke J., 1995, USABILITY EVAL IND, P189
   Dedering Å, 2010, PHYSIOTHER RES INT, V15, P189, DOI 10.1002/pri.457
   Doronichev A., 2016, Daydream labs: exploring and sharing VR's possibilities
   Dube TJ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382882
   Dube TJ., 2019, HCI INT 19, P419, DOI DOI 10.1007/978-3-030-22643-5_33
   Fashimpaur Jacqui, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382888
   Feuchtner T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P31, DOI 10.1145/3242587.3242594
   Gaggioli A., 2018, CYBERPSYCHOLOGY BEHA, V21, P338, DOI [10.1089/cyber.2018.29112.csi, DOI 10.1089/CYBER.2018.29112.CSI]
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Gugenheimer J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P49, DOI 10.1145/2984511.2984576
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   Haynes S, 2008, INT J IND ERGONOM, V38, P35, DOI 10.1016/j.ergon.2007.08.003
   Hill N., 2019, ABOUT US
   Hoppe AH, 2018, COMM COM INF SC, V851, P266, DOI 10.1007/978-3-319-92279-9_36
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Käser DP, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085094
   Kim S., 2004, P ACM SIGGRAPH INT C, P336, DOI DOI 10.1145/1044588.1044662
   Kim YR, 2017, IEEE ICCE, DOI 10.1109/ICCE.2017.7889285
   Lee Y, 2017, LECT NOTES COMPUT SC, V10280, P111, DOI 10.1007/978-3-319-57987-0_9
   Lin Jia-Wei., 2017, ACM SIGGRAPH 2017 Posters on - SIGGRAPH'17, P1, DOI DOI 10.1145/3102163
   Lu XS, 2020, INT SYM MIX AUGMENT, P344, DOI 10.1109/ISMAR50242.2020.00061
   Mackay Wendy E, 1990, Users and customizable software: A coadaptive phenomenon
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Meier M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P519, DOI 10.1109/VR50410.2021.00076
   OBERG T, 1994, ERGONOMICS, V37, P1323, DOI 10.1080/00140139408964911
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364265
   Pick S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P109, DOI 10.1109/3DUI.2016.7460039
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Prätorius M, 2015, IEEE COMPUT GRAPH, V35, P42, DOI 10.1109/MCG.2015.106
   Rajanna V, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204541
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Troiano A, 2008, GAIT POSTURE, V28, P179, DOI 10.1016/j.gaitpost.2008.04.002
   vSpatial Inc, 2016, ABOUT US
   Walker J., 2016, CHI EA 16, V16
   Wang YH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051582
   Whitmire Eric, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130978
   Wobbrock JO, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P667
   Xu WG, 2019, IEEE T VIS COMPUT GR, V25, P1991, DOI 10.1109/TVCG.2019.2898736
   Yao Powen, 2020, Symposium on Spatial User Interaction, P1
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Yu DF, 2018, IEEE T VIS COMPUT GR, V24, P2927, DOI 10.1109/TVCG.2018.2868581
NR 53
TC 3
Z9 3
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2806
EP 2815
DI 10.1109/TVCG.2023.3247060
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1SH7
UT WOS:000966583700001
PM 37027725
DA 2024-11-06
ER

PT J
AU Ebner, C
   Mohr, P
   Langlotz, T
   Peng, YF
   Schmalstieg, D
   Wetzstein, G
   Kalkofen, D
AF Ebner, Christoph
   Mohr, Peter
   Langlotz, Tobias
   Peng, Yifan
   Schmalstieg, Dieter
   Wetzstein, Gordon
   Kalkofen, Denis
TI Off-Axis Layered Displays: Hybrid Direct-View/Near-Eye Mixed Reality
   with Focus Cues
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Two dimensional displays; Resists; Stereo
   image processing; Prototypes; Image color analysis; Lenses; Layered
   display; Direct-view; Near-eye; Mixed Reality; Focus cues
AB This work introduces off-axis layered displays, the first approach to stereoscopic direct-view displays with support for focus cues. Off-axis layered displays combine a head-mounted display with a traditional direct-view display for encoding a focal stack and thus, for providing focus cues. To explore the novel display architecture, we present a complete processing pipeline for the real-time computation and post-render warping of off-axis display patterns. In addition, we build two prototypes using a head-mounted display in combination with a stereoscopic direct-view display, and a more widely available monoscopic direct-view display. In addition we show how extending off-axis layered displays with an attenuation layer and with eye-tracking can improve image quality. We thoroughly analyze each component in a technical evaluation and present examples captured through our prototypes.
C1 [Ebner, Christoph; Mohr, Peter; Schmalstieg, Dieter; Kalkofen, Denis] Graz Univ Technol, Graz, Austria.
   [Langlotz, Tobias] Univ Otago, Dunedin, New Zealand.
   [Peng, Yifan] Univ Hong Kong, Hong Kong, Peoples R China.
   [Wetzstein, Gordon] Stanford Univ, Stanford, CA USA.
   [Kalkofen, Denis] Flinders Univ S Australia, Bedford Pk, Australia.
C3 Graz University of Technology; University of Otago; University of Hong
   Kong; Stanford University; Flinders University South Australia
RP Ebner, C (corresponding author), Graz Univ Technol, Graz, Austria.
EM christoph.ebner@icg.tugraz.at; tobias.langlotz@otago.ac.nz;
   evanpeng@hku.hk; gordonwz@stanford.edu; kalkofen@icg.tugraz.at
RI Langlotz, Tobias/LKN-4608-2024; Peng, Yifan/M-1605-2016
OI Ebner, Christoph/0000-0002-1449-4780; Langlotz,
   Tobias/0000-0003-1275-2026
FU Snap Inc.; Hong Kong UGC Early Career Scheme Fund [27212822]; Marsden
   Fund Council [MFP-UOO2124]
FX This work was partially sponsored by Snap Inc., the Hong Kong UGCEarly
   Career Scheme Fund (27212822), and the Marsden Fund Councilfrom
   Government funding (grant no. MFP-UOO2124).
CR Aksit K, 2022, PROC SPIE, V12019, DOI 10.1117/12.2610285
   Aksit K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130892
   ANDERSEN AH, 1984, ULTRASONIC IMAGING, V6, P81, DOI 10.1016/0161-7346(84)90008-7
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Budhiraja P, 2015, Arxiv, DOI [arXiv:1502.04744, 10.48550/arXiv.1502.04744]
   Cakmakci O, 2006, J DISP TECHNOL, V2, P199, DOI 10.1109/JDT.2006.879846
   Chakravarthula P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356539
   Chang C, 2020, OPTICA, V7, P1563, DOI 10.1364/OPTICA.406004
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Dunn D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1838, DOI [10.1109/VR.2019.8798273, 10.1109/vr.2019.8798273]
   Dunn D, 2017, IEEE T VIS COMPUT GR, V23, P1275, DOI 10.1109/TVCG.2017.2657058
   Ebner C, 2022, IEEE T VIS COMPUT GR, V28, P2256, DOI 10.1109/TVCG.2022.3150504
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Gopakumar M, 2021, OPT LETT, V46, P5822, DOI 10.1364/OL.442851
   Grubert J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3933, DOI 10.1145/2702123.2702331
   Hainich R.R., 2016, Displays: fundamentals & applications
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hong J, 2011, APPL OPTICS, V50, pH87, DOI 10.1364/AO.50.000H87
   Huang FC, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766922
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Javidi B, 2021, OPT EXPRESS, V29, P35078, DOI 10.1364/OE.435915
   Jones B., 2013, P SIGCHI C HUM FACT, P869, DOI DOI 10.1145/2470654.2466112
   Kim D, 2018, OPT EXPRESS, V26, P17170, DOI 10.1364/OE.26.017170
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Kim SK, 2015, OPT EXPRESS, V23, P13230, DOI 10.1364/OE.23.013230
   Kim S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459776
   Kitamura Y, 2001, COMP GRAPH, P231, DOI 10.1145/383259.383285
   Kiyokawa K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P133, DOI 10.1109/ISMAR.2003.1240696
   Krajancich B, 2020, IEEE T VIS COMPUT GR, V26, P1871, DOI 10.1109/TVCG.2020.2973443
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lanman D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508366
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10451-2
   Lee S, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2782219
   Lohmann AW, 1996, J OPT SOC AM A, V13, P470, DOI 10.1364/JOSAA.13.000470
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Mercier O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130846
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Mohr P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300815
   Narain R, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766909
   Padmanaban N, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6187
   Park J-H., 2022, LIGHT ADV MANUFACTUR, V3, P1
   Peng YF, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg5040
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rathinavel K, 2018, IEEE T VIS COMPUT GR, V24, P2857, DOI 10.1109/TVCG.2018.2868570
   Shi L, 2021, NATURE, V591, P234, DOI 10.1038/s41586-020-03152-0
   Su C., 2016, SIGGRAPH ASIA 2016 V, P1
   Takahashi K, 2018, IEEE T IMAGE PROCESS, V27, P4571, DOI 10.1109/TIP.2018.2839263
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P21, DOI 10.1109/VR.2014.6802045
   Ueda T, 2020, IEEE T VIS COMPUT GR, V26, P2051, DOI 10.1109/TVCG.2020.2973496
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Wetzstein G., 2011, ACM Trans. Graph, V30
   Xiao L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275032
   Yu H, 2019, IEEE T VIS COMPUT GR, V25, P1940, DOI 10.1109/TVCG.2019.2898821
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 58
TC 2
Z9 2
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2816
EP 2825
DI 10.1109/TVCG.2023.3247077
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1AQ2
UT WOS:000966122800001
PM 37027729
OA hybrid
DA 2024-11-06
ER

PT J
AU Ishihara, A
   Aga, H
   Ishihara, Y
   Ichikawa, H
   Kaji, H
   Kawasaki, K
   Kobayashi, D
   Kobayashi, T
   Nishida, K
   Hamasaki, T
   Mori, H
   Morikubo, Y
AF Ishihara, Atsushi
   Aga, Hiroyuki
   Ishihara, Yasuko
   Ichikawa, Hirotake
   Kaji, Hidetaka
   Kawasaki, Koichi
   Kobayashi, Daita
   Kobayashi, Toshimi
   Nishida, Ken
   Hamasaki, Takumi
   Mori, Hideto
   Morikubo, Yuki
TI Integrating Both Parallax and Latency Compensation into Video
   See-through Head-mounted Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Head; Cameras; Image edge detection; Rendering
   (computer graphics); Prototypes; Magnetic heads; Video see-through;
   mixed reality; occlusion; latency compensation
AB This work introduces a perspective-corrected video see-through mixed-reality head-mounted display with edge-preserving occlusion and low-latency capabilities. To realize the consistent spatial and temporal composition of a captured real world containing virtual objects, we perform three essential tasks: 1) to reconstruct captured images so as to match the user's view; 2) to occlude virtual objects with nearer real objects, to provide users with correct depth cues; and 3) to reproject the virtual and captured scenes to be matched and to keep up with users' head motions. Captured image reconstruction and occlusion-mask generation require dense and accurate depth maps. However, estimating these maps is computationally difficult, which results in longer latencies. To obtain an acceptable balance between spatial consistency and low latency, we rapidly generated depth maps by focusing on edge smoothness and disocclusion (instead of fully accurate maps), to shorten the processing time. Our algorithm refines edges via a hybrid method involving infrared masks and color-guided filters, and it fills disocclusions using temporally cached depth maps. Our system combines these algorithms in a two-phase temporal warping architecture based upon synchronized camera pairs and displays. The first phase of warping is to reduce registration errors between the virtual and captured scenes. The second is to present virtual and captured scenes that correspond with the user's head motion. We implemented these methods on our wearable prototype and performed end-to-end measurements of its accuracy and latency. We achieved an acceptable latency due to head motion (less than 4 ms) and spatial accuracy (less than 0.1 degrees in size and less than 0.3 degrees in position) in our test environment. We anticipate that this work will help improve the realism of mixed reality systems.
C1 [Ishihara, Atsushi; Aga, Hiroyuki; Ishihara, Yasuko; Ichikawa, Hirotake; Kaji, Hidetaka; Kawasaki, Koichi; Kobayashi, Daita; Kobayashi, Toshimi; Nishida, Ken; Hamasaki, Takumi; Mori, Hideto; Morikubo, Yuki] Sony Grp Corp, Minato City, Tokyo, Japan.
RP Ishihara, A (corresponding author), Sony Grp Corp, Minato City, Tokyo, Japan.
EM atsushi.a.ishihara@sony.com
OI Aga, Hiroyuki/0000-0003-3715-3185; Nishida, Ken/0000-0002-3600-2548;
   Kobayashi, Daita/0000-0002-5961-4774; Ishihara,
   Atsushi/0000-0001-7990-5360
CR Abate A. F., 2014, SERIES TITLE LECT NO, V8525, P319, DOI [10.1007/978-3-319-07458-0_30 2, DOI 10.1007/978-3-319-07458-0_302]
   adaskit Team, 2016, LIBSGM
   Adelstein B. D., 2003, P HUMAN FACTORS ERGO, V47, P2083, DOI DOI 10.1177/154193120304702001
   Aga Hiroyuki, 2019, SID Symposium Digest of Technical Papers, V50, P330, DOI 10.1002/sdtp.12923
   Ai T, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P39, DOI 10.1145/3013971.3014020
   Attig C, 2017, LECT NOTES ARTIF INT, V10276, P3, DOI 10.1007/978-3-319-58475-1_1
   BAJURA M, 1995, IEEE COMPUT GRAPH, V15, P52, DOI 10.1109/38.403828
   Battisti C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P198, DOI 10.1109/ISMAR-Adjunct.2018.00066
   Bauer M., IMAGE BASED RENDERIN, P7
   Blate A, 2019, IEEE T VIS COMPUT GR, V25, P1970, DOI 10.1109/TVCG.2019.2899233
   Bowles H, 2012, COMPUT GRAPH FORUM, V31, P237, DOI 10.1111/j.1467-8659.2012.03002.x
   Carmack J., 2013, Latency Mitigation Strategies
   Casser V, 2019, AAAI CONF ARTIF INTE, P8001
   Chaurasia G, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3384540
   Chaurasia G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487238
   Chen HM, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.21
   Chen Z, 2018, LECT NOTES COMPUT SC, V11208, P176, DOI 10.1007/978-3-030-01225-0_11
   Du C, 2016, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR.2016.17
   Eigen D., 2014, ARXIV
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Ellis SR, 1999, HUM FAC ERG SOC P, P1182
   Feng Q, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3283390
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Freiwald JP, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281521
   Gao C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5692, DOI 10.1109/ICCV48922.2021.00566
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gordon A, 2019, IEEE I CONF COMP VIS, P8976, DOI 10.1109/ICCV.2019.00907
   Gruen R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P791, DOI [10.1109/VR46266.2020.1580498468656, 10.1109/VR46266.2020.000-1]
   Hall E. T., 1990, HIDDEN DIMENSION, P6
   Hebborn AK, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P62, DOI 10.1109/ISMAR.2017.23
   Hedman P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201384
   Hedman P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130828
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Holynski A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275083
   Hornung A, 2009, COMPUT GRAPH FORUM, V28, P2090, DOI 10.1111/j.1467-8659.2009.01416.x
   Jantet V, 2011, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2011.6115662
   Ji-Youn Choi, 2010, 2010 IEEE International Conference on Consumer Electronics (ICCE 2010), P171, DOI 10.1109/ICCE.2010.5418768
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kim P, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174919
   Kopf J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392420
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Luo TR, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1068, DOI [10.1109/VR.2019.8797811, 10.1109/vr.2019.8797811]
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Marcato R. W., OPTIMIZING INVERSE W, P51
   MAZURYK T, 1995, COMPUT GRAPH FORUM, V14, pC29, DOI 10.1111/j.1467-8659.1995.cgf143_0029.x
   McMillan J. L., 1997, IMAGE BASED APPROACH, P206
   MCMILLAN L, 1995, P SOC PHOTO-OPT INS, V2409, P21, DOI 10.1117/12.205865
   Michael A., 2015, ASYNCHRONOUS TIMEWAR, P2
   Misiak M, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489865
   Nakashima Y., 2017, PROCEDINGS BRIT MACH, P83, DOI [10.5244/C.31.832, DOI 10.5244/C.31.832]
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Nehab D., ACCELERATING REAL TI, P11, DOI [10.2312/EGGH/EGGH07/025-0362, DOI 10.2312/EGGH/EGGH07/025-0362]
   Niklaus S., 2020, NOVEL VIEW SYNTHESIS, DOI [10.15760/etd.72942, DOI 10.15760/ETD.72942]
   Ogniewski J., 2017, HIGH QUALITY REAL TI, P8
   Reinert B, 2016, COMPUT GRAPH FORUM, V35, P353, DOI 10.1111/cgf.13032
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Sun W., OVERVIEW FREE VIEWPO, P8
   Tian Y, 2010, SENSORS-BASEL, V10, P2885, DOI 10.3390/s100402885
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Ventura J, 2009, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2009.5336493
   Visa GP, 2014, LECT NOTES COMPUT SC, V8689, P648, DOI 10.1007/978-3-319-10590-1_42
   Walton DR, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139153
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Xiao Lei, 2022, ACM SIGGRAPH 2022 C, P1
   Xiao Tang, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P697, DOI 10.1145/3379337.3415835
   Ximea, MC031MG SY SPEC
   Yang L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024184
NR 74
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2826
EP 2836
DI 10.1109/TVCG.2023.3247460
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0YG1
UT WOS:000966060700001
PM 37027581
DA 2024-11-06
ER

PT J
AU Li, H
   Zhai, HJ
   Yang, XR
   Wu, ZR
   Zheng, YH
   Wang, HF
   Wu, JC
   Bao, HJ
   Zhang, GF
AF Li, Hai
   Zhai, Hongjia
   Yang, Xingrui
   Wu, Zhirong
   Zheng, Yihao
   Wang, Haofan
   Wu, Jianchao
   Bao, Hujun
   Zhang, Guofeng
TI ImTooth: Neural Implicit Tooth for Dental Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Artificial intelligence; Neural implicit representation; Dental Mixed /
   Augmented reality
ID VIRTUAL-REALITY
AB The combination of augmented reality (AR) and medicine is an important trend in current research. The powerful display and interaction capabilities of the AR system can assist doctors to perform more complex operations. Since the tooth itself is an exposed rigid body structure, dental AR is a relatively hot research direction with application potential. However, none of the existing dental AR solutions are designed for wearable AR devices such as AR glasses. At the same time, these methods rely on high-precision scanning equipment or auxiliary positioning markers, which greatly increases the operational complexity and cost of clinical AR. In this work, we propose a simple and accurate neural-implicit model-driven dental AR system, named ImTooth, and adapted for AR glasses. Based on the modeling capabilities and differentiable optimization properties of state-of-the-art neural implicit representations, our system fuses reconstruction and registration in a single network, greatly simplifying the existing dental AR solutions and enabling reconstruction, registration, and interaction. Specifically, our method learns a scale-preserving voxel-based neural implicit model from multi-view images captured from a textureless plaster model of the tooth. Apart from color and surface, we also learn the consistent edge feature inside our representation. By leveraging the depth and edge information, our system can register the model to real images without additional training. In practice, our system uses a single Microsoft HoloLens 2 as the only sensor and display device. Experiments show that our method can reconstruct high-precision models and accomplish accurate registration. It is also robust to weak, repeating and inconsistent textures. We also show that our system can be easily integrated into dental diagnostic and therapeutic procedures, such as bracket placement guidance.
C1 [Li, Hai; Zhai, Hongjia; Bao, Hujun; Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Yang, Xingrui] China Aerodynam Res & Dev Ctr, High Speed Aerodynam Inst, Mianyang, Peoples R China.
   [Wu, Zhirong; Zheng, Yihao; Wang, Haofan] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Wu, Jianchao] Hangzhou Mingzhou Hosp, Dept Stomatol, Hangzhou, Peoples R China.
   [Wu, Jianchao] Taizhou Stomatol Hosp, Taizhou, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.; Wu, JC (corresponding author), Hangzhou Mingzhou Hosp, Dept Stomatol, Hangzhou, Peoples R China.; Wu, JC (corresponding author), Taizhou Stomatol Hosp, Taizhou, Peoples R China.
EM garyli@zju.edu.cn; zhj1999@zju.edu.cn; xingruiy@gmail.com;
   zhirongwu@zju.edu.cn; zhengyihao@zju.edu.cn; wanghaofan@zju.edu.cn;
   wujianchao555@163.com; baohujun@zju.edu.cn; zhangguofeng@zju.edu.cn
RI Zhang, Ge/K-9118-2019; Zheng, Yihao/J-5070-2019
OI Zhang, Guofeng/0000-0001-5661-8430; Yang, Xingrui/0000-0001-6812-3072;
   Zheng, Yihao/0000-0002-0346-3006; Li, Hai/0000-0002-5114-6566
FU NSF of China [61932003]
FX This work was partially supported by NSF of China (No.61932003).
CR Aichert A, 2012, LECT NOTES COMPUT SC, V7511, P601, DOI 10.1007/978-3-642-33418-4_74
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Azinovic D, 2022, PROC CVPR IEEE, P6280, DOI 10.1109/CVPR52688.2022.00619
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489
   Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267
   Brahmbhatt S, 2018, PROC CVPR IEEE, P2616, DOI 10.1109/CVPR.2018.00277
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen AP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14104, DOI 10.1109/ICCV48922.2021.01386
   Cho S., 2021, Adv. Neural Inf. Process. Syst, V34, P9011
   Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Garg S, 2022, INT J ROBOT RES, V41, P573, DOI 10.1177/0278364919839761
   Geppert M, 2019, IEEE INT CONF ROBOT, P5972, DOI [10.1109/icra.2019.8794280, 10.1109/ICRA.2019.8794280]
   Gropp A, 2020, PR MACH LEARN RES, V119
   Hausler S, 2021, PROC CVPR IEEE, P14136, DOI 10.1109/CVPR46437.2021.01392
   Huang TK, 2018, KAOHSIUNG J MED SCI, V34, P243, DOI 10.1016/j.kjms.2018.01.009
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6187, DOI 10.1109/ICCV48922.2021.00615
   Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li Hai, 2022, IEEE Transactions on Visualization and Computer Graphics
   Lin CH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5721, DOI 10.1109/ICCV48922.2021.00569
   Llena C, 2018, EUR J DENT EDUC, V22, pE122, DOI 10.1111/eje.12269
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahvash M, 2013, ACTA NEUROCHIR, V155, P943, DOI 10.1007/s00701-013-1668-2
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Oechsle M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5569, DOI 10.1109/ICCV48922.2021.00554
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Revaud J, 2019, IEEE I CONF COMP VIS, P5106, DOI 10.1109/ICCV.2019.00521
   Rhienmora P., 2010, Proceedings of the 17th ACM Symposium on Virtual Reality Software and Technology, P97, DOI [10.1145/1889863.1889883, DOI 10.1145/1889863.1889883]
   Roessle B, 2023, Arxiv, DOI arXiv:2205.01694
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shi JF, 2022, INT J MED ROBOT COMP, V18, DOI 10.1002/rcs.2401
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881
   Sun LJ, 2018, AM J ORTHOD DENTOFAC, V153, P355, DOI 10.1016/j.ajodo.2017.06.027
   Taira H, 2021, IEEE T PATTERN ANAL, V43, P1293, DOI 10.1109/TPAMI.2019.2952114
   Tan DL, 2022, Arxiv, DOI arXiv:2209.12213
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Wang DX, 2015, IEEE INT CONF ROBOT, P278, DOI 10.1109/ICRA.2015.7139012
   Wang JC, 2019, INT J COMPUT ASS RAD, V14, P763, DOI 10.1007/s11548-019-01921-5
   Wang JC, 2014, IEEE T BIO-MED ENG, V61, P1295, DOI 10.1109/TBME.2014.2301191
   Wang P, 2021, 35 C NEURAL INFORM P, V34
   Wong K, 2018, OTOLARYNG HEAD NECK, V159, P956, DOI 10.1177/0194599818796476
   Xia PJ, 2013, VISUAL COMPUT, V29, P433, DOI 10.1007/s00371-012-0748-2
   Yang X., 2021, IEEE INT S MIXED AUG, P80
   Yariv L, 2021, ADV NEUR IN
   Yariv Lior, 2020, ARXIV200309852
   Yen-Chen L, 2021, IEEE INT C INT ROBOT, P1323, DOI 10.1109/IROS51168.2021.9636708
   Yixiao Ge, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P369, DOI 10.1007/978-3-030-58548-8_22
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu Zehao, 2022, ABS202200665 ARXIV
NR 65
TC 2
Z9 2
U1 3
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2837
EP 2846
DI 10.1109/TVCG.2023.3247459
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D2HD7
UT WOS:000966975000001
PM 37027614
DA 2024-11-06
ER

PT J
AU Shen, HW
   Kiyokawa, K
AF Shen, Han-Wei
   Kiyokawa, Kiyoshi
TI IEEE VR 2023 Introducing the Special Issue
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
   [Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Ikoma, Japan.
C3 University System of Ohio; Ohio State University; Nara Institute of
   Science & Technology
RP Shen, HW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012
NR 0
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP VII
EP VII
DI 10.1109/TVCG.2023.3249919
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1QD1
UT WOS:000966527100001
OA Bronze
DA 2024-11-06
ER

PT J
AU Zeng, H
   Zhao, R
AF Zeng, Hui
   Zhao, Rong
TI Perceptually-guided Dual-mode Virtual Reality System For Motion-adaptive
   Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial resolution; Optical switches; High-speed optical techniques;
   Visualization; Sensitivity; Rendering (computer graphics); Optical
   imaging; Virtual reality system; foveated display; perception model
ID FIELD; SCHEME
AB An ideal Virtual reality (VR) device should simultaneously provide retina-level resolution, wide field-of-view (FOV), and high refresh rate display, thereby bringing users into a deeply immersive virtual world. However, directly providing such high-quality display poses great challenges for display panel fabrication, real-time rendering, and data transfer. To address this issue, we introduce a dual-mode virtual reality system based on the spatio-temporal perception characteristics of human vision. The proposed VR system has a novel optical architecture. It can switch display modes according to the user's perceptual requirements for different display scenes to adaptively adjust the display spatial and temporal resolution based on a given display budget, thus providing users with the optimal visual perception quality. In this work, a complete design pipeline for the dual-mode VR optical system is proposed, and a bench-top prototype is built with only off-the-shelf hardware and components to verify its capability. Compared to the conventional VR system, our proposed scheme is more efficient and flexible in utilizing the display budget, and this work is expected to facilitate the development of the VR device based on the human visual system.
C1 [Zeng, Hui; Zhao, Rong] Tsinghua Univ, Beijing, Peoples R China.
C3 Tsinghua University
EM zeng-h20@mails.tsinghua.edu.cn; r_zhao@mail.tsinghua.edu.cn
OI ZENG, HUI/0000-0002-0926-8092
FU National Nature Science Foundation of China [61836004]
FX This work was supported by National Nature Science Foundation of China
   (No. 61836004).
CR Aksit K, 2019, IEEE T VIS COMPUT GR, V25, P1928, DOI 10.1109/TVCG.2019.2898781
   [Anonymous], 2015, SMPTE Mot. Imag. J
   [Anonymous], 2005, ADAPTIVE FRAMELESS R
   [Anonymous], 2001, JEAN YVES PYRAMIDAL, V5, P4
   [Anonymous], 2022, VARJO DELIVERS HUMAN
   Barten PGJ, 2004, P SOC PHOTO-OPT INS, V5294, P231, DOI 10.1117/12.537476
   Carmel D, 2006, CURR BIOL, V16, P907, DOI 10.1016/j.cub.2006.03.055
   Chapiro A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3338696
   Chaurasia G, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3384540
   Cheng DW, 2022, OPT EXPRESS, V30, P6584, DOI 10.1364/OE.452747
   CURCIO CA, 1990, J COMP NEUROL, V300, P5, DOI 10.1002/cne.903000103
   Denes G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392411
   Gao C, 2021, APPL OPTICS, V60, P8634, DOI 10.1364/AO.432911
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   HOWLETT EM, 1992, P SOC PHOTO-OPT INS, V1669, P193, DOI 10.1117/12.60427
   Iwase Y, 2018, J SOC INF DISPLAY, V26, P304, DOI 10.1002/jsid.666
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Kimura S, 2021, IEEE T VIS COMPUT GR, V27, P4256, DOI 10.1109/TVCG.2021.3106486
   Krajancich B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459784
   Lee J, 2022, OPT EXPRESS, V30, P2078, DOI 10.1364/OE.448262
   Lee J, 2019, OPT EXPRESS, V27, P36757, DOI 10.1364/OE.27.036757
   Liberatore MJ, 2021, VIRTUAL REAL-LONDON, V25, P773, DOI 10.1007/s10055-020-00492-0
   Liu ML, 2018, OPT EXPRESS, V26, P4060, DOI 10.1364/OE.26.004060
   Mantiuk RK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530115
   Park S, 2019, OPT EXPRESS, V27, P29594, DOI 10.1364/OE.27.029594
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Rolland JP, 1998, APPL OPTICS, V37, P4183, DOI 10.1364/AO.37.004183
   Shenker M., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V778, P70, DOI 10.1117/12.940468
   Spjut J, 2020, IEEE T VIS COMPUT GR, V26, P2126, DOI 10.1109/TVCG.2020.2973053
   Tan GJ, 2018, OPT EXPRESS, V26, P25076, DOI 10.1364/OE.26.025076
   Tariq T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530101
   Vieri C, 2018, J SOC INF DISPLAY, V26, P314, DOI 10.1002/jsid.658
   Vr compare, 2022, US
   Walton DR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P746, DOI 10.1109/VR51125.2022.00096
   Watson Andrew B., 2013, Motion Imaging Journal, V122, P18
   Xia XX, 2019, IEEE T VIS COMPUT GR, V25, P3114, DOI 10.1109/TVCG.2019.2932238
   Xiao Lei, SPECIAL INTEREST GRO, P1
   Xiong JH, 2021, LIGHT-SCI APPL, V10, DOI 10.1038/s41377-021-00658-8
   Yin K, 2022, J SOC INF DISPLAY, V30, P381, DOI 10.1002/jsid.1120
   Yoo CY, 2020, OPT EXPRESS, V28, P23690, DOI 10.1364/OE.399808
NR 42
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2249
EP 2257
DI 10.1109/TVCG.2023.3247097
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1JK8
UT WOS:000966352000001
PM 37027616
DA 2024-11-06
ER

PT J
AU Weidner, F
   Boettcher, G
   Arboleda, SA
   Diao, CY
   Sinani, L
   Kunert, C
   Gerhardt, C
   Broll, W
   Raake, A
AF Weidner, Florian
   Boettcher, Gerd
   Arboleda, Stephanie Arevalo
   Diao, Chenyao
   Sinani, Luljeta
   Kunert, Christian
   Gerhardt, Christoph
   Broll, Wolfgang
   Raake, Alexander
TI A Systematic Review on the Visualization of Avatars and Agents in AR &
   VR displayed using Head-Mounted Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Avatars; Rendering (computer graphics); Task analysis; Visualization;
   Systematics; Head-mounted displays; Databases; Virtual reality;
   augmented reality; avatars; visualization
AB Augmented Reality (AR) and Virtual Reality (VR) are pushing from the labs towards consumers, especially with social applications. These applications require visual representations of humans and intelligent entities. However, displaying and animating photo-realistic models comes with a high technical cost while low-fidelity representations may evoke eeriness and overall could degrade an experience. Thus, it is important to carefully select what kind of avatar to display. This article investigates the effects of rendering style and visible body parts in AR and VR by adopting a systematic literature review. We analyzed 72 papers that compare various avatar representations. Our analysis includes an outline of the research published between 2015 and 2022 on the topic of avatars and agents in AR and VR displayed using head-mounted displays, covering aspects like visible body parts (e.g., hands only, hands and head, full-body) and rendering style (e.g., abstract, cartoon, realistic); an overview of collected objective and subjective measures (e.g., task performance, presence, user experience, body ownership); and a classification of tasks where avatars and agents were used into task domains (physical activity, hand interaction, communication, game-like scenarios, and education/training). We discuss and synthesize our results within the context of today's AR and VR ecosystem, provide guidelines for practitioners, and finally identify and present promising research opportunities to encourage future research of avatars and agents in AR/VR environments.
C1 [Weidner, Florian; Boettcher, Gerd; Kunert, Christian; Gerhardt, Christoph; Broll, Wolfgang] Tech Univ Ilmenau, Virtual Worlds & Digital Games Grp, Ilmenau, Germany.
   [Arboleda, Stephanie Arevalo; Diao, Chenyao; Sinani, Luljeta; Raake, Alexander] Audiovisual Technol Grp, Tech Universit&x00E4, t Ilmenau, Ilmenau, Germany.
C3 Technische Universitat Ilmenau
RP Weidner, F (corresponding author), Tech Univ Ilmenau, Virtual Worlds & Digital Games Grp, Ilmenau, Germany.
EM florian.weidner@tu-ilmenau.de; gerd.boettcher@tu-ilmenau.de;
   stephanie.arevalo@tu-ilmenau.de; chenyao.diao@tu-ilmenau.de;
   luljeta.sinani@tu-ilmenau.de; christian.kunert@tu-ilmenau.de;
   christoph.gerhardt@tu-ilmenau.de; wolfgang.broll@tu-ilmenau.de;
   alexander.raake@tu-ilmenau.de
RI Broll, Wolfgang/AAB-5897-2022; Weidner, Florian/JHU-6915-2023; Raake,
   Alexander/R-7050-2017
OI Raake, Alexander/0000-0002-9357-1763; Arevalo Arboleda,
   Stephanie/0000-0001-5577-4407; Broll, Wolfgang/0000-0001-7483-1550
FU CYTEMEX project (Free State of Thuringia, Germany) [FKZ: 2018-FGI-0019];
   MULTI-PARTIES project (Federal Ministry of Education and Research,
   Germany); CO-HUMANICS project (Carl Zeiss Foundation)
FX This work has been partially funded through the CYTEMEX project(Free
   State of Thuringia, Germany, FKZ: 2018-FGI-0019), the MULTI-PARTIES
   project (Federal Ministry of Education and Research, Germany), and the
   CO-HUMANICS project (Carl Zeiss Foundation).
CR Afonso L., 2017, 3DUI
   [Anonymous], 1998, Presence: Teleoperators Virtual Environments
   Argelaguet F., 2016, VR
   Aseeri S. A., 2021, IEEE T VIS COMPUT GR, V27
   BAILENSON J.N., 2004, Encyclopedia of Human-Computer Interaction
   Bailenson J. N., 2006, PRESENCE TELEOPERATO, V15
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Biocca F., 2002, P 5 INT WORKSH PRES, P7
   Bodenheimer B., 2015, SAP
   Boukarras S, 2022, J COGNITIVE NEUROSCI, V34, P897, DOI 10.1162/jocn_a_01834
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Buck LE, 2022, IEEE T VIS COMPUT GR, V28, P2102, DOI 10.1109/TVCG.2022.3150483
   Butz M., 2022, ARTSIT INTERACTIVITY
   Cho S., 2020, VR
   Cho Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.1985
   Choi Y., 2020, VR
   Daher S, 2020, SIMUL HEALTHC, V15, P115, DOI 10.1097/SIH.0000000000000409
   Dai ZY, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.168
   Dewez D, 2022, IEEE T VIS COMPUT GR, V28, P2047, DOI 10.1109/TVCG.2022.3150501
   DOnofrio S., 2023, SPRINGER HDB AUGMENT, P597
   Egan Z., 2020, AIVR
   Freiwald J. P., 2021, MUC
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gamelin G., 2021, PERS UBIQUITOUS COMP, V25
   Gao B., 2020, VR WORKSH
   Genay A, 2022, IEEE T VIS COMPUT GR, V28, P5071, DOI 10.1109/TVCG.2021.3099290
   George C., 2018, VRST
   Gochfeld D., 2019, GEM
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Green R, 2020, ADDICT BEHAV, V108, DOI 10.1016/j.addbeh.2020.106461
   Grubert J., 2018, VR
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   Hantono BS, 2016, 2016 6TH INTERNATIONAL ANNUAL ENGINEERING SEMINAR (INAES), P150, DOI 10.1109/INAES.2016.7821924
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Hassenzahl Marc, 2003, Mensch & Computer, P187, DOI [DOI 10.1007/978-3-322-80058-9_19, 10.1007/978-3-322-80058-919]
   Heidicker P., 2017, 3DUI
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Huang A., 2022, CHI
   Hudson I., 2016, LECT NOTES COMPUTER, V9740
   igroup.org, 2016, IGR PRES QUEST IPQ O
   Jo D., 2017, VRST
   Joy T., 2022, VIRTUAL REAL, V26
   Jung S., 2016, ICAT EGVE
   Jung S., 2017, SUI
   Karademas EC, 2022, HEALTH PSYCHOL REV, V16, P1, DOI 10.1080/17437199.2021.1874471
   Karaosmanoglu S., 2021, CHI
   Kätsyri J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00390
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Khojasteh N, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.643331
   Knierim P., 2018, CHI
   Kocur M., 2020, VRST
   Kocur M., 2022, THESIS
   Kondo R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25951-2
   Kontogeorgiou AM, 2008, PSYCHNOLOGY J, V6, P83
   Korban M., 2022, ABS220104168 CORR
   Krogmeier C, 2020, COMPUT ANIMAT VIRT W, V31, DOI 10.1002/cav.1941
   Krom B. N., 2019, WHC
   Kruzic CO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76672-4
   Latoschik M. E., 2017, VRST
   Li F., 2021, SMC
   Lin L., 2016, SAP
   Lougiakis C., 2020, VR
   Lugrin J., 2016, VRST
   Lugrin J., 2018, VR
   Lugrin J., 2015, VR
   Ma F., 2022, VR
   Makransky G., 2019, J COMPUT ASSIST LEAR, V35
   Marquart G, 2015, PROCEDIA MANUF, V3, P2854, DOI 10.1016/j.promfg.2015.07.783
   Matsuda Y., 2021, FRONTIERS VIRTUAL RE, V2
   Mayer R.E., 2005, The Cambridge handbook of multimedia learning, P201
   McDonnell R., 2012, LECT NOTES COMPUTER, V7660
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Melo M., 2022, VIRTUAL REAL, V26
   Mousas C, 2018, COMPUT HUM BEHAV, V86, P99, DOI 10.1016/j.chb.2018.04.036
   NOROUZI N, 2019, T COMP SCI COMP INTE, DOI DOI 10.1145/3357251.3357587
   Ofek E., 2020, FRONTIERS VIRTUAL RE, V1
   Ogawa N., 2019, VR
   Ogawa N., 2021, IEEE T VIS COMPUT GR, V27
   Ogawa N., 2020, CHI
   Oh CS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00114
   Oliva R, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.937191
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Panteleris P, 2018, IEEE WINT CONF APPL, P436, DOI 10.1109/WACV.2018.00054
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peissl S, 2018, INT J AEROSP PSYCHOL, V28, P98, DOI 10.1080/24721840.2018.1514978
   Petersen G. B., 2021, CHI
   Pickering C., 2015, STUDIES HIGHER ED, V40
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Praetorius A. S., 2020, FDG
   Reinhardt J., 2020, TANGIBLE EMBEDDED IN
   Rigby J. M., 2019, TVX
   Rosa N., 2019, VR
   Roth D., 2017, CHI EXTENDED ABSTRAC
   Rubin R.B., 2004, Communication research measures: A sourcebook
   Rzayev R., 2019, MUC
   Schloss I., 2021, IDC
   SCHRODER M, 2018, IEEE T VIS COMPUT GR, V29, DOI DOI 10.1002/CAV.1751
   Schwind V., 2017, CHI
   Schwind V., 2017, CHI PLAY
   Schwind V., 2018, CHI Play
   Schwind V., 2018, SAP
   SHEPHARD AM, 2022, FRONT VIRTUAL REAL, V3
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Smith H. J., 2018, CHI
   Steed A., 2020, IEEE T VIS COMPUT GR, V26
   Stuart J, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.864676
   Sun Y., 2019, PLOS ONE, V14, p221 803
   Szolin K, 2023, HUM-COMPUT INTER-US, V38, P374, DOI 10.1080/07370024.2022.2103419
   Tran T. Q., 2017, VRST
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Valkov D., 2016, VR
   Volonte M., 2022, VR WORKSH
   Volonte M, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P141, DOI 10.1145/3308532.3329461
   Wang I., 2019, CHI
   Wang T., 2019, VR
   Williams P. A., 2017, AIS T HUM COMPUT INT, V9
   Wirth M., 2021, VR
   Woodworth J. W., 2019, VR
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yoon B., 2019, VR
   Young M. K., 2015, SAP
   Yu K, 2021, IEEE T VIS COMPUT GR, V27, P4129, DOI 10.1109/TVCG.2021.3106480
   Zhang J., 2020, ISCID
   Zhang K., 2022, ASSETS
   Zibrek K., 2019, MIG
   Zibrek K., 2017, SAP
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 130
TC 25
Z9 25
U1 11
U2 22
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2596
EP 2606
DI 10.1109/TVCG.2023.3247072
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1AE1
UT WOS:000966110700001
PM 37027741
DA 2024-11-06
ER

PT J
AU Han, PH
   Wang, TH
   Chou, CH
AF Han, Ping-Hsuan
   Wang, Tzu-Hua
   Chou, Chien-Hsing
TI GroundFlow: Liquid-based Haptics for Simulating Fluid on the Ground in
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE liquid-based haptic; floor-based haptic; multiple fluid feedback;
   virtual reality
AB Utilizing haptic devices to enhance the immersive experience is a direct approach in virtual reality (VR) applications. Various studies develop haptic feedback using force, wind, and thermal mechanisms. However, most haptic devices simulate feedback in dry environments such as the living room, prairie, or city. Water-related environments are thus less explored, for example, rivers, beaches, and swimming pools. In this paper we present GroundFlow, a liquid-based haptic floor system for simulating fluid on the ground in VR. We discuss design considerations and propose a system architecture and interaction design. We conduct two user studies to assist in the design of a multiple-flow feedback mechanism, develop three applications to explore the potential uses of the mechanism, and consider the limitations and challenges thereof to inform VR developers and haptic practitioners.
C1 [Han, Ping-Hsuan; Wang, Tzu-Hua] Natl Taipei Univ Technol, Dept Interact Design, Taipei, Taiwan.
   [Chou, Chien-Hsing] Natl Taipei Univ Educ, Dept Math & Informat Educ, Taipei, Taiwan.
C3 National Taipei University of Technology; National Taipei University of
   Education
RP Han, PH (corresponding author), Natl Taipei Univ Technol, Dept Interact Design, Taipei, Taiwan.
EM han@ntut.edu.tw; wangtzuhua1002@gmail.com; chchou@mail.ntue.edu.tw
RI Han, Ping-Hsuan/GZA-5126-2022
OI Han, Ping-Hsuan/0000-0003-3631-9139
FU National Science and Technology Council of Taiwan [MOST
   110-2222-E-027-012-MY3]
FX This research was supported by the National Science and Technology
   Council of Taiwan under grant MOST 110-2222-E-027-012-MY3.
CR Bernoulli D., 1738, Hydrodynamica
   Boulic C. C., 2012, FLOOR BASED AUDIOHAP
   Cakmak T., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P1, DOI DOI 10.1145/2614066.2614105
   Chen CW, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351436
   DIVR, 2021, VIRT REAL SNORK
   FAUVILLE A, 2021, SCI REP-UK, V11, P1
   Han T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P913, DOI 10.1145/3242587.3242667
   HATSUSHIKA K, 2018, OCEANS 2018 MTSIEEE, P1
   Hoste Lode, 2014, P 8 INT C TANG EMB E, P173, DOI DOI 10.1145/2540930.2540946
   Hulsmann F, 2014, LAVAL VIRTUAL VRIC 1, DOI [10.1145/2617841.2620712, DOI 10.1145/2617841.2620712]
   Je Seungwoo, 2021, P 2021 CHI C HUMAN F, P1
   Khot RA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2933, DOI 10.1145/2702123.2702197
   Koike H., 2013, P 2013 ACM INT C INT, P155, DOI DOI 10.1145/2512349.2512815
   Lawson R, 2014, ATTEN PERCEPT PSYCHO, V76, P541, DOI 10.3758/s13414-013-0559-1
   Lee J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P183, DOI 10.1145/2984511.2984583
   Liao Y.-F., 2019, ADV CIV ENG, P1, DOI DOI 10.1080/14719037.2019.1577907
   Lijuan Liu, 2020, HCI International 2020 - Late Breaking Papers. Digital Human Modeling and Ergonomics, Mobility and Intelligent Environments. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12429), P316, DOI 10.1007/978-3-030-59987-4_23
   Liu SH, 2021, 2021 IEEE INTERNATIONAL SYMPOSIUM ON RADIO-FREQUENCY INTEGRATION TECHNOLOGY (RFIT), DOI [10.1109/RFIT52905.2021.9565295, 10.1145/3458335.3460811]
   Matsuura Y, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P227, DOI 10.1145/3279778.3279796
   Matthews T, 2017, Psychol Med, V47, P2177, DOI 10.1017/S0033291717000629
   Nakano H., 2006, ACM SIGGRAPH 2006 EM, P19
   ON OS, 2020, P 2020 CHI C HUMAN F, P1
   Oppermann L, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P330, DOI 10.1145/2935334.2935368
   Pearson G., 1988, P SIGCHI C HUMAN FAC, P13, DOI DOI 10.1145/57167.57169
   Raffe William L., 2015, P 2015 ANN S COMP HU, V2793134, P295, DOI [10.1145/2793107.2793134, DOI 10.1145/2793107.2793134]
   Schmidt H., 2005, ACM T APPL PERCEPT, V2, P166
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   SINNOTT J, 2019, 25 ACM S VIRTUAL REA, P1
   Takahashi Yoichi, 2012, P 2012 ACM INT C INT, P311
   teamLab, 2016, DRAW WAT SURF CREAT
   Teng SY, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P639, DOI 10.1145/3332165.3347958
   Visell Yon, 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P133, DOI 10.1109/HAPTIC.2010.5444664
   Visell Y, 2010, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2010.5444748
   Visell Y, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P75, DOI 10.1109/3DUI.2010.5444718
   Wang T.-S., 2021, SIGGRAPH AS 2021 EM, P1
   WILBERZ D, 2020, P 2020 CHI C HUMAN F, P1
   Yamanaka S, 2018, 20TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI 2018), DOI 10.1145/3229434.3229435
   Yamashita S., 2016, P ICAT EGVE, P25
NR 38
TC 6
Z9 6
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2670
EP 2679
DI 10.1109/TVCG.2023.3247073
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D0XX1
UT WOS:000966051700001
PM 37027583
DA 2024-11-06
ER

PT J
AU Kern, F
   Niebling, F
   Latoschik, ME
AF Kern, Florian
   Niebling, Florian
   Latoschik, Marc Erich
TI Text Input for Non-Stationary XR Workspaces: Investigating Tap and
   Word-Gesture Keyboards in Virtual and Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Keyboards; X reality; Usability; Performance evaluation; User
   experience; Task analysis; Tracking; Virtual Reality; Augmented Reality;
   Extended Reality; Text Input; Keyboard; Tap; Swipe; Word-Gesture;
   Digital Twin
ID ANOVA; ENTRY; DISPLAY
AB This article compares two state-of-the-art text input techniques between non-stationary virtual reality (VR) and video see-through augmented reality (VST AR) use-cases as XR display condition. The developed contact-based mid-air virtual tap and word-gesture (swipe) keyboard provide established support functions for text correction, word suggestions, capitalization, and punctuation. A user evaluation with 64 participants revealed that XR displays and input techniques strongly affect text entry performance, while subjective measures are only influenced by the input techniques. We found significantly higher usability and user experience ratings for tap keyboards compared to swipe keyboards in both VR and VST AR. Task load was also lower for tap keyboards. In terms of performance, both input techniques were significantly faster in VR than in VST AR. Further, the tap keyboard was significantly faster than the swipe keyboard in VR. Participants showed a significant learning effect with only ten sentences typed per condition. Our results are consistent with previous work in VR and optical see-through (OST) AR, but additionally provide novel insights into usability and performance of the selected text input techniques for VST AR. The significant differences in subjective and objective measures emphasize the importance of specific evaluations for each possible combination of input techniques and XR displays to provide reusable, reliable, and high-quality text input solutions. With our work, we form a foundation for future research and XR workspaces. Our reference implementation is publicly available to encourage replicability and reuse in future XR workspaces.
C1 [Kern, Florian; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Niebling, Florian] Hsch Fulda, Angew Informat, Fulda, Germany.
C3 University of Wurzburg
RP Kern, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
EM florian.kern@uni-wuerzburg.de; florian.niebling@informatik.hs-fulda.de;
   marc.latoschik@uni-wuerzburg.de
RI Latoschik, Marc/HLG-5348-2023
OI Kern, Florian/0000-0001-7092-4872
FU German Federal Ministry of Education and Research in project ViLeArn
   More [16DHB2214]; Bavarian State Ministry For Digital Affairs in project
   XR Hub [A5-3822-2-16]
FX We thank Lukas Schreiner and Jonathan Tschanter for their support in
   developing the reference implementation and Lukas Schreiner for
   conducting the user study. This work was supported by the German Federal
   Ministry of Education and Research in the project ViLeArn More
   (Reference: 16DHB2214) and by the Bavarian State Ministry For Digital
   Affairs in the project XR Hub (Reference: A5-3822-2-16).
CR Adhikary J, 2021, LECT NOTES COMPUT SC, V12935, P132, DOI 10.1007/978-3-030-85610-6_9
   Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   Alharbi Ohoud, 2022, Graphics Interface 2022
   [Anonymous], 2006, P 4 NORDIC C HUMAN C, DOI DOI 10.1145/1182475.1182534
   Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Biener V., 2021, ARXIV211103942CS
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Boletsis Costas., 2019, INT J VIRTUAL REALIT, V19, P2, DOI DOI 10.20870/IJVR.2019.19.3.2917
   Bovet S, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P132, DOI 10.1109/GEM.2018.8516449
   Bowman D., 2004, 3D USER INTERFACES T
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Buckingham G, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.728461
   Chen SY, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024682
   DAMERAU FJ, 1964, COMMUN ACM, V7, P171, DOI 10.1145/363958.363994
   Derby Jessyca L., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1476, DOI 10.1177/1071181319631279
   Dhakal V, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174220
   Dube TJ, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519679
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   DUBE TJ, 2020, 2020 CHI C HUM FACT
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Fashimpaur Jacqui, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382888
   Feit AM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4262, DOI 10.1145/2858036.2858233
   Fereydooni N., 2020, Virtual reality as a remote workspace platform: Opportunities and challenges
   Fiorentino M, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P86, DOI 10.1109/ISMAR.2002.1115077
   Franco-Salvador M, 2018, INT J HUM-COMPUT ST, V113, P15, DOI 10.1016/j.ijhcs.2018.01.006
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.2307/1165127
   Hoppe AH, 2018, COMM COM INF SC, V851, P266, DOI 10.1007/978-3-319-92279-9_36
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Jiang HY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P132, DOI 10.1109/ISMAR-Adjunct.2018.00051
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489940
   Kern F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684498
   KIM N, 2021, HUMAN COMPUTER INTER, P131, DOI DOI 10.1007/978-3-030-82681-9_5
   Klein J, 2002, INTERACT COMPUT, V14, P119, DOI 10.1016/S0953-5438(01)00053-4
   Knierim P, 2021, IEEE PERVAS COMPUT, V20, P71, DOI 10.1109/MPRV.2021.3119378
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174007
   KO CT, 2017, ACM SIGGRAPH 2017 SI, P18, DOI DOI 10.1145/3102163.3102175
   Kristensson P., 2004, P 17 ANN ACM S USER, P43, DOI DOI 10.1145/1029632.1029640
   Kristensson Per Ola, 2012, P 2012 ACM INT C INT, P29, DOI [DOI 10.1145/2166966.2166972, 10.1145/2166966.2166972]
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Kumar C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376317
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Lakens D., 2021, Advances Methods Practices Psychological Science, V4, DOI [DOI 10.1177/2515245920951503, 10.1177/2515245920951503]
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Lee L. H., 2019, 2019 IEEE INT C PERV, P1, DOI [10.1109/PERCOM.2019.8767420, DOI 10.1109/PERCOM.2019.8767420]
   Lee Minkyung, 2003, ICAT
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li GC, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146375
   Li Jingyi, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3546716
   Li YX, 2021, PEER PEER NETW APPL, V14, P2826, DOI 10.1007/s12083-021-01103-8
   Lu XS, 2020, INT SYM MIX AUGMENT, P344, DOI 10.1109/ISMAR50242.2020.00061
   Lu XS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1060, DOI [10.1109/VR.2019.8797901, 10.1109/vr.2019.8797901]
   Lugrin Jean-Luc, 2016, FRONTIERS ICT, V3, DOI [DOI 10.3389/FICT.2016.00026, 10.3389/ fict.2016.00026]
   Lystbaek Mathias N., 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3530882
   MacKenzie I. S., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P161, DOI 10.1145/108844.108868
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   Markussen A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1073, DOI 10.1145/2556288.2556964
   Markussen A, 2013, LECT NOTES COMPUT SC, V8117, P401
   McGill M, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3490495
   Milgram P, 1999, MIXED REALITY, P5
   Ogitani T, 2018, INT CON ADV INFO NET, P342, DOI 10.1109/AINA.2018.00059
   Otte A, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P387, DOI 10.1109/ISMAR-Adjunct.2019.000-4
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364265
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364264
   Pick S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P109, DOI 10.1109/3DUI.2016.7460039
   Rick J., 2010, UIST 10, P77, DOI DOI 10.1145/1866029.1866043
   Rickel E, 2022, LECT NOTES COMPUT SC, V13317, P357, DOI 10.1007/978-3-031-05939-1_24
   Schenkluhn M., 2022, HUMAN COMPUTER INTER, P9
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Shao YF, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P60, DOI 10.1145/2935334.2935336
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Skarbez R, 2021, IEEE T VIS COMPUT GR, V27, P3839, DOI 10.1109/TVCG.2020.2983701
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Turner CJ, 2018, J USABILITY STUD, V13, P94
   Vertanen K., 2011, P C EMP METH NAT LAN, P700, DOI DOI 10.5555/2145432.2145514
   Vertanen K., 2011, P 13 INT C HUM COMP, P295, DOI [DOI 10.1145/2037373.2037418, 10.1145/2037373.2037418]
   Wagner JA, 2019, IEEE COMPUT GRAPH, V39, P41, DOI 10.1109/MCG.2019.2898856
   Walker J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5457, DOI 10.1145/3025453.3025783
   Weir D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2307
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Xu WG, 2019, IEEE T VIS COMPUT GR, V25, P1991, DOI 10.1109/TVCG.2019.2898736
   Yanagihara N, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3365026
   Yildiran NF, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P667, DOI 10.1109/VRW55335.2022.00189
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Zhai S., 2003, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 2003), P97, DOI DOI 10.1145/642611.642630
   Zhai S., 2012, Foundations and Trends in HumanComputer Interaction, V5, P97, DOI [DOI 10.1561/1100000012, 10.1561/1100000012]
   Zhai SM, 2012, COMMUN ACM, V55, P91, DOI 10.1145/2330667.2330689
   Zhican Yang, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351275
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1884, DOI [10.1109/vr.2019.8797837, 10.1109/VR.2019.8797837]
NR 102
TC 0
Z9 0
U1 2
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2658
EP 2669
DI 10.1109/TVCG.2023.3247098
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1ML9
UT WOS:000966431400001
OA hybrid
DA 2024-11-06
ER

PT J
AU Moullec, Y
   Cogné, M
   Saint-Aubert, J
   Lécuyer, A
AF Moullec, Yann
   Cogne, Melanie
   Saint-Aubert, Justine
   Lecuyer, Anatole
TI Assisted walking-in-place: Introducing assisted motion to
   walking-by-cycling in embodied virtual reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Fatigue; Navigation; Avatars; Propioception; Virtual
   environments; User interfaces; Embodiment; virtual walk; avatar;
   perceived effort
ID AGENCY; SENSE; BODY; STIMULATION; SENSATION
AB In this paper, we investigate the use of a motorized bike to support the walk of a self-avatar in virtual reality (VR). While existing walking-in-place (WIP) techniques render compelling walking experiences, they can be judged repetitive and strenuous. Our approach consists in assisting a WIP technique so that the user does not have to actively move in order to reduce effort and fatigue. We chose to assist a technique called walking-by-cycling, which consists in mapping the cycling motion of a bike onto the walking of the user's self-avatar, by using a motorized bike. We expected that our approach could provide participants with a compelling walking experience while reducing the effort required to navigate. We conducted a within-subjects study where we compared "assisted walking-by-cycling" to a traditional active walking-by-cycling implementation, and to a standard condition where the user is static. In the study, we measured embodiment, including ownership and agency, walking sensation, perceived effort and fatigue. Results showed that assisted walking-by-cycling induced more ownership, agency, and walking sensation than the static simulation. Additionally, assisted walking-by-cycling induced levels of ownership and walking sensation similar to that of active walking-by-cycling, but it induced less perceived effort. Taken together, this work promotes the use of assisted walking-by-cycling in situations where users cannot or do not want to exert much effort while walking in embodied VR such as for injured or disabled users, for prolonged uses, medical rehabilitation, or virtual visits.
C1 [Moullec, Yann; Cogne, Melanie; Saint-Aubert, Justine; Lecuyer, Anatole] Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
   [Cogne, Melanie] CHU Rennes, Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Inria; CHU Rennes; Universite de Rennes
RP Moullec, Y (corresponding author), Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
EM yann.moullec@inria.fr; melanie.cogne@chu-rennes.fr;
   justine.saint-aubert@inria.fr; anatole.lecuyer@inria.fr
RI Cogne, Melanie/JVN-4300-2024
OI Moullec, Yann/0000-0002-1604-8864; Saint-Aubert,
   Justine/0000-0001-8412-653X
CR Akselrod M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97540-9
   Amemiya T, 2020, IEEE T HAPTICS, V13, P80, DOI 10.1109/TOH.2020.2965937
   [Anonymous], 2010, P 17 ACM S VIRTUAL R
   Auvray M., 2014, HAPTICS NEUROSCIENCE, DOI [10.1007/978-3-662-44193-0, DOI 10.1007/978-3-662-44193-0_202]
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Bozgeyikli E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P33, DOI 10.1145/2983310.2985763
   Braun N, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0111967
   Bruno L, 2013, LECT NOTES COMPUT SC, V8119, P370
   Bruun-Pedersen J.R., 2016, 2016 IEEE International Conference on Serious Games and Applications for Health (SeGAH), P1
   Bruun-Pedersen JR, 2014, 2014 2ND WORKSHOP ON VIRTUAL AND AUGMENTED ASSISTIVE TECHNOLOGY (VAAT), P23, DOI 10.1109/VAAT.2014.6799464
   Caspar EA, 2015, CONSCIOUS COGN, V33, P226, DOI 10.1016/j.concog.2015.01.007
   Chambon V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00320
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   Crowell III J. A., 2006, IMPROVEMENTS OMNI DI, V2
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Dummer T, 2009, PERCEPTION, V38, P271, DOI 10.1068/p5921
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Feasel J, 2011, IEEE T NEUR SYS REH, V19, P290, DOI 10.1109/TNSRE.2011.2120623
   Feng M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P95, DOI 10.1109/3DUI.2016.7460037
   Freiwald JP, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376574
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Guy Emilie, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2015.7131725
   Hanashima J., ELICIT OWNERSHIP AGE
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   Hoeg ER, 2023, VIRTUAL REAL-LONDON, V27, P245, DOI 10.1007/s10055-021-00544-z
   Hoeg ER, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P242, DOI 10.1109/VRW52623.2021.00052
   Ikei S., RENDERING VIRTUAL WA
   Ikei Y, 2016, P IEEE VIRT REAL ANN, P185, DOI 10.1109/VR.2016.7504715
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Kakehi Y., 2019, ICAT EGVE 2019 INT C, DOI [10.2312/egve.201912792[65]Z, DOI 10.2312/EGVE.201912792[65]Z]
   Kalckert A, 2014, CONSCIOUS COGN, V26, P117, DOI 10.1016/j.concog.2014.02.003
   Kalckert A, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00040
   Ke PNCA, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P438, DOI 10.1109/VR50410.2021.00067
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim JS, 2008, LECT NOTES COMPUT SC, V5166, P58
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kotze P., 2013, LECT NOTES COMPUT SC, P370, DOI [10.1007/978-3-642-40477-1_232, DOI 10.1007/978-3-642-40477-1_232]
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Longo MR, 2009, PERCEPTION, V38, P69, DOI 10.1068/p6045
   Matsuda J., 2021, FRONTIERS VIRTUAL RE, V2
   Micklewright D, 2017, SPORTS MED, V47, P2375, DOI 10.1007/s40279-017-0711-5
   Nabiyouni Mahdi, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P3, DOI 10.1109/3DUI.2015.7131717
   Nilsson N. C., 2013, P MOT GAM, P155, DOI DOI 10.1145/2522628.2522655
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Reiners D., 2016, ICAT EGVE 2016 INT C, DOI [10.2312/egve.201614292[55]M.V, DOI 10.2312/EGVE.201614292[55]M.V]
   Riecke B.E., 2012, vection") in virtual reality?, P17
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Saint-Aubert J, 2023, IEEE T VIS COMPUT GR, V29, P3507, DOI 10.1109/TVCG.2022.3161130
   Saka N, 2016, ICAT EGVE 2016 INT C, DOI [10.2312/egve.201614292, DOI 10.2312/EGVE.201614292]
   Sanchez-Vives MV, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010381
   Sarupuri B, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P138, DOI 10.1145/3131277.3132177
   Skopp NA, 2014, INT J HUM-COMPUT INT, V30, P24, DOI 10.1080/10447318.2013.796441
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Unno K., 2019, 17 INT C VIRT REAL C, P1, DOI [10.1145/3359997.33657222, DOI 10.1145/3359997.33657222]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Yamamoto S., 2022, LECT NOTES COMPUTER, P111, DOI [10.1007/978-3-031-06509-5_93[24]A, DOI 10.1007/978-3-031-06509-5_93[24]A]
   Yamaoka R., RENDERING WALKING SE
   Yan ZX, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P27, DOI 10.1109/3DUI.2016.7460027
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 69
TC 5
Z9 5
U1 3
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2023
VL 29
IS 5
BP 2796
EP 2805
DI 10.1109/TVCG.2023.3247070
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C4PV6
UT WOS:000961761400001
PM 37015135
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Jin, ZH
   Wang, Y
   Wang, QW
   Ming, Y
   Ma, TF
   Qu, HM
AF Jin, Zhihua
   Wang, Yong
   Wang, Qianwen
   Ming, Yao
   Ma, Tengfei
   Qu, Huamin
TI GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of
   Graph Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Analytical models; Deep learning; Predictive models; Visual analytics;
   Data models; Convolutional neural networks; Task analysis; Graph neural
   networks; error diagnosis; visualization
AB Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph data and have achieved significant progress in graph analysis tasks (e.g., node classification) in recent years. However, similar to other deep neural networks like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), GNNs behave like a black box with their details hidden from model developers and users. It is therefore difficult to diagnose possible errors of GNNs. Despite many visual analytics studies being done on CNNs and RNNs, little research has addressed the challenges for GNNs. This paper fills the research gap with an interactive visual analysis tool, GNNLens, to assist model developers and users in understanding and analyzing GNNs. Specifically, Parallel Sets View and Projection View enable users to quickly identify and validate error patterns in the set of wrong predictions; Graph View and Feature Matrix View offer a detailed analysis of individual nodes to assist users in forming hypotheses about the error patterns. Since GNNs jointly model the graph structure and the node features, we reveal the relative influences of the two types of information by comparing the predictions of three models: GNN, Multi-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case studies and interviews with domain experts demonstrate the effectiveness of GNNLens in facilitating the understanding of GNN models and their errors.
C1 [Jin, Zhihua; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Yong] Singapore Management Univ, Sch Comp & Informat Syst, Singapore 188065, Singapore.
   [Wang, Qianwen] Harvard Univ, Cambridge, MA 02140 USA.
   [Ming, Yao] Bloomberg LP, New York, NY 10022 USA.
   [Ma, Tengfei] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 Hong Kong University of Science & Technology; Singapore Management
   University; Harvard University; Bloomberg L.P.; International Business
   Machines (IBM)
RP Jin, ZH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM zjinak@connect.ust.hk; yongwang@smu.edu.sg;
   qianwen_wang@hms.harvard.edu; ymingaa@connect.ust.hk;
   tengfei.ma1@ibm.com; huamin@cse.ust.hk
RI Wang, Qianwen/GRJ-9435-2022; Wang, Yong/HKF-3903-2023; Ma,
   Tengfei/L-6178-2018
FU Hong Kong Theme-based Research Scheme [T41-709/17N]
FX This work was supported in part by Hong Kong Theme-based Research Scheme
   under Grant T41-709/17N.
CR Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   [Anonymous], 2016, 4 INT C LEARNING REP
   Atwood J, 2016, ADV NEUR IN, V29
   Bar-Joseph Z., 2001, BIOINFORMATICS S1, V17 Suppl 1, pS22, DOI [10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Bendix F, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P133, DOI 10.1109/INFVIS.2005.1532139
   Bojchevski A., 2018, ICLR, P1
   Bojchevski A., 2018, PITFALLS GRAPH NEURA
   Bruna J., 2013, ARXIV
   Chaudhuri Anirban, 2018, 2018 AIAA Non-Deterministic Approaches Conference, P1
   Chen L, 2020, IEEE ACCESS, V8, P43618, DOI 10.1109/ACCESS.2020.2977407
   Chen Y., 2020, Advances in neural information processing systems, V33, P19314
   Defferrard M, 2016, ADV NEUR IN, V29
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Duvenaudt D, 2015, ADV NEUR IN, V28
   EVERITT B, 1980, QUAL QUANT, V14, P75, DOI 10.1007/BF00154794
   Fey M, 2019, Arxiv, DOI arXiv:1903.02428
   Fout A, 2017, ADV NEUR IN, V30
   Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hamilton WL, 2017, IEEE DATA ENG B, P1
   Hancock JT, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00305-w
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kipf TN, 2016, arXiv:1609.02907, P1
   Lafferty J. D., 1995, Computing Science and Statistics. Vol.27. Proceedings of the 27th Symposium on the Interface. Statistics and Manufacturing with Subthemes in Environmental Statistics, Graphics and Imaging, P370
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Li XX, 2020, Arxiv, DOI [arXiv:2002.00514, DOI arXiv:2002.00514.null]
   Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   MacKay DJC, 1996, NEURAL COMPUT, V8, P178, DOI 10.1162/neco.1996.8.1.178
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Niepert M, 2016, PR MACH LEARN RES, V48
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Pope PE, 2019, PROC CVPR IEEE, P10764, DOI 10.1109/CVPR.2019.01103
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velickovic P, 2018, INT C LEARNING REPRE
   Vosough Z, 2018, PROC VISBIA WORKSHOP, P4
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wang MJ, 2020, Arxiv, DOI [arXiv:1909.01315, 10.48550/arXiv.1909.01315]
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wu J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P406, DOI 10.1145/3292500.3330950
   Xu BB, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1897, DOI 10.1145/3397271.3401308
   Xu K., INT C LEARN REPR
   Yang YD, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4099
   Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240
   Zayats Victoria, 2018, Transactions of the Association for Computational Linguistics, V6, P121
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhou J, 2021, Arxiv, DOI [arXiv:1812.08434, DOI 10.48550/ARXIV.1812.08434, 10.48550/arXiv.1812.08434]
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P499, DOI 10.1145/3178876.3186116
NR 67
TC 9
Z9 10
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3024
EP 3038
DI 10.1109/TVCG.2022.3148107
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500015
PM 35120004
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Miyashita, Y
   Sawahata, Y
   Komine, K
AF Miyashita, Yamato
   Sawahata, Yasuhito
   Komine, Kazuteru
TI Perceptual Assessment of Image and Depth Quality of Dynamically
   Depth-Compressed Scene for Automultiscopic 3D Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Image reconstruction; Visualization; Stereo
   image processing; Geometry; Tracking; Real-time systems; Compression
   technologies; depth cues; perception and psychophysics; volumetric
ID PERFORMANCE; STEREO; FUSION; MOTION
AB This article discusses the depth range which automultiscopic 3D (A3D) displays should reproduce for ensuring an adequate perceptual quality of substantially deep scenes. These displays usually need sufficient depth reconstruction capabilities covering the whole scene depth, but due to the inherent hardware restriction of these displays this is often difficult, particularly for showing deep scenes. Previous studies have addressed this limitation by introducing depth compression that contracts the scene depth into a smaller depth range by modifying the scene geometry, assuming that the scenes were represented as CG data. The previous results showed that reconstructing only a physical depth of 1 m is needed to show scenes with much deeper depth and without large perceptual quality degradation. However, reconstructing a depth of 1 m is still challenging for actual A3D displays. In this study, focusing on a personal viewing situation, we introduce a dynamic depth compression that combines viewpoint tracking with the previous approach and examines the extent to which scene depths can be compressed while keeping the original perceptual quality. Taking into account the viewer's viewpoint movements, which were considered a cause of unnaturalness in the previous approach, we performed an experiment with an A3D display simulator and found that a depth of just 10 cm was sufficient for showing deep scenes without inducing a feeling of unnaturalness. Next, we investigated whether the simulation results were valid even on a real A3D display and found that the dynamic approach induced better perceptual quality than the static one even on the real A3D display and that it had a depth enhancing effect without any hardware updates. These results suggest that providing a physical depth of 10 cm on personalized A3D displays is general enough for showing any deeper 3D scenes with appealing subjective quality.
C1 [Miyashita, Yamato] NHK Japan Broadcasting Corp, News Technical Ctr, News Prod & Network Engn Dept, Tokyo 1578510, Japan.
   [Sawahata, Yasuhito] NHK Japan Broadcasting Corp, Sci & Technol Res Labs, Tokyo, Japan.
   [Komine, Kazuteru] NHK Japan Broadcasting Corp, Tokyo, Japan.
C3 NHK Japan Broadcasting Corp; NHK Japan Broadcasting Corp; NHK Japan
   Broadcasting Corp
RP Miyashita, Y (corresponding author), NHK Japan Broadcasting Corp, News Technical Ctr, News Prod & Network Engn Dept, Tokyo 1578510, Japan.
EM miyashita.y-fc@nhk.or.jp; sawahata.y-jq@nhk.or.jp; komine.k-cy@nhk.or.jp
OI Miyashita, Yamato/0000-0003-4944-924X; Sawahata,
   Yasuhito/0000-0002-2212-8780; Komine, Kazuteru/0000-0002-0059-4326
CR Adhikarla VK, 2015, VISUAL COMPUT, V31, P1023, DOI 10.1007/s00371-015-1127-6
   Aksit K, 2019, IEEE T VIS COMPUT GR, V25, P1928, DOI 10.1109/TVCG.2019.2898781
   [Anonymous], 2012, BT50013 ITU
   ARTHUR KW, 1993, ACM T INFORM SYST, V11, P239, DOI 10.1145/159161.155359
   Artusi A., 2011, PROC SIGGRAPH ASIA 2
   Barnum PC, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778813
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Chapiro A, 2014, COMPUT GRAPH FORUM, V33, P63, DOI 10.1111/cgf.12291
   Chen W., 2013, STEREOSCOPIC DISPLAY, P613
   Cho I, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P266, DOI 10.1145/2254556.2254606
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Dodgson NA, 2005, COMPUTER, V38, P31, DOI 10.1109/MC.2005.252
   Favalora GE, 2005, COMPUTER, V38, P37, DOI 10.1109/MC.2005.276
   Gately M, 2011, J DISP TECHNOL, V7, P503, DOI 10.1109/JDT.2011.2157455
   Hoshino H, 1998, J OPT SOC AM A, V15, P2059, DOI 10.1364/JOSAA.15.002059
   Ijsselsteijn W, 2001, PRESENCE-TELEOP VIRT, V10, P298, DOI 10.1162/105474601300343621
   Kellnhofer P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980230
   Kellnhofer P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925866
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kulshreshth A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P125, DOI 10.1145/2702123.2702138
   Kulshreshth A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P177, DOI 10.1145/2858036.2858078
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Masia B, 2013, COMPUT GRAPH-UK, V37, P983, DOI 10.1016/j.cag.2013.06.004
   Matoba Y., 2012, PROC ACM SIGGRAPH201
   Neubauer AC, 2010, INTELLIGENCE, V38, P529, DOI 10.1016/j.intell.2010.06.001
   Ochiai Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2850414
   Oskam T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024223
   Pan X., 2019, PROC ACMSIGGRAPH 201, P1
   Sawahata Y, 2018, IEEE T BROADCAST, V64, P488, DOI 10.1109/TBC.2017.2786022
   Shen X, 2017, PROC SPIE, V10219, DOI 10.1117/12.2262376
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   SOLLENBERGER RL, 1993, HUM FACTORS, V35, P483, DOI 10.1177/001872089303500306
   Takaki Y., 2006, PROC INT M INF DISPL, P211
   Terzic K, 2016, SIGNAL PROCESS-IMAGE, V47, P402, DOI 10.1016/j.image.2016.08.002
   van Beurden MHPH, 2011, PROC SPIE, V7863, DOI 10.1117/12.872566
   WARE C, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P37
   Ware C, 1996, ACM T GRAPHIC, V15, P121, DOI 10.1145/234972.234975
   Wartrell Z, 1999, COMP GRAPH, P351, DOI 10.1145/311535.311587
   Watanabe H, 2020, OPT EXPRESS, V28, P24731, DOI 10.1364/OE.397647
   YEH YY, 1990, HUM FACTORS, V32, P45, DOI 10.1177/001872089003200104
   Zhou Q, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214914
   Zwicker Matthias., 2006, P 17 EUROGRAPHICS C, P73, DOI DOI 10.2312/EGWR/EGSR06/073-082
NR 45
TC 3
Z9 3
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3067
EP 3080
DI 10.1109/TVCG.2022.3148419
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500018
PM 35130158
OA hybrid
DA 2024-11-06
ER

PT J
AU Choo, J
   Ropinski, T
   Hu, YF
AF Choo, Jaegul
   Ropinski, Timo
   Hu, Yifan
TI Editorial: Guest Editors' Introduction: Special Section on IEEE
   PacificVis 2023
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Choo, Jaegul] Korea Adv Inst Sci & Technol, Kim Jaechul Grad Sch AI, Daejeon, South Korea.
   [Ropinski, Timo] Ulm Univ, Visual Comp Grp, Ulm, Germany.
   [Hu, Yifan] Amazon Appl Sci, Seattle, WA USA.
C3 Korea Advanced Institute of Science & Technology (KAIST); Ulm University
RP Choo, J (corresponding author), Korea Adv Inst Sci & Technol, Kim Jaechul Grad Sch AI, Daejeon, South Korea.
EM jchoo@kaist.ac.kr; timo.ropinski@uni-ulm.de; yifanh@gmail.com
RI Choo, Jaegul/ABF-8315-2020
OI Ropinski, Timo/0000-0002-7857-5512; Hu, Yifan/0000-0003-2017-924X
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2847
EP 2848
DI 10.1109/TVCG.2023.3265145
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500001
OA Bronze
DA 2024-11-06
ER

PT J
AU Zhou, JH
   Wang, XM
   Wang, J
   Ye, H
   Wang, HL
   Zhou, ZH
   Han, DM
   Ying, HC
   Wu, J
   Chen, W
AF Zhou, Jiehui
   Wang, Xumeng
   Wang, Jie
   Ye, Hui
   Wang, Huanliang
   Zhou, Zihan
   Han, Dongming
   Ying, Haochao
   Wu, Jian
   Chen, Wei
TI FraudAuditor: A Visual Analytics Approach for Collusive Fraud in Health
   Insurance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Fraud; Insurance; Drugs; Behavioral sciences; Diseases; Feature
   extraction; Visual analytics; collusive fraud; fraud detection; health
   insurance
AB Collusive fraud, in which multiple fraudsters collude to defraud health insurance funds, threatens the operation of the healthcare system. However, existing statistical and machine learning-based methods have limited ability to detect fraud in the scenario of health insurance due to the high similarity of fraudulent behaviors to normal medical visits and the lack of labeled data. To ensure the accuracy of the detection results, expert knowledge needs to be integrated with the fraud detection process. By working closely with health insurance audit experts, we propose FraudAuditor, a three-stage visual analytics approach to collusive fraud detection in health insurance. Specifically, we first allow users to interactively construct a co-visit network to holistically model the visit relationships of different patients. Second, an improved community detection algorithm that considers the strength of fraud likelihood is designed to detect suspicious fraudulent groups. Finally, through our visual interface, users can compare, investigate, and verify suspicious patient behavior with tailored visualizations that support different time scales. We conducted case studies in a real-world healthcare scenario, i.e., to help locate the actual fraud group and exclude the false positive group. The results and expert feedback proved the effectiveness and usability of the approach.
C1 [Zhou, Jiehui; Zhou, Zihan; Han, Dongming; Ying, Haochao; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Wang, Xumeng] Nankai Univ, TMCC, CS, Tianjin 300071, Peoples R China.
   [Wang, Jie] Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.
   [Ye, Hui] Tencent, Shenzhen 518054, Guangdong, Peoples R China.
   [Ying, Haochao] Zhejiang Univ, Sch Publ Hlth, Key Lab Intelligent Prevent Med Zhejiang Prov, Hangzhou 310027, Zhejiang, Peoples R China.
   [Wu, Jian] Zhejiang Univ, Inst Wenzhou, Affiliated Hosp 2, Sch Med,Sch Publ Hlth, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Nankai University; Alibaba Group; Tencent; Zhejiang
   University; Zhejiang University
RP Ying, HC; Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.; Ying, HC (corresponding author), Zhejiang Univ, Sch Publ Hlth, Key Lab Intelligent Prevent Med Zhejiang Prov, Hangzhou 310027, Zhejiang, Peoples R China.
EM zhoujiehui@zju.edu.cn; wangxumeng@nankai.edu.cn;
   siwei.wj@alibabainc.com; hazelye@tencent.com; wanghuanliang@zju.edu.cn;
   zhouzihan@zju.edu.cn; dongminghan@zju.edu.cn; haochaoying@zju.edu.cn;
   wujian2000@zju.edu.cn; chenvis@zju.edu.cn
RI Zhou, Jiehui/KBC-2015-2024; Chen, Wei/AAR-9817-2020
OI Chen, Wei/0000-0002-8365-4741; Ying, Haochao/0000-0001-7832-2518; Zhou,
   Jiehui/0000-0003-0709-775X
FU NSFC [62132017, 62202244]
FX This work was supported by NSFC under Grants 62132017 and 62202244.
CR Akoglu L, 2015, DATA MIN KNOWL DISC, V29, P626, DOI 10.1007/s10618-014-0365-y
   Akoglu L, 2010, LECT NOTES ARTIF INT, V6119, P410
   Bertini E, 2007, IEEE CONF VIS ANAL, P139, DOI 10.1109/VAST.2007.4389007
   Bindu PV, 2018, J INTELL INF SYST, V51, P503, DOI 10.1007/s10844-017-0494-z
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Chen S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P499, DOI 10.1109/ICHI.2013.77
   Didimo W, 2011, IEEE PAC VIS SYMP, P203, DOI 10.1109/PACIFICVIS.2011.5742391
   Ding K, 2019, Data Min, P594
   Joudaki Hossein, 2014, Glob J Health Sci, V7, P194, DOI 10.5539/gjhs.v7n1p194
   Ko S, 2014, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2014.7042484
   Li J, 2008, HEALTH CARE MANAG SC, V11, P275, DOI 10.1007/s10729-007-9045-4
   Li ZM, 2012, DATA MIN KNOWL DISC, V25, P577, DOI 10.1007/s10618-012-0255-0
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Maças C, 2022, INFORM VISUAL, V21, P371, DOI 10.1177/14738716221098074
   Maças C, 2020, IEEE INT CONF INF VI, P336, DOI 10.1109/IV51561.2020.00062
   Molloy I, 2017, LECT NOTES COMPUT SC, V9603, P22, DOI 10.1007/978-3-662-54970-4_2
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Niu ZB, 2018, IEEE PAC VIS SYMP, P160, DOI 10.1109/PacificVis.2018.00028
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Silva P, 2021, IEEE INT CONF INF VI, P77, DOI 10.1109/IV53921.2021.00022
   Tao J, 2018, IEEE PAC VIS SYMP, P150, DOI 10.1109/PacificVis.2018.00027
   Wang DX, 2019, IEEE DATA MINING, P598, DOI 10.1109/ICDM.2019.00070
   Wang JY, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P310, DOI 10.1145/3308560.3316586
   Xu BB, 2021, AAAI CONF ARTIF INTE, V35, P4537
   Zgraggen E, 2017, IEEE T VIS COMPUT GR, V23, P1977, DOI 10.1109/TVCG.2016.2607714
   Zhao B, 2019, IEEE INT C BIOINFORM, P1118, DOI 10.1109/BIBM47256.2019.8983130
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhong QW, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P785, DOI 10.1145/3366423.3380159
NR 30
TC 1
Z9 1
U1 13
U2 47
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2849
EP 2861
DI 10.1109/TVCG.2023.3261910
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500002
PM 37030774
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Tu, YM
   Li, OL
   Wang, JP
   Shen, HW
   Powalko, P
   Tomescu-Dubrow, I
   Slomczynski, KM
   Blanas, S
   Jenkins, JC
AF Tu, Yamei
   Li, Olga
   Wang, Junpeng
   Shen, Han-Wei
   Powalko, Przemek
   Tomescu-Dubrow, Irina
   Slomczynski, Kazimierz M.
   Blanas, Spyros
   Jenkins, J. Craig
TI <i>SDR</i>Querier: A Visual Querying Framework for Cross-National Survey
   Data Recycling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data models; Biological system modeling; Rivers;
   Portals; Bit error rate; Sociology; Data harmonization; social science;
   survey data recycling; visual analytics; visual data query
ID VISUALIZATION; MULTIVARIATE; INTERFACE
AB Public opinion surveys constitute a widespread, powerful tool to study peoples' attitudes and behaviors from comparative perspectives. However, even global surveys can have limited geographic and temporal coverage, which can hinder the production of comprehensive knowledge. To expand the scope of comparison, social scientists turn to ex-post harmonization of variables from datasets that cover similar topics but in different populations and/or at different times. These harmonized datasets can be analyzed as a single source and accessed through various data portals. However, the Survey Data Recycling (SDR) research project has identified three challenges faced by social scientists when using data portals: the lack of capability to explore data in-depth or query data based on customized needs, the difficulty in efficiently identifying related data for studies, and the incapability to evaluate theoretical models using sliced data. To address these issues, the SDR research project has developed the SDRQuerier, which is applied to the harmonized SDR database. The SDRQuerier includes a BERT-based model that allows for customized data queries through research questions or keywords (Query-by-Question), a visual design that helps users determine the availability of harmonized data for a given research question (Query-by-Condition), and the ability to reveal the underlying relational patterns among substantive and methodological variables in the database (Query-by-Relation), aiding in the rigorous evaluation or improvement of regression models. Case studies with multiple social scientists have demonstrated the usefulness and effectiveness of the SDRQuerier in addressing daily challenges.
C1 [Tu, Yamei; Shen, Han-Wei; Blanas, Spyros; Jenkins, J. Craig] Ohio State Univ, Columbus, OH 43210 USA.
   [Li, Olga; Powalko, Przemek; Tomescu-Dubrow, Irina; Slomczynski, Kazimierz M.] Polish Acad Sci, PL-01224 Warsaw, Poland.
   [Wang, Junpeng] Visa Res, Palo Alto, CA 94306 USA.
C3 University System of Ohio; Ohio State University; Polish Academy of
   Sciences
RP Tu, YM (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM tu.253@osu.edu; olga.li@ifispan.edu.pl; junpeng.wang.nk@gmail.com;
   shen.94@osu.edu; ppowalko@ifispan.edu.pl; dubrow.4@osu.edu;
   slomczynski.1@osu.edu; blanas.2@osu.edu; jenkins.12@osu.edu
RI Shen, Han-wei/A-4710-2012; Tu, Yamei/KSL-7529-2024
OI Tu, Yamei/0000-0002-0722-837X; Tomescu-Dubrow,
   Irina/0000-0002-7941-522X; Shen, Han-Wei/0000-0002-1211-2320; Wang,
   Junpeng/0000-0002-1130-9914
FU NSF [1738502]; ICICLE project [OAC-2112606]
FX .Thiswork wassupported by the NSF projectunder Grant
   1738502,RIDIR:Survey Data Recycling: New Analytic Framework, Integrated
   Database, andTools for Cross-national Social, Behavioral and Economic
   Research. The workwas also partically supported by ICICLE project under
   Grant OAC-2112606.
CR Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Carlis J. V., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P29, DOI 10.1145/288392.288399
   Dasgupta A, 2015, COMPUT GRAPH FORUM, V34, P341, DOI 10.1111/cgf.12646
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dibia V, 2020, Arxiv, DOI arXiv:2007.15211
   Fails JA, 2006, IEEE CONF VIS ANAL, P167
   Frick J. R., CROSS NATL EQUIVALEN
   Granda P., 2010, Survey Methods in Multinational, Multiregional, and Multicultural Contexts, P315, DOI [DOI 10.1002/9780470609927.CH17, 10.1002/9780470609927.ch17]
   Harris Robert L, 1999, INFORM GRAPHICS COMP
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Healy K, 2014, ANNU REV SOCIOL, V40, P105, DOI 10.1146/annurev-soc-071312-145551
   Hewagamage K. P., 1999, Proceedings 1999 IEEE Symposium on Visual Languages, P296, DOI 10.1109/VL.1999.795916
   Jiang ZL, 2020, Arxiv, DOI arXiv:2004.13005
   Jones AS, 2016, ENVIRON MODELL SOFTW, V84, P412, DOI 10.1016/j.envsoft.2016.07.013
   Kolczynska M., 2019, Advances in Comparative Survey Methodology, P1011
   Kolczynska M, 2020, METHODS DATA ANAL, V14, P91, DOI 10.12758/mda.2019.07
   Liu SX, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089101
   Luo DN, 2012, IEEE T VIS COMPUT GR, V18, P93, DOI 10.1109/TVCG.2010.225
   MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nogueira R, 2020, Arxiv, DOI arXiv:1901.04085
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Ruggles S, 2003, HIST METHOD, V36, P60, DOI 10.1080/01615440309601215
   Ryssevik J, 2001, SOC SCI COMPUT REV, V19, P163, DOI 10.1177/089443930101900203
   Singleton R.A., 2009, Approaches to social research
   Slomczynski KM, 2022, AM BEHAV SCI, V66, P412, DOI 10.1177/00027642211021623
   Tomescu-Dubrow I., 2016, DEMOCRATIC VALUES PR
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinh NX, 2010, J MACH LEARN RES, V11, P2837
   Wang FY, 2015, IEEE PAC VIS SYMP, P129, DOI 10.1109/PACIFICVIS.2015.7156368
   Weber M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P7, DOI 10.1109/infvis.2001.963273
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wysmulek I., 2018, Advances in comparative survey methods, P985, DOI DOI 10.1002/9781118884997.CH45
   Yang W, 2019, Arxiv, DOI arXiv:1902.01718
   Yang W, 2019, Arxiv, DOI arXiv:1903.10972
   Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P19
NR 36
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2862
EP 2874
DI 10.1109/TVCG.2023.3261944
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500003
PM 37030779
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wallinger, M
   Dobler, A
   Nöllenburg, M
AF Wallinger, Markus
   Dobler, Alexander
   Noellenburg, Martin
TI LinSets.zip: Compressing Linear Set Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Data visualization; Image color analysis;
   Heuristic algorithms; Taxonomy; Sparse matrices; Computational
   experiment; linear diagrams; set visualization; user evaluation
ID VISUALIZATION
AB Linear diagrams are used to visualize set systems by depicting set memberships as horizontal line segments in a matrix, where each set is represented as a row and each element as a column. Each such line segment of a set is shown in a contiguous horizontal range of cells of the matrix indicating that the corresponding elements in the columns belong to the set. As each set occupies its own row in the matrix, the total height of the resulting visualization is as large as the number of sets in the instance. Such a linear diagram can be visually sparse and intersecting sets containing the same element might be represented by distant rows. To alleviate such undesirable effects, we present LinSets.zip, a new approach that achieves a more space-efficient representation of linear diagrams. First, we minimize the total number of gaps in the horizontal segments by reordering columns, a criterion that has been shown to increase readability in linear diagrams. The main difference of LinSets.zip to linear diagrams is that multiple non-intersecting sets can be positioned in the same row of the matrix. Furthermore, we present several different rendering variations for a matrix-based representation that utilize the proposed row compression. We implemented the different steps of our approach in a visualization pipeline using integer-linear programming, and suitable heuristics aiming at sufficiently fast computations in practice. We conducted both a quantitative evaluation and a small-scale user experiment to compare the effects of compressing linear diagrams.
C1 [Wallinger, Markus; Dobler, Alexander; Noellenburg, Martin] TU Wien, Algorithms & Complex Grp, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Wallinger, M (corresponding author), TU Wien, Algorithms & Complex Grp, A-1040 Vienna, Austria.
EM mwallinger@ac.tuwien.ac.at; adobler@ac.tuwien.ac.at;
   noellenburg@ac.tuwien.ac.at
OI Wallinger, Markus/0000-0002-2191-4413; Nollenburg,
   Martin/0000-0003-0454-3937; Dobler, Alexander/0000-0002-0712-9726
FU Vienna Science and Technology Fund (WWTF)
FX This work was funded in part by the Vienna Science and Technology Fund
   (WWTF) under Grant 10.47379/ICT19035. Recommended for acceptanceby J.
   Choo, T. Ropinski, and Y. Hu.
CR Alqadah M, 2016, LECT NOTES COMPUT SC, V9781, P250, DOI 10.1007/978-3-319-42333-3_20
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Baimagambetov A, 2018, LECT NOTES ARTIF INT, V10871, P39, DOI 10.1007/978-3-319-91376-6_8
   BOPPANA R, 1992, BIT, V32, P180, DOI 10.1007/BF01994876
   BRELAZ D, 1979, COMMUN ACM, V22, P251, DOI 10.1145/359094.359101
   Chapman P., 2021, TALK ABSTR DIAGRAMS, P1
   Chapman P, 2022, J COMPUT LANG, V71, DOI 10.1016/j.cola.2022.101136
   Chapman P, 2021, LECT NOTES ARTIF INT, V12909, P449, DOI 10.1007/978-3-030-86062-2_47
   Chapman P, 2014, LECT NOTES COMPUT SC, V8578, P146, DOI 10.1007/978-3-662-44043-8_18
   Christofides N, 1976, WORST CASE ANAL NEW
   Dobler A, 2022, LECT NOTES ARTIF INT, V13462, P20, DOI 10.1007/978-3-031-15146-0_2
   GALIL Z, 1986, COMPUT SURV, V18, P23, DOI 10.1145/6462.6502
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Gottfried B, 2015, J SPAT INT SCI, P3, DOI 10.5311/JOSIS.2015.10.187
   Haddadi S, 2008, INFORM PROCESS LETT, V108, P132, DOI 10.1016/j.ipl.2008.04.009
   Hu YF, 2011, LECT NOTES COMPUT SC, V6502, P274, DOI 10.1007/978-3-642-18469-7_25
   Jacobsen B, 2021, IEEE T VIS COMPUT GR, V27, P1257, DOI 10.1109/TVCG.2020.3030475
   Kehlbeck R, 2022, IEEE T VIS COMPUT GR, V28, P433, DOI 10.1109/TVCG.2021.3114834
   Kou L. T., 1977, SIAM Journal on Computing, V6, P67, DOI 10.1137/0206004
   Lamy JB, 2020, IEEE T VIS COMPUT GR, V26, P3285, DOI 10.1109/TVCG.2019.2921544
   Lamy JB, 2017, J VISUAL LANG COMPUT, V43, P71, DOI 10.1016/j.jvlc.2017.09.003
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Luz S, 2019, INFORM VISUAL, V18, P297, DOI 10.1177/1473871618754343
   Malaguti E, 2010, INT T OPER RES, V17, P1, DOI 10.1111/j.1475-3995.2009.00696.x
   Matkovic K., 2020, PROC EUROVIS WORKSHO, P13, DOI [10.2312/eurova.20201080, DOI 10.2312/EUROVA.20201080]
   Nguyen PH, 2016, INFORM VISUAL, V15, P253, DOI 10.1177/1473871615605347
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Rodgers P, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2810012
   Rodgers P, 2012, IEEE T VIS COMPUT GR, V18, P1089, DOI 10.1109/TVCG.2011.143
   Rottmann Peter, 2023, IEEE Trans Vis Comput Graph, V29, P875, DOI 10.1109/TVCG.2022.3209485
   Sato Yuri, 2012, Diagrammatic Representation and Inference. Proceedings 7th International Conference, Diagrams 2012, P352, DOI 10.1007/978-3-642-31223-6_49
   Simonetto P, 2009, COMPUT GRAPH FORUM, V28, P967, DOI 10.1111/j.1467-8659.2009.01452.x
NR 33
TC 1
Z9 1
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2875
EP 2887
DI 10.1109/TVCG.2023.3261934
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500004
PM 37030775
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, YR
   Wang, JP
   Dai, X
   Wang, L
   Yeh, CCM
   Zheng, Y
   Zhang, W
   Ma, KL
AF Li, Yiran
   Wang, Junpeng
   Dai, Xin
   Wang, Liang
   Yeh, Chin-Chia Michael
   Zheng, Yan
   Zhang, Wei
   Ma, Kwan-Liu
TI How Does Attention Work in Vision Transformers? A Visual Analytics
   Attempt
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Head; Transformers; Visual analytics; Task analysis; Measurement;
   Heating systems; Deep learning; explainable artificial intelligence;
   multi-head self-attention; vision transformer; visual analytics
AB Vision transformer (ViT) expands the success of transformer models from sequential data to images. The model decomposes an image into many smaller patches and arranges them into a sequence. Multi-head self-attentions are then applied to the sequence to learn the attention between patches. Despite many successful interpretations of transformers on sequential data, little effort has been devoted to the interpretation of ViTs, and many questions remain unanswered. For example, among the numerous attention heads, which one is more important? How strong are individual patches attending to their spatial neighbors in different heads? What attention patterns have individual heads learned? In this work, we answer these questions through a visual analytics approach. Specifically, we first identify what heads are more important in ViTs by introducing multiple pruning-based metrics. Then, we profile the spatial distribution of attention strengths between patches inside individual heads, as well as the trend of attention strengths across attention layers. Third, using an autoencoder-based learning solution, we summarize all possible attention patterns that individual heads could learn. Examining the attention strengths and patterns of the important heads, we answer why they are important. Through concrete case studies with experienced deep learning experts on multiple ViTs, we validate the effectiveness of our solution that deepens the understanding of ViTs from head importance, head attention strength, and head attention pattern.
C1 [Li, Yiran; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Wang, Junpeng; Dai, Xin; Wang, Liang; Yeh, Chin-Chia Michael; Zheng, Yan; Zhang, Wei] Visa Res, Palo Alto, CA 94301 USA.
C3 University of California System; University of California Davis
RP Li, YR (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM ranli@ucdavis.edu; junpenwa@visa.com; xidai@visa.com; liawang@visa.com;
   miyeh@visa.com; yazheng@visa.com; wzhan@visa.com; klma@ucdavis.edu
RI Yeh, Michael/J-1738-2019; Zheng, Yanlong/ADS-5844-2022
OI Wang, Junpeng/0000-0002-1130-9914
FU National Institute of Health [1R01CA270454-01, 1R01CA273058-01]
FX This work was supported in part by the National Institute of Health
   under Grants 1R01CA270454-01 and 1R01CA273058-01.
CR Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190
   Aflalo E., 2022, PROC IEEECVF C COMPU, p21 406
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bau A., 2019, ICLR
   Cao J., 2020, EUROPEAN C COMPUTER, P565
   Cheonbok Park, 2019, 2019 IEEE Visualization Conference (VIS), P146, DOI 10.1109/VISUAL.2019.8933677
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong ZH, 2020, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis48177.2020.1031
   Dosovitskiy A., 2021, ICLR
   Hao Y., 2021, PROC AAAI C ARTIF IN, p12 963
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Jin Seungmin, 2023, IEEE Trans Vis Comput Graph, V29, P1102, DOI 10.1109/TVCG.2022.3209462
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Li R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P220
   Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Michel P, 2019, ADV NEUR IN, V32
   Raghu M, 2021, ADV NEUR IN, V34
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
NR 31
TC 7
Z9 7
U1 2
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2888
EP 2900
DI 10.1109/TVCG.2023.3261935
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500005
PM 37027263
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

EF