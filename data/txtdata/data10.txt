FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Chen, W
   Wei, YT
   Wang, ZY
   Zhou, SY
   Lin, BR
   Zhou, ZG
AF Chen, Wei
   Wei, Yating
   Wang, Zhiyong
   Zhou, Shuyue
   Lin, Bingru
   Zhou, Zhiguang
TI Federated Visualization: A Privacy-Preserving Strategy for Aggregated
   Visual Query
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Data privacy; Privacy; Data models;
   Federated learning; Servers; Decentralized visualization; federated
   visualization; privacy-preserving visualization
ID MODEL
AB We present a novel privacy preservation strategy for aggregated visual query of decentralized data. The key idea is to imitate the flowchart of the federated learning framework, and reformulate the visualization process within a federated infrastructure. The federation of visualization is fulfilled by leveraging a shared global module that composes the encrypted externalizations of transformed visual features of data pieces in local modules. We design two implementations of federated visualization: a prediction-based scheme, and a query-based scheme. We demonstrate the effectiveness of our approach with a set of visual forms, and verify its robustness with evaluations. We report the value of federated visualization in real scenarios with an expert review.
C1 [Chen, Wei; Wei, Yating] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Wei, Yating] Zhejiang Met & Mat Co, Hangzhou 310003, Zhejiang, Peoples R China.
   [Wang, Zhiyong] Tencent, Guangzhou 510630, Peoples R China.
   [Zhou, Shuyue; Lin, Bingru] Alibaba Grp, Hangzhou 310058, Zhejiang, Peoples R China.
   [Zhou, Zhiguang] Hangzhou Dianzi Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang University; Tencent; Alibaba Group; Hangzhou Dianzi University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM chenvis@zju.edu.cn; weiyating@zju.edu.cn; zerowangzy@zju.edu.cn;
   tangmao.zsy@alibaba-inc.com; bingru.lbr@alibaba-inc.com;
   zhgzhou1983@163.com
RI Chen, Wei/AAR-9817-2020
OI Chen, Wei/0000-0002-8365-4741
FU National Natural Science Foundation of China [62132017, 62277013];
   Fundamental Research Funds for the Central Universities [226-2022-00235]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62132017 and 62277013, and in part by
   the Fundamental Research Funds for the Central Universities under Grant
   226-2022-00235.
CR Agrawal R., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P143
   Arleo A, 2017, SYMP LARG DATA ANAL, P74, DOI 10.1109/LDAV.2017.8231853
   Bonawitz K., 2016, ARXIV
   Brodlie KW, 2004, COMPUT GRAPH FORUM, V23, P223, DOI 10.1111/j.1467-8659.2004.00754.x
   Cao J, 2012, PROC VLDB ENDOW, V5, P1388, DOI 10.14778/2350229.2350255
   Chen W, 2022, Arxiv, DOI arXiv:2007.15227
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Chou J. -K., 2016, SA 2016 SIGGRAPH ASI, P1, DOI [DOI 10.1145/3002151.3002153, 10.1145/3002151.3002153]
   Chou JK, 2019, COMPUT GRAPH FORUM, V38, P340, DOI 10.1111/cgf.13535
   Dasgupta A., 2014, P IEEE VIS WORKSH VI
   Dasgupta A, 2019, IEEE SYM VIS CYB SEC, DOI 10.1109/vizsec48167.2019.9161608
   Dasgupta A, 2011, IEEE T VIS COMPUT GR, V17, P2241, DOI 10.1109/TVCG.2011.163
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Huang L, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230706
   Huang L, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103291
   Kang JW, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2022), P71, DOI 10.1109/Blockchain55522.2022.00020
   Klein Tassilo, 2017, arXiv
   Konecny J., 2016, PROC NIPS WORKSHOP P
   Konečny J, 2016, Arxiv, DOI [arXiv:1610.02527, 10.48550/arXiv.1610.02527]
   Lefebvre S, 2006, ACM T GRAPHIC, V25, P579, DOI 10.1145/1141911.1141926
   Li NH, 2007, PROC INT CONF DATA, P81
   Li T, 2020, IEEE SIGNAL PROC MAG, V37, P50, DOI 10.1109/MSP.2020.2975749
   Liu Y, 2020, AAAI CONF ARTIF INTE, V34, P13172
   Lu MY, 2022, MED IMAGE ANAL, V76, DOI 10.1016/j.media.2021.102298
   Machanavajjhala A., 2007, ACM T KNOWL DISCOV D, V1, P3, DOI [10.1145/1217299.1217302, DOI 10.1145/1217299.1217302]
   McMahan H, 2018, PROC INT C LEARN REP
   Mei HH, 2020, IEEE T VIS COMPUT GR, V26, P1161, DOI 10.1109/TVCG.2019.2934800
   Meidiana A, 2019, SYMP LARG DATA ANAL, P73, DOI [10.1109/LDAV48142.2019.8944358, 10.1109/ldav48142.2019.8944358]
   Moayyed H, 2022, ENERG CONVERS MANAGE, V267, DOI 10.1016/j.enconman.2022.115852
   Oksanen J, 2015, J TRANSP GEOGR, V48, P135, DOI 10.1016/j.jtrangeo.2015.09.001
   Pei JM, 2022, COMPUT NETW, V209, DOI 10.1016/j.comnet.2022.108906
   Plis SM, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00365
   Polap D, 2022, NEURAL NETWORKS, V146, P130, DOI 10.1016/j.neunet.2021.11.018
   Ramsundar B., 2018, TENSORFLOW DEEP LEAR
   Saha DK, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2672
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Soria-Comas J, 2013, ANN CONF PRIV SECUR, P27, DOI 10.1109/PST.2013.6596033
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Wang XM, 2016, J COMPUT SCI TECH-CH, V31, P787, DOI 10.1007/s11390-016-1663-1
   Wang Xumeng, 2023, IEEE Trans Vis Comput Graph, V29, P310, DOI 10.1109/TVCG.2022.3209347
   Wang XM, 2019, IEEE T INTELL TRANSP, V20, P3375, DOI 10.1109/TITS.2018.2875021
   Wang XM, 2019, IEEE T VIS COMPUT GR, V25, P193, DOI 10.1109/TVCG.2018.2865021
   Wang XM, 2018, IEEE T VIS COMPUT GR, V24, P351, DOI 10.1109/TVCG.2017.2745139
   Wei XG, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6572
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Xie JR, 2014, SYMP LARG DATA ANAL, P3, DOI 10.1109/LDAV.2014.7013198
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Zhao Y, 2022, Arxiv, DOI arXiv:1806.00582
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
NR 49
TC 0
Z9 0
U1 0
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2901
EP 2913
DI 10.1109/TVCG.2023.3261938
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500006
PM 37030803
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Rodriguez-Pardo, C
   Garces, E
AF Rodriguez-Pardo, Carlos
   Garces, Elena
TI SeamlessGAN: Self-Supervised Synthesis of Tileable Texture Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Crops; Training; Semantics; Generative adversarial
   networks; Estimation; Virtual environments; Artificial intelligence;
   artificial neural network; machine vision; image texture; graphics;
   computational photography
ID IMAGE; MODEL
AB Real-time graphics applications require high-quality textured materials to convey realism in virtual environments. Generating these textures is challenging as they need to be visually realistic, seamlessly tileable, and have a small impact on the memory consumption of the application. For this reason, they are often created manually by skilled artists. In this work, we present SeamlessGAN, a method capable of automatically generating tileable texture maps from a single input exemplar. In contrast to most existing methods, focused solely on solving the synthesis problem, our work tackles both problems, synthesis and tileability, simultaneously. Our key idea is to realize that tiling a latent space within a generative network trained using adversarial expansion techniques produces outputs with continuity at the seam intersection that can then be turned into tileable images by cropping the central area. Since not every value of the latent space is valid to produce high-quality outputs, we leverage the discriminator as a perceptual error metric capable of identifying artifact-free textures during a sampling process. Further, in contrast to previous work on deep texture synthesis, our model is designed and optimized to work with multi-layered texture representations, enabling textures composed of multiple maps such as albedo, normals, etc. We extensively test our design choices for the network architecture, loss function, and sampling parameters. We show qualitatively and quantitatively that our approach outperforms previous methods and works for textures of different types.
C1 [Rodriguez-Pardo, Carlos; Garces, Elena] SEDDI, Madrid, Spain.
   [Rodriguez-Pardo, Carlos] Univ Carlos III Madrid, Madrid 28005, Spain.
   [Garces, Elena] Univ Rey Juan Carlos, Madrid 28933, Spain.
C3 Universidad Carlos III de Madrid; Universidad Rey Juan Carlos
RP Rodriguez-Pardo, C (corresponding author), SEDDI, Madrid, Spain.
EM carlos.rodriguezpardo.jimenez@gmail.com; elena.garces@seddi.com
RI Rodriguez - Pardo, Carlos/IWM-4608-2023
OI Rodriguez - Pardo, Carlos/0000-0001-6121-7738; Garces,
   Elena/0000-0003-3509-8485
FU Torres Quevedo Fellowship [PTQ2018-009868]
FX This work of Elena Garces was supported in part by Torres Quevedo
   Fellowship under Grant PTQ2018-009868
CR Akl A, 2018, COMPUT VIS IMAGE UND, V172, P12, DOI 10.1016/j.cviu.2018.04.001
   Almahairi A, 2018, PR MACH LEARN RES, V80
   Asano Y., 2019, PROC INT C LEARN REP
   Barnes C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766934
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Benaim S, 2021, COMPUT GRAPH FORUM, V40, P249, DOI 10.1111/cgf.14186
   Bergmann U., 2017, Proceedings of machine learning research, P469
   Burley B., 2012, ACM SIGGRAPH, P1
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   De Benet J. S., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P361, DOI 10.1145/258734.258882
   Dekel T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818113
   Deliot T., 2019, GPU Zen, V2
   Deschaintre V, 2020, COMPUT GRAPH FORUM, V39, P91, DOI 10.1111/cgf.14056
   Deschaintre V, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13765
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dosovitskiy Alexey, 2016, Advances in neural information processing systems, V29
   Dupont E, 2022, Arxiv, DOI [arXiv:2102.04776, 10.1016/j.lwt.2022.113600]
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fruhstuck A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322993
   Galerne B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185569
   Gatys LA, 2015, ADV NEUR IN, V28
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gilet G, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661249
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guehl P, 2020, COMPUT GRAPH FORUM, V39, P159, DOI 10.1111/cgf.14061
   Guingo G, 2017, COMPUT GRAPH FORUM, V36, P111, DOI 10.1111/cgf.13229
   Guo Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417779
   Ha D., 2017, INT C LEARN REPR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   Heitz E, 2021, PROC CVPR IEEE, P9407, DOI 10.1109/CVPR46437.2021.00929
   Heitz E, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233304
   Hensel M, 2017, ADV NEUR IN, V30
   Henzler P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480507
   Hertz A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392471
   Hinz T, 2021, IEEE WINT CONF APPL, P1299, DOI 10.1109/WACV48630.2021.00134
   Hu Y., 2019, ACM Trans. Graph., V38, P1
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Hudson D. A., 2021, Generative adversarial transformers
   IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Janner M, 2017, ADV NEUR IN, V30
   Jetchev N, 2017, Arxiv, DOI arXiv:1611.08207
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2018, INT C LEARNING REPRE, P1
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kaspar A, 2015, COMPUT GRAPH FORUM, V34, P349, DOI 10.1111/cgf.12565
   Kingma DP., 2015, P 3 INT C LEARN REPR
   Kurach K, 2019, PR MACH LEARN RES, V97
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li XY, 2019, PROC CVPR IEEE, P4850, DOI 10.1109/CVPR.2019.00499
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Li ZQ, 2018, LECT NOTES COMPUT SC, V11207, P74, DOI 10.1007/978-3-030-01219-9_5
   Liu GL, 2020, Arxiv, DOI arXiv:2007.07243
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Maas A.L., 2013, P 30 INT C MACH LEAR, P28
   Marcel Sebastien, 2010, P 18 ACM INT C MULT, P1485, DOI [DOI 10.1145/1873951.1874254, 10.1145/1873951.1874254]
   Mardani M., 2020, P ADV NEUR INF PROC
   Mellor J, 2021, PR MACH LEARN RES, V139
   Micikevicius P., 2018, PROC INT C LEARN REP
   Mordvintsev A., 2020, Distill, V5, pe23, DOI [10.23915/distill.00023, DOI 10.23915/DISTILL.00023]
   Moritz J, 2017, COMPUT GRAPH FORUM, V36, P177, DOI 10.1111/cgf.13117
   Nam H, 2018, ADV NEUR IN, V31
   Niklasson E., 2021, Distill
   Paszke A, 2019, ADV NEUR IN, V32
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Raad L, 2018, ANN MATH SCI APPL, V3, P89
   Ren J, 2017, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2017.76
   Rodriguez-Pardo Carlos, 2019, Pattern Recognition and Image Analysis. 9th Iberian Conference, IbPRIA 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11867), P508, DOI 10.1007/978-3-030-31332-6_44
   Rodriguez-Pardo C, 2019, COMPUT GRAPH-UK, V83, P33, DOI 10.1016/j.cag.2019.06.010
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönfeld E, 2020, PROC CVPR IEEE, P8204, DOI 10.1109/CVPR42600.2020.00823
   Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467
   Shi L, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417781
   Shocher A, 2019, IEEE I CONF COMP VIS, P4491, DOI 10.1109/ICCV.2019.00459
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Sinha A., 2020, INT C LEARN REPRESEN
   Sitzmann V., 2020, PROC ADV NEURAL INFO
   Snelgrove X, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149449
   Sushko V, 2021, IEEE COMPUT SOC CONF, P2596, DOI 10.1109/CVPRW53098.2021.00293
   Tancik M., 2020, Advances in Neural Information Processing Systems, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tu PH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417780
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Vinker Y, 2020, Arxiv, DOI arXiv:2004.06014
   Wang JY, 2020, PROC CVPR IEEE, P11502, DOI 10.1109/CVPR42600.2020.01152
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiming Dong, 2007, Proceedings Graphics Interface 2007, P249, DOI 10.1145/1268517.1268558
   Yu Y, 2019, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2019.00327
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201285
   Zhou Y, 2017, COMPUT GRAPH FORUM, V36, P199, DOI 10.1111/cgf.13119
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 104
TC 6
Z9 6
U1 3
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2914
EP 2925
DI 10.1109/TVCG.2022.3143615
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500007
PM 35041604
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, G
   Dai, H
   Zhou, T
   Shen, JB
   Shao, L
AF Chen, Geng
   Dai, Hang
   Zhou, Tao
   Shen, Jianbing
   Shao, Ling
TI Automatic Schelling Point Detection From Meshes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Deep learning; Heating systems; Feature
   extraction; Shape; Point cloud compression; Image edge detection; Deep
   neural network; mesh schelling points; geometric deep learning; heat map
   regression
ID SALIENCY; PARAMETERIZATION
AB Mesh Schelling points explain how humans focus on specific regions of a 3D object. They have a large number of important applications in computer graphics and provide valuable information for perceptual psychology studies. However, detecting mesh Schelling points is time-consuming and expensive since the existing techniques are mostly based on participant observation studies. To overcome these limitations, we propose to employ powerful deep learning techniques to detect mesh Schelling points in an automatic manner, free from participant observation studies. Specifically, we utilize the mesh convolution and pooling operations to extract informative features from mesh objects, and then predict the 3D heat map of Schelling points in an end-to-end manner. In addition, we propose a Deep Schelling Network (DS-Net) to automatically detect the Schelling points, including a multi-scale fusion component and a novel region-specific loss function to improve our network for a better regression of heat maps. To the best of our knowledge, DS-Net is the first deep neural network for detecting Schelling points from 3D meshes. We evaluate DS-Net on a mesh Schelling point dataset obtained from participant observation studies. The experimental results demonstrate that DS-Net is capable of detecting mesh Schelling points effectively and outperforms various state-of-the-art mesh saliency methods and deep learning models, both qualitatively and quantitatively.
C1 [Chen, Geng] Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710060, Peoples R China.
   [Dai, Hang] Mohamed bin Zayed Univ Artificial Intelligence, Abu Dhabi, U Arab Emirates.
   [Zhou, Tao] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
   [Shen, Jianbing] Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China.
   [Shao, Ling] Saudi Data & AI Author, Natl Ctr Artificial Intelligence, Riyadh, Saudi Arabia.
C3 Northwestern Polytechnical University; Mohamed Bin Zayed University of
   Artificial Intelligence; Nanjing University of Science & Technology;
   University of Macau
RP Dai, H (corresponding author), Mohamed bin Zayed Univ Artificial Intelligence, Abu Dhabi, U Arab Emirates.; Shen, JB (corresponding author), Univ Macau, Dept Comp & Informat Sci, State Key Lab Internet Things Smart City, Macau, Peoples R China.
EM geng.chen.cs@gmail.com; hang.dai@mbzuai.ac.ae; taozhou.ai@gmail.com;
   shenjianbingcg@gmail.com; ling.shao@ieee.org
RI Chen, Geng/KMA-8119-2024; Shao, Ling/D-3535-2011
OI Chen, Geng/0000-0001-8350-6581; Zhou, Tao/0000-0002-3733-7286
FU MBZUAI [GR006]; TII funding [TII//ARRC/2072//2021]; National Natural
   Science Foundation of China [62172228]
FX This work was supported in part by MBZUAI start-up funding under Grant
   GR006, in part by TII funding under Grant TII//ARRC/2072//2021, and
   inpart by the National Natural Science Foundation of China under Grant
   62172228.
CR Alexa M, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P202, DOI 10.1109/SMA.1999.749341
   Boscaini D, 2016, ADV NEUR IN, V29
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Chen XB, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185525
   Cignoni P., 2008, 6 EUR IT CHAPT C 200, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALCHAPCONF/129-138, 10.2312/LocalChapterEvents/ItalChap, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/ 129-136, DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136]
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fey M, 2019, Arxiv, DOI arXiv:1903.02428
   Gal R, 2006, ACM T GRAPHIC, V25, P130, DOI 10.1145/1122501.1122507
   Gelfand Natasha, 2005, ACM International Conference Proceeding Series, V255, P197
   Georgakis G, 2018, PROC CVPR IEEE, P1965, DOI 10.1109/CVPR.2018.00210
   Glorot X., 2011, JMLR WORKSHOP C P, P315, DOI DOI 10.1002/ECS2.1832
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde V., 2016, Fusionnet: 3d object classification using multiple data representations
   Hu SF, 2020, IEEE T MULTIMEDIA, V22, P2278, DOI 10.1109/TMM.2019.2952983
   Huang C, 2019, LECT NOTES COMPUT SC, V11765, P291, DOI 10.1007/978-3-030-32245-8_33
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jia Yangqing, 2014, Learning Semantic Image Representations at a Large Scale
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Johnson AE, 2000, PROC CVPR IEEE, P413, DOI 10.1109/CVPR.2000.854868
   Kingma DP, 2014, ADV NEUR IN, V27
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Kraevoy V, 2004, ACM T GRAPHIC, V23, P861, DOI 10.1145/1015706.1015811
   Lau M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925927
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Leifman G, 2016, IEEE T PATTERN ANAL, V38, P2544, DOI 10.1109/TPAMI.2016.2522437
   Leng B, 2015, SIGNAL PROCESS, V112, P119, DOI 10.1016/j.sigpro.2014.09.005
   Li XZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3366785
   Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378
   Liu WP, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194188
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ono Y., 2018, ADV NEURAL INFORM PR, P6237, DOI DOI 10.48550/ARXIV.1805.09662
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schelling T., 1960, The Strategy of Conflict
   Sedaghat N, 2017, Arxiv, DOI arXiv:1604.03351
   Shilane P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243981
   Shu ZY, 2019, IEEE T VIS COMPUT GR, V25, P2583, DOI 10.1109/TVCG.2018.2848628
   Song R, 2021, IEEE T VIS COMPUT GR, V27, P151, DOI 10.1109/TVCG.2019.2928794
   Song R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2530691
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Suwajanakorn S, 2018, ADV NEUR IN, V31
   Thomas H, 2019, Arxiv, DOI arXiv:1904.08889
   Tonioni A, 2018, INT J COMPUT VISION, V126, P1, DOI 10.1007/s11263-017-1037-3
   Torrey Lisa, 2010, HDB RES MACHINE LEAR, P242
   Wang SF, 2015, COMPUT AIDED GEOM D, V35-36, P206, DOI 10.1016/j.cagd.2015.03.003
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang X., 2018, ACM Trans.Graph., V37, P1
   Wang X, 2016, IEEE COMPUT GRAPH, V36, P46, DOI 10.1109/MCG.2016.47
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu JL, 2013, GRAPH MODELS, V75, P255, DOI 10.1016/j.gmod.2013.05.002
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZH, 2019, Arxiv, DOI arXiv:1901.00596
   Xie ZG, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12740
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618484
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhou J, 2021, Arxiv, DOI [arXiv:1812.08434, DOI 10.48550/ARXIV.1812.08434, 10.48550/arXiv.1812.08434]
   Zhou T, 2020, IEEE T MED IMAGING, V39, P2772, DOI 10.1109/TMI.2020.2975344
   Zhou YN, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P187
NR 81
TC 3
Z9 3
U1 2
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2926
EP 2939
DI 10.1109/TVCG.2022.3144143
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500008
PM 35044917
DA 2024-11-06
ER

PT J
AU Fan, JH
   Wang, BB
   Wu, WS
   Hasan, M
   Yang, J
   Yan, LQ
AF Fan, Jiahui
   Wang, Beibei
   Wu, Wenshi
   Hasan, Milos
   Yang, Jian
   Yan, Ling-Qi
TI Efficient Specular Glints Rendering With Differentiable Regularization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Surface roughness; Rough surfaces;
   Microstructure; Light sources; Real-time systems; Gaussian distribution;
   glints rendering; differentiable rendering
AB Rendering glinty details from specular microstructure enhances the level of realism in computer graphics. However, naive sampling fails to render such effects, due to insufficient sampling of the contributing normals on the surface patch visible through a pixel. Other approaches resort to searching for the relevant normals in more explicit ways, but they rely on special acceleration structures, leading to increased storage costs and complexity. In this article, we propose to render specular glints through a different method: differentiable regularization. Our method includes two steps: first, we use differentiable path tracing to render a scene with a larger light size and/or rougher surfaces and record the gradients with respect to light size and roughness. Next, we use the result for the larger light size and rougher surfaces, together with their gradients, to predict the target value for the required light size and roughness by extrapolation. In the end, we get significantly reduced noise compared to rendering the scene directly. Our results are close to the reference, which uses many more samples per pixel, although our method cannot guarantee unbiased convergence to the reference. The overhead for differentiable rendering and prediction is small, so our improvement is almost free. We demonstrate our differentiable regularization on several normal maps, all of which benefit from the method.
C1 [Fan, Jiahui; Wang, Beibei; Wu, Wenshi; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Hasan, Milos] Adobe Res, San Jose, CA 95110 USA.
   [Yan, Ling-Qi] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
C3 Nanjing University of Science & Technology; Adobe Systems Inc.;
   University of California System; University of California Santa Barbara
RP Wang, BB; Yang, J (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM fjh@njust.edu.cn; beibei.wang@njust.edu.cn; wws19990401@njust.edu.cn;
   milos.hasan@gmail.com; csjyang@njust.edu.cn; lingqi@cs.ucsb.edu
OI Fan, Jiahui/0000-0003-0871-7615
FU National Natural Science Foundation of China [62172220, 61802187];
   Fundamental Research Funds for the Central Universities [30920021133];
   China Postdoctoral Science Foundation [2020M671500]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62172220 and 61802187, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   30920021133, and in part by China Postdoctoral Science Foundation under
   Grant 2020M671500. Ling-Qi Yan is supported by gift funds from Adobe,
   Dimension 5 and XVerse.~
CR [Anonymous], 1987, The Scattering of Electromagnetic Waves from Rough Surfaces
   Bouchard G., 2013, PROC SIGGRAPH ASIA T, P1
   Chermain X, 2020, COMPUT GRAPH FORUM, V39, P243, DOI 10.1111/cgf.14141
   Chermain X., 2021, EUROGRAPHICS S RENDE
   Chermain X, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451257
   Jakob W, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601186
   Jakob Wenzel, 2010, Mitsuba Renderer
   Jendersie J, 2019, COMPUT GRAPH FORUM, V38, P39, DOI 10.1111/cgf.13768
   Kaplanyan AS, 2013, COMPUT GRAPH FORUM, V32, P63, DOI 10.1111/cgf.12026
   Kuznetsov A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356525
   Li TM, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275109
   Loubet G, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356510
   Nimier-David M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392406
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Raymond B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925945
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   Velinov Z, 2018, COMPUT GRAPH FORUM, V37, P123, DOI 10.1111/cgf.13347
   Walter B., 2007, RENDERING TECHNIQUES
   Wang B., 2020, T GRAPH, V39, P1
   Wang B., 2020, ACM T GRAPHIC, V39, P1
   Wang BB, 2020, COMPUT GRAPH FORUM, V39, P144, DOI 10.1111/cgf.14007
   Wang BB, 2018, COMPUT GRAPH FORUM, V37, P55, DOI 10.1111/cgf.13547
   Werner S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130840
   Yan LQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201351
   Yan LQ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925915
   Yan LQ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601155
   Zeltner T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392408
   Zhang C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392383
   Zhang C, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356522
   Zhao S., 2020, ACM SIGGRAPH 2020 CO, P1
   Zhu JQ, 2019, COMPUT GRAPH FORUM, V38, P745, DOI 10.1111/cgf.13876
   Zirr T, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P139, DOI 10.1145/2856400.2856409
NR 32
TC 1
Z9 1
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2940
EP 2949
DI 10.1109/TVCG.2022.3144479
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500009
PM 35061587
DA 2024-11-06
ER

PT J
AU Xiong, K
   Fu, SW
   Ding, GM
   Luo, ZS
   Yu, R
   Chen, W
   Bao, HJ
   Wu, YC
AF Xiong, Kai
   Fu, Siwei
   Ding, Guoming
   Luo, Zhongsu
   Yu, Rong
   Chen, Wei
   Bao, Hujun
   Wu, Yingcai
TI Visualizing the Scripts of Data Wrangling With Somnus
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Codes; Semantics; Visualization; Debugging; Python;
   Task analysis; Program understanding; data transformation; visualization
   design
ID FRAMEWORK; VISUALIZATIONS; TRANSFORMATION
AB Data workers use various scripting languages for data transformation, such as SAS, R, and Python. However, understanding intricate code pieces requires advanced programming skills, which hinders data workers from grasping the idea of data transformation at ease. Program visualization is beneficial for debugging and education and has the potential to illustrate transformations intuitively and interactively. In this article, we explore visualization design for demonstrating the semantics of code pieces in the context of data transformation. First, to depict individual data transformations, we structure a design space by two primary dimensions, i.e., key parameters to encode and possible visual channels to be mapped. Then, we derive a collection of 23 glyphs that visualize the semantics of transformations. Next, we design a pipeline, named Somnus, that provides an overview of the creation and evolution of data tables using a provenance graph. At the same time, it allows detailed investigation of individual transformations. User feedback on Somnus is positive. Our study participants achieved better accuracy with less time using Somnus, and preferred it over carefully-crafted textual description. Further, we provide two example applications to demonstrate the utility and versatility of Somnus.
C1 [Xiong, Kai; Ding, Guoming; Chen, Wei; Bao, Hujun; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Xiong, Kai; Fu, Siwei; Ding, Guoming; Luo, Zhongsu; Yu, Rong; Chen, Wei; Bao, Hujun; Wu, Yingcai] Zhejiang Lab, Hangzhou 311121, Peoples R China.
   [Luo, Zhongsu] Zhejiang Univ Technol, Hangzhou 310023, Peoples R China.
C3 Zhejiang University; Zhejiang Laboratory; Zhejiang University of
   Technology
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.; Fu, SW; Wu, YC (corresponding author), Zhejiang Lab, Hangzhou 311121, Peoples R China.
EM kaixiong@zju.edu.cn; fusiwei339@gmail.com; dinggm@zju.edu.cn;
   rickyluozs@gmail.com; 1721298964@qq.com; chenvis@zju.edu.cn;
   bao@cad.zju.edu.cn; ycwu@zju.edu.cn
RI Chen, Wei/AAR-9817-2020; wang, yixuan/JGM-3893-2023
OI Chen, Wei/0000-0002-8365-4741; Xiong, Kai/0000-0002-8203-9667; Bao,
   Hujun/0000-0002-2662-0334
FU NSFC [62072400, 62002331]; Collaborative Innovation Center of Artificial
   Intelligence by MOE; Zhejiang Provincial Government (ZJU); Zhejiang Lab
   [2021KE0AC02, 2020KE0AA02]
FX This work was supported in part by NSFC under Grants 62072400 and
   62002331, and in part by the Collaborative Innovation Center of
   Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).
   This work was supported in part by Zhejiang Lab under Grants 2021KE0AC02
   and 2020KE0AA02.
CR Abedjan Z, 2016, PROC INT CONF DATA, P1134, DOI 10.1109/ICDE.2016.7498319
   Aftandilian EE, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P53
   [Anonymous], 2009, P 14 INT C INT US IN
   [Anonymous], 2004, PROC 3 PROGRAM VISUA
   B. Figures, 2021, APPL IPH UN SAL REV
   B. S. D. Desk, 2020, BALT POL OV FISC YEA
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Baudisch P., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P259, DOI 10.1145/503376.503423
   Baudisch P., 2004, Proceedings of the UIST '04 Symposium on User Interface Software and Technology, P91
   Beck F., 2013, 2013 1 IEEE WORKING, P1
   Beck F, 2013, CONF PROC INT SYMP C, P63, DOI 10.1109/ICPC.2013.6613834
   beecycles, 2018, POW IRM
   Bigelow A, 2019, IEEE CONF VIS ANAL, P81, DOI [10.1109/vast47406.2019.8986909, 10.1109/VAST47406.2019.8986909]
   Bors C, 2019, IEEE COMPUT GRAPH, V39, P61, DOI 10.1109/MCG.2019.2941856
   Bostock M., 2014, VISUALIZING ALGORITH
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bryan Jennifer, 2024, CRAN
   Burg B., 2013, P 26 ANN ACM S US IN, P473, DOI DOI 10.1145/2501988.2502050
   Chotisarn N, 2020, J VISUAL-JAPAN, V23, P539, DOI 10.1007/s12650-020-00647-w
   code2flow, ONL INT COD FLOWCH C
   Demetrescu C, 2002, LECT NOTES COMPUT SC, V2269, P16
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   dplyr, R PACK DPLYR V0 7 8
   Drosos I, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20)
   eclipse, Eclipse layout kernel (elk)
   Faust Rebecca, 2019, arXiv
   Feng Y, 2017, ACM SIGPLAN NOTICES, V52, P422, DOI [10.1145/3062341.3062351, 10.1145/3140587.3062351]
   Fisher D., 2010, Beautiful Visualization - Looking at Data Through the Eyes of Experts, P329
   Grissom Scott, 2003, P 2003 ACM S SOFTW V, P87
   Guo P. J., 2011, P 24 ANN ACM S US IN, P65, DOI 10.1145/2047196.2047205
   Guo Philip J, 2013, P 44 ACM TECHN S COM, P579
   Hansen S, 2002, J VISUAL LANG COMPUT, V13, P291, DOI [10.1006/jvlc.2002.0236, 10.1006/S1045-926X(02)00027-7]
   Hanson D. R., 1997, PROC USENIX ANN TECH, P183
   Harward Matthew, 2010, Proceedings of the 21st Australian Software Engineering Conference (ASWEC 2010), P171, DOI 10.1109/ASWEC.2010.18
   Heer J, 2014, INFORM VISUAL, V13, P111, DOI 10.1177/1473871612462152
   Hoffswell J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174106
   Hoffswell J, 2016, COMPUT GRAPH FORUM, V35, P271, DOI 10.1111/cgf.12903
   Huynh D., 2021, OPENREFINE
   Inala J. P., 2017, PROC ACM PROGRAM LAN, V2, P1
   Jin ZJ, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P683, DOI 10.1145/3035918.3064034
   Junseok Cheon, 2019, International Conference on Data Engineering 2015 (DaEng-2015). Proceedings: Lecture Notes in Electrical Engineering (LNEE 520), P433, DOI 10.1007/978-981-13-1799-6_45
   Jupyter, 2021, JUP NOT
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Khan M, 2017, PROC VLDB ENDOW, V10, P661, DOI 10.14778/3055330.3055333
   Ko A. J., 2004, P SIGCHI C HUM FACT, P151, DOI DOI 10.1145/985692.985712
   Kosower DA, 2014, IEEE INT WORK C SO, P59, DOI 10.1109/SCAM.2014.35
   Kuechler William L, 2003, Journal of Information Systems Education, V14, P389
   Lewis C., 1987, Empirical Studies of Programmers:Ssecond Workshop, P248
   Lieber T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2481, DOI 10.1145/2556288.2557409
   Lieberman H, 1998, SOFTWARE VISUALIZATION, P277
   Do LNQ, 2018, PROC IEEE ACM INT C, P89, DOI 10.1145/3183440.3183470
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   Liu SX, 2018, VIS INFORM, V2, P191, DOI 10.1016/j.visinf.2018.12.001
   Morcos J, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P883, DOI 10.1145/2723372.2735366
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Niederer C, 2018, IEEE T VIS COMPUT GR, V24, P677, DOI 10.1109/TVCG.2017.2745298
   Oney S, 2009, S VIS LANG HUM CEN C, P105, DOI 10.1109/VLHCC.2009.5295287
   Oy A., 2013, VISUSTIN V7 FLOW CHA
   Pu XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445063
   Qian YZ, 2017, ACM T COMPUT EDUC, V18, DOI 10.1145/3077618
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Reback Jeff, 2022, Zenodo, DOI 10.5281/ZENODO.5893288
   Shaffer CA, 2011, SIGCSE 11: PROCEEDINGS OF THE 42ND ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P129
   Shaffer CA, 2007, SIGCSE 2007: PROCEEDINGS OF THE THIRTY-EIGHTH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P150, DOI 10.1145/1227504.1227366
   Shrestha N, 2020, PROC INT CONF SOFTW, P691, DOI 10.1145/3377811.3380352
   Simkin MG, 2005, DECIS SCI-J INNOV ED, V3, P73, DOI 10.1111/j.1540-4609.2005.00053.x
   Sorva J, 2013, ACM T COMPUT EDUC, V13, DOI 10.1145/2490822
   stackoverflow, 2015, REC ERR DPLYR MUT
   Sundararaman J, 2008, SOFTVIS 2008: PROCEEDINGS OF THE 4TH ACM SYMPOSIUM ON SOFTWARE VISUALIZATION, P47
   Swift B, 2013, 2013 1ST INTERNATIONAL WORKSHOP ON LIVE PROGRAMMING (LIVE), P27, DOI 10.1109/LIVE.2013.6617345
   T. Software, 2021, TABL PREP BUILD
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   tidyr, R PACK TIDYR V1 1 3
   Trifacta, 2021, TRIF WRANGL
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   WestWind Soft, AUTOFLOWCHART
   Wickham Hadley, 2023, CRAN
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Zeller A, 1996, ACM SIGPLAN NOTICES, V31, P22, DOI 10.1145/249094.249108
   Zhicheng Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P41, DOI 10.1109/VAST.2011.6102440
NR 82
TC 5
Z9 6
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2950
EP 2964
DI 10.1109/TVCG.2022.3144975
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500010
PM 35077364
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shi, M
   Zhang, JQ
   Chen, SY
   Gao, L
   Lai, YK
   Zhang, FL
AF Shi, Min
   Zhang, Jia-Qi
   Chen, Shu-Yu
   Gao, Lin
   Lai, Yu-Kun
   Zhang, Fang-Lue
TI Reference-Based Deep Line Art Video Colorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Art; Animation; Feature extraction;
   Three-dimensional displays; Transforms; Color; Line art colorization;
   color transform; temporal coherence; few shot learning
AB Coloring line art images based on the colors of reference images is a crucial stage in animation production, which is time-consuming and tedious. This paper proposes a deep architecture to automatically color line art videos with the same color style as the given reference images. Our framework consists of a color transform network and a temporal refinement network based on 3U-net. The color transform network takes the target line art images as well as the line art and color images of the reference images as input and generates corresponding target color images. To cope with the large differences between each target line art image and the reference color images, we propose a distance attention layer that utilizes non-local similarity matching to determine the region correspondences between the target image and the reference images and transforms the local color information from the references to the target. To ensure global color style consistency, we further incorporate Adaptive Instance Normalization (AdaIN) with the transformation parameters obtained from a multiple-layer AdaIN that describes the global color style of the references extracted by an embedder network. The temporal refinement network learns spatiotemporal features through 3D convolutions to ensure the temporal color consistency of the results. Our model can achieve even better coloring results by fine-tuning the parameters with only a small number of samples when dealing with an animation of a new style. To evaluate our method, we build a line art coloring dataset. Experiments show that our method achieves the best performance on line art video coloring compared to the current state-of-the-art methods.
C1 [Shi, Min] North China Elect Power Univ, Beijing 102206, Peoples R China.
   [Zhang, Jia-Qi] Beihang Univ, Beijing 100191, Peoples R China.
   [Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
   [Chen, Shu-Yu; Gao, Lin] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6012, New Zealand.
C3 North China Electric Power University; Beihang University; Chinese
   Academy of Sciences; Institute of Computing Technology, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Cardiff University; Victoria University Wellington
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100190, Peoples R China.
EM shi_min@ncepu.edu.cn; zhangjiaqi79@buaa.edu.cn; chenshuyu@ict.ac.cn;
   gaolin@ict.ac.cn; LaiY4@cardiff.ac.uk; fanglue.zhang@ecs.vuw.ac.nz
RI Lai, Yu-Kun/D-2343-2010; Gao, Lin/JNF-0375-2023
OI jiaqi, zhang/0000-0002-8482-3666; Lai, Yukun/0000-0002-2094-5680
FU National Natural Science Foundation of China [61972379, 62102403,
   61872440]; Science and Technology Service Network Initiative, Chinese
   Academy of Sciences [KFJ-STS-QYZD-2021-11-001]; Royal Society Newton
   Advanced Fellowship [NAF\R2\192151]; Royal Society [IES\R1\180126];
   Youth Innovation Promotion Association CAS; Marsden Fund Council
   [MFP-20-VUW-180]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61972379, 62102403, and 61872440, in
   part by the Science and Technology Service Network Initiative, Chinese
   Academy of Sciences under Grant KFJ-STS-QYZD-2021-11-001, in part by
   Royal Society Newton Advanced Fellowship under Grant NAF\R2\192151, in
   part by Royal Society under Grant IES\R1\180126, and in part by the
   Youth Innovation Promotion Association CAS and the Marsden Fund Council
   managed by Royal Society of New Zealand under Grant MFP-20-VUW-180.
CR [Anonymous], 2014, SA '14
   Bao WB, 2019, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2019.00382
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang YL, 2019, IEEE I CONF COMP VIS, P9065, DOI 10.1109/ICCV.2019.00916
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Ci YZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1536, DOI 10.1145/3240508.3240661
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Hensman P, 2017, PROC INT CONF DOC, P72, DOI 10.1109/ICDAR.2017.295
   HEUSEL M., 2017, P ANN C NEUR INF PRO, P6626
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iizuka S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356570
   Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336
   Jamriska O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323006
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kim H, 2019, IEEE I CONF COMP VIS, P9055, DOI 10.1109/ICCV.2019.00915
   Lee J, 2020, PROC CVPR IEEE, P5800, DOI 10.1109/CVPR42600.2020.00584
   Lei CY, 2019, PROC CVPR IEEE, P3748, DOI 10.1109/CVPR.2019.00387
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li CZ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073675
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   lllyasviel, 2018, Sketchkeras
   lllyasviel, 2018, STYLE2PAINTS
   Miyato T., 2018, The 6th Int. Conf. on Learning Representations (ICLR)
   Odena A, 2016, Deconvolution and checkerboard artifacts, V1, P3, DOI [10.23915/distill.00003, 10.23915/distill.00003.-URL, DOI 10.23915/DISTILL.00003]
   Orzan A, 2013, COMMUN ACM, V56, P101, DOI 10.1145/2483852.2483873
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Risser E, 2017, Arxiv, DOI arXiv:1701.08893
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siyao L., 2021, P IEEE C COMP VIS PA, P6587
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Sykora Daniel, 2004, P 3 INT S NONPH AN R, P121
   Thasarathan H, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P189, DOI 10.1109/CRV.2019.00033
   Varga D, 2017, PROCEEDINGS OF THE 15TH INTERNATIONAL WORKSHOP ON CONTENT-BASED MULTIMEDIA INDEXING (CBMI), DOI 10.1145/3095713.3095742
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Winnemoeller H, 2012, COMPUT GRAPH-UK, V36, P740, DOI 10.1016/j.cag.2012.03.004
   Yoo S, 2019, PROC CVPR IEEE, P11275, DOI 10.1109/CVPR.2019.01154
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang LM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275090
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhu HC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925872
NR 47
TC 10
Z9 13
U1 3
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2965
EP 2979
DI 10.1109/TVCG.2022.3146000
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500011
PM 35077365
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Shin, M
   Kim, J
   Han, Y
   Xie, LX
   Whitelaw, M
   Kwon, BC
   Ko, S
   Elmqvist, N
AF Shin, Minjeong
   Kim, Joohee
   Han, Yunha
   Xie, Lexing
   Whitelaw, Mitchell
   Kwon, Bum Chul
   Ko, Sungahn
   Elmqvist, Niklas
TI Roslingifier: Semi-Automated Storytelling for Animated Scatterplots
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Annotations; Visual effects;
   Streaming media; Organizations; Natural languages; Data-driven
   storytelling; narrative visualization; hans rosling; gapminder;
   trendalyzer
ID NARRATIVE VISUALIZATION; MEAN SHIFT; STORIES
AB We present Roslingifier, a data-driven storytelling method for animated scatterplots. Like its namesake, Hans Rosling (1948-2017), a professor of public health and a spellbinding public speaker, Roslingifier turns a sequence of entities changing over time-such as countries and continents with their demographic data-into an engaging narrative elling the story of the data. This data-driven storytelling method with an in-person presenter is a new genre of storytelling technique and has never been studied before. In this article, we aim to define a design space for this new genre-data presentation-and provide a semi-automated authoring tool for helping presenters create quality presentations. From an in-depth analysis of video clips of presentations using interactive visualizations, we derive three specific techniques to achieve this: natural language narratives, visual effects that highlight events, and temporal branching that changes playback time of the animation. Our implementation of the Roslingifier method is capable of identifying and clustering significant movements, automatically generating visual highlighting and a narrative for playback, and enabling the user to customize. From two user studies, we show that Roslingifier allows users to effectively create engaging data stories and the system features help both presenters and viewers find diverse insights.
C1 [Shin, Minjeong; Xie, Lexing; Whitelaw, Mitchell] Australian Natl Univ, Canberra, ACT 0200, Australia.
   [Kim, Joohee; Han, Yunha; Ko, Sungahn] Ulsan Natl Inst Sci & Technol, Ulsan 689798, South Korea.
   [Kwon, Bum Chul] IBM Res, Cambridge, MA 02142 USA.
   [Elmqvist, Niklas] Univ Maryland, Maryland, MD 20742 USA.
C3 Australian National University; Ulsan National Institute of Science &
   Technology (UNIST); International Business Machines (IBM)
RP Ko, S (corresponding author), Ulsan Natl Inst Sci & Technol, Ulsan 689798, South Korea.
EM minjeong.shin@anu.edu.au; jkim17@unist.ac.kr; diana438@unist.ac.kr;
   lexing.xie@anu.edu.au; mitchell.whitelaw@anu.edu.au;
   bumchul.kwon@us.ibm.com; sako@unist.ac.kr; elm@umd.edu
RI Shin, Minjeong/KHD-9828-2024
OI Kwon, Bum Chul/0000-0002-9391-6274; Shin, Minjeong/0000-0001-6516-0433;
   Ko, Sungahn/0000-0002-7410-5652; Xie, Lexing/0000-0001-8319-0118;
   Elmqvist, Niklas/0000-0001-5805-5301
FU Korean National Research Foundation (NRF) - Korea government (MSIT)
   [2021R1A2C1004542, 2020R1H1A110101311]; Korean Ministry of Science and
   ICT (MSIT) under the Information Technology Research Center support
   program - Korea government (MSIT) [IITP-2020-2017-0-01635]; Institute of
   Information & Communications Technology Planning & Evaluation (IITP) -
   Korea government (MSIT) [2020-0-01336]
FX This work was supported in part by the Korean National Research
   Foundation (NRF) under Grants 2021R1A2C1004542 and 2020R1H1A110101311,
   in part by the Korean Ministry of Science and ICT (MSIT) under the
   Information Technology Research Center support program under Grant
   IITP-2020-2017-0-01635 supervised by the Institute for Information &
   Communications Technology Promotion (IITP), and in part by the Institute
   of Information & Communications Technology Planning & Evaluation (IITP)
   under Grant 2020-0-01336, Artificial Intelligence Graduate School
   Program (UNIST), all funded by the Korea government (MSIT).
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   [Anonymous], 2016, Tech. rep. MSR-TR-2016-14
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bigelow A, 2017, IEEE T VIS COMPUT GR, V23, P481, DOI 10.1109/TVCG.2016.2598609
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Center for Systems Science and Engineering at Johns Hopkins University, 2019, NOV COR COVID 19 201
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chotisarn N, 2021, J VISUAL-JAPAN, V24, P101, DOI 10.1007/s12650-020-00690-7
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Corbin J.M., 2007, BASICS QUALITATIVE R
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Eccles R, 2007, IEEE S VIS ANAL, P19, DOI 10.1109/VAST.2007.4388992
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   G. Foundation, 2007, TREND
   Gao T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3005, DOI 10.1145/2556288.2557228
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Halloran Neil., 2015, The Fallen of World War II
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kim N. W., 2019, P ACM C HUM FACT COM, P1
   Kim NW, 2018, IEEE T VIS COMPUT GR, V24, P595, DOI 10.1109/TVCG.2017.2744118
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kolak K., DAY LIFE MISTER
   Kong N, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P233
   Kosara R, 2016, IEEE COMPUT GRAPH, V36, P80, DOI 10.1109/MCG.2016.2
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kwon B. C., 2014, P COMP JOURN S, P1
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376327
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   N. Science, 2020, QUILL
   Nielsen J., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P557, DOI 10.1145/142750.142986
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Rosling H., 2006, DEBUNKING MYTHS 3 WO
   Rosling H., 2018, Factfulness: ten reasons were wrong about the world and why things are better than you think
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Wattenberg M., 2001, P ACM C HUM FACT COM, P381
   Zhao Z., 2015, HCIL201515 U MAR
   Zhenpeng Zhao, 2019, Information in Contemporary Society. 14th International Conference, iConference 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11420), P327, DOI 10.1007/978-3-030-15742-5_32
NR 56
TC 5
Z9 5
U1 2
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2980
EP 2995
DI 10.1109/TVCG.2022.3146329
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500012
PM 35085082
DA 2024-11-06
ER

PT J
AU Collaris, D
   van Wijk, JJ
AF Collaris, Dennis
   van Wijk, Jarke J.
TI StrategyAtlas: Strategy Analysis for Machine Learning Interpretability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Analytical models; Machine learning; Predictive models;
   Computational modeling; Insurance; Data visualization; Visual analytics;
   machine learning; explainable AI
ID TOOL
AB Businesses in high-risk environments have been reluctant to adopt modern machine learning approaches due to their complex and uninterpretable nature. Most current solutions provide local, instance-level explanations, but this is insufficient for understanding the model as a whole. In this work, we show that strategy clusters (i.e., groups of data instances that are treated distinctly by the model) can be used to understand the global behavior of a complex ML model. To support effective exploration and understanding of these clusters, we introduce StrategyAtlas, a system designed to analyze and explain model strategies. Furthermore, it supports multiple ways to utilize these strategies for simplifying and improving the reference model. In collaboration with a large insurance company, we present a use case in automatic insurance acceptance, and show how professional data scientists were enabled to understand a complex model and improve the production model based on these insights.
C1 [Collaris, Dennis; van Wijk, Jarke J.] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Collaris, D (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
EM d.a.c.collaris@tue.nl; j.j.v.wijk@tue.nl
OI Collaris, Dennis/0000-0001-7612-9319; van Wijk,
   Jarke/0000-0002-5128-976X
FU research programme Commit2Data, RATE Analytics project - Dutch Research
   Council (NWO) [628.003.001]
FX This work was supported by the research programme Commit2Data,
   specifically the RATE Analytics project with Project No. 628.003.001,
   which is financed by the Dutch Research Council (NWO).
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Angelino E, 2018, J MACH LEARN RES, V18
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Biggio B., 2013, JOINT EUR C MACH LEA, DOI [10.1007/978-3-642-40994-3_25, DOI 10.1007/978-3-642-40994-3_25, 10.1007/978- 3-642-40994-3_25]
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Breiman L., 1983, Classification and Regression Trees
   Caballero HSG, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13667
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chen C., 2018, PROC INT C NEURAL IN
   Collaris D., 2018, Instance-Level Explanations for Fraud Detection: A Case Study, P28
   Collaris D, 2020, IEEE PAC VIS SYMP, P26, DOI 10.1109/PacificVis48177.2020.7090
   Demiralp C., 2016, PROC KDD WORKSHOP IN, P37
   EPANECHN.VA, 1969, THEOR PROBAB APPL+, V14, P153, DOI 10.1137/1114019
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   FICO, 2018, EXPL MACH LEARN CHAL
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   Guazzelli A., 2011, PROC WORKSHOP PREDIC, P32
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kaur H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376219
   Kiseleva J, 2013, INT CONF DAT MIN WOR, P391, DOI 10.1109/ICDMW.2013.143
   Krause J., 2018, PROC KDD WORKSHOP IN
   Krause J., 2016, ICML Workshop on Human Interpretability in Machine Learning, P106
   Liu SS, 2019, IEEE T VIS COMPUT GR, V25, P651, DOI 10.1109/TVCG.2018.2865230
   Lou Y, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P623, DOI 10.1145/2487575.2487579
   Lundberg SM, 2017, ADV NEUR IN, V30
   McInnes L., 2018, J OPEN SOURCE SOFTW, V3, DOI [DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Metsalu T, 2015, NUCLEIC ACIDS RES, V43, pW566, DOI 10.1093/nar/gkv468
   Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Sacha D, 2017, NEUROCOMPUTING, V268, P164, DOI 10.1016/j.neucom.2017.01.105
   Seo J, 2002, COMPUTER, V35, P80
   Shepard D., 1968, P 1968 23 ACM NAT C, P517, DOI [10.1145/800186.810616, DOI 10.1145/800186.810616]
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Chan GYY, 2020, Arxiv, DOI arXiv:2007.10614
   Yuan J, 2024, Arxiv, DOI arXiv:2007.10609
   Zahavy T, 2016, PR MACH LEARN RES, V48
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 51
TC 6
Z9 6
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 2996
EP 3008
DI 10.1109/TVCG.2022.3146806
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500013
PM 35085084
OA Green Published, hybrid
DA 2024-11-06
ER

PT J
AU Zhang, W
   Tan, SW
   Chen, SM
   Meng, LH
   Zhang, TY
   Zhu, RC
   Chen, W
AF Zhang, Wei
   Tan, Siwei
   Chen, Siming
   Meng, Linghao
   Zhang, Tianye
   Zhu, Rongchen
   Chen, Wei
TI Visual Reasoning for Uncertainty in Spatio-Temporal Events of Historical
   Figures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Visualization; Cognition; Data visualization; Biographies;
   Task analysis; Data mining; History; uncertainty; spatio-temporal
   events; visual reasoning
ID ANALYTICS
AB The development of digitized humanity information provides a new perspective on data-oriented studies of history. Many previous studies have ignored uncertainty in the exploration of historical figures and events, which has limited the capability of researchers to capture complex processes associated with historical phenomena. We propose a visual reasoning system to support visual reasoning of uncertainty associated with spatio-temporal events of historical figures based on data from the China Biographical Database Project. We build a knowledge graph of entities extracted from a historical database to capture uncertainty generated by missing data and error. The proposed system uses an overview of chronology, a map view, and an interpersonal relation matrix to describe and analyse heterogeneous information of events. The system also includes uncertainty visualization to identify uncertain events with missing or imprecise spatio-temporal information. Results from case studies and expert evaluations suggest that the visual reasoning system is able to quantify and reduce uncertainty generated by the data.
C1 [Zhang, Wei; Zhang, Tianye; Zhu, Rongchen; Chen, Wei] Zhejiang Univ, State Key Lab Cad&CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Tan, Siwei] Zhejiang Univ, Sch Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
   [Meng, Linghao] Tech Univ Eindhoven, Shool Math & Comp Sci, NL-5612 AZ Eindhoven, Netherlands.
C3 Zhejiang University; Zhejiang University; Fudan University; Eindhoven
   University of Technology
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab Cad&CG, Hangzhou 310027, Zhejiang, Peoples R China.; Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
EM vis-public@cad.zju.edu.cn; siweitan@zju.edu.cn; simingchen3@gmail.com;
   alice.menglh@gmail.com; zhangtianye1026@zju.edu.cn; 22051105@zju.edu.cn;
   chenwei@cad.zju.edu.cn
RI Chen, Siming/AAK-1874-2020; Meng, Linhao/LOR-8016-2024; Zhu,
   Rongchen/AAZ-2501-2020; Chen, Wei/AAR-9817-2020
OI Tan, Siwei/0000-0002-0634-8089; Chen, Wei/0000-0002-8365-4741; Meng,
   Linhao/0000-0002-5611-5929
FU National Natural Science Foundation of China [61772456, 61972122];
   Fundamental Research Funds for the Central Universities
   [2-2050205-21-688]; Shanghai Science and Technology Commission
   [21ZR1403300]; Shanghai Sailing Program [21YF1402900]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61772456 and 61972122, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   2-2050205-21-688, in part by Shanghai Science and Technology Commission
   under Grant 21ZR1403300, and in part by Shanghai Sailing Program under
   Grant 21YF1402900.
CR Aigner W, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P457, DOI 10.1109/IV.2005.97
   Barczok R., 2019, PROC IEEE WORKSHOP V, P1
   Bol Peter, 2012, ANN GIS, V18, P3, DOI DOI 10.1080/19475683.2011.647077
   Bol PK, 2013, ANN ASSOC AM GEOGR, V103, P1087, DOI 10.1080/00045608.2013.792178
   Bosch H., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P309, DOI 10.1109/VAST.2011.6102488
   Boyd Davis S., 2014, PROC EUR SOCIAL SCI
   Bradley AJ, 2018, IEEE COMPUT GRAPH, V38, P26, DOI 10.1109/MCG.2018.2878900
   Brooke J., 1995, USABILITY EVAL IND, P189
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Chen BJ, 2020, J CHINESE HIST, V4, P431, DOI 10.1017/jch.2020.15
   Chen SM, 2018, J VISUAL LANG COMPUT, V48, P187, DOI 10.1016/j.jvlc.2018.06.007
   Chen W, 2018, IEEE T VIS COMPUT GR, V24, P2636, DOI 10.1109/TVCG.2017.2758362
   Cho I, 2016, IEEE T VIS COMPUT GR, V22, P210, DOI 10.1109/TVCG.2015.2467971
   CLARK HH, 1969, PSYCHOL REV, V76, P387, DOI 10.1037/h0027578
   Correa Carlos D., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P51, DOI 10.1109/VAST.2009.5332611
   datesandevents, HIST TIM FAM PEOPL
   Dörk M, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1535, DOI 10.1145/2556288.2557083
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Elmqvist N, 2008, INFORM VISUAL, V7, P18, DOI 10.1057/palgrave.ivs.9500170
   Fokkens A, 2018, Arxiv, DOI arXiv:1801.07073
   Galarraga L. A., 2013, P 22 INT C WORLD WID, P413, DOI DOI 10.1145/2488388.2488425
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Harvard University Academia Sinica and Peking University, 2019, CHIN BIOGR DAT CBDB
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hyvönen E, 2019, LECT NOTES COMPUT SC, V11503, P574, DOI 10.1007/978-3-030-21348-0_37
   Jänicke S, 2017, COMPUT GRAPH FORUM, V36, P226, DOI 10.1111/cgf.12873
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Lao N., 2011, P 2011 C EMP METH NA, P529
   Li Jie, 2020, IEEE Trans Vis Comput Graph, V26, P1789, DOI 10.1109/TVCG.2018.2882449
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Lu Lu, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference (PAKDD 2014). Proceedings: LNCS 8443, P509, DOI 10.1007/978-3-319-06608-0_42
   Lu YF, 2018, IEEE T VIS COMPUT GR, V24, P2501, DOI 10.1109/TVCG.2017.2752166
   Page L, 1998, PAGERANK CITATION RA
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Rajaraman A., 2011, MINING MASSIVE DATAS
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Therón R, 2018, SIXTH INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY (TEEM'18), P826, DOI 10.1145/3284179.3284323
   Sánchez RT, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030031
   Turchin P, 2018, P NATL ACAD SCI USA, V115, pE144, DOI 10.1073/pnas.1708800115
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XT, 2016, IEEE CONF VIS ANAL, P51, DOI 10.1109/VAST.2016.7883511
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Wiles S, 2010, PASTS DIGI PRESENCE, V11
   Windhager F., 2019, 4th IEEE Workshop on Visualization for the Digital Humanities (VIS4DH), P1
   Windhager F, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030029
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Zhang W, 2021, VIS INFORM, V5, P34, DOI 10.1016/j.visinf.2021.12.002
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
NR 54
TC 2
Z9 3
U1 4
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3009
EP 3023
DI 10.1109/TVCG.2022.3146508
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500014
PM 35085083
DA 2024-11-06
ER

PT J
AU Zhang, JB
   Wan, ZY
   Liao, J
AF Zhang, Jingbo
   Wan, Ziyu
   Liao, Jing
TI Adaptive Joint Optimization for 3D Reconstruction With Differentiable
   Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Texture optimization; geometry refinement; 3D reconstruction; adaptive
   interleaving strategy; differentiable rendering
AB Due to inevitable noises introduced during scanning and quantization, 3D reconstruction via RGB-D sensors suffers from errors both in geometry and texture, leading to artifacts such as camera drifting, mesh distortion, texture ghosting, and blurriness. Given an imperfect reconstructed 3D model, most previous methods have focused on refining either geometry, texture, or camera pose. Consequently, different optimization schemes and objectives for optimizing each component have been used in previous joint optimization methods, forming a complicated system. In this paper, we propose a novel optimization approach based on differentiable rendering, which integrates the optimization of camera pose, geometry, and texture into a unified framework by enforcing consistency between the rendered results and the corresponding RGB-D inputs. Based on the unified framework, we introduce a joint optimization approach to fully exploit the inter-relationships among the three objective components, and describe an adaptive interleaving strategy to improve optimization stability and efficiency. Using differentiable rendering, an image-level adversarial loss is applied to further improve the 3D model, making it more photorealistic. Experiments on synthetic and real data using quantitative and qualitative evaluation demonstrated the superiority of our approach in recovering both fine-scale geometry and high-fidelity texture.
C1 [Zhang, Jingbo; Wan, Ziyu; Liao, Jing] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Liao, J (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM jbzhang6-c@my.cityu.edu.hk; ziyuwan2-c@my.cityu.edu.hk;
   jingliao@cityu.edu.hk
RI Zhang, Jingbo/GRX-3761-2022
OI LIAO, Jing/0000-0001-7014-5377; Zhang, Jingbo/0000-0003-0009-2315
FU Hong Kong Research Grants Council (RGC) Early Career Scheme [9048148,
   21209119]
FX This work was supported in part by Huawei Ascend and partially supported
   by the Hong Kong Research Grants Council (RGC) Early Career Scheme under
   Grant 9048148 (CityU 21209119).
CR Andersen D, 2019, IEEE T VIS COMPUT GR, V25, P3073, DOI 10.1109/TVCG.2019.2932172
   Bi S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073610
   Chen WZ, 2019, ADV NEUR IN, V32
   Choe G, 2017, INT J COMPUT VISION, V122, P1, DOI 10.1007/s11263-016-0937-y
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Fu YP, 2018, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2018.00488
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Huang JW, 2020, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR42600.2020.00163
   Huang JW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130824
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2021, Arxiv, DOI arXiv:2106.12423
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kingma DP, 2014, ADV NEUR IN, V27
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Lattas A, 2020, PROC CVPR IEEE, P757, DOI 10.1109/CVPR42600.2020.00084
   Li RL, 2020, PROC CVPR IEEE, P3407, DOI 10.1109/CVPR42600.2020.00347
   Li TM, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275109
   Li W, 2019, IEEE T VIS COMPUT GR, V25, P2296, DOI 10.1109/TVCG.2018.2831220
   Li YS, 2022, IEEE T VIS COMPUT GR, V28, P3499, DOI 10.1109/TVCG.2021.3069195
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Liu ZN, 2021, IEEE T VIS COMPUT GR, V27, P83, DOI 10.1109/TVCG.2019.2937300
   Loper MM, 2014, LECT NOTES COMPUT SC, V8695, P154, DOI 10.1007/978-3-319-10584-0_11
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Romanoni A, 2017, IEEE INT CONF COMP V, P706, DOI 10.1109/ICCVW.2017.89
   Schmitt C, 2020, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR42600.2020.00355
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Wan ZY, 2020, PROC CVPR IEEE, P2744, DOI 10.1109/CVPR42600.2020.00282
   Wang C, 2018, INT CONF 3D VISION, P533, DOI 10.1109/3DV.2018.00067
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou QY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601134
   Zollhöfer M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766887
NR 43
TC 4
Z9 5
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3039
EP 3051
DI 10.1109/TVCG.2022.3148245
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500016
PM 35120006
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Xu, JY
   Guo, HQ
   Shen, HW
   Raj, M
   Wurster, SW
   Peterka, T
AF Xu, Jiayi
   Guo, Hanqi
   Shen, Han-Wei
   Raj, Mukund
   Wurster, Skylar W.
   Peterka, Tom
TI Reinforcement Learning for Load-Balanced Parallel Particle Tracing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Costs; Heuristic algorithms; Estimation; Load modeling; Data models;
   Computational modeling; Adaptation models; Distributed and parallel
   particle tracing; dynamic load balancing; reinforcement learning
ID COLLECTIVE COMMUNICATION; MODEL; VISUALIZATION; ALGORITHMS; ADVECTION;
   MPI
AB We explore an online reinforcement learning (RL) paradigm to dynamically optimize parallel particle tracing performance in distributed-memory systems. Our method combines three novel components: (1) a work donation algorithm, (2) a high-order workload estimation model, and (3) a communication cost model. First, we design an RL-based work donation algorithm. Our algorithm monitors workloads of processes and creates RL agents to donate data blocks and particles from high-workload processes to low-workload processes to minimize program execution time. The agents learn the donation strategy on the fly based on reward and cost functions designed to consider processes' workload changes and data transfer costs of donation actions. Second, we propose a workload estimation model, helping RL agents estimate the workload distribution of processes in future computations. Third, we design a communication cost model that considers both block and particle data exchange costs, helping RL agents make effective decisions with minimized communication costs. We demonstrate that our algorithm adapts to different flow behaviors in large-scale fluid dynamics, ocean, and weather simulation data. Our algorithm improves parallel particle tracing performance in terms of parallel efficiency, load balance, and costs of I/O and communication for evaluations with up to 16,384 processors.
C1 [Xu, Jiayi; Shen, Han-Wei; Wurster, Skylar W.] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Guo, Hanqi; Peterka, Tom] Argonne Natl Lab, Math & Comp Sci Div, Lemont, IL 60439 USA.
   [Raj, Mukund] Broad Inst MIT & Harvard, Stanley Ctr Psychiat Res, Cambridge, MA 02142 USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Energy (DOE); Argonne National Laboratory; Harvard
   University; Massachusetts Institute of Technology (MIT); Broad Institute
RP Xu, JY (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM xu.2205@osu.edu; hguo@anl.gov; shen.94@osu.edu; mraj@broadinstitute.org;
   wurster.18@osu.edu; tpeterka@anl.gov
RI Guo, Hanqi/AAL-1929-2021; Raj, Michael/HTM-5309-2023; Shen,
   Han-wei/A-4710-2012; Guo, Hanqi/ADW-4234-2022
OI Xu, Jiayi/0000-0002-9091-6412; Shen, Han-Wei/0000-0002-1211-2320; Guo,
   Hanqi/0000-0001-7776-1834; Wurster, Skylar/0000-0001-6685-615X
FU National Science Foundation Division of Information and Intelligent
   Systems [1955764]; National Science Foundation Office of Advanced
   Cyberinfrastructure [2112606]; U.S. Department of Energy Los Alamos
   National Laboratory [47145]; UT-Battelle LLC [4000159447]; Exascale
   Computing Project (ECP) [17-SC-20-SC]; U.S. Department of Energy Office
   of Science; National Nuclear Security Administration, as part of the
   Co-design center for Online Data Analysis and Reduction (CODAR); U.S.
   Department of Energy, Office of Advanced Scientific Computing Research,
   Scientific Discovery through Advanced Computing (SciDAC) program;
   Laboratory Directed Research and Development (LDRD) funding from Argonne
   National Laboratory; Office of Science, of the U.S. Department of Energy
   [DE-AC02-06CH11357]
FX This work was supported in part by the National Science Foundation
   Division of Information and Intelligent Systems under Grant 1955764, in
   part by the National Science Foundation Office of Advanced
   Cyberinfrastructure under Grant 2112606, in part by U.S. Department of
   Energy Los Alamos National Laboratory under Grant 47145, and in part by
   UT-Battelle LLC under Grant 4000159447 program manager Margaret Lentz.
   This work was also supported in part by Exascale Computing Project (ECP)
   under Grant 17-SC-20-SC, in part by a collaborative effort of the U.S.
   Department of Energy Office of Science and in part by the National
   Nuclear Security Administration, as part of the Co-design center for
   Online Data Analysis and Reduction (CODAR). It was also supported in
   part by the U.S. Department of Energy, Office of Advanced Scientific
   Computing Research, Scientific Discovery through Advanced Computing
   (SciDAC) program, in part by Laboratory Directed Research and
   Development (LDRD) funding from Argonne National Laboratory, and in part
   by the Director, Office of Science, of the U.S. Department of Energy
   under Grant DE-AC02-06CH11357.
CR Agarwal A., 2020, P 33 C LEARN THEOR, P64
   Agarwal A, 2020, Arxiv, DOI arXiv:1908.00261
   Atkeson CG, 1997, IEEE INT CONF ROBOT, P3557, DOI 10.1109/ROBOT.1997.606886
   Behnel S, 2011, COMPUT SCI ENG, V13, P31, DOI 10.1109/MCSE.2010.118
   BERGER MJ, 1987, IEEE T COMPUT, V36, P570, DOI 10.1109/TC.1987.1676942
   Binyahib R, 2019, SYMP LARG DATA ANAL, P52, DOI [10.1109/ldav48142.2019.8944355, 10.1109/LDAV48142.2019.8944355]
   Blumofe RD, 1999, J ACM, V46, P720, DOI 10.1145/324133.324234
   CABRAL B, 1995, SIAM PROC S, P802
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Camp D., 2013, P 13 EUROGRAPHICS S, P1
   Camp D, 2011, IEEE T VIS COMPUT GR, V17, P1702, DOI 10.1109/TVCG.2010.259
   Chan E, 2007, CONCURR COMP-PRACT E, V19, P1749, DOI 10.1002/cpe.1206
   Chen CM, 2012, IEEE PAC VIS SYMP, P145, DOI 10.1109/PacificVis.2012.6183585
   Chen L, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P87
   Childs H., 2014, 2014 21st International Conference on High Performance Computing (HiPC), P1
   Chun-Ming Chen, 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P109, DOI 10.1109/LDAV.2012.6378984
   Dalcín L, 2005, J PARALLEL DISTR COM, V65, P1108, DOI 10.1016/j.jpdc.2005.03.010
   Dinan J, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Fischer P, 2008, J PHYS CONF SER, V125, P12076, DOI 10.1088/1742-6596/125/1/012076
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Garey MR, 1974, P 6 ANN ACM S THEOR, P47
   Garth C, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P329, DOI 10.1109/VISUAL.2004.107
   Gläscher J, 2010, NEURON, V66, P585, DOI 10.1016/j.neuron.2010.04.016
   Guo HQ, 2014, IEEE PAC VIS SYMP, P33, DOI 10.1109/PacificVis.2014.15
   Guo HQ, 2014, IEEE T VIS COMPUT GR, V20, P2555, DOI 10.1109/TVCG.2014.2346418
   Guo HQ, 2013, IEEE T VIS COMPUT GR, V19, P2733, DOI 10.1109/TVCG.2013.144
   Haller G, 2001, PHYSICA D, V149, P248, DOI 10.1016/S0167-2789(00)00199-8
   Hinton G., 2012, COURSERA: Neural networks for machine learning, V4, P26
   Hong F, 2018, IEEE PAC VIS SYMP, P76, DOI 10.1109/PacificVis.2018.00018
   Kaiser L, 2024, Arxiv, DOI arXiv:1903.00374
   Kendall W., 2011, PROC INT C HIGH PERF
   Kendall W, 2011, IEEE COMPUT GRAPH, V31, P6, DOI 10.1109/MCG.2011.102
   Kernighan B.W., 1988, The C Programming Language, V2nd ed.
   Kielmann T, 2001, PARALLEL COMPUT, V27, P1431, DOI 10.1016/S0167-8191(01)00098-9
   Kingma DP, 2014, ADV NEUR IN, V27
   Lane D. A., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P257, DOI 10.1109/VISUAL.1994.346311
   Lane D. A, 1995, CONF950212 SOC IND A
   Li Y, 2008, J TURBUL, V9, P1, DOI 10.1080/14685240802376389
   Lu KW, 2014, INT CONF HIGH PERFOR, P1008, DOI 10.1109/SC.2014.87
   Maltrud ME, 2005, OCEAN MODEL, V8, P31, DOI 10.1016/j.ocemod.2003.12.001
   Mei J., 2020, INT C MACHINE LEARNI, P6820
   Mnih V, 2013, Arxiv, DOI arXiv:1312.5602
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moerland T.M., 2020, arXiv
   Morozov D, 2016, SYMP LARG DATA ANAL, P29, DOI 10.1109/LDAV.2016.7874307
   Morozov Dmitriy., DIY: data-parallel out-of-core library
   Muller Cornelius, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P1, DOI 10.1109/LDAV.2013.6675152
   Muraki S, 2003, PVG 2003 PROCEEDINGS, P95, DOI 10.1109/PVGS.2003.1249047
   Nouanesengsy B, 2012, INT CONF HIGH PERFOR
   Nouanesengsy B, 2011, IEEE T VIS COMPUT GR, V17, P1785, DOI 10.1109/TVCG.2011.219
   Pal CV, 2020, INT CONF SYST THEO, P92, DOI 10.1109/ICSTCC50638.2020.9259716
   Paszke A, 2017, PROC NEURAL INFORMAT
   Paszke A, 2019, ADV NEUR IN, V32
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Peterka T., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P580, DOI 10.1109/IPDPS.2011.62
   Polydoros AS, 2017, J INTELL ROBOT SYST, V86, P153, DOI 10.1007/s10846-017-0468-y
   Pugmire D., 2018, PROC EUROGRAPH S PAR, P45
   Pugmire D., 2012, High Performance Visualization: Enabling Extreme Scale Scientific Insight, P13
   Pugmire D, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   RAFTERY AE, 1985, J R STAT SOC B, V47, P528, DOI 10.1111/j.2517-6161.1985.tb01383.x
   Reverdy P, 2016, IEEE T AUTOM SCI ENG, V13, P54, DOI 10.1109/TASE.2015.2499244
   Rumelhart D. E., 1987, Foundations, P318
   Saraswat V, 2011, ACM SIGPLAN NOTICES, V46, P201, DOI 10.1145/2038037.1941582
   Schwartz S. D., 2021, PROC EUROGRAPH S PAR, P7, DOI [10.2312/pgv20211039, DOI 10.2312/PGV20211039]
   Sujudi D, 1996, PARALLEL COMPUTATIONAL FLUID DYNAMICS, P315, DOI 10.1016/B978-044482322-9/50093-1
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Träff JL, 2019, IEEE T PARALL DISTR, V30, P2060, DOI 10.1109/TPDS.2019.2899843
   Tricoche X, 2002, COMPUT GRAPH-UK, V26, P249, DOI 10.1016/S0097-8493(02)00056-0
   VanRossum G., 2009, PYTHON 3 REFERENCE M
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xu LJ, 2010, PROC SPIE, V7530, DOI 10.1117/12.838659
   Yeung PK, 2012, J FLUID MECH, V700, P5, DOI 10.1017/jfm.2012.5
   Yu H., 2007, Supercomputing, P1
   Zhang J, 2018, IEEE PAC VIS SYMP, P86, DOI 10.1109/PacificVis.2018.00019
   Zhang J, 2018, J VISUAL-JAPAN, V21, P351, DOI 10.1007/s12650-017-0470-2
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P954, DOI 10.1109/TVCG.2017.2744059
   Zhang J, 2016, IEEE PAC VIS SYMP, P80, DOI 10.1109/PACIFICVIS.2016.7465254
NR 78
TC 29
Z9 38
U1 1
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3052
EP 3066
DI 10.1109/TVCG.2022.3148745
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500017
PM 35130159
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kong, WY
   Jiang, ZY
   Sun, SZ
   Guo, ZN
   Cui, WW
   Liu, T
   Lou, JG
   Zhang, DM
AF Kong, Wenyuan
   Jiang, Zhaoyun
   Sun, Shizhao
   Guo, Zhuoning
   Cui, Weiwei
   Liu, Ting
   Lou, Jianguang
   Zhang, Dongmei
TI Aesthetics plus plus : Refining Graphic Designs by Exploring Design
   Principles and Human Preference
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Statistical analysis; Refining; Prototypes; Color;
   Automatic refinement suggestion; design principles; data-driven
   approach; aesthetic quality
AB During the creation of graphic designs, individuals inevitably spend a lot of time and effort on adjusting visual attributes (e.g., positions, colors, and fonts) of elements to make them more aesthetically pleasing. It is a trial-and-error process, requires repetitive edits, and relies on good design knowledge. In this work, we seek to alleviate such difficulty by automatically suggesting aesthetic improvements, i.e., taking an existing design as the input and generating a refined version with improved aesthetic quality as the output. This goal presents two challenges: proposing a refined design based on the user-given one, and assessing whether the new design is better aesthetically. To cope with these challenges, we propose a design principle-guided candidate generation stage and a data-driven candidate evaluation stage. In the candidate generation stage, we generate candidate designs by leveraging design principles as the guidance to make changes around the existing design. In the candidate evaluation stage, we learn a ranking model upon a dataset that can reflect humans' aesthetic preference, and use it to choose the most aesthetically pleasing one from the generated candidates. We implement a prototype system on presentation slides and demonstrate the effectiveness of our approach through quantitative analysis, sample results, and user studies.
C1 [Kong, Wenyuan] Peking Univ, Beijing 100871, Peoples R China.
   [Jiang, Zhaoyun; Liu, Ting] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
   [Sun, Shizhao; Cui, Weiwei; Lou, Jianguang; Zhang, Dongmei] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Guo, Zhuoning] Harbin Inst Technol, Harbin 150001, Heilongjiang, Peoples R China.
C3 Peking University; Xi'an Jiaotong University; Microsoft Research Asia;
   Microsoft; Harbin Institute of Technology
RP Sun, SZ (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM kongwenyuan@pku.edu.cn; jzy124@stu.hit.edu.cn;
   shizhao.sun@microsoft.com; 1183710109@stu.hit.edu.cn;
   weiwei.cui@microsoft.com; tingliu@mail.xjtu.edu.cn; jlou@microsoft.com;
   dongmeiz@microsoft.com
RI Jiang, Zhaoyun/LKN-9461-2024; zhang, dongmei/B-8011-2013; GUO,
   Zhuoning/JFK-5503-2023
OI Jiang, Zhaoyun/0000-0003-0133-9228; GUO, Zhuoning/0000-0003-1448-5566;
   Liu, Ting/0000-0002-7600-0934
CR [Anonymous], 2011, The elements of graphic design
   Baluja S., 2006, WWW 06 P 15 INT C WO, P33, DOI DOI 10.1145/1135777.1135788
   Bauerly M, 2006, INT J HUM-COMPUT ST, V64, P670, DOI 10.1016/j.ijhcs.2006.01.002
   Butler J., 2010, UNIVERSAL PRINCIPLES, P112
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Dayama NR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376553
   Harrington S. J., 2004, P 2004 ACM S DOC ENG, P109, DOI [DOI 10.1145/1030397.1030419, 10.1145/1030397.1030419]
   Hosu V, 2019, PROC CVPR IEEE, P9367, DOI 10.1109/CVPR.2019.00960
   House D, 2005, IEEE Visualization 2005, Proceedings, P87
   House DH, 2006, IEEE T VIS COMPUT GR, V12, P509, DOI 10.1109/TVCG.2006.58
   Hsin-Ying Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P491, DOI 10.1007/978-3-030-58580-8_29
   Kumar R, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2197
   Landa R., 2018, Graphic Design Solutions, V6th
   Li JN, 2021, IEEE T VIS COMPUT GR, V27, P4039, DOI 10.1109/TVCG.2020.2999335
   Li JN, 2021, IEEE T PATTERN ANAL, V43, P2388, DOI 10.1109/TPAMI.2019.2963663
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Lupton E., 2014, Thinking with Type: A Critical Guide for Designers, Writers, Editors, & Students
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Reynolds G, 2011, Presentation Zen: simple ideas on presentation design and delivery
   Sheng KK, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P879, DOI 10.1145/3240508.3240554
   Sutclifffe A., 2001, P 8 INT WORKSHOP INT, V2220, P183, DOI DOI 10.1007/3-540-45522-111
   Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   ULLER-BROCKMANN Josef -., 1981, Grid Systems in Graphic Design, V11a
   Williams Robin., 2004, NONDESIGNERS DESIGN
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Zhao NX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201355
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 33
TC 0
Z9 0
U1 5
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3093
EP 3104
DI 10.1109/TVCG.2022.3151617
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500019
PM 35167478
DA 2024-11-06
ER

PT J
AU Resck, LE
   Ponciano, JR
   Nonato, LG
   Poco, J
AF Resck, Lucas E.
   Ponciano, Jean R.
   Nonato, Luis Gustavo
   Poco, Jorge
TI LegalVis: Exploring and Inferring Precedent Citations in Legal Documents
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Law; Data visualization; Visual analytics; Task analysis; Text analysis;
   Analytical models; Natural language processing; Legal documents; visual
   analytics; Brazilian legal system; natural language processing
ID NONNEGATIVE MATRIX; VISUALIZATION; ALGORITHMS
AB To reduce the number of pending cases and conflicting rulings in the Brazilian Judiciary, the National Congress amended the Constitution, allowing the Brazilian Supreme Court (STF) to create binding precedents (BPs), i.e., a set of understandings that both Executive and lower Judiciary branches must follow. The STF's justices frequently cite the 58 existing BPs in their decisions, and it is of primary relevance that judicial experts could identify and analyze such citations. To assist in this problem, we propose LegalVis, a web-based visual analytics system designed to support the analysis of legal documents that cite or could potentially cite a BP. We model the problem of identifying potential citations (i.e., non-explicit) as a classification problem. However, a simple score is not enough to explain the results; that is why we use an interpretability machine learning method to explain the reason behind each identified citation. For a compelling visual exploration of documents and BPs, LegalVis comprises three interactive visual components: the first presents an overview of the data showing temporal patterns, the second allows filtering and grouping relevant documents by topic, and the last one shows a document's text aiming to interpret the model's output by pointing out which paragraphs are likely to mention the BP, even if not explicitly specified. We evaluated our identification model and obtained an accuracy of 96%; we also made a quantitative and qualitative analysis of the results. The usefulness and effectiveness of LegalVis were evaluated through two usage scenarios and feedback from six domain experts.
C1 [Resck, Lucas E.; Ponciano, Jean R.; Poco, Jorge] Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
   [Nonato, Luis Gustavo] Univ Sao Paulo, ICMC, BR-13566590 Sao Carlos, Brazil.
   [Poco, Jorge] Univ Catolica San Pablo, Arequipa 04001, Peru.
C3 Escola de Pos-Graduacao em Economia (EPGE); Getulio Vargas Foundation;
   Universidade de Sao Paulo; Universidad Catolica San Pablo
RP Resck, LE (corresponding author), Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
EM lucas.domingues@fgv.edu.br; jean.ponciano@fgv.br; gnonato@icmc.usp.br;
   jorge.poco@fgv.br
RI Nonato, Luis/D-5782-2011; Ponciano, Jean/AGE-0314-2022; Poco,
   Jorge/F-3344-2016
OI Resck, Lucas/0000-0001-9634-450X; Ponciano, Jean
   Roberto/0000-0003-4629-3542; Poco, Jorge/0000-0001-9096-6287
FU CNPq-Brazil [303552/2017-4, 312483/2018-0]; Rio de Janeiro State Funding
   Agency (FAPERJ)-Brazil [E-26/201.424/2021]; Sao Paulo Research
   Foundation (FAPESP)-Brazil [2013/07375-0]; School of Applied Mathematics
   at Fundacao Getulio Vargas (FGV)
FX This work was supported in part by CNPq-Brazil under Grants
   #303552/2017-4 and #312483/2018-0, in part by Rio de Janeiro State
   Funding Agency (FAPERJ)-Brazil under Grant #E-26/201.424/2021, in part
   by Sao Paulo Research Foundation (FAPESP)-Brazil under Grant
   #2013/07375-0, and the School of Applied Mathematics at Fundacao Getulio
   Vargas (FGV).
CR Abdul-Rahman A, 2017, COMPUT GRAPH FORUM, V36, P237, DOI 10.1111/cgf.12798
   Alharbi M., 2018, C COMPUTER GRAPHICS, P143
   Ali S, 2006, LECT NOTES COMPUT SC, V4304, P362
   Alsakran J, 2011, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2011.5742382
   Avinash M., 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P475, DOI 10.1007/978-981-13-1501-5_41
   Barros R, 2018, LECT NOTES ARTIF INT, V10868, P857, DOI 10.1007/978-3-319-92058-0_82
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Bird S., 2009, NATURAL LANGUAGE PRO
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bluetick, BLUET VIND ZOND ZOEK
   Brazilian National Council of Justice, NUM TOT CAS PEND JUS
   Brazilian Supreme Court, 2014, APL SUM STF SUM VINC
   Brazilian Supreme Court, 2017, MIN EDS FACH SORT NO
   Brazilian Supreme Court, SUM VINC
   Brazilian Supreme Court, NUM DEC STF ENTR 201
   Buscador Dizer o Direito, BUSCADOR DIZER DIREI
   Cao N., 2016, Introduction to Text Visualization, V1
   Carvalho NR, 2018, ACM INT CONF PR SER, P23, DOI 10.1145/3209415.3209424
   Casetext, COMP CRAFT EXC BRIEF
   Cer D, 2018, Arxiv, DOI [arXiv:1803.11175, DOI 10.48550/ARXIV.1803.11175]
   Chada D. M., 2015, PROC 15 INT C ARTIF, P176
   Cheema M. F., 2016, PROC IEEE VIS WORKSH
   Cichocki A, 2009, IEICE T FUND ELECTR, VE92A, P708, DOI 10.1587/transfun.E92.A.708
   Correia FA, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345416
   D3.js, D3 JS DAT DRIV DOC
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Diakopoulos N., 2015, P IUI WORKSH VIS TEX
   Dueck D, 2005, BIOINFORMATICS, V21, pI144, DOI 10.1093/bioinformatics/bti1041
   Elastic, EL OFF DISTR SEARCH
   Falca~o J., 2013, REV DIREITO ADM, V262, P399
   Ferreira de Oliveira M.C., 2015, P 2015 ACM S DOCUMEN, P97
   Finch Platform, FINCH SIMPL MUND JUR
   Gomez-Nieto E., 2015, PROC 6 WORKSHOP VIS
   Grinberg M., 2018, Flask Web Development: Developing Web Applications with Python
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jänicke S, 2017, COMPUT GRAPH FORUM, V36, P226, DOI 10.1111/cgf.12873
   Janicke Stefan, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P59
   Jusbrasil, JUSBR CON PESS JUST
   Kiesel D, 2021, IEEE T VIS COMPUT GR, V27, P1139, DOI 10.1109/TVCG.2020.3030425
   Kim H, 2007, BIOINFORMATICS, V23, P1495, DOI 10.1093/bioinformatics/btm134
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Le Q., 2014, INT C MACH LEARN PML, P1188
   Lettieri N, 2017, INFORM VISUAL, V16, P332, DOI 10.1177/1473871616681374
   Lettieri N, 2016, SOC NETW ANAL MIN, V6, DOI 10.1007/s13278-016-0365-6
   Lexis, LEX ONL LEG RES
   LexML, LEXML BRAS RED INF L
   Li J., 2016, arXiv
   Linhares CDG, 2019, COMPUT SOC SCI, P83, DOI 10.1007/978-3-030-23495-9_5
   Mahoney CJ, 2019, IEEE INT CONF BIG DA, P1858, DOI 10.1109/BigData47090.2019.9005659
   Mandal A, 2017, COMPUTE'17: PROCEEDINGS OF THE 10TH ANNUAL ACM INDIA COMPUTE CONFERENCE, P1, DOI 10.1145/3140107.3140119
   OABJuris, OABJURIS JUR FORM MA
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Platt JC, 2000, ADV NEUR IN, P61
   Potthast M, 2013, CLEF C MULT MULT INF, P301
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Riehmann P, 2015, COMPUT GRAPH FORUM, V34, P61, DOI 10.1111/cgf.12618
   Robertson S, 2004, J DOC, V60, P503, DOI 10.1108/00220410410560582
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Souza Fabio, 2020, Intelligent Systems. 9th Brazilian Conference, BRACIS 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12319), P403, DOI 10.1007/978-3-030-61377-8_28
   Thomson Reuters, WESTL LEG RES TOOLS
   Thomson Reuters, LEG ON SOL JUND AD R
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Kuppevelt D, 2017, FRONT ARTIF INTEL AP, V302, P95, DOI 10.3233/978-1-61499-838-9-95
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Y, 2017, IOP CONF SER-MAT SCI, V261, DOI 10.1088/1757-899X/261/1/012018
   Watts J., 2017, OPERATION CAR WASH I
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yousef T, 2021, IEEE T VIS COMPUT GR, V27, P1149, DOI 10.1109/TVCG.2020.3028975
   Zaheer M., 2020, Advances in neural information processing systems, V33, P17283
   Zhang P., 2007, Proceedings of the 11th international conference on Artificial intelligence and law, P123, DOI DOI 10.1145/1276318.1276342
   Zhu W, 2016, IEEE INT C BIOINFORM, P1415, DOI 10.1109/BIBM.2016.7822730
NR 75
TC 3
Z9 4
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3105
EP 3120
DI 10.1109/TVCG.2022.3152450
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500020
PM 35180081
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shen, LX
   Shen, EY
   Luo, YY
   Yang, XC
   Hu, XM
   Zhang, XS
   Tai, ZW
   Wang, JM
AF Shen, Leixian
   Shen, Enya
   Luo, Yuyu
   Yang, Xiaocong
   Hu, Xuming
   Zhang, Xiongshuai
   Tai, Zhiwei
   Wang, Jianmin
TI Towards Natural Language Interfaces for Data Visualization: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Natural language processing; Task
   analysis; Human computer interaction; Software; Data mining; natural
   language interfaces; survey
ID INTERACTIVE VISUALIZATION; NARRATIVE VISUALIZATION; MULTIMODAL
   INTERACTION; EXPLORATORY ANALYSIS; TASK; GENERATION; SYSTEM; USER;
   DESIGN; GRAMMAR
AB Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. It enables users to focus on their tasks rather than having to worry about how to operate visualization tools on the interface. In the past two decades, leveraging advanced natural language processing technologies, numerous V-NLI systems have been developed in academic research and commercial software, especially in recent years. In this article, we conduct a comprehensive review of the existing V-NLIs. In order to classify each article, we develop categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. The following seven stages are used: query interpretation, data transformation, visual mapping, view transformation, human interaction, dialogue management, and presentation. Finally, we also shed light on several promising directions for future work in the V-NLI community.
C1 [Shen, Leixian; Shen, Enya; Luo, Yuyu; Yang, Xiaocong; Hu, Xuming; Zhang, Xiongshuai; Tai, Zhiwei; Wang, Jianmin] Tsinghua Univ, Beijing 100190, Peoples R China.
C3 Tsinghua University
RP Shen, EY (corresponding author), Tsinghua Univ, Beijing 100190, Peoples R China.
EM slx20@mails.tsinghua.edu.cn; shenenya@tsinghua.edu.cn;
   luoyy18@mails.tsinghua.edu.cn; yangxc18@mails.tsinghua.edu.cn;
   hxm19@mails.tsinghua.edu.cn; zxs21@mails.tsinghua.edu.cn;
   tzw20@mails.tsinghua.edu.cn; jimwang@tsinghua.edu.cn
OI Shen, Leixian/0000-0003-1084-4912
FU National Natural Science Foundation of China [71690231]; Beijing Key
   Laboratory of Industrial Bigdata System and Application; Zhejiang Lab's
   International Talent Fund for Young Professionals
FX This work was supported by the National Natural Science Foundation of
   China under Grant 71690231 and in part by the Beijing Key Laboratory of
   Industrial Bigdata System and Application. The work of Yuyu Luo was
   supported by the Zhejiang Lab's International Talent Fund for Young
   Professionals.
CR Affolter K, 2019, VLDB J, V28, P793, DOI 10.1007/s00778-019-00567-8
   Akbik A., 2018, P 27 INT C COMP LING, P1638
   Al-Zaidy RA., 2015, P ACM C KNOWL CAPT, P30, DOI [10.1145/2815833.28169562, DOI 10.1145/2815833.28169562]
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 2019, ASK DATA
   [Anonymous], 1996, PROC INT NATURAL LAN
   Apache OpenNLP, 2017, About us
   Bacci F, 2020, LECT NOTES COMPUT SC, V12254, P771, DOI 10.1007/978-3-030-58817-5_55
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Baik C, 2019, PROC INT CONF DATA, P374, DOI 10.1109/ICDE.2019.00041
   Basik F, 2018, INT CONF MANAGE DATA, P1765, DOI 10.1145/3183713.3193562
   Bast H., 2015, P 24 ACM INT C INF K, P1431, DOI DOI 10.1145/2806416.2806472
   Battle L, 2021, IEEE T VIS COMPUT GR, V27, P1128, DOI 10.1109/TVCG.2020.3028891
   Battle L, 2020, IEEE T VIS COMPUT GR, V26, P1246, DOI 10.1109/TVCG.2019.2934556
   Bei-Bei Huang, 2008, 2008 IEEE International Workshop on Semantic Computing and Systems (WSCS 2008), P155, DOI 10.1109/WSCS.2008.14
   Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254
   Bergamaschi S, 2016, INFORM SYST, V55, P1, DOI 10.1016/j.is.2015.07.005
   Bieliauskas S, 2017, 2017 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT 2017), P139, DOI 10.1109/VISSOFT.2017.21
   Bird Steven., 2006, Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, P214
   Blunschi L, 2012, PROC VLDB ENDOW, V5, P932, DOI 10.14778/2336664.2336667
   Bongshin Lee, 2021, Foundations and Trends in Human-Computer Interaction, V14, P1, DOI 10.1561/1100000081
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brown TB, 2020, ADV NEUR IN, V33
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Bylinskii Z, 2017, Arxiv, DOI arXiv:1709.09215
   Card SK., 1999, READINGS INFORM VISU
   Celikyilmaz A., 2021, ARXIV200614799, P1
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen J., 2010, Extended Abstr. Hum. Factors Comput. Syst., P3703
   Chen JY, 2019, AAAI CONF ARTIF INTE, P29
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choo J, 2014, IEEE CONF VIS ANAL, P243, DOI 10.1109/VAST.2014.7042511
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Corio M., 1999, P EUR WORKS NAT LANG, P49
   Cox K., 2001, International Journal of Speech Technology, V4, P297, DOI 10.1023/A:1011368926479
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Dabre R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3406095
   Demir S., 2008, Proceedings of the Fifth International Natural Language Generation Conference, INLG '08, P7
   Demir S, 2012, COMPUT LINGUIST, V38, P527, DOI 10.1162/COLI_a_00091
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deshpande Aditi P., 2020, Information and Communication Technology for Sustainable Development. Proceedings of ICT4SD 2018. Advances in Intelligent Systems and Computing (AISC 933), P205, DOI 10.1007/978-981-13-7166-0_20
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhamdhere K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P493, DOI 10.1145/3025171.3025227
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Duncan IK, 2021, IEEE T VIS COMPUT GR, V27, P2136, DOI 10.1109/TVCG.2020.3041745
   Eisenschlos JM, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Fast E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174047
   Ferres L, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P83
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fu SW, 2020, Arxiv, DOI arXiv:2005.03257
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gao T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3005, DOI 10.1145/2556288.2557228
   Ge Tong, 2021, P 2021 CHI C HUM FAC, P1
   Gehrmann S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P96
   Ghosh A, 2018, VIS INFORM, V2, P235, DOI 10.1016/j.visinf.2018.12.004
   Gingerich M, 2015, AAAI CONF ARTIF INTE, P1728
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Google NLP, 2018, US
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631
   Guo JQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4524
   Gur I, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1339
   Haijun Xia, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P722, DOI 10.1145/3379337.3415845
   Li LH, 2019, Arxiv, DOI [arXiv:1908.03557, 10.48550/arXiv.1908.03557]
   Harris C, 2021, Arxiv, DOI arXiv:2103.11297
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P36, DOI [10.1109/VISUAL.2019.8933766, 10.1109/visual.2019.8933766]
   Henkin R., 2020, IEEE T VIS COMPUT GR, V14, P1
   Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320
   Honnibal M., 2017, spaCy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing, DOI DOI 10.3233/978-1-60750-588-4-1080
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Hu K., 2019, PROC EXTENDED ABSTR, P1
   Hu K, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209910
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Huang ZS, 2020, IEEE T VIS COMPUT GR, V26, P1256, DOI 10.1109/TVCG.2019.2934671
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hulsebos M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1500, DOI 10.1145/3292500.3330993
   IBM Watson Analytics, 2014, US
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   Jiang Q., IEEECOMPUT GRAPH APP, V41, P45
   Jiang S, 2022, IEEE REV BIOMED ENG, V15, P85, DOI 10.1109/RBME.2021.3078190
   John RJL, 2018, LECT NOTES COMPUT SC, V11073, P197, DOI 10.1007/978-3-030-00937-3_23
   Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300
   Joshi M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5803
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou S. E., 2018, PROC INT C LEARN REP, P1
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandogan E, 2012, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2012.6400487
   Kang J, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P229, DOI 10.1145/3109859.3109873
   Kassel JF, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1517, DOI 10.1145/3322276.3322282
   Kassel JF, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188445
   Kato T, 2002, PROC INT C COMPUT LI, P1
   Kaur P., 2015, PROC GI WORKSHOP GRU, P30
   Kerpedjiev S, 1997, COMP STAND INTER, V18, P583, DOI 10.1016/S0920-5489(97)00022-6
   Kerracher N, 2017, COMPUT GRAPH FORUM, V36, P47, DOI 10.1111/cgf.13167
   Key A., 2012, ACM, P681
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim D, 2021, PUBLIC HEALTH NURS, V38, P396, DOI 10.1111/phn.12873
   Kim H, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P116, DOI [10.1109/visual.2019.8933773, 10.1109/VISUAL.2019.8933773]
   Kim Y.-H., 2021, PROC EXTENDED ABSTR, P1
   Kim Y, 2021, IEEE T VIS COMPUT GR, V27, P485, DOI 10.1109/TVCG.2020.3030360
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kincaid R, 2017, IEEE INT C SEMANT CO, P196, DOI 10.1109/ICSC.2017.11
   Kirstain Y, 2021, Arxiv, DOI arXiv:2101.00434
   Kocijan V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4837
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Kumar A., 2016, P 17 ANN M SPECIAL I, P304
   Kumar Abhinav, 2017, SEMDIAL 2017 SAARDIA, P41, DOI [10.21437/SemDial.2017-5, DOI 10.21437/SEMDIAL.2017-5]
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lallé S, 2021, IEEE T VIS COMPUT GR, V27, P2941, DOI 10.1109/TVCG.2019.2958540
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Lee B, 2012, IEEE T VIS COMPUT GR, V18, P2689, DOI 10.1109/TVCG.2012.204
   Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751
   Lee DJL, 2021, INT CONF MANAGE DATA, P2750, DOI 10.1145/3448016.3452748
   Lee K, 2018, P 2018 C N AM CHAPT, V2, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]
   Lee K., 2017, P 2017 C EMPIRICAL M, P188, DOI DOI 10.18653/V1/D17-1018
   LeoJohn R. J., 2017, PROC BIENNIAL C INNO, P1
   Li F, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P709, DOI 10.1145/2588555.2594519
   Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468
   Li F, 2016, SIGMOD REC, V45, P6, DOI 10.1145/2949741.2949744
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Li JA, 2019, Arxiv, DOI arXiv:1901.06767
   Li P, 2017, P INT COMP SOFTW APP, P578, DOI 10.1109/COMPSAC.2017.64
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu Q, 2016, Arxiv, DOI arXiv:1611.04146
   Liu T., 2021, PROC EXTENDED ABSTR, P1
   López G, 2018, ADV INTELL SYST, V592, P241, DOI 10.1007/978-3-319-60366-7_23
   Luo YY, 2021, INT CONF MANAGE DATA, P1235, DOI 10.1145/3448016.3457261
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Madan S, 2018, Arxiv, DOI arXiv:1807.10441
   Maji Subhadip, 2021, arXiv
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mathew M., 2021, ARXIV
   Matsushita M, 2004, INT J HUM-COMPUT ST, V60, P469, DOI 10.1016/j.ijhcs.2003.11.004
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Metoyer R., 2012, P ACM C HUMAN FACTOR, P1659
   Metoyer R, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P503, DOI 10.1145/3172944.3173007
   Microsoft Power BI, 2018, US
   Mikolov T., 2013, Efficient Estimation of Word Representations in Vector Space, P1
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mitri M, 2022, J COMPUT INFORM SYST, V62, P216, DOI 10.1080/08874417.2020.1774442
   Mittal VO, 1998, COMPUT LINGUIST, V24, P431
   Moraes P., 2014, Int. Conf. Natural Lang. Gener, P95, DOI DOI 10.3115/V1/W14-4413
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Murillo-Morales Tomas, 2020, Computers Helping People with Special Needs. 17th International Conference, ICCHP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12376), P373, DOI 10.1007/978-3-030-58796-3_44
   Mutlu B, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2983923
   Nafari M, 2013, COMPUT GRAPH FORUM, V32, P391, DOI 10.1111/cgf.12126
   Nafari M, 2015, IEEE T VIS COMPUT GR, V21, P756, DOI 10.1109/TVCG.2015.2396062
   Narechania A, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P597, DOI 10.1145/3397481.3450667
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Nihalani Neelu., 2011, Em: International Journal of Computer Science Issues (IJCSI), V8, P600
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Obeid J., 2020, P 13 INT C NATURAL L, P138, DOI 10.48550/arXiv.2010.09142
   Oppermann M, 2021, IEEE T VIS COMPUT GR, V27, P495, DOI 10.1109/TVCG.2020.3030387
   Özcan F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2629, DOI 10.1145/3318464.3383128
   Peters ME, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1499, DOI 10.5771/9783845286846
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Pradhan S., 2012, P JOINT C EMPIRICAL, P1
   Pustejovsky J., 2003, NEW DIRECTIONS QUEST, V3, P28
   Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Qian X, 2021, Arxiv, DOI arXiv:2102.06343
   Qian X, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1359, DOI 10.1145/3447548.3467224
   Qian X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2792, DOI 10.1145/3442381.3449923
   Qin XD, 2020, VLDB J, V29, P93, DOI 10.1007/s00778-019-00588-3
   Quamar A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P361, DOI 10.1145/3318464.3386139
   Reinders S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376145
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Rind A, 2016, INFORM VISUAL, V15, P288, DOI 10.1177/1473871615621602
   ROTH SF, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P112, DOI 10.1145/191666.191719
   Saha D, 2016, PROC VLDB ENDOW, V9, P1209, DOI 10.14778/2994509.2994536
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seipel P, 2019, 2019 SEVENTH IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION (VISSOFT), P78, DOI 10.1109/VISSOFT.2019.00017
   Sen J, 2019, INT CONF MANAGE DATA, P1997, DOI 10.1145/3299869.3320248
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Setlur Vidya, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P966, DOI 10.1145/3379337.3415813
   Setlur V, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P166, DOI [10.1109/VIS49827.2021.00041, 10.1109/VIS49827.2021.9623324]
   Setlur V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P216, DOI 10.1109/VIS47514.2020.00050
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Sevastjanova R., 2018, PROC VISUALIZATION E, P1
   Shekarpour S, 2015, J WEB SEMANT, V30, P39, DOI 10.1016/j.websem.2014.06.002
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi DQ, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P58, DOI [10.1109/VDS48975.2019.8973383, 10.1109/vds48975.2019.8973383]
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Siddiqui N, 2020, IEEE INT CONF INF VI, P440, DOI 10.1109/IV51561.2020.00077
   Siddiqui T, 2021, SIGMOD REC, V50, P51, DOI 10.1145/3471485.3471498
   Siddiqui T, 2018, PROC VLDB ENDOW, V11, P1962, DOI 10.14778/3229863.3236235
   Sigtia S, 2020, INT CONF ACOUST SPEE, P6844, DOI [10.1109/icassp40776.2020.9054760, 10.1109/ICASSP40776.2020.9054760]
   Simitsis A, 2008, VLDB J, V17, P117, DOI 10.1007/s00778-007-0075-9
   Sinclair S., 1997, SUBSYMBOLIC NATURAL, V73
   Singh H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3275
   Spreafico A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399829
   Srinivasan Arjun, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P864, DOI 10.1145/3472749.3474792
   Srinivasan A., 2017, EUR IEEE VGTC C VIS, P55, DOI 10.2312/eurovisshort.20171133
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   Srinivasan A, 2020, IEEE COMPUT GRAPH, V40, P96, DOI 10.1109/MCG.2020.2986902
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   Srinivasan A, 2019, PROCEEDINGS OF IUI 2019, P661, DOI 10.1145/3301275.3302292
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Steichen B., 2013, P 2013 INT C INT US, P317, DOI [10.1145/2449396.2449439, DOI 10.1145/2449396.2449439]
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Streeb D, 2022, IEEE T VIS COMPUT GR, V28, P3307, DOI 10.1109/TVCG.2020.3045560
   Stylianou N, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114466
   Su WJ, 2020, Arxiv, DOI [arXiv:1908.08530, DOI 10.48550/ARXIV.1908.08530]
   Suhara Y, 2022, Arxiv, DOI arXiv:2104.01785
   Sun YW, 2010, LECT NOTES COMPUT SC, V6133, P184
   Thompson J. R., 2021, P HUM FACT COMP SYST, P1
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Tory M, 2019, IEEE CONF VIS ANAL, P93, DOI [10.1109/VAST47406.2019.8986918, 10.1109/vast47406.2019.8986918]
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   van den Elzen S, 2013, COMPUT GRAPH FORUM, V32, P191, DOI 10.1111/cgf.12106
   vanDam A, 1997, COMMUN ACM, V40, P63, DOI 10.1145/253671.253708
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Vartak M, 2014, PROC VLDB ENDOW, V7, P1581, DOI 10.14778/2733004.2733035
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wang CH, 2021, AAAI CONF ARTIF INTE, V35, P16114
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang WL, 2020, PROC INT CONF DATA, P97, DOI 10.1109/ICDE48307.2020.00016
   Wang YT, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P960, DOI 10.1145/3025453.3025819
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Wang Z., 2020, P HUM FACT COMP SYST, P1
   Wen Z, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P187, DOI 10.1109/INFVIS.2005.1532146
   Wohlgenannt G, 2019, KEOD: PROCEEDINGS OF THE 11TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL 2: KEOD, P473, DOI 10.5220/0008364704730478
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xia Haijun, 2020, P 33 ANN ACM S US IN, P735, DOI DOI 10.1145/3379337.3415882
   Xian YK, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3775, DOI 10.1145/3447548.3467211
   Xu XJ, 2017, Arxiv, DOI arXiv:1711.04436
   Yagcioglu S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1358
   Yaghmazadeh N, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133887
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yu BW, 2017, IEEE T VIS COMPUT GR, V23, P251, DOI 10.1109/TVCG.2016.2598497
   Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zehrung R, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445195
   Zeng ZH, 2022, IEEE T VIS COMPUT GR, V28, P346, DOI 10.1109/TVCG.2021.3114814
   Zhang D, 2020, PROC VLDB ENDOW, V13, P1835, DOI 10.14778/3407790.3407793
   Zhang H., 2020, ARXIV
   Zhang HM, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P867
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zhang Yuchen, 2017, EMNLP 2017 C EMPIRIC, P1214
   Zhang Zhengyan., 2021, arXiv, DOI DOI 10.1016/J.AIOPEN.2021.12.003
   Zheng W., 2017, PROC ACM INT C INFOR, P217
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
   Zhong VC, 2017, Arxiv, DOI arXiv:1709.00103
   Zhou MY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2389, DOI 10.1145/3447548.3467279
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 290
TC 30
Z9 36
U1 9
U2 41
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3121
EP 3144
DI 10.1109/TVCG.2022.3148007
PG 24
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4DZ2
UT WOS:000981880500021
PM 35104221
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Feng, F
   Liu, JY
   Xiong, SY
   Yang, SQ
   Zhang, YR
   Zhu, B
AF Feng, Fan
   Liu, Jinyuan
   Xiong, Shiying
   Yang, Shuqi
   Zhang, Yaorui
   Zhu, Bo
TI Impulse Fluid Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mathematical models; Numerical models; Computational modeling;
   Animation; Surface tension; Computer graphics; Harmonic analysis; Fluid
   simulation; vortical structures; gauge methods; physics-based animation
ID VORTEX; MOTION
AB We propose a new incompressible Navier-Stokes solver based on the impulse gauge transformation. The mathematical model of our approach draws from the impulse-velocity formulation of Navier-Stokes equations, which evolves the fluid impulse as an auxiliary variable of the system that can be projected to obtain the incompressible flow velocities at the end of each time step. We solve the impulse-form equations numerically on a Cartesian grid. At the heart of our simulation algorithm is a novel model to treat the impulse stretching and a harmonic boundary treatment to incorporate the surface tension effects accurately. We also build an impulse PIC/FLIP solver to support free-surface fluid simulation. Our impulse solver can naturally produce rich vortical flow details without artificial enhancements. We showcase this feature by using our solver to facilitate a wide range of fluid simulation tasks including smoke, liquid, and surface-tension flow. In addition, we discuss a convenient mechanism in our framework to control the scale and strength of the turbulent effects of fluid.
C1 [Feng, Fan; Liu, Jinyuan; Xiong, Shiying; Yang, Shuqi; Zhang, Yaorui; Zhu, Bo] Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.
C3 Dartmouth College
RP Feng, F (corresponding author), Dartmouth Coll, Dept Comp Sci, Hanover, NH 03755 USA.
EM fan.feng.gr@dartmouth.edu; Jinyuan.Liu.GR@dartmouth.edu;
   shiying.xiong@dartmouth.edu; shuqi.yang.98@gmail.com;
   yaoruizh1997@gmail.com; bo.zhu@dartmouth.edu
RI Xiong, Shiying/AAD-9938-2022; Liu, Jinyuan/GNP-2535-2022
OI Feng, Fan/0000-0002-4265-1763; Xiong, Shiying/0000-0002-0468-4249
FU NSF [HCC-2106733, MRI-1919647]
FX This work was supported by NSF under Grants HCC-2106733 and MRI-1919647
CR Angelidis A, 2005, P 2005 ACM SIGGRAPH, P87, DOI [10.1145/1073368.1073380, DOI 10.1145/1073368.1073380]
   [Anonymous], 2005, Natural Phenomena 2005, DOI DOI 10.2312/NPH/NPH05/051-056
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Bridson R., 2015, Fluid simulation for computer graphics
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Brochu Tyson, 2012, S COMPUTER ANIMATION, P87
   BUTTKE TF, 1993, APPL NUMER MATH, V12, P47, DOI 10.1016/0168-9274(93)90111-4
   BUTTKE TF, 1993, NATO ADV SCI INST SE, V395, P39
   Chern A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925868
   Cortez R, 1998, SIAM J SCI COMPUT, V19, P1290, DOI 10.1137/S1064827595293570
   Cortez R, 1996, J COMPUT PHYS, V123, P341, DOI 10.1006/jcph.1996.0028
   Cortez R, 2000, J COMPUT PHYS, V160, P385, DOI 10.1006/jcph.2000.6474
   Cortez R., 1995, THESIS U CALIFORNIA
   Cottet G.H., 2000, Vortex Methods: Theory and Practice, V8
   E W, 1997, J COMPUT PHYS, V130, P67, DOI 10.1006/jcph.1996.5537
   Elcott S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1189762.1189766
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Fu CY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130878
   Gamito M. N., 1995, Computer Animation and Simulation '95. Proceedings of the Eurographics Workshop, P3
   Jiang C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766996
   Kim D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618466
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Koumoutsakos P., 2008, SIGGRAPH 2008 35 INT, P1, DOI DOI 10.1145/1401132.1401166
   KUZMIN GA, 1983, PHYS LETT A, V96, P88, DOI 10.1016/0375-9601(83)90597-2
   Lai MC, 2000, J COMPUT PHYS, V160, P705, DOI 10.1006/jcph.2000.6483
   LEONARD A, 1980, J COMPUT PHYS, V37, P289, DOI 10.1016/0021-9991(80)90040-6
   Liu M, 2004, J COMPUT PHYS, V200, P325, DOI 10.1016/j.jcp.2004.04.006
   MADDOCKS JH, 1995, COMMUN MATH PHYS, V170, P207, DOI 10.1007/BF02099446
   MOIN P, 1986, PHYS FLUIDS, V29, P955, DOI 10.1063/1.865690
   Mullen P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531344
   OSELEDETS VI, 1989, RUSS MATH SURV+, V44, P210, DOI 10.1070/RM1989v044n03ABEH002122
   Padilla M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322962
   Park Sang Il, 2005, S COMPUTER ANIMATION, P261
   Pfaff T, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185608
   Qu ZY, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322945
   ROBERTS PH, 1972, MATHEMATIKA, V19, P169, DOI 10.1112/S0025579300005611
   Rogallo R, 1981, NASA technical memorandum
   Saye R, 2017, J COMPUT PHYS, V344, P683, DOI 10.1016/j.jcp.2017.05.003
   Saye R, 2017, J COMPUT PHYS, V344, P647, DOI 10.1016/j.jcp.2017.04.076
   Saye R, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1501869
   Selle A, 2005, ACM T GRAPHIC, V24, P910, DOI 10.1145/1073204.1073282
   Selle A, 2008, J SCI COMPUT, V35, P350, DOI 10.1007/s10915-007-9166-4
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stock MJ, 2008, J COMPUT PHYS, V227, P9021, DOI 10.1016/j.jcp.2008.05.022
   Summers DM, 1996, P NATL ACAD SCI USA, V93, P1881, DOI 10.1073/pnas.93.5.1881
   Summers DM, 2000, J COMPUT PHYS, V158, P28, DOI 10.1006/jcph.1999.6404
   Gagniere SW, 2020, Arxiv, DOI arXiv:2003.12227
   Weissmann S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778852
   Winckelmans G. S., 2004, ENCY COMPUTATIONAL M, V3, P129
   Yang SQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459866
   Zhang XX, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766982
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
NR 53
TC 6
Z9 6
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN 1
PY 2023
VL 29
IS 6
BP 3081
EP 3092
DI 10.1109/TVCG.2022.3149466
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA F4VV4
UT WOS:000982351900001
PM 35133965
DA 2024-11-06
ER

PT J
AU Li, L
   Fu, HB
   Ovsjanikov, M
AF Li, Lei
   Fu, Hongbo
   Ovsjanikov, Maks
TI WSDesc: Weakly Supervised 3D Local Descriptor Learning for Point Cloud
   Registration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Point cloud compression; Training; Geometry;
   Feature extraction; Rigidity; Data mining; Point cloud; 3D local
   descriptor; geometric registration; differentiable voxelization; 3D CNN;
   weak supervision
ID UNIQUE SIGNATURES; HISTOGRAMS; SURFACE
AB In this work, we present a novel method called WSDesc to learn 3D local descriptors in a weakly supervised manner for robust point cloud registration. Our work builds upon recent 3D CNN-based descriptor extractors, which leverage a voxel-based representation to parameterize local geometry of 3D points. Instead of using a predefined fixed-size local support in voxelization, we propose to learn the optimal support in a data-driven manner. To this end, we design a novel differentiable voxelization layer that can back-propagate the gradient to the support size optimization. To train the extracted descriptors, we propose a novel registration loss based on the deviation from rigidity of 3D transformations, and the loss is weakly supervised by the prior knowledge that the input point clouds have partial overlap, without requiring ground-truth alignment information. Through extensive experiments, we show that our learned descriptors yield superior performance on existing geometric registration benchmarks.
C1 [Li, Lei; Ovsjanikov, Maks] Ecole Polytech, IP Paris, LIX, F-91764 Palaiseau, France.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Institut Polytechnique de Paris; Ecole Polytechnique; City University of
   Hong Kong
RP Fu, HB (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM lli@lix.polytechnique.fr; hongbofu@cityu.edu.hk;
   maks@lix.polytechnique.fr
OI FU, Hongbo/0000-0002-0284-726X; Li, Lei/0000-0002-4657-4718
FU ERC [758800]; ANR AI Chair AIGRETTE; City University of Hong Kong
   [7005729]
FX This work was supported in part by the ERC Starting under Grant
   758800(EXPROTEA), the ANR AI Chair AIGRETTE, and City University of Hong
   Kong under Grant 7005729.
CR Ao S, 2021, PROC CVPR IEEE, P11748, DOI 10.1109/CVPR46437.2021.01158
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Bai XY, 2021, PROC CVPR IEEE, P15854, DOI 10.1109/CVPR46437.2021.01560
   Bai XY, 2020, PROC CVPR IEEE, P6358, DOI 10.1109/CVPR42600.2020.00639
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   Cohen T. S., 2018, PROC INT C LEARNING
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2019, PROC CVPR IEEE, P3239, DOI 10.1109/CVPR.2019.00336
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Deng Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6118, DOI 10.1109/ICCV48922.2021.00608
   Esteves C, 2018, LECT NOTES COMPUT SC, V11217, P54, DOI 10.1007/978-3-030-01261-8_4
   Feng WQ, 2021, PROC CVPR IEEE, P10292, DOI 10.1109/CVPR46437.2021.01016
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Gojcic Z, 2020, PROC CVPR IEEE, P1756, DOI 10.1109/CVPR42600.2020.00183
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Golub G.H., 2013, Matrix Computations, V4th, DOI 10.56021/9781421407944
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Hermans A, 2017, Arxiv, DOI arXiv:1703.07737
   Huang HB, 2018, ACM T GRAPHIC, V37, DOI [10.1145/3137609, 10.1145/3072959.3073654]
   Huang SY, 2021, PROC CVPR IEEE, P4265, DOI 10.1109/CVPR46437.2021.00425
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Juan Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P744, DOI 10.1007/978-3-030-58548-8_43
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26
   Kingma D. P., 2015, P INT C LEARN REPR
   Lawin FJ, 2020, INT CONF 3D VISION, P563, DOI 10.1109/3DV50981.2020.00066
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Li L, 2020, PROC CVPR IEEE, P1916, DOI 10.1109/CVPR42600.2020.00199
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0
   Pais GD, 2020, PROC CVPR IEEE, P7191, DOI 10.1109/CVPR42600.2020.00722
   Paszke A, 2019, ADV NEUR IN, V32
   Plotz Tobias, 2018, P 32 INT C NEURAL IN, P1095
   Poiesi F, 2021, INT C PATT RECOG, P5720, DOI 10.1109/ICPR48806.2021.9411978
   Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Roufosse JM, 2019, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2019.00170
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Saining Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P574, DOI 10.1007/978-3-030-58580-8_34
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Spezialetti Riccardo, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P6400, DOI 10.1109/ICCV.2019.00650
   Spezialetti R., 2020, NEURIPS, P5381
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI [10.1145/1877808.1877821, DOI 10.1145/1877808.1877821]
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang Y, 2019, 33 C NEURAL INFORM P, V32
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wentao Yuan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P733, DOI 10.1007/978-3-030-58558-7_43
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiaoshui Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11363, DOI 10.1109/CVPR42600.2020.01138
   Xu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3112, DOI 10.1109/ICCV48922.2021.00312
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Yang H, 2021, PROC CVPR IEEE, P14345, DOI 10.1109/CVPR46437.2021.01412
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yang JQ, 2017, PATTERN RECOGN, V65, P175, DOI 10.1016/j.patcog.2016.11.019
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yew ZJ, 2020, PROC CVPR IEEE, P11821, DOI 10.1109/CVPR42600.2020.01184
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 78
TC 10
Z9 10
U1 4
U2 29
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3368
EP 3379
DI 10.1109/TVCG.2022.3160005
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900016
PM 35294352
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Velinov, Z
   Mitchell, K
AF Velinov, Zdravko
   Mitchell, Kenny
TI Collimated Whole Volume Light Scattering in Homogeneous Finite Media
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geometry; Cameras; Scattering; Rendering (computer graphics); Real-time
   systems; Monte Carlo methods; Light sources; Raytracing; color; shading;
   shadowing; texture
ID TRANSPORT; MODEL
AB Crepuscular rays form when light encounters an optically thick or opaque medium which masks out portions of the visible scene. Real-time applications commonly estimate this phenomena by connecting paths between light sources and the camera after a single scattering event. We provide a set of algorithms for solving integration and sampling of single-scattered collimated light in a box-shaped medium and show how they extend to multiple scattering and convex media. First, a method for exactly integrating the unoccluded single scattering in rectilinear box-shaped medium is proposed and paired with a ratio estimator and moment-based approximation. Compared to previous methods, it requires only a single sample in unoccluded areas to compute the whole integral solution and provides greater convergence in the rest of the scene. Second, we derive an importance sampling scheme accounting for the entire geometry of the medium. This sampling strategy is then incorporated in an optimized Monte Carlo integration. The resulting integration scheme yields visible noise reduction and it is directly applicable to indoor scene rendering in room-scale interactive experiences. Furthermore, it extends to multiple light sources and achieves superior converge compared to independent sampling with existing algorithms. We validate our techniques against previous methods based on ray marching and distance sampling to prove their superior noise reduction capability.
C1 [Velinov, Zdravko] Disney Res Angeles, Glendale, CA 91201 USA.
   [Mitchell, Kenny] Edinburgh Napier Univ & Roblox Corp, Disney Res Angeles, San Mateo, CA 94403 USA.
RP Velinov, Z (corresponding author), Disney Res Angeles, Glendale, CA 91201 USA.
EM z.velinov@3dgraphics.guru; k.mitchell2@napier.ac.uk
RI Mitchell, Kenny/AAZ-3421-2020
OI Mitchell, Kenny/0000-0003-2420-7447
CR Afra A. T., 2016, P ACM SIGGRAPH 2016, P1
   Annen T., 2007, P 18 EUR C REND TECH, V18, P51, DOI [10.2312/EGWR/EGSR07/, DOI 10.2312/EGWR/EGSR07/051-060]
   [Anonymous], 2017, J COMPUT GRAPH TECHN
   Baran I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866200
   Bitterli B, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073698
   Cerezo E, 2005, VISUAL COMPUT, V21, P303, DOI 10.1007/s00371-005-0287-1
   Chandrasekhar S., 1960, Radiative Transfer
   Chen J., 2011, Symposium on Interactive 3D Graphics and Games, I3D 2011, P39, DOI [10.1145/1944745.1944752, DOI 10.1145/1944745.1944752]
   Deng X, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323041
   DOBASHI Y., 2002, GRAPHICS HARDWARE, P99
   Engelhardt T., 2010, Proceedings_of_the_2010_ ACM_SIGGRAPH_symposium_on_Interactive_3D_Graphics_and_Games, P119
   Georgiev I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508411
   Heitz E, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190852
   Hillaire S, 2020, COMPUT GRAPH FORUM, V39, P13, DOI 10.1111/cgf.14050
   Hoffman N., 2003, GRAPHICS PROGRAMMING, P337
   Jarosz W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899409
   Jensen H. W., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P311, DOI 10.1145/280814.280925
   Jimenez J.-R., 2005, PROC 21 SPRING C COM, P211
   Klehm O., 2014, J COMPUT GRAPH TECHN, V3, P7
   Kulla C, 2012, COMPUT GRAPH FORUM, V31, P1519, DOI 10.1111/j.1467-8659.2012.03148.x
   Lafortune E. P., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P91
   Laine Samuli, 2013, P 5 HIGH PERF GRAPH, P137, DOI [10.1145/2492045.2492060, DOI 10.1145/2492045.2492060]
   Max N. L., 1986, Computer Graphics, V20, P117, DOI 10.1145/15886.15899
   MITCHELL K., 2007, GPU GEMS, P275
   Moro Y., 2006, FAST RENDERING METHO
   Muñoz A, 2014, COMPUT GRAPH FORUM, V33, P167, DOI 10.1111/cgf.12424
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Novák J, 2018, COMPUT GRAPH FORUM, V37, P551, DOI 10.1111/cgf.13383
   Pauly M, 2000, SPRING COMP SCI, P11
   PEGORARO V., 2011, P 37 GRAPHICS INTERF, P151
   Perlin K., 1989, Computer Graphics, V23, P253, DOI 10.1145/74334.74359
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd
   Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545
   Ren Z, 2008, COMPUT GRAPH FORUM, V27, P1945, DOI 10.1111/j.1467-8659.2008.01343.x
   Shirley P., 1994, PHOTOREALISTIC RENDE
   Sun B, 2005, ACM T GRAPHIC, V24, P1040, DOI 10.1145/1073204.1073309
   Toth B., 2009, P EUR SHORT PAP EG, DOI [10.2312/egs.20091048.057-060, DOI 10.2312/EGS.20091048.057-060]
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Vorba J., 2019, ACM SIGGRAPH 2019 Courses, DOI [DOI 10.1145/3305366.3328091, 10.1145/3305366.3328091]
   Wyman C, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P87, DOI 10.1109/RT.2008.4634627
   Wyman Chris, 2013, ACM SIGGRAPH 2013 TA, P45
   Wyman Chris, 2011, PROC ACM SIGGRAPH S, P33
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360635
   Zwicker M, 2015, COMPUT GRAPH FORUM, V34, P667, DOI 10.1111/cgf.12592
NR 44
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3145
EP 3157
DI 10.1109/TVCG.2021.3135764
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900001
PM 35171772
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Zheng, YY
   Chen, BJ
   Shen, YF
   Shen, KD
AF Zheng, Youyi
   Chen, Beijia
   Shen, Yuefan
   Shen, Kaidi
TI TeethGNN: Semantic 3D Teeth Segmentation With Graph Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teeth; Feature extraction; Three-dimensional displays; Semantics; Image
   segmentation; Deep learning; Representation learning; 3D Teeth
   segmentation; graph neural network; geometric deep learning; clustering
ID TOOTH SEGMENTATION
AB In this paper, we present TeethGNN, a novel 3D tooth segmentation method based on graph neural networks (GNNs). Given a mesh-represented 3D dental model in non-euclidean domain, our method outputs accurate and fine-grained separation of each individual tooth robust to scanning noise, foreign matters (e.g., bubbles, dental accessories, etc.), and even severe malocclusion. Unlike previous CNN-based methods that bypass handling non-euclidean mesh data by reshaping hand-crafted geometric features into regular grids, we explore the non-uniform and irregular structure of mesh itself in its dual space and exploit graph neural networks for effective geometric feature learning. To address the crowded teeth issues and incomplete segmentation that commonly exist in previous methods, we design a two-branch network, one of which predicts a segmentation label for each facet while the other regresses each facet an offset away from its tooth centroid. Clustering are later conducted on offset-shifted locations, enabling both the separation of adjoining teeth and the adjustment of incompletely segmented teeth. Exploiting GNN for directly processing mesh data frees us from extracting hand-crafted feature, and largely speeds up the inference procedure. Extensive experiments have shown that our method achieves the new state-of-the-art results for teeth segmentation and outperforms previous methods both quantitatively and qualitatively.
C1 [Zheng, Youyi; Chen, Beijia; Shen, Yuefan] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Peoples R China.
   [Shen, Kaidi] Hangzhou Choho Tech Co Ltd, Hangzhou 310030, Peoples R China.
C3 Zhejiang University
RP Shen, KD (corresponding author), Hangzhou Choho Tech Co Ltd, Hangzhou 310030, Peoples R China.
EM youyizheng@zju.edu.cn; beibeijia@zju.edu.cn; jhonve@zju.edu.cn;
   kd_shen@outlook.com
RI Shen, Yuefan/GWN-0324-2022
OI Shen, Yuefan/0000-0002-6049-7966; Shen, Kaidi/0000-0002-9367-3911
FU National Key Research & Development Program of China [2018YFE0100900]
FX This work was supported by the National Key Research & Development
   Program of China under Grant 2018YFE0100900.
CR BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Boscaini D, 2016, ADV NEUR IN, V29
   Brock A, 2016, Arxiv, DOI [arXiv:1608.04236, 10.48550/arXiv.1608.04236]
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Ester M., 1996, P KDD, P226
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   Jiang L, 2020, PROC CVPR IEEE, P4866, DOI 10.1109/CVPR42600.2020.00492
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kondo T, 2004, IEEE T MED IMAGING, V23, P350, DOI 10.1109/TMI.2004.824235
   Li YY, 2018, ADV NEUR IN, V31
   Li ZL, 2007, 2007 IEEE/ICME INTERNATIONAL CONFERENCE ON COMPLEX MEDICAL ENGINEERING, VOLS 1-4, P163, DOI 10.1109/ICCME.2007.4381713
   Ma Yaqi, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P336, DOI 10.1109/IASP.2010.5476100
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Paszke A, 2019, ADV NEUR IN, V32
   Qi CR, 2017, Arxiv, DOI arXiv:1706.02413
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Schult J, 2020, PROC CVPR IEEE, P8609, DOI 10.1109/CVPR42600.2020.00864
   Sinthanayothin C, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P81, DOI 10.1109/ECTICON.2008.4600377
   Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wongwaen N., 2010, 2010 International Conference on Electronics and Information Engineering (ICEIE 2010), P277, DOI 10.1109/ICEIE.2010.5559877
   Wu K, 2014, COMPUT GRAPH-UK, V38, P199, DOI 10.1016/j.cag.2013.10.028
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu K., 2018, arXiv
   Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685
   Yamany SM, 1999, PROC SPIE, V3640, P115, DOI 10.1117/12.341053
   Yokesh K., 2011, Computer Aided Design and Applications, V8, P211, DOI DOI 10.3722/CADAPS.2011.211-224
   Yuan T., 2010, INT J BIOMED IMAG, V2010, P1
   Zhao MX, 2005, P ANN INT IEEE EMBS, P654
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
NR 36
TC 15
Z9 15
U1 5
U2 48
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3158
EP 3168
DI 10.1109/TVCG.2022.3153501
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900002
PM 35196239
DA 2024-11-06
ER

PT J
AU Song, SC
   Li, CH
   Sun, YJ
   Wang, CB
AF Song, Sicheng
   Li, Chenhui
   Sun, Yujing
   Wang, Changbo
TI VividGraph: Learning to Extract and Redesign Network Graphs From
   Visualization Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data mining; Semantics; Image color analysis; Image segmentation; Data
   visualization; Pipelines; Image edge detection; Information
   visualization; network graph; data extraction; chart recognition;
   semantic segmentation; redesign
AB Network graphs are common visualization charts. They often appear in the form of bitmaps in articles, web pages, magazine prints, and designer sketches. People often want to modify graphs because of their poor design, but it is difficult to obtain their underlying data. In this article, we present VividGraph, a pipeline for automatically extracting and redesigning graphs from static images. We propose using convolutional neural networks to solve the problem of graph data extraction. Our method is robust to hand-drawn graphs, blurred graph images, and large graph images. We also present a graph classification module to make it effective for directed graphs. We propose two evaluation methods to demonstrate the effectiveness of our approach. It can be used to quickly transform designer sketches, extract underlying data from existing graphs, and interactively redesign poorly designed graphs.
C1 [Song, Sicheng; Li, Chenhui; Sun, Yujing; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
C3 East China Normal University
RP Li, CH; Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
EM clare.song@foxmail.com; chli@cs.ecnu.edu.cn; syjing2017@163.com;
   cbwang@cs.ecnu.edu.cn
RI Li, Chenhui/AAR-3682-2020; Wang, Zhen/KCL-5193-2024; Lu,
   Xin/KHW-8570-2024
OI Li, Chenhui/0000-0001-9835-2650; Wang, Changbo/0000-0001-8940-6418;
   Song, Sicheng/0000-0002-2158-0353
FU NSFC [61802128, 62072183]
FX This work was supported by the NSFC under Grants 61802128 and 62072183.
CR Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   [Anonymous], Web Content Accessibility Guidelines 1.0 W3C Recommendation 5-May-1999
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Berlingerio M, 2012, Arxiv, DOI [arXiv:1209.2684, 10.48550/arXiv.1209.2684, DOI 10.48550/ARXIV.1209.2684]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Brynjolfsson E, 2016, AM ECON REV, V106, P133, DOI 10.1257/aer.p20161016
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chollet F., 2015, KERAS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Flower A, 2016, BEHAV MODIF, V40, P396, DOI 10.1177/0145445515616105
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Gross A, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-219
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirsch C., 2009, P WORKSH VIS INT SOC, P11
   Itoh T, 2009, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2009.4906846
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai C., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leijnen S., 2020, PROCEEDINGS, V47, P9, DOI [10.3390/proceedings2020047009, DOI 10.3390/PROCEEDINGS2020047009]
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Liu Y, 2013, PROC SPIE, V8654, DOI 10.1117/12.2008467
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Marin F., 2017, arXiv
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Palmer SE, 2013, ANNU REV PSYCHOL, V64, P77, DOI 10.1146/annurev-psych-120710-100504
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang YF, 2017, AER ADV ENG RES, V112, P12
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wattenberg M, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P110, DOI 10.1109/INFVIS.2002.1173155
   Yang J., 2007, P INT WORKSH WORKSH, P197
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Yuan Li, 2021, arXiv preprint arXiv:2106.13112
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou FF, 2021, J VISUAL-JAPAN, V24, P419, DOI 10.1007/s12650-020-00702-6
NR 57
TC 5
Z9 6
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3169
EP 3181
DI 10.1109/TVCG.2022.3153514
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900003
PM 35196240
DA 2024-11-06
ER

PT J
AU Hu, P
   Boorboor, S
   Marino, J
   Kaufman, AE
AF Hu, Ping
   Boorboor, Saeed
   Marino, Joseph
   Kaufman, Arie E.
TI Geometry-Aware Planar Embedding of Treelike Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Data visualization; Topology; Shape;
   Skeleton; Cameras; Morphology; Geometry-based techniques; camera view
   generation; planar embedding; biomedical visualization
ID VISUALIZATION; TOOL
AB The growing complexity of spatial and structural information in 3D data makes data inspection and visualization a challenging task. We describe a method to create a planar embedding of 3D treelike structures using their skeleton representations. Our method maintains the original geometry, without overlaps, to the best extent possible, allowing exploration of the topology within a single view. We present a novel camera view generation method which maximizes the visible geometric attributes (segment shape and relative placement between segments). Camera views are created for individual segments and are used to determine local bending angles at each node by projecting them to 2D. The final embedding is generated by minimizing an energy function (the weights of which are user adjustable) based on branch length and the 2D angles, while avoiding intersections. The user can also interactively modify segment placement within the 2D embedding, and the overall embedding will update accordingly. A global to local interactive exploration is provided using hierarchical camera views that are created for subtrees within the structure. We evaluate our method both qualitatively and quantitatively and demonstrate our results by constructing planar visualizations of line data (traced neurons) and volume data (CT vascular and bronchial data).
C1 [Hu, Ping; Boorboor, Saeed; Marino, Joseph; Kaufman, Arie E.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University
RP Kaufman, AE (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM pihu@cs.stonybrook.edu; sboorboor@cs.stonybrook.edu;
   jmarino@cs.stonybrook.edu; ari@cs.stonybrook.edu
RI Boorboor, Saeed/ABI-7739-2020
OI Kaufman, Arie/0000-0002-0796-6196; Boorboor, Saeed/0000-0001-6644-5983
FU NSF [CNS1650499, OAC1919752, ICER1940302, IIS2107224]
FX This work was supported by NSF under Grants CNS1650499, OAC1919752,
   ICER1940302, and IIS2107224.
CR Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Angelelli P, 2011, IEEE T VIS COMPUT GR, V17, P2063, DOI 10.1109/TVCG.2011.235
   [Anonymous], 2006, P ACM S SOL PHYS MOD
   Apilla V., 2021, PROC EURO GRAPH WORK, P101
   Arbel T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P248, DOI 10.1109/ICCV.1999.791227
   Auzinger T, 2013, IEEE T VIS COMPUT GR, V19, P2858, DOI 10.1109/TVCG.2013.215
   Bartroli AV, 2001, IEEE VISUAL, P411, DOI 10.1109/VISUAL.2001.964540
   Biasotti S, 2008, MATH VIS, P145, DOI 10.1007/978-3-540-33265-7_5
   Bitter I, 2001, IEEE T VIS COMPUT GR, V7, P195, DOI 10.1109/2945.942688
   Bonaventura X, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20050370
   Boorboor S, 2023, IEEE T VIS COMPUT GR, V29, P1625, DOI 10.1109/TVCG.2021.3127132
   Boorboor S, 2019, IEEE T VIS COMPUT GR, V25, P1018, DOI 10.1109/TVCG.2018.2864852
   Bordoloi UD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P487
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Brown KM, 2011, NEUROINFORMATICS, V9, P143, DOI 10.1007/s12021-010-9095-5
   Clerc M, 2010, PARTICLE SWARM OPTIM, V93
   Eulzer P., 2021, EUROGRAPHICS WORKSHO, P79, DOI [DOI 10.2312/VCBM.20211347, 10.2312/vcbm.202113478, DOI 10.2312/VCBM.202113478]
   Feixas M, 1999, COMPUT GRAPH FORUM, V18, pC95, DOI 10.1111/1467-8659.00331
   Feixas M., 2002, THESIS POLYTECH U CA
   Feixas M, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1462055.1462056
   Feragen A., 2011, 2011 IEEE International Conference on Computer Vision (ICCV 2011), P736, DOI 10.1109/ICCV.2011.6126311
   Feragen A, 2011, LECT NOTES COMPUT SC, V6493, P160
   Ghahremani P, 2022, IEEE T VIS COMPUT GR, V28, P4951, DOI 10.1109/TVCG.2021.3109460
   Hahn HK, 2001, IEEE VISUAL, P395, DOI 10.1109/VISUAL.2001.964538
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hu P, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356490
   Jamian JJ, 2014, J APPL MATH, DOI 10.1155/2014/329193
   Ji GF, 2006, IEEE T VIS COMPUT GR, V12, P1109, DOI 10.1109/TVCG.2006.137
   KAMADA T, 1988, COMPUT VISION GRAPH, V41, P43, DOI 10.1016/0734-189X(88)90116-8
   Kanitsar A, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P37, DOI 10.1109/VISUAL.2002.1183754
   Kanitsar A, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P43, DOI 10.1109/VISUAL.2003.1250353
   Kanitsar A., 2006, Scientific Visualization: The Visual Extraction of Knowledge from Data, P207, DOI DOI 10.1007/3-540-30790-7_13
   Kreiser J, 2018, COMPUT GRAPH FORUM, V37, P597, DOI 10.1111/cgf.13445
   Laidlaw DH, 2005, IEEE T VIS COMPUT GR, V11, P59, DOI 10.1109/TVCG.2005.4
   Lee Noah, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P1073
   Liang Z, 2009, IFMBE PROC, V25, P322, DOI 10.1007/978-3-642-03904-1_90
   Lichtenberg N, 2020, COMPUT GRAPH FORUM, V39, P497, DOI 10.1111/cgf.13888
   Lichtenberg Nils., 2019, VCBM, P265
   Marino J, 2016, IEEE T VIS COMPUT GR, V22, P906, DOI 10.1109/TVCG.2015.2467413
   Meuschke M., 2017, BILDVERARBEITUNG FUE, P352, DOI [DOI 10.1007/978366254345079, DOI 10.1007/978-3-662-54345-079]
   Mistelbauer G, 2013, COMPUT GRAPH FORUM, V32, P231, DOI 10.1111/cgf.12110
   Mistelbauer G, 2012, IEEE PAC VIS SYMP, P233, DOI 10.1109/PacificVis.2012.6183596
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   ONO H, 1988, PERCEPTION, V17, P255, DOI 10.1068/p170255
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   Preim B, 2016, COMPUT GRAPH FORUM, V35, P501, DOI 10.1111/cgf.12927
   Secord A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019628
   Sporns O, 2005, PLOS COMPUT BIOL, V1, P245, DOI 10.1371/journal.pcbi.0010042
   Stoev SL, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P545, DOI 10.1109/VISUAL.2002.1183826
   Takahashi S, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P495
   Tao J, 2016, COMPUT GRAPH-UK, V59, P79, DOI 10.1016/j.cag.2016.05.024
   Tory M, 2007, IEEE T VIS COMPUT GR, V13, P1262, DOI 10.1109/TVCG.2007.70596
   Vazquez P.-P., 2001, Vision, Modeling, and Visualization 2001. Proceedings, P273
   Won JH, 2013, IEEE T VIS COMPUT GR, V19, P81, DOI 10.1109/TVCG.2012.25
   Won JH, 2009, MED PHYS, V36, P5245, DOI 10.1118/1.3243866
   Zhu L, 2005, IEEE T MED IMAGING, V24, P191, DOI 10.1109/TMI.2004.839368
NR 56
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3182
EP 3194
DI 10.1109/TVCG.2022.3153871
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900004
PM 35213310
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kwon, OH
   Kao, CH
   Chen, CH
   Ma, KL
AF Kwon, Oh-Hyun
   Kao, Chiun-How
   Chen, Chun-houh
   Ma, Kwan-Liu
TI A Deep Generative Model for Reordering Adjacency Matrices
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sorting; Data visualization; Neural networks; Computational modeling;
   Training; Computer architecture; Stochastic processes; Graph
   visualization; matrix visualization; machine learning; deep generative
   model; visualization interface
ID VISUALIZATION; ORGANIZATION; ASSIGNMENT; SYSTEM
AB Depending on the node ordering, an adjacency matrix can highlight distinct characteristics of a graph. Deriving a "proper" node ordering is thus a critical step in visualizing a graph as an adjacency matrix. Users often try multiple matrix reorderings using different methods until they find one that meets the analysis goal. However, this trial-and-error approach is laborious and disorganized, which is especially challenging for novices. This paper presents a technique that enables users to effortlessly find a matrix reordering they want. Specifically, we design a generative model that learns a latent space of diverse matrix reorderings of the given graph. We also construct an intuitive user interface from the learned latent space by creating a map of various matrix reorderings. We demonstrate our approach through quantitative and qualitative evaluations of the generated reorderings and learned latent spaces. The results show that our model is capable of learning a latent space of diverse matrix reorderings. Most existing research in this area generally focused on developing algorithms that can compute "better" matrix reorderings for particular circumstances. This paper introduces a fundamentally new approach to matrix visualization of a graph, where a machine learning model learns to generate diverse matrix reorderings of a graph.
C1 [Kwon, Oh-Hyun; Ma, Kwan-Liu] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Kao, Chiun-How] Tamkang Univ, Dept Stat, New Taipei City 251301, Taiwan.
   [Chen, Chun-houh] Acad Sinica, Inst Stat Sci, Taipei 11529, Taiwan.
C3 University of California System; University of California Davis; Tamkang
   University; Academia Sinica - Taiwan
RP Kwon, OH (corresponding author), Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
EM kw@ucdavis.edu; 157294@mail.tku.edu.tw; cchen@stat.sinica.edu.tw;
   ma@cs.ucdavis.edu
RI Kwon, Oh-Hyun/V-8085-2019
OI Ma, Kwan-Liu/0000-0001-8086-0366; Kao, Chiun-How/0000-0001-6735-0441
FU U.S. National Science Foundation [IIS-1741536]
FX This work was supported in part by the U.S. National Science Foundation
   under Grant IIS-1741536.
CR [Anonymous], 1971, Mathematics in the Archaeeological and Historical Sciences
   Ba J.L., 2016, arXiv, DOI DOI 10.48550/ARXIV.1607.06450
   Bar-Joseph Z., 2001, BIOINFORMATICS S1, V17 Suppl 1, pS22, DOI [10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Barabasi AL, 2016, NETWORK SCIENCE, P1
   BARNARD ST, 1993, SUPERCOMP PROC, P493
   Behrisch M, 2020, IEEE T VIS COMPUT GR, V26, P184, DOI 10.1109/TVCG.2019.2934300
   Behrisch M, 2017, IEEE T VIS COMPUT GR, V23, P31, DOI 10.1109/TVCG.2016.2598467
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Bezdek JC, 2002, IEEE IJCNN, P2225, DOI 10.1109/IJCNN.2002.1007487
   Brock A, 2019, Arxiv, DOI arXiv:1809.11096
   Brusco MJ, 2008, PSYCHOMETRIKA, V73, P503, DOI 10.1007/s11336-007-9049-5
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Caraux G, 2005, BIOINFORMATICS, V21, P1280, DOI 10.1093/bioinformatics/bti141
   Chen CH, 2002, STAT SINICA, V12, P7
   Clevert D.A., 2016, P INT C LEARN REPR S, P1
   Climer S, 2006, J MACH LEARN RES, V7, P919
   Dhariwal P, 2020, Arxiv, DOI arXiv:2005.00341
   Ding C., 2004, K MEANS CLUSTERING V
   Earle D, 2015, J COMPUT GRAPH STAT, V24, P1, DOI 10.1080/10618600.2013.874295
   Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863
   Engel J., 2019, PROC INT C LEARN REP
   Gleiser PM, 2003, ADV COMPLEX SYST, V6, P565, DOI 10.1142/S0219525903001067
   Goodfellow L., 2014, ADV NEUR IN, V2, P2672, DOI DOI 10.1145/3422622
   Grover A., 2019, PROC INT C LEARN REP
   GRUVAEUS G, 1972, BRIT J MATH STAT PSY, V25, P200, DOI 10.1111/j.2044-8317.1972.tb00491.x
   Guu Kelvin, 2018, Transactions of the Association for Computational Linguistics, V6, P437, DOI 10.1162/tacl_a_00030
   Hahsler M, 2017, EUR J OPER RES, V257, P133, DOI 10.1016/j.ejor.2016.08.066
   Hahsler M, 2008, J STAT SOFTW, V25, P1
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   HUBERT L, 1976, BRIT J MATH STAT PSY, V29, P190, DOI 10.1111/j.2044-8317.1976.tb00714.x
   Ioffe Sergey, 2015, P MACHINE LEARNING R, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kingma D.P., 2014, P INT C LEARNING REP
   Kolouri S., 2019, PROC INT C LEARN REP
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kunegis J, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1343
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leskovec J., 2012, ADV NEURAL INFORM PR, V25
   Leskovec J, 2014, SNAP Datasets: Stanford large network dataset collection, DOI DOI 10.18637/JSS.V024.I04
   Liiv Innar, 2010, Statistical Analysis and Data Mining, V3, P70, DOI 10.1002/sam.10071
   Mena G. E, 2018, PROC INT C LEARN REP
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Paszke A., 2017, P NIPS WORKSH
   Petit Jordi, 2003, ACM J. Exp. Algorithmics, V8, P2, DOI DOI 10.1145/996546.9965542
   Prillo S., 2020, P MACHINE LEARNING R, V119, P7793
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, 10.48550/ARXIV.1511.06434]
   Ramachandran P, 2019, ADV NEUR IN, V32
   Razavi A, 2019, Arxiv, DOI arXiv:1906.00446
   Reddi Sashank J., 2018, P ICLR, P1
   Scannell JW, 1999, CEREB CORTEX, V9, P277, DOI 10.1093/cercor/9.3.277
   Shen ZR, 2024, Arxiv, DOI arXiv:1812.01243
   Tien YJ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-155
   Traag VA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41695-z
   Tsafrir D, 2005, BIOINFORMATICS, V21, P2301, DOI 10.1093/bioinformatics/bti329
   van Brakel RBJ, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P17, DOI 10.1109/BioVis.2013.6664342
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wilkinson E. N., 1971, Mathematics in the archaeological and historical sciences, P276
   Wu H.M., 2008, Handbook of Data Visualization, P681
   Yanardag P, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1365, DOI 10.1145/2783258.2783417
   YOUNG MP, 1993, P ROY SOC B-BIOL SCI, V252, P13, DOI 10.1098/rspb.1993.0040
   ZACHARY WW, 1977, J ANTHROPOL RES, V33, P452, DOI 10.1086/jar.33.4.3629752
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YZ, 2017, PR MACH LEARN RES, V70
NR 67
TC 3
Z9 3
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3195
EP 3208
DI 10.1109/TVCG.2022.3153838
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900005
PM 35213309
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, YJ
   Rathore, A
   Purvine, E
   Wang, B
AF Zhou, Youjia
   Rathore, Archit
   Purvine, Emilie
   Wang, Bei
TI Topological Simplifications of Hypergraphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Encoding; Bipartite graph; Data
   analysis; Clutter; Pipelines; Hypergraph simplification; hypergraph
   visualization; graph simplification; topological data analysis
ID OF-THE-ART; VISUAL ANALYSIS; VISUALIZATION; GRAPHS; SETS; PERSISTENCE;
   SUPPORTS; TOOL
AB We study hypergraph visualization via its topological simplification. We explore both vertex simplification and hyperedge simplification of hypergraphs using tools from topological data analysis. In particular, we transform a hypergraph into its graph representations, known as the line graph and clique expansion. A topological simplification of such a graph representation induces a simplification of the hypergraph. In simplifying a hypergraph, we allow vertices to be combined if they belong to almost the same set of hyperedges, and hyperedges to be merged if they share almost the same set of vertices. Our proposed approaches are general and mathematically justifiable, and put vertex simplification and hyperedge simplification in a unifying framework.
C1 [Zhou, Youjia; Rathore, Archit; Wang, Bei] Univ Utah, Sci Comp & Imaging SCI Inst, Salt Lake City, UT 84112 USA.
   [Purvine, Emilie] Pacific Northwest Natl Lab, Seattle, WA 98109 USA.
C3 Utah System of Higher Education; University of Utah; United States
   Department of Energy (DOE); Pacific Northwest National Laboratory
RP Zhou, YJ (corresponding author), Univ Utah, Sci Comp & Imaging SCI Inst, Salt Lake City, UT 84112 USA.
EM zhou325@sci.utah.edu; archit@sci.utah.edu; Emilie.Purvine@pnnl.gov;
   beiwang@sci.utah.edu
RI Rathore, Archit/JXN-0689-2024
OI RATHORE, ARCHIT/0000-0002-2965-3561; Purvine,
   Emilie/0000-0003-2069-5594; Zhou, Youjia/0000-0002-4501-8496
FU NSF IIS [1513616]; DOE, [DE-SC0021015]; High Performance Data Analytics
   (HPDA) Program at the Department of Energy's Pacific Northwest National
   Laboratory; Battelle Memorial Institute [DE-ACO6-76RL01830]; U.S.
   Department of Energy (DOE) [DE-SC0021015] Funding Source: U.S.
   Department of Energy (DOE)
FX This work was supported in part by NSF IIS under Grants 1513616 and DOE
   DE-SC0021015, in part by the High Performance Data Analytics (HPDA)
   Program at the Department of Energy's Pacific Northwest National
   Laboratory. Pacific Northwest National Laboratory is operated by
   Battelle Memorial Institute under Grant DE-ACO6-76RL01830.
CR Aksoy S, 2018, CHAPEL HYPERGRAPH LI
   Aksoy SG, 2020, EPJ DATA SCI, V9, DOI 10.1140/epjds/s13688-020-00231-0
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   [Anonymous], 2000, HURR EL BGP TOOLK
   [Anonymous], 1994, The Stanford GraphBase-A Platform for Combinatorial Computing
   [Anonymous], 2013, P 17 EUR C VIS SHORT
   [Anonymous], 2014, EUROVIS STARS
   Arafat NA, 2017, LECT NOTES COMPUT SC, V10439, P387, DOI 10.1007/978-3-319-64471-4_31
   Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556
   Beg Maham Anwar, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P502, DOI 10.1007/978-3-319-93040-4_40
   BERMOND JC, 1977, DISCRETE MATH, V18, P235, DOI 10.1016/0012-365X(77)90127-3
   Brandes U, 2012, J DISCRET ALGORITHMS, V14, P248, DOI 10.1016/j.jda.2011.12.009
   Buchin K, 2010, LECT NOTES COMPUT SC, V5849, P345, DOI 10.1007/978-3-642-11805-0_33
   Carbon S, 2019, NUCLEIC ACIDS RES, V47, pD330, DOI 10.1093/nar/gky1055
   Carlsson G., 2004, P 2004 EUR ACM SIGGR, P124, DOI DOI 10.1145/1057432.1057449
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Coifman RR, 2005, P NATL ACAD SCI USA, V102, P7426, DOI 10.1073/pnas.0500334102
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Davis Allison., 2009, Deep South: A Social Anthropological Study of Caste and Class
   DIBATTISTA G, 1994, COMP GEOM-THEOR APPL, V4, P235, DOI 10.1016/0925-7721(94)00014-X
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Efrat A, 2014, LECT NOTES COMPUT SC, V8871, P452, DOI 10.1007/978-3-662-45803-7_38
   Euler L., 1789, DIFFERENTES QUESTION
   Evans W, 2019, LECT NOTES COMPUT SC, V11904, P18, DOI 10.1007/978-3-030-35802-0_2
   Fouss F, 2007, IEEE T KNOWL DATA EN, V19, P355, DOI 10.1109/TKDE.2007.46
   Freeman LC, 2003, DYNAMIC SOCIAL NETWORK MODELING AND ANALYSIS, P39
   Gerber S, 2010, IEEE T VIS COMPUT GR, V16, P1271, DOI 10.1109/TVCG.2010.213
   Ghrist R, 2008, B AM MATH SOC, V45, P61, DOI 10.1090/s0273-0979-07-01191-3
   GOWER JC, 1969, ROY STAT SOC C-APP, V18, P54
   Gropp H, 1996, LECT NOTES COMPUT SC, V1027, P267, DOI 10.1007/BFb0021810
   Hachul Stefan, 2007, Journal of Graph Algorithms and Applications, V11, P345, DOI 10.7155/jgaa.00150
   Hajij M, 2018, IEEE PAC VIS SYMP, P125, DOI 10.1109/PacificVis.2018.00024
   Hayashi K, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P495, DOI 10.1145/3340531.3412034
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Jacobsen B, 2021, IEEE T VIS COMPUT GR, V27, P1257, DOI 10.1109/TVCG.2020.3030475
   Jenkins L, 2018, IEEE HIGH PERF EXTR
   Joslyn CA, 2020, TH CO SC GE ISS, V12091, P1, DOI 10.1007/978-3-030-48478-1_1
   Kaminski B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224307
   KLEIN DJ, 1993, J MATH CHEM, V12, P81, DOI 10.1007/BF01164627
   Kountouras A, 2016, LECT NOTES COMPUT SC, V9854, P188, DOI 10.1007/978-3-319-45719-2_9
   Koutra D, 2014, P 2014 SIAM INT C DA, P91
   KRITZ MV, 1994, INT J COMPUT MATH, V50, P131, DOI 10.1080/00207169408804250
   Kwon O. -H., 2018, GLAM GRAPH LAYOUT AE
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Lamy JB, 2019, MULTIMED TOOLS APPL, V78, P33091, DOI 10.1007/s11042-019-7655-8
   Lee K, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P144, DOI 10.1145/3394486.3403057
   Lemonnier L, 2021, Arxiv, DOI [arXiv:2003.13564, DOI 10.48550/ARXIV.2003.13564.4]
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Liberzon A, 2015, CELL SYST, V1, P417, DOI 10.1016/j.cels.2015.12.004
   MAKINEN E, 1990, INT J COMPUT MATH, V34, P177, DOI 10.1080/00207169008803875
   Meidiana A, 2019, LECT NOTES COMPUT SC, V11904, P125, DOI 10.1007/978-3-030-35802-0_10
   Nguyen Q., 2012, International Symposium on Graph Drawing, P566, DOI [10.1007/978-3-642-36763-2, DOI 10.1007/978-3-642-36763-2]
   Paquette J, 2011, PROC SPIE, V7865, DOI 10.1117/12.890220
   Praggastis B, 2018, HYPERNETX
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Purohit M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1296, DOI 10.1145/2623330.2623701
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Rodgers P, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2810012
   Shah N, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1055, DOI 10.1145/2783258.2783321
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Shin K, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1679, DOI 10.1145/3308558.3313402
   Simonetto P., 2011, THESIS U BORDEAUX BO
   Simonetto P, 2009, COMPUT GRAPH FORUM, V28, P967, DOI 10.1111/j.1467-8659.2009.01452.x
   Subramanian A, 2005, P NATL ACAD SCI USA, V102, P15545, DOI 10.1073/pnas.0506580102
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Tang J., 2008, P 14 ACM SIGKDD INT, P990, DOI [DOI 10.1145/1401890.1402008, 10.1145/1401890.1402008]
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wang CL, 2017, COMPUT GRAPH FORUM, V36, P263, DOI 10.1111/cgf.12800
   Zien JY, 1999, IEEE T COMPUT AID D, V18, P1389, DOI 10.1109/43.784130
   Zykov A. A., 1974, Russian Mathematical Surveys, V29, P89, DOI DOI 10.1070/RM1974V029N06ABEH001303
NR 74
TC 3
Z9 3
U1 3
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3209
EP 3225
DI 10.1109/TVCG.2022.3153895
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900006
PM 35213311
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, RH
   Li, XZ
   Wong, TT
   Fu, CW
AF Li, Ruihui
   Li, Xianzhi
   Wong, Tien-Tsin
   Fu, Chi-Wing
TI Point Set Self-Embedding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Shape; Point cloud compression; Visualization; Image
   restoration; Feature extraction; Three-dimensional displays; Point set
   self-embedding; jointly-trained networks; shape similarity; point
   distribution
ID ADAPTIVE SIMPLIFICATION
AB This work presents an innovative method for point set self-embedding, that encodes the structural information of a dense point set into its sparser version in a visual but imperceptible form. The self-embedded point set can function as the ordinary downsampled one and be visualized efficiently on mobile devices. Particularly, we can leverage the self-embedded information to fully restore the original point set for detailed analysis on remote servers. This task is challenging, since both the self-embedded point set and the restored point set should resemble the original one. To achieve a learnable self-embedding scheme, we design a novel framework with two jointly-trained networks: one to encode the input point set into its self-embedded sparse point set and the other to leverage the embedded information for inverting the original point set back. Further, we develop a pair of up-shuffle and down-shuffle units in the two networks, and formulate loss terms to encourage the shape similarity and point distribution in the results. Extensive qualitative and quantitative results demonstrate the effectiveness of our method on both synthetic and real-scanned datasets. The source code and trained models will be publicly available at https://github.com/liruihui/Self-Embedding.
C1 [Li, Ruihui] Hunan Univ, Changsha 410082, Hunan, Peoples R China.
   [Li, Ruihui; Wong, Tien-Tsin; Fu, Chi-Wing] Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   [Li, Xianzhi] Huazhong Univ Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
C3 Hunan University; Chinese University of Hong Kong; Huazhong University
   of Science & Technology
RP Fu, CW (corresponding author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.
EM liruihui@hnu.edu.cn; xzli@hust.edu.cn; ttwong@cse.cuhk.edu.hk;
   cwfu@cse.cuhk.edu.hk
RI Li, Xianzhi/IUO-5698-2023; Li, Ruihui/AAA-1369-2022; Fu,
   Chi-Wing/X-4703-2019
OI Li, Xianzhi/0000-0001-6835-5607; Fu, Chi Wing/0000-0002-5238-593X; Li,
   Ruihui/0000-0002-4266-6420; Wong, Tien-Tsin/0000-0002-7792-9307
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [CUHK14201921]; CUHK Direct Grant [4055152]
FX This work was supported in part by the Research Grants Council of the
   Hong Kong Special Administrative Region, China under Project No.
   CUHK14201921 and in part by CUHK Direct Grant under Project No. 4055152.
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Ananthanarayanan G, 2017, COMPUTER, V50, P58, DOI 10.1109/MC.2017.3641638
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Baluja S, 2017, ADV NEUR IN, V30
   Chen X., 2020, INT C LEARN REPR
   Chen ZG, 2018, COMPUT AIDED DESIGN, V102, P12, DOI 10.1016/j.cad.2018.04.010
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dinh L., 2017, PROC INT C LEARN REP, P1
   Dovrat O, 2019, PROC CVPR IEEE, P2755, DOI 10.1109/CVPR.2019.00287
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Han B, 2020, MOBICOM '20: PROCEEDINGS OF THE 26TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2020), P137, DOI 10.1145/3372224.3380888
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hu WB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417764
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Jorge Mario Costa, 2007, Symp. Point Based Graphics, P11
   Kingma D. P., 2018, PROC C WORKSHOP NEUR, p10 215
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Lang I, 2020, PROC CVPR IEEE, P7575, DOI 10.1109/CVPR42600.2020.00760
   Li CL, 2018, Arxiv, DOI arXiv:1810.05795
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li YY, 2018, ADV NEUR IN, V31
   Linsen L., 2001, POINT CLOUD REPRESEN
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Miao YW, 2009, COMPUT AIDED DESIGN, V41, P395, DOI 10.1016/j.cad.2009.01.006
   Mingqing Xiao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P126, DOI 10.1007/978-3-030-58452-8_8
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   Pauly M, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P163, DOI 10.1109/VISUAL.2002.1183771
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qian G., 2021, P IEEE C COMP VIS PA, p11 683
   Qian Y, 2021, Arxiv, DOI arXiv:2005.00383
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   SHANNON CE, 1949, P IRE, V37, P10, DOI 10.1109/JRPROC.1949.232969
   Shi BQ, 2011, COMPUT AIDED DESIGN, V43, P910, DOI 10.1016/j.cad.2011.04.001
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song H, 2009, INT J ADV MANUF TECH, V45, P583, DOI 10.1007/s00170-009-1980-4
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang XL, 2019, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2019.00422
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZH, 2019, COMPUT GRAPH FORUM, V38, P393, DOI 10.1111/cgf.13846
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Witkin A. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P269, DOI 10.1145/192161.192227
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xia M., 2018, ACM Trans. Graphics, V37, P1
   Xia W., 2021, P IEEE CVF INT C COM, P14000
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Ying X, 2013, IEEE T VIS COMPUT GR, V19, P1425, DOI 10.1109/TVCG.2013.63
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Yu ZW, 2010, COMPUT AIDED DESIGN, V42, P598, DOI 10.1016/j.cad.2010.03.003
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Yue Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P752, DOI 10.1007/978-3-030-58529-7_44
   Zhang HL, 2020, IEEE INT CONF MOB, P603, DOI 10.1109/MASS50613.2020.00079
   Zhao WB, 2021, PROCEEDINGS OF THE THIRTIETH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, IJCAI 2021, P1345
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 70
TC 0
Z9 0
U1 0
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3226
EP 3237
DI 10.1109/TVCG.2022.3155808
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900007
PM 35239483
DA 2024-11-06
ER

PT J
AU Narciso, D
   Melo, M
   Rodrigues, S
   Cunha, JP
   Vasconcelos-Raposo, J
   Bessa, M
AF Narciso, David
   Melo, Miguel
   Rodrigues, Susana
   Cunha, Joao Paulo
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI Using Heart Rate Variability for Comparing the Effectiveness of Virtual
   vs Real Training Environments for Firefighters
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Particle measurements; Atmospheric measurements; Heart rate
   variability; Stress; Physiology; Task analysis; Computer graphics;
   virtual reality; professional training; biofeedback
ID ENHANCES REALISTIC RESPONSE; PRESENCE QUESTIONNAIRE; STRESS ASSESSMENT;
   FATIGUE; SYSTEM
AB The use of Virtual Reality (VR) technology to train professionals has increased over the years due to its advantages over traditional training. This paper presents a study comparing the effectiveness of a Virtual Environment (VE) and a Real Environment (RE) designed to train firefighters. To measure the effectiveness of the environments, a new method based on participants' Heart Rate Variability (HRV) was used. This method was complemented with self-reports, in the form of questionnaires, of fatigue, stress, sense of presence, and cybersickness. An additional questionnaire was used to measure and compare knowledge transfer enabled by the environments. The results from HRV analysis indicated that participants were under physiological stress in both environments, albeit with less intensity on the VE. Regarding reported fatigue and stress, the results showed that none of the environments increased such variables. The results of knowledge transfer showed that the VE obtained a significant increase while the RE obtained a positive but non-significant increase (median values, VE: before - 4 after - 7, p = .003; RE: before - 4 after - 5, p = .375). Lastly, the results of presence and cybersickness suggested that participants experienced high overall presence and no cybersickness. Considering all results, the authors conclude that the VE provided effective training but that its effectiveness was lower than that of the RE.
C1 [Narciso, David; Vasconcelos-Raposo, Jose; Bessa, Maximino] Univ Tras os Montes & Alto Douro UTAD, P-5000801 Vila Real, Portugal.
   [Narciso, David; Melo, Miguel; Rodrigues, Susana; Cunha, Joao Paulo; Vasconcelos-Raposo, Jose; Bessa, Maximino] Inst Syst & Comp Engn Technol & Sci INESC TEC, P-4200465 Porto, Portugal.
   [Cunha, Joao Paulo] Univ Porto FEUP, Fac Engn, P-4200465 Porto, Portugal.
C3 University of Tras-os-Montes & Alto Douro; INESC TEC; Universidade do
   Porto
RP Narciso, D (corresponding author), Univ Tras os Montes & Alto Douro UTAD, P-5000801 Vila Real, Portugal.
EM davidnarciso@utad.pt; mcmelo@inesctec.pt;
   susana.c.rodrigues@inesctec.pt; jpcunha@fe.up.pt; jvraposo@utad.pt;
   maxbessa@utad.pt
RI VASCONCELOS-RAPOSO, JOSE/JMB-6306-2023; Bessa, Maximino/B-4729-2012;
   Melo, Miguel/AAN-1855-2020; Branco VASCONCELOS-RAPOSO, JOSE
   Jacinto/G-3743-2010; Cunha, Joao Paulo/F-9039-2010
OI Rodrigues, Susana/0000-0001-6546-340X; Branco VASCONCELOS-RAPOSO, JOSE
   Jacinto/0000-0002-3456-9727; Bessa, Maximino/0000-0002-3002-704X; Cunha,
   Joao Paulo/0000-0003-4131-9045; Melo, Miguel/0000-0003-4050-3473
FU ERDF - European Regional Development Fund through the Operational
   Program for Competitiveness and Internationaliza-tion - COMPETE 2020
   Program; National Funds through the Portuguese Funding Agency, FCT -
   Fundacao para a Ciencia e a Tecnologia, [POCI-01-0145-FEDER-028618];
   PERFECT - Perceptual Equivalence in Virtual Reality For authEntiC
   Training [UIDB/50014/2020, SFRH/BD/147334/2019]
FX This work was supported in part by the ERDF - European Regional
   Development Fund through the Operational Program for Competitiveness and
   Internationaliza-tion - COMPETE 2020 Program, and in part by National
   Funds through the Portuguese Funding Agency, FCT - Fundacao para a
   Ciencia e a Tecnologia, Project under Grant POCI-01-0145-FEDER-028618
   entitled PERFECT - Perceptual Equivalence in Virtual Reality For
   authEntiC Training, Project under Grant UIDB/50014/2020, and PhD under
   Grant SFRH/BD/147334/2019. All the works were conducted at INESC TEC's
   MASSIVE VR Laboratory.
CR Alghamdi M, 2017, BEHAV INFORM TECHNOL, V36, P913, DOI 10.1080/0144929X.2017.1311374
   García AA, 2016, VIRTUAL REAL-LONDON, V20, P27, DOI 10.1007/s10055-015-0280-6
   Backlund P, 2007, IEEE INT CONF INF VI, P899
   Bhagat KK, 2016, VIRTUAL REAL-LONDON, V20, P127, DOI 10.1007/s10055-016-0284-x
   Biodevices, 2019, BIOD SOL ENG BIOM
   Bliss JP, 1997, PRESENCE-TELEOP VIRT, V6, P73, DOI 10.1162/pres.1997.6.1.73
   BRISLIN RW, 1970, J CROSS CULT PSYCHOL, V1, P185, DOI 10.1177/135910457000100301
   Brogni A., 2007, Int. J. Virtual Reality, V6, P1
   Camm AJ, 1996, CIRCULATION, V93, P1043
   Cardoso R., 2002, O Stress nos Professores Portugueses: Estudo IPSSO 2000
   Carl E, 2019, J ANXIETY DISORD, V61, P27, DOI 10.1016/j.janxdis.2018.08.003
   Castaldo R, 2015, BIOMED SIGNAL PROCES, V18, P370, DOI 10.1016/j.bspc.2015.02.012
   Cha M, 2012, FIRE SAFETY J, V50, P12, DOI 10.1016/j.firesaf.2012.01.004
   Clifford G. D., 2006, Advanced Methods and Tools for ECG Data Analysis, P55
   Clifford R. M. S., 2018, 2018 10 INT C VIRT W, DOI DOI 10.1109/VS-GAMES.2018.8493423
   Clifford RMS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P181, DOI [10.1109/VR.2019.8797889, 10.1109/vr.2019.8797889]
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Corelli F, 2020, HUCAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 2: HUCAPP, P146, DOI 10.5220/0008962401460153
   Cunha Joao P. Silva, 2010, 2010 4th International Conference on Pervasive Computing Technologies for Healthcare (Pervasive Health 2010), DOI 10.4108/ICST.PERVASIVEHEALTH2010.8991
   de Visser H, 2011, MED J AUSTRALIA, V194, pS38
   Deng WR, 2019, J AFFECT DISORDERS, V257, P698, DOI 10.1016/j.jad.2019.07.086
   Deniaud C, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P739, DOI 10.1109/SAI.2015.7237225
   Dillon C., 2001, P 4 ANN INT WORKSH P, P21
   Engelbrecht H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00101
   FLAIMTrainer, 2020, FLAIM TRAIN
   Freund E, 2005, P SOC PHOTO-OPT INS, V5664, P388, DOI 10.1117/12.587720
   Gurusamy K, 2008, BRIT J SURG, V95, P1088, DOI 10.1002/bjs.6344
   Hambleton RK., 2011, Cross-cultural research methods in psychology, P46, DOI DOI 10.1017/CBO9780511779381.004
   Harter D, 2011, PROCEEDINGS OF THE ASME WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2011, P301
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Hogue J. R., 2007, P 45 ANN SAF S, P1
   Hozjan T., 2020, SAFETY SECURITY ISSU, P232
   Jang DP, 2002, CYBERPSYCHOL BEHAV, V5, P11, DOI 10.1089/109493102753685845
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Lesage FX, 2012, OCCUP MED-OXFORD, V62, P600, DOI 10.1093/occmed/kqs140
   Lessiter J, 2001, PRESENCE-TELEOP VIRT, V10, P282, DOI 10.1162/105474601300343612
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI [10.1162/pres.1992.1.1.113, DOI 10.1162/PRES.1992.1.1.113]
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   Mossel A, 2017, P IEEE VIRT REAL ANN, P357, DOI 10.1109/VR.2017.7892324
   Nahavandi S., 2019, Intelligent Computing. Proceedings of the 2019 Computing Conference. Advances in Intelligent Systems and Computing (AISC 997), P11, DOI 10.1007/978-3-030-22871-2_2
   Narciso D., 2019, Multimedia Tools Appl, V79, P1
   Pimentel G, 2019, INT J MED INFORM, V129, P60, DOI 10.1016/j.ijmedinf.2019.05.028
   Riva G, 2011, ANN REV CYBERTHERAPY, V9, P2
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   SimulationTrainingSystems, 2020, ADMS FIRE
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2006, PRESENCE-VIRTUAL AUG, V15, P553, DOI 10.1162/pres.15.5.553
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   Sobel-Fox RM, 2013, J PSYCHOSOC ONCOL, V31, P413, DOI 10.1080/07347332.2013.798760
   Statistics L., 2015, SIGN TEST US SPSS ST
   Van Baren J., 2004, IST20013923 NORW U S
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   VERCOULEN JHMM, 1994, J PSYCHOSOM RES, V38, P383, DOI 10.1016/0022-3999(94)90099-X
   Voss A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118308
   Wang C, 2011, PROCEDIA ENVIRON SCI, V10, P313, DOI 10.1016/j.proenv.2011.09.051
   Wiederhold B.K., 2001, CYBERPSYCHOLOGY MIND, P175
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yu I, 2012, IEEE COMPUT GRAPH, V32, P36, DOI 10.1109/MCG.2012.121
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 59
TC 5
Z9 5
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3238
EP 3250
DI 10.1109/TVCG.2022.3156734
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900008
PM 35254983
DA 2024-11-06
ER

PT J
AU Li, X
   Wang, LJ
   Fang, Y
AF Li, Xiang
   Wang, Lingjing
   Fang, Yi
TI Unsupervised Category-Specific Partial Point Set Registration via Joint
   Shape Completion and Registration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Three-dimensional displays; Codes; Optimization; Task analysis;
   Point cloud compression; Training; Point set registration; partial
   registration; unsupervised learning; shape completion
ID ALGORITHM
AB We propose a self-supervised method for partial point set registration. Although recently proposed learning-based methods demonstrate impressive registration performance on full shape observations, these methods often suffer from performance degradation when dealing with partial shapes. To bridge the performance gap between partial and full point set registration, we propose to incorporate a shape completion network to benefit the registration process. To achieve this, we introduce a learnable latent code for each pair of shapes, which can be regarded as the geometric encoding of the target shape. By doing so, our model does not require an explicit feature embedding network to learn the feature encodings. More importantly, both our shape completion and point set registration networks take the shared latent codes as input, which are optimized simultaneously with the parameters of two decoder networks in the training process. Therefore, the point set registration process can benefit from the joint optimization process of latent codes, which are enforced to represent the information of full shapes instead of partial ones. In the inference stage, we fix the network parameters and optimize the latent codes to obtain the optimal shape completion and registration results. Our proposed method is purely unsupervised and does not require ground truth supervision. Experiments on the ModelNet40 dataset demonstrate the effectiveness of our model for partial point set registration.
C1 [Li, Xiang; Wang, Lingjing; Fang, Yi] NYU Tandon, Dept Elect & Comp Engn, NYU Multimedia & Visual Comp Lab, Abu Dhabi, U Arab Emirates.
   [Li, Xiang; Wang, Lingjing; Fang, Yi] NYU Tandon, Dept Elect & Comp Engn, Brooklyn, NY 11201 USA.
C3 New York University
RP Fang, Y (corresponding author), NYU Tandon, Dept Elect & Comp Engn, NYU Multimedia & Visual Comp Lab, Abu Dhabi, U Arab Emirates.
EM xl1845@nyu.edu; lingjing.wang@nyu.edu; yfang@nyu.edu
RI Li, Xiang/AAC-4866-2019
OI Li, Xiang/0000-0002-9946-7000; Fang, Yi/0000-0001-9427-3883
FU NYU Abu Dhabi Institute [AD131]
FX This work was supported by NYU Abu Dhabi Institute under Grant AD131.
CR Rusu AA, 2019, Arxiv, DOI arXiv:1807.05960
   Agamennoni G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4092, DOI 10.1109/IROS.2016.7759602
   Agrawal S, 2019, IEEE WINT CONF APPL, P1099, DOI 10.1109/WACV.2019.00122
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], 2005, P S GEOM PROC
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bouakkaz Messaoud, 2012, Proceedings of the 4th International Joint Conference on Computational Intelligence (IJCCI 2012), P483
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Chen Jianchun, 2019, Advances in Neural Information Processing Systems, P3415
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Gelfand Natasha, 2005, ACM International Conference Proceeding Series, V255, P197
   Groueix T, 2018, LECT NOTES COMPUT SC, V11206, P235, DOI 10.1007/978-3-030-01216-8_15
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Halimi O., 2020, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinzmann T, 2017, SPR PROC ADV ROBOT, V1, P43, DOI 10.1007/978-3-319-50115-4_5
   Hu Y, 2019, IEEE GEOSCI REMOTE S, V16, P947, DOI 10.1109/LGRS.2018.2889247
   Ioffe Sergey, 2015, P MACHINE LEARNING R, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kingma D. P., 2017, 3 INT C LEARNING REP
   [Краевский В.В. Kraevsky V.V.], 2005, [Педагогика, Pedagogika], P13
   Li X, 2021, IEEE T VIS COMPUT GR, V27, P3926, DOI 10.1109/TVCG.2020.2994013
   Li X, 2020, ISPRS J PHOTOGRAMM, V166, P128, DOI 10.1016/j.isprsjprs.2020.05.023
   Li X, 2018, IEEE J-STARS, V11, P3680, DOI 10.1109/JSTARS.2018.2865187
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Litany O, 2012, LECT NOTES COMPUT SC, V7583, P1, DOI 10.1007/978-3-642-33863-2_1
   Liu XY, 2019, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2019.00062
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mitra N. J., 2004, P 2004 EUR ACM SIGGR, P22, DOI DOI 10.1145/1057432.1057435
   Myronenko A., 2007, Advances in Neural Information Processing Systems, V19, P1009
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pauly M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360642
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Rock J, 2015, PROC CVPR IEEE, P2484, DOI 10.1109/CVPR.2015.7298863
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Segal Aleksandr, 2009, Generalized-icpRobotics: Sci Syst, V2, P435, DOI [DOI 10.15607/RSS.2009.V.021, DOI 10.7551/MITPRESS/8727.003.0022]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209
   Tan QY, 2018, PROC CVPR IEEE, P5841, DOI 10.1109/CVPR.2018.00612
   TAN SF, 1995, AICHE J, V41, P1471, DOI 10.1002/aic.690410612
   Thrun S, 2005, IEEE I CONF COMP VIS, P1824
   Wang LJ, 2019, Arxiv, DOI arXiv:1904.01428
   Wang LJ, 2020, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR42600.2020.00456
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wang Y, 2019, 33 C NEURAL INFORM P, V32
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Wen X, 2020, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR42600.2020.00201
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yew ZJ, 2020, PROC CVPR IEEE, P11821, DOI 10.1109/CVPR42600.2020.01184
   Yuan S., 2020, 2020 IEEE RSJ INT C, P8154
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhao W, 2007, VISUAL COMPUT, V23, P987, DOI 10.1007/s00371-007-0167-y
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 71
TC 5
Z9 5
U1 4
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3251
EP 3265
DI 10.1109/TVCG.2022.3157061
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900009
PM 35254987
DA 2024-11-06
ER

PT J
AU Fleck, P
   Calepso, AS
   Hubenschmid, S
   Sedlmair, M
   Schmalstieg, D
AF Fleck, Philipp
   Calepso, Aimee Sousa
   Hubenschmid, Sebastian
   Sedlmair, Michael
   Schmalstieg, Dieter
TI RagRug: A Toolkit for Situated Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Solid modeling; Encoding; Data
   models; Computational modeling; Three-dimensional displays; Augmented
   reality; immersive analytics; situated analytics; visual analytics;
   visualization
ID AUGMENTED REALITY; INFORMATION VISUALIZATION; DESIGN CONSIDERATIONS;
   MIXED REALITY
AB We present RagRug, an open-source toolkit for situated analytics. The abilities of RagRug go beyond previous immersive analytics toolkits by focusing on specific requirements emerging when using augmented reality (AR) rather than virtual reality. RagRug combines state of the art visual encoding capabilities with a comprehensive physical-virtual model, which lets application developers systematically describe the physical objects in the real world and their role in AR. We connect AR visualizations with data streams from the Internet of Things using distributed dataflow. To this end, we use reactive programming patterns so that visualizations become context-aware, i.e., they adapt to events coming in from the environment. The resulting authoring system is low-code; it emphasises describing the physical and the virtual world and the dataflow between the elements contained therein. We describe the technical design and implementation of RagRug, and report on five example applications illustrating the toolkit's abilities.
C1 [Fleck, Philipp; Schmalstieg, Dieter] Graz Univ Technol, Inst Comp G & Vis, A-8010 Graz, Austria.
   [Calepso, Aimee Sousa; Sedlmair, Michael] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Hubenschmid, Sebastian] Univ Konstanz, D-78464 Constance, Germany.
C3 Graz University of Technology; University of Stuttgart; University of
   Konstanz
RP Fleck, P (corresponding author), Graz Univ Technol, Inst Comp G & Vis, A-8010 Graz, Austria.
EM philipp.fleck@icg.tugraz.at; Aimee.Sousa-Calepso@visus.uni-stuttgart.de;
   sebastian.hubenschmid@uni-konstanz.de;
   michael.sedlmair@visus.uni-stuttgart.de; schmalstieg@tugraz.at
OI Hubenschmid, Sebastian/0000-0002-8704-8503; Sousa Calepso,
   Aimee/0000-0002-6625-0585; Schmalstieg, Dieter/0000-0003-2813-2235
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [390831618]; DFG [251654672 TRR 161]
FX This research was supported by the Deutsche Forschungsgemeinschaft (DFG,
   German Research Foundation) under Germany's Excellence Strategy
   underGrant EXC 2120/1 - 390831618 and the DFG under Grant 251654672 -TRR
   161
CR Andrews C, 2012, IEEE CONF VIS ANAL, P123, DOI 10.1109/VAST.2012.6400559
   [Anonymous], VEG LIT GRAMM INT GR
   Garcia-Macias JA, 2011, COMPUTER, V44, P46, DOI 10.1109/MC.2011.128
   Back M, 2010, IEEE INT CON MULTI, P1160, DOI 10.1109/ICME.2010.5582532
   Badam SK, 2019, INFORM VISUAL, V18, P68, DOI 10.1177/1473871617725907
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Ball R, 2007, COMPUT GRAPH-UK, V31, P380, DOI 10.1016/j.cag.2007.01.029
   Beaudouin-Lafon M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P446, DOI 10.1145/332040.332473
   Belimpasakis P, 2011, IEEE T CONSUM ELECTR, V57, P139, DOI 10.1109/TCE.2011.5735494
   Bertin J., 1983, Semiology of Graphics
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Buschmann F., 1996, PatternOriented Software Architecture: A System of Patterns
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/vr.2019.8797978, 10.1109/VR.2019.8797978]
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Ens B., 2017, Proceedings of the 43rd Graphics Interface Conference, P156
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Fekete JD, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P167, DOI 10.1109/INFVIS.2004.64
   Gamma E., 1994, DESIGN PATTERNS ELEM
   Gandy M., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology - UIST '14, P627, DOI DOI 10.1145/2642918.2647369
   Grubert J, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P215, DOI 10.1145/2992154.2992162
   Gunnarsson Ann-Sofie, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P233, DOI 10.1109/ISMAR.2006.297820
   Harrison Chris, 2011, P 24 ANN ACM S US IN, P441, DOI [DOI 10.1145/2047196.2047255, 10.1145/2047196.2047255]
   Heer J., 2005, P SIGCHI C HUM FACT, P421
   Herbert B, 2018, COMPUT GRAPH-UK, V77, P166, DOI 10.1016/j.cag.2018.09.017
   Herr D., 2017, P IEEE IMM AN WORKSH, P1112
   Hillar G.C., 2017, MQTT ESSENTIALS LIGH
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Huo K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173793
   Jansen Y, 2013, IEEE T VIS COMPUT GR, V19, P2396, DOI 10.1109/TVCG.2013.134
   Jo D, 2016, IEEE T CONSUM ELECTR, V62, P334, DOI 10.1109/TCE.2016.7613201
   Jones A, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P465, DOI 10.1145/2992154.2998580
   Kasahara Shunichi, 2013, P 7 INT C TANG EMB E, P223, DOI DOI 10.1145/2460625.2460661
   King GR, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P52
   Lacoche J, 2014, WORK SOFTW ENG, P19, DOI 10.1109/SEARIS.2014.7152797
   Larregui J. I., 2018, IMMERSIVE ANAL GEOLO
   Ledermann F, 2005, P IEEE VIRT REAL ANN, P187
   Ledo D., 2015, Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services, P187, DOI DOI 10.1145/2785830.2785871
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2012, IEEE T VIS COMPUT GR, V18, P2689, DOI 10.1109/TVCG.2012.204
   Li Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300917
   Liu C, 2012, P 2012 ACM ANN C HUM, P2973, DOI [10.1145/2207676.2208706, DOI 10.1145/2207676.2208706]
   MacIntyre B., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P65, DOI 10.1109/ISMAR.2011.6092371
   MacWilliams A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P123, DOI 10.1109/ISMAR.2003.1240695
   Merino L, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383017
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376330
   Norouzi* N., 2019, Artificial intelligence in IoT, P1
   Olsen DR, 2007, UIST 2007: PROCEEDINGS OF THE 20TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P251
   Pokric B, 2014, 2014 28TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P803, DOI 10.1109/WAINA.2014.127
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Reitmayr G., 2001, P ACM S VIRT REAL SO, P47
   Salber Daniel, 1999, CHI, P434, DOI [DOI 10.1145/302979.303126, 10.1145/302979.303126]
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schmidt D, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P379
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Spohrer JC, 1999, IBM SYST J, V38, P602, DOI 10.1147/sj.384.0602
   Subramonyam H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300628
   Suzuki R., 2019, P INT C ART REAL TEL, P105
   Taylor R.M., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology - VRST '01, P55, DOI DOI 10.1145/505008.505019
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   Veas E, 2013, PERS UBIQUIT COMPUT, V17, P1515, DOI 10.1007/s00779-012-0597-z
   Walsh J.A., 2011, Conferences in Research and Practice in Information Technology Series, V117, P39
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Xiao Robert, 2013, P SIGCHI C HUM FACT, P879, DOI [10.1145/2470654.2466113, DOI 10.1145/2470654.2466113]
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yost B, 2006, IEEE T VIS COMPUT GR, V12, P837, DOI 10.1109/TVCG.2006.184
   Zhang L, 2020, P 33 ANN ACM S US IN
   Zhanyong Wan, 2002, Practical Aspects of Declarative Languages. 4th International Symposium, PADL 2002. Proceedings (Lecture Notes in Computer Science Vol.2257), P155
   Zhao MQ, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139309
   Zollmann Stefanie, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P19, DOI 10.1109/ISMAR.2010.5643546
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
NR 80
TC 29
Z9 31
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3281
EP 3297
DI 10.1109/TVCG.2022.3157058
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900010
PM 35254986
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Deng, DZ
   Wu, YH
   Shu, XH
   Wu, J
   Fu, SW
   Cui, WW
   Wu, YC
AF Deng, Dazhen
   Wu, Yihong
   Shu, Xinhuan
   Wu, Jiang
   Fu, Siwei
   Cui, Weiwei
   Wu, Yingcai
TI VisImages: A Fine-Grained Expert-Annotated Visualization Dataset
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Visualization; Analytical models; Systematics; Visual
   analytics; Computational modeling; Taxonomy; Visualization dataset;
   crowdsourcing; literature analysis; visualization classification;
   visualization detection
ID COLLECTION; CHALLENGE
AB Images in visualization publications contain rich information, e.g., novel visualization designs and implicit design patterns of visualizations. A systematic collection of these images can contribute to the community in many aspects, such as literature analysis and automated tasks for visualization. In this paper, we build and make public a dataset, VisImages, which collects 12,267 images with captions from 1,397 papers in IEEE InfoVis and VAST. Built upon a comprehensive visualization taxonomy, the dataset includes 35,096 visualizations and their bounding boxes in the images. We demonstrate the usefulness of VisImages through three use cases: 1) investigating the use of visualizations in the publications with VisImages Explorer, 2) training and benchmarking models for visualization classification, and 3) localizing visualizations in the visual analytics systems automatically.
C1 [Deng, Dazhen; Wu, Yihong; Wu, Jiang; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Shu, Xinhuan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Fu, Siwei] Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
   [Cui, Weiwei] Microsoft Res Asia, Beijing, Peoples R China.
C3 Zhejiang University; Hong Kong University of Science & Technology;
   Zhejiang Laboratory; Microsoft; Microsoft Research Asia
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM dengdazhen@zju.edu.cn; wuyihong@zju.edu.cn; xinhuan.shu@connect.ust.hk;
   wujiang5521@zju.edu.cn; fusiwei339@gmail.com; weiweicu@microsoft.com;
   ycwu@zju.edu.cn
RI wang, yixuan/JGM-3893-2023; Deng, Dazhen/JXW-7493-2024; Wu,
   Yihong/AAP-4587-2021
OI Shu, Xinhuan/0000-0002-9736-4454; Deng, Dazhen/0000-0002-9057-8353; Wu,
   Yihong/0000-0002-4905-2501
FU NSFC [62072400, 62002331]; Collaborative Innovation Center of Artificial
   Intelligence by MOE; Zhejiang Provincial Government (ZJU); Zhejiang Lab
   [2020KE0AA02, 2021KE0AC02]; Microsoft Research Asia
FX This work was supported in part by NSFC under Grants 62072400 and
   62002331 and in part by the Collaborative Innovation Center of
   Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).
   This work was also supported by Zhejiang Lab under Grants 2020KE0AA02
   and 2021KE0AC02, and Microsoft Research Asia.
CR Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bengio Y., 2017, Deep Learning, V1
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chuang J., 2013, PMLR, P612
   Clark C, 2016, ACM-IEEE J CONF DIG, P143, DOI 10.1145/2910896.2910904
   Cook K, 2014, INFORM VISUAL, V13, P301, DOI 10.1177/1473871613490678
   Cui WW, 2010, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2010.5429600
   Deng D., 2021, P CHI, P1, DOI [DOI 10.1145/3411764.34454312, 10.1145/3411764.34454312]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Fekete J. -D., 2004, INFOVIS 2004 CONTEST
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Keim D. A., 2002, Information Visualization, V1, P20, DOI 10.1057/palgrave/ivs/9500003
   Koh K, 2010, IEEE T VIS COMPUT GR, V16, P1190, DOI 10.1109/TVCG.2010.175
   Krippendorff K., 2011, Computing Krippendorff's alpha-reliability
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee B, 2019, IEEE COMPUT GRAPH, V39, P78, DOI 10.1109/MCG.2019.2914844
   Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038
   Lex A, 2010, IEEE T VIS COMPUT GR, V16, P1027, DOI 10.1109/TVCG.2010.138
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Li R, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P26, DOI 10.1109/SciVis.2018.8823764
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   nltk, NLTK LIB NLTK METR A
   Plaisant C, 2008, IEEE T VIS COMPUT GR, V14, P120, DOI 10.1109/TVCG.2007.70412
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ponsard Antoine, 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, CHI EA 16, P2264, DOI 10.1145/2851581
   Redmon J., 2018, arXiv, DOI 10.48550/arXiv.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Shu XH, 2021, J VISUAL-JAPAN, V24, P85, DOI 10.1007/s12650-020-00689-0
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K., 2015, C TRACK P
   Su CY, 2021, VIS INFORM, V5, P56, DOI 10.1016/j.visinf.2021.12.005
   Su H., 2012, Human Computation-Papers from the 2012 AAAI Workshop, Technical Report
   Tominski C, 2021, VIS INFORM, V5, P28, DOI 10.1016/j.visinf.2021.06.004
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang YY, 2021, VIS INFORM, V5, P49, DOI 10.1016/j.visinf.2021.12.003
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu YC, 2010, IEEE T VIS COMPUT GR, V16, P1109, DOI 10.1109/TVCG.2010.183
   Xie L., 2016, BLOG POST
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang W, 2021, VIS INFORM, V5, P34, DOI 10.1016/j.visinf.2021.12.002
   Zhou FF, 2021, J VISUAL-JAPAN, V24, P419, DOI 10.1007/s12650-020-00702-6
NR 64
TC 11
Z9 11
U1 0
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3298
EP 3311
DI 10.1109/TVCG.2022.3155440
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900011
PM 35254982
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Eckelt, K
   Hinterreiter, A
   Adelberger, P
   Walchshofer, C
   Dhanoa, V
   Humer, C
   Heckmann, M
   Steinparz, C
   Streit, M
AF Eckelt, Klaus
   Hinterreiter, Andreas
   Adelberger, Patrick
   Walchshofer, Conny
   Dhanoa, Vaishali
   Humer, Christina
   Heckmann, Moritz
   Steinparz, Christian
   Streit, Marc
TI Visual Exploration of Relationships and Structure in Low-Dimensional
   Embeddings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Layout; Data visualization; Space
   exploration; Visual analytics; Trajectory; Dimensionality reduction;
   projection; visual analytics; layout enrichment; aggregation; comparison
ID PROJECTIONS; REDUCTION; SPACE
AB In this work, we propose an interactive visual approach for the exploration and formation of structural relationships in embeddings of high-dimensional data. These structural relationships, such as item sequences, associations of items with groups, and hierarchies between groups of items, are defining properties of many real-world datasets. Nevertheless, most existing methods for the visual exploration of embeddings treat these structures as second-class citizens or do not take them into account at all. In our proposed analysis workflow, users explore enriched scatterplots of the embedding, in which relationships between items and/or groups are visually highlighted. The original high-dimensional data for single items, groups of items, or differences between connected items and groups are accessible through additional summary visualizations. We carefully tailored these summary and difference visualizations to the various data types and semantic contexts. During their exploratory analysis, users can externalize their insights by setting up additional groups and relationships between items and/or groups. We demonstrate the utility and potential impact of our approach by means of two use cases and multiple examples from various domains.
C1 [Eckelt, Klaus; Hinterreiter, Andreas; Adelberger, Patrick; Walchshofer, Conny; Dhanoa, Vaishali; Humer, Christina; Heckmann, Moritz; Steinparz, Christian; Streit, Marc] Johannes Kepler Univ Linz, A-4040 Linz, Austria.
   [Dhanoa, Vaishali] Pro2Future GmbH, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz
RP Eckelt, K (corresponding author), Johannes Kepler Univ Linz, A-4040 Linz, Austria.
EM klaus.eckelt@jku.at; andreas.hinterreiter@jku.at;
   patrick.adelberger@jku.at; conny.walchshofer@jku.at;
   vaishali.dhanoa@pro2future.at; christina.humer@jku.at;
   moritz.heckmann@datavisyn.io; christian.steinparz@jku.at;
   marc.streit@jku.at
OI Streit, Marc/0000-0001-9186-2092; Humer, Christina/0000-0002-0249-4062;
   Reis, Conny/0000-0003-3942-8445; Eckelt, Klaus/0000-0001-6832-9070;
   Dhanoa, Vaishali/0000-0002-0493-8616; Adelberger,
   Patrick/0000-0003-1819-5929
FU Boehringer Ingelheim Regional Center Vienna; State of Upper Austria;
   Austrian Federal Ministry of Education, Science and Research via the LIT
   - Linz Institute of Technology [LIT-2019-7-SEE-117]; State of Upper
   Austria (Human-Interpretable Machine Learning); Austrian Science Fund
   [FWF DFH 23-N]; FFG [881844]; Austrian COMET Program Competence Centers
   for Excellent Technologies under the Austrian Federal Ministry for
   Climate Action, Environment, Energy, Mobility, Innovation and
   Technology; Austrian Federal Ministry for Digital and Economic Affairs;
   Province of Upper Austria; Province of Styria
FX This work was supported in part by Boehringer Ingelheim Regional Center
   Vienna, the State of Upper Austria and the Austrian Federal Ministry of
   Education, Science and Research via the LIT - Linz Institute of
   Technology under Grant LIT-2019-7-SEE-117, in part by the State of Upper
   Austria (Human-Interpretable Machine Learning), and the Austrian Science
   Fund under Grant FWF DFH 23-N and in part by FFG, under Grant 881844:
   "Pro2Future is funded within the Austrian COMET Program Competence
   Centers for Excellent Technologies under the auspices of the Austrian
   Federal Ministry for Climate Action, Environment, Energy, Mobility,
   Innovation and Technology, the Austrian Federal Ministry for Digital and
   Economic Affairs and of the Provinces of Upper Austria and Styria. COMET
   is managed by the Austrian Research Promotion Agency FFG".
CR Adelberger P, 2021, BIOINFORMATICS, V37, P4559, DOI 10.1093/bioinformatics/btab695
   Arendt DL, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P259, DOI 10.1145/3377325.3377514
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bibal A, 2020, ESANN, P393
   Boggust A, 2022, Arxiv, DOI arXiv:1912.04853
   Brehmer M., 2014, P 5 WORKSH TIM ERR N, P1, DOI DOI 10.1145/2669557.2669559
   Cabello R., 2021, THREEJS JAVASCRIPT 3
   Cabello R., 2021, CATMULL ROM SPLINE
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Catmull E., 1974, Com- puter Aided Geometric Design, P317, DOI DOI 10.1016/B978-0-12-079050-0.50020-5
   Chao GQ, 2019, MACH LEARN KNOW EXTR, V1, P341, DOI 10.3390/make1010020
   Chatzimparmpas A, 2020, IEEE T VIS COMPUT GR, V26, P2696, DOI 10.1109/TVCG.2020.2986996
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   Cutura R, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399875
   D3, 2020, D3 CONT
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Facebook Inc, 2021, React: A JavaScript library for building user interface
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Fujiwara T, 2022, IEEE T VIS COMPUT GR, V28, P758, DOI 10.1109/TVCG.2021.3114807
   Gomez-Nieto E, 2016, IEEE T VIS COMPUT GR, V22, P1223, DOI 10.1109/TVCG.2015.2489660
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Havard P., 2019, KINGBASE A FREE CHES
   Heimerl F, 2022, IEEE T VIS COMPUT GR, V28, P2953, DOI 10.1109/TVCG.2020.3045918
   Heulot N, 2013, P EUROVIS WORKSH VIS, P11
   Hinterreiter A, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387165
   Hollt T, 2019, COMPUT GRAPH FORUM, V38, P569, DOI 10.1111/cgf.13711
   HORST A. M., 2020, palmerpenguins: Palmer Achipelago (Antarctica) Penguin Data. R Package Version 0.1.0
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jin Zhihua, 2020, arXiv
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Joia P, 2015, COMPUT GRAPH FORUM, V34, P281, DOI 10.1111/cgf.12640
   Junior Wilson Estecio Marcilio, 2020, 17th International Conference on Information Technology-New Generations (ITNG 2020). Advances in Intelligent Systems and Computing (AISC 1134), P241, DOI 10.1007/978-3-030-43020-7_32
   Karpathy A., 2016, TSNEJS
   Kasai K, 2016, PATHOL INT, V66, P653, DOI 10.1111/pin.12476
   Kim H, 2016, IEEE T VIS COMPUT GR, V22, P131, DOI 10.1109/TVCG.2015.2467615
   Kizilirmak D., 2018, PGN2GIF
   Kolata G., 2021, The New York Times
   Kwon BC, 2017, IEEE T VIS COMPUT GR, V23, P221, DOI 10.1109/TVCG.2016.2598446
   Lehmann DJ, 2015, COMPUT GRAPH FORUM, V34, P291, DOI 10.1111/cgf.12641
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Liao HS, 2018, IEEE T VIS COMPUT GR, V24, P2531, DOI 10.1109/TVCG.2017.2754480
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P241, DOI 10.1109/TVCG.2020.3011155
   Marcilio WE, 2021, EXPERT SYST APPL, V178, DOI 10.1016/j.eswa.2021.115020
   Marcilio WE, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100239
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   National Cancer Institute, 2019, The Cancer Genome Atlas Program
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Partl C, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-S19-S3
   Paulovich FV, 2007, SIBGRAPI, P27, DOI 10.1109/SIBGRAPI.2007.21
   People+AI Research (PAIR) Initiative, 2019, UMAP-JS
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Ramsay RG, 2008, NAT REV CANCER, V8, P523, DOI 10.1038/nrc2439
   Robinson I, 2020, Arxiv, DOI arXiv:2002.05687
   Sainburg T, 2021, NEURAL COMPUT, V33, P2881, DOI 10.1162/neco_a_01434
   Sarikaya A, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13408
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sato F, 2009, J BIOCHEM, V146, P833, DOI 10.1093/jb/mvp126
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Sohns JT, 2022, IEEE T VIS COMPUT GR, V28, P540, DOI 10.1109/TVCG.2021.3114870
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Streit M, 2019, BIOINFORMATICS, V35, P3140, DOI 10.1093/bioinformatics/btz009
   Uhlen M, 2017, SCIENCE, V357, P660, DOI 10.1126/science.aan2507
   VanHorn K. C., 2020, HAISU HIERARCHICAL S, DOI [10.1101/2020.10.05.324798, DOI 10.1101/2020.10.05.324798]
   Wenskovitch J, 2018, IEEE T VIS COMPUT GR, V24, P131, DOI 10.1109/TVCG.2017.2745258
   Xia JZ, 2018, J VISUAL LANG COMPUT, V48, P52, DOI 10.1016/j.jvlc.2018.08.003
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang L, 2012, J ZHEJIANG UNIV-SC B, V13, P855, DOI 10.1631/jzus.B1100382
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
NR 70
TC 5
Z9 5
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3312
EP 3326
DI 10.1109/TVCG.2022.3156760
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900012
PM 35254984
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Zhang, SH
   Chen, CH
   Zollmann, S
AF Zhang, Song-Hai
   Chen, Chiahao
   Zollmann, Stefanie
TI One-Step Out-of-Place Resetting for Redirected Walking in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Virtual environments; Aerospace electronics; User
   interfaces; Tracking; Teleportation; Reinforcement learning; Redirected
   walking; out-of-place resetting and two-arrows indicator
AB Redirected walking (RDW) allows users to explore virtual environments in limited physical spaces by imperceptibly steering them away from obstacles and space boundaries. However, even with those techniques, the risk of collision cannot always be avoided. For such situations, resetting techniques have been proposed to provide an immediate adjustment of the physical walking direction of a user. Existing resetting techniques are either applied in-place, where the user changes orientation but stays in the same position or out-of-place methods where the user is guided to move from the current position to a safe location all while freezing the movement in the virtual world. While out-of-place methods have the potential to provide more freedom to user movements after resetting, current out-of-place methods do not provide enough guidance for the users to move to optimal locations. In this work, we propose a novel out-of-place resetting strategy that guides users to optimal physical locations with the most potential for free movement and a smaller amount of resetting required for their further movements. For this purpose, we calculate a heat map of the walking area according to the average walking distance using a simulation of the currently used RDW algorithm. Based on this heat map, we identify the most suitable position for a one-step reset within a predefined searching range and use this one as the reset point. Our results show that our method increases the average moving distance within one cycle of resetting. Furthermore, our resetting method can be applied to any physical area with obstacles. That means that RDW methods that were not suitable for such environments (e.g., Steer to Center) combined with our resetting can also be extended to such complex walking areas. In addition, we present a user interface to provide a similar visual experience between these methods, using a two-arrows indicator to help users adjust their position and direction.
C1 [Zhang, Song-Hai; Chen, Chiahao] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
   [Zollmann, Stefanie] Univ Otago, Dept Comp Sci, Dunedin 9016, New Zealand.
C3 Tsinghua University; University of Otago
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100084, Peoples R China.
EM shz@tsinghua.edu.cn; accplusjh@gmail.com; stefanie.zollmann@otago.ac.nz
OI Zollmann, Stefanie/0000-0002-4690-5409
FU National Natural Science Foundation of China [62132012, 61772298];
   Research Grant of Beijing Higher Institution Engineering Research
   Center; Tsinghua-Tencent Joint Laboratory for Internet Innovation
   Technology
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62132012 and 61772298, in part by
   Research Grant of Beijing Higher Institution Engineering Research
   Center, and Tsinghua-Tencent Joint Laboratory for Internet Innovation
   Technology.
CR [Anonymous], 2016, Applied Computer Science
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P75, DOI 10.1109/3DUI.2009.4811208
   Chen H., 2018, P 25 IEEE C VIRT REA
   Chen HW, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P523
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Fajen BR, 2003, J EXP PSYCHOL HUMAN, V29, P343, DOI 10.1037/0096-1523.29.2.343
   Fan X., 2021, VIRTUAL REALITY INTE, V3, P501
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Razzaque S., 2005, Redirected Walking
   Sekiya N, 1996, J HUM MOVEMENT STUD, V30, P241
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.00-82, 10.1109/VR46266.2020.1581503942658]
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Xie X., 2010, Proc. 7th Symposium on Applied Perception in Graphics and Visualization (APGV), P65, DOI DOI 10.1145/1836248.1836260
NR 32
TC 12
Z9 12
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3327
EP 3339
DI 10.1109/TVCG.2022.3158609
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900013
PM 35275821
DA 2024-11-06
ER

PT J
AU Sarvghad, A
   Franqui-Nadal, R
   Reznik-Zellen, R
   Chawla, R
   Mahyar, N
AF Sarvghad, Ali
   Franqui-Nadal, Rolando
   Reznik-Zellen, Rebecca
   Chawla, Ria
   Mahyar, Narges
TI Scientometric Analysis of Interdisciplinary Collaboration and Gender
   Trends in 30 Years of IEEE VIS Publications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Co-authorship; collaboration; gender; IEEE VIS publications;
   inter-institutional; interdisciplinary; scientometric
ID SCIENTIFIC COLLABORATION; COMPUTER-SCIENCE; VISUALIZATION; NETWORK;
   PRODUCTIVITY; DIVERSITY; PATTERNS; MODEL
AB We present the results of a scientometric analysis of 30 years of IEEE VIS publications between 1990-2020, in which we conducted a multifaceted analysis of interdisciplinary collaboration and gender composition among authors. To this end, we curated BiblioVIS, a bibliometric dataset that contains rich metadata about IEEE VIS publications, including 3032 articles and 6113 authors. One of the main factors differentiating BiblioVIS from similar datasets is the authors' gender and discipline data, which we inferred through iterative rounds of computational and manual processes. Our analysis shows that, by and large, inter-institutional and interdisciplinary collaboration has been steadily growing over the past 30 years. However, interdisciplinary research was mainly between a few fields, including Computer Science, Engineering and Technology, and Medicine and Health disciplines. Our analysis of gender shows steady growth in women's authorship. Despite this growth, the gender distribution is still highly skewed, with men dominating (approximate to 75%) of this space. Our predictive analysis of gender balance shows that if the current trends continue, gender parity in the visualization field will not be reached before the third quarter of the century (approximate to 2070). Our primary goal in this work is to call the visualization community's attention to the critical topics of collaboration, diversity, and gender. Our research offers critical insights through the lens of diversity and gender to help accelerate progress towards a more diverse and representative research community.
C1 [Sarvghad, Ali; Franqui-Nadal, Rolando; Reznik-Zellen, Rebecca; Chawla, Ria; Mahyar, Narges] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Sarvghad, A (corresponding author), Univ Massachusetts Amherst, Amherst, MA 01003 USA.
EM asarv@cs.umass.edu; rfranqui@umass.edu; rreznikz@library.umass.edu;
   rchawla@umass.edu; nmahyar@cs.umass.edu
RI Reznik-Zellen, Rebecca/AAO-1897-2021
OI Reznik-Zellen, Rebecca/0000-0001-9321-8284; Sarvghad,
   Ali/0000-0003-3718-7043
CR Abbasi A, 2011, J INFORMETR, V5, P594, DOI 10.1016/j.joi.2011.05.007
   Aggrawal N, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P494, DOI 10.1109/NGCT.2016.7877466
   [Anonymous], 2021, ORCID PUBLICATIONS
   [Anonymous], THINGS AR CHANG 2021
   [Anonymous], INT MED LAB DRESD
   [Anonymous], GEN 4 ENG RES CTR
   [Anonymous], 2008, WSDM
   [Anonymous], ?About us"
   [Anonymous], GEND IO DET GEND NAM
   [Anonymous], OUTL AC DISC
   [Anonymous], IEEE VIS COD COND
   Bartneck C, 2010, SCIENTOMETRICS, V85, P41, DOI 10.1007/s11192-010-0242-4
   Bartneck C, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P699
   Beaver DD, 2001, SCIENTOMETRICS, V52, P365, DOI 10.1023/A:1014254214337
   Birnholtz JP, 2007, J AM SOC INF SCI TEC, V58, P2226, DOI 10.1002/asi.20684
   Bradford S. C., 1934, Engineering, V137, P85, DOI DOI 10.1177/016555158501000
   Bukvova H., 2010, Studying research collaboration: A literature review
   Chou JK, 2011, COMPUT GRAPH FORUM, V30, P721, DOI 10.1111/j.1467-8659.2011.01921.x
   Cohoon JM, 2011, COMMUN ACM, V54, P72, DOI 10.1145/1978542.1978561
   Correia A, 2018, SCIENTOMETRICS, V114, P31, DOI 10.1007/s11192-017-2562-0
   Council N.R., 2014, CONV FAC TRANSD INT, DOI DOI 10.17226/18722
   D'Ignazio C, 2020, STRONG IDEAS SERIES, P97
   Datta S, 2017, IEEE T BIG DATA, V3, P3, DOI 10.1109/TBDATA.2016.2611668
   Dattolo A, 2018, IEEE INT CON INF VIS, P133, DOI 10.1109/iV.2018.00033
   Delgado-Garcia JF, 2014, 2014 9TH LATIN AMERICAN WEB CONGRESS (LA-WEB), P77, DOI 10.1109/LAWeb.2014.13
   Divakarmurthy Pramod., 2012, Proceedings of the 27th Annual ACM Symposium on Applied Computing, P2041
   Dong YX, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P480, DOI 10.1145/2808797.2808846
   Dong-Pil Yu, 2020, GECCO'20. Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion, P61, DOI 10.1145/3377929.3398157
   Elmacioglu E, 2005, SIGMOD REC, V34, P33, DOI 10.1145/1083784.1083791
   Elsevier, 2021, GENDER GLOBAL RES LA
   Fanelli D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0149504
   Gaither K, 2017, IEEE COMPUT GRAPH, V37, P106, DOI 10.1109/MCG.2017.3621230
   Gaskó N, 2016, SCIENTOMETRICS, V108, P613, DOI 10.1007/s11192-016-1968-4
   Halevi G, 2019, SPRINGER HBK, P563, DOI 10.1007/978-3-030-02511-3_21
   Hamadicharef B, 2012, ADV INTEL SOFT COMPU, V144, P101
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Heinze T, 2008, RES POLICY, V37, P888, DOI 10.1016/j.respol.2008.01.009
   Henry N, 2007, INT J HUM-COMPUT INT, V23, P239, DOI 10.1080/10447310701702402
   Holman L, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004956
   Hornbæk K, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3325285
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Jiang XY, 2016, J VISUAL-JAPAN, V19, P561, DOI 10.1007/s12650-015-0323-9
   Barbosa SDJ, 2017, SCIENTOMETRICS, V110, P275, DOI 10.1007/s11192-016-2162-4
   Kaye J.J., 2009, EXT ABS ACM C HUMAN, P2585, DOI DOI 10.1145/1520340.1520364
   Keegan B, 2013, Arxiv, DOI arXiv:1307.7172
   Kim MC, 2016, SCIENTOMETRICS, V107, P123, DOI 10.1007/s11192-015-1830-0
   Li SF, 2007, ACAD EMERG MED, V14, P1194, DOI 10.1197/j.aem.2007.08.009
   Liu YX, 2013, INT CONF MACH LEARN, P1070, DOI 10.1109/ICMLC.2013.6890752
   Liu Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3553, DOI 10.1145/2556288.2556969
   Cavero JM, 2015, SCIENTOMETRICS, V103, P85, DOI 10.1007/s11192-014-1520-3
   Mattauch S, 2020, COMMUN ACM, V63, P74, DOI 10.1145/3376901
   McGee E.O., 2020, Black, Brown, bruised: How racialized STEM education stifles innovation
   Medel P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P411, DOI 10.1145/3017680.3017794
   Medin D. L., 2012, Diversity makes better science
   Mueller C, 2017, BMC SURG, V17, DOI 10.1186/s12893-017-0211-4
   National Science Foundation, GROW CONV RES
   National Science Foundation, CONV ACC
   Newman MEJ, 2004, P NATL ACAD SCI USA, V101, P5200, DOI 10.1073/pnas.0307545100
   Newman MEJ, 2001, P NATL ACAD SCI USA, V98, P404, DOI 10.1073/pnas.021544898
   Nielsen MW, 2017, P NATL ACAD SCI USA, V114, P1740, DOI 10.1073/pnas.1700616114
   Ortega L, 2006, COLL RES LIBR, V67, P446, DOI 10.5860/crl.67.5.446
   Padilla S., 2014, CHI 14 HUM FACT COMP, P815, DOI DOI 10.1145/2559206.2578867
   Peng YF, 2017, INFORM SYST FRONT, V19, P1329, DOI 10.1007/s10796-017-9771-1
   Pierce SJ, 1999, J AM SOC INFORM SCI, V50, P271, DOI 10.1002/(SICI)1097-4571(1999)50:3<271::AID-ASI10>3.0.CO;2-M
   Ponsard Antoine, 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, CHI EA 16, P2264, DOI 10.1145/2851581
   Porter AL, 2006, RES EVALUAT, V15, P187, DOI 10.3152/147154406781775841
   Qingyi Gao, 2010, Proceedings of the 2010 IEEE Second International Conference on Social Computing (SocialCom 2010). the Second IEEE International Conference on Privacy, Security, Risk and Trust (PASSAT 2010), P615, DOI 10.1109/SocialCom.2010.96
   Qiu L., 1992, Research Evaluation, V2, P169, DOI [DOI 10.1093/REV/2.3.169, 10.1093/rev/2.3.169]
   Richards C, 2016, INT REV PSYCHIATR, V28, P95, DOI 10.3109/09540261.2015.1106446
   Rodríguez D, 2012, J SYST SOFTWARE, V85, P562, DOI 10.1016/j.jss.2011.09.009
   Santamaría L, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.156
   Scherer Moritz, 2021, 2021 IEEE International Instrumentation and Measurement Technology Conference (I2MTC), DOI 10.1109/I2MTC50364.2021.9460037
   Schummer J, 2004, SCIENTOMETRICS, V59, P425, DOI 10.1023/B:SCIE.0000018542.71314.38
   Servia-Rodriguez S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0114302
   Sharp P, 2017, SCIENCE, V355, P589, DOI 10.1126/science.aam8563
   Shneiderman Ben, 2016, The New ABCs of Research: Achieving Breakthrough Collaborations
   Sonnenwald DH, 2007, ANNU REV INFORM SCI, V41, P643, DOI 10.1002/aris.2007.1440410121
   Sooryamoorthy R, 2007, J COMPUT-MEDIAT COMM, V12, P733, DOI 10.1111/j.1083-6101.2007.00347.x
   Spiel K, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3310425
   Stvilia B., 2010, P AM SOC INFORM SCI, V47, P1
   Tohidi H, 2006, INT J PROD ECON, V103, P610, DOI 10.1016/j.ijpe.2005.12.002
   Tovanich N, 2022, IEEE T VIS COMPUT GR, V28, P497, DOI 10.1109/TVCG.2021.3114787
   van Rijnsoever FJ, 2011, RES POLICY, V40, P463, DOI 10.1016/j.respol.2010.11.001
   Vincent Larivire, 2013, Science Nature News, V504, P211, DOI [DOI 10.1038/504211A, 10.1038/504211a]
   Vuillemot R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2703, DOI 10.1145/2702123.2702237
   Wagner C.S., 2001, WWW Document
   Wang LL, 2021, COMMUN ACM, V64, P78, DOI 10.1145/3430803
   Yang Y, 2017, VIS INFORM, V1, P40, DOI 10.1016/j.visinf.2017.01.005
   Young KL, 2021, GLOBAL NETW, V21, P365, DOI 10.1111/glob.12309
   Yu DJ, 2018, IEEE T FUZZY SYST, V26, P430, DOI 10.1109/TFUZZ.2017.2672732
   Zhang QP, 2010, IEEE INTELL SYST, V25, P67, DOI 10.1109/MIS.2010.136
NR 92
TC 3
Z9 3
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3340
EP 3353
DI 10.1109/TVCG.2022.3158236
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900014
PM 35286260
DA 2024-11-06
ER

PT J
AU Li, HY
   Shen, HW
AF Li, Haoyu
   Shen, Han-Wei
TI Local Latent Representation Based on Geometric Convolution for Particle
   Data Feature Exploration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature extraction; Neural networks; Point cloud compression; Data
   visualization; Convolution; Three-dimensional displays; Kernel; Data
   transformation; particle data; feature extraction and tracking; deep
   learning
ID TRACKING; EXTRACTION; SEARCH
AB Feature related particle data analysis plays an important role in many scientific applications such as fluid simulations, cosmology simulations and molecular dynamics. Compared to conventional methods that use hand-crafted feature descriptors, some recent studies focus on transforming the data into a new latent space, where features are easier to be identified, compared and extracted. However, it is challenging to transform particle data into latent representations, since the convolution neural networks used in prior studies require the data presented in regular grids. In this article, we adopt Geometric Convolution, a neural network building block designed for 3D point clouds, to create latent representations for scientific particle data. These latent representations capture both the particle positions and their physical attributes in the local neighborhood so that features can be extracted by clustering in the latent space, and tracked by applying tracking algorithms such as mean-shift. We validate the extracted features and tracking results from our approach using datasets from three applications and show that they are comparable to the methods that define hand-crafted features for each specific dataset.
C1 [Li, Haoyu; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Li, HY (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM li.8460@osu.edu; hwshen@cse.ohio-state.edu
RI Shen, Han-wei/A-4710-2012; Li, Haoyu/AGW-7688-2022
OI Li, Haoyu/0000-0002-7138-8263; Shen, Han-Wei/0000-0002-1211-2320
FU National Science Foundation Division of Information and Intelligent
   Systems [1955764]; National Science Foundation Office of Advanced
   Cyberinfrastructure [2112606]; U.S. Department of Energy Los Alamos
   National Laboratory [47145]; UT-Battelle LLC [4000159447]
FX This work was supported in part by the National Science Foundation
   Division of Information and Intelligent Systems under Grant 1955764, in
   part by the National Science Foundation Office of Advanced
   Cyberinfrastructure under Grant 2112606, in part by the U.S. Department
   of Energy Los Alamos National Laboratory contract under Grant 47145, and
   in part by UT-Battelle LLC under Grant 4000159447 program manager
   Margaret Lentz.
CR [Anonymous], 2006, PACIFIC GRAPHICS
   Asvadi A, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1255, DOI 10.1109/ITSC.2016.7795718
   Behroozi PS, 2013, ASTROPHYS J, V762, DOI 10.1088/0004-637X/762/2/109
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Biswas A, 2021, IEEE T VIS COMPUT GR, V27, P4439, DOI 10.1109/TVCG.2020.3006426
   Caban JJ, 2007, IEEE T VIS COMPUT GR, V13, P1472, DOI 10.1109/TVCG.2007.70599
   Chen J, 2003, PVG 2003 PROCEEDINGS, P103
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   Christoudias T, 2015, 2015 IEEE Scientific Visualization Conference (SciVis), P79
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Dutta S, 2016, IEEE T VIS COMPUT GR, V22, P837, DOI 10.1109/TVCG.2015.2467436
   Fryer CL, 2006, ASTROPHYS J, V643, P292, DOI 10.1086/501493
   Gralka P, 2018, IEEE COMPUT GRAPH, V38, P106, DOI 10.1109/MCG.2017.3301120
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Han M., 2021, arXiv, DOI DOI 10.1615/JFLOWVISIMAGEPROC.2022041197
   Hassani K, 2019, IEEE I CONF COMP VIS, P8159, DOI 10.1109/ICCV.2019.00825
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P1716, DOI 10.1109/TVCG.2018.2879866
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Ioffe Sergey, 2015, P MACHINE LEARNING R, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Ji GF, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P209, DOI 10.1109/VISUAL.2003.1250374
   Jiang M, 2002, P IEEE TCVG S VIS, DOI 10.2312/VisSym/VisSym02/217-225
   KIEFER J, 1953, P AM MATH SOC, V4, P502, DOI 10.2307/2032161
   Kuhnert J, 2014, Advances in PDE modeling and computation, P119
   Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109
   Li YY, 2018, ADV NEUR IN, V31
   Linsen L, 2008, IEEE T VIS COMPUT GR, V14, P1483, DOI 10.1109/TVCG.2008.167
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Monfort M., 2017, Modeling, Analysis, and Visualization of Anisotropy, P375
   Muelder C, 2009, IEEE PAC VIS SYMP, P17, DOI 10.1109/PACIFICVIS.2009.4906833
   Nadaraya EA., 1964, THEOR PROBAB APPL, V9, P141, DOI DOI 10.1002/bies.20342
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Porter WP., 2019, 2019 IEEE VISUALIZAT, P1
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   SAMTANEY R, 1994, COMPUTER, V27, P20, DOI 10.1109/2.299407
   Sauer F, 2017, IEEE T VIS COMPUT GR, V23, P1624, DOI 10.1109/TVCG.2017.2674918
   Silver D, 1998, VISUALIZATION '98, PROCEEDINGS, P79, DOI 10.1109/VISUAL.1998.745288
   Takle J, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P1482, DOI 10.1109/SC.Companion.2012.275
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Warner B, 1996, AM STAT, V50, P284, DOI 10.2307/2684922
   Weber G, 2011, MATH VIS, P241
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Xu JY, 2022, IEEE T VIS COMPUT GR, V28, P1514, DOI 10.1109/TVCG.2020.3017568
NR 52
TC 1
Z9 1
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3354
EP 3367
DI 10.1109/TVCG.2022.3159114
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900015
PM 35290186
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, C
   Zhang, SH
   Zhang, YZ
   Zollmann, S
   Hu, SM
AF Wang, Chen
   Zhang, Song-Hai
   Zhang, Yizhuo
   Zollmann, Stefanie
   Hu, Shi-Min
TI On Rotation Gains Within and Beyond Perceptual Limitations for Seated VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Task analysis; Computer science; Tracking;
   Visualization; Head-mounted displays; User experience; Rotation gains;
   amplified head rotation; head-mounted displays
ID HAND; EXPLORATION; WALKING
AB Head tracking in head-mounted displays (HMDs) enables users to explore a 360-degree virtual scene with free head movements. However, for seated use of HMDs such as users sitting on a chair or a couch, physically turning around 360-degree is not possible. Redirection techniques decouple tracked physical motion and virtual motion, allowing users to explore virtual environments with more flexibility. In seated situations with only head movements available, the difference of stimulus might cause the detection thresholds of rotation gains to differ from that of redirected walking. Therefore we present an experiment with a two-alternative forced-choice (2AFC) design to compare the thresholds for seated and standing situations. Results indicate that users are unable to discriminate rotation gains between 0.89 and 1.28, a smaller range compared to the standing condition. We further treated head amplification as an interaction technique and found that a gain of 2.5, though not a hard threshold, was near the largest gain that users consider applicable. Overall, our work aims to better understand human perception of rotation gains in seated VR and the results provide guidance for future design choices of its applications.
C1 [Wang, Chen; Zhang, Song-Hai; Zhang, Yizhuo; Hu, Shi-Min] Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100190, Peoples R China.
   [Zollmann, Stefanie] Univ Otago, Dept Comp Sci, Dunedin 9016, New Zealand.
C3 Tsinghua University; University of Otago
RP Wang, C (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, BNRist, Beijing 100190, Peoples R China.
EM cw.chenwang@outlook.com; shz@tsinghua.edu.cn;
   yizhuo-z18@mails.tsinghua.edu.cn; stefanie.zollmann@otago.ac.nz;
   shimin@tsinghua.edu.cn
RI Hu, Shi-Min/AAW-1952-2020; Wang, Chen/JPK-7141-2023
OI Wang, Chen/0000-0002-9315-3780; Zollmann, Stefanie/0000-0002-4690-5409;
   Hu, Shi-Min/0000-0001-7507-6542
FU Natural Science Foundation of China [62132012]; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology
FX This work was supported by the Natural Science Foundation of China under
   Grant 62132012, and in part by the Tsinghua-Tencent Joint Laboratory for
   Internet Innovation Technology. This work involved human subjects or
   animals in its research. Approval of all ethical and experimental
   procedures and protocols was granted by Ethics Committee of Tsinghua
   University, and performed inline with the Declaration of Helsinki.
CR Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Borah J., 1979, SENSORY MECH MODELIN
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Bruder G., 2009, WORKSHOP PERCEPTUAL, P10
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Brument H, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3485282
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Chin-I Huang, 2010, 2010 International Symposium on Computer, Communication, Control and Automation (3CA 2010), P179, DOI 10.1109/3CA.2010.5533601
   Congdon BJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364277
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.1581285352835, 10.1109/VR46266.2020.00-38]
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [10.20380/GI2018.21, DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23]
   Frees S, 2005, P IEEE VIRT REAL ANN, P99
   Freitag S, 2016, IEEE T VIS COMPUT GR, V22, P1462, DOI 10.1109/TVCG.2016.2518298
   Freiwald JP, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376574
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Han DT, 2018, IEEE T VIS COMPUT GR, V24, P1467, DOI 10.1109/TVCG.2018.2794659
   Hodgson E., 2008, ACM T APPL PERCEPT, V8, P1
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Jaekl PM, 2005, EXP BRAIN RES, V163, P388, DOI 10.1007/s00221-004-2191-8
   Jay C, 2003, PRESENCE-VIRTUAL AUG, V12, P268, DOI 10.1162/105474603765879521
   Jerald J, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P155
   Jialei Li, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P59, DOI 10.1109/3DUI.2015.7131727
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kohli L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P105, DOI 10.1109/3DUI.2012.6184193
   Kopper R., 2011, P 3 IEEE VR WORKSH P, P10
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Langbehn Eike, 2019, P MENSCH COMP 2019 H, P235, DOI [10.1145/3340764.3340778, DOI 10.1145/3340764.3340778]
   Li Y, 2021, Virtual Reality Intell. Hardware, V3, P451, DOI [10.1016/j.vrih.2021.06.003, DOI 10.1016/J.VRIH.2021.06.003.72]
   Linares D, 2016, R J, V8, P122
   Liu X., 2021, Virtual Reality Intell. Hardware, V3, P470, DOI DOI 10.1016/J.VRIH.2021.06.004.73Y
   Ngoc LL, 2013, P IEEE VIRT REAL ANN, P51, DOI 10.1109/VR.2013.6549359
   Matthews BJ, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P19, DOI [10.1109/VR.2019.8797974, 10.1109/vr.2019.8797974]
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nilsson NC, 2016, P IEEE VIRT REAL ANN, P241, DOI 10.1109/VR.2016.7504743
   Norouzi N, 2019, J REHABIL ASSIST TER, V6, DOI 10.1177/2055668319841309
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque S., 2005, Redirected Walking
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.1581330966612, 10.1109/VR46266.2020.00082]
   Stebbins T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P377, DOI [10.1109/vr.2019.8797994, 10.1109/VR.2019.8797994]
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.14506112[45]F
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Tanaka R, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2016.7460029
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wang M., 2021, VIRTUAL REALITY INTE, V3, piv
   Wang M, 2020, COMPUT VIS MEDIA, V6, P3, DOI 10.1007/s41095-020-0162-z
   Wang SC, 2004, IEEE SYS MAN CYBERN, P6291
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zhang R., 2013, Proc. Proceedings of the ACM Symposium on Applied Perception (SAP), P71
   Zhang SH, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P504, DOI 10.1109/VRW52623.2021.00134
   Zielasko D, 2021, COMPUTERS, V10, DOI 10.3390/computers10060073
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.1581426770550, 10.1109/VR46266.2020.00-44]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 68
TC 6
Z9 6
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3380
EP 3391
DI 10.1109/TVCG.2022.3159799
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900017
PM 35294351
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Betancourt, J
   Wojtkowski, B
   Castillo, P
   Thouvenin, I
AF Betancourt, Julio
   Wojtkowski, Baptiste
   Castillo, Pedro
   Thouvenin, Indira
TI Exocentric Control Scheme for Robot Applications: An Immersive Virtual
   Reality Approach
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Robots; Drones; Virtual environments; Visualization; Cameras; Autonomous
   aerial vehicles; Testing; Automatic control; robotics; teleoperation;
   UAVs; virtual reality; virtual robotics
ID QUATERNION-BASED CONTROL; BILATERAL TELEOPERATION; DISTURBANCE OBSERVER;
   QUADROTOR; INTERFACE; TRACKING; SYSTEM
AB Unmanned Aerial Vehicles (UAVs) exhibit great agility but usually require an experienced pilot to operate them in certain applications such as inspection for disaster scenarios or buildings. The reduction of cognitive overload when driving this kind of aerial robot becomes a challenge and several solutions can be found in the literature. A new virtual control scheme for reducing this cognitive overload when controlling an aerial robot is proposed in this paper. The architecture is based on a novel interaction Drone Exocentric Advanced Metaphor (DrEAM) located in a Cave Automated Virtual Environment (CAVE) and a real robot containing an embedded controller based on quaternion formulation. The testing room, where real robots are evolving, is located away from the CAVE and they are connected via UDP in a ground station. The user controls manually a virtual drone through the DrEAM interaction metaphor, and the real robot imitates autonomously in real time the trajectory imposed by the user in the virtual environment. Experimental results illustrate the easy implementation and feasibility of the proposed scheme in two different scenarios. Results from these tests show that the mental effort when controlling a drone using the proposed virtual control scheme is lower than when controlling it in direct view. Moreover, the easy maneuverability and controllability of the real drone is also demonstrated in real time experiments.
C1 [Betancourt, Julio; Wojtkowski, Baptiste; Castillo, Pedro; Thouvenin, Indira] Univ technol Compiegne, CNRS, Heudiasyc Heurist & Diag Complex Syst, CS 60 319, F-60203 Compiegne, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Technologie de Compiegne
RP Castillo, P (corresponding author), Univ technol Compiegne, CNRS, Heudiasyc Heurist & Diag Complex Syst, CS 60 319, F-60203 Compiegne, France.
EM gubetanc@hds.utc.fr; bwojtkow@hds.utc.fr; castillo@hds.utc.fr;
   ithouven@hds.utc.fr
RI Betancourt, Julio/JXM-4534-2024
OI Thouvenin, Indira/0000-0002-5279-1356; Castillo Garcia,
   Pedro/0000-0001-8324-8762
FU French Government Research Program Robotex Equipment of Excellence
   [ANR-10-EQPX-44]; ERDF (European Regional Development Fund);
   Hauts-de-France region
FX The authors would like to thank the French Government Research Program
   Robotex Equipment of Excellence ANR-10-EQPX-44 and the ERDF (European
   Regional Development Fund) 2014/2020 and the Hauts-de-France region for
   funding this project.
CR Abaunza H, 2017, IFAC PAPERSONLINE, V50, P11453, DOI 10.1016/j.ifacol.2017.08.1816
   [Anonymous], 2018, PROC 26 SIGNAL PROCE
   [Anonymous], 2000, Statistical Communique of the Peoples Republic of China on National Economic and Social Development
   [Anonymous], 2015, P 3 INT C HUM AG INT
   Baichuan Huang, 2019, 2019 International Conference on Robotics and Automation (ICRA), P6949, DOI 10.1109/ICRA.2019.8794200
   BERGAMASCO M, 1994, IEEE INT CONF ROBOT, P1449, DOI 10.1109/ROBOT.1994.351286
   Cariño J, 2015, INT CONF UNMAN AIRCR, P825, DOI 10.1109/ICUAS.2015.7152367
   Castillo A, 2019, CONTROL ENG PRACT, V82, P14, DOI 10.1016/j.conengprac.2018.09.016
   Chen MZ, 2019, IEEE T COMMUN, V67, P6386, DOI 10.1109/TCOMM.2019.2917440
   Chovancová A, 2016, ROBOT AUTON SYST, V79, P87, DOI 10.1016/j.robot.2016.01.011
   Ding Cheng-jun, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P2024, DOI 10.1109/ICAL.2009.5262601
   Dong-Soo Kwon, 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3114, DOI 10.1109/ROBOT.2000.845142
   Endsley Mica, 1988, P HUM FACT SOC ANN M, V32, P97, DOI 10.1177/154193128803200221
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Faessler M, 2017, IEEE ROBOT AUTOM LET, V2, P476, DOI 10.1109/LRA.2016.2640362
   Frenoy R., 2016, P 2016 C USER MODELI, P131
   Fricoteaux L, 2014, ENG APPL ARTIF INTEL, V33, P47, DOI 10.1016/j.engappai.2014.03.005
   Gioioso G, 2015, IEEE INT CONF ROBOT, P318, DOI 10.1109/ICRA.2015.7139018
   Gray Edwyn., 2004, 19 CENTURY TORPEDOES
   Herisse B, 2009, IEEE INT CONF ROBOT, P737
   Hirukawa H, 2004, ROBOT AUTON SYST, V48, P165, DOI 10.1016/j.robot.2004.07.007
   Hou XL, 2017, IFAC PAPERSONLINE, V50, P10262, DOI 10.1016/j.ifacol.2017.08.1474
   Ibarra-Jimenez E, 2017, IFAC PAPERSONLINE, V50, P11415, DOI 10.1016/j.ifacol.2017.08.1805
   Jeanne F, 2017, IEEE INT CONF ADV LE, P472, DOI 10.1109/ICALT.2017.32
   Kelly A, 2011, SPRINGER TRAC ADV RO, V70, P211
   Kim S, 2018, INT C CONTR AUTOMAT, P1541
   Lee SJ, 2014, CONTROL ENG PRACT, V33, P35, DOI 10.1016/j.conengprac.2014.09.002
   Li JY, 2018, ROBOT AUTON SYST, V108, P1, DOI 10.1016/j.robot.2018.06.001
   Lin J.-S., 2015, Comput. Sci. Inf. Syst, V3, P122, DOI [10.13189/csit.2015.030405, DOI 10.13189/CSIT.2015.030405]
   Lin QP, 1997, IEEE INT CONF ROBOT, P1022, DOI 10.1109/ROBOT.1997.614269
   Liu NJ, 2019, CHIN AUTOM CONGR, P1789, DOI [10.1109/CAC48633.2019.8997211, 10.1109/cac48633.2019.8997211]
   Loup-Escande E, 2017, COMPUT HUM BEHAV, V75, P42, DOI 10.1016/j.chb.2017.05.006
   LUMELSKY VJ, 1993, IEEE T SYST MAN CYB, V23, P194, DOI 10.1109/21.214777
   Macchini Matteo, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10212, DOI 10.1109/ICRA40945.2020.9196664
   Martínez CAL, 2015, IEEE T CONTR SYST T, V23, P206, DOI 10.1109/TCST.2014.2321522
   Martinez-Palafox O, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4193, DOI 10.1109/IROS.2006.281912
   Mercado D, 2018, ROBOTICA, V36, P1493, DOI 10.1017/S0263574718000516
   Murphy R.R., 2005, Proceedings of the Human;;;;;;Factors and Ergonomics Society Annual Meeting, DOI DOI 10.1177/154193120504900347
   Naceri A, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P284, DOI 10.1109/ICAR46387.2019.8981649
   Nahri SNF, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P416, DOI 10.1109/saupec/robmech/prasa48453.2020.9041010
   Okura, 2014, ITE TRANS MEDIA TECH, V2, P82, DOI DOI 10.3169/MTA.2.82
   Regenbrecht J, 2017, IEEE SYMP 3D USER, P199, DOI 10.1109/3DUI.2017.7893340
   Rifai H., 2011, IFAC P, V44, P13782
   Saakes D, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P13
   Saitoh Kensaku, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P173, DOI 10.1109/ISMAR.2006.297810
   Sanahuja, 2016, FL AIR FRAMEWORK LIB
   Sanchez LF, 2020, ROBOTICA, V38, P2189, DOI 10.1017/S026357472000003X
   Santiago DD, 2019, ISA T, V95, P392, DOI 10.1016/j.isatra.2019.05.006
   Slawiñski E, 2017, ISA T, V71, P415, DOI 10.1016/j.isatra.2017.09.021
   Stanton Christopher, 2012, P AUSTR C ROB AUT, V8, P51
   Suarez A, 2018, IEEE INT C INT ROBOT, P6746, DOI 10.1109/IROS.2018.8593940
   Fernandez RAS, 2016, INT CONF UNMAN AIRCR, P1013, DOI 10.1109/ICUAS.2016.7502665
   Teixeira JM, 2014, SYMP VIRTUAL AUGMENT, P28, DOI 10.1109/SVR.2014.42
   Temma R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P507, DOI 10.1145/3332165.3347953
   Thomason J, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3232232
   Thomason J, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P419, DOI 10.1145/3025171.3025179
   Walter B., 2004, AIAA 3 UNM UNL TECHN, P6320
   Ye YQ, 2013, IEEE-ASME T MECH, V18, P1431, DOI 10.1109/TMECH.2013.2255882
   Yew AWW, 2017, PROC CIRP, V61, P305, DOI 10.1016/j.procir.2016.11.183
   Yonezawa K, 2015, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2015.7223421
NR 60
TC 3
Z9 3
U1 2
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3392
EP 3404
DI 10.1109/TVCG.2022.3160389
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900018
PM 35298381
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hergl, C
   Nagel, T
   Scheuermann, G
AF Hergl, Chiara
   Nagel, Thomas
   Scheuermann, Gerik
TI Visualizing Higher-Order 3D Tensors by Multipole Lines
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tensors; Visualization; Stress; Strain; Indexes; Data visualization;
   Anisotropic magnetoresistance; Tensor algebra; higher-order tensor;
   line-based; deviatoric decomposition; anisotropy
AB Physics, medicine, earth sciences, mechanical engineering, geo-engineering, bio-engineering and many more application areas use tensorial data. For example, tensors are used in formulating the balance equations of charge, mass, momentum, or energy as well as the constitutive relations that complement them. Some of these tensors (i.e., stiffness tensor, strain gradient, photo-elastic tensor) are of order higher than two. Currently, there are nearly no visualization techniques for such data beyond glyphs. An important reason for this is the limit of currently used tensor decomposition techniques. In this article, we propose to use the deviatoric decomposition to draw lines describing tensors of arbitrary order in three dimensions. The deviatoric decomposition splits a three-dimensional tensor of any order with any type of index symmetry into totally symmetric, traceless tensors. These tensors, called deviators, can be described by a unique set of directions (called multipoles by J. C. Maxwell) and scalars. These multipoles allow the definition of multipole lines which can be computed in a similar fashion to tensor lines and allow a line-based visualization of three-dimensional tensors of any order. We give examples for the visualization of symmetric, second-order tensor fields as well as fourth-order tensor fields. To allow an interpretation of the multipole lines, we analyze the connection between the multipoles and the eigenvectors/eigenvalues in the second-order case. For the fourth-order stiffness tensor, we prove relations between multipoles and important physical quantities such as shear moduli as well as the eigenvectors of the second-order right Cauchy-Green tensor.
C1 [Hergl, Chiara; Scheuermann, Gerik] Univ Leipzig, Fac Math & Comp Sci, Inst Comp Sci, Image & Signal Proc Grp, D-04109 Leipzig, Germany.
   [Nagel, Thomas] Tech Univ Bergakad Freiberg, Chair Soil Mech & Fdn Engn, Geotech Inst, D-09599 Freiberg, Germany.
C3 Leipzig University; Technical University Freiberg
RP Hergl, C (corresponding author), Univ Leipzig, Fac Math & Comp Sci, Inst Comp Sci, Image & Signal Proc Grp, D-04109 Leipzig, Germany.
EM hergl@informatik.uni-leipzig.de; thomas.nagel@ifgt.tu-freiberg.de;
   scheuermann@informatik.uni-leipzig.de
RI ; Nagel, Thomas/T-8805-2019
OI Hergl, Chiara/0000-0002-4016-9113; Nagel, Thomas/0000-0001-8459-4616;
   Scheuermann, Gerik/0000-0001-5200-8870
CR BACKUS G, 1970, REV GEOPHYS SPACE GE, V8, P633, DOI 10.1029/RG008i003p00633
   Blecha C., 2021, EUROGRAPHICS ASS
   Bruno P, 2018, Arxiv, DOI arXiv:1803.10356
   Cowin SC., 2007, Tissue Mechanics, DOI DOI 10.1007/s10237-009-0173-2
   DELMARCELLE T, 1993, IEEE COMPUT GRAPH, V13, P25, DOI 10.1109/38.219447
   Dickinson R. R., 1989, Proceedings of the SPIE - The International Society for Optical Engineering, V1083, P173, DOI 10.1117/12.952885
   Dickinson R. R., 1991, Extracting Meaning from Complex Data: Processing, Display, Interaction II, V1459, P166
   Florack L, 2010, J MATH IMAGING VIS, V38, P171, DOI 10.1007/s10851-010-0217-3
   Hamermesh M., 1989, Addison Wesley Series in Physics
   Helbig K., 2015, FDN ANISOTROPY EXPLO, V22
   Hergl C, 2020, Arxiv, DOI arXiv:2009.11723
   Hergl C, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14209
   Hergl C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P291, DOI [10.1109/VISUAL.2019.8933592, 10.1109/visual.2019.8933592]
   Hlawitschka M, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P27
   Isenberg T, 2015, MATH VIS, P235, DOI 10.1007/978-3-319-15090-1_12
   JERPHAGNON J, 1978, ADV PHYS, V27, P609, DOI 10.1080/00018737800101454
   Kratz A, 2013, COMPUT GRAPH FORUM, V32, P49, DOI 10.1111/j.1467-8659.2012.03231.x
   Maas SA, 2012, J BIOMECH ENG-T ASME, V134, DOI 10.1115/1.4005694
   MEHRABADI MM, 1990, Q J MECH APPL MATH, V43, P15, DOI 10.1093/qjmam/43.1.15
   Nagel T, 2016, ENVIRON EARTH SCI, V75, DOI 10.1007/s12665-016-5429-4
   Neeman A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P35
   Neeman A. G., 2008, Proceedings of the Fifth Eurographics/IEEE VGTC Conference on PointBased Graphics, P121
   Peng Z., 2009, Proceedings of Theory and Practice of Computer Graphics, P149, DOI [10.2312/LocalChapterEvents/TPCG/TPCG09/149-163, DOI 10.2312/LOCALCHAPTEREVENTS/TPCG/TPCG09/149-163]
   RYCHLEWSKI J, 1984, PMM-J APPL MATH MEC+, V48, P303
   Schultz T, 2011, COMPUT GRAPH FORUM, V30, P841, DOI 10.1111/j.1467-8659.2011.01933.x
   Schultz T, 2010, COMPUT GRAPH FORUM, V29, P1143, DOI 10.1111/j.1467-8659.2009.01675.x
   Schultz T., 2013, VISUALIZATION PROCES
   Schultz T, 2010, IEEE T VIS COMPUT GR, V16, P1595, DOI 10.1109/TVCG.2010.199
   Sylvester J. J., 1876, London Edinburgh Dublin Philos. Mag. J. Sci., V2, P291, DOI DOI 10.1080/14786447608639108
   Systemes D., AB CAE
   Wilson A, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P11
   Zobel V., 2017, Modeling, Analysis, and Visualization of Anisotropy, P65
   Zou WN, 2013, INT J SOLIDS STRUCT, V50, P2457, DOI 10.1016/j.ijsolstr.2013.03.037
   Zou WN, 2001, MATH MECH SOLIDS, V6, P249, DOI 10.1177/108128650100600303
NR 34
TC 0
Z9 0
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3405
EP 3418
DI 10.1109/TVCG.2022.3158869
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900019
PM 35298379
DA 2024-11-06
ER

PT J
AU Mancinelli, C
   Nazzaro, G
   Pellacini, F
   Puppo, E
AF Mancinelli, Claudio
   Nazzaro, Giacomo
   Pellacini, Fabio
   Puppo, Enrico
TI b/Surf: Interactive Bezier Splines on Surface Meshes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Manifolds; Splines (mathematics); Measurement; Approximation algorithms;
   Visualization; Robustness; Geometry; Geometric meshes; spline curves;
   user interfaces; geometry processing
ID SUBDIVISION SCHEMES; CURVES; SMOOTHNESS
AB We present a practical framework to port Bezier curves to surfaces. We support the interactive drawing and editing of Bezier splines on manifold meshes with millions of triangles, by relying on just repeated manifold averages. We show that direct extensions of the de Casteljau and Bernstein evaluation algorithms to the manifold setting are fragile, and prone to discontinuities when control polygons become large. Conversely, approaches based on subdivision are robust and can be implemented efficiently. We implement manifold extensions of the recursive de Casteljau bisection, and an open-uniform Lane-Riesenfeld subdivision scheme. For both schemes, we present algorithms for curve tracing, point evaluation, and approximated point insertion. We run bulk experiments to test our algorithms for robustness and performance, and we compare them with other methods at the state of the art, always achieving correct results and superior performance. For interactive editing, we port all the basic user interface interactions found in 2D tools directly to the mesh. We also support mapping complex SVG drawings to the mesh and their interactive editing.
C1 [Mancinelli, Claudio; Puppo, Enrico] Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, I-16126 Genoa, GE, Italy.
   [Nazzaro, Giacomo; Pellacini, Fabio] Sapienza Univ Rome, Dept Comp Sci, I-00185 Rome, RM, Italy.
C3 University of Genoa; Sapienza University Rome
RP Puppo, E (corresponding author), Univ Genoa, Dept Informat Bioengn Robot & Syst Engn, I-16126 Genoa, GE, Italy.
EM claudio.mancinelli@dibris.unige.it; nazzaro@di.uniroma1.it;
   pellacini@di.uniroma1.it; enrico.puppo@unige.it
RI Mancinelli, Claudio/AAU-9061-2021
OI Puppo, Enrico/0000-0001-9780-5283; Mancinelli,
   Claudio/0000-0001-7935-3500
CR Absil PA, 2016, SIAM J IMAGING SCI, V9, P1788, DOI 10.1137/16M1057978
   [Anonymous], 2010, SCALABLE VECTOR GRAP
   [Anonymous], 2019, AD ILL
   [Anonymous], 2009, THESIS U MARYLAND CO
   Arnould A, 2015, LECT NOTES COMPUT SC, V9389, P491, DOI 10.1007/978-3-319-25040-3_53
   Bertsekas D.P., 1998, Network optimization: Continuous and discrete models
   Biermann H, 2002, ACM T GRAPHIC, V21, P312, DOI 10.1145/566570.566583
   Camarinha M., 1995, IMA Journal of Mathematical Control and Information, V12, P399, DOI 10.1093/imamci/12.4.399
   Cashman TJ, 2007, LECT NOTES COMPUT SC, V4647, P121
   De Goes Fernando, 2016, ACM Trans. Graph., V35, P1
   doCarmo M.P., 1992, Riemannian geometry. Mathematics: Theory & Applications
   Duchamp T, 2018, NUMER ALGORITHMS, V77, P361, DOI 10.1007/s11075-017-0319-8
   Dyn N, 2019, COMPUT AIDED GEOM D, V71, P119, DOI 10.1016/j.cagd.2019.03.003
   Dyn N, 2017, J COMPUT APPL MATH, V311, P54, DOI 10.1016/j.cam.2016.07.008
   Farin, 2001, CURVES SURFACES CAGD
   Gousenbourger P.-Y., 2018, J MATH IMAG VIS, V61, P1
   Gousenbourger PY, 2014, INT C PATT RECOG, P4086, DOI 10.1109/ICPR.2014.700
   GROVE K, 1973, MATH Z, V132, P11, DOI 10.1007/BF01214029
   Herholz P, 2019, COMPUT GRAPH FORUM, V38, P79, DOI 10.1111/cgf.13607
   Hofer M, 2004, ACM T GRAPHIC, V23, P284, DOI 10.1145/1015706.1015716
   Jin Y, 2019, COMPUT AIDED DESIGN, V113, P24, DOI 10.1016/j.cad.2019.03.001
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Knöppel F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462005
   LANE JM, 1980, IEEE T PATTERN ANAL, V2, P35, DOI 10.1109/TPAMI.1980.4766968
   LEE DT, 1984, NETWORKS, V14, P393, DOI 10.1002/net.3230140304
   Lin A., 2001, P 2001 INT S ALG APP, P36
   Morera DM, 2008, VISUAL COMPUT, V24, P1025, DOI 10.1007/s00371-008-0298-9
   Nava-Yazdani E, 2013, COMPUT AIDED GEOM D, V30, P722, DOI 10.1016/j.cagd.2013.06.002
   Nazzaro G, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3487909
   NOAKES L, 1989, IMA J MATH CONTROL I, V6, P465, DOI 10.1093/imamci/6.4.465
   Noakes L, 1998, ADV COMPUT MATH, V8, P165, DOI 10.1023/A:1018940112654
   Noakes L, 1999, P AM MATH SOC, V127, P1827, DOI 10.1090/S0002-9939-99-04809-1
   Panozzo D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461935
   PARK FC, 1995, J MECH DESIGN, V117, P36, DOI 10.1115/1.2826114
   Pellacini F, 2019, SMART TOOLS APPL GRA
   Poerner M, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 TALKS, DOI 10.1145/3214745.3214761
   Polthier Konrad., 1998, Mathematical visualization (Berlin, 1997), P135, DOI [10.1007/978-3-662-03567-2_11, DOI 10.1007/978-3-662-03567-2_11]
   Popiel T, 2007, J APPROX THEORY, V148, P111, DOI 10.1016/j.jat.2007.03.002
   Pottmann H, 2005, COMPUT AIDED GEOM D, V22, P693, DOI 10.1016/j.cagd.2005.06.006
   Sakai T., 1997, RIEMANNIAN GEOMETRY
   Salomon D., 2006, Curves and Surfaces for Computer Graphics
   Samir C, 2012, FOUND COMPUT MATH, V12, P49, DOI 10.1007/s10208-011-9091-7
   Schmidt R, 2013, COMPUT GRAPH FORUM, V32, P255, DOI 10.1111/cgf.12045
   Schmidt R, 2006, ACM T GRAPHIC, V25, P605, DOI 10.1145/1141911.1141930
   Sharp N, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417839
   Sharp N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3243651
   Sharp N, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322979
   Sharp Nicholas, 2019, geometry-central
   Sun Qian., 2013, Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, P153
   Wallner J., 2020, Handbook of Variational Methods for Nonlinear Geometric Data, P121
   Wallner J, 2006, CONSTR APPROX, V24, P289, DOI 10.1007/s00365-006-0638-3
   Wallner J, 2006, ACM T GRAPHIC, V25, P356, DOI 10.1145/1138450.1138459
   Xin SQ, 2007, COMPUT AIDED DESIGN, V39, P1081, DOI 10.1016/j.cad.2007.08.001
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
NR 54
TC 7
Z9 7
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3419
EP 3435
DI 10.1109/TVCG.2022.3171179
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900020
PM 35503826
DA 2024-11-06
ER

PT J
AU Reimann, D
   Ram, N
   Gaschler, R
AF Reimann, Daniel
   Ram, Nilam
   Gaschler, Robert
TI Lollipops Help Align Visual and Statistical Fit Estimates in
   Scatterplots With Nonlinear Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data models; Estimation; Computational modeling; Visualization; Data
   visualization; Psychology; Task analysis; Information visualization;
   perception and psychophysics; theory and models
ID PERCEPTUAL ORGANIZATION; ATTENTION; SLOPE; LAW
AB Scatterplots overlayed with a nonlinear model enable visual estimation of model-data fit. Although statistical fit is calculated using vertical distances, viewers' subjective fit is often based on shortest distances. Our results suggest that adding vertical lines ("lollipops") supports more accurate fit estimation in the steep area of model curves (https://osf.io/fybx5/).
C1 [Reimann, Daniel; Gaschler, Robert] Fernuniv, Dept Psychol, D-58097 Hagen, Germany.
   [Ram, Nilam] Stanford Univ, Dept Psychol & Commun, Stanford, CA 94305 USA.
C3 Fern University Hagen; Stanford University
RP Reimann, D (corresponding author), Fernuniv, Dept Psychol, D-58097 Hagen, Germany.
EM daniel.reimann@fernuni-hagen.de; nilamram@stanford.edu;
   robert.gaschler@fernuni-hagen.de
OI Ram, Nilam/0000-0003-1671-5257; Gaschler, Robert/0000-0002-8576-5330
CR Ali N, 2013, HUM FACTORS, V55, P183, DOI 10.1177/0018720812452592
   Baker CI, 2004, PSYCHOL SCI, V15, P460, DOI 10.1111/j.0956-7976.2004.00702.x
   Best LA, 2007, PERCEPT MOTOR SKILL, V104, P707, DOI 10.2466/PMS.104.3.707-721
   Ciccione L, 2021, COGNITIVE PSYCHOL, V128, DOI 10.1016/j.cogpsych.2021.101406
   Cleveland W.S., 1985, The Elements of Graphing Data
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   COLLYER CE, 1990, PERCEPT MOTOR SKILL, V71, P371
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Doherty ME, 2009, BEHAV RES METHODS, V41, P55, DOI 10.3758/BRM.41.1.55
   Duclos R, 2015, J CONSUM PSYCHOL, V25, P317, DOI 10.1016/j.jcps.2014.11.005
   Evans NJ, 2018, PSYCHOL REV, V125, P592, DOI 10.1037/rev0000105
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Heathcote A, 2000, PSYCHON B REV, V7, P185, DOI 10.3758/BF03212979
   Jewell G, 2000, NEUROPSYCHOLOGIA, V38, P93, DOI 10.1016/S0028-3932(99)00045-7
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   MOSTELLER F, 1981, AM STAT, V35, P150, DOI 10.2307/2683983
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   PALMER S, 1994, PSYCHON B REV, V1, P29, DOI 10.3758/BF03200760
   Reimann D, 2021, IEEE T VIS COMPUT GR, V27, P3834, DOI 10.1109/TVCG.2021.3051853
   Reimann D, 2020, EXP PSYCHOL, V67, P292, DOI 10.1027/1618-3169/a000499
   Salha R. B., 2015, International Journal of Statistics and Probability, V4, DOI [10.5539/ijsp.v4n1p138, DOI 10.5539/IJSP.V4N1P138]
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sher V, 2017, COMPUT GRAPH FORUM, V36, P61, DOI 10.1111/cgf.13168
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tufte Edward., 1993, The Visual Display of Quantitative Information
   Ware C., 2019, Information Visualization: Perception for Design
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Wickham H, 2015, STAT ANAL DATA MIN, V8, P203, DOI 10.1002/sam.11271
   Wilkinson L., 2012, APA HDB RES METHODS, P73, DOI [10.1037/13621-004, DOI 10.1037/13621-004]
   Woodin G, 2022, IEEE T VIS COMPUT GR, V28, P1209, DOI 10.1109/TVCG.2021.3088343
   Yang FM, 2019, IEEE T VIS COMPUT GR, V25, P1474, DOI 10.1109/TVCG.2018.2810918
   Zacks JM, 2020, POL INS BEH BRAIN SC, V7, P52, DOI 10.1177/2372732219893712
NR 33
TC 2
Z9 2
U1 1
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3436
EP 3440
DI 10.1109/TVCG.2022.3158093
PG 5
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H4XO7
UT WOS:000996011900021
PM 35263256
DA 2024-11-06
ER

PT J
AU Zeng, YH
   Fu, JL
   Chao, HY
   Guo, BN
AF Zeng, Yanhong
   Fu, Jianlong
   Chao, Hongyang
   Guo, Baining
TI Aggregated Contextual Transformations for High-Resolution Image
   Inpainting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Generators; Generative adversarial networks; Cognition; Training; Task
   analysis; Filling; Convolution; Image synthesis; image inpainting;
   object removal; generative adversarial networks (GAN)
ID TEXTURE SYNTHESIS; COMPLETION; REMOVAL
AB Image inpainting that completes large free-form missing regions in images is a promising yet challenging task. State-of-the-art approaches have achieved significant progress by taking advantage of generative adversarial networks (GAN). However, these approaches can suffer from generating distorted structures and blurry textures in high-resolution images (e.g., $512\times 512$512x512). The challenges mainly drive from (1) image content reasoning from distant contexts, and (2) fine-grained texture synthesis for a large missing region. To overcome these two challenges, we propose an enhanced GAN-based model, named Aggregated COntextual-Transformation GAN (AOT-GAN), for high-resolution image inpainting. Specifically, to enhance context reasoning, we construct the generator of AOT-GAN by stacking multiple layers of a proposed AOT block. The AOT blocks aggregate contextual transformations from various receptive fields, allowing to capture both informative distant image contexts and rich patterns of interest for context reasoning. For improving texture synthesis, we enhance the discriminator of AOT-GAN by training it with a tailored mask-prediction task. Such a training objective forces the discriminator to distinguish the detailed appearances of real and synthesized patches, and in turn facilitates the generator to synthesize clear textures. Extensive comparisons on Places2, the most challenging benchmark with 1.8 million high-resolution images of 365 complex scenes, show that our model outperforms the state-of-the-art. A user study including more than 30 subjects further validates the superiority of AOT-GAN. We further evaluate the proposed AOT-GAN in practical applications, e.g., logo removal, face editing, and object removal. Results show that our model achieves promising completions in the real world. We release codes and models in https://github.com/researchmm/AOT-GAN-for-Inpainting.
C1 [Zeng, Yanhong; Chao, Hongyang] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510275, Peoples R China.
   [Zeng, Yanhong; Chao, Hongyang] Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou 510006, Peoples R China.
   [Fu, Jianlong; Guo, Baining] Microsoft Res, Redmond, WA 98052 USA.
C3 Sun Yat Sen University; Microsoft
RP Chao, HY (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 510275, Peoples R China.; Chao, HY (corresponding author), Minist Educ, Key Lab Machine Intelligence & Adv Comp, Guangzhou 510006, Peoples R China.; Fu, JL (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM zengyh7@mail2.sysu.edu.cn; jianf@microsoft.com;
   isschhy@mail.sysu.edu.cn; bainguo@microsoft.com
RI zeng, yanhong/Y-2891-2018
FU NSF of China [61672548, U1611461]
FX This work was supported in part by NSF of China under Grants 61672548
   and U1611461.
CR Ballester C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P10, DOI 10.1109/ICCV.2001.937493
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chu-Tak Li, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12538), P5, DOI 10.1007/978-3-030-66823-5_1
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gilbert A, 2020, IEEE T VIS COMPUT GR, V26, P2417, DOI 10.1109/TVCG.2018.2889297
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Herling J, 2014, IEEE T VIS COMPUT GR, V20, P866, DOI 10.1109/TVCG.2014.2298016
   Hong Kibeom, 2021, ICCV, P14609
   Hu ZY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3320, DOI 10.1145/3394171.3413853
   Huang JB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982398
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, INT C LEARNING REPRE, P1
   Kawai N, 2016, IEEE T VIS COMPUT GR, V22, P1236, DOI 10.1109/TVCG.2015.2462368
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Miyato T., 2018, The 6th Int. Conf. on Learning Representations (ICLR)
   Nazeri K., 2019, Edgeconnect: Generative image inpainting with adversarial edge learning
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   PUKELSHEIM F, 1994, AM STAT, V48, P88, DOI 10.2307/2684253
   Qin C, 2018, SIGNAL PROCESS-IMAGE, V60, P160, DOI 10.1016/j.image.2017.10.003
   Qin J, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2020.103155
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sagong MC, 2019, PROC CVPR IEEE, P11352, DOI 10.1109/CVPR.2019.01162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1109/APCAP.2017.8420330, 10.1007/978-3-030-01216-8_1]
   Su H., 2018, PROC BRIT MACH VIS C
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Wan ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4672, DOI 10.1109/ICCV48922.2021.00465
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Y, 2018, ADV NEUR IN, V31
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang ZY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2486, DOI 10.1145/3219819.3219944
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Xue HW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P291, DOI 10.1145/3474085.3475421
   Yan WQ, 2005, MULTIMEDIA SYST, V10, P379, DOI 10.1007/s00530-005-0167-6
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yi ZL, 2020, PROC CVPR IEEE, P7505, DOI 10.1109/CVPR42600.2020.00753
   Yu F., 2015, ARXIV
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng Y., 2021, NEURIPS
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao S., 2020, PROC INT C LEARN REP
   Zheng H., 2021, IEEE INT C COMP VIS, P10242
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 72
TC 62
Z9 74
U1 24
U2 83
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL 1
PY 2023
VL 29
IS 7
BP 3266
EP 3280
DI 10.1109/TVCG.2022.3156949
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I1CA5
UT WOS:001000210200001
PM 35254985
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, CL
   Han, J
AF Wang, Chaoli
   Han, Jun
TI DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scientific visualization; deep learning; survey
ID NEURAL-NETWORKS; FLOW DATA; SUPERRESOLUTION; STREAMLINES; FRAMEWORK;
   PHYSICS; GRAPHS
AB Since 2016, we have witnessed the tremendous growth of artificial intelligence+visualization (AI+VIS) research. However, existing survey articles on AI+VIS focus on visual analytics and information visualization, not scientific visualization (SciVis). In this article, we survey related deep learning (DL) works in SciVis, specifically in the direction of DL4SciVis: designing DL solutions for solving SciVis problems. To stay focused, we primarily consider works that handle scalar and vector field data but exclude mesh data. We classify and discuss these works along six dimensions: domain setting, research task, learning type, network architecture, loss function, and evaluation metric. The article concludes with a discussion of the remaining gaps to fill along the discussed dimensions and the grand challenges we need to tackle as a community. This state-of-the-art survey guides SciVis researchers in gaining an overview of this emerging topic and points out future directions to grow this research.
C1 [Wang, Chaoli; Han, Jun] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Wang, CL (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM chaoli.wang@nd.edu; jhan5@nd.edu
RI Wang, Chaoli/AAJ-5173-2020
OI Han, Jun/0000-0002-7286-062X; Wang, Chaoli/0000-0002-0859-3619
FU U.S. National Science Foundation [IIS-1455886, CNS-1629914, DUE-1833129,
   IIS-1955395, IIS-2101696, OAC-2104158]
FX This work was supported by U.S. National Science Foundation under Grants
   IIS-1455886, CNS-1629914, DUE-1833129, IIS-1955395, IIS-2101696, and
   OAC-2104158.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   An YF, 2021, IEEE COMPUT GRAPH, V41, P122, DOI 10.1109/MCG.2021.3097555
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ballard D H., 1987, AAAI C ARTIFICIAL IN, P279
   Barrow H.G., 1977, P 5 INT JOINT C ART, P659
   Bau David, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P351, DOI 10.1007/978-3-030-58452-8_21
   Bau D, 2019, 7 INT C LEARNING REP
   Bau D, 2020, P NATL ACAD SCI USA, V117, P30071, DOI 10.1073/pnas.1907375117
   Bau D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323023
   Bengio Y, 2021, COMMUN ACM, V64, P58, DOI 10.1145/3448250
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Berthelot D, 2017, Arxiv, DOI [arXiv:1703.10717, DOI 10.1109/AC-CESS.2018.2804278]
   Bi J., 2003, P 20 INT C MACH LEAR
   Borkiewicz K, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P1, DOI 10.1109/VIS49827.2021.9623327
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Carion N, 2020, EUR C COMP VIS, P213, DOI 10.1007/978-3-030-58452-813
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chan ER, 2021, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR46437.2021.00574
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Chu MY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459845
   Chu MY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073643
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Corouge I, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P344
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2019, J VISUAL-JAPAN, V22, P65, DOI 10.1007/s12650-018-0523-1
   Dosovitskiy A., 2020, PROC INT C LEARN REP
   Eckert ML, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356545
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Fang ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1408, DOI 10.1109/ICCV48922.2021.00146
   Frogner C, 2015, ADV NEUR IN, V28
   Ghahremani P, 2022, IEEE T VIS COMPUT GR, V28, P4951, DOI 10.1109/TVCG.2021.3109460
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gori M, 2005, IEEE IJCNN, P729
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Grill J.-B., 2020, P 34 INT C NEURAL IN, P21284
   Gu P., 2022, P IEEE PAC VIS S
   Gu PF, 2021, IEEE COMPUT GRAPH, V41, P111, DOI 10.1109/MCG.2021.3089627
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Han J, 2022, COMPUT GRAPH FORUM, V41, P109, DOI 10.1111/cgf.14526
   Han J, 2022, VIS INFORM, V6, P62, DOI 10.1016/j.visinf.2022.04.004
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, COMPUT GRAPH-UK, V103, P168, DOI 10.1016/j.cag.2022.02.001
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2019, IEEE COMPUT GRAPH, V39, P54, DOI 10.1109/MCG.2018.2881523
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Han M., 2021, arXiv, DOI DOI 10.1615/JFLOWVISIMAGEPROC.2022041197
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2016, ICLR
   Hsu TMH, 2019, Arxiv, DOI arXiv:1909.06335
   He KM, 2020, PROC CVPR IEEE, P9726, DOI 10.1109/CVPR42600.2020.00975
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2020, VIS INFORM, V4, P109, DOI 10.1016/j.visinf.2020.04.004
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   He XY, 2022, J VISUAL-JAPAN, V25, P379, DOI 10.1007/s12650-021-00787-7
   He XY, 2022, J VISUAL-JAPAN, V25, P77, DOI 10.1007/s12650-021-00779-7
   Hensel M, 2017, ADV NEUR IN, V30
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Hong F, 2018, IEEE PAC VIS SYMP, P76, DOI 10.1109/PacificVis.2018.00018
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jakob J, 2021, IEEE T VIS COMPUT GR, V27, P1279, DOI 10.1109/TVCG.2020.3028947
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Kairouz P, 2021, FOUND TRENDS MACH LE, V14, P1, DOI 10.1561/2200000083
   Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5
   Kashir B, 2021, J VISUAL-JAPAN, V24, P771, DOI 10.1007/s12650-020-00732-0
   Kato H, 2020, Arxiv, DOI arXiv:2006.12057
   KAWATO M, 1990, BIOL CYBERN, V62, P275, DOI 10.1007/BF00201442
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P59, DOI 10.1111/cgf.13619
   Kimura I, 2009, J VISUAL-JAPAN, V12, P73, DOI 10.1007/BF03181945
   Kipf TN, 2016, arXiv:1609.02907, P1
   Kohl G., 2020, PMLR, P5349
   Krizhevsky A., 2012, ImageNet classification with deep convolutional neural networks, P1097
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lan FF, 2021, COMPUT GRAPH FORUM, V40, P635, DOI 10.1111/cgf.14332
   Lan SY, 2019, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2019.00109
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li DQ, 2021, PROC CVPR IEEE, P8296, DOI 10.1109/CVPR46437.2021.00820
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li HY, 2023, IEEE T VIS COMPUT GR, V29, P3354, DOI 10.1109/TVCG.2022.3159114
   Li MY, 2020, PROC CVPR IEEE, P5283, DOI 10.1109/CVPR42600.2020.00533
   Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057
   Lin J., 2019, PROC INT C LEARN REP, P1
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu Q, 2019, Arxiv, DOI arXiv:1912.03587
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu Y, 2019, J VISUAL-JAPAN, V22, P95, DOI 10.1007/s12650-018-0519-x
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Ma KL, 2007, IEEE COMPUT GRAPH, V27, P6, DOI 10.1109/MCG.2007.129
   Marzouk A, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852164
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Kipf TN, 2016, Arxiv, DOI arXiv:1611.07308
   Nguyen N, 2021, Arxiv, DOI arXiv:2104.01554
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/visual.2019.8933759, 10.1109/VISUAL.2019.8933759]
   Raina R., 2009, LEARNING USING GRAPH, P873, DOI DOI 10.1145/1553374.1553486
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Raji M., 2017, PROC EUROGRAPHICS S, P31
   Ren K, 2020, ISPRS INT GEO-INF, V9, DOI 10.3390/ijgi9010019
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosenblatt F., 1961, 1196G8 CORN U
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rumelhart David E., 1986, Learning internal representations by error propagation, DOI [DOI 10.7551/MITPRESS/5236.001.0001, 10.1016/b978-1-4832-1446-7.50035-2]
   Sahoo S., 2021, PROC EUROGRAPHICS VI, P49
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Sajjadi MSM, 2017, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2017.481
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shen ZQ, 2024, Arxiv, DOI arXiv:1810.13306
   Shi N, 2022, IEEE T VIS COMPUT GR, V28, P2301, DOI 10.1109/TVCG.2022.3165345
   Shi N, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3309993
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi XJ, 2015, ADV NEUR IN, V28
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V., 2020, P ADV NEUR INF PROC
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Thomas MM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417786
   Thuerey N., 2021, arXiv
   Tkachev G, 2022, IEEE T VIS COMPUT GR, V28, P4713, DOI 10.1109/TVCG.2021.3101418
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Tzeng FY, 2005, IEEE T VIS COMPUT GR, V11, P273, DOI 10.1109/TVCG.2005.38
   Tzeng FY, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P505, DOI 10.1109/VISUAL.2003.1250413
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CL, 2017, COMPUT GRAPH FORUM, V36, P263, DOI 10.1111/cgf.12800
   Wang H., 2020, PROC INT C LEARN REP, P1
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang XY, 2019, IEEE I CONF COMP VIS, P6970, DOI 10.1109/ICCV.2019.00707
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang YF, 2021, IEEE T VIS COMPUT GR, V27, P1301, DOI 10.1109/TVCG.2020.3030374
   Wang YF, 2020, IEEE T VIS COMPUT GR, V26, P960, DOI 10.1109/TVCG.2019.2934369
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss J., 2021, arXiv, DOI 10.48550/arXiv.2106.05429
   Weiss S, 2022, Arxiv, DOI arXiv:2112.01579
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Werhahn M, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340251
   Wiewel S, 2020, COMPUT GRAPH FORUM, V39, P15, DOI 10.1111/cgf.14097
   Wiewel S, 2019, COMPUT GRAPH FORUM, V38, P71, DOI 10.1111/cgf.13620
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Wurster SW, 2022, Arxiv, DOI arXiv:2107.00462
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Xu H, 2023, COMPUT ECON, V61, P1, DOI 10.1007/s10614-019-09909-8
   Yang CH, 2019, J VISUAL-JAPAN, V22, P991, DOI 10.1007/s12650-019-00583-4
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang QS, 2018, FRONT INFORM TECH EL, V19, P27, DOI 10.1631/FITEE.1700808
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang Si, 2019, Comput Soc Netw, V6, P11, DOI 10.1186/s40649-019-0069-y
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhang YX, 2021, PROC CVPR IEEE, P10140, DOI 10.1109/CVPR46437.2021.01001
   Zhang ZW, 2022, IEEE T KNOWL DATA EN, V34, P249, DOI 10.1109/TKDE.2020.2981333
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
   Zhu FY, 2021, IEEE COMPUT GRAPH, V41, P57, DOI 10.1109/MCG.2021.3097730
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Y., 2021, P IEEECVF INT C COMP, P5057
   Zoph Barret, 2017, 5 INT C LEARN REPR I
NR 186
TC 16
Z9 18
U1 4
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3714
EP 3733
DI 10.1109/TVCG.2022.3167896
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200019
PM 35439135
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, Q
   Su, HL
   Duanmu, ZF
   Liu, WT
   Wang, Z
AF Liu, Qi
   Su, Honglei
   Duanmu, Zhengfang
   Liu, Wentao
   Wang, Zhou
TI Perceptual Quality Assessment of Colored 3D Point Clouds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Monitoring; Color; Databases; Colored noise;
   Three-dimensional displays; Quality assessment; Point cloud; subjective
   quality assessment; attention model; objective quality assessment
ID VISUAL QUALITY; GEOMETRY; ERROR; MODEL
AB 3D point clouds have found a wide variety of applications in multimedia processing, remote sensing, and scientific computing. Although most point cloud processing systems are developed to improve viewer experiences, little work has been dedicated to perceptual quality assessment of 3D point clouds. In this work, we build a new 3D point cloud database, namely the Waterloo Point Cloud (WPC) database. In contrast to existing datasets consisting of small-scale and low-quality source content of constrained viewing angles, the WPC database contains 20 high quality, realistic, and omni-directional source point clouds and 740 diversely distorted point clouds. We carry out a subjective quality assessment experiment over the database in a controlled lab environment. Our statistical analysis suggests that existing objective point cloud quality assessment (PCQA) models only achieve limited success in predicting subjective quality ratings. We propose a novel objective PCQA model based on an attention mechanism and a variant of information content-weighted structural similarity, which significantly outperforms existing PCQA models. The database has been made publicly available at https://github.com/qdushl/Waterloo-Point-Cloud-Database.
C1 [Liu, Qi; Su, Honglei] Qingdao Univ, Coll Elect Informat, Qingdao 266071, Peoples R China.
   [Duanmu, Zhengfang; Liu, Wentao; Wang, Zhou] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada.
C3 Qingdao University; University of Waterloo
RP Su, HL (corresponding author), Qingdao Univ, Coll Elect Informat, Qingdao 266071, Peoples R China.
EM sdqi.liu@gmail.com; suhonglei@qdu.edu.cn; zduanmu@uwaterloo.ca;
   w238liu@uwaterloo.ca; zhou.wang@uwaterloo.ca
RI Su, Honglei/KQV-0892-2024
OI , Qi/0000-0002-3958-9962; Su, Honglei/0000-0001-6144-4930; Wang,
   Zhou/0000-0003-4413-4441
FU Natural Sciences and Engineering Research Council of Canada; National
   Natural Science Foundation of China [61772294, 62172259]; Shandong
   Provincial Natural Science Foundation of China [ZR2018PF002,
   ZR2021MF025]; Open Project Program of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [VRLAB2021A01]; Joint
   Funding for Smart Computing of Shandong Natural Science Foundation of
   China [ZR2019LZH002]; State Key Laboratory of High Performance Server
   and Storage Technology, Inspur Group, Jinan, China
FX & nbsp;This work was supported in part by the Natural Sciences and
   Engineering Research Council of Canada, in part by the National Natural
   Science Foundation of China under Grants 61772294 and 62172259, in part
   by the Shandong Provincial Natural Science Foundation of China under
   Grants ZR2018PF002 and ZR2021MF025, in part by the Open Project Program
   of State Key Laboratory of Virtual Reality Technology and Systems,
   Beihang University, under Grant VRLAB2021A01, in part by the Joint
   Funding for Smart Computing of Shandong Natural Science Foundation of
   China under Grant ZR2019LZH002, and in part by jointly completed by the
   State Key Laboratory of High Performance Server and Storage Technology,
   Inspur Group, Jinan, China.
CR Agisoft, AG PHOT
   Alexiou E., 2018, P IEEE INT C MULT EX
   Alexiou E., 2018, PROC SPIE OPT ENG AP
   Alexiou E., 2019, INT WORK QUAL MULTIM, P3, DOI DOI 10.1109/qomex.2019.8743277
   Alexiou E., 2017, 9 INT C QUAL MULTIME, P1
   Alexiou E., 2017, P APPL DIGIT IMAGE P
   Alexiou E, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123121
   Alexiou E, 2020, IEEE INT CONF MULTI
   Alexiou E, 2018, IEEE INT CON MULTI
   Alexiou E, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.20
   Alexiou E, 2018, PROC SPIE, V10752, DOI 10.1117/12.2321518
   Alexiou E, 2018, PICT COD SYMP, P51, DOI 10.1109/PCS.2018.8456252
   Alexiou E, 2017, IEEE INT WORKSH MULT
   Cao KM, 2020, IEEE ACCESS, V8, P171203, DOI 10.1109/ACCESS.2020.3024633
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cignoni P., 2008, 6 EUR IT CHAPT C 200, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALCHAPCONF/129-138, 10.2312/LocalChapterEvents/ItalChap, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/ 129-136, DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136]
   CloudCompare, CloudCompare 3D point cloud and mesh processing software open source project
   Cruz LAD, 2019, INT WORK QUAL MULTIM, DOI [10.1109/qomex.2019.8743258, 10.1109/LARS-SBR-WRE48964.2019.00009]
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Diniz R., 2021, Electronic Imaging, P256
   Diniz R, 2021, IEEE SIGNAL PROC LET, V28, P1150, DOI 10.1109/LSP.2021.3088059
   Diniz R, 2020, IEEE IMAGE PROC, P3443, DOI 10.1109/ICIP40778.2020.9190956
   Diniz R, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123076
   Dumic E, 2018, 2018 FIRST INTERNATIONAL COLLOQUIUM ON SMART GRID METROLOGY (SMAGRIMET)
   Dumic E, 2021, EUR SIGNAL PR CONF, P595, DOI 10.23919/Eusipco47968.2020.9287504
   Guede C., 2017, JTC1SC29WG11 ISOIEC
   Gutierrez J., 2020, Electronic Imaging, P128
   He ZY, 2021, IEEE IMAGE PROC, P1444, DOI 10.1109/ICIP42928.2021.9506762
   Hua L., 2021, PROC IEEE INT S BROA, P1
   Hua L, 2022, IET IMAGE PROCESS, V16, P1083, DOI 10.1049/ipr2.12211
   Hua L, 2020, PROC SPIE, V11550, DOI 10.1117/12.2573686
   ITU, 2012, BT50013 ITU
   Javaheri Alireza, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P1, DOI 10.1109/ICMEW.2017.8026263
   Javaheri A, 2020, Arxiv, DOI arXiv:2003.13669
   Javaheri A, 2021, IEEE T MULTIMEDIA, V23, P4049, DOI 10.1109/TMM.2020.3037481
   Javaheri A, 2020, IEEE IMAGE PROC, P3438, DOI [10.1109/ICIP40778.2020.9191233, 10.1109/icip40778.2020.9191233]
   Javaheri A, 2020, IEEE SIGNAL PROC LET, V27, P1350, DOI 10.1109/LSP.2020.3010128
   Javaheri A, 2017, IEEE INT WORKSH MULT
   JPEG, JPEG PLEN DAT
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Lavoué G, 2016, IEEE T VIS COMPUT GR, V22, P1987, DOI 10.1109/TVCG.2015.2480079
   Le Callet P., 2019, PROC ACM S APPL PERC, P1
   Liu Q, 2021, IEEE T CIRC SYST VID, V31, P4645, DOI 10.1109/TCSVT.2021.3100282
   Liu Q, 2021, IEEE T MULTIMEDIA, V23, P3278, DOI 10.1109/TMM.2020.3023294
   Liu Q, 2021, IEEE T IMAGE PROCESS, V30, P6623, DOI 10.1109/TIP.2021.3096060
   Liu Y., 2020, arXiv
   Loop C., 2016, ISO/ IEC JTC1/ SC29 Joint WG11/WG1 (MPEG/JPEG) input document m38673 M 72012
   Mammou K., 2017, JTC1SC29WG11 MPEG IS
   Mammou K., 2018, JTC1SC29WG11 MPEG IS
   Mekuria R., 2016, INT ORG STANDARDIZAT
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   Meynet G, 2019, INT WORK QUAL MULTIM
   Montgomery D. C., 2014, Applied Statistics and Probability for Engineers, V6
   MPEG, MPEG POINT CLOUD DAT
   Nehmé Y, 2021, IEEE T VIS COMPUT GR, V27, P2202, DOI 10.1109/TVCG.2020.3036153
   Perry S, 2020, IEEE IMAGE PROC, P3428, DOI 10.1109/ICIP40778.2020.9191308
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Solimini AG, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056160
   Su HL, 2019, IEEE IMAGE PROC, P3182, DOI [10.1109/ICIP.2019.8803298, 10.1109/icip.2019.8803298]
   Tao WX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5266, DOI 10.1145/3474085.3475645
   Tian D., 2017, ISO/IEC JTC1/SC29/WG11 Doc. M39966
   Tian D., 2017, ISOIEC JTC1 SC29WG11
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Torlig EM, 2018, PROC SPIE, V10752, DOI 10.1117/12.2322741
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Viola I, 2020, IEEE SIGNAL PROC LET, V27, P1660, DOI 10.1109/LSP.2020.3024065
   Viola I, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123089
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu HK, 2019, Arxiv, DOI arXiv:1908.02111
   Wu XJ, 2021, IEEE T CIRC SYST VID, V31, P4630, DOI 10.1109/TCSVT.2021.3101484
   Xu YL, 2022, IEEE T BROADCAST, V68, P33, DOI 10.1109/TBC.2021.3114510
   Yang Q, 2021, IEEE T MULTIMEDIA, V23, P3877, DOI 10.1109/TMM.2020.3033117
   Yang Qi, 2022, IEEE Trans Pattern Anal Mach Intell, V44, P3015, DOI 10.1109/TPAMI.2020.3047083
   Ye SQ, 2022, IEEE T VIS COMPUT GR, V28, P3206, DOI 10.1109/TVCG.2021.3058311
   Zeng J, 2020, IEEE T IMAGE PROCESS, V29, P3474, DOI 10.1109/TIP.2019.2961429
   Zerman E., 2019, IS&T Electronic Imaging, Image Quality and System Performance XVI
   Zerman E, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123137
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhang J, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P827, DOI 10.1109/ICALIP.2014.7009910
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang YJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1230, DOI 10.1145/3474085.3475294
   Zhang ZC, 2022, Arxiv, DOI arXiv:2107.02041
   Zhao X, 2022, IEEE T VIS COMPUT GR, V28, P4940, DOI 10.1109/TVCG.2021.3109392
NR 92
TC 28
Z9 29
U1 8
U2 34
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3642
EP 3655
DI 10.1109/TVCG.2022.3167151
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200014
PM 35417349
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Eirich, J
   Jaeckle, D
   Sedlmair, M
   Wehner, C
   Schmid, U
   Bernard, J
   Schreck, T
AF Eirich, Joscha
   Jaeckle, Dominik
   Sedlmair, Michael
   Wehner, Christoph
   Schmid, Ute
   Bernard, Jurgen
   Schreck, Tobias
TI ManuKnowVis: How to Support Different User Groups in Contextualizing and
   Leveraging Knowledge Repositories
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Design study; H.5.2 [Information interfaces and presentation]: User
   interfaces-graphical user interfaces (GUI); user-centered design; visual
   analytics in manufacturing
ID VISUALIZATION; DESIGN; INTERNET; SYSTEM; THINGS; MODEL; GRAPH
AB We present ManuKnowVis, the result of a design study, in which we contextualize data from multiple knowledge repositories of a manufacturing process for battery modules used in electric vehicles. In data-driven analyses of manufacturing data, we observed a discrepancy between two stakeholder groups involved in serial manufacturing processes: Knowledge providers (e.g., engineers) have domain knowledge about the manufacturing process but have difficulties in implementing data-driven analyses. Knowledge consumers (e.g., data scientists) have no first-hand domain knowledge but are highly skilled in performing data-driven analyses. ManuKnowVis bridges the gap between providers and consumers and enables the creation and completion of manufacturing knowledge. We contribute a multi-stakeholder design study, where we developed ManuKnowVis in three main iterations with consumers and providers from an automotive company. The iterative development led us to a multiple linked view tool, in which, on the one hand, providers can describe and connect individual entities (e.g., stations or produced parts) of the manufacturing process based on their domain knowledge. On the other hand, consumers can leverage this enhanced data to better understand complex domain problems, thus, performing data analyses more efficiently. As such, our approach directly impacts the success of data-driven analyses from manufacturing data. To demonstrate the usefulness of our approach, we carried out a case study with seven domain experts, which demonstrates how providers can externalize their knowledge and consumers can implement data-driven analyses more efficiently.
C1 [Eirich, Joscha; Wehner, Christoph; Schmid, Ute] Univ Bamberg, D-96047 Bamberg, Germany.
   [Eirich, Joscha; Jaeckle, Dominik] BMW Grp, D-80788 Munich, Germany.
   [Sedlmair, Michael] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Bernard, Jurgen] Univ Zurich, UZH Digital Socienty Initiat DSI, CH-8006 Zurich, Switzerland.
   [Schreck, Tobias] Graz Univ Technol, A-8010 Graz, Austria.
C3 Otto Friedrich University Bamberg; BMW AG; University of Stuttgart;
   University of Zurich; Graz University of Technology
RP Eirich, J (corresponding author), Univ Bamberg, D-96047 Bamberg, Germany.; Eirich, J (corresponding author), BMW Grp, D-80788 Munich, Germany.
EM joscha.eirich@uni-bamberg.de; dominik.Jaeckle@bmw.de;
   michael.sedlmair@visus.uni-stuttgart.de;
   christoph.wehner@uni-bamberg.de; ute.schmid@uni-bamberg.de;
   mail@juergen-bernard.de; tobias.schreck@cgv.tugraz.at
RI Bernard, Jürgen/AAK-5732-2021
OI Schmid, Ute/0000-0002-1301-0326; Schreck, Tobias/0000-0003-0778-8665;
   Wehner, Christoph/0000-0003-0421-4113
FU Austrian FFG-COMET-K1 Center Pro2Future [881844]
FX The work of Tobias Schreck was partially supported in part by the
   Austrian FFG-COMET-K1 Center Pro2Future (Products and Production Systems
   of the Future) under Grant 881844.
CR Ansari F, 2019, IFAC PAPERSONLINE, V52, P1597, DOI 10.1016/j.ifacol.2019.11.428
   Ansari F, 2018, CIRP J MANUF SCI TEC, V22, P91, DOI 10.1016/j.cirpj.2018.06.002
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Barsky A, 2008, IEEE T VIS COMPUT GR, V14, P1253, DOI 10.1109/TVCG.2008.117
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Bousdekis A, 2019, IFAC PAPERSONLINE, V52, P607, DOI 10.1016/j.ifacol.2019.11.226
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Culjak I., 2012, 2012 35th International Convention on Information and Communication Technology, Electronics and Microelectronics, P1725
   Dudás M, 2018, KNOWL ENG REV, V33, DOI 10.1017/S0269888918000073
   Eiglsperger M, 2004, LECT NOTES COMPUT SC, V3383, P155
   Eirich J., 2021, P EUR C INF SYST, P1
   Eirich J., 2022, P EUR C INF SYST, P1
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Eirich J, 2020, 2020 IEEE VISUALIZATION IN DATA SCIENCE (VDS 2020), P22, DOI 10.1109/VDS51726.2020.00007
   Eppler M., 2009, MANAGING INFORM QUAL, V2nd
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Flyvbjerg B, 2006, QUAL INQ, V12, P219, DOI 10.1177/1077800405284363
   Guo H, 2016, IEEE T VIS COMPUT GR, V22, P51, DOI 10.1109/TVCG.2015.2467613
   Ivson P, 2020, IEEE T VIS COMPUT GR, V26, P3109, DOI 10.1109/TVCG.2019.2907583
   Ivson P, 2018, IEEE T VIS COMPUT GR, V24, P687, DOI 10.1109/TVCG.2017.2745105
   Kampker A, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY AND MANAGEMENT (ICITM 2019), P137, DOI 10.1109/ICITM.2019.8710702
   Kampker A, 2014, INT ELECTR DRIVE PRO, P419
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Li D, 2017, PROCEDIA ENGINEER, V174, P885, DOI 10.1016/j.proeng.2017.01.237
   Lloyd D, 2011, IEEE T VIS COMPUT GR, V17, P2498, DOI 10.1109/TVCG.2011.209
   Lorensen B., 2004, NIH NSF P FALL 2004, V1, P5
   Machado GM, 2009, IEEE T VIS COMPUT GR, V15, P1291, DOI 10.1109/TVCG.2009.113
   Maier R., 2007, KNOWLEDGE MANAGEMENT
   Manesh MF, 2021, IEEE T ENG MANAGE, V68, P289, DOI 10.1109/TEM.2019.2963489
   Mazumdar S, 2012, LECT NOTES COMPUT SC, V7117, P112, DOI 10.1007/978-3-642-25953-1_10
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nonaka I., 1995, The Knowledge-Creating Company: How Japanese Companies Create the Dynamics of Innovation
   Qin J, 2017, PROC CIRP, V63, P307, DOI 10.1016/j.procir.2017.02.036
   Rahman MK, 2020, IEEE DATA MINING, P442, DOI 10.1109/ICDM50108.2020.00053
   Reitz F, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P679, DOI 10.1109/IV.2009.24
   Sahann R, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P66, DOI 10.1109/VIS49827.2021.9623301
   Schwab M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300786
   Sedlmair M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1727
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2729, DOI 10.1109/TVCG.2012.255
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sedlmair M, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P173, DOI 10.1109/IV.2009.95
   Shaikh FK, 2017, IEEE SYST J, V11, P983, DOI 10.1109/JSYST.2015.2415194
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Suschnigg J., 2020, P INT WORKSH BIG DAT, P579
   Tan YS, 2017, PROC CIRP, V61, P376, DOI 10.1016/j.procir.2016.11.242
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wang XY, 2009, COMPUT GRAPH-UK, V33, P616, DOI 10.1016/j.cag.2009.06.004
   Wanner J., 2020, ENTERPRISE MODELLING, V15, P616
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yang H, 2019, IISE TRANS, V51, P1190, DOI 10.1080/24725854.2018.1555383
   Yin R. K., 2014, Case study research: Designs and methods
   Zhang XY, 2021, IEEE PAC VIS SYMP, P196, DOI 10.1109/PacificVis52677.2021.00033
   Zhou FF, 2019, J VISUAL-JAPAN, V22, P419, DOI 10.1007/s12650-018-0530-2
   Zhou J, 2013, ADV MANUF, V1, P1, DOI 10.1007/s40436-013-0006-5
   Zong W, 2017, IEEE T ENG MANAGE, V64, P287, DOI 10.1109/TEM.2017.2648516
NR 59
TC 0
Z9 0
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3441
EP 3457
DI 10.1109/TVCG.2023.3279857
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200001
PM 37335784
OA Green Published
DA 2024-11-06
ER

PT J
AU Lin, ZH
   Gu, X
   Li, S
   Hu, ZM
   Wang, GP
AF Lin, Zehui
   Gu, Xiang
   Li, Sheng
   Hu, Zhiming
   Wang, Guoping
TI Intentional Head-Motion Assisted Locomotion for Reducing Cybersickness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cybersickness; head motion; locomotion; presence; rotation; translation;
   velocity
ID WALKING-IN-PLACE; VIRTUAL-REALITY; SICKNESS; NAVIGATION
AB We present an efficient locomotion technique that can reduce cybersickness through aligning the visual and vestibular induced self-motion illusion. Our locomotion technique stimulates proprioception consistent with the visual sense by intentional head motion, which includes both the head's translational movement and yaw rotation. A locomotion event is triggered by the hand-held controller together with an intended physical head motion simultaneously. Based on our method, we further explore the connections between the level of cybersickness and the velocity of self motion through a series of experiments. We first conduct Experiment 1 to investigate the cybersickness induced by different translation velocities using our method and then conduct Experiment 2 to investigate the cybersickness induced by different angular velocities. Our user studies from these two experiments reveal a new finding on the correlation between translation/angular velocities and the level of cybersickness. The cybersickness is greatest at the lowest velocity using our method, and the statistical analysis also indicates a possible U-shaped relation between the translation/angular velocity and cybersickness degree. Finally, we conduct Experiment 3 to evaluate the performances of our method and other commonly-used locomotion approaches, i.e., joystick-based steering and teleportation. The results show that our method can significantly reduce cybersickness compared with the joystick-based steering and obtain a higher presence compared with the teleportation. These advantages demonstrate that our method can be an optional locomotion solution for immersive VR applications using commercially available HMD suites only.
C1 [Lin, Zehui; Gu, Xiang; Li, Sheng; Hu, Zhiming; Wang, Guoping] Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.
C3 Peking University
RP Li, S (corresponding author), Peking Univ, Sch Comp Sci, Beijing 100871, Peoples R China.
EM zehui@pku.edu.cn; gu_xiang@pku.edu.cn; lisheng@pku.edu.cn;
   jimmyhu@pku.edu.cn; wgp@pku.edu.cn
RI wang, guoping/KQU-3394-2024
OI Li, Sheng/0000-0002-8901-2184; Gu, Xiang/0000-0002-8527-9113; Hu,
   Zhiming/0000-0002-5105-9753
FU National Key Ramp;D Program of China [2021YFF0500901]; National Natural
   Science Foundation of China [62172013, 61631001]
FX This work was supported in part by the National Key R & amp;D Program of
   China under Grant 2021YFF0500901 and in part by the National Natural
   Science Foundation of China under Grants 62172013 and 61631001.
CR Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Buhler H, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P517, DOI 10.1109/VR.2018.8446346
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Chardonnet JR, 2021, VIRTUAL REAL-LONDON, V25, P565, DOI 10.1007/s10055-020-00474-2
   Cheng-Li Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P334, DOI 10.1109/FSKD.2012.6234149
   Christensen R. R., 1998, Proceedings of the ASME Dynamic Systems and Control Division-1998, P119
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   Douglas SarahA., 1999, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI'99), P215, DOI [10.1145/302979.303042, DOI 10.1145/302979.303042]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   Harris L. R., 2002, Virtual Reality, V6, P75, DOI 10.1007/s100550200008
   Hashemian AM, 2022, IEEE T VIS COMPUT GR, V28, P1792, DOI 10.1109/TVCG.2020.3025084
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Hlavacka F, 1996, NEUROSCI LETT, V210, P83, DOI 10.1016/0304-3940(96)12667-7
   Hsiao E. W., 2018, UND RES SYMP
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Langbehn Eike, 2018, Redirected Walking in Virtual Reality, P1
   LaValle S., 2022, VIRTUAL REAL-LONDON
   Li S., 2020, IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2020.3044563, DOI 10.1109/TVCG.2020.3044563]
   Liu CL, 2007, LECT NOTES COMPUT SC, V4555, P666
   Liu SH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P817, DOI [10.1109/VR.2019.8798158, 10.1109/vr.2019.8798158]
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Oman CM, 1998, J VESTIBUL RES-EQUIL, V8, P51, DOI 10.1016/S0957-4271(97)00040-2
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   Plouzeau J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P661, DOI 10.1109/VR.2018.8446192
   Porcino TM, 2017, IEEE INT CONF SERIOU
   Punpongsanon P, 2017, IEEE T VIS COMPUT GR, V23, P1952, DOI 10.1109/TVCG.2016.2586071
   Razzaque S., 2002, Virtual Environments 2002. Eurographics Workshop Proceedings, P123
   Razzaque S., 2001, P EUR, P289
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Regenbrecht H, 2002, PRESENCE-TELEOP VIRT, V11, P425, DOI 10.1162/105474602760204318
   Reinhard R, 2017, TRANSPORT RES F-TRAF, V48, P74, DOI 10.1016/j.trf.2017.05.005
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Riecke B.E., 2012, vection") in virtual reality?, P17
   Riecke B. E., 2015, P 3 S SPAT US INT LO, P123, DOI DOI 10.1145/2788940.2788956
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2009, IEEE COMPUT GRAPH, V29, P76, DOI 10.1109/MCG.2009.55
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Stoffregen TA, 2014, EXP BRAIN RES, V232, P1389, DOI 10.1007/s00221-014-3859-3
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Viirre E, 1996, IEEE ENG MED BIOL, V15, P41, DOI 10.1109/51.486717
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Ware C., 1990, Computer Graphics, V24, P175, DOI 10.1145/91394.91442
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Williams B., 2006, P ACM SIGGRAPH 2006, P182
   Williams B., 2006, Proceedings of the 3rd Symposium on applied Perception in Graphics and visualization (ACM), P21, DOI [10.1145/1140491.1140495, DOI 10.1145/1140491.1140495]
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
NR 73
TC 0
Z9 0
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3458
EP 3471
DI 10.1109/TVCG.2022.3160232
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200002
PM 35298380
DA 2024-11-06
ER

PT J
AU Chu, YY
   Wang, WC
   Li, L
AF Chu, Yiyao
   Wang, Wencheng
   Li, Lei
TI Robustly Extracting Concise 3D Curve Skeletons by Enhancing the Capture
   of Prominent Features
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Curve skeleton; medial surface; set cover; edge contraction
ID MEDIAL AXIS; ALGORITHM; FRAMEWORK; SURFACE; SIMPLIFICATION
AB Extracting concise 3D curve skeletons with existing methods is still a serious challenge as these methods require tedious parameter adjustment to suppress the influence of shape boundary perturbations to avoid spurious branches. In this paper, we address this challenge by enhancing the capture of prominent features and using them for skeleton extraction, motivated by the observation that the shape is mainly represented by prominent features. Our method takes the medial mesh of the shape as input, which can maintain the shape topology well. We develop a series of novel measures for simplifying and contracting the medial mesh to capture prominent features and represent them concisely, by which means the influences of shape boundary perturbations on skeleton extraction are suppressed and the quantity of data needed for skeleton extraction is significantly reduced. As a result, we can robustly and concisely extract the curve skeleton based on prominent features, avoiding the trouble of tuning parameters and saving computations, as shown by experimental results.
C1 [Chu, Yiyao; Wang, Wencheng] Chinese Univ Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
   [Chu, Yiyao; Wang, Wencheng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Li, Lei] SenseTime Res, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Wang, WC (corresponding author), Chinese Univ Sci, Inst Software, State Key Lab Comp Sci, Beijing 100190, Peoples R China.
EM chuyy@ios.ac.cn; whn@ios.ac.cn; lilei1@sensetime.com
RI Wang, Wencheng/A-3828-2009
OI wang, wen cheng/0000-0001-5094-4606
FU National Natural Science Foundation of China [62072446]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62072446.
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392462
   Amenta N, 2001, COMP GEOM-THEOR APPL, V20, P25, DOI 10.1016/S0925-7721(01)00033-5
   Amenta N., 2001, P 6 ACM S SOL MOD AP, P249
   [Anonymous], 2007, P IEEE INT C COMP VI
   Arcelli C, 2011, IEEE T PATTERN ANAL, V33, P709, DOI 10.1109/TPAMI.2010.140
   Attali D, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P13, DOI 10.1109/ICIP.1996.560357
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Aujay G, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P151
   Blum H., 1967, Models for Perception of Speech and Visual Form
   Bouix S, 2005, MED IMAGE ANAL, V9, P209, DOI 10.1016/j.media.2004.06.026
   Chazal F, 2005, GRAPH MODELS, V67, P304, DOI 10.1016/j.gmod.2005.01.002
   Chu YY, 2019, COMPUT GRAPH FORUM, V38, P607, DOI 10.1111/cgf.13864
   Chuang JH, 2000, IEEE T PATTERN ANAL, V22, P1241
   Contente O, 2015, IEEE INT CONF AUTON, P50, DOI 10.1109/ICARSC.2015.16
   Cornea ND, 2007, IEEE T VIS COMPUT GR, V13, P530, DOI 10.1109/TVCG.2007.1002
   Couprie M, 2016, PATTERN RECOGN LETT, V76, P22, DOI 10.1016/j.patrec.2015.03.014
   Culver T, 2004, COMPUT AIDED GEOM D, V21, P65, DOI 10.1016/j.cagd.2003.07.008
   Dey T.K., 2006, S GEOMETRY PROCESSIN, V6, P143
   Dey Tamal K., 1998, Publ. l'Inst. Math., V66, P23
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gieser J., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P327, DOI 10.1145/1137856.1137905
   Hassouna MS, 2005, LECT NOTES COMPUT SC, V3749, P654
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461913
   Jalba AC, 2016, IEEE T PATTERN ANAL, V38, P30, DOI 10.1109/TPAMI.2015.2414420
   Jalba AC, 2013, IEEE T PATTERN ANAL, V35, P1495, DOI 10.1109/TPAMI.2012.212
   Jiang HY, 2019, IEEE I CONF COMP VIS, P5430, DOI 10.1109/ICCV.2019.00553
   Junjie Cao, 2010, Proceedings of the Shape Modeling International (SMI 2010), P187, DOI 10.1109/SMI.2010.25
   Li CY, 2011, LECT NOTES COMPUT SC, V6636, P84, DOI 10.1007/978-3-642-21073-0_10
   Li L, 2022, IEEE T VIS COMPUT GR, V28, P1486, DOI 10.1109/TVCG.2020.3018483
   Li L, 2018, COMPUT GRAPH FORUM, V37, P313, DOI 10.1111/cgf.13570
   Li L, 2017, COMPUT GRAPH FORUM, V36, P529, DOI 10.1111/cgf.13098
   Li P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2753755
   Livesu M, 2013, VISUAL COMPUT, V29, P907, DOI 10.1007/s00371-013-0855-8
   Livesu M, 2012, IEEE T VIS COMPUT GR, V18, P1891, DOI 10.1109/TVCG.2012.71
   Lohou C, 2007, PATTERN RECOGN, V40, P2301, DOI 10.1016/j.patcog.2006.12.032
   Ma J, 2012, VISUAL COMPUT, V28, P7, DOI 10.1007/s00371-011-0594-7
   Miklos B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778838
   Nelsen B., 2010, CHARMING PROOFS
   Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2
   Pan YL, 2019, COMPUT AIDED GEOM D, V71, P16, DOI 10.1016/j.cagd.2019.04.007
   Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680
   Qin HX, 2020, IEEE T VIS COMPUT GR, V26, P2805, DOI 10.1109/TVCG.2019.2903805
   Rebain D, 2019, COMPUT GRAPH FORUM, V38, P5, DOI 10.1111/cgf.13599
   Reniers D, 2008, IEEE T VIS COMPUT GR, V14, P355, DOI 10.1109/TC.2007.70786
   Shen W, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4715-3
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   Sun F, 2016, IEEE T VIS COMPUT GR, V22, P1278, DOI 10.1109/TVCG.2015.2448080
   Tagliasacchi A, 2016, COMPUT GRAPH FORUM, V35, P573, DOI 10.1111/cgf.12865
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   Tagliasacchi A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531377
   Tang JP, 2019, PROC CVPR IEEE, P4536, DOI 10.1109/CVPR.2019.00467
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Tao Wang, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P55, DOI 10.1109/ICCVW.2009.5457719
   Telea A., 2012, P THEOR PRACT COMP G, P99
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Xu Z, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392379
   Xu Z, 2019, INT CONF 3D VISION, P298, DOI 10.1109/3DV.2019.00041
   Yan YJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201396
   Yan YJ, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925938
   Zhu H., 2004, J SOFTW, V15, P206
NR 61
TC 0
Z9 0
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3472
EP 3488
DI 10.1109/TVCG.2022.3161962
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200003
PM 35324442
DA 2024-11-06
ER

PT J
AU Yan, L
   Masood, TB
   Rasheed, F
   Hotz, I
   Wang, B
AF Yan, Lin
   Masood, Talha Bin
   Rasheed, Farhan
   Hotz, Ingrid
   Wang, Bei
TI Geometry-Aware Merge Tree Comparisons for Time-Varying Data With
   Interleaving Distances
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Merge trees; merge tree metrics; topological data analysis; topology in
   visualization
ID CONTOUR TREES; RED-SEA; VISUALIZATION; PERSISTENCE; STABILITY; EDDIES
AB Merge trees, a type of topological descriptors, serve to identify and summarize the topological characteristics associated with scalar fields. They have great potential for analyzing and visualizing time-varying data. First, they give compressed and topology-preserving representations of data instances. Second, their comparisons provide a basis for studying the relations among data instances, such as their distributions, clusters, outliers, and periodicities. A number of comparative measures have been developed for merge trees. However, these measures are often computationally expensive since they implicitly consider all possible correspondences between critical points of the merge trees. In this paper, we perform geometry-aware comparisons of merge trees using labeled interleaving distances. The main idea is to decouple the computation of a comparative measure into two steps: a labeling step that generates a correspondence between the critical points of two merge trees, and a comparison step that computes distances between a pair of labeled merge trees by encoding them as matrices. We show that our approach is general, computationally efficient, and practically useful. Our framework makes it possible to integrate geometric information of the data domain in the labeling process. At the same time, the framework reduces the computational complexity since not all possible correspondences have to be considered. We demonstrate via experiments that such geometry-aware merge tree comparisons help to detect transitions, clusters, and periodicities of time-varying datasets, as well as to diagnose and highlight the topological changes between adjacent data instances.
C1 [Yan, Lin; Wang, Bei] Univ Utah, Sci Imaging SCI Inst, Salt Lake City, UT 84112 USA.
   [Masood, Talha Bin; Rasheed, Farhan; Hotz, Ingrid] Linkoping Univ, Dept Sci & Technol, S-60174 Linkoping, Sweden.
C3 Utah System of Higher Education; University of Utah; Linkoping
   University
RP Yan, L (corresponding author), Univ Utah, Sci Imaging SCI Inst, Salt Lake City, UT 84112 USA.
EM lynne.h.yan@gmail.com; talha.bin.masood@liu.se; farhan.rasheed@liu.se;
   ingrid.hotz@liu.se; beiwang@sci.utah.edu
RI Yan, Lin/HJY-9781-2023
OI Yan, Lin/0000-0001-7017-0329; Rasheed, Farhan/0000-0003-0632-1545; Hotz,
   Ingrid/0000-0001-7285-0483
FU DOE [DE-SC0021015]; NSF [IIS 1910733]; Swedish e-Science Research Center
   (SeRC); Excellence Center at Linkoping - Lund in Information Technology
   (ELLIIT); Swedish Research Council [2019-05487]; Wallenberg AI,
   Autonomous Systems and Software Program (WASP); Swedish Research Council
   [2019-05487] Funding Source: Swedish Research Council
FX This work was supported in part by DOE under Grant DE-SC0021015, in
   partby NSF under Grant IIS 1910733. The work of Ingrid Hotz was
   supported inpart by the Swedish e-Science Research Center (SeRC), in
   part by the Excellence Center at Linkoping - Lund in Information
   Technology (ELLIIT), in part by the Swedish Research Council (VR) under
   Grant 2019-05487, and in part by the Wallenberg AI, Autonomous Systems
   and Software Program (WASP).
CR Athawale TM, 2022, IEEE T VIS COMPUT GR, V28, P1955, DOI 10.1109/TVCG.2020.3022359
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Bauer U, 2021, FOUND COMPUT MATH, V21, P1441, DOI 10.1007/s10208-020-09488-3
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Beketayev K., 2012, Proceedings of the Workshop at SIGGRAPH Asia, P155
   Bin Masood T, 2013, VISUAL COMPUT, V29, P761, DOI 10.1007/s00371-013-0828-y
   Bremer PT, 2015, COMPUT VIS SCI, V17, P1, DOI 10.1007/s00791-015-0241-3
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Brown A., 2021, J APPL COMPUT TOPOL, V5, P99, DOI DOI 10.1007/S41468-020-00063-X
   Bubenik P, 2015, FOUND COMPUT MATH, V15, P1501, DOI 10.1007/s10208-014-9229-5
   Cardona G, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-3
   Carlsson G., 2004, P 2004 EUR ACM SIGGR, P124, DOI DOI 10.1145/1057432.1057449
   Carlsson G, 2010, J MACH LEARN RES, V11, P1425
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carriere M., 2017, P 33 INT S COMP GEOM, V77, P1
   Catanzaro M.J., 2020, J. Appl. Comput. Topol., V4, P353
   Chazal F., 2016, Structure and stability of persistence modules, DOI [10.1007/978-3-319-42545-0, DOI 10.1007/978-3-319-42545-0]
   Chazal F, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P237, DOI 10.1145/1542362.1542407
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Curry J.M., 2014, THESIS U PENNSYLVANI
   Curry Justin, 2018, Journal of Applied and Computational Topology, V2, P301, DOI DOI 10.1007/S41468-019-00024-Z
   De Doncker P, 2003, J ELECTROMAGNET WAVE, V17, P877, DOI 10.1163/156939303322503466
   De Silva V, 2018, THEOR APPL CATEG, V33, P583
   de Silva V., 2016, P DISCR COMP GEOM, P1
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2019, P 35 INT S COMP GEOM
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   EDELSBRUNNER H., 2010, Computational Topology: An Introduction (Applied Mathematics)
   Fofonov A, 2019, COMPUT GRAPH FORUM, V38, P286, DOI 10.1111/cgf.13531
   Gasparovic E., PREPRINT
   Gerber S, 2010, IEEE T VIS COMPUT GR, V16, P1271, DOI 10.1109/TVCG.2010.213
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Herick M, 2020, IVAPP: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 3: IVAPP, P54, DOI 10.5220/0008956300540061
   Hoteit I., 2018, NEW FRONTIERS OPERAT
   Kanari L, 2020, ALGORITHMS, V13, DOI 10.3390/a13120335
   Kerber Michael, 2017, Journal of Experimental Algorithmics (JEA), V22, P1, DOI 10.1145/3064175
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Merelli E, 2015, ENTROPY-SWITZ, V17, P6872, DOI 10.3390/e17106872
   Morozov D., 2013, P TOP BAS METH VIS
   Munch E., 2019, Research in Data Science, P109
   Munch E., 2016, P 32 INT S COMP GEOM
   Nagaraj S, 2011, COMPUT GRAPH FORUM, V30, P1101, DOI 10.1111/j.1467-8659.2011.01959.x
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Popinet S., 2004, ClusterWorld, V2, P7
   Reininghaus J, 2012, IEEE T VIS COMPUT GR, V18, P1563, DOI 10.1109/TVCG.2011.269
   Reininghaus J, 2011, IEEE T VIS COMPUT GR, V17, P2045, DOI 10.1109/TVCG.2011.159
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Smith Z, 2016, CONF REC ASILOMAR C, P1834, DOI 10.1109/ACSSC.2016.7869701
   Soler M, 2018, SYMP LARG DATA ANAL, P23, DOI 10.1109/LDAV.2018.8739196
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Touli EF, 2019, LEIBNIZ INT PR INFOR, V144, DOI 10.4230/LIPIcs.ESA.2019.83
   Valsangkar AA, 2019, IEEE T VIS COMPUT GR, V25, P1460, DOI 10.1109/TVCG.2018.2810068
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Zhan P, 2019, GEOPHYS RES LETT, V46, P2167, DOI 10.1029/2018GL081387
   Zhan P, 2014, J GEOPHYS RES-OCEANS, V119, P3909, DOI 10.1002/2013JC009563
   Zhang KZ, 1996, ALGORITHMICA, V15, P205, DOI 10.1007/BF01975866
NR 62
TC 2
Z9 2
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3489
EP 3506
DI 10.1109/TVCG.2022.3163349
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200004
PM 35349444
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Saint-Aubert, J
   Cogne, M
   Bonan, I
   Launey, Y
   Lecuyer, A
AF Saint-Aubert, Justine
   Cogne, Melanie
   Bonan, Isabelle
   Launey, Yoann
   Lecuyer, Anatole
TI Influence of User Posture and Virtual Exercise on Impression of
   Locomotion During VR Observation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Action observation; embodiment; locomotion; posture; virtual exercise
ID RUBBER HAND ILLUSION; MOTION SICKNESS; SELF; VECTION; SENSE; HEAD;
   EMBODIMENT; OWNERSHIP; WALKING; VISION
AB A seated user watching his avatar walking in Virtual Reality (VR) may have an impression of walking. In this paper, we show that such an impression can be extended to other postures and other locomotion exercises. We present two user studies in which participants wore a VR headset and observed a first-person avatar performing virtual exercises. In the first experiment, the avatar walked and the participants (n=36) tested the simulation in 3 different postures (standing, sitting and Fowler's posture). In the second experiment, other participants (n=18) were sitting and observed the avatar walking, jogging or stepping over virtual obstacles. We evaluated the impression of locomotion by measuring the impression of walking (respectively jogging or stepping) and embodiment in both experiments. The results show that participants had the impression of locomotion in either sitting, standing and Fowler's posture. However, Fowler's posture significantly decreased both the level of embodiment and the impression of locomotion. The sitting posture seems to decrease the sense of agency compared to standing posture. Results also show that the majority of the participants experienced an impression of locomotion during the virtual walking, jogging, and stepping exercises. The embodiment was not influenced by the type of virtual exercise. Overall, our results suggest that an impression of locomotion can be elicited in different users' postures and during different virtual locomotion exercises. They provide valuable insight for numerous VR applications in which the user observes a self-avatar moving, such as video games, gait rehabilitation, training, etc.
C1 [Saint-Aubert, Justine; Lecuyer, Anatole] Campus Univ Beaulieu, Inria Rennes, F-35042 Rennes, France.
   [Cogne, Melanie; Bonan, Isabelle; Launey, Yoann] Rennes Univ Hosp, F-35000 Rennes, France.
C3 Universite de Rennes; CHU Rennes; Universite de Rennes
RP Saint-Aubert, J (corresponding author), Campus Univ Beaulieu, Inria Rennes, F-35042 Rennes, France.
EM justine.saint-aubert@inria.fr; Melanie.COGNE@chu-rennes.fr;
   isabelle.bonan@chu-rennes.fr; yoann.launey@chu-rennes.fr;
   anatole.lecuyer@inria.fr
RI Launey, Yoann/AAN-7176-2020; Cogne, Melanie/JVN-4300-2024
OI Saint-Aubert, Justine/0000-0001-8412-653X; Launey,
   Yoann/0000-0001-9105-8862
FU Research and Innovation Department of the University Hospital of Rennes
FX We wish to thank the Research and Innovation Department of the
   University Hospital of Rennes for promoting and supporting our study. We
   also wish to thank Anna Moraitis forproofreading this document
CR Alsmith AJT, 2014, CONSCIOUS COGN, V24, P70, DOI 10.1016/j.concog.2013.12.005
   Austen EL, 2004, COGN AFFECT BEHAV NE, V4, P170, DOI 10.3758/CABN.4.2.170
   Barra J, 2013, NEUROPHYSIOL CLIN, V43, P197, DOI 10.1016/j.neucli.2013.02.001
   Bergström I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148060
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bossard M, 2018, J VISION, V18, DOI 10.1167/18.2.3
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   BRANDT T, 1973, EXP BRAIN RES, V16, P476, DOI 10.1007/BF00234474
   Burin D, 2020, NEUROIMAGE, V222, DOI 10.1016/j.neuroimage.2020.117297
   Calvo-Merino B, 2005, CEREB CORTEX, V15, P1243, DOI 10.1093/cercor/bhi007
   Carriot J, 2008, NEUROPHYSIOL CLIN, V38, P423, DOI 10.1016/j.neucli.2008.09.003
   Chambon V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00320
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Costantini M, 2007, CONSCIOUS COGN, V16, P229, DOI 10.1016/j.concog.2007.01.001
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Dijkstra K, 2007, COGNITION, V102, P139, DOI 10.1016/j.cognition.2005.12.009
   Ehrsson HH, 2004, SCIENCE, V305, P875, DOI 10.1126/science.1097011
   Flanagan JR, 2003, NATURE, V424, P769, DOI 10.1038/nature01861
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Guterman PS, 2012, J VESTIBUL RES-EQUIL, V22, P105, DOI 10.3233/VES-2012-0448
   Holden MK, 2005, CYBERPSYCHOL BEHAV, V8, P187, DOI 10.1089/cpb.2005.8.187
   Howard IP, 2001, PERCEPTION, V30, P583, DOI 10.1068/p3106
   Kannape OA, 2012, INT J PSYCHOPHYSIOL, V83, P191, DOI 10.1016/j.ijpsycho.2011.12.006
   KANO C, 1991, Ecological Psychology, V3, P241, DOI 10.1207/s15326969eco0303_3
   Kemeny A., 2017, IS T INT S EL IM SCI, P48, DOI [DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-097, 10.2352/issn.2470-1173.2017.3.ervr-097]
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Lenggenhager B., 2015, vestibular contributions of sence of body self and others, P1, DOI DOI 10.5167/UZH-139675
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lenggenhager B, 2009, CONSCIOUS COGN, V18, P110, DOI 10.1016/j.concog.2008.11.003
   Marengo J., 2019, P IEEE C GAM, P1
   Maselli A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00693
   Matsuda Y., 2020, IEEE C VIRTUAL REALI
   McManus M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0243381
   Merhi O, 2007, HUM FACTORS, V49, P920, DOI 10.1518/001872007X230262
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   Nordahl R., 2012, 2012 IEEE VR Workshop on Perceptual Illusions in Virtual Environments, P21, DOI 10.1109/PIVE.2012.6229796
   Oman C. M., 2003, The Neurolab Spacelab Mission, P69
   Palmisano S, 2000, PERCEPTION, V29, P57, DOI 10.1068/p2990
   Palmisano S, 2008, PERCEPTION, V37, P22, DOI 10.1068/p5806
   Palmisano S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0195886
   Park HR, 2014, CLIN REHABIL, V28, P794, DOI 10.1177/0269215514523145
   Patla AE, 1997, GAIT POSTURE, V5, P54, DOI 10.1016/S0966-6362(96)01109-5
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peng TH, 2019, CLIN REHABIL, V33, P1277, DOI 10.1177/0269215519839108
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Preston C, 2015, SCI REP-UK, V5, DOI 10.1038/srep18345
   Preuss N, 2019, J EXP PSYCHOL HUMAN, V45, P209, DOI 10.1037/xhp0000597
   Previc F H, 1992, J Vestib Res, V2, P285
   Price TF, 2011, PSYCHOPHYSIOLOGY, V48, P718, DOI 10.1111/j.1469-8986.2010.01127.x
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riecke B.E., 2009, JAPANESE J PSYCHONOM, V28, P135, DOI [DOI 10.14947/PSYCHONO.KJ00005878681, 10.14947/PSYCHONO.KJ00005878681]
   Tekgün E, 2021, CONSCIOUS COGN, V91, DOI 10.1016/j.concog.2021.103108
   TELFORD L, 1993, PERCEPT PSYCHOPHYS, V53, P682, DOI 10.3758/BF03211744
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Thür C, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00436
   Tian NN, 2020, IEEE CONF COMPU INTE, P359, DOI 10.1109/CoG47356.2020.9231830
   Tovee C. A., 1999, Adaptation to a Linear Vection Stimulus in a Virtual Reality Environment
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Wegner DM, 2004, J PERS SOC PSYCHOL, V86, P838, DOI 10.1037/0022-3514.86.6.838
   YOUNG LR, 1990, AVIAT SPACE ENVIR MD, V61, P525
NR 70
TC 12
Z9 12
U1 7
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3507
EP 3518
DI 10.1109/TVCG.2022.3161130
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200005
PM 35349443
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Aristidou, A
   Yiannakidis, A
   Aberman, K
   Cohen-Or, D
   Shamir, A
   Chrysanthou, Y
AF Aristidou, Andreas
   Yiannakidis, Anastasios
   Aberman, Kfir
   Cohen-Or, Daniel
   Shamir, Ariel
   Chrysanthou, Yiorgos
TI Rhythm is a Dancer: Music-Driven Motion Synthesis With Global Structure
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; global structure consistency; motion motifs; music-driven;
   motion signatures
ID BEAT TRACKING; STYLE; PHYSICS
AB Synthesizing human motion with a global structure, such as a choreography, is a challenging task. Existing methods tend to concentrate on local smooth pose transitions and neglect the global context or the theme of the motion. In this work, we present a music-driven motion synthesis framework that generates long-term sequences of human motions which are synchronized with the input beats, and jointly form a global structure that respects a specific dance genre. In addition, our framework enables generation of diverse motions that are controlled by the content of the music, and not only by the beat. Our music-driven dance synthesis framework is a hierarchical system that consists of three levels: pose, motif, and choreography. The pose level consists of an LSTM component that generates temporally coherent sequences of poses. The motif level guides sets of consecutive poses to form a movement that belongs to a specific distribution using a novel motion perceptual-loss. And the choreography level selects the order of the performed movements and drives the system to follow the global structure of a dance genre. Our results demonstrate the effectiveness of our music-driven framework to generate natural and consistent movements on various dance types, having control over the content of the synthesized motions, and respecting the overall structure of the dance.
C1 [Aristidou, Andreas; Yiannakidis, Anastasios; Chrysanthou, Yiorgos] Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
   [Aristidou, Andreas; Yiannakidis, Anastasios; Chrysanthou, Yiorgos] CYENS Ctr Excellence, CY-1016 Nicosia, Cyprus.
   [Aberman, Kfir; Cohen-Or, Daniel] Tel Aviv Univ, Dept Comp Sci, IL-6997801 Tel Aviv, Israel.
   [Shamir, Ariel] Reichman Univ, Interdisciplinary Ctr Herzliya, Dept Comp Sci, IL-4610101 Herzliyya, Israel.
C3 University of Cyprus; Tel Aviv University; Reichman University
RP Aristidou, A (corresponding author), Univ Cyprus, Dept Comp Sci, CY-1678 Nicosia, Cyprus.
EM a.aristidou@ieee.org; tasyiann@gmail.com; kfiraberman@gmail.com;
   cohenor@gmail.com; arik@idc.ac.il; yiorgos@cs.ucy.ac.cy
RI Aristidou, Andreas/AAI-8096-2020
OI Yiannakidis, Anastasios/0000-0002-3721-6548; Shamir,
   Ariel/0000-0001-7082-7845; Aristidou, Andreas/0000-0001-7754-0791
FU University of Cyprus; European Union [739578]; Government of the
   Republic of Cyprus through the Ministry of Research, Innovation and
   Digital Policy
FX This work was Supported in part by the University of Cyprus, in part by
   the European Union's Horizon 2020 Research and Innovation Programme
   under Grant 739578, and in part by the Government of the Republic of
   Cyprus through the Deputy Ministry of Research, Innovation and Digital
   Policy.
CR Ahn H, 2020, IEEE ROBOT AUTOM LET, V5, P3501, DOI 10.1109/LRA.2020.2977333
   Alemi O., 2017, PROC 23 ACM SIGKDD I, P6
   Alexanderson S, 2020, COMPUT GRAPH FORUM, V39, P487, DOI 10.1111/cgf.13946
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Aristidou A, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3344383
   Aristidou A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275038
   Aristidou A, 2018, VISUAL COMPUT, V34, P1725, DOI 10.1007/s00371-017-1452-z
   Beaudoin P., 2008, P ACM SIGGRAPH EUR S, P117
   Bellini Rachele, 2018, Computational Visual Media, V4, P197, DOI 10.1007/s41095-018-0115-y
   Bello JP, 2005, IEEE T SPEECH AUDI P, V13, P1035, DOI 10.1109/TSA.2005.851998
   Bütepage J, 2017, PROC CVPR IEEE, P1591, DOI 10.1109/CVPR.2017.173
   Chen K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459932
   Chiang IK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P241, DOI 10.1145/2733373.2806220
   Clegg A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766986
   Davis A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201371
   Ellis DPW, 2007, J NEW MUSIC RES, V36, P51, DOI 10.1080/09298210701653344
   Fan RK, 2012, IEEE T VIS COMPUT GR, V18, P501, DOI 10.1109/TVCG.2011.73
   Foster SL, 2011, CHOREOGRAPHING EMPATHY: KINESTHESIA IN PERFORMANCE, P1
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Fraleigh S.H., 1987, DANCE LIVED BODY DES
   Fukayama S., 2014, PROC 11 C ADV COMPUT
   Geijtenbeek T, 2012, COMPUT GRAPH FORUM, V31, P2492, DOI 10.1111/j.1467-8659.2012.03189.x
   Geijtenbeek T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508399
   Ghorbani S, 2020, COMPUT GRAPH FORUM, V39, P225, DOI 10.1111/cgf.14116
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Gui LY, 2018, LECT NOTES COMPUT SC, V11208, P823, DOI 10.1007/978-3-030-01225-0_48
   Ha S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366174
   Habibie I., 2017, BRIT MACH VIS C, DOI DOI 10.5244/C.31.119
   Hämäläinen P, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2767002
   Henter GE, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417836
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Huang R., 2021, PROC INT C LEARN REP, P14
   Iwamoto N., 2018, P INT C ADV COMP ENT, P653
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kao HK, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P147, DOI 10.1145/3394171.3413848
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim TH, 2003, ACM T GRAPHIC, V22, P392, DOI 10.1145/882262.882283
   Kingma D.P., 2014, P INT C LEARNING REP
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kucherenko T, 2019, PROCEEDINGS OF THE 19TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA' 19), P97, DOI 10.1145/3308532.3329472
   Langlois TR, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601178
   Lee Hsin-Ying, 2019, Adv. Neural Inform. Process. Syst., P3586
   Lee JH, 2002, ACM T GRAPHIC, V21, P491
   Lee Juheon., 2019, Proceedings of the 20th International Society for Music Information Retrieval Conference (Delft, The Netherlands), P894, DOI [10.5281/zenodo.3527958, DOI 10.5281/ZENODO.3527958]
   Lee K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275071
   Lee M, 2013, MULTIMED TOOLS APPL, V62, P895, DOI 10.1007/s11042-012-1288-5
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Levine S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185524
   Li RL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13381, DOI 10.1109/ICCV48922.2021.01315
   Li Y., 2020, PREPRINT
   Ling HY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392422
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   Liu LB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201315
   Liu LB, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2893476
   Liu LJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073682
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   McFee B., 2015, P PYTH SCI C, P18, DOI 10.25080/Majora-7b98-3ed-003
   McKinney MF, 2007, J NEW MUSIC RES, V36, P1, DOI 10.1080/09298210701653252
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Min JY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366172
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Ofli F, 2012, IEEE T MULTIMEDIA, V14, P747, DOI 10.1109/TMM.2011.2181492
   Pavllo D., 2018, P BRIT MACH VIS C, P14
   Peng XB, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201311
   Peng XB, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073602
   Ren XC, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P46, DOI 10.1145/3394171.3413932
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Sauer D, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596991
   Schulz A., 2011, P ACM SIGGRAPH POST
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Shlizerman E, 2018, PROC CVPR IEEE, P7574, DOI 10.1109/CVPR.2018.00790
   Shum HPH, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409067
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soga A., 2016, P ACM SIGGRAPH POST
   Starke S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392450
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Tang TR, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1598, DOI 10.1145/3240508.3240526
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Treuille A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239458
   Wang H, 2021, IEEE T VIS COMPUT GR, V27, P216, DOI 10.1109/TVCG.2019.2936810
   Wang ZY, 2021, IEEE T VIS COMPUT GR, V27, P14, DOI 10.1109/TVCG.2019.2938520
   Wikipedia, 2021, DANCE
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
   Ye ZJ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P744, DOI 10.1145/3394171.3414005
   Yin KK, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239556
   Zhang H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201366
   Zhou Y., 2018, P ICLR, P13
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201285
   Zhuang WL, 2020, Arxiv, DOI arXiv:2006.05743
   Zhuang WL, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485664
NR 92
TC 16
Z9 16
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3519
EP 3534
DI 10.1109/TVCG.2022.3163676
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200006
PM 35353702
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Dubey, RK
   Sohn, SS
   Thrash, T
   Hölscher, C
   Borrmann, A
   Kapadia, M
AF Dubey, Rohit K. K.
   Sohn, Samuel S. S.
   Thrash, Tyler
   Hoelscher, Christoph
   Borrmann, Andre
   Kapadia, Mubbasir
TI Cognitive Path Planning With Spatial Memory Distortion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cognitive path-planning; human wayfinding; fine-to-course; spatial
   memory; agglomerative hierarchical clustering
ID DISTANCE; DECAY; CATEGORIES; RETRIEVAL; MODEL; MAPS
AB Human path-planning operates differently from deterministic AI-based path-planning algorithms due to the decay and distortion in a human's spatial memory and the lack of complete scene knowledge. Here, we present a cognitive model of path-planning that simulates human-like learning of unfamiliar environments, supports systematic degradation in spatial memory, and distorts spatial recall during path-planning. We propose a Dynamic Hierarchical Cognitive Graph (DHCG) representation to encode the environment structure by incorporating two critical spatial memory biases during exploration: categorical adjustment and sequence order effect. We then extend the "Fine-To-Coarse" (FTC), the most prevalent path-planning heuristic, to incorporate spatial uncertainty during recall through the DHCG. We conducted a lab-based Virtual Reality (VR) experiment to validate the proposed cognitive path-planning model and made three observations: (1) a statistically significant impact of sequence order effect on participants' route-choices, (2) approximately three hierarchical levels in the DHCG according to participants' recall data, and (3) similar trajectories and significantly similar wayfinding performances between participants and simulated cognitive agents on identical path-planning tasks. Furthermore, we performed two detailed simulation experiments with different FTC variants on a Manhattan-style grid. Experimental results demonstrate that the proposed cognitive path-planning model successfully produces human-like paths and can capture human wayfinding's complex and dynamic nature, which traditional AI-based path-planning algorithms cannot capture.
C1 [Dubey, Rohit K. K.] Tech Univ Munich, Chair Computat Modeling & Simulat, D-80333 Munich, Germany.
   [Borrmann, Andre] Tech Univ Munich, Dept Civil & Environm Engn, Munich, Germany.
   [Dubey, Rohit K. K.] Leonhard Obermeyer Ctr TUM, D-80333 Munich, Germany.
   [Sohn, Samuel S. S.; Kapadia, Mubbasir] Rutgers State Univ, Comp Sci Dept, New Brunswick, NJ USA.
   [Thrash, Tyler] St Louis Univ, St Louis, MO 63103 USA.
   [Hoelscher, Christoph] Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
C3 Technical University of Munich; Technical University of Munich; Rutgers
   University System; Rutgers University New Brunswick; Saint Louis
   University; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Dubey, RK (corresponding author), Tech Univ Munich, Chair Computat Modeling & Simulat, D-80333 Munich, Germany.; Dubey, RK (corresponding author), Leonhard Obermeyer Ctr TUM, D-80333 Munich, Germany.
EM rohit.dubey@tum.de; samuel.sohn@rutgers.edu; tyler.thrash@gess.ethz.ch;
   choelsch@ethz.ch; andre.borrmann@tum.de; mubbasir.kapadia@rutgers.edu
OI Dubey, Rohit Kumar/0000-0003-0273-7850; Borrmann,
   Andre/0000-0003-2088-7254
FU Future Cities Laboratory at the Singapore-ETH Centre [FI 370074016]; NSF
   [IIS-1703883, IIS-1955404, IIS-1955365]; Leonhard Obermeyer Center at
   the Technical University of Munich
FX This work was supported in part by Future Cities Laboratory at the
   Singapore-ETH Centre: FI 370074016, in part by NSF under Grants
   IIS-1703883, IIS-1955404, and IIS-1955365, in part by Leonhard Obermeyer
   Center at the Technical University of Munich.& nbsp;
CR Altmann EM, 2012, PSYCHOL SCI, V23, P1435, DOI 10.1177/0956797612446027
   [Anonymous], 2002, Cartography and Geographic Information Science, DOI DOI 10.1559/152304002782008503
   Barrouillet P, 2012, PSYCHON B REV, V19, P87, DOI 10.3758/s13423-011-0192-8
   Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586
   Botea A., 2004, J. Game Dev, V1, P1
   Briggs R., 1973, IMAGE ENV, P361
   Chrastil ER, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112544
   Crawford LE, 2010, PSYCHON B REV, V17, P725, DOI 10.3758/PBR.17.5.725
   Dubey R. K., 2019, P MOT INT GAM, p15:1
   Epstein RA, 2017, NAT NEUROSCI, V20, P1504, DOI 10.1038/nn.4656
   Feldman NH, 2009, PSYCHOL REV, V116, P752, DOI 10.1037/a0017196
   Golledge R., 1999, Wayfinding behavior: Cognitive mapping and other spatial processes, DOI [10.56021/9780801859939, DOI 10.56021/9780801859939]
   Graham SM, 2000, MEM COGNITION, V28, P1191, DOI 10.3758/BF03211820
   Gupta S, 2017, PROC CVPR IEEE, P7272, DOI 10.1109/CVPR.2017.769
   Haun DBM, 2005, ACTA PSYCHOL, V118, P149, DOI 10.1016/j.actpsy.2004.10.011
   HIRTLE SC, 1985, MEM COGNITION, V13, P208, DOI 10.3758/BF03197683
   HUTTENLOCHER J, 1991, PSYCHOL REV, V98, P352, DOI 10.1037/0033-295X.98.3.352
   Jeantet I, 2020, LECT NOTES COMPUT SC, V12080, P261, DOI 10.1007/978-3-030-44584-3_21
   Jefferies M.E., 2008, Robotics and Cognitive Approaches to Spatial Mapping
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Kielar PM, 2018, TRANSPORTMETRICA A, V14, P406, DOI 10.1080/23249935.2017.1309472
   Kim JH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12101592
   Koenig S, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P476
   KOHONEN T, 1977, NEUROSCIENCE, V2, P1065, DOI 10.1016/0306-4522(77)90129-4
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5
   Kuipers B., 1978, COGNITIVE SCI, V2, P129, DOI [10.1016/S0364-0213(78)80003-2, DOI 10.1016/S0364-0213(78)80003-2]
   Kuo CT, 2018, Arxiv, DOI arXiv:1810.05357
   Lee JY, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5414, DOI 10.1109/IROS.2009.5354686
   Lee S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322972
   Lewandowsky S, 2009, TRENDS COGN SCI, V13, P120, DOI 10.1016/j.tics.2008.12.003
   Li HR, 2020, IEEE T NEUR NET LEAR, V31, P2064, DOI 10.1109/TNNLS.2019.2927869
   Madl T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157343
   MAYO CW, 1964, J ABNORM SOC PSYCH, V68, P335, DOI 10.1037/h0041716
   McNamara T., 1994, Thinking and Problem Solving, P81
   MCNAMARA TP, 1992, J EXP PSYCHOL LEARN, V18, P1173, DOI 10.1037/0278-7393.18.6.1173
   MCNAMARA TP, 1986, COGNITIVE PSYCHOL, V18, P87, DOI 10.1016/0010-0285(86)90016-2
   MUBBASIR KAPADIA., 2015, SYNTHESIS LECT VISUA, V7, P1, DOI [10.2200/s00673ed1v01y201509cgr020, DOI 10.2200/S00673ED1V01Y201509CGR020]
   MURDOCK BB, 1993, PSYCHOL REV, V100, P183, DOI 10.1037/0033-295X.100.2.183
   Nayak S., 2011, PROC AAAI FALL S SER, P249
   Peer M, 2021, TRENDS COGN SCI, V25, P37, DOI 10.1016/j.tics.2020.10.004
   Quandt T., 2013, Multiplayer: The social aspects of digital gaming
   REITMAN JS, 1980, COGNITIVE PSYCHOL, V12, P554, DOI 10.1016/0010-0285(80)90020-1
   SADALLA EK, 1979, MEM COGNITION, V7, P291, DOI 10.3758/BF03197602
   SCHMAJUK NA, 1992, BIOL CYBERN, V67, P165, DOI 10.1007/BF00201023
   Sohn SS, 2018, ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION, AND GAMES (MIG 2018), DOI 10.1145/3274247.3274518
   Solway A, 2012, MEM COGNITION, V40, P177, DOI 10.3758/s13421-011-0142-8
   STEVENS A, 1978, COGNITIVE PSYCHOL, V10, P422, DOI 10.1016/0010-0285(78)90006-3
   Tai Lei, 2016, arXiv
   THORNDYKE PW, 1981, COGNITIVE PSYCHOL, V13, P526, DOI 10.1016/0010-0285(81)90019-0
   Timpf Sabine., 1998, HIERARCHICAL STRUCTU
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   TVERSKY B, 1992, GEOFORUM, V23, P131, DOI 10.1016/0016-7185(92)90011-R
   van Elswijk L., 2013, THESIS RADBOUD U NIJ
   Voicu H, 2003, NEURAL NETWORKS, V16, P569, DOI 10.1016/S0893-6080(03)00095-9
   Wiener J. M., 2003, Spatial Cognition Computation, V3, P331, DOI [10.1207/s15427633scc03045, DOI 10.1207/S15427633SCC03045]
   Wong CK, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2243
   Zhang WW, 2009, PSYCHOL SCI, V20, P423, DOI 10.1111/j.1467-9280.2009.02322.x
   Zhong CL, 2016, IEEE T CYBERNETICS, V46, P3157, DOI 10.1109/TCYB.2015.2498760
NR 58
TC 0
Z9 0
U1 14
U2 59
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3535
EP 3549
DI 10.1109/TVCG.2022.3163794
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200007
PM 35358048
OA Green Published, hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Domova, V
   Vrotsou, K
AF Domova, Veronika
   Vrotsou, Katerina
TI A Model for Types and Levels of Automation in Visual Analytics: A
   Survey, a Taxonomy, and Examples
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; levels of automation; taxonomy; framework;
   event-sequence analytics
ID FUNCTION ALLOCATION; VISUALIZATION; TRUST; EXPLORATION; DESIGN;
   TRANSFORMATIONS; UNCERTAINTY; PERFORMANCE; DIRECTIONS; ALGORITHM
AB The continuous growth in availability and access to data presents a major challenge to the human analyst. As the manual analysis of large and complex datasets is nowadays practically impossible, the need for assisting tools that can automate the analysis process while keeping the human analyst in the loop is imperative. A large and growing body of literature recognizes the crucial role of automation in Visual Analytics and suggests that automation is among the most important constituents for effective Visual Analytics systems. Today, however, there is no appropriate taxonomy nor terminology for assessing the extent of automation in a Visual Analytics system. In this article, we aim to address this gap by introducing a model of levels of automation tailored for the Visual Analytics domain. The consistent terminology of the proposed taxonomy could provide a ground for users/readers/reviewers to describe and compare automation in Visual Analytics systems. Our taxonomy is grounded on a combination of several existing and well-established taxonomies of levels of automation in the human-machine interaction domain and relevant models within the visual analytics field. To exemplify the proposed taxonomy, we selected a set of existing systems from the event-sequence analytics domain and mapped the automation of their visual analytics process stages against the automation levels in our taxonomy.
C1 [Domova, Veronika] Stanford Univ, Human Comp Interact, Stanford, CA 94305 USA.
   [Vrotsou, Katerina] Linkoping Univ, Informat Visualizat, S-58183 Linkoping, Sweden.
C3 Stanford University; Linkoping University
RP Domova, V (corresponding author), Stanford Univ, Human Comp Interact, Stanford, CA 94305 USA.
EM vdomova@stanford.edu; katerina.vrotsou@liu.se
OI Domova, Veronika/0000-0002-1647-9402; Vrotsou,
   Katerina/0000-0003-4761-8601
FU Wallenberg AI, Autonomous Systems and Software Program
FX This work was supported by Wallenberg AI, Autonomous Systems and
   Software Program.
CR Ahlberg C., 1996, SIGMOD Record, V25, P25, DOI 10.1145/245882.245893
   Angelini M., 2018, INFORMATICS
   [Anonymous], 2019, Data Engineering
   [Anonymous], 2012, ACM CHI, DOI DOI 10.1145/2207676.2207741
   Arnott D, 2006, INFORM SYST J, V16, P55, DOI 10.1111/j.1365-2575.2006.00208.x
   BAINBRIDGE L, 1983, AUTOMATICA, V19, P775, DOI 10.1016/0005-1098(83)90046-8
   Barricelli BR, 2019, J SYST SOFTWARE, V149, P101, DOI 10.1016/j.jss.2018.11.041
   Baxter G., 2012, Ecce, P65, DOI [https://doi.org/10.1145/2448136.2448149, DOI 10.1145/2448136.2448149]
   Behringer Michael, 2018, Enterprise Information Systems. 19th International Conference, ICEIS 2017. Revised Selected Papers. Lecture Notes in Business Information Processing (LNBIP 321), P498, DOI 10.1007/978-3-319-93375-7_23
   Belhajjame K., 2010, Proceedings of the 13th International Conference on Extending Database Technology, P573, DOI DOI 10.1145/1739041.1739110
   BERNARD J, 2017, ELECT IMAGING, V2017, P34, DOI DOI 10.2352/ISSN.2470-1173.2017.1.VDA-387
   Bertini E., 2009, P ACM SIGKDD WORKSH, P12
   Bertini E., 2010, ACM SIGKDD EXPLORATI, V11, P9, DOI [DOI 10.1145/1809400.1809404, 10.1145/1809400.1809404]
   Billings C. E., 1991, HUMAN CTR AIRCRAFT A, VVol. 103885
   Bolón-Canedo V, 2013, KNOWL INF SYST, V34, P483, DOI 10.1007/s10115-012-0487-8
   Broadbent D., 1958, PERCEPTION COMMUNICA, DOI 10.1037/10037-000
   Broadbent D. E., 1971, DECIS STRESS, DOI DOI 10.2307/2018933
   Burstein MarkH., 1996, Advances in Psychology, V113, P285
   Card SK., 1999, READINGS INFORM VISU
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   CHAPANIS A, 1965, OCCUP PSYCHOL, V39, P1
   Council N.R., 1998, FUTURE AIR TRAFFIC C
   Crisan A., 2021, CHI, P1, DOI DOI 10.1145/3411764.3445775
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Cypher A., 1993, WATCH WHAT I DO PROG
   Dakuo Wang, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359313
   Dasgupta A, 2017, IEEE T VIS COMPUT GR, V23, P271, DOI 10.1109/TVCG.2016.2598544
   Dasu T., 2003, EXPLORATORY DATA MIN
   de Oliveira MCF, 2003, IEEE T VIS COMPUT GR, V9, P378, DOI 10.1109/TVCG.2003.1207445
   Domova V, 2019, IEEE INT CONF BIG DA, P1072, DOI 10.1109/BigData47090.2019.9006351
   Domova V, 2017, 2017 GLOBAL INTERNET OF THINGS SUMMIT (GIOTS 2017), P140
   Du F, 2017, IEEE T VIS COMPUT GR, V23, P1636, DOI 10.1109/TVCG.2016.2539960
   Edwards Elwyn., 1973, Man and computer in process control
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Endsley M. R., 1987, Proceedings of the Human Factors Society 31st Annual Meeting: Rising to New Heights with Technology, P1388
   Endsley MR, 2018, J COGN ENG DECIS MAK, V12, P29, DOI 10.1177/1555343417723432
   Endsley MR, 1999, ERGONOMICS, V42, P462, DOI 10.1080/001401399185595
   ENDSLEY MR, 1995, HUM FACTORS, V37, P381, DOI 10.1518/001872095779064555
   Fayyad U, 1996, COMMUN ACM, V39, P27, DOI 10.1145/240455.240464
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Feigh KM, 2014, J COGN ENG DECIS MAK, V8, P23, DOI 10.1177/1555343413490945
   Fisher D., 2012, P SIGCHI C HUM FACT, P1673, DOI DOI 10.1145/2207676.2208294
   FITTS P. M., 1951, Human Engineering for an Effective Air Navigation and Traffic Control System
   Fitts PM., 1967, Human performance
   Fong T., 2001, Collaborative control: A robot-centric model for vehicle teleoperation
   Gabel M., 2008, SIGSOFT FSE, P339, DOI [DOI 10.1145/1453101.1453150, 10.1145/1453101.1453150]
   Gelman A, 2004, J COMPUT GRAPH STAT, V13, P755, DOI 10.1198/106186004X11435
   Görg C, 2013, IEEE T VIS COMPUT GR, V19, P1646, DOI 10.1109/TVCG.2012.324
   Gotz D, 2009, INFORM VISUAL, V8, P42, DOI 10.1057/ivs.2008.31
   Gratzl S, 2014, IEEE T VIS COMPUT GR, V20, P2023, DOI 10.1109/TVCG.2014.2346260
   Guo H, 2016, IEEE T VIS COMPUT GR, V22, P51, DOI 10.1109/TVCG.2015.2467613
   Guo P. J., 2011, P 24 ANN ACM S US IN, P65, DOI 10.1145/2047196.2047205
   Han J, 2012, MOR KAUF D, P1
   Harris WR, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI 10.1145/1993316.1993536
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hellerstein JosephM., 2018, IEEE Data Eng. Bull, V41, P23
   Herrera F, 2011, KNOWL INF SYST, V29, P495, DOI 10.1007/s10115-010-0356-2
   Hoffman RR, 2013, IEEE INTELL SYST, V28, P84, DOI 10.1109/MIS.2013.24
   Horvitz E, 1999, P CHI, P159, DOI DOI 10.1145/302979.303030
   Hossain M.S., 2011, AAAI '11 Workshop on Scalable Integration of Analytics and Visualization (WS-11-17), P22
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Johnson M., 2010, INT WORKSHOP COORDIN, P172
   Johnson M, 2018, J COGN ENG DECIS MAK, V12, P77, DOI 10.1177/1555343417736462
   Kaber DB, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P205
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Karer B., 2018, ELECT IMAG, V2018, P377
   Keim D, 2001, COMMUN ACM, V44, P38, DOI 10.1145/381641.381656
   Keim D.A., 2010, Acm Sigkdd Explorations Newsletter, V11, P5, DOI [DOI 10.1145/1809400.1809403, 10.1145/1809400.1809403.]
   Keim D. A., 2010, MASTERING INFORM AGE
   Keim DA, 2002, IEEE T VIS COMPUT GR, V8, P1, DOI 10.1109/2945.981847
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kern H, 1974, INDUSTRIEARBEIT ARBE
   Kerracher N, 2017, COMPUT GRAPH FORUM, V36, P47, DOI 10.1111/cgf.13167
   Kerren A, 2012, WINT SIMUL C PROC
   Kim H, 2017, AAAI CONF ARTIF INTE, P1001
   Kim W, 2003, DATA MIN KNOWL DISC, V7, P81, DOI 10.1023/A:1021564703268
   Klein G, 2004, IEEE INTELL SYST, V19, P91, DOI 10.1109/MIS.2004.74
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Konstantinou N, 2020, INFORM SYST, V92, DOI 10.1016/j.is.2019.101480
   Liu H, 1998, IEEE INTELL SYST APP, V13, P26
   Liu SX, 2018, VIS INFORM, V2, P191, DOI 10.1016/j.visinf.2018.12.001
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   Lu JH, 2017, FRONT COMPUT SCI-CHI, V11, P192, DOI 10.1007/s11704-016-6028-y
   Makonin S, 2016, P ANN HICSS, P1427, DOI 10.1109/HICSS.2016.181
   Mathisen A, 2019, COMPUT GRAPH FORUM, V38, P649, DOI 10.1111/cgf.13717
   Mishra N., 2012, Int. J. Comput. Sci. Inf. Technol. (IJCSIT), V3, P4434
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Moray N, 2000, J EXP PSYCHOL-APPL, V6, P44, DOI 10.1037//0278-7393.6.1.44
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Mühlbacher T, 2014, IEEE T VIS COMPUT GR, V20, P1643, DOI 10.1109/TVCG.2014.2346578
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Natu M., 2008, P JOINT INT C DAT SC, P60
   Nauta M, 2019, MACH LEARN KNOW EXTR, V1, DOI 10.3390/make1010019
   Niu ZX, 2011, LECT NOTES ARTIF INT, V7002, P380, DOI 10.1007/978-3-642-23881-9_50
   NORMAN DA, 1990, PHILOS T R SOC B, V327, P585, DOI 10.1098/rstb.1990.0101
   O.-R. A. D. O. committee, 2016, TAX DEF TERMS REL DR, DOI [10.4271/J3016_201609, DOI 10.4271/J3016_201609]
   Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354
   Paton N, 2019, 21 INT WORKSHOP DESI, P1
   Perer Adam., 2014, P 19 INT C INTELLIGE, P153, DOI [10.1145/ 2557500.2557508, DOI 10.1145/2557500.2557508]
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Reinartz T, 2002, DATA MIN KNOWL DISC, V6, P191, DOI 10.1023/A:1014047731786
   Rezig E, 2019, PROC VLDB ENDOW, V12, P1954, DOI 10.14778/3352063.3352108
   Ropinski T., 2017, IEEE VIS PANEL PHOEN
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Scerbo M.W., 1996, HUM FAC TRANSP, P37
   Sheridan T., 1978, Human and Computer Control of Undersea Teleoperators (Technical Report)
   SHERIDAN TB, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS, VOLS 1-5, P823, DOI 10.1109/ICSMC.1995.537867
   Sheridan TB, 2000, INT J HUM-COMPUT ST, V52, P203, DOI 10.1006/ijhc.1999.0285
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B., 2020, AIS Trans. Hum. Comput. Interact., V12, P109, DOI [10.17705/1thci.00131, DOI 10.17705/1THCI.00131]
   Shneiderman B, 2020, INT J HUM-COMPUT INT, V36, P495, DOI 10.1080/10447318.2020.1741118
   Shneiderman Ben, 2015, IEEE Comput Graph Appl, V35, P10, DOI 10.1109/MCG.2015.64
   Simoff SJ, 2008, LECT NOTES COMPUT SC, V4404, P1
   Skitka LJ, 2000, INT J AVIAT PSYCHOL, V10, P85, DOI 10.1207/S15327108IJAP1001_5
   Spence R, 1998, INTERACT COMPUT, V11, P137, DOI 10.1016/S0953-5438(98)00022-8
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Thomson J, 2005, P SOC PHOTO-OPT INS, V5669, P146, DOI 10.1117/12.587254
   TUKEY JW, 1980, AM STAT, V34, P23, DOI 10.2307/2682991
   Van den Broeck J, 2005, PLOS MED, V2, P966, DOI 10.1371/journal.pmed.0020267
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Verbruggen Gust., 2017, Proceedings of AutoML 2017@ ECML-PKDD: Automatic selection, configuration and composition of machine learning algorithms, P18
   von Landesberger Tatiana, 2014, Handbook of Human Centric Visualization, P653
   Vrotsou K, 2019, IEEE T VIS COMPUT GR, V25, P2597, DOI 10.1109/TVCG.2018.2848247
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Wang DK, 2021, Arxiv, DOI arXiv:2101.03970
   Wang DM, 2021, INT SYMP INERT SENSO, DOI 10.1109/INERTIAL51137.2021.9430471
   Wang XM, 2016, J COMPUT SCI TECH-CH, V31, P787, DOI 10.1007/s11390-016-1663-1
   Ware C., 2019, Information Visualization: Perception for Design
   Watkins E. T., 2000, AFITGCSENG00M24 WRIG
   Wickens C, 2018, J COGN ENG DECIS MAK, V12, P35, DOI 10.1177/1555343417727438
   Xin D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445306
   Xue B, 2016, IEEE T EVOLUT COMPUT, V20, P606, DOI 10.1109/TEVC.2015.2504420
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   Yang D., 2007, ACM SIGKDD EXPLORATI, V9, P22, DOI DOI 10.1145/1345448.1345453
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zöller MA, 2021, J ARTIF INTELL RES, V70, P409
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 141
TC 3
Z9 4
U1 1
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3550
EP 3568
DI 10.1109/TVCG.2022.3163765
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200008
PM 35358047
DA 2024-11-06
ER

PT J
AU Guo, ZC
   Tao, J
   Chen, SM
   Chawla, NV
   Wang, CL
AF Guo, Zhichun
   Tao, Jun
   Chen, Siming
   Chawla, Nitesh V.
   Wang, Chaoli
TI SD<SUP>2</SUP>: Slicing and Dicing Scholarly Data for Interactive
   Evaluation of Academic Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scholarly performance; publication; citation; hierarchical histogram;
   visual analytics
ID VISUALIZATION; EXPLORATION; CONTEXT
AB Comprehensively evaluating and comparing researchers' academic performance is complicated due to the intrinsic complexity of scholarly data. Different scholarly evaluation tasks often require the publication and citation data to be investigated in various manners. In this article, we present an interactive visualization framework, SD2, to enable flexible data partition and composition to support various analysis requirements within a single system. SD2 features the hierarchical histogram, a novel visual representation for flexibly slicing and dicing the data, allowing different aspects of scholarly performance to be studied and compared. We also leverage the state-of-the-art set visualization technique to select individual researchers or combine multiple scholars for comprehensive visual comparison. We conduct multiple rounds of expert evaluation to study the effectiveness and usability of SD2 and revise the design and system implementation accordingly. The effectiveness of SD2 is demonstrated via multiple usage scenarios with each aiming to answer a specific, commonly raised question.
C1 [Guo, Zhichun] Sun Yat sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
   [Guo, Zhichun; Chawla, Nitesh V.; Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Tao, Jun] Sun Yat sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Tao, Jun] Natl Supercomp Ctr Guangzhou, Guangzhou 510006, Guangdong, Peoples R China.
   [Tao, Jun; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
C3 Sun Yat Sen University; University of Notre Dame; Sun Yat Sen
   University; Fudan University
RP Tao, J (corresponding author), Sun Yat sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.; Tao, J (corresponding author), Natl Supercomp Ctr Guangzhou, Guangzhou 510006, Guangdong, Peoples R China.; Tao, J (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
EM zguo5@nd.edu; taoj23@mail.sysu.edu.cn; simingchen@fudan.edu.cn;
   nchawla@nd.edu; chaoli.wang@nd.edu
RI Chen, Siming/AAK-1874-2020; Wang, Chaoli/AAJ-5173-2020; Chawla,
   Nitesh/F-2690-2016
OI Chawla, Nitesh/0000-0003-3932-5956; Wang, Chaoli/0000-0002-0859-3619
FU National Natural Science Foundation of China [61902446, 91937302]; Key
   Ramp;D Program of Guangdong [2019B010151001]; Shanghai Municipal Science
   and Technology Major Project [2018SHZDZX01]; ZJLab, Shanghai Sailing
   Program [21YF1402900]; Science and Technology Commission of Shanghai
   Municipality [21ZR1403300]; U.S. National Science Foundation
   [IIS-1455886, DUE-1833129, IIS-1955395, IIS-2101696, OAC-2104158]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61902446 and 91937302, in part by the
   Key R & amp;D Program of Guangdong under Grant 2019B010151001, in part
   by Shanghai Municipal Science and Technology Major Project under Grant
   2018SHZDZX01, in part by ZJLab, Shanghai Sailing Program under Grant
   21YF1402900, in part by the Science and Technology Commission of
   Shanghai Municipality under Grant 21ZR1403300, and in part by U.S.
   National Science Foundation under grants IIS-1455886, DUE-1833129,
   IIS-1955395, IIS-2101696, and OAC-2104158.
CR AMiner, 2018, AI 10 MOST INFL SCHO
   Beck F., 2014, JOINT P 4 INT WORKSH, V1244, P53
   Cao N, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.73
   China Computer Federation, 2019, LIST COMP SCI C JOUR
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Du F, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200490
   Fung TL, 2016, IEEE PAC VIS SYMP, P244, DOI 10.1109/PACIFICVIS.2016.7465279
   Glueck M, 2016, IEEE T VIS COMPUT GR, V22, P101, DOI 10.1109/TVCG.2015.2467733
   Guerra-Gómez JA, 2013, TRANSPORT RES REC, P48, DOI 10.3141/2392-06
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Lamping J, 1996, J VISUAL LANG COMPUT, V7, P33, DOI 10.1006/jvlc.1996.0003
   Lee B., 2007, Information Visualization, V6, P233, DOI DOI 10.1057/PALGRAVE.IVS.9500157
   Lee B., 2005, CHI 05 EXTENDED ABST, P1969, DOI DOI 10.1145/1056808.1057069
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   Liu DY, 2017, INFORM VISUAL, V16, P179, DOI 10.1177/1473871616667632
   Liu JH, 2018, IEEE ACCESS, V6, P12825, DOI 10.1109/ACCESS.2018.2800032
   Liu ZP, 2020, IEEE T VIS COMPUT GR, V26, P2732, DOI 10.1109/TVCG.2019.2898186
   Maguire E., 2016, P EUR IEEE VGTC C VI, P103
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Rind A., 2017, P EUR IEEE VGTC C VI, P169
   Shi L, 2015, IEEE T KNOWL DATA EN, V27, P3417, DOI 10.1109/TKDE.2015.2453957
   Shin M, 2019, IEEE CONF VIS ANAL, P1, DOI [10.1109/VAST47406.2019.8986934, 10.1109/vast47406.2019.8986934]
   SHNEIDERMAN B, 1992, ACM T GRAPHIC, V11, P92, DOI 10.1145/102377.115768
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   Tu Y, 2007, IEEE T VIS COMPUT GR, V13, P1286, DOI 10.1109/TVCG.2007.70529
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   van Liere R, 2003, IEEE T VIS COMPUT GR, V9, P206, DOI 10.1109/TVCG.2003.1196007
   Wang Y., 2018, ACM T INTERACT INTEL, V8, p5:1
   Wang Y, 2019, J VISUAL-JAPAN, V22, P941, DOI 10.1007/s12650-019-00585-2
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Wu Meng Qi Yelena, 2013, 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P779
   Wu YH, 2016, IEEE T VIS COMPUT GR, V22, P260, DOI [10.1109/TVCG.2015.2468151, 10.1109/TVCG.2015.2465151]
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Zhang J, 2009, IEEE T VIS COMPUT GR, V15, P1153, DOI 10.1109/TVCG.2009.202
   Zhao J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5003, DOI 10.1145/2858036.2858488
NR 39
TC 1
Z9 2
U1 0
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3569
EP 3585
DI 10.1109/TVCG.2022.3163727
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200009
PM 35363616
DA 2024-11-06
ER

PT J
AU Yang, C
   Zhang, ZW
   Fan, ZP
   Jiang, RH
   Chen, QJ
   Song, X
   Shibasaki, R
AF Yang, Chuang
   Zhang, Zhiwen
   Fan, Zipei
   Jiang, Renhe
   Chen, Quanjun
   Song, Xuan
   Shibasaki, Ryosuke
TI EpiMob: Interactive Visual Analytics of Citywide Human Mobility
   Restrictions for Epidemic Control
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human mobility simulation; epidemic control; visual analytics;
   interactive system; big trajectory data
ID COVID-19
AB The outbreak of coronavirus disease (COVID-19) has swept across more than 180 countries and territories since late January 2020. As a worldwide emergency response, governments have implemented various measures and policies, such as self-quarantine, travel restrictions, work from home, and regional lockdown, to control the spread of the epidemic. These countermeasures seek to restrict human mobility because COVID-19 is a highly contagious disease that is spread by human-to-human transmission. Medical experts and policymakers have expressed the urgency to effectively evaluate the outcome of human restriction policies with the aid of big data and information technology. Thus, based on big human mobility data and city POI data, an interactive visual analytics system called Epidemic Mobility (EpiMob) was designed in this study. The system interactively simulates the changes in human mobility and infection status in response to the implementation of a certain restriction policy or a combination of policies (e.g., regional lockdown, telecommuting, screening). Users can conveniently designate the spatial and temporal ranges for different mobility restriction policies. Then, the results reflecting the infection situation under different policies are dynamically displayed and can be flexibly compared and analyzed in depth. Multiple case studies consisting of interviews with domain experts were conducted in the largest metropolitan area of Japan (i.e., Greater Tokyo Area) to demonstrate that the system can provide insight into the effects of different human mobility restriction policies for epidemic control, through measurements and comparisons.
C1 [Yang, Chuang; Zhang, Zhiwen; Fan, Zipei; Jiang, Renhe; Chen, Quanjun; Song, Xuan; Shibasaki, Ryosuke] Univ Tokyo, Ctr Spatial Informat Sci, Tokyo 1138654, Japan.
   [Fan, Zipei; Jiang, Renhe; Chen, Quanjun; Song, Xuan; Shibasaki, Ryosuke] Southern Univ Sci & Technol, SUSTech UTokyo Joint Res Ctr Super Smart City, Shenzhen 518055, Guangdong, Peoples R China.
C3 University of Tokyo; Southern University of Science & Technology
RP Jiang, RH; Song, X (corresponding author), Univ Tokyo, Ctr Spatial Informat Sci, Tokyo 1138654, Japan.
EM chuang.yang@csis.u-tokyo.ac.jp; zhangzhiwen@csis.u-tokyo.ac.jp;
   fanzipei@iis.u-tokyo.ac.jp; jiangrh@csis.u-tokyo.ac.jp;
   chen1990@iis.u-tokyo.ac.jp; songxuan@csis.u-tokyo.ac.jp;
   shiba@csis.u-tokyo.ac.jp
RI Zhang, Haoran/M-2665-2019; Zhang, Zhiwen/ABI-4441-2022; Jiang,
   Renhe/AAU-3856-2020; 子沛, 范/AAJ-2988-2020; Yang, Chuang/HNI-7345-2023;
   Song, Xuan/L-8086-2018; Jiang, Renhe/L-8202-2018
OI Fan, Zipei/0000-0002-1442-1530; Song, Xuan/0000-0003-4042-7888; Zhiwen,
   Zhang/0000-0001-9524-7871; Jiang, Renhe/0000-0003-2593-4638; YANG,
   Chuang/0000-0002-8504-0057
FU Grants-in-Aid for Scientific Research [20K19782] Funding Source: KAKEN
CR Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Afzal S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P86, DOI 10.1109/VIS47514.2020.00024
   [Anonymous], 2016, The Multi -Agent Transport Simulation MATSim
   [Anonymous], 2011, P 3 INT C ADV SYST S
   Asahi Shimbun, 2020, HOUSEHOLD INFECT RIS
   Baratchi M, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P401, DOI 10.1145/2632048.2636068
   Barrett C. L., 2008, P 2008 ACM IEEE C SU, P1, DOI [DOI 10.1109/SC.2008.5214892, 10.1109/sc.2008.5214892]
   Bartsch SM, 2020, AM J PREV MED, V59, P493, DOI 10.1016/j.amepre.2020.06.011
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Boyandin I., 2013, VISUALIZATION TEMPOR
   Boyandin Ilya, 2019, FLOWMAP BLUE
   Brauer F, 2008, LECT NOTES MATH, V1945, P19
   Brinkhoff T, 2002, GEOINFORMATICA, V6, P153, DOI 10.1023/A:1015231126594
   Brodsky I., 2018, H3: Hexagonal hierarchical geospatial indexing system
   Chang S, 2021, NATURE, V589, P82, DOI 10.1038/s41586-020-2923-3
   Chen M, 2020, Arxiv, DOI arXiv:2012.04757
   Chinazzi M, 2020, SCIENCE, V368, P395, DOI [10.1126/science.aba9757, 10.1101/2020.02.09.20021261]
   Dong ES, 2020, LANCET INFECT DIS, V20, P533, DOI 10.1016/S1473-3099(20)30120-1
   Dunne C., 2015, P 33 ANN C HUM FACT, P255, DOI DOI 10.1145/2702613.2725459
   Eichner M, 2007, BMC INFECT DIS, V7, DOI 10.1186/1471-2334-7-17
   Eubank S, 2004, NATURE, V429, P180, DOI 10.1038/nature02541
   Fan C, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95894-8
   Giordano G, 2020, NAT MED, V26, P855, DOI 10.1038/s41591-020-0883-7
   González MC, 2008, NATURE, V453, P779, DOI 10.1038/nature06958
   Guan W, 2020, NEW ENGL J MED, V382, P1708, DOI 10.1056/NEJMoa2002032
   Guo D, 2007, INT J GEOGR INF SCI, V21, P859, DOI 10.1080/13658810701349037
   Hale T, 2021, NAT HUM BEHAV, V5, P529, DOI 10.1038/s41562-021-01079-8
   Horanont T, 2013, IEEE INTELL SYST, V28, P26, DOI 10.1109/MIS.2013.3
   Jiang RH, 2018, AAAI CONF ARTIF INTE, P784
   Johanna N, 2020, J PUBLIC HEALTH RES, V9, P523, DOI 10.4081/jphr.2020.2011
   Kang X., 2020, IEEE T IND INFORM, V17, P820
   Kuniya T, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030789
   Lai SJ, 2020, NATURE, V585, P410, DOI [10.1038/s41586-020-2293-x, 10.1101/2020.03.03.20029843]
   Lau H, 2020, J TRAVEL MED, V27, DOI 10.1093/jtm/taaa037
   Leaver Dave, 2012, LEAFLET MARKERCLUSTE
   Linton NM, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020538
   Mokbel Mohamed F., 2013, Advances in Spatial and Temporal Databases. 13th International Symposium, SSTD 2013. Proceedings. LNCS 8098, P38, DOI 10.1007/978-3-642-40235-7_3
   Mukandavire Z, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0236003
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   NHK, 2020, TOK SHINJ IZ CLOS 8
   Ouyang K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3812
   Phithakkitnukoon S, 2010, LECT NOTES COMPUT SC, V6219, P14, DOI 10.1007/978-3-642-14715-9_3
   Prem K, 2020, LANCET PUBLIC HEALTH, V5, pE261, DOI 10.1016/S2468-2667(20)30073-6
   Renhe Jiang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191746
   Signorelli Carlo, 2020, Acta Biomed, V91, P175, DOI 10.23750/abm.v91i3-S.9511
   Silva PCL, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110088
   Song Gao, 2020, SIGSPATIAL Special, V12, P16, DOI 10.1145/3404820.3404824
   Taipale J, 2021, Arxiv, DOI arXiv:2104.06857
   Tian HY, 2020, SCIENCE, V368, P638, DOI 10.1126/science.abb6105
   Van den Broeck W, 2011, BMC INFECT DIS, V11, DOI [10.1186/1471-2334-11-37, 10.1186/1471-2458-11-575]
   Yañez A, 2017, 2017 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P24, DOI 10.1109/VAHC.2017.8387497
   Yang ZF, 2020, J THORAC DIS, V12, P165, DOI 10.21037/jtd.2020.02.64
   ZENRIN CO, 2011, TEL PACK DB FEBR 201
   Zuo F., 2020, P 9 SIGKDD INT WORKS
NR 55
TC 12
Z9 12
U1 4
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3586
EP 3601
DI 10.1109/TVCG.2022.3165385
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200010
PM 35385385
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Müller-Sielaff, J
   Beladi, SB
   Vrede, SW
   Meuschke, M
   Lucas, PJF
   Pijnenborg, JMA
   Oeltze-Jafra, S
AF Mueller-Sielaff, Juliane
   Beladi, Seyed Behnam
   Vrede, Stephanie W.
   Meuschke, Monique
   Lucas, Peter J. F.
   Pijnenborg, Johanna M. A.
   Oeltze-Jafra, Steffen
TI Visual Assistance in Development and Validation of Bayesian Networks for
   Clinical Decision Support
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Terms-Bayesian networks; visual analysis; clinical decision support;
   causal model development
ID VISUALIZATION; KNOWLEDGE; EXPERTS; MODEL; HEAD; TOOL
AB The development and validation of Clinical Decision Support Models (CDSM) based on Bayesian networks (BN) is commonly done in a collaborative work between medical researchers providing the domain expertise and computer scientists developing the decision support model. Although modern tools provide facilities for data-driven model generation, domain experts are required to validate the accuracy of the learned model and to provide expert knowledge for fine-tuning it while computer scientists are needed to integrate this knowledge in the learned model (hybrid modeling approach). This generally time-expensive procedure hampers CDSM generation and updating. To address this problem, we developed a novel interactive visual approach allowing medical researchers with less knowledge in CDSM to develop and validate BNs based on domain specific data mainly independently and thus, diminishing the need for an additional computer scientist. In this context, we abstracted and simplified the common workflow in BN development as well as adjusted the workflow to medical experts' needs. We demonstrate our visual approach with data of endometrial cancer patients and evaluated it with six medical researchers who are domain experts in the gynecological field.
C1 [Mueller-Sielaff, Juliane] Otto von Guericke Univ Magdeburg OVGU, Dept Neurol, D-39106 Magdeburg, Germany.
   [Beladi, Seyed Behnam] OVGU, Dept Simulat & Graph, D-39106 Magdeburg, Germany.
   [Beladi, Seyed Behnam] OVGU, Dept Neurol, D-39106 Magdeburg, Germany.
   [Vrede, Stephanie W.; Pijnenborg, Johanna M. A.] Radboud Univ Nijmegen, Med Ctr, Dept Obstet & Gynecol, NL-6525 GA Nijmegen, Netherlands.
   [Meuschke, Monique] OVGU, Dept Simulat & Graph, D-39106 Magdeburg, Germany.
   [Meuschke, Monique] Univ Jena, Inst Comp Sci, D-07743 Jena, Germany.
   [Lucas, Peter J. F.] Univ Twente, Enschede, Netherlands.
   [Lucas, Peter J. F.] Leiden Univ, LIACS, NL-2311 EZ Leiden, Netherlands.
   [Oeltze-Jafra, Steffen] OVGU, Dept Neurol, D-39106 Magdeburg, Germany.
   [Oeltze-Jafra, Steffen] OVGU, Ctr Behav Brain Sci, D-39106 Magdeburg, Germany.
   [Oeltze-Jafra, Steffen] Hannover Med Sch, Peter L Reichertz Inst Med Informat, D-30625 Hannover, Germany.
C3 Otto von Guericke University; Otto von Guericke University; Otto von
   Guericke University; Radboud University Nijmegen; Otto von Guericke
   University; Friedrich Schiller University of Jena; University of Twente;
   Leiden University - Excl LUMC; Leiden University; Otto von Guericke
   University; Otto von Guericke University; Hannover Medical School
RP Müller-Sielaff, J (corresponding author), Otto von Guericke Univ Magdeburg OVGU, Dept Neurol, D-39106 Magdeburg, Germany.
EM Juliane.Mueller-Sielaff@med.ovgu.de; SeyedBehnam.Beladi@ovgu.de;
   Stephanie.Vrede@radboudumc.nl; Meuschke@isg.cs.uni-magdeburg.de;
   Peter.Lucas@utwente.nl; Hanny.MA.Pijnenborg@radboudumc.nl;
   Steffen.Oeltze-Jafra@med.ovgu.de
RI Lucas, Peter/D-1708-2012; Pijnenborg, Johanna/G-4455-2016
OI Muller-Sielaff, Juliane/0000-0002-8279-0901; Lucas,
   Peter/0000-0001-5454-2428; Oeltze-Jafra, Steffen/0000-0002-6962-9080
FU Federal State of Saxony-Anhalt, Germany [FKZ: I 88]
FX & nbsp; This work was supported by the Federal State of Saxony-Anhalt,
   Germany under Grant FKZ: I 88.
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Amirkhani H, 2017, IEEE T PATTERN ANAL, V39, P2154, DOI 10.1109/TPAMI.2016.2636828
   Andersen S. K., 1989, IJCAI-89 Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, P1080
   Arora P, 2019, VALUE HEALTH, V22, P439, DOI 10.1016/j.jval.2019.01.006
   Bae J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P64, DOI 10.5220/0006102300640074
   Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   Bae J, 2011, IEEE T VIS COMPUT GR, V17, P2268, DOI 10.1109/TVCG.2011.187
   Bayes Server Ltd, ABOUT US
   BayesFusion, 2020, SMILE STRUCT MOD INF
   BayesFusion LLC, 2017, GEN MOD
   Blanco S. P., 2019, THESIS TU MADRID MAD
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Cain J., 2001, PLANNING IMPROVEMENT
   Champion C, 2017, Arxiv, DOI arXiv:1707.00791
   Chen YC, 2017, J ARTIF INTELL RES, V59, P103, DOI 10.1613/jair.5371
   Chiang C.-H., 2005, Visualizing graphical probabilistic models
   Chuprikova E., 2018, P EUROVIS WORKSH REP, P1
   Cypko M. A., 2020, TRELYNCA TUMOR BOARD, P57
   Cypko M. A., 2017, THESIS U LEIPZIG LEI
   Cypko MA, 2017, INT J COMPUT ASS RAD, V12, P1959, DOI 10.1007/s11548-017-1531-7
   Cypko MA, 2015, STUD HEALTH TECHNOL, V216, P259, DOI 10.3233/978-1-61499-564-7-259
   Dodier R., 1998, P C UNC ART INT, P1
   Druzdzel M. J., 1996, AISB Quarterly, P43
   Druzdzel MJ, 1999, J AM MED INFORM ASSN, P1206
   Elmqvist N, 2015, INFORM VISUAL, V14, P250, DOI 10.1177/1473871613513228
   Elsaesser C., 1990, MACH INTELL PATTERN, V10, P319
   European network of individual treatment in endometrial cancer (ENITEC), US
   Franzin A, 2017, BIOINFORMATICS, V33, P1250, DOI 10.1093/bioinformatics/btw807
   Grinberg M., 2018, Flask Web Development: Developing Web Applications with Python
   HAREL D, 1988, COMMUN ACM, V31, P514, DOI 10.1145/42411.42414
   Hassall KL, 2019, ENVIRON MODELL SOFTW, V122, DOI 10.1016/j.envsoft.2019.104539
   Hindalong E, 2020, IEEE PAC VIS SYMP, P181, DOI 10.1109/PacificVis48177.2020.5111
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Kornaropoulos Evgenios M., 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P499, DOI 10.1007/978-3-642-36763-2_44
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Latif S., 2019, EUROVIS SHORT PAPERS, P115
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Michiels M, 2021, NEUROCOMPUTING, V428, P166, DOI 10.1016/j.neucom.2020.11.066
   Müller J, 2020, COMPUT GRAPH-UK, V91, P1, DOI 10.1016/j.cag.2020.06.004
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   N. S. Corp, 2021, NET APPL
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Pearl J., 1988, PROBABILISTIC REASON
   Pfister DG, 2014, J NATL COMPR CANC NE, V12, P1454, DOI 10.6004/jnccn.2014.0142
   Reijnen C, 2019, INT J GYNECOL CANCER, V29, pA6, DOI 10.1136/ijgc-2019-ESGO.7
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Scutari M., 2020, BAYESIAN NETW STRUCT, V4, P1
   Scutari M, 2010, J STAT SOFTW, V35, P1, DOI 10.18637/jss.v035.i03
   SIMON HA, 1954, J AM STAT ASSOC, V49, P467, DOI 10.2307/2281124
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.2669579, 10.1145/2669557.26695792,9, DOI 10.1145/2669557.26695792,9]
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Tonda A., 2013, PROC 11 BIANNUAL INT, P21
   Velikova M, 2013, ARTIF INTELL MED, V57, P73, DOI 10.1016/j.artmed.2012.12.004
   Verma T. S., 1991, EQUIVALENCE SYNTHESI
   Vogogias A, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3230623
   Vourgidis I, 2019, ADV INTELL SYST, V840, P108, DOI 10.1007/978-3-319-97982-3_9
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Winkler RL., 2003, INTRO BAYESIAN INFER
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 62
TC 1
Z9 1
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3602
EP 3616
DI 10.1109/TVCG.2022.3166071
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200011
PM 35394912
OA Green Published
DA 2024-11-06
ER

PT J
AU Chen, BJ
   Fu, HB
   Zhou, K
   Zheng, YY
AF Chen, Beijia
   Fu, Hongbo
   Zhou, Kun
   Zheng, Youyi
TI OrthoAligner: Image-Based Teeth Alignment Prediction via Latent Style
   Manipulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teeth alignment; GAN inversion; StyleGAN
AB In this article, we present OrthoAligner, a novel method to predict the visual outcome of orthodontic treatment in a portrait image. Unlike the state-of-the-art method, which relies on a 3D teeth model obtained from dental scanning, our method generates realistic alignment effects in images without requiring additional 3D information as input and thus making our system readily available to average users. The key of our approach is to employ the 3D geometric information encoded in an unsupervised generative model, i.e., StyleGAN in this article. Instead of directly conducting translation in the image space, we embed the teeth region extracted from a given portrait to the latent space of the StyleGAN generator and propose a novel latent editing method to discover a geometrically meaningful editing path that yields the alignment process in the image space. To blend the edited mouth region with the original portrait image, we further introduce a BlendingNet to remove boundary artifacts and correct color inconsistency. We also extend our method to short video clips by propagating the alignment effects across neighboring frames. We evaluate our method in various orthodontic cases, compare it to the state-of-the-art and competitive baselines, and validate the effectiveness of each component.
C1 [Chen, Beijia; Zhou, Kun; Zheng, Youyi] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
   [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 Zhejiang University; City University of Hong Kong
RP Zheng, YY (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Peoples R China.
EM beibeijia@zju.edu.cn; hongbofu@cityu.edu.hk; kunzhou@acm.org;
   youyizheng@zju.edu.cn
RI Zhou, Kun/ITT-3967-2023
OI FU, Hongbo/0000-0002-0284-726X
FU National Key Research amp; Development China [2018YFE0100900]
FX & nbsp;This work was supported in part by the National Key Research &
   Development China under Grant 2018YFE0100900.
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Abdal R, 2020, PROC CVPR IEEE, P8293, DOI 10.1109/CVPR42600.2020.00832
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Alaluf Y, 2021, Arxiv, DOI [arXiv:2102.02754, DOI 10.48550/ARXIV.2102.02754]
   Almahairi A, 2018, PR MACH LEARN RES, V80
   Brock A, 2019, Arxiv, DOI arXiv:1809.11096
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen HJ, 2019, PROC CVPR IEEE, P10034, DOI 10.1109/CVPR.2019.01028
   Chen X, 2016, Arxiv, DOI arXiv:1606.03657
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Collins E, 2020, PROC CVPR IEEE, P5770, DOI 10.1109/CVPR42600.2020.00581
   Egger B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3395208
   Goetschalckx L, 2019, IEEE I CONF COMP VIS, P5743, DOI 10.1109/ICCV.2019.00584
   Gu Q., 2019, P IEEE CVF INT C COM, p10 481
   Guan SY, 2020, Arxiv, DOI arXiv:2007.01758
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jahanian Ali, 2020, arXiv
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2018, Arxiv, DOI arXiv:1710.10196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma DP, 2014, ADV NEUR IN, V27
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Li XY, 2021, PROC CVPR IEEE, P8635, DOI 10.1109/CVPR46437.2021.00853
   Liu M, 2019, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2019.00379
   Liu MY, 2018, Arxiv, DOI arXiv:1703.00848
   Liu S, 2022, IEEE T PATTERN ANAL, V44, P8538, DOI 10.1109/TPAMI.2021.3083484
   Lu YD, 2020, Arxiv, DOI arXiv:2011.11842
   Maas A. L., 2013, P ICML ATL GEORG US
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pan XA, 2021, Arxiv, DOI arXiv:2011.00844
   Park T., 2020, EUR C COMP VIS, P319, DOI DOI 10.1007/978-3-030-58545-7_19
   Perarnau G, 2016, Arxiv, DOI [arXiv:1611.06355, DOI 10.48550/ARXIV.1611.06355]
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Richardson E, 2021, Arxiv, DOI arXiv:2008.00951
   Serra J., 2012, Mathematical Morphology and its Applications to Image Processing, V2
   Shen YJ, 2021, Arxiv, DOI [arXiv:2007.06600, 10.48550/ARXIV.2007.06600]
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Shen YJ, 2020, PROC CVPR IEEE, P9240, DOI 10.1109/CVPR42600.2020.00926
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Siarohin A., 2019, ADV NEURAL INFORM PR, P7137
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taigman Y., 2016, arXiv
   Tewari A., 2022, ACM T GRAPHIC, V39, P1
   Tewari A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417803
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tov Omer, 2021, arXiv
   Xia W., 2021, arXiv
   Yang LC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417771
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhu PH, 2021, Arxiv, DOI arXiv:2012.09036
NR 58
TC 1
Z9 2
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3617
EP 3629
DI 10.1109/TVCG.2022.3166159
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200012
PM 35404818
DA 2024-11-06
ER

PT J
AU Ling, JW
   Wang, ZB
   Lu, M
   Wang, Q
   Qian, C
   Xu, F
AF Ling, Jingwang
   Wang, Zhibo
   Lu, Ming
   Wang, Quan
   Qian, Chen
   Xu, Feng
TI Semantically Disentangled Variational Autoencoder for Modeling 3D Facial
   Details
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Detail reconstruction; facial animation; semantic disentanglement
ID FACE RECONSTRUCTION
AB Parametric face models, such as morphable and blendshape models, have shown great potential in face representation, reconstruction, and animation. However, all these models focus on large-scale facial geometry. Facial details such as wrinkles are not parameterized in these models, impeding accuracy and realism. In this article, we propose a method to learn a Semantically Disentangled Variational Autoencoder (SDVAE) to parameterize facial details and support independent detail manipulation as an extension of an off-the-shelf large-scale face model. Our method utilizes the non-linear capability of Deep Neural Networks for detail modeling, achieving better accuracy and greater representation power compared with linear models. In order to disentangle the semantic factors of identity, expression and age, we propose to eliminate the correlation between different factors in an adversarial manner. Therefore, wrinkle-level details of various identities, expressions, and ages can be generated and independently controlled by changing latent vectors of our SDVAE. We further leverage our model to reconstruct 3D faces via fitting to facial scans and images. Benefiting from our parametric model, we achieve accurate and robust reconstruction, and the reconstructed details can be easily animated and manipulated. We evaluate our method on practical applications, including scan fitting, image fitting, video tracking, model manipulation, and expression and age animation. Extensive experiments demonstrate that the proposed method can robustly model facial details and achieve better results than alternative methods.
C1 [Ling, Jingwang; Wang, Zhibo; Xu, Feng] Tsinghua Univ, Sch Software & BNRist, Beijing 100084, Peoples R China.
   [Lu, Ming] Intel Labs, Beijing 100086, Peoples R China.
   [Wang, Quan; Qian, Chen] Sensetime Res, Beijing, Peoples R China.
C3 Tsinghua University; Intel Corporation
RP Xu, F (corresponding author), Tsinghua Univ, Sch Software & BNRist, Beijing 100084, Peoples R China.
EM lingjw20@mails.tsinghua.edu.cn; wzb17@mails.tsinghua.edu.cn;
   lu199192@gmail.com; wangquan@sensetime.com; qianchen@sensetime.com;
   xufeng2003@gmail.com
OI Ling, Jingwang/0000-0001-8746-8578
FU Beijing Natural Science Foundation [JQ19015]; NSFC [62021002, 61727808];
   National Key Ramp;D Program of China [2018YFA0704000]; THUIBCS; Tsinghua
   University; BLBCI; Beijing Municipal Education Commission
FX This work was supported in part by Beijing Natural Science Foundation
   underGrant JQ19015, in part by the NSFC under Grants 62021002 and
   61727808,in part by the National Key R & D Program of China under Grant
   2018YFA0704000. This work was supported in part by THUIBCS, Tsinghua
   University and BLBCI, Beijing Municipal Education Commission.
CR Abrevaya VF, 2019, IEEE I CONF COMP VIS, P9418, DOI 10.1109/ICCV.2019.00951
   Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   Amberg B, 2008, IEEE INT CONF AUTOMA, P667
   Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   Bagautdinov T, 2018, PROC CVPR IEEE, P3877, DOI 10.1109/CVPR.2018.00408
   Beeler T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778777
   Beeler T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964970
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bolkart T, 2015, COMPUT VIS IMAGE UND, V131, P100, DOI 10.1016/j.cviu.2014.06.013
   Bouaziz S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461976
   Brunton A, 2014, LECT NOTES COMPUT SC, V8689, P297, DOI 10.1007/978-3-319-10590-1_20
   Cao C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766943
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chandran P, 2020, INT CONF 3D VISION, P345, DOI 10.1109/3DV50981.2020.00044
   Chen AP, 2019, IEEE I CONF COMP VIS, P9428, DOI 10.1109/ICCV.2019.00952
   Cheng SY, 2019, Arxiv, DOI arXiv:1903.10384
   Deng QX, 2022, IEEE T VIS COMPUT GR, V28, P3113, DOI 10.1109/TVCG.2021.3051251
   Feng WQ, 2022, IEEE T VIS COMPUT GR, V28, P3959, DOI 10.1109/TVCG.2021.3110658
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Ghosh P., 2020, PROC 8 INT C LEARN R
   Guo YD, 2019, IEEE T PATTERN ANAL, V41, P1294, DOI 10.1109/TPAMI.2018.2837742
   Ichim AE, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073664
   Jiang BY, 2020, IEEE T VIS COMPUT GR, V26, P2560, DOI 10.1109/TVCG.2020.2988476
   Jiang L, 2018, IEEE T IMAGE PROCESS, V27, P4756, DOI 10.1109/TIP.2018.2845697
   Jiang ZH, 2019, PROC CVPR IEEE, P11949, DOI 10.1109/CVPR.2019.01223
   Kim H, 2018, PR MACH LEARN RES, V80
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lewis John P, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liu C., 2009, Beyond pixels: exploring new representations and applications for motion analysis
   Neumann T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508417
   Nowozin S, 2016, ADV NEUR IN, V29
   Olga S., 2005, EUROGRAPHICS STATE A, DOI DOI 10.2312/EGST.20051044
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Shamai G, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337067
   Slossberg R, 2019, LECT NOTES COMPUT SC, V11131, P498, DOI 10.1007/978-3-030-11015-4_36
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P852, DOI 10.1109/ICCV.1995.466848
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Tewari A, 2020, IEEE T PATTERN ANAL, V42, P357, DOI 10.1109/TPAMI.2018.2876842
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Vlasic Daniel, 2006, P ACM SIGGRAPH COURS, P24
   Wang ZB, 2022, IEEE T VIS COMPUT GR, V28, P2364, DOI 10.1109/TVCG.2020.3033838
   Wang ZB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417824
   Wu CL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925882
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Zhang JY, 2022, IEEE T VIS COMPUT GR, V28, P1274, DOI 10.1109/TVCG.2020.3013876
   Zheng CW, 2022, IEEE T VIS COMPUT GR, V28, P3365, DOI 10.1109/TVCG.2021.3064846
   Zhou YX, 2019, PROC CVPR IEEE, P1097, DOI 10.1109/CVPR.2019.00119
NR 52
TC 6
Z9 6
U1 2
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3630
EP 3641
DI 10.1109/TVCG.2022.3166666
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200013
PM 35412983
DA 2024-11-06
ER

PT J
AU Chan, TT
   Wang, YX
   So, RHY
   Jia, J
AF Chan, Tsz Tai
   Wang, Yixuan
   So, Richard Hau Yue
   Jia, Jerry
TI Predicting Subjective Discomfort Associated With Lens Distortion in VR
   Headsets During Vestibulo-Ocular Response to VR Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; lens distortion; visual discomfort; motion sickness;
   disorientation; vestibulo-ocular reflex
ID INDUCED MOTION SICKNESS; AMPLITUDE
AB With advances in Virtual Reality (VR) technology, user expectation for a near-perfect experience is also increasing. The push for a wider field-of-view can increase the challenges of correcting lens distortion. Past studies on imperfect VR experiences have focused on motion sickness provoked by vection-inducing VR stimuli and discomfort due to mismatches in accommodation and binocular convergence. Disorientation and discomfort due to unintended optical flow induced by lens distortion, referred to as dynamic distortion (DD), has, to date, received little attention. This study examines and models the effects of DD during head rotations with various fixed gazes stabilized by vestibulo-ocular reflex (VOR). Increases in DD levels comparable to lens parameters from poorly designed commercial VR lenses significantly increase discomfort scores of viewers in relation to disorientation, dizziness, and eye strain. Cross-validated results indicate that the model is able to predict significant differences in subjective scores resulting from different commercial VR lenses and these predictions correlated with empirical data. The present work provides new insights to understand symptoms of discomfort in VR during user interactions with static world-locked / space-stabilized scenes and contributes to the design of discomfort-free VR headset lenses.
C1 [Chan, Tsz Tai] Hong Kong Univ Sci & Technol, Dept Ind Engn & Decis Analyt, Hong Kong, Peoples R China.
   [Wang, Yixuan] Hong Kong Univ Sci & Technol, Dept Chem & Biol Engn, Hong Kong, Peoples R China.
   [So, Richard Hau Yue] Hong Kong Univ Sci & Technol, Dept Ind Engn & Decis Analyt, Hong Kong, Peoples R China.
   [So, Richard Hau Yue] Hong Kong Univ Sci & Technol, Dept Chem & Biol Engn, Hong Kong, Peoples R China.
   [Jia, Jerry] Meta Real Labs, Menlo Pk, CA 94025 USA.
C3 Hong Kong University of Science & Technology; Hong Kong University of
   Science & Technology; Hong Kong University of Science & Technology; Hong
   Kong University of Science & Technology
RP Chan, TT (corresponding author), Hong Kong Univ Sci & Technol, Dept Ind Engn & Decis Analyt, Hong Kong, Peoples R China.
EM ttchanac@connect.ust.hk; ywanggx@connect.ust.hk; rhyso@ust.hk;
   jerry.jia@fb.com
RI Wang, Yixuan/GZK-6559-2022
FU Meta Reality Lab; Hong Kong University Grants Council
FX The work of Tsz Tai Chan and Yixuan Wang was supported in part by Meta
   Reality Lab and in part by Hong Kong University Grants Council.
CR [Anonymous], 2017, P IS T INT S EL IM E, DOI DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-097
   [Anonymous], 2008, POWER ANAL 2 GROUP I
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Cao Z., 2017, THESIS DUKE U N CARO
   Chen DJ, 2016, ERGONOMICS, V59, P582, DOI 10.1080/00140139.2015.1078501
   Crampton G.H., 1990, MOTION SPACE SICKNES
   de Castro A, 2011, OPT EXPRESS, V19, P19265, DOI 10.1364/OE.19.019265
   Eisinga R, 2013, INT J PUBLIC HEALTH, V58, P637, DOI 10.1007/s00038-012-0416-3
   Ellis S.R. E., 1991, Pictorial Communication in Virtual and Real Environments, V2nd
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Guo CCT, 2017, APPL ERGON, V63, P1, DOI 10.1016/j.apergo.2017.03.011
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kim W, 2021, IEEE T IMAGE PROCESS, V30, P559, DOI 10.1109/TIP.2020.3036782
   Kinsella A., 2014, THESIS CLEMSON U CLE
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   MCCOLGIN FH, 1960, J OPT SOC AM, V50, P774, DOI 10.1364/JOSA.50.000774
   MCKEE SP, 1984, VISION RES, V24, P25, DOI 10.1016/0042-6989(84)90140-8
   Moss JD, 2011, DISPLAYS, V32, P159, DOI 10.1016/j.displa.2011.05.010
   Oman CM, 2012, J VESTIBUL RES-EQUIL, V22, P117, DOI 10.3233/VES-2011-0432
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Palmisano S, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.587698
   Pierre MES, 2015, DISPLAYS, V36, P1, DOI 10.1016/j.displa.2014.10.005
   Prothero J. D., 1998, ROLE REST FRAMES VEC
   Prothero JD, 2003, VIRTUAL AND ADAPTIVE ENVIRONMENTS: APPLICATIONS, IMPLICATIONS, AND HUMAN PERFORMANCE ISSUES, P47
   Ramshaw M., 2020, P INT C ART REAL TEL, P141
   REASON JT, 1970, ADV SCI, V26, P386
   So R.H. Y., 1999, Contemporary Ergonomics
   So R. H. Y., 1994, P UK INF GROUP M HUM, P1
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Strasburger H, 2011, J VISION, V11, DOI 10.1167/11.5.13
   Stratton G.M., 1897, PSYCHOL REV, V4, P341, DOI [10.1037/h0075482, DOI 10.1037/H0075482, 10.1037/h0071173, DOI 10.1037/H0071173]
   Zhang SN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1269, DOI 10.1109/VR.2019.8798136
NR 35
TC 6
Z9 8
U1 3
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3656
EP 3669
DI 10.1109/TVCG.2022.3168190
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200015
PM 35439136
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Gao, BY
   Mai, ZJ
   Tu, HW
   Duh, HBL
AF Gao, BoYu
   Mai, Zijun
   Tu, Huawei
   Duh, Henry Been-Lirn
TI Effects of Transfer Functions and Body Parts on Body-Centric Locomotion
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Transfer functions; Torso; Task analysis; Knee; Velocity control;
   Navigation; Legged locomotion; Human-centered computing; human computer
   interaction (HCI); interaction paradigms; virtualreality
ID WALKING-IN-PLACE
AB Body-centric locomotion allows users to control both movement speed and direction with body parts (e.g., head tilt, arm swing or torso lean) to navigate in virtual reality (VR). However, there is little research to systematically investigate the effects of body parts for speed and direction control on virtual locomotion by taking in account different transfer functions(L: linear function, P: power function, and CL: piecewise function with constant and linear function). Therefore, we conducted an experiment to evaluate the combinational effects of the three factors (body parts for direction control, body parts for speed control, and transfer functions) on virtual locomotion. Results showed that (1) the head outperformed the torso for movement direction control in task completion time and environmental collisions; (2) Arm-based speed control led to shorter traveled distances than both head and knee. Head-based speed control had fewer environmental collisions than knee; (3) Body-centric locomotion with CL function was faster but less accurate than both L and P functions. Task time significantly decreased from P, L to CL functions, while traveled distance and overshoot significantly increased from P, L to CL functions. L function was rated with the highest score of USE-S, -pragmatic and -hedonic; (4) Transfer function had a significant main effect on motion sickness: the participants felt more headache and nausea when performing locomotion with CL function. Our results provide implications for body-centric locomotion design in VR applications.
C1 [Gao, BoYu; Mai, Zijun] Jinan Univ, Guangdong Inst Smart Educ, Coll Cyber Secur Informat Sci & Technol, Guangzhou 510632, Peoples R China.
   [Tu, Huawei; Duh, Henry Been-Lirn] La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne 3086, Australia.
C3 Jinan University; La Trobe University
RP Tu, HW (corresponding author), La Trobe Univ, Dept Comp Sci & Informat Technol, Melbourne 3086, Australia.
EM bygao@jnu.edu.cn; maizijun@stu2020.jnu.edu.cn; h.tu@latrobe.edu.au;
   b.duh@latrobe.edu.au
RI Duh, Henry/G-3220-2010; Gao, Boyu/JNE-3525-2023; TU, Hu/KCL-6683-2024
OI Duh, Henry/0000-0003-4808-6109; Tu, Huawei/0000-0001-9689-9767; Gao,
   BoYu/0000-0001-8523-2828
FU National Natural Science Foundation of China [61902147]; Guangdong
   Province [2021A1515012629]; Guangzhou Applied and Basic Applied
   Foundation [202102021131]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61902147, in part by Guangdong Province
   under Grant 2021A1515012629, in part by Guangzhou Applied and Basic
   Applied Foundation under Grant 202102021131.
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Biswas N, 2021, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR-Adjunct54149.2021.00050
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bouguila L., 2004, P 6 INT C MULT INT, P77, DOI [DOI 10.1145/1027933.1027948, 10.1145/1027933.1027948]
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P75, DOI 10.1162/105474601750182333
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruno L, 2017, INT J HUM-COMPUT ST, V105, P1, DOI 10.1016/j.ijhcs.2017.03.006
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Calandra D., 2018, EG 2018-Short Papers, P53, DOI [10.2312/egs.20181043, DOI 10.2312/EGS.20181043]
   Calandra D, 2019, IEEE ICCE, P348, DOI [10.1109/icce-berlin47944.2019.8966165, 10.1109/ICCE-Berlin47944.2019.8966165]
   Cannavò A, 2021, IEEE T VIS COMPUT GR, V27, P1871, DOI 10.1109/TVCG.2020.3032440
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Cirio G., 2009, Proceedings of the 16th ACM Symposium on Virtual Reality Software and Technology, P155, DOI [DOI 10.1145/1643928.1643965.85L.A, DOI 10.1145/1643928.1643965, 10.1145/1643928.1643965]
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Ganapathi P, 2019, PROCEEDINGS OF THE 12TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2019, DOI 10.1145/3359566.3360059
   Gao BY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P493, DOI 10.1109/VR50410.2021.00073
   Griffin NN, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P211, DOI 10.1145/3242671.3242707
   Guy Emilie, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P43, DOI 10.1109/3DUI.2015.7131725
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   Janeh O, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.717291
   Jia Wang, 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P31, DOI 10.1109/3DUI.2012.6184181
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim JS, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P39, DOI 10.1109/VR.2012.6180876
   Kim JS, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P261, DOI 10.1109/VR.2009.4811045
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Kruijff E., 2015, P 3 ACM S SPAT US IN, P103, DOI 10.1145/2788940.2788943
   Lee CH, 2009, VISUAL COMPUT, V25, P1009, DOI 10.1007/s00371-009-0356-y
   McCullough M, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P107, DOI 10.1145/2804408.2804416
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P747, DOI 10.1145/3126594.3126645
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Park C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P254, DOI 10.1109/ISMAR-Adjunct.2018.00079
   Péruch P, 2000, LECT NOTES ARTIF INT, V1849, P253
   Pfeiffer T, 2016, P IEEE VIRT REAL ANN, P263, DOI 10.1109/VR.2016.7504754
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Punpongsanon P, 2017, IEEE T VIS COMPUT GR, V23, P1952, DOI 10.1109/TVCG.2016.2586071
   Sarupuri B, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P138, DOI 10.1145/3131277.3132177
   Sarupuri B, 2017, IEEE SYMP 3D USER, P227, DOI 10.1109/3DUI.2017.7893354
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P103, DOI 10.9781/ijimai.2017.09.001
   Slater M., 1995, Virtual Environments '95. Selected Papers of the Eurographics Workshops, P135
   SONG D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P111, DOI 10.1109/VRAIS.1993.380790
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Tregillus S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4063, DOI 10.1145/3025453.3025521
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   von Willich J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376626
   Wartenberg F., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P469
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Williams B, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010329
   Williams Betsy., 2013, Proc. ACM Symp. on Applied Perception, P67, DOI DOI 10.1145/2492494.2492512
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
   Yan L., 2004, P 4 INT IEEE C POL A, P1
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.1581426770550, 10.1109/VR46266.2020.00-44]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 59
TC 4
Z9 4
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3670
EP 3684
DI 10.1109/TVCG.2022.3169222
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200016
PM 35446769
DA 2024-11-06
ER

PT J
AU Zeng, HP
   Wang, XB
   Wang, Y
   Wu, AY
   Pong, TC
   Qu, HM
AF Zeng, Haipeng
   Wang, Xingbo
   Wang, Yong
   Wu, Aoyu
   Pong, Ting-Chuen
   Qu, Huamin
TI <i>GestureLens</i>: Visual Analysis of Gestures in Presentation Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Gesture; hand movements; presentation video analysis; visual analysis
ID SPEECH
AB Appropriate gestures can enhance message delivery and audience engagement in both daily communication and public presentations. In this article, we contribute a visual analytic approach that assists professional public speaking coaches in improving their practice of gesture training through analyzing presentation videos. Manually checking and exploring gesture usage in the presentation videos is often tedious and time-consuming. There lacks an efficient method to help users conduct gesture exploration, which is challenging due to the intrinsically temporal evolution of gestures and their complex correlation to speech content. In this article, we propose GestureLens, a visual analytics system to facilitate gesture-based and content-based exploration of gesture usage in presentation videos. Specifically, the exploration view enables users to obtain a quick overview of the spatial and temporal distributions of gestures. The dynamic hand movements are firstly aggregated through a heatmap in the gesture space for uncovering spatial patterns, and then decomposed into two mutually perpendicular timelines for revealing temporal patterns. The relation view allows users to explicitly explore the correlation between speech content and gestures by enabling linked analysis and intuitive glyph designs. The video view and dynamic view show the context and overall dynamic movement of the selected gestures, respectively. Two usage scenarios and expert interviews with professional presentation coaches demonstrate the effectiveness and usefulness of GestureLens in facilitating gesture exploration and analysis of presentation videos.
C1 [Zeng, Haipeng] Sun Yat Sen Univ, Shenzhen 518107, Guangdong, Peoples R China.
   [Wang, Xingbo; Wu, Aoyu; Pong, Ting-Chuen; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Yong] Singapore Management Univ, Singapore 188065, Singapore.
C3 Sun Yat Sen University; Hong Kong University of Science & Technology;
   Singapore Management University
RP Zeng, HP (corresponding author), Sun Yat Sen Univ, Shenzhen 518107, Guangdong, Peoples R China.
EM zenghp5@mail.sysu.edu.cn; xwangeg@cse.ust.hk; yongwang@smu.edu.sg;
   awuac@cse.ust.hk; tcpong@cse.ust.hk; huamin@cse.ust.hk
RI Wang, Xingbo/JHS-6567-2023
OI Wu, Aoyu/0000-0001-9187-9265; Wang, Xingbo/0000-0001-5693-1128
FU 100 Talents Program of Sun Yat-sen University; ITF UICP [UIT/142]; ITF
   PRP [PRP/001/21FX]
FX This work was supported in part by the 100 Talents Program of Sun
   Yat-sen University, in part by a Grant from ITF UICP under Project No.
   UIT/142, and in part by a Grant from ITF PRP under Project No.
   PRP/001/21FX.
CR Alibali MW, 2001, J MEM LANG, V44, P169, DOI 10.1006/jmla.2000.2752
   Alibali MW, 1999, PSYCHOL SCI, V10, P327, DOI 10.1111/1467-9280.00163
   Madeo RCB, 2016, EXPERT SYST APPL, V56, P100, DOI 10.1016/j.eswa.2016.02.021
   Beattie G., 2016, Rethinking body language: How hand movements reveal hidden thought
   Bernard J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P217, DOI 10.5220/0006127502170224
   Bernard J, 2013, IEEE T VIS COMPUT GR, V19, P2257, DOI 10.1109/TVCG.2013.178
   Bressem J, 2011, SEMIOTICA, V184, P53, DOI 10.1515/semi.2011.022
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carstens Adelia, 2019, IT, P1
   Currie T., 2015, 10 TIPS HELP YOU GES
   Dael N, 2012, J NONVERBAL BEHAV, V36, P97, DOI 10.1007/s10919-012-0130-0
   Denizci C., 2015, ISTANBUL EGITIMDE YE, V1, P147
   Ginosar S, 2019, PROC CVPR IEEE, P3492, DOI 10.1109/CVPR.2019.00361
   Gunter TC, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00080
   Haider F, 2016, INT CONF ACOUST SPEE, P2812, DOI 10.1109/ICASSP.2016.7472190
   Hilliard C, 2017, BEHAV RES METHODS, V49, P1, DOI 10.3758/s13428-015-0685-x
   Hoogterp B., 2014, YOUR PERFECT PRESENT
   Tanveer MI, 2017, Arxiv, DOI arXiv:1707.04790
   Jane F., 2018, MOVE MIRROR AI EXPT
   Jang SJ, 2016, IEEE T VIS COMPUT GR, V22, P21, DOI 10.1109/TVCG.2015.2468292
   Jang Sujin., 2014, P 2 ACM S SPAT US IN, P30
   Kang S, 2016, COGN RES, V1, DOI 10.1186/s41235-016-0004-9
   KENDON A., 1994, Research on language and social interaction, V27, P175, DOI DOI 10.1207/S15327973RLSI27032
   Kendon Adam, 2004, Gesture: Visible Action as Utterance
   Khoury P., 2017, 5 TALKING YOUR HANDS
   Kipp M., 2014, Handbook of Corpus Phonology, P420
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Lucas S., 2009, The Art of Public Speaking, V10th
   Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Okada S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P303, DOI 10.1145/2522848.2522898
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   T. International, 2011, GEST YOUR BOD SPEAKS
   Tanveer M. I., 2018, P CHI C HUM FACT COM, P1
   Tanveer MI, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P385, DOI 10.1145/2856767.2856785
   Tieu L, 2017, GLOSSA-UK, V2, DOI 10.5334/gjgl.334
   Wagner P, 2014, SPEECH COMMUN, V57, P209, DOI 10.1016/j.specom.2013.09.008
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wang X., 2020, PROC CHI C HUM FACTO, P1
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wittenburg Peter., 2006, P 5 INT C LANG RES E
   Wu A., 2018, IEEE T VIS COMPUT GR, V26, P2429
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI [10.1109/icra.2019.8793720, 10.1109/ICRA.2019.8793720]
   Yuanda Ling, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873038
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 51
TC 4
Z9 4
U1 1
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3685
EP 3697
DI 10.1109/TVCG.2022.3169175
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200017
PM 35446768
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Parmar, D
   Lin, LRE
   DSouza, N
   Jörg, S
   Leonard, AE
   Daily, SB
   Babu, SV
AF Parmar, Dhaval
   Lin, Lorraine
   DSouza, Nikeetha
   Jorg, Sophie
   Leonard, Alison E.
   Daily, Shaundra B.
   Babu, Sabarish V.
TI How Immersion and Self-Avatars in VR Affect Learning Programming and
   Computational Thinking in Middle School Education
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computer science education; embodied cognition; immersion; self-avatars;
   VR in middle school education; virtual reality
ID VIRTUAL-REALITY; EMBODIMENT; WORLDS; SENSE; K-12
AB We present an empirical evaluation of immersion and self-avatars as compared to desktop viewing in Virtual Reality (VR) for learning computer programming and computational thinking in middle school education using an educational VR simulation. Students were asked to programmatically choreograph dance performances for virtual characters within an educational desktop application we built earlier called Virtual Environment Interactions (VEnvI). As part of a middle school science class, 90 students from the 6th and 7th grades participated in our study. All students first visually programmed dance choreography for a virtual character they created in VEnvI on a laptop. Then, they viewed and interacted with the resulting dance performance in a between-subjects design in one of the three conditions. We compared and contrasted the benefits of embodied immersive virtual reality (EVR) viewing utilizing a head-mounted display with a body-scaled and gender-matched self-avatar, immersive virtual reality only (IVR) viewing, and desktop VR (NVR) viewing with VEnvI on pedagogical outcomes, programming performance, presence, and attitudes towards STEM and computational thinking. Results from a cognition questionnaire showed that, in the learning dimensions of Knowledge and Understanding (Bloom's taxonomy) as well as Multistructural (SOLO taxonomy), participants in EVR and IVR scored significantly higher than NVR. Also, participants in EVR scored significantly higher than IVR. We also discovered similar results in objective programming performance and presence scores in VEnvI. Furthermore, students' attitudes towards computer science, programming confidence, and impressions significantly improved to be the highest in EVR and then IVR as compared to NVR condition. Our work suggests that educators and developers of educational VR simulations, who want to enhance knowledge and understanding as well as simultaneous acquisition of multiple abstract concepts, can do so by employing immersion and self-avatars in VR learning experiences.
C1 [Parmar, Dhaval] Northeastern Univ, Boston, MA 02115 USA.
   [Lin, Lorraine; Jorg, Sophie; Leonard, Alison E.; Babu, Sabarish V.] Clemson Univ, Clemson, SC 29634 USA.
   [DSouza, Nikeetha] Indiana Univ, Bloomington, IN 47405 USA.
   [Daily, Shaundra B.] Duke Univ, Durham, NC 27708 USA.
C3 Northeastern University; Clemson University; Indiana University System;
   Indiana University Bloomington; Duke University
RP Parmar, D (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM d.parmar@northeastern.edu; lorrain@clemson.edu; nfarfand@iu.edu;
   sjoerg@clemson.edu; aleona2@clemson.edu; shani.b@duke.edu;
   sbabu@clemson.edu
RI Parmar, Dhaval/W-2724-2019
OI Babu, Sabarish/0000-0002-8348-0534
FU U.S. National Science Foundation [CNS 1344228]
FX This work was supported by U.S. National Science Foundation ( NSFINSPIRE
   Award) under Grant CNS 1344228.
CR Anderson LW., 2001, TAXONOMY LEARNING TE
   [Anonymous], 2018, Science engineering indicators 2018: Higher education in science and engineering
   Armstrong CM, 2013, J CLIN EXP NEUROPSYC, V35, P113, DOI 10.1080/13803395.2012.740002
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639
   Bertrand J, 2015, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2015.7223317
   Bhargava A, 2022, IEEE T VIS COMPUT GR, V28, P4198, DOI 10.1109/TVCG.2021.3083423
   Bhargava A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P519, DOI [10.1109/VR46266.2020.1581293987781, 10.1109/VR46266.2020.00-31]
   Biggs J, 2014, Evaluating the Quality of Learning: The SOLO Taxonomy (Structure of the Observed Learning Outcome)
   Chan JCP, 2011, IEEE T LEARN TECHNOL, V4, P187, DOI 10.1109/TLT.2010.27
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Cooper S., 2000, NE C J COMPUTING SMA, P107
   Coulter R., 2007, MED MEETS VIRT REALI, V125
   Daily SB, 2014, PROCEEDINGS OF THE 45TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'14), P91, DOI 10.1145/2538862.2538917
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Day B, 2019, J EXP PSYCHOL-APPL, V25, P1, DOI 10.1037/xap0000192
   Dodgson NA, 2004, PROC SPIE, V5291, P36, DOI 10.1117/12.529999
   Ebrahimi E, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR.2018.8446539
   Flavián C, 2021, J HOSP MARKET MANAG, V30, P1, DOI 10.1080/19368623.2020.1770146
   Gallagher S., 2005, BODY SHAPES MIND
   Hew KF, 2010, BRIT J EDUC TECHNOL, V41, P33, DOI 10.1111/j.1467-8535.2008.00900.x
   Hoffman HG, 2004, SCI AM, V291, P58, DOI 10.1038/scientificamerican0804-58
   Isaac J, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P245, DOI 10.1109/3DUI.2016.7460062
   Johnsen K, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1049
   Johnson-Glenberg M.C., 2011, Serious Educational Game Assessment, P241, DOI DOI 10.1007/978-94-6091-329-7_15
   Johnson-Glenberg MC, 2021, J COMPUT ASSIST LEAR, V37, P1263, DOI 10.1111/jcal.12567
   Juan C, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, PROCEEDINGS, P186, DOI 10.1109/ICALT.2008.121
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lee V.R., 2014, Learning technologies and the body: Integration and implementation in formal and informal learning environments
   Leonard A. E., 2014, PROC 45 ACM TECH S C, P91
   Leonard AE, 2021, J RES TECHNOL EDUC, V53, P159, DOI 10.1080/15391523.2020.1760754
   Lin L, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119884
   Llobera J, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0300
   Madden J, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0229788
   Maloney J., 2010, ACM T COMPUT EDUC, V10, P1, DOI DOI 10.1145/1868358.1868363
   McManus ErinA., 2011, Proceedings of the ACM SIGGRAPH Symposium on Applied Perception in Graphics and Visualization, P37
   Merchant Z, 2014, COMPUT EDUC, V70, P29, DOI 10.1016/j.compedu.2013.07.033
   Misa T.J., 2011, Gender codes: Why women are leaving computing
   Modi K., 2012, A Report from the Girl Scout Research Institute
   Mohler BJ, 2010, PRESENCE-TELEOP VIRT, V19, P230, DOI 10.1162/pres.19.3.230
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Papert S., 1980, MINDSTORMS CHILDREN
   Parmar D, 2016, VIRTUAL REAL-LONDON, V20, P141, DOI 10.1007/s10055-016-0287-7
   Parmar D, 2016, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2016.7504696
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Raij AB, 2007, IEEE T VIS COMPUT GR, V13, P443, DOI 10.1109/TVCG.2007.1036
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Schwartz Raz., 2018, A Networked Self and Human Augmentics, Artificial Intelligence, Sentience, editado por Zizi Papacharissi, P108, DOI DOI 10.4324/9781315202082-9
   Seymour NE, 2002, ANN SURG, V236, P458, DOI 10.1097/00000658-200210000-00008
   Shapiro L., 2019, Embodied Cognition
   Steed A, 2016, IEEE T VIS COMPUT GR, V22, P1406, DOI 10.1109/TVCG.2016.2518135
   Strauss A., 1998, Basics of qualitative research techniques, P1
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Tuena C, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11081067
   Tuena C, 2019, J CLIN MED, V8, DOI 10.3390/jcm8050620
   Tuena C, 2017, ANN REV CYBERTHERAPY, V15, P98
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zhao JY, 2020, SPAT COGN COMPUT, V20, P328, DOI 10.1080/13875868.2020.1817925
NR 60
TC 7
Z9 7
U1 25
U2 78
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD AUG 1
PY 2023
VL 29
IS 8
BP 3698
EP 3713
DI 10.1109/TVCG.2022.3169426
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L3CU5
UT WOS:001022080200018
PM 35468062
DA 2024-11-06
ER

PT J
AU Radu, I
   Schneider, B
AF Radu, Iulian
   Schneider, Bertrand
TI How Augmented Reality (AR) Can Help and Hinder Collaborative Learning: A
   Study of AR in Electromagnetism Education
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; collaboration; education; makerspaces
ID MATHEMATICS
AB Learning physics is often difficult for students because concepts such as electricity, magnetism and sound, cannot be seen with the naked eye. Emerging technologies such as Augmented Reality (AR) can transform education by making challenging concepts visible and accessible to novices. We present a Hololens-based augmented reality system where collaborators learn about the invisible electromagnetism phenomena involved in audio speakers, and we measure the benefits of AR technology through quantitative and qualitative methods. Specifically, we measure learning (knowledge gains and transfer) and collaborative knowledge exchange behaviors. Our results indicate that, while AR generally provides a novelty effect, specific educational AR visualizations can be both beneficial and detrimental to learning - they helped students to learn spatial content and structural relationships, but hindered their understanding of kinesthetic content. Furthermore, AR facilitated learning in collaborations by providing representational common ground, which improved communication and peer teaching. We discuss these effects, as well as identify factors that have positive impact (e.g., co-located representations, easier access to resources, better grounding) or negative impact (e.g., tunnel vision, overlooking kinesthetic feedback) on student collaborative learning with augmented reality applications.
C1 [Radu, Iulian; Schneider, Bertrand] Harvard Univ, Grad Sch Educ, Cambridge, MA 02138 USA.
C3 Harvard University
RP Radu, I (corresponding author), Harvard Univ, Grad Sch Educ, Cambridge, MA 02138 USA.
EM iulian_radu@gse.harvard.edu; bertrand_schneider@gse.harvard.edu
OI RADU, IULIAN/0000-0002-0184-2969
FU National Science Foundation [1748093]
FX This work was supported by the National Science Foundation under Grant
   1748093.
CR Abdusselam MS, 2020, TECHNOL PEDAGOG EDUC, V29, P407, DOI 10.1080/1475939X.2020.1766550
   Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   Anderson JL, 2013, J SCI EDUC TECHNOL, V22, P914, DOI 10.1007/s10956-013-9438-8
   Arici F, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103647
   Bacca J, 2019, AUSTRALAS J EDUC TEC, V35, P102, DOI 10.14742/ajet.4182
   Bacca J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01486
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Beheshti E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1583, DOI 10.1145/3025453.3025479
   Bellucci A, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206508
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Ibáñez MB, 2014, COMPUT EDUC, V71, P1, DOI 10.1016/j.compedu.2013.09.004
   Bujak KR, 2013, COMPUT EDUC, V68, P536, DOI 10.1016/j.compedu.2013.02.017
   Cai S, 2017, INTERACT LEARN ENVIR, V25, P778, DOI 10.1080/10494820.2016.1181094
   Chan J., 2013, Proceedings of the 12th International Conference on Interaction Design and Children - IDC '13, P491, DOI [10.1145/2485760.2485812, DOI 10.1145/2485760.2485812]
   Chen Y.C., 2006, P ACM INT C VIRT REA, P369
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   DesPortes K., 2016, 2016 IEEE Frontiers in Education Conference (FIE), P1, DOI DOI 10.1109/FIE.2016.7757381
   Dunser A., 2012, P 24 AUSTR COMP HUM, P107
   Faridi H, 2021, COMPUT APPL ENG EDUC, V29, P258, DOI 10.1002/cae.22342
   Fontes D. T. M., 2019, BRAZ APPL SCI REV, V3, P2693
   Fyfe ER, 2014, EDUC PSYCHOL REV, V26, P9, DOI 10.1007/s10648-014-9249-3
   Garzón J, 2019, VIRTUAL REAL-LONDON, V23, P447, DOI 10.1007/s10055-019-00379-9
   Hanna MG, 2018, ARCH PATHOL LAB MED, V142, P638, DOI 10.5858/arpa.2017-0189-OA
   Kidd SH, 2016, LECT N EDUC TECHNOL, P97, DOI 10.1007/978-981-10-0027-0_6
   Lee G, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P343, DOI [10.1109/VR46266.2020.1581166222244, 10.1109/VR46266.2020.00-50]
   Maloney DP, 2001, AM J PHYS, V69, pS12, DOI 10.1119/1.1371296
   Martín-Gutiérrez J, 2015, COMPUT HUM BEHAV, V51, P752, DOI 10.1016/j.chb.2014.11.093
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Moore TJ, 2015, J RES SCI TEACH, V52, P296, DOI 10.1002/tea.21199
   Morrison A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1889
   Pittman C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P761, DOI [10.1109/VRW50115.2020.00231, 10.1109/VRW50115.2020.00-44]
   Radu Iulian, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449243
   Radu Iulian, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432944
   Radu I., 2016, Exploring the usability of augmented reality interaction techniques during children's early elementary-school years
   Radu I., 2015, Proceedings of the 14th International Conference on Interaction Design and Children - IDC '15, P430, DOI DOI 10.1145/2771839.2771871
   Radu I., 2019, INT C COMP SUPP COLL, P128
   Radu I, 2014, PERS UBIQUIT COMPUT, V18, P1533, DOI 10.1007/s00779-013-0747-y
   Rogers Y., 2006, TABLE STUDIES COLOCA
   Salomon G., 1989, INT J EDUC RES, V13, P89, DOI [https://doi.org/10.1016/0883-0355(89)90018-9, DOI 10.1016/0883-0355(89)90018-9]
   Shehab S., 2020, EXPLORING RELATIONSH
   Stahl G., 2007, The Computer Supported Collaborative Learning (CSCL) Conference 2007, P652
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Tuli N., 2020, PROCEDIA COMPUT SCI, V172, P660, DOI [10.1016/j.procs.2020.05.086, DOI 10.1016/J.PROCS.2020.05.086]
   WEBB NM, 1991, J RES MATH EDUC, V22, P366, DOI 10.2307/749186
   Wijdenes P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3174361
   Yuill N, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2147783.2147784
NR 46
TC 6
Z9 7
U1 9
U2 41
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3734
EP 3745
DI 10.1109/TVCG.2022.3169980
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300001
PM 35500084
DA 2024-11-06
ER

PT J
AU Preston, A
   Ma, KL
AF Preston, Annie
   Ma, Kwan-Liu
TI Communicating Uncertainty and Risk in Air Quality Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; air pollution; uncertainty
ID VISUALIZING UNCERTAINTY; POLLUTION
AB Environmental sensors provide crucial data for understanding our surroundings. For example, air quality maps based on sensor readings help users make decisions to mitigate the effects of pollution on their health. Standard maps show readings from individual sensors or colored contours indicating estimated pollution levels. However, showing a single estimate may conceal uncertainty and lead to underestimation of risk, while showing sensor data yields varied interpretations. We present several visualizations of uncertainty in air quality maps, including a frequency-framing "dotmap" and small multiples, and we compare them with standard contour and sensor-based maps. In a user study, we find that including uncertainty in maps has a significant effect on how much users would choose to reduce physical activity, and that people make more cautious decisions when using uncertainty-aware maps. Additionally, we analyze think-aloud transcriptions from the experiment to understand more about how the representation of uncertainty influences people's decision-making. Our results suggest ways to design maps of sensor data that can encourage certain types of reasoning, yield more consistent responses, and convey risk better than standard maps.
C1 [Preston, Annie; Ma, Kwan-Liu] Univ Calif Davis, Comp Sci, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Preston, A (corresponding author), Univ Calif Davis, Comp Sci, Davis, CA 95616 USA.
EM apreston@ucdavis.edu; ma@cs.ucdavis.edu
OI Ma, Kwan-Liu/0000-0001-8086-0366
FU U.S. National Science Foundation [IIS-1741536, IIS-1528203]
FX This work was supported by U.S. National Science Foundation under Grants
   IIS-1741536 and IIS-1528203.
CR Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Bolin D, 2017, J COMPUT GRAPH STAT, V26, P513, DOI 10.1080/10618600.2016.1228537
   Christian Lindmeier W, 2018, Saudi Med J, V39, P641, DOI DOI 10.1163/2210-7975_HRD-9841-20180002
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fontes T., 2010, REV FACULDADE CIENCI, V7, P6
   Garcia-Retamero R, 2013, CURR DIR PSYCHOL SCI, V22, P392, DOI 10.1177/0963721413491570
   Görtler J, 2019, IEEE T VIS COMPUT GR, V25, P2193, DOI 10.1109/TVCG.2019.2903945
   Greis M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174079
   Greis M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P828, DOI 10.1145/3025453.3025998
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P143, DOI 10.1145/2993901.2993919
   Hulman J, 2018, IEEE T VIS COMPUT GR, V24, P446, DOI 10.1109/TVCG.2017.2743898
   Joslyn S, 2013, CURR DIR PSYCHOL SCI, V22, P308, DOI 10.1177/0963721413481473
   Joslyn S, 2010, METEOROL APPL, V17, P180, DOI 10.1002/met.190
   Joslyn SL, 2012, J EXP PSYCHOL-APPL, V18, P126, DOI 10.1037/a0025185
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Khreis H, 2017, ENVIRON INT, V100, P1, DOI 10.1016/j.envint.2016.11.012
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Kinkeldey C, 2014, CARTOGR GEOGR INF SC, V41, P430, DOI 10.1080/15230406.2014.949868
   Klippel A, 2011, ANN ASSOC AM GEOGR, V101, P1011, DOI 10.1080/00045608.2011.577364
   Knowles SG, 2014, TECHNOL CULT, V55, P773, DOI 10.1353/tech.2014.0110
   Li XD, 2019, NATURE, V570, P437, DOI 10.1038/d41586-019-01960-7
   Liu HY, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10020041
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Love AL, 2005, IEEE COMPUT GRAPH, V25, P69, DOI 10.1109/MCG.2005.71
   Lucchesi LR, 2017, STAT, V6, P292, DOI 10.1002/sta4.150
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   Pebesma EJ, 2007, INT J GEOGR INF SCI, V21, P515, DOI 10.1080/13658810601064009
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Powell P, 2016, BREATHE, V12, P201, DOI 10.1183/20734735.011416
   Severtson DJ, 2013, RISK ANAL, V33, P818, DOI 10.1111/j.1539-6924.2012.01893.x
   Soden R, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3173027
   Soden R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2042, DOI 10.1145/3025453.3025983
   Tessum CW, 2019, P NATL ACAD SCI USA, V116, P6001, DOI 10.1073/pnas.1818859116
   Wells EM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0050526
   Wu X, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abd4049
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
NR 40
TC 7
Z9 7
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3746
EP 3757
DI 10.1109/TVCG.2022.3171443
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300002
PM 35486550
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chakhchoukh, M
   Boukhelifa, N
   Bezerianos, A
AF Chakhchoukh, Mehdi
   Boukhelifa, Nadia
   Bezerianos, Anastasia
TI Understanding How In-Visualization Provenance Can Support Trade-Off
   Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision making; multi-criteria; provenance; qualitative study;
   trade-offs; visualization
ID VISUAL ANALYSIS; EXPLORATION; SENSEMAKING; AWARENESS
AB In domains, such as agronomy or manufacturing, experts need to consider trade-offs when making decisions that involve several, often competing, objectives. Such analysis is complex and may be conducted over long periods of time, making it hard to revisit. In this paper, we consider the use of analytic provenance mechanisms to aid experts recall and keep track of trade-off analysis. We implemented VisProm, a web-based trade-off analysis system, that incorporates in-visualization provenance views, designed to help experts keep track of trade-offs and their objectives. We used VisProm as a technology probe to understand user needs and explore the potential role of provenance in this context. Through observation sessions with three groups of experts analyzing their own data, we make the following contributions. We first, identify eight high-level tasks that experts engaged in during trade-off analysis, such as locating and characterizing interest zones in the trade-off space, and show how these tasks can be supported by provenance visualization. Second, we refine findings from previous work on provenance purposes such as recall and reproduce, by identifying specific objects of these purposes related to trade-off analysis, such as interest zones, and exploration structure (e.g., exploration of alternatives and branches). Third, we discuss insights on how the identified provenance objects and our designs support these trade-off analysis tasks, both when revisiting past analysis and while actively exploring. And finally, we identify new opportunities for provenance-driven trade-off analysis, for example related to monitoring the coverage of the trade-off space, and tracking alternative trade-off scenarios.
C1 [Chakhchoukh, Mehdi] Univ Paris Saclay, CNRS, INRIA, AgroParisTech,INRAE,UMR MIA Paris, F-91190 Gif sur yvette, Paris, France.
   [Boukhelifa, Nadia] Univ Paris Saclay, AgroParisTech, INRAE, UMR MIA Paris, F-91120 Palaiseau, Paris, France.
   [Bezerianos, Anastasia] Univ Paris Saclay, CNRS, INRIA, F-91190 Gif sur yvette, France.
C3 AgroParisTech; INRAE; Universite Paris Cite; Inria; Centre National de
   la Recherche Scientifique (CNRS); Universite Paris Saclay; INRAE;
   Universite Paris Cite; Universite Paris Saclay; AgroParisTech; Inria;
   Universite Paris Saclay; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS)
RP Chakhchoukh, M (corresponding author), Univ Paris Saclay, CNRS, INRIA, AgroParisTech,INRAE,UMR MIA Paris, F-91190 Gif sur yvette, Paris, France.
EM mehdi.chakhchoukh@universite-paris-saclay.fr; nadia.boukhelifa@inrae.fr;
   anastasia.bezerianos@universite-paris-saclay.fr
OI Chakhchoukh, Mehdi/0000-0002-3967-0488; Bezerianos,
   Anastasia/0000-0002-7142-2548
FU CERPOLETHIS ethics board
FX This work involved human subjects or animals in its research. Approval
   of allethical and experimental procedures and protocols was granted by
   the CERPOLETHIS ethics board.
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Barczewski Antoine, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382845
   Bautista J., 2008, Proceedings of the working conference on advanced visual interfaces, P207
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Boukhelifa N, 2013, COMPUT GRAPH FORUM, V32, P31, DOI 10.1111/cgf.12090
   Boukhelifa N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300874
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Ceballos B, 2016, PROG ARTIF INTELL, V5, P315, DOI 10.1007/s13748-016-0093-1
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dunne C., 2012, P SIGCHI C HUMAN FAC, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Feng M, 2017, IEEE T VIS COMPUT GR, V23, P351, DOI 10.1109/TVCG.2016.2599058
   Gotz D, 2009, INFORM VISUAL, V8, P42, DOI 10.1057/ivs.2008.31
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Hakanen J, 2021, J OPER RES SOC, V72, P2073, DOI 10.1080/01605682.2020.1768809
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hutchinson Hilary, 2003, C HUM FACT COMP SYST
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Liu ZC, 2017, IEEE T VIS COMPUT GR, V23, P321, DOI 10.1109/TVCG.2016.2598797
   Loorak M, 2018, COMPUT GRAPH FORUM, V37, P51, DOI 10.1111/cgf.13400
   Madanagopal K, 2019, IEEE COMPUT GRAPH, V39, P30, DOI 10.1109/MCG.2019.2933419
   Marsaw A., 2007, PROC 45 AIAA AEROSP
   Miettinen K, 2014, OR SPECTRUM, V36, P3, DOI 10.1007/s00291-012-0297-0
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P1009, DOI 10.1109/TVCG.2021.3114827
   Nguyen PH, 2016, IEEE CONF VIS ANAL, P91, DOI 10.1109/VAST.2016.7883515
   North C., 2011, Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, P33, DOI 10.1145/1979742.1979570
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Park Y, 2016, PROC INT CONF DATA, P755, DOI 10.1109/ICDE.2016.7498287
   Ragan ED, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2711, DOI 10.1145/2702123.2702376
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shrinivasan YB, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.87
   Skopik A., 2005, SIGCHI C HUMAN FACTO, P771, DOI DOI 10.1145/1054972.1055079
   Sorger J, 2016, IEEE T VIS COMPUT GR, V22, P290, DOI 10.1109/TVCG.2015.2468011
   Strauss A., 1998, Basics of qualitative research techniques, P1
   Triantaphyllou E., 2013, MULTICRITERIA DECISI, V44
   Trinkaus HL, 2005, COMPUT OPER RES, V32, P1289, DOI 10.1016/j.cor.2003.11.010
   Tusar T, 2015, IEEE T EVOLUT COMPUT, V19, P225, DOI 10.1109/TEVC.2014.2313407
   Wall E, 2022, IEEE T VIS COMPUT GR, V28, P966, DOI 10.1109/TVCG.2021.3114862
   Wattenberg M, 2006, IEEE T VIS COMPUT GR, V12, P549, DOI 10.1109/TVCG.2006.65
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   Xu K, 2015, IEEE COMPUT GRAPH, V35, P54, DOI 10.1109/MCG.2015.50
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P340, DOI 10.1109/TVCG.2017.2745279
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
NR 48
TC 3
Z9 3
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3758
EP 3774
DI 10.1109/TVCG.2022.3171074
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300003
PM 35507619
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, XY
   Cheng, SH
   Mueller, K
AF Zhang, Xinyu
   Cheng, Shenghui
   Mueller, Klaus
TI Graphical Enhancements for Effective Exemplar Identification in
   Contextual Data Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE High-dimensional data; multivariate data; contextual displays; exemplar
   generation; decision support; configuration space
ID CATEGORICAL-DATA; VISUAL ANALYSIS
AB An exemplar is an entity that represents a desirable instance in a multi-attribute configuration space. It offers certain strengths in some of its attributes without unduly compromising the strengths in other attributes. Exemplars are frequently sought after in real life applications, such as systems engineering, investment banking, drug advisory, product marketing and many others. We study a specific method for the visualization of multi-attribute configuration spaces, the Data Context Map (DCM), for its capacity in enabling users to identify proper exemplars. The DCM produces a 2D embedding where users can view the data objects in the context of the data attributes. We ask whether certain graphical enhancements can aid users to gain a better understanding of the attribute-wise tradeoffs and so select better exemplar sets. We conducted several user studies for three different graphical designs, namely iso-contour, value-shaded topographic rendering and terrain topographic rendering, and compare these with a baseline DCM display. As a benchmark we use an exemplar set generated via Pareto optimization which has similar goals but unlike humans can operate in the native high-dimensional data space. Our study finds that the two topographic maps are statistically superior to both the iso-contour and the DCM baseline display.
C1 [Zhang, Xinyu; Mueller, Klaus] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Cheng, Shenghui] Westlake Univ, Westlake Inst Adv Study, Hangzhou 310024, Peoples R China.
   [Cheng, Shenghui] Res Ctr Ind Future, Hangzhou 310024, Peoples R China.
C3 State University of New York (SUNY) System; Stony Brook University;
   Westlake University
RP Cheng, SH (corresponding author), Westlake Univ, Westlake Inst Adv Study, Hangzhou 310024, Peoples R China.; Cheng, SH (corresponding author), Res Ctr Ind Future, Hangzhou 310024, Peoples R China.
EM zhang146@cs.stonybrook.edu; chengshenghui@westlake.edu.cn;
   mueller@cs.stonybrook.ed
RI Zhang, Xinyu/HKF-8200-2023; Zhang, Xiaofeng/JMC-6060-2023
OI Zhang, Xinyu/0000-0002-7475-8979; Zhang, Xiaofeng/0000-0003-2738-3286;
   Mueller, Klaus/0000-0002-0996-8590; Cheng, Shenghui/0000-0002-3767-8371
FU NSF [1527200, 1941613]
FX & nbsp;This work was supported by NSF under Grants IIS 1527200 and
   1941613.& nbsp;
CR Abbass HA, 2001, IEEE C EVOL COMPUTAT, P971, DOI 10.1109/CEC.2001.934295
   [Anonymous], 2011, Multiple criteria decision making: From early history to the 21st century
   [Берёзкин B.Е. Berezkin V.E.], 2006, [Журнал вычислительной математики и математической физики, Zhurnal vychislitel'noi matematiki i matematicheskoi fiziki], V46, P2009
   Blasco X, 2008, INFORM SCIENCES, V178, P3908, DOI 10.1016/j.ins.2008.06.010
   Bourke P., CONREC CONTOURING SU
   Broeksema B, 2013, COMPUT GRAPH FORUM, V32, P158, DOI 10.1111/cgf.12194
   Chalmers M., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT '93 Proceedings, P377
   Chambers J. M., 2018, Graphical methods for data analysis
   Chen JS, 2013, IEEE J-STSP, V7, P205, DOI 10.1109/JSTSP.2013.2246763
   Chen SH, 2013, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2013.6596140
   Cheng SH, 2019, IEEE T VIS COMPUT GR, V25, P1361, DOI 10.1109/TVCG.2018.2808489
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   Cockburn A, 2000, BCS CONFERENCE S, P425
   Cockburn A., 2004, P AUIC
   datavizcatalogue, RADAR CHART
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Ferariu Lavinia, 2014, 2014 IEEE 12th International Symposium on Applied Machine Intelligence and Informatics (SAMI), P73, DOI 10.1109/SAMI.2014.6822417
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Gronemann Martin, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P426, DOI 10.1007/978-3-642-36763-2_38
   Harabor D., 2011, Proceedings of the AAAI Conference on Artificial Intelligence, P1114
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hartigan J. A., 1975, Journal of Statistical Computation and Simulation, V4, P187, DOI 10.1080/00949657508810123
   Hinum K, 2005, J UNIVERS COMPUT SCI, V11, P1792
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hogräfer M, 2020, COMPUT GRAPH FORUM, V39, P647, DOI 10.1111/cgf.14031
   Hwang C.-L., 2012, Multiple Objective Decision Making-Methods and Applications: a State-of-the-Art Survey, V164
   ics, AUTOMPG DATASET
   Ingram S, 2009, IEEE T VIS COMPUT GR, V15, P249, DOI 10.1109/TVCG.2008.85
   Inselberg A., 1987, P COMPUTER GRAPHICS, P25
   kaggle, COMPLETE POKEMON DAT
   Kandel E R., 2000, Principles of Neural Science, V4, P22
   Kiker GA, 2005, INTEGR ENVIRON ASSES, V1, P95, DOI 10.1897/IEAM_2004a-015.1
   Kraus M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376675
   Kruskal J. B., 1978, Multidimensional Scaling
   Lavin A, 2015, Arxiv, DOI arXiv:1505.05947
   Lotov AV, 2008, LECT NOTES COMPUT SC, V5252, P213, DOI 10.1007/978-3-540-88908-3_9
   Mahmood S, 2020, IEEE T VIS COMPUT GR, V26, P2875, DOI 10.1109/TVCG.2019.2895642
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meyer M., 2002, Journal of Graphics Tools, V7, P13, DOI 10.1080/10867651.2002.10487551
   Miettinen K., 1999, NONLINEAR MULTIOBJEC
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   Nam JE, 2013, IEEE T VIS COMPUT GR, V19, P291, DOI 10.1109/TVCG.2012.65
   Nash A, 2013, AI MAG, V34, P85, DOI 10.1609/aimag.v34i4.2512
   Nasrolahzadeh M, 2020, IEEE SYS MAN CYBERN, P3868, DOI [10.1109/smc42975.2020.9283308, 10.1109/SMC42975.2020.9283308]
   Oesterling P., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P91, DOI 10.1109/VAST.2010.5652940
   OLSEN KA, 1993, INFORM PROCESS MANAG, V29, P69, DOI 10.1016/0306-4573(93)90024-8
   Ozsahin D.U., 2021, Applications of MultiCriteria Decision-Making Theories in Healthcare and Biomedical Engineering, P41, DOI [10.1016/b978-0-12-824086-1.00003-7, DOI 10.1016/B978-0-12-824086-1.00003-7]
   Pagliosa LD, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6020016
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Robertson G., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P153, DOI 10.1145/288392.288596
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Sawaragi Y., 1985, Theory of multiobjective optimization
   Shenas H., 2005, P C COMP GRAPH INT T, P443
   Tory M, 2007, IEEE T VIS COMPUT GR, V13, P1262, DOI 10.1109/TVCG.2007.70596
   Tory M, 2009, IEEE T VIS COMPUT GR, V15, P1033, DOI 10.1109/TVCG.2009.127
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Dijk TC, 2014, LECT NOTES COMPUT SC, V8728, P1, DOI 10.1007/978-3-319-11593-1_1
   Van Kerm P, 2003, STATA J, V3, P148, DOI 10.1177/1536867X0300300204
   Van Veldhuizen D.A., 1998, P LAT BREAK PAP GEN, P221
   Velasquez M., 2013, INT J OPERATIONS RES, V10, P56
   Wilkinson L, 2009, AM STAT, V63, P179, DOI 10.1198/tas.2009.0033
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Wise J. A., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P51, DOI 10.1109/INFVIS.1995.528686
   Yi J. S., 2005, Information Visualization, V4, P239, DOI 10.1057/palgrave.ivs.9500099
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
NR 70
TC 1
Z9 1
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3775
EP 3787
DI 10.1109/TVCG.2022.3170531
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300004
PM 35482700
DA 2024-11-06
ER

PT J
AU Bruder, V
   Larsen, M
   Ertl, T
   Childs, H
   Frey, S
AF Bruder, Valentin
   Larsen, Matthew
   Ertl, Thomas
   Childs, Hank
   Frey, Steffen
TI A Hybrid in Situ Approach for Cost Efficient Image Database Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; High performance computing; In situ
ID VISUALIZATION
AB The visualization of results while the simulation is running is increasingly common in extreme scale computing environments. We present a novel approach for in situ generation of image databases to achieve cost savings on supercomputers. Our approach, a hybrid between traditional inline and in transit techniques, dynamically distributes visualization tasks between simulation nodes and visualization nodes, using probing as a basis to estimate rendering cost. Our hybrid design differs from previous works in that it creates opportunities to minimize idle time from four fundamental types of inefficiency: variability, limited scalability, overhead, and rightsizing. We demonstrate our results by comparing our method against both inline and in transit methods for a variety of configurations, including two simulation codes and a scaling study that goes above 19 K cores. Our findings show that our approach is superior in many configurations. As in situ visualization becomes increasingly ubiquitous, we believe our technique could lead to significant amounts of reclaimed cycles on supercomputers.
C1 [Bruder, Valentin] Daimler Truck AG, D-70327 Stuttgart, Germany.
   [Larsen, Matthew] Luminary Cloud Inc, Palo Alto, CA 97403 USA.
   [Ertl, Thomas] Univ Stuttgart, D-70174 Stuttgart, Germany.
   [Childs, Hank] Univ Oregon, Eugene, OR 97403 USA.
   [Frey, Steffen] Univ Groningen, NL-9712 Groningen, Netherlands.
C3 University of Stuttgart; University of Oregon; University of Groningen
RP Bruder, V (corresponding author), Daimler Truck AG, D-70327 Stuttgart, Germany.
EM valentin.bruder@visus.uni-stuttgart.de; larsen30@llnl.gov;
   thomas.ertl@vis.uni-stuttgart.de; hank@uoregon.edu; s.d.frey@rug.nl
OI Bruder, Valentin/0000-0001-5063-4894; Ertl, Thomas/0000-0003-4019-2505;
   Frey, Steffen/0000-0002-1872-6905
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [251654672]; Intel Graphics and Visualization Institutes of XeLLENCE
   program [35512501]; Exascale Computing Project [17-SC-20-SC]; National
   Nuclear Security Administration
FX <STRONG>???????</STRONG>This work was supported in part by Deutsche
   Forschungsgemeinschaft (DFG,German Research Foundation) with in Project
   A02 of the SFB/Transregio 161under Grant 251654672, in part by the Intel
   Graphics and Visualization Institutes of XeLLENCE program under Grant CG
   #35512501, in part by Exascale Computing Project under Grant
   17-SC-20-SC, and in part by a collaborative effort of the U.S.
   Department of Energy Office of Science
   (https://doi.org/10.13039/100000015) and the National Nuclear Security
   Administration.
CR Ahrens J, 2014, INT CONF HIGH PERFOR, P424, DOI 10.1109/SC.2014.40
   Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   [Anonymous], 2013, CLOVERLEAF PREPARING, DOI [10.3371/CSRP.MACH.061213, DOI 10.3371/CSRP.MACH.061213]
   [Anonymous], 2010, PROC IEEE INT S PARA
   Ayachit U., 2015, P 1 WORKSH IN SIT IN, P25, DOI [10.1145/2828612. 2828624, DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   Ayachit U, 2016, PROCEEDINGS OF ISAV 2016: 2ND WORKSHOP ON IN SITU INFRASTRUCTURES FOR ENABLING EXTREME-SCALE ANALYSIS AND VISUALIZATION, P40, DOI [10.1109/ISAV.2016.013, 10.1109/ISAV.2016.13]
   Barbosa Joao, 2021, ISAV'21: ISAV'21: In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, P1, DOI 10.1145/3490138.3490139
   Bauer AC, 2016, COMPUT GRAPH FORUM, V35, P577, DOI 10.1111/cgf.12930
   Bennett JC, 2012, INT CONF HIGH PERFOR
   Binyahib R, 2019, IEEE T VIS COMPUT GR, V25, P2349, DOI 10.1109/TVCG.2018.2833113
   Bruder V, 2020, IEEE T VIS COMPUT GR, V26, P2848, DOI 10.1109/TVCG.2019.2898435
   Childs H, 2020, INT J HIGH PERFORM C, V34, P676, DOI 10.1177/1094342020935991
   Childs H, 2019, IEEE COMPUT GRAPH, V39, P76, DOI 10.1109/MCG.2019.2936674
   Dayal J, 2014, IEEE ACM INT SYMP, P246, DOI 10.1109/CCGrid.2014.104
   Dirand E, 2018, LECT NOTES COMPUT SC, V10776, P159, DOI 10.1007/978-3-319-69953-0_10
   Dorier Matthieu, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P67, DOI 10.1109/LDAV.2013.6675160
   Dorier M., 2016, ACM Trans. Parallel Comput, V3, P15, DOI 10.1145/2987371
   Dorier M, 2019, PROCEEDINGS OF IN SITU INFRASTRUCTURES FOR ENABLING EXTREME-SCALE ANALYSIS AND VISUALIZATION (ISAV 2019), P23, DOI 10.1145/3364228.3364234
   Dutta S, 2017, IEEE T VIS COMPUT GR, V23, P811, DOI 10.1109/TVCG.2016.2598604
   Friesen Brian, 2016, Comput Astrophys Cosmol, V3, P4, DOI 10.1186/s40668-016-0017-2
   Godoy WF, 2020, SOFTWAREX, V12, DOI 10.1016/j.softx.2020.100561
   Goswami A, 2016, IEEE ACM INT SYMP, P32, DOI 10.1109/CCGrid.2016.58
   Grosset Pascal, 2021, ISAV'21: ISAV'21: In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization, P12, DOI 10.1145/3490138.3490143
   Kress James, 2020, High Performance Computing. 35th International Conference, ISC High Performance 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12151), P146, DOI 10.1007/978-3-030-50743-5_8
   Kress J, 2019, LECT NOTES COMPUT SC, V11501, P99, DOI 10.1007/978-3-030-20656-7_6
   Larsen M., 2017, Proceedings of the in Situ Infrastructures on Enabling Extreme-Scale Analysis and Visualization, ISAV17, P42, DOI [DOI 10.1145/3144769.3144778, DOI 10.1145/3144769.31447782]
   Larsen M, 2016, SYMP LARG DATA ANAL, P37, DOI 10.1109/LDAV.2016.7874308
   Mehta K, 2019, PROCEEDINGS OF WORKS19: THE 2019 14TH IEEE/ACM WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS), P11, DOI 10.1109/WORKS49585.2019.00007
   Moreland K., 2011, PROC INT C HIGH PERF, P1
   Moreland K, 2016, IEEE COMPUT GRAPH, V36, P48, DOI 10.1109/MCG.2016.48
   Morozov D, 2016, SYMP LARG DATA ANAL, P29, DOI 10.1109/LDAV.2016.7874307
   O'Leary P, 2016, PARALLEL COMPUT, V55, P43, DOI 10.1016/j.parco.2015.10.005
   Peterka T, 2020, INT J HIGH PERFORM C, V34, P409, DOI 10.1177/1094342020913628
   Terraz T, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126922
   Do TMA, 2020, LECT NOTES COMPUT SC, V12137, P538, DOI 10.1007/978-3-030-50371-0_40
   Wang Z, 2020, IEEE INT C CL COMP, P209, DOI 10.1109/CLUSTER49012.2020.00031
   Whitlock B, 2011, Proceedings of the 11th Eurographics conference on Parallel Graphics and Visualization, DOI 10.2312/EGPGV/EGPGV11/101-109
   Woodring J, 2016, IEEE T VIS COMPUT GR, V22, P857, DOI 10.1109/TVCG.2015.2467411
   Zhang W., 2019, JOSS, V4, P1370, DOI DOI 10.21105/JOSS.01370
   Zheng F., 2011, Proceedings of the sixth workshop on Parallel Data Storage, P37
   Zheng F, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503279
NR 41
TC 0
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3788
EP 3798
DI 10.1109/TVCG.2022.3169590
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300005
PM 35486551
OA Green Published
DA 2024-11-06
ER

PT J
AU Qiao, YL
   Gao, L
   Liu, SZ
   Liu, LG
   Lai, YK
   Chen, XL
AF Qiao, Yi-Ling
   Gao, Lin
   Liu, Shu-Zhi
   Liu, Ligang
   Lai, Yu-Kun
   Chen, Xilin
TI Learning-Based Intrinsic Reflectional Symmetry Detection
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mesh processing; symmetry detection; deep learning; intrinsic
   reflectional symmetry; laplacian; eigenanalysis
ID ANIMATION
AB Reflectional symmetry is a ubiquitous pattern in nature. Previous works usually solve this problem by voting or sampling, suffering from high computational cost and randomness. In this article, we propose a learning-based approach to intrinsic reflectional symmetry detection. Instead of directly finding symmetric point pairs, we parametrize this self-isometry using a functional map matrix, which can be easily computed given the signs of Laplacian eigenfunctions under the symmetric mapping. Therefore, we manually label the eigenfunction signs for a variety of shapes and train a novel neural network to predict the sign of each eigenfunction under symmetry. Our network aims at learning the global property of functions and consequently converts the problem defined on the manifold to the functional domain. By disentangling the prediction of the matrix into separated bases, our method generalizes well to new shapes and is invariant under perturbation of eigenfunctions. Through extensive experiments, we demonstrate the robustness of our method in challenging cases, including different topology and incomplete shapes with holes. By avoiding random sampling, our learning-based algorithm is over 20 times faster than state-of-the-art methods, and meanwhile, is more robust, achieving higher correspondence accuracy in commonly used metrics.
C1 [Qiao, Yi-Ling] Univ Maryland, College Pk, MD 20742 USA.
   [Qiao, Yi-Ling; Gao, Lin; Liu, Shu-Zhi] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
   [Gao, Lin; Liu, Shu-Zhi] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 101408, Peoples R China.
   [Liu, Ligang] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF10 3AT, Wales.
   [Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Beijing 101408, Peoples R China.
C3 University System of Maryland; University of Maryland College Park;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology,
   CAS; Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Cardiff University; Chinese Academy of Sciences; Institute
   of Computing Technology, CAS
RP Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 101408, Peoples R China.; Chen, XL (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing 101408, Peoples R China.
EM qiaoyiling15@mails.ucas.ac.cn; gaolin@ict.ac.cn;
   liushuzhi16@mails.ucas.ac.cn; lgliu@ustc.edu.cn; laiy4@cardiff.ac.uk;
   xlchen@ict.ac.cn
RI Gao, Lin/JNF-0375-2023; Lai, Yu-Kun/D-2343-2010; Chen,
   Xilin/A-1409-2012; Liu, Ligang/IZQ-5817-2023; Chen, Xilin/I-4153-2014
OI Chen, Xilin/0000-0003-3024-4404; Lai, Yukun/0000-0002-2094-5680
FU Beijing Municipal Natural Science Foundation for Distinguished Young
   Scholars [JQ21013]; National Natural Science Foundation of China
   [62061136007, 61872440]; Royal Society Newton Advanced Fellowship
   [NAF-R2-192151]; Youth Innovation Promotion Association CAS
FX This work was supported in part by the Beijing Municipal Natural Science
   Foundation for Distinguished Young Scholars under Grant JQ21013, in part
   by the National Natural Science Foundation of China under Grants
   62061136007 and 61872440, and in part by Royal Society Newton Advanced
   Fellowship under Grant NAF-R2-192151 and the Youth Innovation Promotion
   Association CAS.
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Anguelov D., 2005, ADV NEURAL INFORM PR
   [Anonymous], 2010, PROC 3D DATA PROCESS
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2016, ADV NEUR IN, V29
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J, 2014, Arxiv, DOI arXiv:1312.6203
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P1466, DOI 10.1109/TVCG.2018.2871190
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dessein A, 2017, COMPUT GRAPH FORUM, V36, P95, DOI 10.1111/cgf.12997
   Donati N, 2020, PROC CVPR IEEE, P8589, DOI 10.1109/CVPR42600.2020.00862
   Giorgi Daniela, 2007, Shrec: shape retrieval contest: Watertight models track
   Halimi O, 2019, PROC CVPR IEEE, P4365, DOI 10.1109/CVPR.2019.00450
   Huang RQ, 2019, IEEE I CONF COMP VIS, P8587, DOI 10.1109/ICCV.2019.00868
   Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974
   Kim VG, 2010, COMPUT GRAPH FORUM, V29, P1689, DOI 10.1111/j.1467-8659.2010.01778.x
   Kingma D.P., 2014, P INT C LEARNING REP
   Li MC, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275042
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778840
   Litany O, 2017, IEEE I CONF COMP VIS, P5660, DOI 10.1109/ICCV.2017.603
   Liu XP, 2015, COMPUT GRAPH-UK, V46, P198, DOI 10.1016/j.cag.2014.09.016
   Luo R, 2020, IEEE T VIS COMPUT GR, V26, P1745, DOI 10.1109/TVCG.2018.2881451
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Melzi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356524
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Mitra N.J., 2010, ACM Trans. Graph, V29, P1
   Mitra NJ, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276456, 10.1145/1239451.1239514]
   Mitra NJ, 2013, EUROGRAPHICS STATE A, P175
   Nagar R., 2018, P ECCV, P417
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Poulenard A, 2019, INT CONF 3D VISION, P47, DOI 10.1109/3DV.2019.00015
   Raviv D, 2010, INT J COMPUT VISION, V89, P18, DOI 10.1007/s11263-010-0320-3
   Roufosse JM, 2019, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2019.00170
   Rustamov R. M., 2007, P S GEOM PROC, V257, P225, DOI 10.1145/1281991.1282022
   Shao TJ, 2018, Arxiv, DOI arXiv:1803.11385
   Speciale P, 2016, LECT NOTES COMPUT SC, V9912, P313, DOI 10.1007/978-3-319-46484-8_19
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Tevs A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601220
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang H, 2017, COMPUT GRAPH FORUM, V36, P51, DOI 10.1111/cgf.13271
   Xu K, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366200
   Xu K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618484
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
NR 45
TC 1
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3799
EP 3808
DI 10.1109/TVCG.2022.3172361
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300006
PM 35522628
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Wang, JP
   Wang, L
   Zheng, Y
   Yeh, CCM
   Jain, S
   Zhang, W
AF Wang, Junpeng
   Wang, Liang
   Zheng, Yan
   Yeh, Chin-Chia Michael
   Jain, Shubham
   Zhang, Wei
TI Learning-From-Disagreement: A Model Comparison and Visual Analytics
   Framework
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Learning from disagreement; model comparison; feature visualization;
   visual analytics; explainable AI
ID CLASSIFICATION
AB With the fast-growing number of classification models being produced every day, numerous model interpretation and comparison solutions have also been introduced. For example, LIME [1] and SHAP [2] can interpret what input features contribute more to a classifier's output predictions. Different numerical metrics (e.g., accuracy) can be used to easily compare two classifiers. However, few works can interpret the contribution of a data feature to a classifier in comparison with its contribution to another classifier. This comparative interpretation can help to disclose the fundamental difference between two classifiers, select classifiers in different feature conditions, and better ensemble two classifiers. To accomplish it, we propose a learning-from-disagreement (LFD) framework to visually compare two classification models. Specifically, LFD identifies data instances with disagreed predictions from two compared classifiers and trains a discriminator to learn from the disagreed instances. As the two classifiers' training features may not be available, we train the discriminator through a set of meta-features proposed based on certain hypotheses of the classifiers to probe their behaviors. Interpreting the trained discriminator with the SHAP values of different meta-features, we provide actionable insights into the compared classifiers. Also, we introduce multiple metrics to profile the importance of meta-features from different perspectives. With these metrics, one can easily identify meta-features with the most complementary behaviors in two classifiers, and use them to better ensemble the classifiers. We focus on binary classification models in the financial services and advertising industry to demonstrate the efficacy of our proposed framework and visualizations.
C1 [Wang, Junpeng; Wang, Liang; Zheng, Yan; Yeh, Chin-Chia Michael; Jain, Shubham; Zhang, Wei] Visa Res, Palo Alto, CA 94301 USA.
RP Wang, JP (corresponding author), Visa Res, Palo Alto, CA 94301 USA.
EM junpenwa@visa.com; liawang@visa.com; yazheng@visa.com; miyeh@visa.com;
   shubhjai@visa.com; wzhan@visa.com
RI Zheng, Yanlong/ADS-5844-2022; Yeh, Michael/J-1738-2019
OI Jain, Shubham/0009-0009-2790-0475; Wang, Junpeng/0000-0002-1130-9914
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   AnyAI, 2018, OPENCTR
   Bishop C. M., 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119
   Breiman L, 1996, MACH LEARN, V24, P49
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   github, WINN SOL AV CTR PROB
   github, AV FEAT
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li ZK, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P539, DOI 10.1145/3357384.3357951
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Loh WY, 2011, WIRES DATA MIN KNOWL, V1, P14, DOI 10.1002/widm.8
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2019, Arxiv, DOI [arXiv:1802.03888, 10.48550/arXiv.1802.03888]
   McMahan HB, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1222
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Molnar C., 2020, Lulu. com
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Murugesan S, 2019, IEEE COMPUT GRAPH, V39, P47, DOI 10.1109/MCG.2019.2919033
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   paperswithcode, CTR PRED AV
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Piringer H, 2010, COMPUT GRAPH FORUM, V29, P983, DOI 10.1111/j.1467-8659.2009.01684.x
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sill J, 2009, Arxiv, DOI [arXiv:0911.0460, 10.48550/arXiv.0911.0460, DOI 10.48550/ARXIV.0911.0460]
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Springenberg JT, 2015, Arxiv, DOI [arXiv:1412.6806, DOI 10.48550/ARXIV.1412.6806]
   Wang JP, 2021, IEEE PAC VIS SYMP, P186, DOI 10.1109/PacificVis52677.2021.00032
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wang W., 2006, P SIGCHI C HUM FACT, P517
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Yeh CCM, 2020, IEEE INT CONF BIG DA, P1736, DOI 10.1109/BigData50022.2020.9378417
   Yu W., 2016, P 33 INT C MACH LEAR
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zeng HP, 2017, Arxiv, DOI arXiv:1710.05285
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhao J, 2014, IEEE T VIS COMPUT GR, V20, P1773, DOI 10.1109/TVCG.2014.2346922
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou Z., 2012, ENSEMBLE METHODS FDN, DOI [10.1201/b12207, DOI 10.1201/B12207]
NR 56
TC 2
Z9 2
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3809
EP 3825
DI 10.1109/TVCG.2022.3172107
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300007
PM 35503830
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Deng, Z
   Liu, Y
   Pan, H
   Jabi, W
   Zhang, JY
   Deng, BL
AF Deng, Zhi
   Liu, Yang
   Pan, Hao
   Jabi, Wassim
   Zhang, Juyong
   Deng, Bailin
TI Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Freeform surface; architectural geometry; planar quadrilateral mesh;
   sketch-based modeling; deep learning
AB The freeform architectural modeling process often involves two important stages: concept design and digital modeling. In the first stage, architects usually sketch the overall 3D shape and the panel layout on a physical or digital paper briefly. In the second stage, a digital 3D model is created using the sketch as a reference. The digital model needs to incorporate geometric requirements for its components, such as the planarity of panels due to consideration of construction costs, which can make the modeling process more challenging. In this work, we present a novel sketch-based system to bridge the concept design and digital modeling of freeform roof-like shapes represented as planar quadrilateral (PQ) meshes. Our system allows the user to sketch the surface boundary and contour lines under axonometric projection and supports the sketching of occluded regions. In addition, the user can sketch feature lines to provide directional guidance to the PQ mesh layout. Given the 2D sketch input, we propose a deep neural network to infer in real-time the underlying surface shape along with a dense conjugate direction field, both of which are used to extract the final PQ mesh. To train and validate our network, we generate a large synthetic dataset that mimics architect sketching of freeform quadrilateral patches. The effectiveness and usability of our system are demonstrated with quantitative and qualitative evaluation as well as user studies.
C1 [Deng, Zhi] Univ Sci & Technol China, Sch Data Sci, Hefei 230026, Peoples R China.
   [Liu, Yang; Pan, Hao] Microsoft Res Asia, Internet Graph Grp, Beijing 100080, Peoples R China.
   [Jabi, Wassim] Cardiff Univ, Welsh Sch Architecture, Cardiff CF24 3AA, Wales.
   [Zhang, Juyong] Univ Sci & Technol China, Sch Math Sci, Hefei 230026, Peoples R China.
   [Deng, Bailin] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft Research Asia; Microsoft; Cardiff University;
   Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Cardiff University
RP Deng, BL (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, Wales.
EM zhideng@mail.ustc.edu.cn; yangliu@microsoft.com; haopan@microsoft.com;
   jabiw@cardiff.ac.uk; juyong@ustc.edu.cn; dengb3@cardiff.ac.uk
RI Deng, Zhi/ABD-5542-2021; Liu, Yang/ABD-2239-2020
OI Jabi, Wassim/0000-0002-2594-9568; PAN, Hao/0000-0003-3628-9777; Deng,
   Bailin/0000-0002-0158-7670; Liu, Yang/0000-0002-3768-6654
FU National Natural Science Foundation of China [62122071]; Youth
   Innovation Promotion Association CAS [2018495]; Fundamental Research
   Funds for the Central Universities [WK3470000021]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62122071, in part by Youth Innovation
   Promotion Association CAS under Grant 2018495, and in part by "the
   Fundamental Research Funds for the Central Universities" under Grant
   WK3470000021.
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Chen XJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409062
   Chen XJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1356682.1356684
   Cordier F., 2016, P SIGGRAPH ASIA COUR
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   Delanoy J, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203197
   Deng BL, 2015, COMPUT AIDED DESIGN, V61, P13, DOI 10.1016/j.cad.2014.01.004
   Deng BL, 2013, COMPUT GRAPH FORUM, V32, P11, DOI 10.1111/cgf.12021
   Deng ZT, 2020, INT CONF 3D VISION, P593, DOI 10.1109/3DV50981.2020.00069
   Deuss M., 2015, SHAPEOP A ROBUST EXT, P505
   Diamanti O, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766906
   Diamanti O, 2014, COMPUT GRAPH FORUM, V33, P1, DOI 10.1111/cgf.12426
   doCarmo M.P., 1976, Differential geometry of curves and surfaces
   Du D, 2022, IEEE T VIS COMPUT GR, V28, P2415, DOI 10.1109/TVCG.2020.3030330
   Dvoroznák M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417805
   Entem E, 2015, COMPUT GRAPH-UK, V46, P221, DOI 10.1016/j.cag.2014.09.037
   Farin G., 2000, The Essentials of CAGD
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   Glymph J, 2004, AUTOMAT CONSTR, V13, P187, DOI 10.1016/j.autcon.2003.09.008
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Han XG, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073629
   Han ZZ, 2020, IEEE T IMAGE PROCESS, V29, P8721, DOI 10.1109/TIP.2020.3018865
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang HB, 2017, IEEE T VIS COMPUT GR, V23, P2003, DOI 10.1109/TVCG.2016.2597830
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Jung A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2749458
   Kingma D.P., 2014, P INT C LEARNING REP
   Li CJ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417807
   Li CJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275051
   Li CJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073632
   Liu Y, 2006, ACM T GRAPHIC, V25, P681, DOI 10.1145/1141911.1141941
   Liu Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024174
   Lun ZL, 2017, INT CONF 3D VISION, P67, DOI 10.1109/3DV.2017.00018
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276429, 10.1145/1239451.1239492]
   Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951
   Olsen L, 2009, COMPUT GRAPH-UK, V33, P85, DOI 10.1016/j.cag.2008.09.013
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Paszke A, 2019, ADV NEUR IN, V32
   Poranne R, 2015, IEEE T VIS COMPUT GR, V21, P652, DOI 10.1109/TVCG.2014.2388205
   Pottmann H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239516
   Pottmann H, 2015, COMPUT GRAPH-UK, V47, P145, DOI 10.1016/j.cag.2014.11.002
   Rivers A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778846
   Schmidt R., 2005, EUROGRAPHICS WORKSHO, P53
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Smirnov D., 2021, INT C LEARN REPR ICL
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Tai CL, 2004, COMPUT GRAPH FORUM, V23, P71, DOI 10.1111/j.1467-8659.2004.00006.x
   Vaxman A, 2014, COMPUT GRAPH FORUM, V33, P121, DOI 10.1111/cgf.12405
   Vaxman A, 2012, COMPUT GRAPH FORUM, V31, P1647, DOI 10.1111/j.1467-8659.2012.03170.x
   Wang LJ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1820, DOI 10.1145/3240508.3240699
   Wu JJ, 2018, LECT NOTES COMPUT SC, V11215, P673, DOI 10.1007/978-3-030-01252-6_40
   Wu J, 2017, ADV NEUR IN, V30
   Yan GW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417832
   Yang L, 2021, GRAPH MODELS, V115, DOI 10.1016/j.gmod.2021.101102
   Yang YL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024158
   Zadravec M, 2010, COMPUT GRAPH FORUM, V29, P1671, DOI 10.1111/j.1467-8659.2010.01776.x
   Zhang S.-H., 2021, P IEEECVF C COMPUTER, P6012
   Zhao X, 2013, ADV ARCHITECTURAL GE, P305, DOI DOI 10.1007/978-3-7091-1251-9_25
NR 59
TC 7
Z9 8
U1 0
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3826
EP 3839
DI 10.1109/TVCG.2022.3170853
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300008
PM 35503829
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, WX
   Zhou, HJ
   Dong, Z
   Yan, QA
   Xiao, CX
AF Zhang, Wenxiao
   Zhou, Huajian
   Dong, Zhen
   Yan, Qingan
   Xiao, Chunxia
TI Rank-PointRetrieval: Reranking Point Cloud Retrieval via a Visually
   Consistent Registration Evaluation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Feature extraction; Three-dimensional displays;
   Task analysis; Cloud computing; Training; Global Positioning System;
   Point cloud; point cloud retrieval; place recognition; reranking methods
ID 3D; HISTOGRAMS
AB Point cloud-based place recognition is a fundamental part of the localization task, and it can be achieved through a retrieval process. Reranking is a critical step in improving the retrieval accuracy, yet little effort has been devoted to reranking in point cloud retrieval. In this paper, we investigate the versatility of rigid registration in reranking the point cloud retrieval results. Specifically, after obtaining the initial retrieval list based on the global point cloud feature distance, we perform registration between the query and point clouds in the retrieval list. We propose an efficient strategy based on visual consistency to evaluate each registration with a registration score in an unsupervised manner. The final reranked list is computed by considering both the original global feature distance and the registration score. In addition, we find that the registration score between two point clouds can also be used as a pseudo label to judge whether they represent the same place. Thus, we can create a self-supervised training dataset when there is no ground truth of positional information. Moreover, we develop a new probability-based loss to obtain more discriminative descriptors. The proposed reranking approach and the probability-based loss can be easily applied to current point cloud retrieval baselines to improve the retrieval accuracy. Experiments on various benchmark datasets show that both the reranking registration method and probability-based loss can significantly improve the current state-of-the-art baselines.
C1 [Zhang, Wenxiao; Zhou, Huajian; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Dong, Zhen] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & Re, Wuhan 430079, Peoples R China.
   [Yan, Qingan] InnoPeak Technol Inc, Palo Alto, CA 94303 USA.
C3 Wuhan University; Wuhan University
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM wenxxiao.zhang@gmail.com; eagle_zhou@foxmail.com;
   dongzhenwhu@whu.edu.cn; yanqunganssg@gmail.com; cxxiao@whu.edu.cn
RI Zhang, Wenxiao/KCK-3295-2024
OI ZHANG, WENXIAO/0000-0001-8680-6010; Dong, Zhen/0000-0002-0152-3300
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   NSFC [61972298]; Wuhan University-Huawei GeoInformatices Innovation Lab
FX This work was supported in part by the Key Technological Innovation
   Projects of Hubei Province under Grant 2018AAA062, in part by NSFC under
   Grant 61972298, and in part by Wuhan University-Huawei GeoInformatices
   Innovation Lab.
CR [Anonymous], 2013, P 16 INT C ADV ROB
   Ao S, 2021, PROC CVPR IEEE, P11748, DOI 10.1109/CVPR46437.2021.01158
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Choy C, 2020, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR42600.2020.00259
   Choy C, 2019, IEEE I CONF COMP VIS, P8957, DOI 10.1109/ICCV.2019.00905
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Elbaz G, 2017, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2017.265
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Foley J.D., 1996, Computer Graphics: Principles and Practice
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Hinton G. E., 2002, ADV NEURAL INFORM PR, V15, P857, DOI DOI 10.5555/2968618.2968725
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Juan Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P744, DOI 10.1007/978-3-030-58548-8_43
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26
   Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346
   Liu L, 2019, IEEE I CONF COMP VIS, P2570, DOI 10.1109/ICCV.2019.00266
   Liu Z, 2019, IEEE I CONF COMP VIS, P2831, DOI 10.1109/ICCV.2019.00292
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Lu WX, 2019, PROC CVPR IEEE, P6382, DOI 10.1109/CVPR.2019.00655
   Ma YX, 2016, IEEE COMPUT SOC CONF, P643, DOI 10.1109/CVPRW.2016.86
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Mellado N, 2016, IEEE T VIS COMPUT GR, V22, P2160, DOI 10.1109/TVCG.2015.2505287
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Spezialetti Riccardo, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P6400, DOI 10.1109/ICCV.2019.00650
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Warsaw JK, 2021, IEEE WINT CONF APPL, P1789, DOI 10.1109/WACV48630.2021.00183
   Xia Y, 2021, PROC CVPR IEEE, P11343, DOI 10.1109/CVPR46437.2021.01119
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Ye M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1239, DOI 10.1145/2733373.2806326
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Yixiao Ge, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P369, DOI 10.1007/978-3-030-58548-8_22
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang WX, 2019, PROC CVPR IEEE, P12428, DOI 10.1109/CVPR.2019.01272
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou QY, 2018, Arxiv, DOI [arXiv:1801.09847, 10.48550/arXiv.1801.09847, DOI 10.48550/ARXIV.1801.09847]
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 55
TC 4
Z9 4
U1 6
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3840
EP 3854
DI 10.1109/TVCG.2022.3170695
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300009
PM 35476576
DA 2024-11-06
ER

PT J
AU Ratzenböck, S
   Obermüller, V
   Möller, T
   Alves, J
   Bomze, IM
AF Ratzenboeck, Sebastian
   Obermueller, Verena
   Moeller, Torsten
   Alves, Joao
   Bomze, Immanuel M.
TI Uncover: Toward Interpretable Models for Detecting New Star Cluster
   Members
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interpretable models; model selection; novelty detection; star clusters
ID VISUAL ANALYTICS; GENERATION; SUPPORT; KERNEL
AB In this design study, we present Uncover, an interactive tool aimed at astronomers to find previously unidentified member stars in stellar clusters. We contribute data and task abstraction in the domain of astronomy and provide an approach for the non-trivial challenge of finding a suitable hyper-parameter set for highly flexible novelty detection models. We achieve this by substituting the tedious manual trial and error process, which usually results in finding a small subset of passable models with a five-step workflow approach. We utilize ranges of a priori defined, interpretable summary statistics models have to adhere to. Our goal is to enable astronomers to use their domain expertise to quantify model goodness effectively. We attempt to change the current culture of blindly accepting a machine learning model to one where astronomers build and modify a model based on their expertise. We evaluate the tools' usability and usefulness in a series of interviews with domain experts.
C1 [Ratzenboeck, Sebastian; Moeller, Torsten; Alves, Joao; Bomze, Immanuel M.] Data Sci Res Network, A-1090 Vienna, Austria.
   [Ratzenboeck, Sebastian; Obermueller, Verena; Moeller, Torsten] Fac Comp Sci, A-1090 Vienna, Austria.
   [Alves, Joao] Dept Astrophys, A-1180 Vienna, Austria.
   [Bomze, Immanuel M.] ISOR VCOR, A-1090 Vienna, Austria.
RP Ratzenböck, S (corresponding author), Data Sci Res Network, A-1090 Vienna, Austria.
EM sebastian.ratzenboeck@univie.ac.at; a11711429@unet.univie.ac.at;
   torsten.moeller@univie.ac.at; joao.alves@univie.ac.at;
   immanuel.bomze@univie.ac.at
RI Alves, João/AAH-7435-2019
OI Alves, Joao/0000-0002-4355-0921; Ratzenboeck,
   Sebastian/0000-0002-6215-4270; Moller, Torsten/0000-0003-1192-0710;
   Bomze, Immanuel/0000-0002-6288-9226
CR Amer M., 2013, P ACM SIGKDD WORKSH, P8, DOI DOI 10.1145/2500853.2500857
   [Anonymous], 1979, USSR COMPUTATIONAL M, DOI [10.1016/0041-5553(79)90085-5, DOI 10.1016/0041-5553(79)90085-5]
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bánhalmi A, 2007, LECT NOTES ARTIF INT, V4701, P543
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Brown AGA, 2021, ASTRON ASTROPHYS, V649, DOI 10.1051/0004-6361/202039657
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Cánovas H, 2019, ASTRON ASTROPHYS, V626, DOI 10.1051/0004-6361/201935321
   Cantat-Gaudin T, 2019, ASTRON ASTROPHYS, V624, DOI 10.1051/0004-6361/201834453
   Cantat-Gaudin T, 2018, ASTRON ASTROPHYS, V618, DOI 10.1051/0004-6361/201833476
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Castro-Ginard A, 2020, ASTRON ASTROPHYS, V635, DOI 10.1051/0004-6361/201937386
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   CHANDLER P, 1991, COGNITION INSTRUCT, V8, P293, DOI 10.1207/s1532690xci0804_2
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen BQ, 2020, ASTRON ASTROPHYS, V643, DOI 10.1051/0004-6361/201935955
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P807, DOI 10.2307/2288711
   Das S, 2021, IEEE T VIS COMPUT GR, V27, P4401, DOI 10.1109/TVCG.2020.3002166
   de Zeeuw PT, 1999, ASTRON J, V117, P354, DOI 10.1086/300682
   DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364
   Demiralp C., 2016, PROC KDD WORKSHOP IN, P37
   Deng HM, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING, VOLS 1 AND 2, P540, DOI 10.1109/CIDM.2007.368922
   Désir C, 2013, PATTERN RECOGN, V46, P3490, DOI 10.1016/j.patcog.2013.05.022
   Ducourant C, 2017, ASTRON ASTROPHYS, V597, DOI 10.1051/0004-6361/201527574
   Esplin TL, 2020, ASTRON J, V159, DOI 10.3847/1538-3881/ab8dbd
   Evangelista PF, 2007, LECT NOTES COMPUT SC, V4668, P269
   Fisher R. A., 1922, Philos. Trans. R. Soc. Lond. A, Contain. Pap. Math. Phys. Character, V222, P309, DOI [10.1098/rsta.1922.0009, DOI 10.1098/RSTA.1922.0009]
   Gagné J, 2018, ASTROPHYS J, V856, DOI 10.3847/1538-4357/aaae09
   Gaia Collaboration, 2018, ASTRON ASTROPHYS, V616, pA1
   Gaia Collaboration, 2016, ASTRON ASTROPHYS, V595, pA1
   Galli PAB, 2020, ASTRON ASTROPHYS, V634, DOI 10.1051/0004-6361/201936708
   Ghafoori Z, 2016, LECT NOTES ARTIF INT, V9652, P183, DOI 10.1007/978-3-319-31750-2_15
   Ghafoori Z, 2018, IEEE T NEUR NET LEAR, V29, P5057, DOI 10.1109/TNNLS.2017.2785792
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Grandvalet Y, 2004, MACH LEARN, V55, P251, DOI 10.1023/B:MACH.0000027783.34431.42
   Grasser N, 2021, ASTRON ASTROPHYS, V652, DOI 10.1051/0004-6361/202140438
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kamdar H, 2019, ASTROPHYS J LETT, V884, DOI 10.3847/2041-8213/ab4997
   Khazai S., IEEE GEOSCI REMOTE S, V8
   Kuhn MA, 2019, ASTROPHYS J, V870, DOI 10.3847/1538-4357/aaef8c
   Lada CJ, 2003, ANNU REV ASTRON ASTR, V41, P57, DOI 10.1146/annurev.astro.41.011802.094844
   Lex A, 2010, IEEE T VIS COMPUT GR, V16, P1027, DOI 10.1109/TVCG.2010.138
   Liu W, 2014, PROC CVPR IEEE, P3826, DOI 10.1109/CVPR.2014.483
   Liu Y, 2010, 2010 IEEE International Conference on Data Mining, P911, DOI [DOI 10.1109/ICDM.2010.35, 10.1109/ICDM.2010.35]
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Majewski SR, 2017, ASTRON J, V154, DOI 10.3847/1538-3881/aa784d
   Meingast S, 2021, ASTRON ASTROPHYS, V645, DOI 10.1051/0004-6361/202038610
   Meingast S, 2019, ASTRON ASTROPHYS, V622, DOI 10.1051/0004-6361/201834950
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nam EJ, 2007, IEEE CONF VIS ANAL, P75
   Newton ER, 2021, ASTRON J, V161, DOI 10.3847/1538-3881/abccc6
   Packer E, 2013, IEEE T VIS COMPUT GR, V19, P2179, DOI 10.1109/TVCG.2013.224
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pister A, 2021, IEEE T VIS COMPUT GR, V27, P1775, DOI 10.1109/TVCG.2020.3030347
   Ratzenböck S, 2020, ASTRON ASTROPHYS, V639, DOI 10.1051/0004-6361/202037591
   Rigliaco E, 2016, ASTRON ASTROPHYS, V588, DOI 10.1051/0004-6361/201527253
   Rockafellar RT., 2009, VARIATIONAL ANAL
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Scarr Joey, 2012, Foundations and Trends in Human-Computer Interaction, V6, P1, DOI 10.1561/1100000046
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schreck T, 2008, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2008.4677350
   Schultz T, 2013, IEEE T VIS COMPUT GR, V19, P2100, DOI 10.1109/TVCG.2013.181
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Seo J, 2002, COMPUTER, V35, P80
   Sobol IM., 1967, USSR COMP MATH MATH, V16, P236, DOI [DOI 10.1016/0041-5553(76)90154-3, 10.1016/0041-5553(76)90154-3]
   Tax DMJ, 2004, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2004.1334542
   Tax DMJ, 2002, J MACH LEARN RES, V2, P155, DOI 10.1162/15324430260185583
   Torsney-Weir T, 2011, IEEE T VIS COMPUT GR, V17, P1892, DOI 10.1109/TVCG.2011.248
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang SJ, 2013, APPL SOFT COMPUT, V13, P1193, DOI 10.1016/j.asoc.2012.11.005
   Wang SQ, 2018, PATTERN RECOGN, V74, P198, DOI 10.1016/j.patcog.2017.09.012
   Ward JL, 2020, MON NOT R ASTRON SOC, V495, P663, DOI 10.1093/mnras/staa1056
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xiao YC, 2015, IEEE T CYBERNETICS, V45, P927, DOI 10.1109/TCYB.2014.2340433
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Yianilos P. N, 1991, 9108290271 NEC RES I
NR 81
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3855
EP 3872
DI 10.1109/TVCG.2022.3172560
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300010
PM 35511834
DA 2024-11-06
ER

PT J
AU Subhash, V
   Pandey, K
   Natarajan, V
AF Subhash, Varshini
   Pandey, Karran
   Natarajan, Vijay
TI A GPU Parallel Algorithm for Computing Morse-Smale Complexes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalar field; morse-smale complex; shared memory parallel algorithm; GPU
ID COMPUTATION; SIMPLIFICATION
AB The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior between critical points of a scalar function. It supports multi-scale topological analysis and visualization of feature-rich scientific data. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. Its computation continues to pose significant algorithmic challenges. In particular, the non-trivial structure of the connections between the saddle critical points are not amenable to parallel computation. This paper describes a fine grained parallel algorithm for computing the Morse-Smale complex and a GPU implementation (gmsc). The algorithm first determines the saddle-saddle reachability via a transformation into a sequence of vector operations, and next computes the paths between saddles by transforming it into a sequence of matrix operations. Computational experiments show that the method achieves up to 8.6x speedup over pyms3d and 6x speedup over TTK, the current shared memory implementations. The paper also presents a comprehensive experimental analysis of different steps of the algorithm and reports on their contribution towards runtime performance. Finally, it introduces a CPU based data parallel algorithm for simplifying the Morse-Smale complex via iterative critical point pair cancellation.
C1 [Subhash, Varshini; Pandey, Karran; Natarajan, Vijay] Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Subhash, V (corresponding author), Indian Inst Sci, Dept Comp Sci & Automat, Bangalore 560012, Karnataka, India.
EM varshini96@gmail.com; karran13@gmail.com; vijayn@iisc.ac.in
OI Subhash, Varshini/0000-0003-1889-6821; Natarajan,
   Vijay/0000-0002-7956-1470
FU Swarnajayanti Fellowship from the Department of Science and Technology,
   India [DST/SJF/ETA-02/2015-16]; Mindtree Chair research grant; IoE Grant
   from Indian Institute of Science, Bangalore
FX This work was supported in part by the Swarnajayanti Fellowship from the
   Department of Science and Technology, India under Grants
   DST/SJF/ETA-02/2015-16, in part by Mindtree Chair research grant, and an
   IoE Grant from Indian Institute of Science, Bangalore.
CR [Anonymous], 2022, GPUSTAT
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   csa.iisc, 2020, MSCOMPLEX
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Delgado-Friedrichs O, 2015, IEEE T PATTERN ANAL, V37, P654, DOI 10.1109/TPAMI.2014.2346172
   developer.nvidia, 2020, CUDA ZON
   developer.nvidia, 2020, CUSPARSE
   developer.nvidia, 2020, THRUST
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, VB48c, P1
   Fugacci U, 2019, GRAPH MODELS, V103, DOI 10.1016/j.gmod.2019.101023
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy A, 2012, INT PARALL DISTRIB P, P484, DOI 10.1109/IPDPS.2012.52
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Harker S, 2014, FOUND COMPUT MATH, V14, P151, DOI 10.1007/s10208-013-9145-0
   Harris M., 2007, GPU gems, V3, P851
   JaJa Joseph, 1992, An introduction to parallel algorithms
   klacansky, 2020, OP SCI VIS DAT
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Merrill D, 2012, ACM SIGPLAN NOTICES, V47, P117, DOI 10.1145/2370036.2145832
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Petruzza S, 2020, IEEE T VIS COMPUT GR, V26, P140, DOI 10.1109/TVCG.2019.2934620
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Seidel R, 1995, J COMPUT SYST SCI, V51, P400, DOI 10.1006/jcss.1995.1078
   Shivashankar N., 2014, THESIS INDIAN I SCI
   Shivashankar N., 2017, TOPOLOGICAL METHODS, P317
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Subhash V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P36, DOI 10.1109/VIS47514.2020.00014
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Zwick U., 2001, Algorithms - ESA 2001. 9th Annual European Symposium. Proceedings (Lecture Notes in Computer Science Vol.2161), P33
   Zwick U, 2002, J ACM, V49, P289, DOI 10.1145/567112.567114
NR 41
TC 2
Z9 2
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3873
EP 3887
DI 10.1109/TVCG.2022.3174769
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300011
PM 35552135
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cornel, D
   Zechmeister, S
   Gröller, E
   Waser, J
AF Cornel, Daniel
   Zechmeister, Silvana
   Groeller, Eduard
   Waser, Jurgen
TI Watertight Incremental Heightfield Tessellation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization techniques and methodologies; heightfield rendering;
   terrain rendering; level of detail; tessellation
ID TERRAIN; INTERPOLATION
AB In this article, we propose a method for the interactive visualization of medium-scale dynamic heightfields without visual artifacts. Our data fall into a category too large to be rendered directly at full resolution, but small enough to fit into GPU memory without pre-filtering and data streaming. We present the real-world use case of unfiltered flood simulation data of such medium scale that need to be visualized in real time for scientific purposes. Our solution facilitates compute shaders to maintain a guaranteed watertight triangulation in GPU memory that approximates the interpolated heightfields with view-dependent, continuous levels of detail. In each frame, the triangulation is updated incrementally by iteratively refining the cached result of the previous frame to minimize the computational effort. In particular, we minimize the number of heightfield sampling operations to make adaptive and higher-order interpolations viable options. We impose no restriction on the number of subdivisions and the achievable level of detail to allow for extreme zoom ranges required in geospatial visualization. Our method provides a stable runtime performance and can be executed with a limited time budget. We present a comparison of our method to three state-of-the-art methods, in which our method is competitive to previous non-watertight methods in terms of runtime, while outperforming them in terms of accuracy.
C1 [Cornel, Daniel; Zechmeister, Silvana; Waser, Jurgen] VRVis Forsch GmbH, A-1220 Vienna, Austria.
   [Groeller, Eduard] TU Wien, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Cornel, D (corresponding author), VRVis Forsch GmbH, A-1220 Vienna, Austria.
EM cornel@vrvis.at; zechmeister@vrvis.at; groeller@cg.tuwien.ac.at;
   jwaser@vrvis.at
OI Rauer-Zechmeister, Silvana/0000-0002-4715-0351; Cornel,
   Daniel/0000-0002-2481-6720
FU BMK; BMDW; Styria; SFG; Tyrol and Vienna Business Agency in the scope of
   COMET - Competence Centers for Excellent Technologies [879730]
FX This work was supported by BMK, BMDW, Styria, SFG, Tyrol and Vienna
   Business Agency in the scope of COMET - Competence Centers for Excellent
   Technologies under Grant 879730 which is managed by FFG.& nbsp;
CR [Anonymous], 2009, P 30 ANN C EUR ASS C
   Asirvatham A., 2005, GPU GEMS 2, V2, P27
   Bonaventura X, 2011, GPU PRO, V2, P3
   Boubekeur T, 2008, COMPUT GRAPH FORUM, V27, P102, DOI 10.1111/j.1467-8659.2007.01040.x
   Cantlay I., 2011, CISC VIS NETW IND GL
   Cheng TP, 2013, COMPUT GEOSCI-UK, V54, P178, DOI 10.1016/j.cageo.2012.11.013
   Cornel D, 2019, COMPUT GRAPH FORUM, V38, P25, DOI 10.1111/cgf.13669
   Cornel D., 2022, ARXIV
   DICK CHRISTIAN., 2009, P EUROGRAPHICS 2009, P43, DOI [10.2312/ega.20091007, DOI 10.2312/EGA.20091007]
   Dupuy J, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406186
   Dyken C, 2009, COMPUT GRAPH FORUM, V28, P2255, DOI 10.1111/j.1467-8659.2009.01438.x
   Englert Matthias, 2020, ACM SIGGRAPH 2020 TA, DOI [10.1145/3388767.3407391, DOI 10.1145/3388767.3407391]
   Houska P., 2020, THESIS TU WIEN VIENN
   Hu LA, 2010, IEEE T VIS COMPUT GR, V16, P718, DOI 10.1109/TVCG.2009.101
   Jang H, 2013, COMPUT AIDED DESIGN, V45, P517, DOI 10.1016/j.cad.2012.10.034
   Johanson C., 2004, THESIS LUND U LUND
   Kang H, 2018, GRAPH MODELS, V97, P64, DOI 10.1016/j.gmod.2018.04.001
   Kang H, 2015, VISUAL COMPUT, V31, P455, DOI 10.1007/s00371-014-0941-6
   Kerbl B., 2022, P EUR, P53
   Khoury J., 2019, GPU ZEN 2 ADV RENDER, P3
   Kidner DB, 2003, INT J REMOTE SENS, V24, P2981, DOI 10.1080/0143116031000086835
   Lee ES, 2016, J SUPERCOMPUT, V72, P2579, DOI 10.1007/s11227-015-1522-9
   Lee H., 2013, P SIGGRAPH AS POST
   Li X, 2016, SCI CHINA MATH, V59, P617, DOI 10.1007/s11425-015-5063-8
   Livny Y, 2008, VISUAL COMPUT, V24, P139, DOI 10.1007/s00371-007-0180-1
   Löffler F, 2009, WSCG 2009, COMMUNICATION PAPERS PROCEEDINGS, P47
   Losasso F, 2004, ACM T GRAPHIC, V23, P769, DOI 10.1145/1015706.1015799
   Luo JX, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P226
   Pajarola R, 2007, VISUAL COMPUT, V23, P583, DOI [10.1007/s00371-007-0163-2, 10.1007/S00371-007-0163-2]
   Ripolles O, 2012, COMPUT GEOSCI-UK, V41, P147, DOI 10.1016/j.cageo.2011.08.025
   Santerre B, 2020, 2020 NICOGRAPH INTERNATIONAL, NICOINT, P86, DOI 10.1109/NicoInt50878.2020.00025
   Tatarchuk N., 2009, CISC VIS NETW IND GL
   Tevs A, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P183
   WELSH DJA, 1967, COMPUT J, V10, P85, DOI 10.1093/comjnl/10.1.85
NR 34
TC 1
Z9 1
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3888
EP 3899
DI 10.1109/TVCG.2022.3173081
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300012
PM 35522629
DA 2024-11-06
ER

PT J
AU Spittle, B
   Frutos-Pascual, M
   Creed, C
   Williams, I
AF Spittle, Becky
   Frutos-Pascual, Maite
   Creed, Chris
   Williams, Ian
TI A Review of Interaction Techniques for Immersive Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Augmented reality; virtual reality; HCI; interaction; input; tasks;
   usability; multimodal; immersive
ID SELECTION TECHNIQUES; OBJECT MANIPULATION; GESTURE; HAND; USABILITY;
   SPEECH
AB The recent proliferation of immersive technology has led to the rapid adoption of consumer-ready hardware for Augmented Reality (AR) and Virtual Reality (VR). While this increase has resulted in a variety of platforms that can offer a richer interactive experience, the advances in technology bring more variability in display types, interaction sensors and use cases. This provides a spectrum of device-specific interaction possibilities, with each offering a tailor-made solution for delivering immersive experiences to users, but often with an inherent lack of standardisation across devices and applications. To address this, a systematic review and an evaluation of explicit, task-based interaction methods in immersive environments are presented in this paper. A corpus of papers published between 2013 and 2020 is reviewed to thoroughly explore state-of-the-art user studies, which investigate input methods and their implementation for immersive interaction tasks (pointing, selection, translation, rotation, scale, viewport, menu-based and abstract). Focus is given to how input methods have been applied within the spectrum of immersive technology (AR, VR, XR). This is achieved by categorising findings based on display type, input method, study type, use case and task. Results illustrate key trends surrounding the benefits and limitations of each interaction technique and highlight the gaps in current research. The review provides a foundation for understanding the current and future directions for interaction studies in immersive environments, which, at this pivotal point in XR technology adoption, provides routes forward for achieving more valuable, intuitive and natural interactive experiences.
C1 [Spittle, Becky; Frutos-Pascual, Maite; Creed, Chris; Williams, Ian] Birmingham City Univ, Sch Comp & Digital Technol, DMT Lab, Birmingham B5 5JU, England.
C3 Birmingham City University
RP Spittle, B (corresponding author), Birmingham City Univ, Sch Comp & Digital Technol, DMT Lab, Birmingham B5 5JU, England.
EM becky.spittle@bcu.ac.uk; maite.frutos@bcu.ac.uk; chris.creed@bcu.ac.uk;
   ian.williams@bcu.ac.uk
OI Spittle, Becky/0000-0002-4392-0531; Creed, Chris/0000-0003-4146-6272;
   Williams, Ian/0000-0002-0651-0963; Frutos-Pascual,
   Maite/0000-0001-5861-1259
CR Alallah F, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281541
   Aliprantis John, 2019, P 1 INT WORKSH VIS P
   [Anonymous], 2014, PROC SIGGRAPH ASIA M
   Arora R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P463, DOI 10.1145/3332165.3347942
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bai Z, 2012, INTERACT COMPUT, V24, P450, DOI 10.1016/j.intcom.2012.07.004
   Bailly C, 2019, LECT NOTES COMPUT SC, V11749, P395, DOI 10.1007/978-3-030-29390-1_22
   Bazzaza MW, 2014, 2014 INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT AND LEARNING (TALE), P495, DOI 10.1109/TALE.2014.7062576
   Becker V, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311853
   Belkacem I, 2019, Arxiv, DOI arXiv:1905.05810
   Bhowmick Shimmila, 2020, IndiaHCI 2020: Proceedings of the 11th Indian Conference on Human-Computer Interaction, P12, DOI 10.1145/3429290.3429292
   Blaga AD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376554
   Bothen S., 2018, P 13 INT C FDN DIGIT, P1, DOI [10.1145/3235765.3235772, DOI 10.1145/3235765.3235772]
   Brancati N, 2017, PERS UBIQUIT COMPUT, V21, P203, DOI 10.1007/s00779-016-0987-8
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Chan E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3403, DOI 10.1145/2858036.2858589
   Cheema N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376701
   Chen D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P285, DOI [10.1109/VR46266.2020.1581293094740, 10.1109/VR46266.2020.00-56]
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Chittaro L, 2019, INT J HUM-COMPUT INT, V35, P1501, DOI 10.1080/10447318.2018.1541546
   Dalim CSC, 2020, INT J HUM-COMPUT ST, V134, P44, DOI 10.1016/j.ijhcs.2019.10.002
   Dalim CSC, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P82, DOI [10.1109/ISMAR-Adjunct.2016.39, 10.1109/ISMAR-Adjunct.2016.0046]
   Dey A, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P49, DOI [10.1109/ISMAR-Adjunct.2016.0036, 10.1109/ISMAR-Adjunct.2016.29]
   Dong Z, 2020, PROC INT CONF SOFTW, P481, DOI 10.1145/3377811.3380402
   Esteves A, 2020, INT J HUM-COMPUT ST, V139, DOI 10.1016/j.ijhcs.2020.102414
   Esteves A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P167, DOI 10.1145/3126594.3126616
   Fadzli Fazliaty Edora, 2019, 2019 IEEE 7th Conference on Systems, Process and Control (ICSPC), P242, DOI 10.1109/ICSPC47137.2019.9067992
   Flavián C, 2019, J BUS RES, V100, P547, DOI 10.1016/j.jbusres.2018.10.050
   Franco J, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3368416
   Frank JA, 2016, IEEE ROMAN, P302, DOI 10.1109/ROMAN.2016.7745146
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Ganapathi Priya, 2018, P 20 INT C HUM COMP, P166
   Ghosh D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376173
   Goh ES, 2019, IEEE ACCESS, V7, P40581, DOI 10.1109/ACCESS.2019.2906394
   Hart S.G., 1986, NASA TASK LOAD INDEX, V1
   Henderson J., 2020, P 22 INT C HUM COMP, P1
   Henrikson R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376489
   Hertel J, 2021, INT SYM MIX AUGMENT, P431, DOI 10.1109/ISMAR52148.2021.00060
   Jackson Philip, 2020, Procedia Computer Science, P209, DOI 10.1016/j.procs.2020.02.138
   Jing Qian, 2020, IMX '20: ACM International Conference on Interactive Media Experiences, P74, DOI 10.1145/3391614.3393648
   Kang HJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P275, DOI [10.1109/VR46266.2020.00047, 10.1109/VR46266.2020.00-57]
   Kim M., 2016, MULTIMEDIA TOOLS APP, V75, p16 529
   Krupke D, 2018, IEEE INT C INT ROBOT, P5003, DOI 10.1109/IROS.2018.8594043
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Lamberti F, 2017, IEEE T HUM-MACH SYST, V47, P152, DOI 10.1109/THMS.2016.2573830
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Lu XS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1060, DOI [10.1109/VR.2019.8797901, 10.1109/vr.2019.8797901]
   Manuri F, 2015, PROCEEDINGS OF THE 2015 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT TECHNOLOGIES FOR INTERACTIVE ENTERTAINMENT, P37, DOI 10.4108/icst.intetain.2015.259629
   Marques Bernardo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427324
   Mayer S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376479
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P237, DOI 10.1145/2993369.2993388
   Mohan P., 2019, PROC 17 INT C VIRTUA, P1
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI DOI 10.1145/2591689
   Mossel A., 2013, Proc. Virtual Real. Int. Conf. Laval Virtual - VRIC '13, P1, DOI DOI 10.1145/2466816.2466829
   Muller Florian, 2020, P 2020 CHI C HUMAN F, P1
   Munsinger B., 2019, P 11 INT C VIRT WORL, P1
   Nazri N. I. A. M., 2015, PROC ASIA PACIFIC HC, P46
   Nizam SS Muhammad., 2018, Int. J. Adv. Sci. Eng. Inf. Technol, V8, P1460
   Özacar K, 2017, INTERACT COMPUT, V29, P579, DOI 10.1093/iwc/iww035
   Perea P., 2020, PROC INT C ADV VIS I, P1
   Pereira A, 2017, IEEE ROMAN, P764, DOI 10.1109/ROMAN.2017.8172389
   Pham T, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P227, DOI 10.1145/3196709.3196719
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Plasson C., 2020, P INT C ADV VIS INT, P1
   Plasson C, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P409, DOI 10.1145/3343055.3360760
   Pourmemar M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365693
   Prilla M., 2019, AIS T HUM COMPUT INT, V11, P157
   Pringle A, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P389, DOI 10.1145/3316782.3322752
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Rao N, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P427, DOI [10.1109/VRW50115.2020.00091, 10.1109/VRW50115.2020.0-185]
   Rutten I, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376668
   Sadri S, 2019, INT SYM MIX AUGMENT, P93, DOI 10.1109/ISMAR.2019.00-21
   Samini A, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P121, DOI 10.1145/2993369.2993380
   Satriadi KA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P593, DOI [10.1109/vr.2019.8798340, 10.1109/VR.2019.8798340]
   Schoonenboom J, 2017, KOLNER Z SOZIOL SOZ, V69, P107, DOI 10.1007/s11577-017-0454-1
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Su GE, 2020, INT J HUM-COMPUT ST, V141, DOI 10.1016/j.ijhcs.2020.102433
   Tanikawa T, 2015, 12TH ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY CONFERENCE (ACE15), DOI 10.1145/2832932.2832956
   Tung YC, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3327, DOI 10.1145/2702123.2702214
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Uva AE, 2019, IEEE T HUM-MACH SYST, V49, P421, DOI 10.1109/THMS.2019.2919719
   Väyrynen J, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P499, DOI 10.1145/3282894.3289745
   Villarreal-Narvaez S, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P855, DOI 10.1145/3357236.3395511
   Waldow K., 2018, P 24 ACM S VIRT REAL, P1
   Wang ZM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P165, DOI [10.1109/ISMAR-Adjunct51615.2020.00052, 10.1109/BDEIM52318.2020.00045]
   Whitlock M., 2018, P IEEE C VIRT REAL 3, P42
   Williams Adam S., 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427330
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Wolf E, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P195, DOI 10.1145/3340555.3353724
   Xu W, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P204, DOI [10.1109/VR46266.2020.1581268453415, 10.1109/VR46266.2020.00-65]
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Ye H, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392404
   Yin JB, 2019, IEEE ACCESS, V7, P17663, DOI 10.1109/ACCESS.2019.2895219
   Yu DF, 2019, INT SYM MIX AUGMENT, P103, DOI 10.1109/ISMAR.2019.00-20
   Zhao J, 2021, POST-COMMUNIST ECON, V33, P379, DOI 10.1080/14631377.2020.1745560
   Zhu FY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376233
NR 101
TC 19
Z9 20
U1 14
U2 78
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3900
EP 3921
DI 10.1109/TVCG.2022.3174805
PG 22
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300013
PM 35552136
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Qiao, XT
   Cao, Y
   Lau, RWH
AF Qiao, Xiaotian
   Cao, Ying
   Lau, Rynson W. H.
TI Design Order Guided Visual Note Layout Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual note; design order; layout optimization
ID OVERLAP; VISUALIZATION
AB With the goal of making contents easy to understand, memorize and share, a clear and easy-to-follow layout is important for visual notes. Unfortunately, since visual notes are often taken by the designers in real time while watching a video or listening to a presentation, the contents are usually not carefully structured, resulting in layouts that may be difficult for others to follow. In this article, we address this problem by proposing a novel approach to automatically optimize the layouts of visual notes. Our approach predicts the design order of a visual note and then warps the contents along the predicted design order such that the visual note can be easier to follow and understand. At the core of our approach is a learning-based framework to reason about the element-wise design orders of visual notes. In particular, we first propose a hierarchical LSTM-based architecture to predict a grid-based design order of the visual note, based on the graphical and textual information. We then derive the element-wise order from the grid-based prediction. Such an idea allows our network to be weakly-supervised, i.e., making it possible to predict dense grid-based orders from visual notes with only coarse annotations. We evaluate the effectiveness of our approach on visual notes with diverse content densities and layouts. The results show that our network can predict plausible design orders for various types of visual notes and our approach can effectively optimize their layouts in order for them to be easier to follow.
C1 [Qiao, Xiaotian] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
   [Cao, Ying; Lau, Rynson W. H.] City Univ Hong Kong, Hong Kong, Peoples R China.
C3 Xidian University; City University of Hong Kong
RP Cao, Y; Lau, RWH (corresponding author), City Univ Hong Kong, Hong Kong, Peoples R China.
EM qiaoxt1992@gmail.com; caoying59@gmail.com; rynson.lau@cityu.edu.hk
RI Qiao, Xiaotian/ABB-7324-2022
OI LAU, Rynson W H/0000-0002-8957-8129; Qiao, Xiaotian/0000-0002-5351-8335
FU RGC of Hong Kong [11205620]
FX & nbsp;This work was supported in part by a General Research Fund from
   RGC of Hong Kong under Grant 11205620.
CR Arroyo DM, 2021, PROC CVPR IEEE, P13637, DOI 10.1109/CVPR46437.2021.01343
   Baskinger Mark, 2008, Interactions, V15, P28, DOI 10.1145/1340961.1340969
   Boccignone G, 2004, PHYSICA A, V331, P207, DOI 10.1016/j.physa.2003.09.011
   Bresciani A., 2013, USE PEN AND PAPER WI
   Brockmann D, 2000, NEUROCOMPUTING, V32, P643, DOI 10.1016/S0925-2312(00)00227-7
   Lipton ZC, 2015, Arxiv, DOI arXiv:1506.00019
   Cao Y, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601183
   Cao Y, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366160
   Carlton E., 2016, SKETCHNOTE BASICS LA
   Carrizosa E, 2019, OMEGA-INT J MANAGE S, V86, P125, DOI 10.1016/j.omega.2018.07.008
   Chen ZZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P642
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dimeo R., 2015, SKETCHNOTING SCI TAL
   Dwyer T, 2006, LECT NOTES COMPUT SC, V3843, P153
   Eisner W., 2008, COMICS SEQUENTIAL AR
   Gange G, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P23
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Gomez-Nieto E, 2016, IEEE T VIS COMPUT GR, V22, P1223, DOI 10.1109/TVCG.2015.2489660
   Gomez-Nieto E, 2014, IEEE T VIS COMPUT GR, V20, P457, DOI 10.1109/TVCG.2013.242
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2014, Arxiv, DOI [arXiv:1308.0850, 10.48550/arXiv.1308.0850]
   Gupta K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P984, DOI 10.1109/ICCV48922.2021.00104
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.2307/2334940
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heminghous J., 2006, Symposium on Applied Perception in Graphics and Visualization, V1, P152, DOI DOI 10.1145/1140491.1140529
   Hockley WE, 2008, MEM COGNITION, V36, P1351, DOI 10.3758/MC.36.7.1351
   Hsin-Ying Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P491, DOI 10.1007/978-3-030-58580-8_29
   Hurst N, 2009, DOCENG'09: PROCEEDINGS OF THE 2009 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P99
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jacobs C, 2003, ACM T GRAPHIC, V22, P838, DOI 10.1145/882262.882353
   Jiang M, 2016, IEEE T NEUR NET LEAR, V27, P1241, DOI 10.1109/TNNLS.2015.2496306
   Kittle B., 2015, DESIGN PRINCIPLE 3 W
   Lai A., 2016, SKETCHNOTING INTRO V
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li JN, 2021, IEEE T VIS COMPUT GR, V27, P4039, DOI 10.1109/TVCG.2020.2999335
   Li JN, 2021, IEEE T PATTERN ANAL, V43, P2388, DOI 10.1109/TPAMI.2019.2963663
   Lindberg O., 2018, M LEWIS POWER SKETCH
   Liu HY, 2013, IEEE I CONF COMP VIS, P3232, DOI 10.1109/ICCV.2013.401
   Liu XT, 2018, COMPUT GRAPH FORUM, V37, P7, DOI 10.1111/cgf.12526
   Malamed C., 2009, Visual Language for Designers: Principles for creating graphics that people understand
   Marcilio WE, 2019, INFORM VISUAL, V18, P426, DOI 10.1177/1473871619845093
   McCloud S., 2006, Making Comics: Storytelling Secrets of Comics, Manga, and Graphic Novels
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mikolov I., 2013, P ADV NEURAL INFORM, V26, P1
   Neill D., 2012, SKETCHNOTES PREFACE
   Nielsen J., 2006, F SHAPED PATTERN REA
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   PAIVIO A, 1991, CAN J PSYCHOL, V45, P255, DOI 10.1037/h0084295
   Pang XF, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982422
   Pascanu R., 2013, P 30 INT C MACH LEAR, P1310, DOI DOI 10.48550/ARXIV.1211.5063
   Rohde M., 2013, SKETCHNOTE HDB ILLUS
   Simonyan K., 2015, P INT C LEARN REPR I, P1
   Siris A, 2020, PROC CVPR IEEE, P12130, DOI 10.1109/CVPR42600.2020.01215
   Strobelt H, 2012, COMPUT GRAPH FORUM, V31, P1135, DOI 10.1111/j.1467-8659.2012.03106.x
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang W, 2011, PROC CVPR IEEE, P441, DOI 10.1109/CVPR.2011.5995423
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Wu YC, 2011, COMPUT GRAPH FORUM, V30, P741, DOI 10.1111/j.1467-8659.2011.01923.x
   Xia C, 2020, IEEE ACCESS, V8, P15598, DOI 10.1109/ACCESS.2020.2966628
   Xia C, 2019, IEEE T IMAGE PROCESS, V28, P3502, DOI 10.1109/TIP.2019.2897966
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yoghourdjian V, 2016, IEEE T VIS COMPUT GR, V22, P339, DOI 10.1109/TVCG.2015.2467251
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 66
TC 1
Z9 1
U1 2
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3922
EP 3936
DI 10.1109/TVCG.2022.3171839
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300014
PM 35503828
DA 2024-11-06
ER

PT J
AU Savvides, R
   Henelius, A
   Oikarinen, E
   Puolamaki, K
AF Savvides, Rafael
   Henelius, Andreas
   Oikarinen, Emilia
   Puolamaki, Kai
TI Visual Data Exploration as a Statistical Testing Procedure: Within-View
   and Between-View Multiple Comparisons
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information visualization; interactive data exploration and discovery;
   statistical testing
ID INFERENCE; METRICS
AB A fundamental problem in visual data exploration concerns whether observed patterns are true or merely random noise. This problem is especially pertinent in visual analytics, where the user is presented with a barrage of patterns, without any guarantees of their statistical validity. Recently this problem has been formulated in terms of statistical testing and the multiple comparisons problem. In this paper, we identify two levels of multiple comparisons problems in visualization: the within-view and the between-view problem. We develop a statistical testing procedure for interactive data exploration that controls the family-wise error rate on both levels. The procedure enables the user to determine the compatibility of their assumptions about the data with visually observed patterns. We present use-cases where we visualize and evaluate patterns in real-world data.
C1 [Savvides, Rafael; Henelius, Andreas; Oikarinen, Emilia; Puolamaki, Kai] Univ Helsinki, Helsinki, Finland.
C3 University of Helsinki
RP Savvides, R (corresponding author), Univ Helsinki, Helsinki, Finland.
EM rafael.savvides@helsinki.fi; andreas.henelius@op.fi;
   emilia.oikarinen@helsinki.fi; kai.puolamaki@helsinki.fi
RI Puolamaki, Kai/C-9016-2017
OI Puolamaki, Kai/0000-0003-1819-1047
FU Academy of Finland [326280, 326339]; Doctoral Programme in Computer
   Science at University of Helsinki
FX The authors wish to thank the Academy of Finland (decisions 326280 and
   326339), and the Doctoral Programme in Computer Science at University of
   Helsinki, for financial support
CR Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Behrisch M, 2017, IEEE T VIS COMPUT GR, V23, P31, DOI 10.1109/TVCG.2016.2598467
   Boley Mario, 2013, P ACM SIGKDD WORKSH, P27
   Bolte F., 2020, FDN DATA VISUALIZATI, P39
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Dal Maso M, 2005, BOREAL ENVIRON RES, V10, P323
   Dasgupta A, 2010, IEEE T VIS COMPUT GR, V16, P1017, DOI 10.1109/TVCG.2010.184
   De Vito S, 2008, SENSOR ACTUAT B-CHEM, V129, P750, DOI 10.1016/j.snb.2007.09.060
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dudoit S, 2003, STAT SCI, V18, P71, DOI 10.1214/ss/1056397487
   Foster DP, 2008, J R STAT SOC B, V70, P429, DOI 10.1111/j.1467-9868.2007.00643.x
   Ge YC, 2003, TEST-SPAIN, V12, P1, DOI 10.1007/BF02595811
   Gelman A, 2004, J COMPUT GRAPH STAT, V13, P755, DOI 10.1198/106186004X11435
   Gelman A, 2003, INT STAT REV, V71, P369
   Gove R, 2019, IEEE INT CON INF VIS, P201, DOI 10.1109/IV.2019.00042
   Hämäläinen W, 2019, DATA MIN KNOWL DISC, V33, P325, DOI 10.1007/s10618-018-0590-x
   Hullman J., 2018, MEDIUM
   Hullman J., 2021, Harvard Data Science Review, V3, P3
   Junninen H, 2009, BOREAL ENVIRON RES, V14, P447
   Lehmann DJ, 2015, COMPUT GRAPH FORUM, V34, P291, DOI 10.1111/cgf.12641
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Nguyen B. D. Q., 2020, EUROVIS WORKSH VIS A, P49
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133
   Pu XY, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P37
   Puolamäki K, 2021, J MACH LEARN RES, V22
   Rafi Z, 2020, BMC MED RES METHODOL, V20, DOI 10.1186/s12874-020-01105-9
   Ramdas A, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3211, DOI 10.1145/3292500.3332282
   Savvides R, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1509, DOI 10.1145/3292500.3330994
   Schneidewind J, 2006, IEEE CONF VIS ANAL, P199
   Schreiber T, 2000, PHYSICA D, V142, P346, DOI 10.1016/S0167-2789(00)00043-9
   Tatu A, 2011, IEEE T VIS COMPUT GR, V17, P584, DOI 10.1109/TVCG.2010.242
   TUKEY JW, 1972, Q APPL MATH, V30, P51, DOI 10.1090/qam/99740
   Unwin A., 2002, Pattern Detection and Discovery. ESF Exploratory Workshop Proceedings (Lecture Notes in Artificial Intelligence Vol. 2447), P63
   Vanderplas S, 2020, ANNU REV STAT APPL, V7, P61, DOI 10.1146/annurev-statistics-031219-041252
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Walls L. A., 2019, PROC CHI C HUM FACTO, P1
   Wang YH, 2020, IEEE T VIS COMPUT GR, V26, P759, DOI 10.1109/TVCG.2019.2934796
   Westfall P. H., 1993, Resampling-based multiple testing: Examples and methods for p-value adjustment
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Zgraggen E, 2017, IEEE T VIS COMPUT GR, V23, P1977, DOI 10.1109/TVCG.2016.2607714
   Zgraggen Emanuel, 2018, P 2018 CHI C HUM FAC, P1, DOI [DOI 10.1145/3173574.3174053, 10.1145/3173574.3174053]
   Zhao ZG, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P527, DOI 10.1145/3035918.3064019
NR 45
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3937
EP 3948
DI 10.1109/TVCG.2022.3175532
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300015
PM 35588414
OA hybrid
DA 2024-11-06
ER

PT J
AU Kusumastuti, SA
   Pollard, KA
   Oiknine, AH
   Dalangin, B
   Raber, TR
   Files, BT
AF Kusumastuti, Sarah A.
   Pollard, Kimberly A.
   Oiknine, Ashley H.
   Dalangin, Bianca
   Raber, Tiffany R.
   Files, Benjamin T.
TI Practice Improves Performance of a 2D Uncertainty Integration Task
   Within and Across Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision making; training; visualization; uncertainty
ID LITERACY
AB Information uncertainty is ubiquitous in everyday life, including in domains as diverse as weather forecasts, investments, and health risks. Knowing how to interpret and integrate this uncertain information is vital for making good decisions, but this can be difficult for experts and novices alike. In this study, we examine whether brief, focused practice can improve people's ability to understand and integrate bivariate Gaussian uncertainty visualized via ensemble displays, summary displays, and distributional displays, and we examine whether this is influenced by the complexity of the displayed information. In two experiments (N=118 and 56), decision making was faster and more accurate after practice relative to before practice. Furthermore, the performance improvements transferred to use of display types that were not practiced. This suggests that practice with feedback may improve underlying skills in probabilistic reasoning and provides a promising approach to improve people's decision making under uncertainty.
C1 [Kusumastuti, Sarah A.] Univ Southern Calif, Dept Psychol, Los Angeles, CA 90089 USA.
   [Pollard, Kimberly A.; Raber, Tiffany R.; Files, Benjamin T.] DEVCOM Army Res Lab, Los Angeles, CA 90094 USA.
   [Oiknine, Ashley H.; Dalangin, Bianca] DCS Corp, Los Angeles, CA 90094 USA.
C3 University of Southern California
RP Files, BT (corresponding author), DEVCOM Army Res Lab, Los Angeles, CA 90094 USA.
EM kusumast@usc.edu; kimberly.a.pollard.civ@army.mil; aoiknine@dcscorp.com;
   bdalangin@dcscorp.com; benjamin.t.files.civ@army.mil;
   tiffany.raber.civ@army.mil
OI Kusumastuti, Sarah AFR/0000-0001-6362-218X; Pollard,
   Kimberly/0000-0002-5849-1987; Files, Benjamin/0000-0002-1141-7886
FU DEVCOM Army Research Laboratory's Human Sciences Campaign
FX This work was supported by the DEVCOM Army Research Laboratory's Human
   Sciences Campaign.
CR Belia S, 2005, PSYCHOL METHODS, V10, P389, DOI 10.1037/1082-989X.10.4.389
   Bertin J., 1983, Semiology of Graphics
   Boone AP, 2018, J EXP PSYCHOL-APPL, V24, P275, DOI 10.1037/xap0000166
   Carvalho SB, 2011, BIOL CONSERV, V144, P2020, DOI 10.1016/j.biocon.2011.04.024
   Cokely ET, 2012, JUDGM DECIS MAK, V7, P25
   de Moel H, 2015, MITIG ADAPT STRAT GL, V20, P865, DOI 10.1007/s11027-015-9654-z
   Dent B. D., 1999, Cartography: Thematic Map Design
   Emery KJ, 2019, CURR OPIN BEHAV SCI, V30, P28, DOI 10.1016/j.cobeha.2019.05.002
   Files BT, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00726
   Fiore SM, 2019, ADV INTELL SYST, V794, P141, DOI 10.1007/978-3-319-94947-5_14
   Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Greis M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174079
   Higgins ET, 2001, EUR J SOC PSYCHOL, V31, P3, DOI 10.1002/ejsp.27
   Hoekstra R, 2014, PSYCHON B REV, V21, P1157, DOI 10.3758/s13423-013-0572-3
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Hubert M, 2008, COMPUT STAT DATA AN, V52, P5186, DOI 10.1016/j.csda.2007.11.008
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Jihye Song, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P1654, DOI 10.1177/1071181319631520
   John O. P., HDB PERSONALITY THEO, P114
   John Oliver P., 1991, The Big Five Inventory: Versions 4a and 54
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Korporaal M, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00032
   Kosslyn S.M., 2006, GRAPH DESIGN EYE MIN, DOI 10.1093/acprof:oso/9780195311846.001.0001
   Li QS, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-57204-1
   Liu L, 2019, IEEE T VIS COMPUT GR, V25, P882, DOI 10.1109/TVCG.2018.2865193
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   McKenzie G, 2016, INT J GEOGR INF SCI, V30, P221, DOI 10.1080/13658816.2015.1082566
   Metcalfe JS, 2015, LECT NOTES ARTIF INT, V9183, P63, DOI 10.1007/978-3-319-20816-9_7
   Mishra AA, 2020, PHYS FLUIDS, V32, DOI 10.1063/5.0020858
   Newman GE, 2012, PSYCHON B REV, V19, P601, DOI 10.3758/s13423-012-0247-5
   Okan Y, 2015, J EXP PSYCHOL-APPL, V21, P178, DOI 10.1037/xap0000045
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Padilla LM, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0076-1
   Rensink Ronald A., 2014, HDB HUMAN CENTRIC VI, P147, DOI [DOI 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485- 2_6]
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Ruginski IT, 2016, SPAT COGN COMPUT, V16, P154, DOI 10.1080/13875868.2015.1137577
   RYAN RM, 1982, J PERS SOC PSYCHOL, V43, P450, DOI 10.1037/0022-3514.43.3.450
   Stan Development Team, 2019, Stan Modeling Language Users Guide and Reference Manual, p2.29
   Tulloch VJ, 2013, BIOL CONSERV, V162, P41, DOI 10.1016/j.biocon.2013.03.003
   van der Bles AM, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181870
NR 42
TC 1
Z9 1
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3949
EP 3960
DI 10.1109/TVCG.2022.3173889
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300016
PM 35536797
DA 2024-11-06
ER

PT J
AU Cross, J
   Boag-Hodgson, C
   Ryley, T
   Mavin, TJ
   Potter, LE
AF Cross, Jamie
   Boag-Hodgson, Christine
   Ryley, Tim
   Mavin, Timothy J.
   Potter, Leigh Ellen
TI Using Extended Reality in Flight Simulators: A Literature Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Aerospace; artificial; augmented; extended and virtual realities;
   simulation; training
ID VIRTUAL-REALITY
AB Extended reality has long been utilized in the games industry and is emergent for pilot training in the military and commercial airline sectors. This paper follows the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to present a systematic quantitative literature review (SQLR) on the use of extended reality in flight simulators. It also encompasses recent studies of teaching and learning in immersive, virtual environments in non-aviation disciplines. The review identified 39 papers spanning all areas of the virtuality continuum across academic, commercial, and military aviation sectors, as well as engineering and medicine. The SQLR found that extended reality in flight simulators is being introduced in the commercial and military aviation sectors. However, within academia, hardware constraints have hindered the ability to provide positive empirical evidence of simulator effectiveness. While virtual reality may not replace traditional flight simulators in the near future, the technology is available to supplement classroom training activities and some aspects of simulator procedure training with promising cognitive learning outcomes. However, its usefulness as a mechanism of skills transfer to the real world has not been evaluated, highlighting numerous research opportunities.
C1 [Cross, Jamie; Boag-Hodgson, Christine; Ryley, Tim] Griffith Univ, Sch Engn & Built Environm Aviat, Nathan, Qld 4111, Australia.
   [Mavin, Timothy J.] Griffith Inst Educ Res, Nathan, Qld 4111, Australia.
   [Potter, Leigh Ellen] Griffith Univ, Sch Informat & Commun Technol, Nathan, Qld 4111, Australia.
   [Potter, Leigh Ellen] Griffith Univ, IDEA Lab Innovat Design & Emerging Applicat, Nathan, Qld 4111, Australia.
C3 Griffith University; Griffith University; Griffith University
RP Cross, J (corresponding author), Griffith Univ, Sch Engn & Built Environm Aviat, Nathan, Qld 4111, Australia.
EM jamie.cross@griffith.edu.au; c.boag-hodgson@griffith.edu.au;
   t.ryley@griffith.edu.au; t.mavin@griffith.edu.au;
   l.potter@griffith.edu.au
RI Ryley, Tim/A-2784-2010; Boag-Hodgson, Christine/S-9977-2019; Potter,
   Leigh Ellen/D-4626-2019
OI Ryley, Tim/0000-0003-0878-5546; Potter, Leigh Ellen/0000-0003-3747-1335;
   Cross, Jamie/0000-0001-7768-1535; Boag-Hodgson,
   Christine/0000-0002-8361-1151
CR Air France, 2019, VIRT REAL BUS EXP
   Airbus, 2019, AIRB BRINGS COCKP YO
   Aslandere T., 2015, 2015 IEEE Aerospace Conference, P1, DOI DOI 10.1109/AERO.2015.7118876
   Aslandere Turgay., 2014, Virtuelle und Erweiterte Realitat, P1
   Bailey RE, 2004, PROC SPIE, V5424, P98, DOI 10.1117/12.554462
   Bauer M., 2008, P AIAA MOD SIM TECHN, P1, DOI [10.2514/6.2008-7030, DOI 10.2514/6.2008-7030]
   Bergstrom J., 2010, Journal of contingencies and crisis management, V18, P220, DOI DOI 10.1111/J.1468.5973.2010.00618.X
   Bhattacharjee D, 2018, COMPUT ELECTR ENG, V65, P236, DOI 10.1016/j.compeleceng.2017.08.023
   Boeing, 2017, FLYING VIRT SOL
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Carretta T R., 1998, Transfer of Training Effectiveness in Flight Simulation: 1986 to 1997, DOI DOI 10.21236/ADA362818
   Comerford D, 2007, ERGON DES, V15, P8, DOI 10.1177/106480460701500105
   Dahlstrom N, 2009, THEOR ISS ERGON SCI, V10, P305, DOI 10.1080/14639220802368864
   Dahlström N, 2008, AVIATION, V12, P22, DOI 10.3846/1648-7788.2008.12.28-32
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Dehn LB, 2018, COMPUT HUM BEHAV, V79, P40, DOI 10.1016/j.chb.2017.10.019
   Dorr K., 2001, VIRTUAL COCKPIT SIMU
   Dreyer D, 2014, P INT C HUM COMP INT, P1
   European Aviation Safety Agency (EASA), 2018, Certification Specifications and Acceptable Means of Compliance for Large Aeroplanes CS-25, Appendices C and O, Amendment 22
   FAA, 2020, FLIGHT SIM TRAIN 60
   FlightGlobal, 2020, KLM CIT SEEKS EASA B
   Foster PP, 2015, FRONT AGING NEUROSCI, V7, DOI 10.3389/fnagi.2015.00117
   Fussell SG, 2020, INT J AVIAT AERONAUT, V7
   Goutal L., 2000, ERGONOMIC SOFTWARE T, P173
   Halsmer D. M., 2018, P ASEE ANN C EXP
   HART S G, 1988, P139
   Hillebrand A., 2013, PROC HUM FACTORS ERG, P2047, DOI [10.1177/1541931213571457, DOI 10.1177/1541931213571457]
   Hoyle C., 2019, FLIGHT INT, V196, P15
   HP Development Company, 2020, HP REV G2
   HTC Corporation, 2019, HTC VIVE
   Huagen Wan, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P129, DOI 10.1109/ISVRI.2011.5759615
   Hunt X, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P598, DOI 10.1145/3292147.3292225
   Ip HHS, 2018, COMPUT EDUC, V117, P1, DOI 10.1016/j.compedu.2017.09.010
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality
   Lin HC, 2020, THINK SKILLS CREAT, V37, DOI 10.1016/j.tsc.2020.100705
   Losey S., 2018, AIR FORCE IS REVOLUT
   Lufthansa FlyingLab, 2019, DISC INN PROD SERV F
   Macchiarella N.D., 2008, Collegiate Aviation Review, V26, P67, DOI DOI 10.22488/OKSTATE.18.100367
   Macchiarella N.D., 2006, International Journal of Applied Aviation Studies, V6, P299
   Martín-Gutiérrez J, 2015, COMPUT HUM BEHAV, V51, P752, DOI 10.1016/j.chb.2014.11.093
   Mavin TJ, 2010, PROF PRACT-BASED LEA, P268, DOI 10.1007/978-90-481-3939-2_15
   MENA, US CUB ADDR VIRT AUG
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Müller J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1245, DOI 10.1145/2858036.2858043
   Newman J., 2018, NAV AVIATION NEWS, V100, P22
   Newman J., 2016, NAV AVIATION NEWS, V98
   Oberhauser M., 2017, P 32 C EUR ASS AV PS, P565
   Oberhauser M., 2018, Aviation Psychology and Applied Human Factors, DOI [DOI 10.1027/2192-0923/A000134, 10.1027/2192-0923/a000134]
   Oberhauser M., 2017, P 32 C EUR ASS AV PS, P322
   Oberhauser M., 2017, VIRTUAL REALITY FLIG, DOI 10.1007/s10111-017-0421-7
   Oberhauser M, 2016, ADV INTELL SYST, V485, P17, DOI 10.1007/978-3-319-41983-1_2
   Oberhauser M, 2015, LECT NOTES ARTIF INT, V9174, P460, DOI 10.1007/978-3-319-20373-7_44
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pratt & Whitney, 2017, J CIVIL AVIATION MAY
   Rogers R.O., 2010, International Journal of Applied Aviation Studies, V10, P153
   Rolls Royce, 2019, ROLLS ROYC QAT AIRW
   Rustourismnews, 2020, RUSTOURISMNEWS
   Safadel P, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165438
   Schaper MM, 2018, INT J HUM-COMPUT ST, V114, P36, DOI 10.1016/j.ijhcs.2018.01.003
   Shin H, 2015, J PHYS THER SCI, V27, P2999, DOI 10.1589/jpts.27.2999
   Taylor HL, 1999, INT J AVIAT PSYCHOL, V9, P319, DOI 10.1207/s15327108ijap0904_1
   Tran T. H., 2018, 2018 IEEEAIAA 37 DIG, P1, DOI [10.1109/DASC.2018.8569261, DOI 10.1109/DASC.2018.8569261]
   Yavrucuk I., 2009, PROC AIAA MODEL SIMU, P1, DOI [10.2514/6.2009-5832, DOI 10.2514/6.2009-5832]
   Zhao KR, 2011, CHIN CONT DECIS CONF, P4361, DOI 10.1109/CCDC.2011.5968994
NR 64
TC 14
Z9 15
U1 11
U2 28
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3961
EP 3975
DI 10.1109/TVCG.2022.3173921
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300017
PM 35536798
DA 2024-11-06
ER

PT J
AU Chen, RS
   Zhang, FL
   Finnie, S
   Chalmers, A
   Rhee, T
AF Chen, Rongsen
   Zhang, Fang-Lue
   Finnie, Simon
   Chalmers, Andrew
   Rhee, Taehyun
TI Casual 6-DoF: Free-Viewpoint Panorama Using a Handheld 360° Camera
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 6 Degrees-of-freedom; 6-DoF; view synthesis; free-viewpoint images;
   panoramic depth estimation
AB Six degrees-of-freedom (6-DoF) video provides telepresence by enabling users to move around in the captured scene with a wide field of regard. Compared to methods requiring sophisticated camera setups, the image-based rendering method based on photogrammetry can work with images captured with any poses, which is more suitable for casual users. However, existing image based rendering methods are based on perspective images. When used to reconstruct 6-DoF views, it often requires capturing hundreds of images, making data capture a tedious and time-consuming process. In contrast to traditional perspective images, 360 degrees images capture the entire surrounding view in a single shot, thus, providing a faster capturing process for 6-DoF view reconstruction. This article presents a novel method to provide 6-DoF experiences over a wide area using an unstructured collection of 360 degrees panoramas captured by a conventional 360 degrees camera. Our method consists of 360 degrees data capturing, novel depth estimation to produce a high-quality spherical depth panorama, and high-fidelity free-viewpoint generation. We compared our method against state-of-the-art methods, using data captured in various environments. Our method shows better visual quality and robustness in the tested scenes.
C1 [Chen, Rongsen; Finnie, Simon; Chalmers, Andrew; Rhee, Taehyun] Victoria Univ Wellington, Computat Media Innovat Ctr, Wellington 6140, New Zealand.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand.
C3 Victoria University Wellington; Victoria University Wellington
RP Rhee, T (corresponding author), Victoria Univ Wellington, Computat Media Innovat Ctr, Wellington 6140, New Zealand.; Zhang, FL (corresponding author), Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington, New Zealand.
EM rongsen.chen@vuw.ac.nz; fanglue.zhang@vuw.ac.nz; simon.finnie@vuw.ac.nz;
   andrew.chalmers@vuw.ac.nz; taehyun.rhee@vuw.ac.nz
RI Chalmers, Andrew/AAM-5135-2021
OI Rhee, Taehyun/0000-0002-6150-0637
FU Computational Media Innovation Centre, Victoria University of
   Wellington; Tertiary Education Commission in New Zealand through
   Entrepreneurial University Programme
FX This work was supported in part by the Computational Media Innovation
   Centre, Victoria University of Wellington, and in part by the Tertiary
   Education Commission in New Zealand through Entrepreneurial University
   Programme.~
CR Attal B., 2020, ECCV, P441, DOI DOI 10.1007/978-3-030-58452-8_26
   Bansal R, 2016, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2016), P63, DOI 10.1109/SYSMART.2016.7894491
   Bertel T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417770
   Bertel T, 2019, IEEE T VIS COMPUT GR, V25, P1828, DOI 10.1109/TVCG.2019.2898799
   Bonopera Sebastien, 2020, sibr: A System for Image Based Rendering
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Cazals F., 2006, Effective Computational Geometry for Curves and Surfaces, P231, DOI DOI 10.1007/978-3-540-33259-6_6
   Cho H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P880, DOI [10.1109/vr.2019.8798142, 10.1109/VR.2019.8798142]
   Choi I, 2019, IEEE I CONF COMP VIS, P7780, DOI 10.1109/ICCV.2019.00787
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Griwodz C, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P241, DOI 10.1145/3458305.3478443
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Hedman P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130828
   Hedman P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982420
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   Jancosek M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3121, DOI 10.1109/CVPR.2011.5995693
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Koniaris C, 2019, IEEE T VIS COMPUT GR, V25, P1666, DOI 10.1109/TVCG.2018.2818156
   KOSKINEN L, 1991, P SOC PHOTO-OPT INS, V1568, P262, DOI 10.1117/12.46121
   Lipski C, 2014, IEEE T CIRC SYST VID, V24, P942, DOI 10.1109/TCSVT.2014.2302379
   Mei X, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Pozo AP, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356555
   Riegler Gernot, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P623, DOI 10.1007/978-3-030-58529-7_37
   Riegler G, 2021, Arxiv, DOI arXiv:2011.07233
   Sato T, 2010, J VIS COMMUN IMAGE R, V21, P416, DOI 10.1016/j.jvcir.2010.02.006
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Shum H.-Y., 2008, Image-based rendering
   Shum HY, 2000, PROC SPIE, V4067, P2, DOI 10.1117/12.386541
   Thatte J, 2017, 2017 IEEE Visual Communications and Image Processing (VCIP), P1
   Thatte J., 2018, Electronic Imaging, V2018, P352
   Waechter M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2999533
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang NH, 2020, IEEE INT CONF ROBOT, P582, DOI 10.1109/ICRA40945.2020.9196975
   Xu JM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459849
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhou TH, 2018, Arxiv, DOI arXiv:1805.09817
   Zinger S, 2010, J VIS COMMUN IMAGE R, V21, P533, DOI 10.1016/j.jvcir.2010.01.004
   Zioulis N, 2019, INT CONF 3D VISION, P690, DOI 10.1109/3DV.2019.00081
NR 51
TC 5
Z9 6
U1 0
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3976
EP 3988
DI 10.1109/TVCG.2022.3176832
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300018
PM 35605000
DA 2024-11-06
ER

PT J
AU Mori, S
   Schmalstieg, D
   Kalkofen, D
AF Mori, Shohei
   Schmalstieg, Dieter
   Kalkofen, Denis
TI Good Keyframes to Inpaint
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Diminished reality; inpainting; keyframe; good keyframes to inpaint;
   SLAM
ID DIMINISHED REALITY
AB Diminished Reality (DR) propagates pixels from a keyframe to subsequent frames for real-time inpainting. Keyframe selection has a significant impact on the inpainting quality, but untrained users struggle to identify good keyframes. Automatic selection is not straightforward either, since no previous work has formalized or verified what determines a good keyframe. We propose a novel metric to select good keyframes to inpaint. We examine the heuristics adopted in existing DR inpainting approaches and derive multiple simple criteria measurable from SLAM. To combine these criteria, we empirically analyze their effect on the quality using a novel representative test dataset. Our results demonstrate that the combined metric selects RGBD keyframes leading to high-quality inpainting results more often than a baseline approach in both color and depth domains. Also, we confirmed that our approach has a better ranking ability of distinguishing good and bad keyframes. Compared to random selections, our metric selects keyframes that would lead to higher-quality and more stably converging inpainting results. We present three DR examples, automatic keyframe selection, user navigation, and marker hiding.
C1 [Mori, Shohei; Schmalstieg, Dieter; Kalkofen, Denis] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Mori, S (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
EM s.mori.jp@ieee.org; schmalstieg@tugraz.at; kalkofen@icg.tugraz.at
RI Mori, Shohei/AAL-6642-2020
OI Schmalstieg, Dieter/0000-0003-2813-2235; Kalkofen,
   Denis/0000-0002-0359-206X; Mori, Shohei/0000-0003-0540-7312
FU Austrian Science Fund FWF [P33634]; Austrian Science Fund (FWF) [P33634]
   Funding Source: Austrian Science Fund (FWF)
FX This work was supported in part by Austrian Science Fund FWF under Grant
   P33634.
CR [Anonymous], 2009, BMVC
   [Anonymous], 2010, LECT NOTES COMPUT SC
   [Anonymous], 2013, ITE TRANS MEDIA TECH, DOI DOI 10.3169/MTA.1.343
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barnum P, 2009, INT SYM MIX AUGMENT, P111, DOI 10.1109/ISMAR.2009.5336483
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cbangsheng Zhao, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P427, DOI 10.1109/ICPR.1996.546862
   Cosco F, 2013, IEEE T VIS COMPUT GR, V19, P159, DOI 10.1109/TVCG.2012.107
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dhamo H, 2019, PATTERN RECOGN LETT, V125, P333, DOI 10.1016/j.patrec.2019.05.007
   Fujii R, 2020, LECT NOTES COMPUT SC, V12242, P440, DOI 10.1007/978-3-030-58465-8_32
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   Herling J., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P207, DOI 10.1109/ISMAR.2010.5643572
   Herling J, 2014, IEEE T VIS COMPUT GR, V20, P866, DOI 10.1109/TVCG.2014.2298016
   Jarusirisawad Songkran, 2010, Progress in Informatics, P11, DOI 10.2201/NiiPi.2010.7.3
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kawai N, 2017, IEEE T VIS COMPUT GR, V23, P2288, DOI 10.1109/TVCG.2016.2617325
   Kawai N, 2016, IEEE T VIS COMPUT GR, V22, P1236, DOI 10.1109/TVCG.2015.2462368
   Keller M, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P1, DOI 10.1109/3DV.2013.9
   Korkalo O., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P247, DOI 10.1109/ISMAR.2010.5643590
   Li ZW, 2013, INT SYM MIX AUGMENT, P11, DOI 10.1109/ISMAR.2013.6671759
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Mori S, 2020, IEEE T VIS COMPUT GR, V26, P2994, DOI 10.1109/TVCG.2020.3003768
   Mori S, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P1, DOI 10.1109/ISMAR-Adjunct.2018.00020
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Philip J, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190846
   Rameau F, 2016, IEEE T VIS COMPUT GR, V22, P2395, DOI 10.1109/TVCG.2016.2593768
   Sasao H., 2016, ITE TRANS MEDIA TECH, V4, P21
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   Schöps T, 2017, IEEE T VIS COMPUT GR, V23, P2455, DOI 10.1109/TVCG.2017.2734578
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Siltanen Sanni, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P253, DOI 10.1109/ISMAR.2006.297831
   Siltanen S, 2017, VISUAL COMPUT, V33, P193, DOI 10.1007/s00371-015-1174-z
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zokai S, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P217, DOI 10.1109/ISMAR.2003.1240705
NR 38
TC 2
Z9 2
U1 2
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 3989
EP 4000
DI 10.1109/TVCG.2022.3176958
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300019
PM 35605001
DA 2024-11-06
ER

PT J
AU Xu, C
   Qu, W
   Xu, XM
   Liu, XT
AF Xu, Cheng
   Qu, Wei
   Xu, Xuemiao
   Liu, Xueting
TI Multi-Scale Flow-Based Occluding Effect and Content Separation for
   Cartoon Animations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cartoon effect-content separation; cartoon effect removal; optical flow
ID INTRINSIC IMAGE DECOMPOSITION; REMOVAL; MODEL
AB Occluding effects have been frequently used to present weather conditions and environments in cartoon animations, such as raining, snowing, moving leaves, and moving petals. While these effects greatly enrich the visual appeal of the cartoon animations, they may also cause undesired occlusions on the content area, which significantly complicate the analysis and processing of the cartoon animations. In this article, we make the first attempt to separate the occluding effects and content for cartoon animations. The major challenge of this problem is that, unlike natural effects that are realistic and small-sized, the effects of cartoons are usually stylistic and large-sized. Besides, effects in cartoons are manually drawn, so their motions are more unpredictable than realistic effects. To separate occluding effects and content for cartoon animations, we propose to leverage the difference in the motion patterns of the effects and the content, and capture the locations of the effects based on a multi-scale flow-based effect prediction (MFEP) module. A dual-task learning system is designed to extract the effect video and reconstruct the effect-removed content video at the same time. We apply our method on a large number of cartoon videos of different content and effects. Experiments show that our method significantly outperforms the existing methods. We further demonstrate how the separated effects and content facilitate the analysis and processing of cartoon videos through different applications, including segmentation, inpainting, and effect migration.
C1 [Xu, Cheng; Qu, Wei; Xu, Xuemiao] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Xu, Xuemiao] Minist Educ, State Key Lab Subtrop Bldg Sci, Key Lab Big Data & Intelligent Robot, Guangzhou 510006, Peoples R China.
   [Xu, Xuemiao] Guangdong Prov Key Lab Computat Intelligence & Cyb, Guangzhou 510006, Peoples R China.
   [Liu, Xueting] Caritas Inst Higher Educ, Hk, Peoples R China.
C3 South China University of Technology; Saint Francis University Hong Kong
RP Xu, XM (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM cschengxu@gmail.com; vivianquaug@gmail.com; xuemx@scut.edu.cn;
   tliu@cihe.edu.hk
RI Liu, Xueting/AAG-9648-2019; Xu, Cheng/HZL-1279-2023
OI Liu, Xueting/0000-0002-0868-5353; Xu, Cheng/0000-0002-4281-6214
FU Key-Area Research and Development Program of Guangdong Province, China
   [2020B010165004, 2020B010166003, 2018B010107003]; NSFC [61772206,
   U1611461, 61472145]; Research Grants Council of the Hong Kong Special
   Administrative Region, China [UGC/FDS11/E01/21]
FX The work was supported in part by the Key-Area Research and Development
   Program of Guangdong Province, China under Grants 2020B010165004,
   2020B010166003, and 2018B010107003, in part by NSFC under Grants
   61772206, U1611461, and 61472145, and in part by the Research Grants
   Council of the Hong Kong Special Administrative Region, China under
   Grant UGC/FDS11/E01/21.
CR Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326, DOI 10.1167/16.12.326]
   Alayrac JB, 2019, IEEE I CONF COMP VIS, P5733, DOI 10.1109/ICCV.2019.00583
   Alayrac JB, 2019, PROC CVPR IEEE, P2452, DOI 10.1109/CVPR.2019.00256
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Chang YL, 2019, IEEE I CONF COMP VIS, P9065, DOI 10.1109/ICCV.2019.00916
   Chang Y, 2017, IEEE I CONF COMP VIS, P1735, DOI 10.1109/ICCV.2017.191
   Chen J, 2018, PROC CVPR IEEE, P6286, DOI 10.1109/CVPR.2018.00658
   Chen J, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2290595
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Faisal M, 2007, LECT NOTES COMPUT SC, V4633, P513
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Han BJ, 2018, IEEE T IMAGE PROCESS, V27, P4873, DOI 10.1109/TIP.2018.2849880
   HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jeon J, 2014, LECT NOTES COMPUT SC, V8695, P218, DOI 10.1007/978-3-319-10584-0_15
   Jiang TX, 2019, IEEE T IMAGE PROCESS, V28, P2089, DOI 10.1109/TIP.2018.2880512
   Jiang TX, 2017, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2017.301
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2015, IEEE T IMAGE PROCESS, V24, P2658, DOI 10.1109/TIP.2015.2428933
   Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9
   Kingma D.P., 2014, P INT C LEARNING REP
   Lai WS, 2018, LECT NOTES COMPUT SC, V11219, P179, DOI 10.1007/978-3-030-01267-0_11
   Le H, 2019, IEEE I CONF COMP VIS, P8577, DOI 10.1109/ICCV.2019.00867
   Li C, 2020, PROC CVPR IEEE, P3562, DOI 10.1109/CVPR42600.2020.00362
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li MH, 2019, Arxiv, DOI arXiv:1909.06148
   Li MH, 2021, IEEE T IMAGE PROCESS, V30, P2029, DOI 10.1109/TIP.2021.3050313
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liu CT, 2019, Arxiv, DOI arXiv:1908.01683
   Liu JY, 2019, IEEE T IMAGE PROCESS, V28, P699, DOI 10.1109/TIP.2018.2869722
   Liu R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14020, DOI 10.1109/ICCV48922.2021.01378
   Liu XT, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508396
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nandoriya A, 2017, IEEE I CONF COMP VIS, P2430, DOI 10.1109/ICCV.2017.264
   Shelhamer E, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P235, DOI 10.1109/ICCVW.2015.39
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang LM, 2015, Arxiv, DOI arXiv:1507.02159
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J., 2006, MATH IND, P103, DOI DOI 10.1007/978-3-540-34767-55
   Wu XH, 2019, NEUROCOMPUTING, V360, P61, DOI 10.1016/j.neucom.2019.06.011
   Xue TF, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766940
   Yang W., 2016, CoRR, abs/1609.07769
   Yang WH, 2020, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR42600.2020.00179
   Yang WH, 2019, PROC CVPR IEEE, P1661, DOI 10.1109/CVPR.2019.00176
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yanhong Zeng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P528, DOI 10.1007/978-3-030-58517-4_31
   Ye XC, 2015, IEEE T CIRC SYST VID, V25, P1721, DOI 10.1109/TCSVT.2015.2392491
   Zeng Y, 2020, Arxiv, DOI arXiv:2005.11742
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang L, 2012, IEEE T VIS COMPUT GR, V18, P1156, DOI 10.1109/TVCG.2011.111
   Zhang T, 2018, ASIAPAC SIGN INFO PR, P1061, DOI 10.23919/APSIPA.2018.8659604
   Zhu HC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925872
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
NR 63
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 4001
EP 4014
DI 10.1109/TVCG.2022.3174656
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300020
PM 35552137
DA 2024-11-06
ER

PT J
AU Chang, BF
   Sun, GD
   Li, T
   Huang, HC
   Liang, RH
AF Chang, Baofeng
   Sun, Guodao
   Li, Tong
   Huang, Houchao
   Liang, Ronghua
TI MUSE: Visual Analysis of Musical Semantic Sequence
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Musical semantic sequence; semantic analysis; temporal sequence; feature
   extraction
ID VISUALIZATION
AB Visualization has the capacity of converting auditory perceptions of music into visual perceptions, which consequently opens the door to music visualization (e.g., exploring group style transitions and analyzing performance details). Current research either focuses on low-level analysis without constructing and comparing music group characteristics, or concentrates on high-level group analysis without analyzing and exploring detailed information. To fill this gap, integrating the high-level group analysis and low-level details exploration of music, we design a musical semantic sequence visualization analytics prototype system (MUSE) that mainly combines a distribution view and a semantic detail view, assisting analysts in obtaining the group characteristics and detailed interpretation. In the MUSE, we decompose the music into note sequences for modeling and abstracting music into three progressively fine-grained pieces of information (i.e., genres, instruments and notes). The distribution view integrates a new density contour, which considers sequence distance and semantic similarity, and helps analysts quickly identify the distribution features of the music group. The semantic detail view displays the music note sequences and combines the window moving to avoid visual clutter while ensuring the presentation of complete semantic details. To prove the usefulness and effectiveness of MUSE, we perform two case studies based on real-world music MIDI data. In addition, we conduct a quantitative user study and an expert evaluation.
C1 [Chang, Baofeng; Sun, Guodao; Li, Tong; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Huang, Houchao] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University of Technology
RP Sun, GD (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM baofeng.chang@zjut.edu.cn; guodao@zjut.edu.cn; tongli@zjut.edu.cn;
   houchaohuang@zjut.edu.cn; rhliang@zjut.edu.cn
RI Sun, Guodao/AAN-4428-2021
OI Li, Tong/0000-0002-4642-9932; Chang, Baofeng/0000-0002-1028-716X
FU National Key Research and Development Program of China [2020YFB1707700];
   National Natural Science Foundation of China [61972356, 62036009]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFB1707700 and in part by
   the National Natural Science Foundation of China under Grants 61972356
   and 62036009.
CR Albers D, 2011, IEEE T VIS COMPUT GR, V17, P2392, DOI 10.1109/TVCG.2011.232
   Baur D, 2010, IEEE T VIS COMPUT GR, V16, P1119, DOI 10.1109/TVCG.2010.206
   Cantareira GD, 2016, IEEE T MULTIMEDIA, V18, P2238, DOI 10.1109/TMM.2016.2614226
   Chai W., 2001, P 2001 INT C ART INT, P1
   Chan WY, 2010, IEEE T VIS COMPUT GR, V16, P161, DOI 10.1109/TVCG.2009.63
   Cheng ZY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3654
   Coelho D, 2020, IEEE T VIS COMPUT GR, V26, P1650, DOI 10.1109/TVCG.2020.2969056
   Cuthbert M., 2022, MUSIC21 DOCUMENTION
   Cuthbert M.S., 2010, P 11 INT SOC MUS INF, P637, DOI DOI 10.5281/ZENODO.1416114
   Dai HJ, 2017, BIOINFORMATICS, V33, P3575, DOI 10.1093/bioinformatics/btx480
   De Prisco R, 2016, IEEE INT CONF INF VI, P177, DOI 10.1109/IV.2016.56
   Dong HW, 2018, AAAI CONF ARTIF INTE, P34
   Dunteman G., 1989, PRINCIPAL COMPONENTS, DOI 10.4135/9781412985475
   Farbood M. M., 2007, PROC INT COMPUT MUSI, P111
   Fukayama H. N. T. N. S., 2018, P INT COMP MUS C, P250
   Goto M., 2011, Proceedings of the 12th International Society for Music Information Retrieval Conference (ISMIR), P311
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Gove R., 2018, P IEEE S VIS CYB SEC, P1, DOI 10.1109/VIZSEC.2018.8709177
   Grachten M., 2013, P 14 INT SOC MUS INF
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Ho CC, 2005, COMPUT GRAPH FORUM, V24, P537, DOI 10.1111/j.1467-8659.2005.00879.x
   Jaenicke S, 2016, IEEE T VIS COMPUT GR, V22, P200, DOI 10.1109/TVCG.2015.2467620
   Nguyen KT, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P9, DOI 10.1109/BioVis.2013.6664341
   Khulusi R, 2020, COMPUT GRAPH FORUM, V39, P82, DOI 10.1111/cgf.13905
   Knees P, 2013, ACM T MULTIM COMPUT, V10, DOI 10.1145/2542205.2542206
   Kruskal J. B., 1978, Multidimensional Scaling
   Le Q., 2014, INT C MACH LEARN PML, P1188
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Lima H, 2019, IEEE INT CON INF VIS, P352, DOI 10.1109/IV.2019.00066
   Lima HB, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3461835
   Liu CAR, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1336, DOI 10.1145/2623330.2623741
   Liu C, 2016, IEEE T KNOWL DATA EN, V28, P211, DOI 10.1109/TKDE.2015.2468715
   Lopez-Rincon O, 2019, IEEE ACCESS, V7, P140344, DOI 10.1109/ACCESS.2019.2944083
   Mathisen A, 2017, 2017 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P7, DOI 10.1109/VDS.2017.8573439
   McKay C., 2006, P INT COMP MUS C NEW, P302
   McKay C, 2018, P INT SOC MUS INF RE, P348
   MONGEAU M, 1990, COMPUT HUMANITIES, V24, P161, DOI 10.1007/BF00117340
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Pereira RM, 2017, IEEE INT CON MULTI, P1446, DOI 10.1109/ICME.2017.8019531
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Sheh A., 2003, PROC INT C MUSIC INF, P183
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sun GD, 2019, J VISUAL-JAPAN, V22, P1193, DOI 10.1007/s12650-019-00600-6
   Topirceanu A, 2014, 2014 EUROPEAN NETWORK INTELLIGENCE CONFERENCE (ENIC), P89, DOI 10.1109/ENIC.2014.10
   Torrens Marc., 2004, Proc. ISMIR, P421
   Unger A, 2018, IEEE T VIS COMPUT GR, V24, P66, DOI 10.1109/TVCG.2017.2744686
   Valle R, 2018, Arxiv, DOI arXiv:1807.10204
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Walshaw C., 2016, P INT WORKSH FOLK MU, P22
   Walshaw C, 2018, IEEE INT CON INF VIS, P478, DOI 10.1109/iV.2018.00089
   Wikipedia Contributors, 2021, JAZZ WIK FREE ENC
   Yachdav G, 2016, BIOINFORMATICS, V32, P3501, DOI 10.1093/bioinformatics/btw474
   Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746
   Zhang YX, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P206, DOI [10.1109/VISUAL.2019.8933584, 10.1109/visual.2019.8933584]
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
   Ziegler H., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P83, DOI 10.1109/VAST.2010.5652530
NR 57
TC 1
Z9 1
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD SEPT 1
PY 2023
VL 29
IS 9
BP 4015
EP 4030
DI 10.1109/TVCG.2022.3175364
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O2BA8
UT WOS:001041912300021
PM 35609098
DA 2024-11-06
ER

PT J
AU Linhares, CDG
   Lima, DM
   Ponciano, JR
   Olivatto, MM
   Gutierrez, MA
   Poco, J
   Traina, C Jr
   Traina, AJM
AF Linhares, Claudio D. G.
   Lima, Daniel M.
   Ponciano, Jean R.
   Olivatto, Mauro M.
   Gutierrez, Marco A.
   Poco, Jorge
   Traina Jr, Caetano
   Traina, Agma J. M.
TI ClinicalPath: A Visualization Tool to Improve the Evaluation of
   Electronic Health Records in Clinical Decision-Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information visualization; interactive visualizations; human-computer
   interaction; electronic health records
ID GUIDANCE
AB Physicians work at a very tight schedule and need decision-making support tools to help on improving and doing their work in a timely and dependable manner. Examining piles of sheets with test results and using systems with little visualization support to provide diagnostics is daunting, but that is still the usual way for the physicians' daily procedure, especially in developing countries. Electronic Health Records systems have been designed to keep the patients' history and reduce the time spent analyzing the patient's data. However, better tools to support decision-making are still needed. In this article, we propose ClinicalPath, a visualization tool for users to track a patient's clinical path through a series of tests and data, which can aid in treatments and diagnoses. Our proposal is focused on patient's data analysis, presenting the test results and clinical history longitudinally. Both the visualization design and the system functionality were developed in close collaboration with experts in the medical domain to ensure a right fit of the technical solutions and the real needs of the professionals. We validated the proposed visualization based on case studies and user assessments through tasks based on the physician's daily activities. Our results show that our proposed system improves the physicians' experience in decision-making tasks, made with more confidence and better usage of the physicians' time, allowing them to take other needed care for the patients.
C1 [Linhares, Claudio D. G.; Lima, Daniel M.; Traina Jr, Caetano; Traina, Agma J. M.] Univ Sao Paulo, Inst Math & Comp Sci, BR-05508070 Sao Carlos, Brazil.
   [Lima, Daniel M.; Gutierrez, Marco A.] Univ Sao Paulo, Lab Informat Biomed, Inst Coracao, Hospitaldas Clin HCFMUSP,Fac Med, BR-05508070 Sao Paulo, Brazil.
   [Ponciano, Jean R.] Getulio Vargas Fdn, Sch Appl Math, BR-22250900 Rio De Janeiro, Brazil.
   [Olivatto, Mauro M.] Fed Univ Fronteira Sul, Grad Course Med, BR-89802112 Chapeco, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo; Getulio Vargas
   Foundation; Universidade Federal da Fronteira Sul
RP Linhares, CDG (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci, BR-05508070 Sao Carlos, Brazil.
EM claudiodgl@usp.br; daniel.lima@incor.usp.br; jean.ponciano@fgv.br;
   mauro_olivatto@hotmail.com; marco.gutierrez@incor.usp.br;
   jorge.poco@fgv.br; caetano@icmc.usp.br; agma@icmc.usp.br
RI Ponciano, Jean/AGE-0314-2022; Gutierrez, Marco/G-6926-2012; Poco,
   Jorge/F-3344-2016; Traina, Caetano/E-9814-2011; Linhares,
   Claudio/AAJ-8869-2021; Traina, Agma/F-1299-2011; Lima, Daniel
   Mario/S-5366-2017
OI Gutierrez, Marco/0000-0003-0964-6222; Poco, Jorge/0000-0001-9096-6287;
   Traina, Caetano/0000-0002-6625-6047; Linhares,
   Claudio/0000-0001-7012-4461; Traina, Agma/0000-0003-4929-7258; Lima,
   Daniel Mario/0000-0002-7818-6103; Ponciano, Jean
   Roberto/0000-0003-4629-3542
FU Sao Paulo Research Foundation (FAPESP) [2020/10049-0, 2020/07200-9,
   2016/17078-0]; Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq); Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior (CAPES) [312483/2018-0]; Rio de Janeiro Research Foundation
   (FAPERJ) [E-26/201.424/2021]; Foxconn Technology Group; Zerbini
   Foundation; Getulio Vargas Foundation
FX This work was supported in part by Sao Paulo Research Foundation
   (FAPESP) under Grants #2020/10049-0, #2020/07200-9, and #2016/17078-0;
   in part by the Conselho Nacional de Desenvolvimento Cientifico e
   Tecnologico (CNPq) and Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior (CAPES) under Grant #312483/2018-0 in part by Rio de
   Janeiro Research Foundation (FAPERJ) under Grant #E-26/201.424/2021, in
   part by Foxconn Technology Group, Zerbini Foundation under Project
   AIMED-CATI 030/2007 FOXCONN-001/2019, and in part by Getulio Vargas
   Foundation.
CR Abdullah SS, 2020, INFORMATICS-BASEL, V7, DOI 10.3390/informatics7020017
   Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   Aigner W, 2006, ARTIF INTELL MED, V37, P203, DOI 10.1016/j.artmed.2006.04.002
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Bade R., 2004, P SIGCHI C HUM FACT, P105, DOI [10.1145/985692.985706, DOI 10.1145/985692.985706]
   Barriviera C., 2017, P 2 INT C INF ASS TE, P46
   Bernard Jurgen, 2015, IEEE Comput Graph Appl, V35, P44, DOI 10.1109/MCG.2015.49
   Borgo R., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cazzolato M., 2021, PROC 36 BRAZILIAN S, P25
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chire J., 2020, Data mining approach to analyze COVID19 dataset of Brazilian patients, DOI [10.1101/2020.08.13.20174508, DOI 10.1101/2020.08.13.20174508]
   Dabek F, 2017, 2017 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P55, DOI 10.1109/VAHC.2017.8387501
   Faiola A, 2011, LECT NOTES COMPUT SC, V6779, P119, DOI 10.1007/978-3-642-21716-6_13
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Glicksberg BS, 2019, BIOINFORMATICS, V35, P4515, DOI 10.1093/bioinformatics/btz409
   Gschwandtner T, 2011, IEEE PAC VIS SYMP, P43, DOI 10.1109/PACIFICVIS.2011.5742371
   Hirsch JS, 2015, J AM MED INFORM ASSN, V22, P263, DOI 10.1136/amiajnl-2014-002945
   Klimov D, 2010, ARTIF INTELL MED, V49, P11, DOI 10.1016/j.artmed.2010.02.001
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Linhares CDG, 2021, COMP MED SY, P125, DOI 10.1109/CBMS52027.2021.00059
   Linhares CDG, 2021, J VISUAL-JAPAN, V24, P1011, DOI 10.1007/s12650-021-00759-x
   Lins Lauro., 2011, Proceedings of the IEEE VisWeek Workshop on Visual Analytics in Healthcare, P13
   Mello L. E., 2020, Opening Brazilian COVID-19 patient data to support world research on pandemics, DOI [10.5281/zenodo.3966427, DOI 10.5281/ZENODO.3966427]
   Mello L. E., 2022, FAPESP COVID-19 Data Sharing/BR
   Ordóñez P, 2012, IBM J RES DEV, V56, DOI 10.1147/JRD.2012.2200431
   Packer E, 2013, IEEE T VIS COMPUT GR, V19, P2179, DOI 10.1109/TVCG.2013.224
   Resck LE, 2023, IEEE T VIS COMPUT GR, V29, P3105, DOI 10.1109/TVCG.2022.3152450
   Rind Alexander, 2011, Information Quality in e-Health. Proceedings 7th Conference of the Workgroup Human-Computer Interaction and Usability Engineering of the Austrian Computer Society, USAB 2011, P301, DOI 10.1007/978-3-642-25364-5_22
   Rostamzadeh N, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4010007
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shneiderman B, 2013, COMPUTER, V46, P58, DOI 10.1109/MC.2013.38
   Steinhauer N., 2020, PROC EUROVIS SHORT P, P169
   Suchodolski K., 2022, ICUData
   Sultanum N, 2019, IEEE T VIS COMPUT GR, V25, P142, DOI 10.1109/TVCG.2018.2864905
   Sun V., 2018, PROC ENANPAD, V42, P1
   Szelagowski M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217383
   Ten-Caten F, 2021, INT J INFECT DIS, V105, P579, DOI 10.1016/j.ijid.2021.03.016
   Wagemans J, 2012, PSYCHOL BULL, V138, P1218, DOI 10.1037/a0029334
   Wang TD, 2009, IEEE T VIS COMPUT GR, V15, P1049, DOI 10.1109/TVCG.2009.187
   Ware C., 2013, Interactive Technologies, P514, DOI 10.1016/B978-0-12-381464-7.00018-1
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
NR 43
TC 2
Z9 2
U1 2
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4031
EP 4046
DI 10.1109/TVCG.2022.3175626
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200001
PM 35588413
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cibulski, L
   May, T
   Schmidt, J
   Kohlhammer, J
AF Cibulski, Lena
   May, Thorsten
   Schmidt, Johanna
   Kohlhammer, Joern
TI COMPO*SED: Composite Parallel Coordinates for Co-Dependent
   Multi-Attribute Choices
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multi-criteria decision-making; parallel coordinates; systems
   engineering design; visual exploration
ID VISUAL ANALYSIS; VISUALIZATION; EXPLORATION
AB We propose Composite Parallel Coordinates, a novel parallel coordinates technique to effectively represent the interplay of component alternatives in a system. It builds upon a dedicated data model that formally describes the interaction of components. Parallel coordinates can help decision-makers identify the most preferred solution among a number of alternatives. Multi-component systems require one such multi-attribute choice for each component. Each of these choices might have side effects on the system's operability and performance, making them co-dependent. Common approaches employ complex multi-component models or involve back-and-forth iterations between single components until an acceptable compromise is reached. A simultaneous visual exploration across independently modeled but connected components is needed to make system design more efficient. Using dedicated layout and interaction strategies, our Composite Parallel Coordinates allow analysts to explore both individual properties of components as well as their interoperability and joint performance. We showcase the effectiveness of Composite Parallel Coordinates for co-dependent multi-attribute choices by means of three real-world scenarios from distinct application areas. In addition to the case studies, we reflect on observing two domain experts collaboratively working with the proposed technique and communicating along the way.
C1 [Cibulski, Lena; May, Thorsten; Kohlhammer, Joern] Fraunhofer IGD, D-64283 Darmstadt, Germany.
   [Schmidt, Johanna] VRVis Res Ctr, A-1220 Vienna, Austria.
RP Cibulski, L (corresponding author), Fraunhofer IGD, D-64283 Darmstadt, Germany.
EM lena.cibulski@igd.fraunhofer.de; thorsten.may@igd.fraunhofer.de;
   johanna.schmidt@vrvis.at; Joern.Kohlhammer@igd.fraunhofer.de
OI Kohlhammer, Jorn/0000-0003-1706-8979; Schmidt,
   Johanna/0000-0002-9638-6344; May, Thorsten/0000-0001-8027-2687;
   Cibulski, Lena/0000-0002-8246-5746
FU LCM - K2 Center; BMK; BMDW; Styria; SFG; Tyrol; Vienna Business Agency
   [879730]
FX This work was supported in part by the LCM - K2 Center within the
   framework of the Austrian COMET-K2 program. VRVis was supported by
   BMK,BMDW, Styria, SFG, Tyrol, and Vienna Business Agency in the scope of
   COMET (879730), managed by FFG.
CR Andrews K., 2015, P 15 INT C KNOWL TEC, P1
   [Anonymous], 2001, 1st International Symposium on Smart Graphics
   Basole RC, 2015, IEEE COMPUT GRAPH, V35, P41, DOI 10.1109/MCG.2015.3
   Bhattarai D, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 3: IVAPP, P83, DOI 10.5220/0007375400830095
   Carlson-Skalak S, 1998, RES ENG DES, V10, P63, DOI 10.1007/BF01616688
   Chang CL, 2018, IEEE PAC VIS SYMP, P195, DOI 10.1109/PacificVis.2018.00033
   Chen SH, 2013, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2013.6596140
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Claessen JHT, 2011, IEEE T VIS COMPUT GR, V17, P2310, DOI 10.1109/TVCG.2011.201
   CODD EF, 1970, COMMUN ACM, V13, P377, DOI 10.1145/357980.358007
   Dang TN, 2010, IEEE T VIS COMPUT GR, V16, P1044, DOI 10.1109/TVCG.2010.197
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Garrison L, 2021, IEEE T VIS COMPUT GR, V27, P2908, DOI 10.1109/TVCG.2021.3057519
   Gratzl S, 2014, IEEE T VIS COMPUT GR, V20, P2023, DOI 10.1109/TVCG.2014.2346260
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Heinrich J., 2013, STAR Proc. Eurographics, V2013, P95, DOI [10.2312/conf/EG2013/stars/095-116, DOI 10.2312/C0NF/EG2013/STARS/095, DOI 10.2312/CONF/EG2013/STARS/095-116]
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Isenberg P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1217
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kehrer J, 2011, IEEE T VIS COMPUT GR, V17, P934, DOI 10.1109/TVCG.2010.111
   Kipouros T, 2013, P 54 STRUCT STRUCT D, P1750
   Konyha Z., 2009, Proceedings of the Spring Conference on Computer Graphics, P31
   Korhonen P, 2008, LECT NOTES COMPUT SC, V5252, P195, DOI 10.1007/978-3-540-88908-3_8
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Kossiakoff A., 2003, Systems Engineering: Principles and Practices
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lind M, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P25, DOI 10.1109/IV.2009.43
   Lotov AV, 2008, LECT NOTES COMPUT SC, V5252, P213, DOI 10.1007/978-3-540-88908-3_9
   Marth E, 2019, 2019 IEEE INTERNATIONAL ELECTRIC MACHINES & DRIVES CONFERENCE (IEMDC), P839, DOI 10.1109/IEMDC.2019.8785397
   Miettinen K, 2014, OR SPECTRUM, V36, P3, DOI 10.1007/s00291-012-0297-0
   Mittal S., 1989, P INT JOINT C ARTIFI, P1395
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Neale D.C., 2004, Proc. of the 2004 ACM conf. on Computer supported cooperative work, P112, DOI DOI 10.1145/1031607.1031626
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI DOI 10.1145/345513.345282
   Riehmann P., 2020, CONFIGURATION FINDER
   Roberts JC, 1998, IEEE INFOR VIS, P8, DOI 10.1109/IV.1998.694193
   Sillitto Hillary, 2018, INCOSE International Symposium, V28, DOI 10.1002/j.2334-5837.2018.00542.x
   Spence B., 1995, Proceedings. Information Visualization (Cat. No.95TB100000), P4, DOI 10.1109/INFVIS.1995.528680
   Splechtna R, 2018, VISUAL COMPUT, V34, P1087, DOI 10.1007/s00371-018-1516-8
   Splechtna R, 2015, IEEE CONF VIS ANAL, P89, DOI 10.1109/VAST.2015.7347635
   Tadeja SK, 2021, AIAA J, V59, P5332, DOI 10.2514/1.J060441
   Trautner T, 2021, COMPUT GRAPH FORUM, V40, P399, DOI 10.1111/cgf.14316
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Weidele DKI, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P221, DOI [10.1109/VISUAL.2019.8933632, 10.1109/visual.2019.8933632]
   Zeman K., 2020, PROC INT TOOLS METHO, P569
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
   Zhicheng Liu, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P41, DOI 10.1109/VAST.2011.6102440
   Zhou H, 2008, COMPUT GRAPH FORUM, V27, P1047, DOI 10.1111/j.1467-8659.2008.01241.x
NR 53
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4047
EP 4061
DI 10.1109/TVCG.2022.3180899
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200002
PM 35679374
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Zheng, CW
   Lin, WB
   Xu, F
AF Zheng, Chengwei
   Lin, Wenbin
   Xu, Feng
TI A Self-Occlusion Aware Lighting Model for Real-Time Dynamic
   Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Surface reconstruction; Real-time systems; Geometry; Image
   reconstruction; Computational modeling; Shape; Albedo reconstruction; 3D
   dynamic reconstruction; spatially varying lighting; real-time
   reconstruction
ID INTRINSIC IMAGE DECOMPOSITION; AMBIENT OCCLUSION; SHAPE; REPRESENTATION;
   VIDEO
AB In real-time dynamic reconstruction, geometry and motion are the major focuses while appearance is not fully explored, leading to the low-quality appearance of the reconstructed surfaces. In this article, we propose a lightweight lighting model that considers spatially varying lighting conditions caused by self-occlusion. This model estimates per-vertex masks on top of a single Spherical Harmonic (SH) lighting to represent spatially varying lighting conditions without adding too much computation cost. The mask is estimated based on the local geometry of a vertex to model the self-occlusion effect, which is the major reason leading to the spatial variation of lighting. Furthermore, to use this model in dynamic reconstruction, we also improve the motion estimation quality by adding a real-time per-vertex displacement estimation step. Experiments demonstrate that both the reconstructed appearance and the motion are largely improved compared with the current state-of-the-art techniques.
C1 [Zheng, Chengwei; Lin, Wenbin; Xu, Feng] Tsinghua Univ, Sch Software & BNRist, Beijing 100190, Peoples R China.
C3 Tsinghua University
RP Zheng, CW (corresponding author), Tsinghua Univ, Sch Software & BNRist, Beijing 100190, Peoples R China.
EM zhengcw18@gmail.com; lwb20@mails.tsinghua.edu.cn; xufeng2003@gmail.com
RI Zheng, Chengwei/HPC-8073-2023; Lin, Wenbin/LOS-1323-2024
OI Zheng, Chengwei/0000-0002-3657-0297; Lin, Wenbin/0000-0001-9175-6003
FU Beijing Natural Science Foundation [JQ19015]; NSFC [62021002, 61727808];
   National Key Ramp;D Program of China [2018YFA0704000]; Institute for
   Brain and Cognitive Science; Tsinghua University (THUIBCS); Beijing
   Laboratory of Brain and Cognitive Intelligence, Beijing Municipal
   Education Commission (BLBCI)
FX This work was supported in part by the Beijing Natural Science
   Foundation under Grant JQ19015, the NSFC under Grants 62021002, and
   61727808, the National Key R & D Program of China under Grant
   2018YFA0704000. This work was supported by the Institute for Brain and
   Cognitive Science, Tsinghua University (THUIBCS) and Beijing Laboratory
   of Brain and Cognitive Intelligence, Beijing Municipal Education
   Commission (BLBCI).
CR Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   Barron JT, 2013, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2013.10
   Barron JT, 2012, PROC CVPR IEEE, P334, DOI 10.1109/CVPR.2012.6247693
   Barron JT, 2012, LECT NOTES COMPUT SC, V7575, P57, DOI 10.1007/978-3-642-33765-9_5
   Bavoil L., 2008, ACM SIGGRAPH 2008 TA, DOI [10.1145/1401032.1401061, DOI 10.1145/1401032.1401061]
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Bi S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766946
   Bonneel N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661253
   Bousseau A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618476
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Casas D, 2014, COMPUT GRAPH FORUM, V33, P371, DOI 10.1111/cgf.12296
   Chen QF, 2013, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2013.37
   Cheng LC, 2018, PROC CVPR IEEE, P656, DOI [10.1109/CVPR.2018.00075, 10.1109/ICMLC.2018.8527016]
   Cheng Z, 2019, IEEE I CONF COMP VIS, P2521, DOI 10.1109/ICCV.2019.00261
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Díaz J, 2010, COMPUT GRAPH-UK, V34, P337, DOI 10.1016/j.cag.2010.03.005
   Du RF, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190843
   Fan QN, 2018, PROC CVPR IEEE, P8944, DOI 10.1109/CVPR.2018.00932
   Garces E, 2012, COMPUT GRAPH FORUM, V31, P1415, DOI 10.1111/j.1467-8659.2012.03137.x
   Garrido P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2890493
   Gotardo P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275073
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722
   Hachama M, 2015, IEEE I CONF COMP VIS, P810, DOI 10.1109/ICCV.2015.99
   Han Y, 2013, IEEE I CONF COMP VIS, P1617, DOI 10.1109/ICCV.2013.204
   Hauagge D, 2016, IEEE T PATTERN ANAL, V38, P639, DOI 10.1109/TPAMI.2015.2453959
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Horn B.K.P., 1970, Shape from shading: A method for obtaining the shape of a smooth opaque object from one view
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Innmann M, 2016, LECT NOTES COMPUT SC, V9912, P362, DOI 10.1007/978-3-319-46484-8_22
   Jeon J, 2014, LECT NOTES COMPUT SC, V8695, P218, DOI 10.1007/978-3-319-10584-0_15
   Kanamori Y, 2019, Arxiv, DOI arXiv:1908.02714
   Knecht M., 2007, STATE ART REPORT AMB
   Kontkanen J., 2005, P S INT 3D GRAPH GAM, P41
   Kovacs B, 2017, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2017.97
   Laine S, 2010, COMPUT GRAPH FORUM, V29, P1325, DOI 10.1111/j.1467-8659.2010.01728.x
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Li ZQ, 2018, PROC CVPR IEEE, P9039, DOI 10.1109/CVPR.2018.00942
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Liu YF, 2020, PROC CVPR IEEE, P3245, DOI 10.1109/CVPR42600.2020.00331
   Lombardi S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201401
   Luo JD, 2020, IEEE T VIS COMPUT GR, V26, P3434, DOI 10.1109/TVCG.2020.3023565
   Maier R, 2017, IEEE I CONF COMP VIS, P3133, DOI 10.1109/ICCV.2017.338
   Martin-Brualla R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275099
   Meka A, 2017, IEEE T VIS COMPUT GR, V23, P2447, DOI 10.1109/TVCG.2017.2734425
   Meka A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925907
   Mingsong Dou, 2017, ACM Transactions on Graphics, V36, DOI 10.1145/3130800.3130801
   Nagano K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275075
   Narihira T, 2015, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2015.342
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Pandey R, 2019, PROC CVPR IEEE, P9701, DOI 10.1109/CVPR.2019.00994
   Prada F, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073679
   Ramamoorthi R, 2001, COMP GRAPH, P497, DOI 10.1145/383259.383317
   Reinbothe C. K., 2009, P ANN C EUR ASS COMP, P51
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Rother M., 2011, ADV NEURAL INFORM PR, P765
   Saito S, 2017, PROC CVPR IEEE, P2326, DOI 10.1109/CVPR.2017.250
   Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659
   Shanmugam P, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P73
   Shen L, 2011, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2011.5995738
   Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tung T., 2008, P IEEE C COMP VIS PA, P1
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
   Wu CL, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275101
   Wu CL, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661232
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xin Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P380, DOI 10.1007/978-3-030-58555-6_23
   Xing GY, 2020, IEEE T VIS COMPUT GR, V26, P1672, DOI 10.1109/TVCG.2018.2876541
   Ye G., 2014, ACM T GRAPHIC, V33, P1
   Ye Yu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P84, DOI 10.1007/978-3-030-58542-6_6
   Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186
   Yu Y, 2019, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2019.00327
   Zheng CW, 2022, IEEE T VIS COMPUT GR, V28, P3365, DOI 10.1109/TVCG.2021.3064846
   Zhou TH, 2015, IEEE I CONF COMP VIS, P3469, DOI 10.1109/ICCV.2015.396
   Zhukov S., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P45
   Zollhöfer M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766887
   Zuo XX, 2017, IEEE I CONF COMP VIS, P3152, DOI 10.1109/ICCV.2017.340
NR 79
TC 0
Z9 0
U1 2
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4062
EP 4073
DI 10.1109/TVCG.2022.3178237
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200003
PM 35622791
DA 2024-11-06
ER

PT J
AU Su, WC
   Ye, H
   Chen, SY
   Gao, L
   Fu, HB
AF Su, Wanchao
   Ye, Hui
   Chen, Shu-Yu
   Gao, Lin
   Fu, Hongbo
TI DrawingInStyles: Portrait Image Generation and Editing With Spatially
   Conditioned StyleGAN
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Semantics; Image synthesis; Codes; Training; Transforms; Spatial
   resolution; Sketch-based portrait generation; suggestive interfaces;
   data-driven approaches; StyleGAN; conditional generation
AB The research topic of sketch-to-portrait generation has witnessed a boost of progress with deep learning techniques. The recently proposed StyleGAN architectures achieve state-of-the-art generation ability but the original StyleGAN is not friendly for sketch-based creation due to its unconditional generation nature. To address this issue, we propose a direct conditioning strategy to better preserve the spatial information under the StyleGAN framework. Specifically, we introduce Spatially Conditioned StyleGAN (SC-StyleGAN for short), which explicitly injects spatial constraints to the original StyleGAN generation process. We explore two input modalities, sketches and semantic maps, which together allow users to express desired generation results more precisely and easily. Based on SC-StyleGAN, we present DrawingInStyles, a novel drawing interface for non-professional users to easily produce high-quality, photo-realistic face images with precise control, either from scratch or editing existing ones. Qualitative and quantitative evaluations show the superior generation ability of our method to existing and alternative solutions. The usability and expressiveness of our system are confirmed by a user study.
C1 [Su, Wanchao; Ye, Hui; Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
   [Chen, Shu-Yu] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100045, Peoples R China.
   [Gao, Lin] Chinese Acad Sci, Beijing Key Lab Mobile Comp & Pervas Device, Inst Comp Technol, Beijing 100045, Peoples R China.
   [Gao, Lin] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
C3 City University of Hong Kong; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Fu, HB (corresponding author), City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
EM wanchao.su@cityu.edu.hk; hui.ye@cityu.edu.hk; chenshuyu@ict.ac.cn;
   gaolin@ict.ac.cn; hongbofu@cityu.edu.hk
RI Gao, Lin/JNF-0375-2023
OI Ye, Hui/0000-0001-9539-9920; SU, Wanchao/0000-0002-7498-3033; FU,
   Hongbo/0000-0002-0284-726X
FU Research Grants Council of the Hong Kong Special Administrative
   Region,China [CityU 11212119]; Centre for Applied Computing and
   Interactive Media (ACIM) of School of Creative Media, CityUniversity of
   Hong Kong; National Natural Science Foundation of China [62102403];
   Beijing Municipal Natural Science Foundation for Distinguished Young
   Scholars [JQ21013]; Youth Innovation Promotion Association, Chinese
   Academy of Sciences
FX The work was supported by unrestricted gifts from Adobe and grants from
   the Research Grants Council of the Hong Kong Special Administrative
   Region,China under Grant CityU 11212119, and in part by the Centre for
   Applied Computing and Interactive Media (ACIM) of School of Creative
   Media, CityUniversity of Hong Kong. Shu-Yu Chen was supported by the
   National Natural Science Foundation of China under Grant 62102403. Lin
   Gao was supported by the Beijing Municipal Natural Science Foundation
   for Distinguished Young Scholars under Grant JQ21013, Youth Innovation
   Promotion Association, Chinese Academy of Sciences
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Abdal R, 2020, PROC CVPR IEEE, P8293, DOI 10.1109/CVPR42600.2020.00832
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Alharbi Y, 2020, PROC CVPR IEEE, P5133, DOI 10.1109/CVPR42600.2020.00518
   Brock A, 2019, Arxiv, DOI arXiv:1809.11096
   Chen SY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459760
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P1967, DOI 10.1109/TNNLS.2018.2875194
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Härkönen E, 2020, Arxiv, DOI [arXiv:2004.02546, DOI 10.48550/ARXIV.2004.02546]
   Hensel M, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2020, Arxiv, DOI arXiv:2006.06676
   Karras T, 2018, Arxiv, DOI arXiv:1710.10196
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim H, 2021, PROC CVPR IEEE, P852, DOI 10.1109/CVPR46437.2021.00091
   Lee CH, 2020, Arxiv, DOI arXiv:1907.11922
   Lee YJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964922
   Li YH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P991, DOI 10.1145/3394171.3413684
   Li YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2323, DOI 10.1145/3343031.3350854
   Mirza M, 2014, Arxiv, DOI arXiv:1411.1784
   Park T., 2020, EUR C COMP VIS, P319, DOI DOI 10.1007/978-3-030-58545-7_19
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Portenier T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201393
   Richardson E, 2021, Arxiv, DOI arXiv:2008.00951
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sangkloy P, 2017, PROC CVPR IEEE, P6836, DOI 10.1109/CVPR.2017.723
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Shuyang Gu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P3431, DOI 10.1109/CVPR.2019.00355
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tov Omer, 2021, arXiv
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu ZZ, 2020, Arxiv, DOI arXiv:2011.12799
   Yang S, 2020, Arxiv, DOI arXiv:2001.02890
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu FS, 2016, Arxiv, DOI arXiv:1506.03365
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JP, 2020, Arxiv, DOI arXiv:2004.00049
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601145
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
   Zhu Peihao, 2021, arXiv
NR 46
TC 8
Z9 9
U1 3
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4074
EP 4088
DI 10.1109/TVCG.2022.3178734
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200004
PM 35635812
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, GH
   Orlosky, J
   Feiner, S
   Ratsamee, P
   Uranishi, Y
AF Zhao, Guanghan
   Orlosky, Jason
   Feiner, Steven
   Ratsamee, Photchara
   Uranishi, Yuki
TI Mitigation of VR Sickness During Locomotion With a Motion-Based Dynamic
   Vision Modulator
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Optical flow; Modulation; Angular velocity; Image color
   analysis; Teleportation; Legged locomotion; VR sickness; contrast
   manipulation; vision modulation; shading and rendering
ID SIMULATOR SICKNESS; SPEED PERCEPTION; SELF-MOTION; MOVEMENT; DEPTH;
   NAVIGATION; PARALLAX; VELOCITY; VIEW
AB In virtual reality, VR sickness resulting from continuous locomotion via controllers or joysticks is still a significant problem. In this article, we present a set of algorithms to mitigate VR sickness that dynamically modulate the user's field of view by modifying the contrast of the periphery based on movement, color, and depth. In contrast with previous work, this vision modulator is a shader that is triggered by specific motions known to cause VR sickness, such as acceleration, strafing, and linear velocity. Moreover, the algorithm is governed by delta velocity, delta angle, and average color of the view. We ran two experiments with different washout periods to investigate the effectiveness of dynamic modulation on the symptoms of VR sickness, in which we compared this approach against a baseline and pitch-black field-of-view restrictors. Our first experiment made use of a just-noticeable-sickness design, which can be useful for building experiments with a short washout period.
C1 [Zhao, Guanghan; Orlosky, Jason] Osaka Univ, Suita, Osaka 5650871, Japan.
   [Ratsamee, Photchara; Uranishi, Yuki] Osaka Univ, Cybermedia Ctr, Suita, Osaka 5650871, Japan.
   [Feiner, Steven] Columbia Univ, Comp Sci, New York, NY 10027 USA.
C3 Osaka University; Osaka University; Columbia University
RP Zhao, GH (corresponding author), Osaka Univ, Suita, Osaka 5650871, Japan.
EM zhao.guanghan@lab.ime.cmc.osaka-u.ac.jp; jasonorlosky@gmail.com;
   feiner@cs.columbia.edu; photchara@ime.cmc.osaka-u.ac.jp;
   uranishi@ime.cmc.osaka-u.ac.jp
RI Ratsamee, Photchara/ABI-5958-2020
OI Ratsamee, Photchara/0000-0002-3081-2232; Orlosky,
   Jason/0000-0002-0538-6630; Zhao, Guanghan/0000-0002-1216-9685; Feiner,
   Steven/0000-0001-9978-7090
FU ONRG [N62909-18-1-2036]
FX This work was supported by ONRG under Grant N62909-18-1-2036.
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Alexander SJ, 1945, J PSYCHOL, V20, P3, DOI 10.1080/00223980.1945.9712754
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Bhandari Jiwan, 2018, GRAPHICS INTERFACE, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018, DOI 10.20380/GI2018, 10. 20380/GI2018.22]
   Bolas Mark, 2017, US Patent, Patent No. [9,645,395, 9645395]
   Bonato F, 2005, AVIAT SPACE ENVIR MD, V76, P823
   Bos JE, 2010, APPL ERGON, V41, P516, DOI 10.1016/j.apergo.2009.11.007
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Brooks K, 2001, PERCEPTION, V30, P725, DOI 10.1068/p3143
   Brown JF, 1931, PSYCHOL FORSCH, V14, P199, DOI 10.1007/BF00403873
   Brument Hugo, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P20, DOI 10.1007/978-3-030-62655-6_2
   Bubka A, 2006, AVIAT SPACE ENVIR MD, V77, P811
   Budhiraja P, 2017, Arxiv, DOI arXiv:1710.02599
   Cao ZK, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P105, DOI 10.1109/VR.2018.8446210
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chardonnet JR, 2021, VIRTUAL REAL-LONDON, V25, P565, DOI 10.1007/s10055-020-00474-2
   Cronkleton E., 2020, How fast can a human run?
   Dahlman J, 2008, J NEUROENG REHABIL, V5, DOI 10.1186/1743-0003-5-35
   Diels C., 2010, Annu. Res., V22
   Diels C., 2014, Contemporary Ergonomics and Human Factors, P301, DOI DOI 10.1201/B16742-56
   Duan H., 2017, Proceedings of Pacific Rim Conference on Multimedia, P662
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   EWERT JP, 1972, EXP BRAIN RES, V16, P41
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   GIBSON EJ, 1959, J EXP PSYCHOL, V58, P40, DOI 10.1037/h0043883
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   HELD R, 1961, J COMP PHYSIOL PSYCH, V54, P33, DOI 10.1037/h0046207
   Helmholtz H., 1925, HELMHOLTZS TREATISE
   Hillaire S, 2008, IEEE COMPUT GRAPH, V28, P47, DOI 10.1109/MCG.2008.113
   JAGER J, 1981, ANN NY ACAD SCI, V374, P330, DOI 10.1111/j.1749-6632.1981.tb30880.x
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshavarz B, 2011, DISPLAYS, V32, P181, DOI 10.1016/j.displa.2011.05.009
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Liu SH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392482
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Lou RD, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1058, DOI [10.1109/VR.2019.8798164, 10.1109/vr.2019.8798164]
   M. Station, 2020, Lordenfel: Castles and dungeons RPG pack
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Nie GY, 2020, IEEE T VIS COMPUT GR, V26, P2535, DOI 10.1109/TVCG.2019.2893668
   Norouzi N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225162
   Oman C M, 1982, Acta Otolaryngol Suppl, V392, P1
   Ono H, 2005, PERCEPTION, V34, P477, DOI 10.1068/p5221
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Peng YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376847
   PERRONE JA, 1994, VISION RES, V34, P2917, DOI 10.1016/0042-6989(94)90060-4
   Reason J.T., 1975, Motion Sickness
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   RUNESON S, 1974, PSYCHOL RES-PSYCH FO, V37, P3, DOI 10.1007/BF00309076
   Russell MEB, 2014, APPL PSYCHOPHYS BIOF, V39, P269, DOI 10.1007/s10484-014-9265-6
   Seay AF, 2001, P IEEE VIRT REAL ANN, P299, DOI 10.1109/VR.2001.913806
   Shupak A, 2006, AVIAT SPACE ENVIR MD, V77, P1213
   Stanney KM, 1998, HUM FAC ERG SOC P, P1476
   STONE LS, 1992, VISION RES, V32, P1535, DOI 10.1016/0042-6989(92)90209-2
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   THOMPSON P, 1982, VISION RES, V22, P377, DOI 10.1016/0042-6989(82)90153-5
   Webb NA, 2003, AVIAT SPACE ENVIR MD, V74, P622
   Weech S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194137
   WIST ER, 1975, PERCEPT PSYCHOPHYS, V17, P549, DOI 10.3758/BF03203967
   Wu F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1882, DOI [10.1109/VR.2019.8798015, 10.1109/vr.2019.8798015]
   Young L. R., 1973, PROC 5 S ROLE VESTIB, P205
   Zielasko D., 2018, P IEEE VR WORKSH EV, P1
   Zielasko D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1884, DOI [10.1109/vr.2019.8797837, 10.1109/VR.2019.8797837]
NR 67
TC 2
Z9 2
U1 9
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4089
EP 4103
DI 10.1109/TVCG.2022.3181262
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200005
PM 35687624
DA 2024-11-06
ER

PT J
AU Fan, LW
   Li, HY
   Shi, MW
AF Fan, Linwei
   Li, Huiyu
   Shi, Miaowen
TI Redirected Walking for Exploring Immersive Virtual Spaces With HMD: A
   Comprehensive Review and Recent Advances
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Legged locomotion; Aerospace electronics; Space exploration;
   Visualization; Visual perception; Tracking; Layout; Virtual reality;
   real walking; redirected walking; redirection; locomotion
ID MOTION COMPRESSION; TELEPRESENT WALKING; LARGE-SCALE; ENVIRONMENTS;
   NAVIGATION
AB Real walking techniques can provide the user with a more natural, highly immersive walking experience compared to the experience of other locomotion techniques. In contrast to the direct mapping between the virtual space and an equal-sized physical space that can be simply realized, the nonequivalent mapping that enables the user to explore a large virtual space by real walking within a confined physical space is complex. To address this issue, the redirected walking (RDW) technique is proposed by many works to adjust the user's virtual and physical movements based on some redirection manipulations. In this manner, subtle or overt motion deviations can be injected between the user's virtual and physical movements, allowing the user to undertake real walking in large virtual spaces by using different redirection controller methods. In this paper, we present a brief review to describe major concepts and methodologies in the field of redirected walking. First, we provide the fundamentals and basic criteria of RDW, and then we describe the redirection manipulations that can be applied to adjust the user's movements during virtual exploration. Furthermore, we clarify the redirection controller methods that properly adopt strategies for combining different redirection manipulations and present a classification of these methods by several categories. Finally, we summarize several experimental metrics to evaluate the performance of redirection controller methods and discuss current challenges and future work. Our study systematically classifies the relevant theories, concepts, and methods of RDW, and provides assistance to the newcomers in understanding and implementing the RDW technique.
C1 [Fan, Linwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Li, Huiyu] Shandong Univ Finance & Econ, Sch Management Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Shi, Miaowen] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University of
   Finance & Economics; Shandong University
RP Li, HY (corresponding author), Shandong Univ Finance & Econ, Sch Management Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM lwfan129@163.com; huiyl91@163.com; shimiaowen@hotmail.com
RI Fan, Linwei/ABG-8736-2021
OI Fan, Linwei/0000-0001-9986-2396; Li, Huiyu/0000-0003-2272-0984
FU National Natural Science Foundation of China [62002200]; Natural Science
   Foundation of Shandong Province [ZR2020QF012, ZR2020MF037]; Shandong
   Co-Innovation Center of Future Intelligent Computing(Shandong 2011
   Project),; NSFC-Zhejiang Joint Fund of the Integration of
   Informatization and Industrialization [U1909210]; Introduction and
   Education Plan of Young Creative Talents in Colleges
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62002200, in part by the Natural Science
   Foundation of Shandong Province under Grants ZR2020QF012 and
   ZR2020MF037, in part by the Shandong Co-Innovation Center of Future
   Intelligent Computing(Shandong 2011 Project), in part by the
   NSFC-Zhejiang Joint Fund of the Integration of Informatization and
   Industrialization under Grant U1909210,and in part by the Introduction
   and Education Plan of Young Creative Talents in Colleges.
CR Nguyen A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281515
   Nguyen A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI 10.1109/VR.2018.8446225
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bachmann ER, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P108, DOI 10.1109/CGames.2012.6314560
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Boletsis Costas, 2017, International Conference Interfaces and Human Computer Interaction 2017. Proceedings, P263
   Bolte B, 2015, IEEE T VIS COMPUT GR, V21, P545, DOI 10.1109/TVCG.2015.2391851
   Bolte Benjamin, 2010, P 17 ACM S VIRT REAL, P11
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Bruder G., 2009, Proceedings of the 15th Joint virtual reality Eurographics conference on Virtual Environments, P145
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P1068, DOI 10.1109/TVCG.2011.274
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Bruder G, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P75, DOI 10.1109/3DUI.2009.4811208
   Cardoso JCS, 2019, COMPUT GRAPH-UK, V85, P55, DOI 10.1016/j.cag.2019.09.005
   Chen H., 2017, P COMP GRAPH INT C
   Chen R., 2015, ACM Trans. Graph., V34, P1
   Chen WY, 2019, LECT NOTES COMPUT SC, V11883, P226, DOI 10.1007/978-3-030-31908-3_14
   Chen WY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P878, DOI [10.1109/vr.2019.8798146, 10.1109/VR.2019.8798146]
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Cho YH, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P527, DOI 10.1109/VR.2018.8446442
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dichgans J., 1978, Visual-Vestibular Interaction: Effects on Self-Motion Perception and Postural Control
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Dong TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P894, DOI [10.1109/vr.2019.8798319, 10.1109/VR.2019.8798319]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Engel David., 2008, P 2008 ACM S VIRTUAL, P157, DOI 10.1145/1450579.1450612
   Field T, 2004, PROC INT C ARTIF INT, P58
   Fine China Games, Fine China
   Freitag S, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2014.6798852
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   Gandrud Jonathan, 2016, P ACM S APPL PERC, P31, DOI [10.1145/2931002.2931010, DOI 10.1145/2931002.2931010]
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Goldfeather J., 2012, 2012 IEEE VR Workshop on Perceptual Illusions in Virtual Environments, P17, DOI 10.1109/PIVE.2012.6229795
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   GREEN DM, 1993, J ACOUST SOC AM, V93, P2096, DOI 10.1121/1.406696
   Hayashi D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P386, DOI [10.1109/VR.2019.8797989, 10.1109/vr.2019.8797989]
   Hilfert Thomas, 2016, Visualization in Engineering, V4, DOI 10.1186/s40327-015-0031-5
   Hirt C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P976, DOI [10.1109/vr.2019.8798118, 10.1109/VR.2019.8798118]
   Hirt C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P978, DOI [10.1109/vr.2019.8797709, 10.1109/VR.2019.8797709]
   Hodgson E., 2008, ACM T APPL PERCEPT, V8, P1
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP02012, 10.1207/s15327108ijap02012]
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   Langbehn E., 2019, Walking in virtual reality: Perceptually-inspired interaction techniques for locomotion in immersive environments
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li HY, 2021, PROCEEDINGS OF 23RD ACM INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447526.3472018
   Li HY, 2020, IEEE ACCESS, V8, P180210, DOI 10.1109/ACCESS.2020.3027985
   Li HY, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-1517-3
   Li HY, 2019, PROCEDIA COMPUT SCI, V147, P468, DOI 10.1016/j.procs.2019.01.274
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Matsumoto K., 2017, P ACM SIGGRAPH, P1
   Matsumoto K, 2021, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR52148.2021.00067
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   Matsumoto K, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P105, DOI 10.1109/3DUI.2016.7460038
   Matsushita K., 2016, Acetic acid bacteria. Ecology and physiology., DOI DOI 10.1007/978-4-431-55933-7
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Monteiro P, 2018, COMPUT GRAPH-UK, V77, P80, DOI 10.1016/j.cag.2018.10.003
   Nagao R, 2018, IEEE T VIS COMPUT GR, V24, P1584, DOI 10.1109/TVCG.2018.2793038
   Nescher T., 2013, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformat-ics), V7848, P172, DOI [10.1007/978-3-642-38803-310, DOI 10.1007/978-3-642-38803-310]
   Nescher T, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P15, DOI 10.1109/CW.2012.10
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Nguyen A, 2020, PROC 26 ACM S VIRTUA, P1
   Nguyen A., 2021, PhD thesis
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nilsson NC, 2016, P IEEE VIRT REAL ANN, P241, DOI 10.1109/VR.2016.7504743
   Nitzsche N, 2004, PRESENCE-TELEOP VIRT, V13, P44, DOI 10.1162/105474604774048225
   Nitzsche N, 2003, PROC SPIE, V5079, P265, DOI 10.1117/12.488379
   Nogalski M., 2016, P SOUND MUS COMP C, V16, P17
   Nogalski M, 2016, P IEEE VIRT REAL ANN, P245, DOI 10.1109/VR.2016.7504745
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Peck TC, 2012, IEEE T VIS COMPUT GR, V18, P1053, DOI 10.1109/TVCG.2011.289
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Podkosova I., 2015, PROC 25 INT C ARTIF, P109
   Puterman M.L., 2014, Markov decision processes: Discrete stochastic dynamic programming
   Rademacher P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P199, DOI 10.1145/280814.280871
   Razzaque S., 2005, Redirected Walking
   Razzaque S., 2001, P EUR, P289
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Riecke B.E., 2006, ACM T APPL PERCEPT, V3, DOI DOI 10.1145/1166087.1166091
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Rössler P, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5189
   Rothacher Y, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36035-6
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Simons DJ, 2005, TRENDS COGN SCI, V9, P16, DOI 10.1016/j.tics.2004.11.006
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.14506112[45]F
   Steinicke F., 2008, P VIRT REAL INT C, P15
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Su JB, 2007, PRESENCE-VIRTUAL AUG, V16, P385, DOI 10.1162/pres.16.4.385
   Suma E. A., 2015, PROC ACM SIGGRAPH EM, P1
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Thomas J., 2020, PROC 26 ACM S VIRTUA, P1
   Thomas J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P317, DOI [10.1109/VRW50115.2020.00071, 10.1109/VRW50115.2020.0-205]
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Tsabedze T, 2021, INT J INTELL ROBOT, V5, P381, DOI 10.1007/s41315-021-00198-9
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Vasylevska K., 2015, The Visual Language of Technique, P81
   Vasylevska K, 2017, IEEE SYMP 3D USER, P12, DOI 10.1109/3DUI.2017.7893312
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Wang ZY, 2016, PR MACH LEARN RES, V48
   WATSON AB, 1983, PERCEPT PSYCHOPHYS, V33, P113, DOI 10.3758/BF03202828
   Williams B., 2006, Proceedings of the 3rd Symposium on applied Perception in Graphics and visualization (ACM), P21, DOI [10.1145/1140491.1140495, DOI 10.1145/1140491.1140495]
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Yang L., 2011, P SIGGRAPH AS C, P1
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zank M, 2016, VISUAL COMPUT, V32, P1323, DOI 10.1007/s00371-016-1229-9
   Zank M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P49, DOI 10.1109/3DUI.2016.7460030
   Zank M, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P229, DOI 10.1109/CW.2015.20
   Zhang R., 2014, Proc. Proceedings of the 2nd ACM Symposium on Spatial User Interaction, P62, DOI [10.1145/2659766.2659783.177M, DOI 10.1145/2659766.2659783.177M]
   Zhang R., 2013, Proc. Proceedings of the ACM Symposium on Applied Perception (SAP), P71
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 149
TC 14
Z9 14
U1 7
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4104
EP 4123
DI 10.1109/TVCG.2022.3179269
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200006
PM 35639681
DA 2024-11-06
ER

PT J
AU Nakamura, F
   Murakami, M
   Suzuki, K
   Fukuoka, M
   Masai, K
   Sugimoto, M
AF Nakamura, Fumihiko
   Murakami, Masaaki
   Suzuki, Katsuhiro
   Fukuoka, Masaaki
   Masai, Katsutoshi
   Sugimoto, Maki
TI Analyzing the Effect of Diverse Gaze and Head Direction on Facial
   Expression Recognition With Photo-Reflective Sensors Embedded in a
   Head-Mounted Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Facial expression recognition; head-mounted display; embedded
   photo-reflective sensor; gaze direction; face direction
ID FACE RECONSTRUCTION
AB As one of the facial expression recognition techniques for Head-Mounted Display (HMD) users, embedded photo-reflective sensors have been used. In this paper, we investigate how gaze and face directions affect facial expression recognition using the embedded photo-reflective sensors. First, we collected a dataset of five facial expressions (Neutral, Happy, Angry, Sad, Surprised) while looking in diverse directions by moving 1) the eyes and 2) the head. Using the dataset, we analyzed the effect of gaze and face directions by constructing facial expression classifiers in five ways and evaluating the classification accuracy of each classifier. The results revealed that the single classifier that learned the data for all gaze points achieved the highest classification performance. Then, we investigated which facial part was affected by the gaze and face direction. The results showed that the gaze directions affected the upper facial parts, while the face directions affected the lower facial parts. In addition, by removing the bias of facial expression reproducibility, we investigated the pure effect of gaze and face directions in three conditions. The results showed that, in terms of gaze direction, building classifiers for each direction significantly improved the classification accuracy. However, in terms of face directions, there were slight differences between the classifier conditions. Our experimental results implied that multiple classifiers corresponding to multiple gaze and face directions improved facial expression recognition accuracy, but collecting the data of the vertical movement of gaze and face is a practical solution to improving facial expression recognition accuracy.
C1 [Nakamura, Fumihiko; Murakami, Masaaki; Suzuki, Katsuhiro; Fukuoka, Masaaki; Sugimoto, Maki] Keio Univ, Fac Sci & Technol, Yokohama, Kanagawa 2238522, Japan.
   [Masai, Katsutoshi] Keio Univ, NTT Commun Sci Labs, Yokohama, Kanagawa 2430198, Japan.
   [Masai, Katsutoshi] Keio Univ, Fac Sci & Technol, Yokohama, Kanagawa 2238522, Japan.
C3 Keio University; Keio University; Nippon Telegraph & Telephone
   Corporation; Keio University
RP Nakamura, F (corresponding author), Keio Univ, Fac Sci & Technol, Yokohama, Kanagawa 2238522, Japan.
EM f.nakamura@imlab.ics.keio.ac.jp; mmurakami@imlab.ics.keio.ac.jp;
   katsuhirosuzuki@imlab.ics.keio.ac.jp; mskifukuoka@imlab.ics.keio.ac.jp;
   masai@imlab.ics.keio.ac.jp; sugimoto@imlab.ics.keio.ac.jp
OI Fukuoka, Masaaki/0000-0001-7892-4623; Masai,
   Katsutoshi/0000-0001-9768-5314; Nakamura, Fumihiko/0000-0001-6285-3963
FU JST ERATO [JPMJER1701]; JSPS KAKENHI [16H05870];  [21J13664];
   Grants-in-Aid for Scientific Research [21J13664] Funding Source: KAKEN
FX This work was supported in part by JST ERATO under Grant JPMJER1701, in
   part by JSPS KAKENHI under Grant 16H05870, and in part by the in-Aid for
   JSPS Research Fellow for Young Scientists (DC2) under Grant 21J13664.
   This work involved human subjects or animals in its research. Approval
   of allethical and experimental procedures and protocols was granted by
   the ethics committee at the Faculty of Science and Technology, Keio
   University under Application No. 31-69, and performed in line with the
   Declaration of Helsinki
CR Tran AT, 2018, PROC CVPR IEEE, P3935, DOI 10.1109/CVPR.2018.00414
   Annett Michelle., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, UIST '11, P337, DOI DOI 10.1145/2047196.2047240
   Asano Nao, 2017, P 27 INT C ART REAL, P21
   Bedri Abdelkareem, 2015, P ADJ P UBICOMP ISWC, DOI [DOI 10.1145/2800835.2807933, 10.1145/2800835.2807933, DOI 10.1145/2800835]
   Bernal G, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P160, DOI 10.1145/3267242.3267268
   Burgos-Artizzu Xavier P., 2015, Kobe, Japan) 15). SIGGRAPH Asia 2015 Technical Briefs, DOI DOI 10.1145/2820903.2820910
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Fukuoka M, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P9, DOI 10.1145/3355355.3361888
   Futami K, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P624, DOI 10.1145/3341162.3348389
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Hsu GS, 2014, IEEE T INF FOREN SEC, V9, P2110, DOI 10.1109/TIFS.2014.2361028
   Kahou SE, 2016, J MULTIMODAL USER IN, V10, P99, DOI 10.1007/s12193-015-0195-2
   Kratz Sven., 2009, MobileHCI, P1, DOI DOI 10.1145/1613858.1613864
   Lattas A, 2020, PROC CVPR IEEE, P757, DOI 10.1109/CVPR42600.2020.00084
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li R, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P180, DOI 10.1145/3267242.3267265
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Martinez B, 2019, IEEE T AFFECT COMPUT, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   Masai Katsutoshi, 2020, AHs '20: Proceedings of the Augmented Humans International Conference, DOI 10.1145/3384657.3384787
   Masai K, 2020, INT SYM MIX AUGMENT, P374, DOI 10.1109/ISMAR50242.2020.00064
   Masai K, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3012941
   Masai K, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P317, DOI 10.1145/2856767.2856770
   Murakami M, 2019, ACM SIGGRAPH 2019 EMERGING TECHNOLOGIES (SIGGRAPH '19), DOI 10.1145/3305367.3335039
   Ogata Masa., 2013, Proceedings of the ACM Symposium on User Interface Software and Technology (UIST'13), P539, DOI DOI 10.1145/2501988.2502039
   Olszewski K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980252
   Perusquía-Hernández M, 2017, IEEE T AFFECT COMPUT, V8, P522, DOI 10.1109/TAFFC.2017.2755040
   Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009
   Rostaminia Soha, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314410
   Sakashita M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P217, DOI 10.1145/3126594.3126608
   Suzuki K, 2017, P IEEE VIRT REAL ANN, P177, DOI 10.1109/VR.2017.7892245
   Takegawa Y, 2020, INT SYM MIX AUGMENT, P101, DOI 10.1109/ISMAR50242.2020.00030
   Thies J, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201350
   Tuochao Chen, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P112, DOI 10.1145/3379337.3415879
   Wei SE, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323030
   Withana A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3661, DOI 10.1145/2702123.2702371
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhou B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030730
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 41
TC 4
Z9 4
U1 5
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4124
EP 4139
DI 10.1109/TVCG.2022.3179766
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200007
PM 35653450
DA 2024-11-06
ER

PT J
AU Reyes-Aviles, F
   Fleck, P
   Schmalstieg, D
   Arth, C
AF Reyes-Aviles, Fernando
   Fleck, Philipp
   Schmalstieg, Dieter
   Arth, Clemens
TI Compact World Anchors: Registration Using Parametric Primitives as Scene
   Description
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Camera localization; correspondence problem; 3D registration;
   closed-form method; augmented reality
ID POSE ESTIMATION; POINT
AB We present a registration method relying on geometric constraints extracted from parametric primitives contained in 3D parametric models. Our method solves the registration in closed-form from three line-to-line, line-to-plane or plane-to-plane correspondences. The approach either works with semantically segmented RGB-D scans of the scene or with the output of plane detection in common frameworks like ARKit and ARCore. Based on the primitives detected in the scene, we build a list of descriptors using the normals and centroids of all the found primitives, and match them against the pre-computed list of descriptors from the model in order to find the scene-to-model primitive correspondences. Finally, we use our closed-form solver to estimate the 6DOFtransformation from three lines and one point, which we obtain from the parametric representations of the model and scene parametric primitives. Quantitative and qualitative experiments on synthetic and real-world data sets demonstrate the performance and robustness of our method. We show that it can be used to create compact world anchors for indoor localization in AR applications on mobile devices leveraging commercial SLAM capabilities.
C1 [Reyes-Aviles, Fernando] VRVis Competence Ctr Vienna, A-1220 Vienna, Austria.
   [Fleck, Philipp; Schmalstieg, Dieter; Arth, Clemens] Graz Univ Technol, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Reyes-Aviles, F (corresponding author), VRVis Competence Ctr Vienna, A-1220 Vienna, Austria.
EM fernando.reyes-aviles@icg.tugraz.at; philipp.fleck@icg.tugraz.at;
   schmalstieg@tugraz.at; arth@icg.tugraz.at
OI Schmalstieg, Dieter/0000-0003-2813-2235; Reyes-Aviles,
   Fernando/0000-0002-4299-597X
FU Competence Center VRVis; BMK; BMDW; Styria; SFG; Tyrol and Vienna
   Business Agency under the scope of COMET - Competence Centers for
   Excellent Technologies [879730]
FX This work was supported in part by Competence Center VRVis. VRVis is
   funded by BMK, BMDW, Styria, SFG, Tyrol and Vienna Business Agency under
   the scope of COMET - Competence Centers for Excellent Technologies-under
   Grant 879730 managed by FFG.
CR Abdellali H., 2019, P IEEE INT C COMP VI
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Avetisyan A, 2019, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2019.00272
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bhattacharya U, 2019, IEEE I CONF COMP VIS, P5884, DOI 10.1109/ICCV.2019.00598
   Boyd S., 2004, Convex Optimization, DOI 10.1017/CBO9780511804441
   Briales J, 2017, PROC CVPR IEEE, P5612, DOI 10.1109/CVPR.2017.595
   Camposeco F, 2016, LECT NOTES COMPUT SC, V9909, P202, DOI 10.1007/978-3-319-46454-1_13
   CHEN HH, 1991, IEEE T PATTERN ANAL, V13, P530, DOI 10.1109/34.87340
   David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Förstner W, 2017, IEEE INT CONF COMP V, P2165, DOI 10.1109/ICCVW.2017.253
   Gaudillière V, 2019, INT SYM MIX AUGMENT, P8, DOI 10.1109/ISMAR.2019.00017
   Glocker B, 2013, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2013.6671777
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331
   HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Hou J, 2020, PROC CVPR IEEE, P2095, DOI 10.1109/CVPR42600.2020.00217
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Klein G, 2009, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2009.5336495
   Klein George, 2007, P1
   Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9
   Li H., 2007, IEEE INT C COMP VIS, P1, DOI DOI 10.1109/ICCV.2007.4409077
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0_15
   Lourakis M, 2018, IEEE INT C INT ROBOT, P5813, DOI 10.1109/IROS.2018.8594296
   Mateus A, 2020, PROC CVPR IEEE, P7232, DOI 10.1109/CVPR42600.2020.00726
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205
   OLSSON C., 2006, P 2006 IEEE COMP VIS, P1206, DOI DOI 10.1109/CVPR.2006.307
   Olsson C, 2008, INT C PATT RECOG, P2469
   Pathak K, 2010, IEEE T ROBOT, V26, P424, DOI 10.1109/TRO.2010.2042989
   Ramalingam S, 2013, INT J COMPUT VISION, V102, P73, DOI 10.1007/s11263-012-0576-x
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Stanescu A, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P206, DOI 10.1109/ISMAR-Adjunct.2018.00068
   Sweeney C, 2014, LECT NOTES COMPUT SC, V8692, P16, DOI 10.1007/978-3-319-10593-2_2
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Ventura J, 2014, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2014.61
   Wientapper F, 2018, COMPUT VIS IMAGE UND, V173, P57, DOI 10.1016/j.cviu.2018.04.006
   Wuest H, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P346, DOI 10.1109/ISMAR-Adjunct.2016.0114
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Zhang L, 2018, IEEE ACCESS, V6, P75545, DOI [10.1109/ACCESS.2018.2873617, 10.1109/TCBB.2018.2848633]
   Zhang XH, 2012, APPL OPTICS, V51, P936, DOI 10.1364/AO.51.000936
   Zhou LP, 2020, IEEE INT CONF ROBOT, P1308, DOI [10.1109/ICRA40945.2020.9197023, 10.1109/icra40945.2020.9197023]
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
NR 51
TC 4
Z9 4
U1 0
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4140
EP 4153
DI 10.1109/TVCG.2022.3183264
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200008
PM 35704545
DA 2024-11-06
ER

PT J
AU Delaforge, A
   Azé, J
   Bringay, S
   Mollevi, C
   Sallaberry, A
   Servajean, M
AF Delaforge, Alexis
   Aze, Jerome
   Bringay, Sandra
   Mollevi, Caroline
   Sallaberry, Arnaud
   Servajean, Maximilien
TI EBBE-Text: Explaining Neural Networks by Exploring Text Classification
   Decision Boundaries
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Binary text classification; decision boundary; deep learning;
   interpretability; neural networks; representation space; visual
   analytics
ID VISUAL ANALYSIS; ALGORITHM; TOOL
AB While neural networks (NN) have been successfully applied to many NLP tasks, the way they function is often difficult to interpret. In this article, we focus on binary text classification via NNs and propose a new tool, which includes a visualization of the decision boundary and the distances of data elements to this boundary. This tool increases the interpretability of NN. Our approach uses two innovative views: (1) an overview of the text representation space and (2) a local view allowing data exploration around the decision boundary for various localities of this representation space. These views are integrated into a visual platform, EBBE-Text, which also contains state-of-the-art visualizations of NN representation spaces and several kinds of information obtained from the classification process. The various views are linked through numerous interactive functionalities that enable easy exploration of texts and classification results via the various complementary views. A user study shows the effectiveness of the visual encoding and a case study illustrates the benefits of using our tool for the analysis of the classifications obtained with several recent NNs and two datasets.
C1 [Delaforge, Alexis; Aze, Jerome] Univ Montpellier, CNRS, LIRMM, Montpellier, France.
   [Bringay, Sandra; Sallaberry, Arnaud; Servajean, Maximilien] Univ Montpellier, LIRMM, AMIS Res Grp Paul Valery, CNRS, F-34000 Montpellier, France.
   [Mollevi, Caroline] Univ Montpellier, ICM, IDESP, INSERM, F-34000 Montpellier, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Centre National de la Recherche Scientifique (CNRS);
   Universite Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Institut National de la Sante et de la Recherche Medicale
   (Inserm); Universite de Montpellier; UNICANCER; Institut Regional du
   Cancer Montpellier / Val d'Aurelle (ICM)
RP Delaforge, A (corresponding author), Univ Montpellier, CNRS, LIRMM, Montpellier, France.
EM alexis.delaforge@lirmm.fr; Jerome.Aze@lirmm.fr; sandra.bringay@lirmm.fr;
   caroline.mollevi@chu-montpellier.fr; arnaud.sallaberry@lirmm.fr;
   maximilien.servajean@lirmm.fr
RI Bringay, Sandra/IQX-4430-2023; Delaforge, Alexis/JDD-1394-2023;
   Sallaberry, Arnaud/IRY-9056-2023; Servajean, Maximilien/IQW-9683-2023
OI Delaforge, Alexis/0000-0002-7255-8295; Bringay,
   Sandra/0000-0002-2830-3666
FU Region Occitanie; SIRIC Montpellier Cancer [INCa_Inserm_DGOS_12553]
FX This work was supported in part by Region Occitanie [Program "Allocation
   Doctorale 2019"] and in part by SIRIC Montpellier Cancer under Grant
   INCa_Inserm_DGOS_12553.
CR Ahmed H, 2018, SECUR PRIVACY, V1, DOI 10.1002/spy2.9
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Bahdanau D., 2015, 3 INT C LEARN REPR I
   Beaudouin V., 2020, SOCIAL SCI RES NETW
   Bouneffouf D, 2016, COMPUTERS, V5, DOI 10.3390/computers5010001
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Chae J., 2017, PROC WORKSHOP VIS AN
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Delaforge A., 2021, Revue des Nouvelles Technol. de l'Information, VE-37, P169
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   DIMOPOULOS Y, 1995, NEURAL PROCESS LETT, V2, P1, DOI 10.1007/BF02309007
   FORTUNE S, 1987, ALGORITHMICA, V2, P153, DOI 10.1007/BF01840357
   Gal Y, 2017, PR MACH LEARN RES, V70
   Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018
   Goyal Y, 2016, Arxiv, DOI arXiv:1608.08974
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Karpathy A., 2016, PROC INT C LEARN REP
   Laugel T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2801
   Li J., 2016, arXiv
   Lin Z., 2017, ICLR
   Lipton Z. C., 2018, Queue, V16, P31, DOI [10.1145/3236386.3241340, DOI 10.1145/3236386.3241340]
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P241, DOI 10.1109/TVCG.2020.3011155
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mcallister A. J., 1999, Tech. Rep. TR-99-126a
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Melnik O, 2002, MACH LEARN, V48, P321, DOI 10.1023/A:1013968124284
   Migut MA, 2015, DATA MIN KNOWL DISC, V29, P273, DOI 10.1007/s10618-013-0342-x
   Mikolov T., 2013, P 26 C NEUR INF PROC, P3111
   Montavon G., 2019, LNCS (LNAI), V11700, P193, DOI 10.1007/978-3-030-28954-610
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Radford A., 2019, Language models are unsupervised multitask learners, V1, P9
   Raganato Alessandro, 2018, P 2018 EMNLP WORKSHO, DOI DOI 10.18653/V1/W18-5431
   Ramamurthy KN, 2019, PR MACH LEARN RES, V97
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rodrigues FCM, 2019, INFORMATION, V10, DOI 10.3390/info10090280
   Rodriguez-Tello E, 2008, COMPUT OPER RES, V35, P3331, DOI 10.1016/j.cor.2007.03.001
   Seifert C., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P418, DOI 10.1109/ICDMW.2010.181
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Semeniuta S., 2017, P 2017 C EMPIRICAL M, DOI DOI 10.18653/V1/D17-1066
   Sener O., 2018, ICLR
   Settles B., 2011, P 2011 C EMP METH NA, P1467
   Settles B, 2009, ACTIVE LEARNING LIT
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sievert C., 2014, P WORKSH INT LANG LE, P63, DOI [DOI 10.3115/V1/W14-3110, 10.3115/v1/W14-3110, DOI 10.1109/DSAA.2017.61]
   Smilkov D., 2017, PROC 34 INT C MACH L
   Smilkov D., 2016, P ADV NEUR INF PROC, V26
   Springenberg J., 2015, ARXIV
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P63
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Vilone G, 2021, MACH LEARN KNOW EXTR, V3, P615, DOI 10.3390/make3030032
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Waltl Bernhard, 2018, Jusletter IT, V4, P1
   Wang ZJ, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P132
   Wu T., 2019, ACM_Transactions_on Computer-Human_Interaction_, V26, P1
   Xu YB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2565, DOI 10.1145/3219819.3220051
   Yan ZY, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P302, DOI 10.1109/ISKE.2008.4730945
   Zenkel T, 2019, Arxiv, DOI arXiv:1901.11359
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 73
TC 2
Z9 2
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4154
EP 4171
DI 10.1109/TVCG.2022.3184247
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200009
PM 35724275
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, YT
   Guo, YC
   Li, YX
   Wang, C
   Zhang, SH
AF Liu, Ying-Tian
   Guo, Yuan-Chen
   Li, Yi-Xiao
   Wang, Chen
   Zhang, Song-Hai
TI Learning Implicit Glyph Shape Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Task analysis; Rendering (computer graphics); Image resolution;
   Three-dimensional displays; Solid modeling; Graphics; Font generation;
   implicit representation
AB Automatic generation of fonts can greatly facilitate the font design process, and provide prototypes where designers can draw inspiration from. Existing generation methods are mainly built upon rasterized glyph images to utilize the successful convolutional architecture, but ignore the vector nature of glyph shapes. We present an implicit representation, modeling each glyph as shape primitives enclosed by several quadratic curves. This structured implicit representation is shown to be better suited for glyph modeling, and enables rendering glyph images at arbitrary high resolutions. Our representation gives high-quality glyph reconstruction and interpolation results, and performs well on the challenging one-shot font style transfer task comparing to other alternatives both qualitatively and quantitatively.
C1 [Liu, Ying-Tian; Guo, Yuan-Chen; Wang, Chen; Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Liu, Ying-Tian; Guo, Yuan-Chen; Wang, Chen; Zhang, Song-Hai] Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Li, Yi-Xiao] Tsinghua Univ, Acad Arts & Design, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.; Zhang, SH (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
EM liuyingt20@mails.tsinghua.edu.cn; guoyc19@mails.tsinghua.edu.cn;
   liyixiao20@mails.tsinghua.edu.cn; cw.chenwang@outlook.com;
   shz@tsinghua.edu.cn
RI ; Wang, Chen/JPK-7141-2023
OI Liu, Ying-Tian/0000-0001-8293-3223; Wang, Chen/0000-0002-9315-3780
FU National Natural Science Foundation of China [61832016]; Research Grant
   of Beijing Higher Institution Engineering Research Center and
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61832016, in part by the Research Grant
   of Beijing Higher Institution Engineering Research Center and
   Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology.
CR Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Balashova E, 2019, COMPUT GRAPH FORUM, V38, P429, DOI 10.1111/cgf.13540
   Blinn J. F., 1982, Computer Graphics, V16, DOI 10.1145/965145.801290
   Campbell NDF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601212
   Carlier A., 2020, PROC 34 INT C NEURAL
   Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chlumsky V, 2018, COMPUT GRAPH FORUM, V37, P273, DOI 10.1111/cgf.13265
   Deng BY, 2020, PROC CVPR IEEE, P31, DOI 10.1109/CVPR42600.2020.00011
   Fabris A. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P317, DOI 10.1145/258734.258874
   Gao YC, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P33, DOI 10.1145/3355088.3365142
   Gao Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356574
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Green C., 2007, ACM SIGGRAPH 2007 CO, P9
   Gupta S., 1981, Computer Graphics, V15, P1, DOI 10.1145/965161.806783
   Hayashi H, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104927
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ioffe Sergey, 2015, P MACHINE LEARNING R, V37, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Kingma D.P., 2014, P INT C LEARNING REP
   Kingma DP, 2013, ARXIV
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Lian Z, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3213767
   Lin XM, 2019, MULTIMED TOOLS APPL, V78, P783, DOI 10.1007/s11042-017-5457-4
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Loop C, 2005, ACM T GRAPHIC, V24, P1000, DOI 10.1145/1073204.1073303
   Lopes RG, 2019, IEEE I CONF COMP VIS, P7929, DOI 10.1109/ICCV.2019.00802
   Maas A. L., 2013, P ICML ATL GEORG US
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Reddy P, 2021, ADV NEUR IN, V34
   Reddy P, 2021, PROC CVPR IEEE, P7338, DOI 10.1109/CVPR46437.2021.00726
   RICCI A, 1973, COMPUT J, V16, P157, DOI 10.1093/comjnl/16.2.157
   Roy P, 2020, PROC CVPR IEEE, P13225, DOI 10.1109/CVPR42600.2020.01324
   Smirnov D, 2020, PROC CVPR IEEE, P558, DOI 10.1109/CVPR42600.2020.00064
   Suveeranont R, 2010, LECT NOTES COMPUT SC, V6133, P127, DOI 10.1007/978-3-642-13544-6_12
   TAUBIN G, 1994, ACM T GRAPHIC, V13, P3, DOI 10.1145/174462.174531
   Wang YZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480488
   Wang YZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392456
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang S, 2019, AAAI CONF ARTIF INTE, P1238
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 43
TC 0
Z9 0
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4172
EP 4182
DI 10.1109/TVCG.2022.3183400
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200010
PM 35709112
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, YY
   Jiang, GY
   Yu, M
   Xu, HY
   Ho, YS
AF Chen, Yeyao
   Jiang, Gangyi
   Yu, Mei
   Xu, Haiyong
   Ho, Yo-Sung
TI Deep Light Field Spatial Super-Resolution Using Heterogeneous Imaging
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Spatial resolution; Superresolution; Visualization; Image
   reconstruction; Light fields; Training; Light field; heterogeneous
   imaging; spatial super-resolution; pyramid reconstruction
ID RESOLUTION; CAMERAS
AB Light field (LF) imaging expands traditional imaging techniques by simultaneously capturing the intensity and direction information of light rays, and promotes many visual applications. However, owing to the inherent trade-off between the spatial and angular dimensions, LF images acquired by LF cameras usually suffer from low spatial resolution. Many current approaches increase the spatial resolution by exploring the four-dimensional (4D) structure of the LF images, but they have difficulties in recovering fine textures at a large upscaling factor. To address this challenge, this paper proposes a new deep learning-based LF spatial super-resolution method using heterogeneous imaging (LFSSR-HI). The designed heterogeneous imaging system uses an extra high-resolution (HR) traditional camera to capture the abundant spatial information in addition to the LF camera imaging, where the auxiliary information from the HR camera is utilized to super-resolve the LF image. Specifically, an LF feature alignment module is constructed to learn the correspondence between the 4D LF image and the 2D HR image to realize information alignment. Subsequently, a multi-level spatial-angular feature enhancement module is designed to gradually embed the aligned HR information into the rough LF features. Finally, the enhanced LF features are reconstructed into a super-resolved LF image using a simple feature decoder. To improve the flexibility of the proposed method, a pyramid reconstruction strategy is leveraged to generate multi-scale super-resolution results in one forward inference. The experimental results show that the proposed LFSSR-HI method achieves significant advantages over the state-of-the-art methods in both qualitative and quantitative comparisons. Furthermore, the proposed method preserves more accurate angular consistency.
C1 [Chen, Yeyao; Jiang, Gangyi; Yu, Mei; Xu, Haiyong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Ho, Yo-Sung] Gwangju Inst Sci & Technol, Sch Elect Engn & Comp Sci, Gwangju 61005, South Korea.
C3 Ningbo University; Gwangju Institute of Science & Technology (GIST)
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM cyy941027@126.com; jianggangyi@nbu.edu.cn; yumei2@126.com;
   xuhaiyong@nbu.edu.cn; hoyo@gist.ac.kr
RI jiang, gang/KII-8233-2024
OI HO, YO-SUNG/0000-0002-7220-1034; Xu, Haiyong/0000-0003-1590-6799
FU Natural Science Foundation of China [62071266, 61871247, 61931022,
   62171243, U1301257]; Natural Science Foundation of Ningbo [202003N4088];
   K. C. Wong Magna Fund at Ningbo University.
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 62071266, 61871247, 61931022, 62171243 and U1301257,
   in part by the Natural Science Foundation of Ningbo under Grant
   202003N4088, and in part by the K. C. Wong Magna Fund at Ningbo
   University.
CR Alam MZ, 2018, MACH VISION APPL, V29, P11, DOI 10.1007/s00138-017-0862-2
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Anwar S, 2022, IEEE T PATTERN ANAL, V44, P1192, DOI 10.1109/TPAMI.2020.3021088
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Boominathan V, 2014, IEEE INT CONF COMPUT
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Farrugia RA, 2017, IEEE J-STSP, V11, P1058, DOI 10.1109/JSTSP.2017.2747127
   Ghassab VK, 2020, IEEE T MULTIMEDIA, V22, P1447, DOI 10.1109/TMM.2019.2946094
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Haris M, 2021, IEEE T PATTERN ANAL, V43, P4323, DOI 10.1109/TPAMI.2020.3002836
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Honauer K, 2017, LECT NOTES COMPUT SC, V10113, P19, DOI 10.1007/978-3-319-54187-7_2
   Jayaweera SS, 2021, IEEE SIGNAL PROC LET, V28, P31, DOI 10.1109/LSP.2020.3043990
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Jin J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P193, DOI 10.1145/3394171.3413585
   Jin J, 2020, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR42600.2020.00233
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kingma DP, 2014, ADV NEUR IN, V27
   Koniaris C, 2019, IEEE T VIS COMPUT GR, V25, P1666, DOI 10.1109/TVCG.2018.2818156
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Le Pendu M, 2018, IEEE T IMAGE PROCESS, V27, P1981, DOI 10.1109/TIP.2018.2791864
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Ma DZ, 2020, IEEE IMAGE PROC, P2970, DOI 10.1109/ICIP40778.2020.9190751
   Meng XX, 2021, IEEE T VIS COMPUT GR, V27, P3350, DOI 10.1109/TVCG.2020.2975801
   Mignard-Debise L, 2019, IEEE T COMPUT IMAG, V5, P585, DOI 10.1109/TCI.2019.2911856
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3790, DOI 10.1109/TIP.2020.2966081
   Mitra K., 2012, 2012 IEEE COMPUTER S, P22
   Raj A.S., Stanford Lytro Light Field Archive
   Rerabek M., 2016, PROC 8 INT C QUAL MU
   Rossi M, 2018, IEEE T IMAGE PROCESS, V27, P4207, DOI 10.1109/TIP.2018.2828983
   Song ZX, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102847
   Vaish V., 2008, The (new) Stanford light field archive, V6
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang YQ, 2021, IEEE T IMAGE PROCESS, V30, P1057, DOI 10.1109/TIP.2020.3042059
   Wang YL, 2018, IEEE T IMAGE PROCESS, V27, P4274, DOI 10.1109/TIP.2018.2834819
   Wang YW, 2017, IEEE T VIS COMPUT GR, V23, P2357, DOI 10.1109/TVCG.2016.2628743
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanner S., 2013, Proc. Vision, Modeling & Visual, V13, P225
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Yang FZ, 2020, PROC CVPR IEEE, P5790, DOI 10.1109/CVPR42600.2020.00583
   Yeung HWF, 2019, IEEE T IMAGE PROCESS, V28, P2319, DOI 10.1109/TIP.2018.2885236
   Yingqian Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P290, DOI 10.1007/978-3-030-58592-1_18
   Yoon Y, 2017, IEEE SIGNAL PROC LET, V24, P848, DOI 10.1109/LSP.2017.2669333
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Zhang JH, 2019, IEEE T VIS COMPUT GR, V25, P1603, DOI 10.1109/TVCG.2018.2810279
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao MD, 2018, IEEE T COMPUT IMAG, V4, P406, DOI 10.1109/TCI.2018.2838457
   Zheng HT, 2017, IEEE INT CONF COMP V, P2481, DOI 10.1109/ICCVW.2017.292
   Zhou WH, 2020, IEEE T IMAGE PROCESS, V29, P1606, DOI 10.1109/TIP.2019.2944343
   Zhu H, 2021, IEEE T VIS COMPUT GR, V27, P3019, DOI 10.1109/TVCG.2019.2957761
NR 53
TC 8
Z9 8
U1 4
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4183
EP 4197
DI 10.1109/TVCG.2022.3184047
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200011
PM 35714091
DA 2024-11-06
ER

PT J
AU Nguyen, N
   Bohak, C
   Engel, D
   Mindek, P
   Strnad, O
   Wonka, P
   Li, S
   Ropinski, T
   Viola, I
AF Nguyen, Ngan
   Bohak, Ciril
   Engel, Dominik
   Mindek, Peter
   Strnad, Ondrej
   Wonka, Peter
   Li, Sai
   Ropinski, Timo
   Viola, Ivan
TI Finding Nano-Otzi: Cryo-Electron Tomography Visualization Guided by
   Learned Segmentation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Image segmentation; Visualization; Task analysis;
   Three-dimensional displays; Signal to noise ratio; Noise measurement;
   Volume rendering; computer graphics techniques; machine learning
   techniques; scalar field data; life sciences
ID IMAGE SEGMENTATION; CRYO-EM; HISTOGRAMS; ENTROPY; DESIGN
AB Cryo-electron tomography (cryo-ET) is a new 3D imaging technique with unprecedented potential for resolving submicron structural details. Existing volume visualization methods, however, are not able to reveal details of interest due to low signal-to-noise ratio. In order to design more powerful transfer functions, we propose leveraging soft segmentation as an explicit component of visualization for noisy volumes. Our technical realization is based on semi-supervised learning, where we combine the advantages of two segmentation algorithms. First, the weak segmentation algorithm provides good results for propagating sparse user-provided labels to other voxels in the same volume and is used to generate dense pseudo-labels. Second, the powerful deep-learning-based segmentation algorithm learns from these pseudo-labels to generalize the segmentation to other unseen volumes, a task that the weak segmentation algorithm fails at completely. The proposed volume visualization uses deep-learning-based segmentation as a component for segmentation-aware transfer function design. Appropriate ramp parameters can be suggested automatically through frequency distribution analysis. Furthermore, our visualization uses gradient-free ambient occlusion shading to further suppress the visual presence of noise, and to give structural detail the desired prominence. The cryo-ET data studied in our technical experiments are based on the highest-quality tilted series of intact SARS-CoV-2 virions. Our technique shows the high impact in target sciences for visual data analysis of very noisy volumes that cannot be visualized with existing techniques.
C1 [Nguyen, Ngan; Bohak, Ciril; Strnad, Ondrej; Wonka, Peter; Viola, Ivan] King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
   [Engel, Dominik; Ropinski, Timo] Ulm Univ, D-89081 Ulm, Germany.
   [Mindek, Peter] TU Wien, Nanograph GmbH, A-1040 Vienna, Austria.
   [Li, Sai] Tsinghua Univ, Sch Life Sci, Beijing 100190, Peoples R China.
C3 King Abdullah University of Science & Technology; Ulm University;
   Technische Universitat Wien; Tsinghua University
RP Nguyen, N; Bohak, C (corresponding author), King Abdullah Univ Sci & Technol, Thuwal 23955, Saudi Arabia.
EM ngan.nguyen@kaust.edu.sa; ciril.bohak@fri.uni-lj.si;
   dominik.engel@uni-ulm.de; mindek@cg.tuwien.ac.at;
   ondrej.strnad@kaust.edu.sa; peter.wonka@kaust.edu.sa;
   sai@tsinghua.edu.cn; timo.ropinski@uni-ulm.de; ivan.viola@kaust.edu.sa
RI Strnad, Ondřej/GXV-9172-2022; Li, Sai/AAC-5187-2019; Viola,
   Ivan/O-8944-2014
OI Viola, Ivan/0000-0003-4248-6574; Engel, Dominik/0000-0002-5766-7215;
   Nguyen, Hoang Ngan/0000-0003-0054-801X; Strnad,
   Ondrej/0000-0002-8077-4692; Ropinski, Timo/0000-0002-7857-5512; Bohak,
   Ciril/0000-0002-9015-2897; Wonka, Peter/0000-0003-0627-9746; Li,
   Sai/0000-0002-9353-0355
FU Tsinghua University Spring Breeze Fund [2021Z99CFZ004]; National Natural
   Science Foundation of China [32171195]; King Abdullah University of
   Science and Technology (KAUST) [BAS/1/1680-01-01]; KAUST Visualization
   Core Lab; Baden-Wurt-temberg Stiftung through ABEM Project
FX The work of Sai Li was supported in part by Tsinghua University Spring
   Breeze Fund under Grant 2021Z99CFZ004, and in part by the National
   Natural Science Foundation of China under Grant 32171195. This work was
   supported in part by the King Abdullah University of Science and
   Technology (KAUST) under Grant BAS/1/1680-01-01, in part by KAUST
   Visualization Core Lab, in part by the Baden-Wurt-temberg Stiftung
   through ABEM Project.
CR Bepler T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18952-1
   Berg S, 2019, NAT METHODS, V16, P1226, DOI 10.1038/s41592-019-0582-9
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Bergman LD, 1995, VISUALIZATION '95 - PROCEEDINGS, P118, DOI 10.1109/VISUAL.1995.480803
   Bortsova G, 2019, LECT NOTES COMPUT SC, V11769, P810, DOI 10.1007/978-3-030-32226-7_90
   Buchholz TO, 2019, I S BIOMED IMAGING, P502, DOI [10.1109/isbi.2019.8759519, 10.1109/ISBI.2019.8759519]
   Cai L, 2013, COMPUT MED IMAG GRAP, V37, P450, DOI 10.1016/j.compmedimag.2013.08.008
   Chen C, 2020, FRONT CARDIOVASC MED, V7, DOI 10.3389/fcvm.2020.00025
   Chen M, 2019, NAT METHODS, V16, P1161, DOI 10.1038/s41592-019-0591-8
   Cheng HC, 2019, IEEE T VIS COMPUT GR, V25, P1378, DOI 10.1109/TVCG.2018.2796085
   CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P192, DOI 10.1109/TVCG.2010.35
   Diepenbrock S, 2011, IEEE COMPUT GRAPH, V31, P6, DOI 10.1109/MCG.2011.70
   DOYLE W, 1962, J ACM, V9, P259, DOI 10.1145/321119.321123
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Bui TD, 2017, Arxiv, DOI arXiv:1709.03199
   Garcia-Garcia A, 2017, Arxiv, DOI [arXiv:1704.06857, 10.48550/arXiv.1704.06857, DOI 10.48550/ARXIV.1704.06857]
   GLASBEY CA, 1993, CVGIP-GRAPH MODEL IM, V55, P532, DOI 10.1006/cgip.1993.1040
   Gros C, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102038
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Huang XR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20945-6
   Jumper J., 2020, P 14 CRIT ASS TECHN, V22
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Kingma DP, 2014, ADV NEUR IN, V27
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Koning RI, 2018, ANN ANAT, V217, P82, DOI 10.1016/j.aanat.2018.02.004
   Krull A, 2019, PROC CVPR IEEE, P2124, DOI 10.1109/CVPR.2019.00223
   Kühlbrandt W, 2014, SCIENCE, V343, P1443, DOI 10.1126/science.1251652
   Lee D.H., 2013, P WORKSH CHALL REPR, VVolume 3, P896
   Lee KS, 2017, Arxiv, DOI [arXiv:1706.00120, 10.48550/arXiv.1706.00120, DOI 10.48550/ARXIV.1706.00120]
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Leigh KE, 2019, METHOD CELL BIOL, V152, P217, DOI 10.1016/bs.mcb.2019.04.003
   Lequan Yu, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P287, DOI 10.1007/978-3-319-66185-8_33
   Li CH, 1998, PATTERN RECOGN LETT, V19, P771, DOI 10.1016/S0167-8655(98)00057-9
   Lindholm S, 2010, IEEE T VIS COMPUT GR, V16, P1301, DOI 10.1109/TVCG.2010.195
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu C, 2020, STRUCTURE, V28, P1218, DOI 10.1016/j.str.2020.10.001
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   Lundström C, 2006, IEEE T VIS COMPUT GR, V12, P1570, DOI 10.1109/TVCG.2006.100
   Luo S., 2017, P 33 SPRING C COMP G, P1, DOI 10.1145/3154353.3154357
   Ma B, 2018, IEEE T VIS COMPUT GR, V24, P3253, DOI 10.1109/TVCG.2017.2776935
   Mastronarde DN, 2017, J STRUCT BIOL, V197, P102, DOI 10.1016/j.jsb.2016.07.011
   Micikevicius P, 2017, arXiv
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Moebel E, 2021, NAT METHODS, V18, P1386, DOI 10.1038/s41592-021-01275-4
   Niblack W, 1985, An introduction to digital image processing
   Oktay O, 2018, Arxiv, DOI [arXiv:1804.03999, 10.48550/arXiv.1804.03999]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paszke A, 2019, ADV NEUR IN, V32
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   Phansalkar Neerad, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P218, DOI 10.1109/ICCSP.2011.5739305
   Prassni JS, 2010, IEEE T VIS COMPUT GR, V16, P1358, DOI 10.1109/TVCG.2010.208
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schur FKM, 2019, CURR OPIN STRUC BIOL, V58, P1, DOI 10.1016/j.sbi.2019.03.018
   SHANBHAG AG, 1994, CVGIP-GRAPH MODEL IM, V56, P414, DOI 10.1006/cgip.1994.1037
   Shigematsu H, 2013, ULTRAMICROSCOPY, V131, P61, DOI 10.1016/j.ultramic.2013.04.001
   Siddique N, 2021, IEEE ACCESS, V9, P82031, DOI 10.1109/ACCESS.2021.3086020
   Soille P., 2004, MORPHOLOGICAL IMAGE, DOI [DOI 10.1007/978-3-662-03939-7, DOI 10.1007/978-3-662-05088-0]
   Su M, 2018, bioRxiv, DOI [10.1101/256792, 10.1101/256792, DOI 10.1101/256792]
   Bui TD, 2019, BIOMED SIGNAL PROCES, V54, DOI 10.1016/j.bspc.2019.101613
   Bui TD, 2019, LECT NOTES COMPUT SC, V11383, P378, DOI 10.1007/978-3-030-11723-8_38
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Vatani N., 2015, Open Access Library J., V2, DOI [10.4236/oalib.1101203, DOI 10.4236/OALIB.1101203]
   Veach E., 1997, ROBUST MONTE CARLO M
   Wang XY, 2019, IEEE I CONF COMP VIS, P6970, DOI 10.1109/ICCV.2019.00707
   Yao HP, 2020, CELL, V183, P730, DOI 10.1016/j.cell.2020.09.018
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   ZACK GW, 1977, J HISTOCHEM CYTOCHEM, V25, P741, DOI 10.1177/25.7.70454
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00689-1_1, 10.1007/978-3-030-00889-5_1]
   Zhu WT, 2019, MED PHYS, V46, P576, DOI 10.1002/mp.13300
NR 82
TC 6
Z9 6
U1 0
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4198
EP 4214
DI 10.1109/TVCG.2022.3186146
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200012
PM 35749328
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Gu, X
   Li, S
   Yi, KR
   Yang, XJ
   Liu, HL
   Wang, GP
AF Gu, Xiang
   Li, Sheng
   Yi, Kangrui
   Yang, Xiaojuan
   Liu, Huiling
   Wang, Guoping
TI Role-Exchange Playing: An Exploration of Role-Playing Effects for
   Anti-Bullying in Immersive Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Virtual environments; Cognition; Medical treatment; Ethics;
   Training; Psychology; Role-exchange; role-playing; role reversal;
   anti-bullying; minor education; virtual reality
ID PERSPECTIVE-TAKING; PARTICIPANT ROLES; REALITY; EMBODIMENT;
   VICTIMIZATION; STEREOTYPE; CHILDREN; SKILLS; BIAS; US
AB Role-playing is widely used in many areas, such as psychotherapy and behavior change. However, few studies have explored the possible effects of playing multiple roles in a single role-playing process. We propose a new role-playing paradigm, called role-exchange playing, in which a user plays two opposite roles successively in the same simulated event for better cognitive enhancement. We designed an experiment with this novel role-exchange playing strategy in the immersive virtual environments; and school bullying was chosen as a scenario in this case. A total of 234 middle/high school students were enrolled in the mixed-design experiment. From the user study, we found that through role-exchange, students developed more morally correct opinions about bullying, as well as increased empathy and willingness to engage in supportive behavior. They also showed increased commitment to stopping bullying others. Our role-exchange paradigm could achieve a better effect than traditional role-playing methods in situations where participants have no prior experience associated with the roles they play. Therefore, using role-exchange playing in the immersive virtual environments to educate minors can help prevent them from bullying others in the real world. Our study indicates a positive significance in moral education of teenagers. Our role-exchange playing may have the potential to be extended to such applications as counseling, therapy, and crime prevention.
C1 [Gu, Xiang; Li, Sheng; Yi, Kangrui; Liu, Huiling; Wang, Guoping] Peking Univ, Beijing 100871, Peoples R China.
   [Yang, Xiaojuan] Shandong Normal Univ, Jinan 250061, Shandong, Peoples R China.
   [Liu, Huiling] Lamar Univ, Beaumont, TX 77705 USA.
C3 Peking University; Shandong Normal University; Texas State University
   System; Lamar University
RP Li, S (corresponding author), Peking Univ, Beijing 100871, Peoples R China.
EM gu.xiang@pku.edu.cn; lisheng@pku.edu.cn; yikangrui@pku.edu.cn;
   yxjuan08@126.com; hliu3@lamar.edu; wgp@pku.edu.cn
RI wang, guoping/KQU-3394-2024
OI Gu, Xiang/0000-0002-8527-9113; Li, Sheng/0000-0002-8901-2184
FU National Key R & D Program of China [2021YFF0500901]; National Natural
   Science Foundation of China [62172013]
FX This work was supported in part by the National Key R & D Program of
   China under Grant 2021YFF0500901, and in part by the National Natural
   Science Foundation of China under Grant 62172013.
CR Abeditehrani Hanieh, 2020, Clin Psychol Eur, V2, pe2693, DOI 10.32872/cpe.v2i1.2693
   Abeditehrani H, 2021, J BEHAV THER EXP PSY, V70, DOI 10.1016/j.jbtep.2020.101599
   Ahir K., 2019, AUGMENT HUM RES, V5, P7, DOI DOI 10.1007/S41133-019-0025-2
   Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Bailenson J, 2018, JAMA PEDIATR, V172, P905, DOI 10.1001/jamapediatrics.2018.1909
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Bissonnette J, 2016, VIRTUAL REAL-LONDON, V20, P71, DOI 10.1007/s10055-016-0283-y
   Borg M., 1998, EDUC PSYCHOL-UK, V18, P433, DOI [10.1080/0144341980180405, DOI 10.1080/0144341980180405]
   Chen A, 2018, ACAD PSYCHIATR, V42, P362, DOI 10.1007/s40596-017-0862-6
   Chen JC, 2015, J TRANSFORM EDUC, V13, P85, DOI 10.1177/1541344614560196
   Chowdhury TI, 2021, IEEE T VIS COMPUT GR, V27, P3079, DOI 10.1109/TVCG.2019.2958332
   Christ Marc, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8086914
   Cobb S., 2008, PROC 10 VIRTUAL REAL, P75
   Cowie H., 2012, Handbook of Youth Prevention Science, P177
   Crawford C. R., 2011, THESIS MCGILL U LIB
   Donohoe P., 2020, Int. J. Bullying Prevention, V2, P264
   Fominykh M., 2018, Journal of Interactive Learning Research, V29, P169
   Garcia-Palacios A, 2001, CYBERPSYCHOL BEHAV, V4, P341, DOI 10.1089/109493101300210231
   Gehlbach H, 2004, EDUC PSYCHOL REV, V16, P207, DOI 10.1023/B:EDPR.0000034021.12899.11
   Gillath O, 2008, MEDIA PSYCHOL, V11, P259, DOI 10.1080/15213260801906489
   Görzig A, 2013, J CHILD MEDIA, V7, P9, DOI 10.1080/17482798.2012.739756
   Gonzalez-Liencres C, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00820
   Groom V, 2009, SOC INFLUENCE, V4, P231, DOI 10.1080/15534510802643750
   Gutierrez B, 2014, GAMES HEALTH J, V3, P371, DOI 10.1089/g4h.2013.0071
   Hale A. E., 1986, Conducting Clin. Sociometric Explorations: A Manual for Psychodramatists and Sociometrists
   Hasler BS, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174965
   Heydenberk RA, 2006, CONFL RESOLUT Q, V24, P55, DOI 10.1002/crq.157
   Hsu J. C., 1999, Mult. comparisons: Theory and methods
   Ingram KM, 2019, J ADOLESCENCE, V71, P72, DOI 10.1016/j.adolescence.2018.12.006
   Ivanov L., 2020, 33 INT FLAIRS C, V2020, P312
   Jackson PL, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00112
   Jouriles EN, 2009, BEHAV THER, V40, P337, DOI 10.1016/j.beth.2008.09.002
   Karna A, 2011, CHILD DEV, V82, P311, DOI 10.1111/j.1467-8624.2010.01557.x
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kyriacou C, 2016, BRIT EDUC RES J, V42, P631, DOI 10.1002/berj.3225
   Lebrun-Harris LA, 2019, J CHILD FAM STUD, V28, P2543, DOI 10.1007/s10826-018-1170-9
   Li S., 2020, IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2020.3044563, DOI 10.1109/TVCG.2020.3044563]
   Louie AK, 2018, ACAD PSYCHIATR, V42, P747, DOI 10.1007/s40596-018-0995-2
   MCGREGOR J, 1993, J EDUC RES, V86, P215, DOI 10.1080/00220671.1993.9941833
   Meister L, 2015, TRENDS COGN SCI, V19, P6, DOI 10.1016/j.tics.2014.11.001
   Moreno J. L., 1952, Group Psychother., V4, P243
   Nair BT, 2019, J EDUC HEALTH PROMOT, V8, DOI 10.4103/jehp.jehp_162_18
   Oh SY, 2016, COMPUT HUM BEHAV, V60, P398, DOI 10.1016/j.chb.2016.02.007
   Olweus D, 2020, SCAND J PSYCHOL, V61, P108, DOI 10.1111/sjop.12486
   Olweus D, 2010, AM J ORTHOPSYCHIAT, V80, P124, DOI 10.1111/j.1939-0025.2010.01015.x
   Padgett S., 2013, UNIVERSAL J ED RES, V1, P33, DOI [10.13189/ujer.2013.010201, DOI 10.13189/UJER.2013.010201]
   Pang H., 2018, Ment. Health Educ. Primary Secondary Sch., V16, P4
   PAULHUS DL, 1984, J PERS SOC PSYCHOL, V46, P598, DOI 10.1037/0022-3514.46.3.598
   Peck TC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376419
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pedram S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.106223
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Polanin JR, 2012, SCHOOL PSYCHOL REV, V41, P47
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Price M, 2007, J ANXIETY DISORD, V21, P742, DOI 10.1016/j.janxdis.2006.11.002
   Reinhard R, 2020, MEDIA PSYCHOL, V23, P293, DOI 10.1080/15213269.2019.1598435
   Rizzo AA, 2004, NEUROPSYCHOL REHABIL, V14, P207, DOI 10.1080/09602010343000183
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salmivalli C, 1996, AGGRESSIVE BEHAV, V22, P1, DOI 10.1002/(SICI)1098-2337(1996)22:1<1::AID-AB1>3.0.CO;2-T
   Salmivalli C, 2014, THEOR PRACT, V53, P286, DOI 10.1080/00405841.2014.947222
   Sassenberg K, 2005, J EXP SOC PSYCHOL, V41, P506, DOI 10.1016/j.jesp.2004.10.002
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Spencer S, 2019, J EDUC COMPUT RES, V57, P1772, DOI 10.1177/0735633119855613
   Stanton D, 1998, ST HEAL T, V58, P219
   Thornberg R, 2012, WEST J EMERG MED, V13, P247, DOI 10.5811/westjem.2012.3.11792
   Vala M., 2007, P 6 INT JOINT C AUT, P1
   Veenstra R, 2005, DEV PSYCHOL, V41, P672, DOI 10.1037/0012-1649.41.4.672
   Wang N, 2018, 18TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (IVA'18), P219, DOI 10.1145/3267851.3267913
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 72
TC 11
Z9 11
U1 18
U2 61
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4215
EP 4228
DI 10.1109/TVCG.2022.3184986
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200013
PM 35727780
DA 2024-11-06
ER

PT J
AU Zhang, WX
   Zhou, HJ
   Dong, Z
   Liu, J
   Yan, QA
   Xiao, CX
AF Zhang, Wenxiao
   Zhou, Huajian
   Dong, Zhen
   Liu, Jun
   Yan, Qingan
   Xiao, Chunxia
TI Point Cloud Completion Via Skeleton-Detail Transformer
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud; point cloud completion; shape completion
ID SHAPE
AB Point cloud shape completion plays a central role in diverse 3D vision and robotics applications. Early methods used to generate global shapes without local detail refinement. Current methods tend to leverage local features to preserve the observed geometric details. However, they usually adopt the convolutional architecture over the incomplete point cloud to extract local features to restore the diverse information of both latent shape skeleton and geometric details, where long-distance correlation among the skeleton and details is ignored. In this work, we present a coarse-to-fine completion framework, which makes full use of both neighboring and long-distance region cues for point cloud completion. Our network leverages a Skeleton-Detail Transformer, which contains cross-attention and self-attention layers, to fully explore the correlation from local patterns to global shape and utilize it to enhance the overall skeleton. Also, we propose a selective attention mechanism to save memory usage in the attention process without significantly affecting performance. We conduct extensive experiments on the ShapeNet dataset and real-scanned datasets. Qualitative and quantitative evaluations demonstrate that our proposed network outperforms current state-of-the-art methods.
C1 [Zhang, Wenxiao; Zhou, Huajian; Xiao, Chunxia] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
   [Dong, Zhen] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Liu, Jun] Singapore Univ Technol & Design, Singapore 487372, Singapore.
   [Yan, Qingan] InnoPeak Technol Inc, Palo Alto, CA 94303 USA.
C3 Wuhan University; Wuhan University; Singapore University of Technology &
   Design
RP Xiao, CX (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM wenxxiao.zhang@gmail.com; eagle_zhou@foxmail.com;
   dongzhenwhu@whu.edu.cn; jun_liu@sutd.edu.sg; yanqinganssg@gmail.com;
   cxxiao@whu.edu.cn
RI Zhang, Wenxiao/KCK-3295-2024
OI Liu, Jun/0000-0002-4365-4165; Dong, Zhen/0000-0002-0152-3300; ZHANG,
   WENXIAO/0000-0001-8680-6010
FU Key Technological Innovation Projects of Hubei Province [2018AAA062];
   NSFC [61972298]; Wuhan University-Huawei GeoInformatices Innovation Lab
FX This work was supported in part by the Key Technological Innovation
   Projects of Hubei Province under Grant 2018AAA062, in part by NSFC under
   Grant 61972298, and in part by Wuhan University-Huawei GeoInformatices
   Innovation Lab.
CR Cao T., 2022, PROC IEEECVF C COMPU, P3783
   Chang A. X., 2015, Tech. Rep. 1
   Chen X., 2020, INT C LEARN REPR
   Dai A, 2018, PROC CVPR IEEE, P4578, DOI 10.1109/CVPR.2018.00481
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2020, ARXIV201011929, DOI 10.48550/arXiv.2010.11929
   Engel N, 2021, IEEE ACCESS, V9, P134826, DOI 10.1109/ACCESS.2021.3116304
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   Hu H, 2019, IEEE I CONF COMP VIS, P3463, DOI 10.1109/ICCV.2019.00356
   Huang T., 2021, P IEEE CVF INT C COM, p12 508
   Huang ZT, 2020, PROC CVPR IEEE, P7659, DOI 10.1109/CVPR42600.2020.00768
   Hui H., 2021, P IEEE INT C COMPUTE, P6098
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kim YM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366157
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Li DP, 2017, IEEE T VIS COMPUT GR, V23, P1809, DOI 10.1109/TVCG.2016.2553102
   Li YY, 2015, COMPUT GRAPH FORUM, V34, P435, DOI 10.1111/cgf.12573
   Liu MH, 2020, AAAI CONF ARTIF INTE, V34, P11596
   Mildenhall B., 2020, PROC IEEECVF C COMPU, P7463
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Nie Y., 2020, Adv. Neural Inf. Process. Syst., V33, P16119
   Pan L, 2021, PROC CVPR IEEE, P8520, DOI 10.1109/CVPR46437.2021.00842
   Pan L, 2020, IEEE INT CONF ROBOT, P1113, DOI [10.1109/ICRA40945.2020.9197499, 10.1109/icra40945.2020.9197499]
   Pan L, 2020, IEEE ROBOT AUTOM LET, V5, P4392, DOI 10.1109/LRA.2020.2994483
   Pan XR, 2021, PROC CVPR IEEE, P7459, DOI 10.1109/CVPR46437.2021.00738
   Pauly M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360642
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Ramachandran P, 2019, ADV NEUR IN, V32
   Richard A, 2020, INT CONF 3D VISION, P101, DOI 10.1109/3DV50981.2020.00020
   Rundi Wu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P281, DOI 10.1007/978-3-030-58548-8_17
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Shi YF, 2016, COMPUT GRAPH-UK, V55, P55, DOI 10.1016/j.cag.2015.11.003
   Sorkine O, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P191, DOI 10.1109/SMI.2004.1314506
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Thrun S, 2005, IEEE I CONF COMP VIS, P1824
   Varley J, 2017, IEEE INT C INT ROBOT, P2442, DOI 10.1109/IROS.2017.8206060
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XG, 2022, IEEE T PATTERN ANAL, V44, P8139, DOI 10.1109/TPAMI.2021.3108410
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wang Xintao, 2021, P IEEE CVF INT C COM
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wen X, 2021, PROC CVPR IEEE, P7439, DOI 10.1109/CVPR46437.2021.00736
   Wu F., 2018, P INT C LEARN REPR, P1
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xia YQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1938, DOI 10.1145/3474085.3475348
   Xiang P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5479, DOI 10.1109/ICCV48922.2021.00545
   Xie H., 2020, P EUR C COMP VIS, P365, DOI DOI 10.1007/978-3-030-58545-721
   Yan QA, 2017, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2017.24
   Yang B, 2017, IEEE INT CONF COMP V, P679, DOI 10.1109/ICCVW.2017.86
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yang ZL, 2019, ADV NEUR IN, V32
   Yida Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P70, DOI 10.1007/978-3-030-58580-8_5
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang JM, 2021, IEEE ROBOT AUTOM LET, V6, P596, DOI 10.1109/LRA.2020.3048658
   Zhang Q., 2020, P EUR C COMP VIS, P512, DOI 10.1007/978-3-030-58595-2_31
   Zhang WX, 2020, COMPUT AIDED GEOM D, V82, DOI 10.1016/j.cagd.2020.101925
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhao HS, 2020, PROC CVPR IEEE, P10073, DOI 10.1109/CVPR42600.2020.01009
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
   Zwicker M., 2019, P IEEE CVF INT C COM, p10 441
NR 71
TC 10
Z9 10
U1 7
U2 37
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4229
EP 4242
DI 10.1109/TVCG.2022.3185247
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200014
PM 35737629
DA 2024-11-06
ER

PT J
AU Calvo, L
   Cucchietti, F
   Pérez-Montoro, M
AF Calvo, Luz
   Cucchietti, Fernando
   Perez-Montoro, Mario
TI Measuring the Effectiveness of Static Maps to Communicate Changes Over
   Time
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information visualization; cognition; static maps; user interfaces;
   perception
ID DESIGN; FAMILIARITY; PERCEPTION; INFORMATION; LIKING; ISSUES
AB Both in digital and print media, it is common to use static maps to show the evolution of values in various regions over time. The ability to communicate local or global trends, while reducing the cognitive load on readers, is of vital importance for an audience that is not always well versed in map interpretation. This study aims to measure the efficiency of four static maps (choropleth, tile grid map and their banded versions) to test their usefulness in presenting changes over time from a user experience perspective. We first evaluate the effectiveness of these map types by quantitative performance analysis (time and success rates). In a second phase, we gather qualitative data to detect which type of map favors decision-making. On a quantitative level, our results show that certain types of maps work better to show global trends, while other types are more useful when analyzing regional trends or detecting the regions that fit a specific pattern. On a qualitative level, those representations which are already familiar to the user are often better valued despite having lower measured success rates.
C1 [Calvo, Luz; Cucchietti, Fernando] Barcelona Supercomp Ctr BSC, CASE Dept, Barcelona 08034, Spain.
   [Perez-Montoro, Mario] Univ Barcelona, Dept Lib & Informat Sci & Audiovisual Commun, Barcelona 08007, Spain.
C3 Universitat Politecnica de Catalunya; Barcelona Supercomputer Center
   (BSC-CNS); University of Barcelona
RP Calvo, L (corresponding author), Barcelona Supercomp Ctr BSC, CASE Dept, Barcelona 08034, Spain.
EM luz.calvo@bsc.es; fernando.cucchietti@bsc.es; perez-montoro@ub.edu
RI Pérez-Montoro, Mario/E-1472-2012; Cucchietti, Fernando/C-7765-2016
OI Cucchietti, Fernando/0000-0002-9027-1263
FU Bioethics Committee of the Universitat de Barcelona Institutional Review
   Board [IRB00003099]
FX This work involved human subjects or animals in its research. Approval
   of all ethical and experimental procedures and protocols was granted by
   Bioethics Committee of the Universitat de Barcelona Institutional Review
   Board under Application No. IRB00003099 and performed in line with the
   bioethics directives of Universitat de Barcelona.
CR AfterTheFlood, 2020, London squared
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alharbi A, 2015, 2015 SCIENCE AND INFORMATION CONFERENCE (SAI), P151, DOI 10.1109/SAI.2015.7237139
   Andrienko N., 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   [Anonymous], 2007, Cartogr Int J Geogr Inf Geovisualization, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   [Anonymous], 2011, Geoscientific Model Develop. Discuss.
   Armstrong MP, 2018, ANN AM ASSOC GEOGR, V108, P179, DOI 10.1080/24694452.2017.1356698
   Babich N., 2020, Usability testing: Moderated versus unmoderated
   Bernhaupt R, 2016, LECT NOTES COMPUT SC, V9856, P56, DOI 10.1007/978-3-319-44902-9_5
   Bertin J., 1983, Semiology of Graphics
   Besancon L., 2020, arXiv, DOI DOI 10.48550/ARXIV.2005.00324
   Blok C.A., 2005, Dynamic visualization variables in animation to support monitoring of spatial phenomena
   BOARD C, 1977, T I BRIT GEOGR, V2, P19, DOI 10.2307/622191
   Board of Governers of the Federal Reserve, 2020, FED RESERVE BULL, V106
   Bogacz S, 2002, LECT NOTES ARTIF INT, V2317, P347
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [DOI 10.1016/B978-0-08-042415-6.50014-4, 10.1016/b978-0-08-042415-6.50014-4]
   Brunsdon C, 2007, COMPUT ENVIRON URBAN, V31, P52, DOI 10.1016/j.compenvurbsys.2005.07.009
   Buckley A., 2013, P 26 INT CART C, P21
   Cairo A., 2017, Uncertainty and Graphicacy: How Should Statisticians, Journalists, and Designers Reveal Uncertainty in Graphics for Public Consumption? Power from Statistics: Data, Information, and Knowledge
   Carrard P., 2018, Front. Narrative Stud., V4, P263
   Chou L., 2019, Top 10 map types in data visualization
   Ciokosz-Styk A., 2012, Geoinformation Issues, V4, P33
   Collins L., 2019, How to analyse usability testing results
   ColorBrewer, 2022, Color advice for maps
   Cordes RE, 2001, INT J HUM-COMPUT INT, V13, P411, DOI 10.1207/S15327590IJHC1304_04
   Datavizcatalogue, 2018, Chart combinations: Tile grid maps-dataviz catalogue blog
   Dent B. D., 1975, American Cartographer, V2, P154, DOI [10.1559/152304075784313278, DOI 10.1559/152304075784313278]
   Di Gesù V, 1999, PATTERN RECOGN LETT, V20, P207, DOI 10.1016/S0167-8655(98)00115-9
   Dodge Martin., 2011, Rethinking Maps: New Frontiers in Cartographic Theory, V1st
   Dorling D., 2011, Map Reader: Theories of Mapping Practice and Cartographic Representation, P252, DOI 10.1002/9780470979587.ch33
   Dovbysh O, 2020, DIGIT JOURNAL, V8, P972, DOI 10.1080/21670811.2020.1777883
   Du Y, 2018, PERS UBIQUIT COMPUT, V22, P503, DOI 10.1007/s00779-018-1120-y
   Engebretsen M., 2020, DATA VISUALIZATION S, DOI DOI 10.1515/9789048543137
   Erickson G., 2017, New methods of market research and analysis
   Esteves Salome, 2021, Human Interaction, Emerging Technologies and Future Applications III. Proceedings of the 3rd International Conference on Human Interaction and Emerging Technologies: Future Applications (IHIET 2020). Advances in Intelligent Systems and Computing (AISC 1253), P404, DOI 10.1007/978-3-030-55307-4_61
   Fabrikant S.I., 2009, Cartographica, V44, P139, DOI DOI 10.3138/CARTO.44.3.139
   Fish C, 2011, CARTOGR GEOGR INF SC, V38, P350, DOI 10.1559/15230406384350
   Fotheringham A., 2000, InglesQuantitative Geography: Perspectives on Spatial Data Analysis, V1st
   Friendly M., 2001, Milestones in the history of thematic cartography, statistical graphics, and data visualization
   Gazepoint, 2022, Eye tracking system technology for everyone-UX testing
   Goldsberry K., 2009, Cartographica, V44, P201
   Gordon B., 2019, Product user testing: The void between laboratory testing and field testing
   Griffin T. L. C., 1980, Cartography, V11, P163
   Gyozo Torok Z., 2019, Cognitive Infocommunications, Theory and Applications, P49
   Hall B., 2019, IIBEC
   Hansen J, 2009, SOC COGNITION, V27, P161, DOI 10.1521/soco.2009.27.2.161
   Hassenzahl M., 2004, P HUM FACT COMP SYST, P1283, DOI 10.1145/985921.986044
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   HILLYARD SA, 1984, PERCEPT PSYCHOPHYS, V36, P185, DOI 10.3758/BF03202679
   Holtz S., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P129, DOI 10.1109/LDAV.2011.6092333
   Jacobs A, 2004, J EXP PSYCHOL HUMAN, V30, P822, DOI 10.1037/0096-1523.30.5.822
   Johnson M. L., 2005, Cartographic Perspectives, P84
   Juergens Carsten, 2020, KN J Cartogr Geogr Inf, V70, P155, DOI 10.1007/s42489-020-00057-w
   Keim DA, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P33, DOI 10.1109/INFVIS.2002.1173144
   Kernik M., 2017, Mapping, Society, and Technology
   Kevorkian A., 2020, medRxiv, DOI [10.1101/2020.03.14.20035964, DOI 10.1101/2020.03.14.20035964]
   Kim SH, 2012, IEEE T VIS COMPUT GR, V18, P2421, DOI 10.1109/TVCG.2012.215
   Kittur A., 2007, P ACM C HUM FACT COM
   Koenig P.-Y., 2010, PROC C GRAPH INTERFA, P113
   Kraak M. J., 2014, CARTOGRAPHIC PERSPEC, V77, P35, DOI [10.14714/CP77.1234, DOI 10.14714/CP77.1234]
   Langton S., 2019, Cartograms, hexograms and regular grids: A commentary on minimising misrepresentation in spatial data visualisations
   Li R, 2021, HUM BEHAV EMERG TECH, V3, P97, DOI 10.1002/hbe2.248
   Lupa M, 2017, ISPRS INT GEO-INF, V6, DOI 10.3390/ijgi6090276
   Martens MH, 2007, TRANSPORT RES F-TRAF, V10, P476, DOI 10.1016/j.trf.2007.05.003
   McDonald Jason K., 2020, Journal of Design Research, V18, P57, DOI 10.1504/JDR.2020.112057
   McDonald JK, 2019, TECHTRENDS, V63, P149, DOI 10.1007/s11528-018-0302-9
   McNeill G, 2017, COMPUT GRAPH FORUM, V36, P435, DOI 10.1111/cgf.13200
   Melloni G, 2017, J ACCOUNT PUBLIC POL, V36, P220, DOI 10.1016/j.jaccpubpol.2017.03.001
   Moon E, 2019, DES J, V22, P1515, DOI 10.1080/14606925.2019.1594974
   Nicolet C., 1991, SPACE GEOGRAPHY POLI
   Noriega P, 2016, ADV INTELL SYST, V485, P53, DOI 10.1007/978-3-319-41983-1_6
   Nusrat S., 2015, P EUR C VIS SHORT PA, P61
   Nusrat S, 2018, IEEE T VIS COMPUT GR, V24, P1100, DOI 10.1109/TVCG.2016.2642109
   Nusrat S, 2016, COMPUT GRAPH FORUM, V35, P619, DOI 10.1111/cgf.12932
   Pais El., 2021, El Pais
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Post W., 2021, U.S. coronavirus cases: Tracking deaths, confirmed cases by state
   Rensink RA, 2021, J VISION, V21, DOI 10.1167/jov.21.8.3
   Richards M., 2019, Data visualization and usability testing
   Roth R.E., 2017, International Journal of Cartography, V3, P61, DOI 10.1080/ 23729333.2017.1288534
   Rubin J., 2008, en-gbHandbook of Usability Testing: How to Plan, Design, and Conduct Effective Tests
   Sauro J., 2016, Quantifying the user experience: practical statistics for user, P350
   Sauro J., 2005, PROC HUMAN COMPUT IN
   Schade A., 2015, Pilot testing: Getting it right (before) the first time
   Schiewe J., 2019, KN-Journal of Cartography and Geographic Information, V69, P217, DOI [DOI 10.1007/S42489-019-00026-Y, DOI 10.1007/S42489-019-00026-Y4]
   Semega J, 2020, Income and Poverty in the United States: 2019 Internet
   Skowronnek A., 2016, Beyond choropleth maps: A review of techniques to visualize quantitative areal geodata
   Slocum T. A., 2006, Cartographica Int. J. Geographic Informat. Geovisualization, V27, P67
   Slomska-Przech K, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020069
   Sobral T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020332
   Sonderegger A, 2019, LECT NOTES COMPUT SC, V11749, P140, DOI 10.1007/978-3-030-29390-1_8
   Spinde T., 2020, P ACM IEEE JOINT C D, P389, DOI [10.1145/3383583.3398619, DOI 10.1145/3383583.3398619, 10.1145/3383583, DOI 10.1145/3383583]
   Stigberg S., 2017, 8 SCAND C INF SYST B
   Strickland L, 2020, Q J EXP PSYCHOL, V73, P1495, DOI 10.1177/1747021820914915
   Swoboda E, 2016, ICME-13 TOPICAL SURV, P1, DOI 10.1007/978-3-319-44272-3_1
   T. N. Y. Times, 2020, The New York Times
   Thomas KE, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00760
   Thrower NormanJ. W., 1972, Maps Man: an examination of cartography in relation to culture and civilization
   Tobler W, 2004, ANN ASSOC AM GEOGR, V94, P58, DOI 10.1111/j.1467-8306.2004.09401004.x
   Tomlin W. C., 2018, UX OPTIMIZATION COMB, P147
   Trischler J, 2018, J SERV RES-US, V21, P75, DOI 10.1177/1094670517714060
   Ueland J. S., 2004, The Florida Geographer, V35, P11
   Vardhan P., 2020, OSF preprints, Tech. Rep.
   Vaughan L, 2018, MAPPING SOCIETY, P1, DOI 10.14324/111.9781787353053
   W. L. i. R.-B. U. Experience, 2006, Prioritizing web usability: Book by Jakob Nielsen and Hoa Loranger
   Wongsuphasawat K., 2016, P IEEE C INF VIS
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
   ZISSMAN A, 1990, PSYCHOL REC, V40, P481, DOI 10.1007/BF03399535
NR 108
TC 3
Z9 3
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4243
EP 4255
DI 10.1109/TVCG.2022.3188940
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200015
PM 35820017
OA Green Published
DA 2024-11-06
ER

PT J
AU Xue, ML
   Wang, YH
   Han, C
   Zhang, J
   Wang, Z
   Zhang, KY
   Hurter, C
   Zhao, J
   Deussen, O
AF Xue, Mingliang
   Wang, Yunhai
   Han, Chang
   Zhang, Jian
   Wang, Zheng
   Zhang, Kaiyi
   Hurter, Christophe
   Zhao, Jian
   Deussen, Oliver
TI Target Netgrams: An Annulus-Constrained Stress Model for Radial Graph
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Stress; Visualization; Data visualization; Computational
   modeling; Adaptation models; Task analysis; Radial visualization; stress
   model; hierarchy constraint; graph
ID LEAST-SQUARES; ALGORITHM
AB We present Target Netgrams as a visualization technique for radial layouts of graphs. Inspired by manually created target sociograms, we propose an annulus-constrained stress model that aims to position nodes onto the annuli between adjacent circles for indicating their radial hierarchy, while maintaining the network structure (clusters and neighborhoods) and improving readability as much as possible. This is achieved by having more space on the annuli than traditional layout techniques. By adapting stress majorization to this model, the layout is computed as a constrained least square optimization problem. Additional constraints (e.g., parent-child preservation, attribute-based clusters and structure-aware radii) are provided for exploring nodes, edges, and levels of interest. We demonstrate the effectiveness of our method through a comprehensive evaluation, a user study, and a case study.
C1 [Xue, Mingliang; Wang, Yunhai; Han, Chang; Zhang, Kaiyi] Shandong Univ, Dept Comp Sci, Qingdao 266237, Peoples R China.
   [Zhang, Jian] Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100045, Peoples R China.
   [Wang, Zheng] China Informat Consulting & Designing Inst Co Ltd, Beijing 100004, Peoples R China.
   [Hurter, Christophe] Ecole Natl Aviat Civile, ENAC, F-31400 Toulouse, France.
   [Zhao, Jian] Univ Waterloo, Cheriton Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Deussen, Oliver] Univ Konstanz, Comp & Informat Sci, D-78464 Constance, Germany.
C3 Shandong University; Chinese Academy of Sciences; Computer Network
   Information Center, CAS; Universite Federale Toulouse Midi-Pyrenees
   (ComUE); Universite de Toulouse; Ecole Nationale de l'Aviation Civile
   (ENAC); University of Waterloo; University of Konstanz
RP Wang, YH (corresponding author), Shandong Univ, Dept Comp Sci, Qingdao 266237, Peoples R China.
EM xml95007@gmail.com; cloudseawang@gmail.com; hatch.on27@gmail.com;
   zhangjian@sccas.cn; wangzheng_ai@126.com; zhang.kaiyi42@gmail.com;
   christophe.hurter@enac.fr; jianzhao@uwaterloo.ca;
   oliver.deussen@uni-konstanz.de
RI Hurter, Christophe/IAM-1546-2023; Deussen, Oliver/HKF-2004-2023
OI Zhang, Jian/0000-0003-1348-8124; Hurter, Christophe/0000-0003-4318-6717;
   Zhao, Jian/0000-0001-5008-4319; Zhang, Kaiyi/0000-0002-0505-7343; Han,
   Chang/0000-0003-2285-1247; Xue, Mingliang/0000-0001-8842-1667
FU National Key Research amp; Development Plan of China [2019YFB1704201];
   NSFC [62132017, 62141217]
FX This work was supported in part by the National Key Research &
   Development Plan of China under Grant 2019YFB1704201 and NSFC under
   Grants 62132017 and 62141217.
CR Albo Y, 2016, IEEE T VIS COMPUT GR, V22, P569, DOI 10.1109/TVCG.2015.2467322
   [Anonymous], 2013, Global optimization with non-convex constraints: Sequential and parallel algorithms
   Bachmaier C., 2005, J GRAPH ALGORITHMS A, V9, P53
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Brandes Ulrik, 2011, Journal of Graph Algorithms and Applications, V15, P157, DOI 10.7155/jgaa.00221
   Brandes U, 2003, IEEE T VIS COMPUT GR, V9, P241, DOI 10.1109/TVCG.2003.1196010
   Burch M., 2014, Handbook of Human Centric Visualization, P429, DOI [DOI 10.1007/978-1-4614-7485-217, DOI 10.1007/978146147485217]
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2440, DOI 10.1109/TVCG.2011.193
   Carrington P.J., 2005, MODELS METHODS SOCIA
   Castermans T, 2019, IEEE T VIS COMPUT GR, V25, P2969, DOI 10.1109/TVCG.2018.2865361
   CLEVELAND WS, 1986, INT J MAN MACH STUD, V25, P491, DOI 10.1016/S0020-7373(86)80019-0
   Demmel JW, 1997, Applied Numerical Linear Algebra
   Diehl S, 2010, IEEE T VIS COMPUT GR, V16, P935, DOI 10.1109/TVCG.2010.209
   Du F, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2916, DOI 10.1145/3025453.3025628
   Dwyer T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P65, DOI 10.1109/INFVIS.2005.1532130
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   EADES P., 1992, B I COMBINATORICS IT, P10
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   Freeman L. C., 2000, J. Soc. Struct., V1
   Gansner ER, 2013, IEEE T VIS COMPUT GR, V19, P927, DOI 10.1109/TVCG.2012.299
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Goldberg J, 2011, INFORM VISUAL, V10, P182, DOI 10.1177/1473871611406623
   Havre S, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P105, DOI 10.1109/INFVIS.2001.963287
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hogan B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5360, DOI 10.1145/2858036.2858368
   Hu YF, 2015, WIRES COMPUT STAT, V7, P115, DOI 10.1002/wics.1343
   Huang G, 2020, PHYSICA A, V539, DOI 10.1016/j.physa.2019.122948
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jankun-Kelly TJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P59, DOI 10.1109/INFVIS.2003.1249009
   Jennings HH, 1952, SOCIOMETRY, V15, P400, DOI 10.2307/2785750
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Keim DA, 2006, IEEE CONF VIS ANAL, P123
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Leskovec J., 2007, ACM T KNOWL DISCOV D, V1, P2, DOI DOI 10.1145/1217299.1217301
   Leskovec J., 2012, ADV NEURAL INFORM PR, V25
   Mead JL, 2010, LINEAR ALGEBRA APPL, V432, P1936, DOI 10.1016/j.laa.2009.04.017
   Nevis E. C., 2013, Organizational Consulting: A Gestalt Approach
   Newman MEJ, 2006, PHYS REV E, V74, DOI 10.1103/PhysRevE.74.036104
   Nightingale F., 1958, Notes on Matters Affecting the Health, Efficiency, and Hospital Administration of the British Army
   Northway ML, 1940, SOCIOMETRY, V3, P144, DOI 10.2307/2785439
   Pavlo A., 2006, arXiv
   Perry B. L., 2018, EGOCENTRIC NETWORK A, V44
   Playfair W., 1801, Statistical Breviary
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Rozemberczki B, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1325, DOI 10.1145/3340531.3411866
   Schofield B, 2008, P AMER CONTR CONF, P2597, DOI 10.1109/ACC.2008.4586883
   STARK PB, 1995, COMPUTATION STAT, V10, P129
   Stasko J, 2000, INT J HUM-COMPUT ST, V53, P663, DOI 10.1006/ijhc.2000.0420
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   The dblp team, 2021, DBLP computer science bibliography. Monthly snapshot release of Match 2021
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Weber M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P7, DOI 10.1109/infvis.2001.963273
   Wills GJ, 1999, J COMPUT GRAPH STAT, V8, P190, DOI 10.2307/1390633
   Yang TB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Zhao J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5003, DOI 10.1145/2858036.2858488
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 59
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4256
EP 4268
DI 10.1109/TVCG.2022.3187425
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200016
PM 35786556
OA Green Published
DA 2024-11-06
ER

PT J
AU Huang, F
   Liu, C
   Hsiao, KW
   Kuo, YM
   Chu, HK
   Yang, YL
AF Huang, Fei
   Liu, Chen
   Hsiao, Kai-Wen
   Kuo, Ying-Miao
   Chu, Hung-Kuo
   Yang, Yong-Liang
TI Image-Based OA-Style Paper Pop-Up Design via Mixed-Integer Programming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Stability analysis; Computational
   modeling; Geometry; Solid modeling; Optimization; Origami architecture;
   paper pop-up; image-based design; foldable structure; mixed-integer
   programming
ID CARD DESIGN; DEFORMATION; SURFACE
AB Origami architecture (OA) is a fascinating papercraft that involves only a piece of paper with cuts and folds. Interesting geometric structures 'pop up' when the paper is opened. However, manually designing such a physically valid 2D paper pop-up plan is challenging since fold lines must jointly satisfy hard spatial constraints. Existing works on automatic OA-style paper pop-up design all focused on how to generate a pop-up structure that approximates a given target 3D model. This article presents the first OA-style paper pop-up design framework that takes 2D images instead of 3D models as input. Our work is inspired by the fact that artists often use 2D profiles to guide the design process, thus benefited from the high availability of 2D image resources. Due to the lack of 3D geometry information, we perform novel theoretic analysis to ensure the foldability and stability of the resultant design. Based on a novel graph representation of the paper pop-up plan, we further propose a practical optimization algorithm via mixed-integer programming that jointly optimizes the topology and geometry of the 2D plan. We also allow the user to interactively explore the design space by specifying constraints on fold lines. Finally, we evaluate our framework on various images with interesting 2D shapes. Experiments and comparisons exhibit both the efficacy and efficiency of our framework.
C1 [Huang, Fei; Yang, Yong-Liang] Univ Bath, Dept Comp Sci, Bath BA2 7AY, England.
   [Liu, Chen] Meta Facebook Real Labs, Redmond, WA 98052 USA.
   [Hsiao, Kai-Wen; Kuo, Ying-Miao; Chu, Hung-Kuo] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 University of Bath; National Tsing Hua University
RP Yang, YL (corresponding author), Univ Bath, Dept Comp Sci, Bath BA2 7AY, England.
EM huangfei037@hotmail.com; chenliu@wustl.edu; kevin30112@gmail.com;
   jollytreeskuo@gmail.com; hkchu@cs.nthu.edu.tw; y.yang@cs.bath.ac.uk
OI Yang, Yong-Liang/0000-0002-8071-5756; Huang, Fei/0000-0001-5928-4018
FU CAMERA; RCUK Centre for the Analysis of Motion, Entertainment Research
   and Applications [EP/M023281/1, EP/T022523/1]; Ministry of Science and
   Technology of Taiwan [110-2221-E-007-061-MY3, 110-2221-E-007-060-MY3];
   EPSRC [EP/M023281/1, EP/T022523/1] Funding Source: UKRI
FX This work was supported in part by CAMERA, the RCUK Centre for the
   Analysis of Motion, Entertainment Research and Applications under Grants
   EP/M023281/1 and EP/T022523/1, and in part by the Ministry of Science
   and Technology of Taiwan under Grants 110-2221-E-007-061-MY3 and
   110-2221-E-007-060-MY3, and a gift from Adobe.
CR Chatani M., 1985, Pop-Up Origamic Architecture
   Chen J.-M., 2006, P INT C SUP, P1029
   Choi GPT, 2019, NAT MATER, V18, P999, DOI 10.1038/s41563-019-0452-y
   Chow K.-C., 2021, ABOUT US
   Cignoni P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2537852
   Demaine ED, 2007, GEOMETRIC FOLDING ALGORITHMS: LINKAGES, ORIGAMI, POLYHEDRA, P1, DOI 10.1017/CBO9780511735172
   Glassner A, 2002, IEEE COMPUT GRAPH, V22, P74, DOI 10.1109/38.988749
   Glassner A, 2002, IEEE COMPUT GRAPH, V22, P79, DOI 10.1109/38.974521
   Gurobi Optimization LLC, 2022, Gurobi Optimizer Reference Manual
   Hendrix S. L., 2006, Advanced Technology for Learning, V3, P119, DOI 10.2316/Journal.208.2006.2.208-0878
   Hildebrand K, 2012, COMPUT GRAPH FORUM, V31, P583, DOI 10.1111/j.1467-8659.2012.03037.x
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854
   Ion A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417835
   Jiang CG, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417844
   Jiang CG, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356540
   Julius D, 2005, COMPUT GRAPH FORUM, V24, P581, DOI 10.1111/j.1467-8659.2005.00883.x
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Kilian M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3015460
   Kilian M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360674
   Konakovic M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925944
   Konakovic-Lukovic M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201373
   Le SN, 2014, IEEE T VIS COMPUT GR, V20, P276, DOI 10.1109/TVCG.2013.108
   Li XY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778848
   Li XY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964993
   Li Y, 2007, COMPUT ANIMAT VIRT W, V18, P395, DOI 10.1002/cav.188
   Liu YJ, 2009, IEEE T AUTOM SCI ENG, V6, P700, DOI 10.1109/TASE.2008.2009926
   Massarwi F, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P148, DOI 10.1109/PG.2007.16
   McCrae J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024202
   Mitani J, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P93
   Mitani J, 2004, ACM T GRAPHIC, V23, P259, DOI 10.1145/1015706.1015711
   Nemhauser G.L., 1999, Integer and Combinatorial Optimization, V55
   ORourke J., 2011, How to Fold It: The Mathematics of Linkages, Origami, and Polyhedra
   Rabinovich M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3180494
   Rabinovich M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275088
   Ruiz C, 2015, VISUAL COMPUT, V31, P925, DOI 10.1007/s00371-015-1125-8
   Ruiz CR, 2014, COMPUT GRAPH FORUM, V33, P487, DOI 10.1111/cgf.12320
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Shatz I, 2006, VISUAL COMPUT, V22, P825, DOI 10.1007/s00371-006-0067-6
   Solomon J, 2012, COMPUT GRAPH FORUM, V31, P1567, DOI 10.1111/j.1467-8659.2012.03162.x
   Stein O, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201303
   Tachi T., 2013, P INT ASS SHELL SPAT, P1
   Tachi T, 2010, IEEE T VIS COMPUT GR, V16, P298, DOI 10.1109/TVCG.2009.67
   Tang CC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2832906
   Wang CCL, 2004, VISUAL COMPUT, V20, P521, DOI 10.1007/s00371-004-0256-0
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Xiao N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3156934
   Xu J, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P343, DOI 10.1109/PG.2007.10
   Zhao LY, 2018, IEEE T VIS COMPUT GR, V24, P2167, DOI 10.1109/TVCG.2017.2708108
   Zhu L, 2013, COMPUT GRAPH FORUM, V32, P167, DOI 10.1111/cgf.12224
NR 51
TC 1
Z9 1
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4269
EP 4283
DI 10.1109/TVCG.2022.3189569
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200017
PM 35802544
OA Green Published
DA 2024-11-06
ER

PT J
AU Liang, YZ
   Song, Q
   Wang, R
   Huo, YC
   Bao, HJ
AF Liang, Yuzhi
   Song, Qi
   Wang, Rui
   Huo, Yuchi
   Bao, Hujun
TI Automatic Mesh and Shader Level of Detail
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geometry simplification; level of detail; real-time rendering; shader
   optimization
AB The level of detail (LOD) technique has been widely exploited as a key rendering optimization in many graphics applications. Numerous approaches have been proposed to automatically generate different kinds of LODs, such as geometric LOD or shader LOD. However, none of them have considered simplifying the geometry and shader at the same time. In this paper, we explore the observation that simplifications of geometric and shading details can be combined to provide a greater variety of tradeoffs between performance and quality. We present a new discrete multiresolution representation of objects, which consists of mesh and shader LODs. Each level of the representation could contain both simplified representations of shader and mesh. To create such LODs, we propose two automatic algorithms that pursue the best simplifications of meshes and shaders at adaptively selected distances. The results show that our mesh and shader LOD achieves better performance-quality tradeoffs than prior LOD representations, such as those that only consider simplified meshes or shaders.
C1 [Liang, Yuzhi; Song, Qi; Wang, Rui; Huo, Yuchi; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, R (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM yuzhiliang@zju.edu.cn; songqi@zju.edu.cn; rwang@cad.zju.edu.cn;
   huo.yuchi.sc@gmail.com; bao@cad.zju.edu.cn
RI Liang, Yuzhi/HGU-1971-2022
OI Huo, Yuchi/0000-0003-3296-7999; Bao, Hujun/0000-0002-2662-0334; Liang,
   Yuzhi/0000-0001-9467-5284
FU Key Ramp;D Program of Zhejiang Province [2022C01025]; NSFC [61872319];
   Fundamental Research Funds for the Central Universities, Zhejiang Lab
   [121005-PI2101]; Information Technology Center and State Key Lab of
   CADamp;CG, Zhejiang University
FX This work was supported in part by the Key R & D Program of Zhejiang
   Province under Grant 2022C01025, in part by NSFC under Grant 61872319,
   in part by the Fundamental Research Funds for the Central Universities,
   Zhejiang Lab under Grant 121005-PI2101, and in part by the Information
   Technology Center and State Key Lab of CAD & CG, Zhejiang University.
   This work has been integrated in the Rays Engine project.
CR Bruneton E, 2012, IEEE T VIS COMPUT GR, V18, P242, DOI 10.1109/TVCG.2011.81
   Cignoni P, 1998, COMPUT GRAPH-UK, V22, P37, DOI 10.1016/S0097-8493(97)00082-4
   CLARK JH, 1976, COMMUN ACM, V19, P547, DOI 10.1145/360349.360354
   Cohen J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P115, DOI 10.1145/280814.280832
   De Floriani L, 2002, TUTORIALS ON MULTIRESOLUTION IN GEOMETRIC MODELLING, P363
   Dijkstra E. W., 1959, Numer. Math, V1, P269, DOI [DOI 10.1007/BF01386390, 10.1007/BF01386390]
   Dorn J, 2015, COMPUT GRAPH FORUM, V34, P77, DOI 10.1111/cgf.12747
   Dupuy J, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508422
   EpicGames, 2020, MAT DEM
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Han C, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239479
   He Y, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925923
   He Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818104
   Heckbert P.S., 1997, SURVEY POLYGONAL SUR
   Hoppe H., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P59, DOI 10.1109/VISUAL.1999.809869
   Hoppe H, 1998, VISUALIZATION '98, PROCEEDINGS, P35, DOI 10.1109/VISUAL.1998.745282
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Jon H., 2021, COMPUT GRAPH FORUM
   Lindstrom P, 2000, ACM T GRAPHIC, V19, P204, DOI 10.1145/353981.353995
   Luebke David, 2002, Level of detail for 3D graphics
   Luebke DP, 2001, IEEE COMPUT GRAPH, V21, P24, DOI 10.1109/38.920624
   McAuley S., 2013, PROC ACM SPECIAL INT
   Olano Marc, 2003, P ACM SIGGRAPH EUROG, P7, DOI DOI 10.5555/844174.844176
   Olano Marc, 2010, P 2010 ACM SIGGRAPH, P181, DOI DOI 10.1145/1730804.1730834
   Pellacini F, 2005, ACM T GRAPHIC, V24, P464, DOI 10.1145/1073204.1073214
   Pellacini F, 2005, ACM T GRAPHIC, V24, P445, DOI 10.1145/1073204.1073212
   Scherzer Daniel, 2007, Proceedings of the 18th Eurographics conference on Rendering Techniques, P45
   simplygon, 2015, US
   Sitthi-amorn P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024186
   Sitthi-Amorn P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409080
   UnrealEngine, 2016, UNR ENG 4 DOC
   van Kaick OM, 2006, COMPUT GRAPH FORUM, V25, P197, DOI 10.1111/j.1467-8659.2006.00935.x
   Wang R, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661276
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
NR 34
TC 3
Z9 3
U1 3
U2 27
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4284
EP 4295
DI 10.1109/TVCG.2022.3188775
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200018
PM 35793302
DA 2024-11-06
ER

PT J
AU He, XY
   Tao, YB
   Yang, SL
   Dai, HR
   Lin, H
AF He, Xiangyang
   Tao, Yubo
   Yang, Shuoliu
   Dai, Haoran
   Lin, Hai
TI voxel2vec: A Natural Language Processing Approach to Learning
   Distributed Representations for Scientific Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graphical models; Association analysis; feature classification;
   representation learning; scientific data
ID DIMENSION PROJECTION; VISUAL ANALYSIS; VISUALIZATION; EXPLORATION;
   FRAMEWORK; SELECTION
AB Relationships in scientific data, such as the numerical and spatial distribution relations of features in univariate data, the scalar-value combinations' relations in multivariate data, and the association of volumes in time-varying and ensemble data, are intricate and complex. This paper presents voxel2vec, a novel unsupervised representation learning model, which is used to learn distributed representations of scalar values/scalar-value combinations in a low-dimensional vector space. Its basic assumption is that if two scalar values/scalar-value combinations have similar contexts, they usually have high similarity in terms of features. By representing scalar values/scalar-value combinations as symbols, voxel2vec learns the similarity between them in the context of spatial distribution and then allows us to explore the overall association between volumes by transfer prediction. We demonstrate the usefulness and effectiveness of voxel2vec by comparing it with the isosurface similarity map of univariate data and applying the learned distributed representations to feature classification for multivariate data and to association analysis for time-varying and ensemble data.
C1 [He, Xiangyang; Tao, Yubo; Yang, Shuoliu; Dai, Haoran; Lin, Hai] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Tao, YB; Lin, H (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM xiangyanghe@zju.edu.cn; taoyubo@cad.zju.edu.cn; lucida@zju.edu.cn;
   haoran.dai@zju.edu.cn; lin@cad.zju.edu.cn
RI zhu, hao/KHW-3813-2024; TAO, yubo/R-3465-2019
OI Tao, Yubo/0000-0002-2283-6437; dai, haoran/0000-0003-1780-186X; Lin,
   Hai/0000-0002-1682-8465
CR Armandpour M, 2019, AAAI CONF ARTIF INTE, P3191
   Bai ZH, 2020, J VISUAL-JAPAN, V23, P745, DOI 10.1007/s12650-020-00654-x
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Biswas A, 2013, IEEE T VIS COMPUT GR, V19, P2683, DOI 10.1109/TVCG.2013.133
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Bruckner S, 2010, COMPUT GRAPH FORUM, V29, P773, DOI 10.1111/j.1467-8659.2009.01689.x
   Buda M, 2018, NEURAL NETWORKS, V106, P249, DOI 10.1016/j.neunet.2018.07.011
   Carr H, 2014, IEEE T VIS COMPUT GR, V20, P1100, DOI 10.1109/TVCG.2013.269
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Dutta S, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139298
   Ester M., 1996, P KDD, P226
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Fuchs R, 2009, COMPUT GRAPH FORUM, V28, P1670, DOI 10.1111/j.1467-8659.2009.01429.x
   Gao HC, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1406, DOI 10.1145/3219819.3220041
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Guo HQ, 2011, IEEE PAC VIS SYMP, P19, DOI 10.1109/PACIFICVIS.2011.5742368
   Guo HQ, 2012, IEEE T VIS COMPUT GR, V18, P1397, DOI 10.1109/TVCG.2012.80
   Haidacher M, 2011, IEEE T VIS COMPUT GR, V17, P1969, DOI 10.1109/TVCG.2011.258
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   Hastie T., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   He XY, 2019, J VISUAL-JAPAN, V22, P897, DOI 10.1007/s12650-019-00584-3
   He XY, 2018, VIS INFORM, V2, P254, DOI 10.1016/j.visinf.2018.12.005
   Imre M, 2017, IEEE PAC VIS SYMP, P180, DOI 10.1109/PACIFICVIS.2017.8031592
   Inselberg A, 1985, VISUAL COMPUT, V1, P69, DOI 10.1007/BF01898350
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kumar M., 2010, P NIPS, V23
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Leistikow S, 2020, IEEE COMPUT GRAPH, V40, P72, DOI 10.1109/MCG.2019.2915215
   Liu XT, 2016, IEEE T VIS COMPUT GR, V22, P955, DOI 10.1109/TVCG.2015.2467431
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Lu KW, 2017, IEEE PAC VIS SYMP, P141, DOI 10.1109/PACIFICVIS.2017.8031588
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Ma B, 2019, IEEE T VIS COMPUT GR, V25, P1091, DOI 10.1109/TVCG.2018.2864815
   Mikolov T., 2013, P 26 C NEUR INF PROC, P3111
   Mikolov T, 2013, Arxiv, DOI arXiv:1301.3781
   Nagaraj S, 2011, COMPUT GRAPH FORUM, V30, P1101, DOI 10.1111/j.1467-8659.2011.01959.x
   Obermaier H, 2016, IEEE T VIS COMPUT GR, V22, P2331, DOI 10.1109/TVCG.2015.2507592
   Parsons L., 2004, ACM SIGKDD Explorations Newsletter, P90
   Paszke A., 2017, NIPS W
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Porter WP, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P131, DOI [10.1109/visual.2019.8933759, 10.1109/VISUAL.2019.8933759]
   Sauber N, 2006, IEEE T VIS COMPUT GR, V12, P917, DOI 10.1109/TVCG.2006.165
   Schneider D, 2008, IEEE T VIS COMPUT GR, V14, P1475, DOI 10.1109/TVCG.2008.143
   Schneider D, 2013, COMPUT AIDED GEOM D, V30, P521, DOI 10.1016/j.cagd.2012.03.023
   Sukharev J, 2009, IEEE PAC VIS SYMP, P161, DOI 10.1109/PACIFICVIS.2009.4906852
   Tao J, 2019, IEEE T VIS COMPUT GR, V25, P1236, DOI 10.1109/TVCG.2018.2864808
   Tkachev G, 2021, IEEE T VIS COMPUT GR, V27, P3091, DOI 10.1109/TVCG.2019.2961893
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wang Y., 2013, P EUR S PAR GRAPH VI, P17
   Wang YF, 2020, IEEE T VIS COMPUT GR, V26, P960, DOI 10.1109/TVCG.2019.2934369
   Wang ZJ, 2016, IEEE T VIS COMPUT GR, V22, P807, DOI 10.1109/TVCG.2015.2467292
   Wu FR, 2015, COMPUT GRAPH FORUM, V34, P163, DOI 10.1111/cgf.12755
   Xu J, 2020, IEEE T VIS COMPUT GR, V26, P2387, DOI 10.1109/TVCG.2018.2887230
   Zhang JJ, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P111
   Zhao X, 2010, Vol Graph, P69
   Zhou B, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13399
   Zhou L, 2014, COMPUT GRAPH FORUM, V33, P151, DOI 10.1111/cgf.12371
   Zhou L, 2012, COMPUT GRAPH-UK, V36, P596, DOI 10.1016/j.cag.2012.02.007
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
   Zirikly A., 2015, P 1 WORKSH VECT SPAC, P176
NR 70
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4296
EP 4311
DI 10.1109/TVCG.2022.3189094
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200019
PM 35797320
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Quadri, GJ
   Nieves, JA
   Wiernik, BM
   Rosen, P
AF Quadri, Ghulam Jilani
   Nieves, Jennifer Adorno
   Wiernik, Brenton M.
   Rosen, Paul
TI Automatic Scatterplot Design Optimization for Clustering Identification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scatterplot; overdraw; clustering; design optimization; perception;
   topological data analysis
ID MULTIDIMENSIONAL DATA; PERCEPTION; DENSITY; VISUALIZATION; REDUCTION;
   EXPLORATION; TAXONOMY
AB Scatterplots are among the most widely used visualization techniques. Compelling scatterplot visualizations improve understanding of data by leveraging visual perception to boost awareness when performing specific visual analytic tasks. Design choices in scatterplots, such as graphical encodings or data aspects, can directly impact decision-making quality for low-level tasks like clustering. Hence, constructing frameworks that consider both the perceptions of the visual encodings and the task being performed enables optimizing visualizations to maximize efficacy. In this article, we propose an automatic tool to optimize the design factors of scatterplots to reveal the most salient cluster structure. Our approach leverages the merge tree data structure to identify the clusters and optimize the choice of subsampling algorithm, sampling rate, marker size, and marker opacity used to generate a scatterplot image. We validate our approach with user and case studies that show it efficiently provides high-quality scatterplot designs from a large parameter space.
C1 [Quadri, Ghulam Jilani] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
   [Nieves, Jennifer Adorno] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
   [Wiernik, Brenton M.] Univ S Florida, Dept Psychol, Tampa, FL 33620 USA.
   [Rosen, Paul] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill;
   State University System of Florida; University of South Florida; State
   University System of Florida; University of South Florida; Utah System
   of Higher Education; University of Utah
RP Quadri, GJ (corresponding author), Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
EM ghulamjilani@usf.edu; jorgea1@usf.edu; brenton@wiernik.org;
   prosen@sci.utah.edu
RI Wiernik, Brenton/G-4854-2016; Rosen, Paul/GXM-8609-2022
OI Rosen, Paul/0000-0002-0873-9518; Quadri, Ghulam
   Jilani/0000-0002-8054-5048
CR Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Amorim EPD, 2012, IEEE CONF VIS ANAL, P53, DOI 10.1109/VAST.2012.6400489
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Anobile G, 2016, PERCEPTION, V45, P5, DOI 10.1177/0301006615602599
   [Anonymous], 2021, R LANG ENV STAT COMP
   Aupetit M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P141, DOI [10.1109/visual.2019.8933620, 10.1109/VISUAL.2019.8933620]
   Bachthaler S, 2008, IEEE T VIS COMPUT GR, V14, P1428, DOI 10.1109/TVCG.2008.119
   Bederson BB, 2002, ACM T GRAPHIC, V21, P833, DOI 10.1145/571647.571649
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Bertini E., 2006, Information Visualization, V5, P95, DOI 10.1057/palgrave.ivs.9500122
   Bertini E, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P826, DOI 10.1109/IV.2005.62
   Bertini E, 2004, IEEE INFOR VIS, P622, DOI 10.1109/IV.2004.1320207
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Brooks ME, 2017, R J, V9, P378, DOI 10.32614/RJ-2017-066
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen HD, 2014, IEEE T VIS COMPUT GR, V20, P1683, DOI 10.1109/TVCG.2014.2346594
   Chen HL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173991
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P729, DOI 10.1109/TVCG.2019.2934541
   Cheng SH, 2019, IEEE T VIS COMPUT GR, V25, P1361, DOI 10.1109/TVCG.2018.2808489
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cohen EH, 2008, J VISION, V8, DOI 10.1167/8.7.6
   Cohen J., 1973, Human Communication Research, V28, P473, DOI [10.1111/j.14682958.2002.tb00828.x, DOI 10.1111/J.14682958.2002.TB00828.X]
   Coraddu A, 2016, P I MECH ENG M-J ENG, V230, P136, DOI 10.1177/1475090214540874
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   Derthick M, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P137, DOI 10.1109/INFVIS.2003.1249019
   Dix A, 2002, ser. AVI '02, P167, DOI DOI 10.1145/1556262.1556289
   Dua D., 2017, UCI MACHINE LEARNING
   Ellis G, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P82, DOI 10.1109/IV.2002.1028760
   Ellis G, 2007, IEEE T VIS COMPUT GR, V13, P1216, DOI 10.1109/TVCG.2007.70535
   Etemadpour R, 2017, INFORM VISUAL, V16, P3, DOI 10.1177/1473871615606187
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   Fekete JD, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P117, DOI 10.1109/INFVIS.2002.1173156
   Few Stephen, 2008, VISUAL BUSINESS INTE
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Gramazio CC, 2014, IEEE T VIS COMPUT GR, V20, P1953, DOI 10.1109/TVCG.2014.2346983
   Akcora CG, 2019, Arxiv, DOI arXiv:1906.07852
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hu RZ, 2020, IEEE T VIS COMPUT GR, V26, P739, DOI 10.1109/TVCG.2019.2934799
   Johansson J., 2006, Information Visualization, V5, P125, DOI 10.1057/palgrave.ivs.9500117
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Joia P, 2015, COMPUT GRAPH FORUM, V34, P281, DOI 10.1111/cgf.12640
   Kaya H, 2019, TURK J ELECTR ENG CO, V27, P4783, DOI 10.3906/elk-1807-87
   Keim DA, 2010, INFORM VISUAL, V9, P301, DOI 10.1057/ivs.2009.34
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Kosara R, 2002, IEEE COMPUT GRAPH, V22, P22, DOI 10.1109/38.974515
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Ludecke D., 2022, SEE R PACKAGE VISUAL
   Ludecke D., 2020, J OPEN SOURCE SOFTW, V5, DOI [DOI 10.21105/JOSS.02445, 10.21105/joss.02445]
   Ludecke Daniel, 2024, CRAN
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Matejka J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2707, DOI 10.1145/2702123.2702585
   Matute J, 2018, IEEE T VIS COMPUT GR, V24, P542, DOI 10.1109/TVCG.2017.2744339
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nguyen Hoa., 2016, SIGGRAPH ASIA 2016 Symposium on Visualization, page, P2
   Palmer CR, 2000, SIGMOD REC, V29, P82, DOI 10.1145/335191.335384
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Pedersen Thomas Lin, 2024, CRAN
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Poco J, 2011, COMPUT GRAPH FORUM, V30, P1111, DOI 10.1111/j.1467-8659.2011.01960.x
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Rensink Ronald A., 2014, HDB HUMAN CENTRIC VI, P147, DOI [DOI 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485-2_6, 10.1007/978-1-4614-7485- 2_6]
   Rieck B, 2015, COMPUT GRAPH FORUM, V34, P431, DOI 10.1111/cgf.12655
   Rojas JAR, 2017, SYMP LARG DATA ANAL, P26, DOI 10.1109/LDAV.2017.8231848
   Rosen Paul, 2018, Computer-Aided Design and Applications, V15, P610, DOI 10.1080/16864360.2017.1419648
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Sadahiro Y., 1997, Cartographica: The International Journal for Geographic Information and Geovisualization, V34, P49, DOI DOI 10.3138/Y308-2422-8615-1233
   Sarikaya A, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13408
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   StatCounter, 2019, DESKT SCREEN RES STA
   Strack B, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/781670
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Trautner T, 2020, COMPUT GRAPH FORUM, V39, P551, DOI 10.1111/cgf.14001
   Dang TN, 2014, IEEE T VIS COMPUT GR, V20, P1624, DOI 10.1109/TVCG.2014.2346572
   Urribarri DK, 2017, INFORM VISUAL, V16, P113, DOI 10.1177/1473871616638892
   Veras R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300771
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Wegman E., 1997, CLASSIFICATION KNOWL
   Wei LY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778816
   Wei LY, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360619
   Wickham H, 2020, Readr: Read rectangular text data
   Wickham H., 2021, DPLYR GRAMMAR DATA M
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Wong Bang, 2010, Nat Methods, V7, P863
   Woodruff A., 1998, 11th Annual Symposium on User Interface Software and Technology. UIST. Proceedings of the ACM Symposium, P19, DOI 10.1145/288392.288397
   Xia JZ, 2018, IEEE T VIS COMPUT GR, V24, P236, DOI 10.1109/TVCG.2017.2744098
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yan DM, 2015, J COMPUT SCI TECH-CH, V30, P439, DOI 10.1007/s11390-015-1535-0
   Yeh IC, 2009, EXPERT SYST APPL, V36, P2473, DOI 10.1016/j.eswa.2007.12.020
   YELLOTT JI, 1983, SCIENCE, V221, P382, DOI 10.1126/science.6867716
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zhao X, 2019, COMPUT GRAPH FORUM, V38, P213, DOI 10.1111/cgf.13683
   Zheng Y., 2013, P ACM SIGMOD INT C M, P433, DOI DOI 10.1145/2463676,2465319
   Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y
NR 109
TC 4
Z9 4
U1 5
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD OCT 1
PY 2023
VL 29
IS 10
BP 4312
EP 4327
DI 10.1109/TVCG.2022.3189883
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q8ZW3
UT WOS:001060356200020
PM 35816525
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bernal-Berdun, E
   Martin, D
   Malpica, S
   Perez, PJ
   Gutierrez, D
   Masia, B
   Serrano, A
AF Bernal-Berdun, Edurne
   Martin, Daniel
   Malpica, Sandra
   Perez, Pedro J.
   Gutierrez, Diego
   Masia, Belen
   Serrano, Ana
TI D-SAV360: A Dataset of Gaze Scanpaths on 360<SUP>°</SUP> Ambisonic
   Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Videos; Behavioral sciences; Visualization; Stereo image processing;
   Estimation; Solid modeling; Predictive models; Gaze; Saliency;
   Fixations; Ambisonics; 360(degrees) Videos; Dataset
ID SALIENCY PREDICTION; EYE
AB Understanding human visual behavior within virtual reality environments is crucial to fully leverage their potential. While previous research has provided rich visual data from human observers, existing gaze datasets often suffer from the absence of multimodal stimuli. Moreover, no dataset has yet gathered eye gaze trajectories (i.e., scanpaths) for dynamic content with directional ambisonic sound, which is a critical aspect of sound perception by humans. To address this gap, we introduce D-SAV360, a dataset of 4,609 head and eye scanpaths for 360(degrees) videos with first-order ambisonics. This dataset enables a more comprehensive study of multimodal interaction on visual behavior in virtual reality environments. We analyze our collected scanpaths from a total of 87 participants viewing 85 different videos and show that various factors such as viewing mode, content type, and gender significantly impact eye movement statistics. We demonstrate the potential of D-SAV360 as a benchmarking resource for state-of-the-art attention prediction models and discuss its possible applications in further research. By providing a comprehensive dataset of eye movement data for dynamic, multimodal virtual environments, our work can facilitate future investigations of visual behavior and attention in virtual reality.
C1 [Bernal-Berdun, Edurne; Martin, Daniel; Malpica, Sandra; Perez, Pedro J.; Gutierrez, Diego; Masia, Belen; Serrano, Ana] Univ Zaragoza, I3A, Zaragoza, Spain.
C3 University of Zaragoza
RP Bernal-Berdun, E (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM edurnebernal@unizar.es; danims@unizar.es; smalpica@unizar.es;
   756642@unizar.es; diegog@unizar.es; bmasia@unizar.es; anase@unizar.es
RI Martin, Daniel/KLZ-9356-2024; Malpica, Sandra/LBH-5196-2024; Serrano
   Pacheu, Ana Belen/ABC-3358-2021
OI Bernal-Berdun, Edurne/0000-0002-5275-8652; Serrano Pacheu, Ana
   Belen/0000-0002-7796-3177
FU European Union [682080, 956585]; Spanish Agencia Estatal de
   Investigacion [PID2019-105004GB-I00, PID2022-141539NB-I00]; Gobierno de
   Aragon
FX We extend our gratitude to the members of the Graphics and Imaging Lab
   for their support and collaboration in the video recordings, especially
   to Maria Plaza for her valuable assistance during the capture pro-cess.
   We would also like to thank the anonymous reviewers for their insightful
   comments and the participants in the experiment. Our work has received
   funding from the European Union's Horizon 2020 research and innovation
   programme (ERC project CHAMELEON, Grant No 682080, and Marie
   Sklodowska-Curie project PRIME, Grant No 956585). This project was also
   funded by the Spanish Agencia Estatal de Investigacion (projects
   PID2019-105004GB-I00 and PID2022-141539NB-I00). Additionally, Sandra
   Malpica, Daniel Martin, and Edurne Bernal-Berdun were supported by a
   Gobierno de Aragon predoctoral grant (2018-2022, 2020-2024, and
   2021-2025, respectively).
CR Arabadzhiyska E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073642
   Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275
   Bernal-Berdun E., 2022, Computers & Graphics, V3, P9
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Bylinskii Zoya, MIT SALIENCY BENCHMA
   Chao FY, 2021, IEEE INT WORKSH MULT, DOI 10.1109/MMSP53017.2021.9733647
   Chao FY, 2020, IEEE I C VI COM I PR, P355, DOI 10.1109/vcip49819.2020.9301766
   Chao Fang-Yi, 2020, IEEE INT CONF MULTI, P1, DOI [DOI 10.1109/icmew46912.2020.9105956, 10.1109/ICMEW46912.2020.9105956]
   Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154
   Coensel B. D., 2017, P INT C EXP NOIS CON, P5407
   Cokelek M, 2021, PROCEEDINGS OF 17TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA 2021), DOI 10.23919/MVA51890.2021.9511406
   da Silva AC, 2020, SYMP VIRTUAL AUGMENT, P39, DOI 10.1109/SVR51698.2020.00022
   Dahou Y., 2020, Lecture Notes in Computer Science
   David EJ, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P432, DOI 10.1145/3204949.3208139
   De Simone F., 2019, Electronic Imaging, V31, P3
   Gutiérrez J, 2018, SIGNAL PROCESS-IMAGE, V69, P35, DOI 10.1016/j.image.2018.05.003
   Häkkinen J, 2010, PROC SPIE, V7524, DOI 10.1117/12.838857
   Hellerud E, 2009, INT CONF ACOUST SPEE, P269, DOI 10.1109/ICASSP.2009.4959572
   Jansen L, 2009, J VISION, V9, DOI 10.1167/9.1.29
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kennedy R. S., 1993, The international journal of aviation psychology, P5
   Kim H., 2022, IEEE Trans. on Visualization and Computer Graphics, V28, P1
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Lee H., 2019, Journal of the Audio Engineering Society, V8
   Li J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2360, DOI 10.1145/3343031.3350973
   Lo WC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P211, DOI 10.1145/3083187.3083219
   Ma R., 2023, Sustainability, V15, P7
   Malpica S., 2020, Scientific Reports, P3
   Maranes C., 2020, IEEE C VIRT REAL 3D
   Martin D, 2020, CVPR WORKSH COMP VIS
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Masia B., 2021, IEEE Computer Graphics and Applications, V2, P3
   Min X., 2020, IEEE Trans. on Image Processing, V29, P2
   Miyahira A, 2000, LIFE SCI, V68, P569, DOI 10.1016/S0024-3205(00)00963-2
   Morgado P., 2020, Advances in Neural Information Processing Systems, V2
   Morgado P, 2018, ADV NEUR IN, V31
   N.-O. R. A. Thomas Politzer O.D. Former NORA President, 2008, Vision Is Our Dominant Sense
   Noesselt T., 2008, Brain Research, V1220, P2
   Nuthmann A, 2010, J VISION, V10, DOI 10.1167/10.8.20
   Ozcinar C, 2018, INT WORK QUAL MULTIM, P1
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Rana A, 2019, INT CONF ACOUST SPEE, P2012, DOI 10.1109/ICASSP.2019.8683318
   Rossi S, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3381846
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Skaramagkas V., 2021, IEEE REV BIOMEDICAL
   Su YC, 2017, LECT NOTES COMPUT SC, V10114, P154, DOI 10.1007/978-3-319-54190-7_10
   Tavakoli H. R., 2019, DAVE DEEP AUDIOVISUA, P3
   Teed Z., 2020, EUR C COMP VIS, P402, DOI [DOI 10.1007/978-3-030-58536-524, 10.1007/978-3-030-58536-5_2]
   Tian C., 2022, IEEE Trans. on Circuits and Systems for Video Technology, V32, P8
   Warp R., 2022, Journal of the Audio Engineering Society, P2
   Wilcox R, 2012, INTRODUCTION TO ROBUST ESTIMATION AND HYPOTHESIS TESTING, 3RD EDITION, P291, DOI 10.1016/B978-0-12-386983-8.00007-X
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Zhang RP, 2023, VISUAL COMPUT, V39, P1163, DOI 10.1007/s00371-021-02395-w
   Zhang Y., 2021, PREPRINT
   Zhang YM, 2023, ACM T STORAGE, V19, DOI 10.1145/3568424
   Zhang Z., 2018, P EUR C COMP VIS ECC, V1, P6
   Zhu D., 2022, ACM Trans. on Multimedia Computing, Communications and Applications
   Zhu Y., 2018, Signal Processing: Image Communication, V69, P3
NR 61
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4350
EP 4360
DI 10.1109/TVCG.2023.3320237
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100004
PM 37782595
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Song, WF
   Jin, XL
   Li, S
   Chen, CLZ
   Hao, AM
   Hou, X
AF Song, Wenfeng
   Jin, Xingliang
   Li, Shuai
   Chen, Chenglizhao
   Hao, Aimin
   Hou, Xia
TI FineStyle: Semantic-Aware Fine-Grained Motion Style Transfer with Dual
   Interactive-Flow Fusion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Motion Style Transfer; Semantic-aware Motion Transfer; Dual
   Interactive-Flow Fusion
AB We present FineStyle, a novel framework for motion style transfer that generates expressive human animations with specific styles for virtual reality and vision fields. It incorporates semantic awareness, which improves motion representation and allows for precise and stylish animation generation. Existing methods for motion style transfer have all failed to consider the semantic meaning behind the motion, resulting in limited controls over the generated human animations. To improve, FineStyle introduces a new cross-modality fusion module called Dual Interactive-Flow Fusion (DIFF). As the first attempt, DIFF integrates motion style features and semantic flows, producing semantic-aware style codes for fine-grained motion style transfer. FineStyle uses an innovative two-stage semantic guidance approach that leverages semantic clues to enhance the discriminative power of both semantic and style features. At an early stage, a semantic-guided encoder introduces distinct semantic clues into the style flow. Then, at a fine stage, both flows are further fused interactively, selecting the matched and critical clues from both flows. Extensive experiments demonstrate that FineStyle outperforms state-of-the-art methods in visual quality and controllability. By considering the semantic meaning behind motion style patterns, FineStyle allows for more precise control over motion styles. Source code and model are available on https://github.com/XingliangJin/Fine-Style.git.
C1 [Song, Wenfeng; Jin, Xingliang; Hou, Xia] Beijing Informat Sci & Technol Univ, Comp Sch, Beijing, Peoples R China.
   [Li, Shuai] Beihang Univ, Zhongguancun Lab, Beijing, Peoples R China.
   [Chen, Chenglizhao] China Univ Petr East China, Coll Comp Sci & Technol, Dongying, Peoples R China.
   [Li, Shuai; Hao, Aimin] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Hou, Xia] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg 2019RU004, Beijing, Peoples R China.
C3 Beijing Information Science & Technology University; Zhongguancun
   Laboratory; Beihang University; China University of Petroleum; Beihang
   University; Chinese Academy of Medical Sciences - Peking Union Medical
   College
RP Chen, CLZ (corresponding author), China Univ Petr East China, Coll Comp Sci & Technol, Dongying, Peoples R China.
EM songwenfenga@gmail.com; xingliangjin276@gmail.com; lishuai@buaa.edu.cn;
   cclz123@163.com; ham@buaa.edu.cn; houxia@bistu.edu.cn
RI Jin, XingLiang/GLT-3212-2022; Zhao, Mingyu/HHS-0141-2022; HOU,
   Xia/JCD-6851-2023
OI jin, xingliang/0000-0001-9209-7804
FU National Natural Science Foundation of China [62102036, 62172246,
   62272021]; Beijing Natural Science Foundation [4222024]; R&D Program of
   Beijing Municipal Education Commission [KM202211232003]; Open Project
   Program of State Key Laboratory of Virtual Reality Technology and
   Systems, Beihang University [VRLAB2022A02]; Research Unit of Virtual
   Human and Virtual Surgery [2019RU004]; National Key R&D Program of China
   [2018YFB1700603]; Youth Innovation and Technology Support Plan of
   Colleges and Universities in Shandong Province [2021KJ062]
FX This paper is supported by National Natural Science Foundation of China
   (62102036, 62172246, 62272021), Beijing Natural Science Foundation
   (4222024), R&D Program of Beijing Municipal Education Commission
   (KM202211232003), Open Project Program of State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang
   University(No.VRLAB2022A02), Research Unit of Virtual Human and Virtual
   Surgery (2019RU004), National Key R&D Program of China
   (No.2018YFB1700603), and the Youth Innovation and Technology Support
   Plan of Colleges and Universities in Shandong Province (2021KJ062).
CR Aberman K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392469
   Ahuja C, 2019, INT CONF 3D VISION, P719, DOI 10.1109/3DV.2019.00084
   Amaya K, 1996, PROC GRAPH INTERF, P222
   Aristidou A, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099566
   Baek K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14134, DOI 10.1109/ICCV48922.2021.01389
   Banaga SG, 2022, IEEE INT SYMP M AU R, P964, DOI 10.1109/ISMAR-Adjunct57072.2022.00216
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   Cai HY, 2018, LECT NOTES COMPUT SC, V11206, P374, DOI [10.1007/978-3-030-01216-8_, 10.1007/978-3-030-01216-8_23]
   Cervantes P, 2022, LECT NOTES COMPUT SC, V13677, P356, DOI 10.1007/978-3-031-19790-1_22
   Chen DP, 2021, INT SYM MIX AUGMENT, P275, DOI 10.1109/ISMAR52148.2021.00043
   Chen J., 2022, P IEEECVF C COMPUTER, P6646
   Chen XL, 2021, COMPUT GRAPH FORUM, V40, P127, DOI 10.1111/cgf.142620
   Cho Y, 2022, IEEE INT SYMP M AU R, P768, DOI 10.1109/ISMAR-Adjunct57072.2022.00162
   Choi Y, 2020, PROC CVPR IEEE, P8185, DOI 10.1109/CVPR42600.2020.00821
   CMU, Carnegie-mellon mocap database
   Du H., 2019, P ACM SIGGRAPH C MOT, P1
   Gal R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530164
   Gao RH, 2021, PROC CVPR IEEE, P15490, DOI 10.1109/CVPR46437.2021.01524
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Ghosh A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1376, DOI 10.1109/ICCV48922.2021.00143
   Guo C, 2022, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR52688.2022.00509
   Guo CA, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2021, DOI 10.1145/3394171.3413635
   Hensel M, 2017, ADV NEUR IN, V30
   Holden D, 2017, IEEE COMPUT GRAPH, V37, P42, DOI 10.1109/MCG.2017.3271464
   Holden D, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925975
   Hsu E, 2005, ACM T GRAPHIC, V24, P1082, DOI 10.1145/1073204.1073315
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ikemoto L, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477927
   Jang DK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3516429
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kawar Bahjat, 2022, arXiv
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Kwon G, 2022, PROC CVPR IEEE, P18041, DOI 10.1109/CVPR52688.2022.01753
   Lee ES, 2022, LECT NOTES COMPUT SC, V13699, P338, DOI 10.1007/978-3-031-19842-7_20
   Lin X., 2018, Human motion modeling using dvgans
   Liu CK, 2005, ACM T GRAPHIC, V24, P1071, DOI 10.1145/1073204.1073314
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu Y, 2019, IEEE T MULTIMEDIA, V21, P2209, DOI 10.1109/TMM.2019.2897897
   Liu Z.-S., 2022, arXiv
   Ma Z., 2022, IEEE T NEUR NETW LEA
   Marwah T, 2017, IEEE I CONF COMP VIS, P1435, DOI 10.1109/ICCV.2017.159
   Mason I, 2018, COMPUT GRAPH FORUM, V37, P143, DOI 10.1111/cgf.13555
   Mason I, 2022, P ACM COMPUT GRAPH, V5, DOI 10.1145/3522618
   Mixamo, About us
   MXH*10 MA W., 2010, P 2010 ACM SIGGRAPH, P21, DOI DOI 10.1109/IUCS.2010.5666642
   Park G, 2020, INT SYM MIX AUGMENT, P588, DOI 10.1109/ISMAR50242.2020.00086
   Park S, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480145
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Pavllo D., 2018, arXiv preprint arXiv:1805.06485, DOI [DOI 10.1109/HUMANOIDS.2018.8624922, 10.1109/HUMANOIDS.2018.8624922]
   Petrovich M, 2022, LECT NOTES COMPUT SC, V13682, P480, DOI 10.1007/978-3-031-20047-2_28
   Petrovich M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10965, DOI 10.1109/ICCV48922.2021.01080
   Radford A, 2021, PR MACH LEARN RES, V139
   Raimundo DW, 2022, IEEE COMPUT SOC CONF, P807, DOI 10.1109/CVPRW56347.2022.00096
   Ren Z., 2022, arXiv
   Saharia C., 2022, Advances in Neural Information Processing Systems, V35, P36479
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Shi Y., 2022, IEEE Trans. Vis. Comput. Graph., V29, P236, DOI DOI 10.1109/TVCG.2022.32094861,2,3
   Smith HJ, 2019, P ACM COMPUT GRAPH, V2, DOI 10.1145/3340254
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song Jiaming, 2020, arXiv preprint arXiv:2010.02502
   Song WF, 2022, IEEE INT SYMP M AU R, P429, DOI 10.1109/ISMAR-Adjunct57072.2022.00092
   Tao TX, 2022, PROC CVPR IEEE, P6583, DOI 10.1109/CVPR52688.2022.00648
   Tevet G, 2022, LECT NOTES COMPUT SC, V13682, P358, DOI 10.1007/978-3-031-20047-2_21
   Tevet Guy, 2022, arXiv preprint arXiv:2209.14916
   Togo R, 2021, IEEE ACCESS, V9, P64860, DOI 10.1109/ACCESS.2021.3069876
   Ulyanov D, 2016, ARXIV
   Unuma M., 1995, P 22 ANN C COMPUTER, P91, DOI DOI 10.1145/218380.218419
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vasiliu V, 2019, INT SYM MIX AUGMENT, P66, DOI 10.1109/ISMAR.2019.00-25
   Wang Jack M., 2007, P 24 INT C MACH LEAR, P975, DOI [DOI 10.1145/1273496.1273619, 10.1145/1273496.1273619]
   Wen YH, 2021, PROC CVPR IEEE, P13607, DOI 10.1109/CVPR46437.2021.01340
   Willett W, 2022, IEEE T VIS COMPUT GR, V28, P22, DOI 10.1109/TVCG.2021.3114844
   Wright M, 2022, LECT NOTES COMPUT SC, V13485, P560, DOI 10.1007/978-3-031-16788-1_34
   Wu ZJ, 2022, LECT NOTES COMPUT SC, V13676, P189, DOI 10.1007/978-3-031-19787-1_11
   Xia SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766999
   Xinghao Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P614, DOI 10.1007/978-3-030-58539-6_37
   Xun H, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P58, DOI 10.1109/ISMAR-Adjunct.2019.00029
   Yan SJ, 2019, IEEE I CONF COMP VIS, P4393, DOI 10.1109/ICCV.2019.00449
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang S., 2023, arXiv
   Yao HY, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555434
   Yin W., 2023, P IEEE CVF WINT C A, P5058
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
   Yumer ME, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925955
   Zhang Jianrong, 2023, ARXIV230106052
   Zhang M., 2022, ARXIV220815001
   Zhao M., 2023, arXiv
   Zhou KL, 2021, INT SYM MIX AUGMENT, P41, DOI 10.1109/ISMAR52148.2021.00018
NR 91
TC 0
Z9 0
U1 7
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4361
EP 4371
DI 10.1109/TVCG.2023.3320216
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100005
PM 37788214
DA 2024-11-06
ER

PT J
AU Lee, SU
   Kim, J
   Lee, J
AF Lee, Seung Un
   Kim, Jinwook
   Lee, Jeongmi
TI Effects of Reward Schedule and Avatar Visibility on Joint Agency During
   VR Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Joint Agency; Performance; Reward Schedule; Avatar Visibility; Virtual
   Reality; Collaboration
ID SENSE; STRENGTHENS; FEEDBACK
AB Joint agency, a group-level sense of agency, has been studied as an essential social cognitive element while engaging in collaborative tasks. The joint agency has been actively investigated in diverse contexts (e.g., performance, reward schedules, and predictability), yet the studies were mostly conducted in traditional 2D computer environments. Since virtual reality (VR) is an emerging technology for remote collaboration, we aimed to probe the effects of traditional reward schedule factors along with novel VR features (i.e., avatar visibility) on joint agency during remote collaboration. In this study, we implemented an experiment based on a card-matching game to test the effects of the reward schedule (fair or equal) and the counterpart's avatar hand visibility (absent or present) on the sense of joint agency. The results showed that participants felt a higher sense of joint agency when the reward was distributed equally regardless of the individual performance and when the counterpart's avatar hand was present. Moreover, the effects of reward schedule and avatar hand visibility interacted, with a bigger amount of deficit for the absent avatar hand when the reward was distributed differentially according to performance. Interestingly, the sense of joint agency was strongly correlated to the level of collaborative performance, as well as to perceptions of other social cognitive factors, including cooperativeness, reward fairness, and social presence. These results contribute to the understanding of joint agency perceptions during VR collaboration and provide design guidelines for remote collaborative tasks and environments for users' optimal social experience and performance.
C1 [Lee, Seung Un; Kim, Jinwook; Lee, Jeongmi] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, J (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM seungun.lee@kaist.ac.kr; jinwook.kim31@kaist.ac.kr; jeongmi@kaist.ac.kr
RI ; Lee, Jeongmi/D-1912-2018
OI Kim, Jinwook/0000-0002-1962-5815; Lee, Jeongmi/0000-0002-3403-8117
FU National Research Council of Science and Technology (NST) [CRC21011];
   National Research Foundation of Korea (NRF) - Ministry of Science and
   ICT (MSIT), Republic of Korea [2022R1A4A5033689]
FX This work was supported by a grant from the National Research Council of
   Science and Technology (NST) (CRC21011) and the National Research
   Foundation of Korea (NRF) (2022R1A4A5033689) funded by the Ministry of
   Science and ICT (MSIT), Republic of Korea.
CR ADAMS JS, 1965, ADV EXP SOC PSYCHOL, V2, P267
   BETTENCOURT BA, 1992, J EXP SOC PSYCHOL, V28, P301, DOI 10.1016/0022-1031(92)90048-O
   Bierhoff HW, 2012, JUSTICE AND CONFLICTS: THEORETICAL AND EMPIRICAL CONTRIBUTIONS, P135, DOI 10.1007/978-3-642-19035-3_8
   Bolt NK, 2017, COGNITION, V161, P60, DOI 10.1016/j.cognition.2017.01.004
   Bolt NK, 2016, CONSCIOUS COGN, V46, P173, DOI 10.1016/j.concog.2016.10.001
   Cappelen A. W., 2014, Proceedings of the National Academy of Sciences, V111, P2
   Cho P. S., 2020, Social Neuroscience, V15, P2
   De Vicariis C., 2022, Phenomenology and the Cognitive Sciences, V9, P1
   DEUTSCH M, 1975, J SOC ISSUES, V31, P137, DOI 10.1111/j.1540-4560.1975.tb01000.x
   Dokic J, 2010, NEUROPSYCHOLOGY OF THE SENSE OF AGENCY: FROM CONSCIOUSNESS TO ACTION, P23, DOI 10.1007/978-88-470-1587-6_2
   Freiwald JP, 2021, MENSCH AND COMPUTER 2021 (MUC 21), P393, DOI 10.1145/3473856.3473870
   Frömer R, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21315-z
   Gallotti M, 2013, TRENDS COGN SCI, V17, P160, DOI 10.1016/j.tics.2013.02.002
   Gamelin G, 2021, PERS UBIQUIT COMPUT, V25, P467, DOI 10.1007/s00779-020-01431-1
   GRANT DA, 1948, PSYCHOL BULL, V45, P427, DOI 10.1037/h0053912
   Gumilar I, 2021, COMPUT GRAPH-UK, V94, P62, DOI 10.1016/j.cag.2020.10.003
   Haggard P, 2017, NAT REV NEUROSCI, V18, P197, DOI 10.1038/nrn.2017.14
   Harms C., 2004, 7 ANN INT WORKSH PRE, P4
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Homans G. C., 1974, Social behavior: Its elementary forms, P2
   Hudson Irwin, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P14, DOI 10.1007/978-3-319-39907-2_2
   Ismail MAF, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159619
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   Jing A., 2022, Proceedings of the ACM on Human-Computer Interaction, V6, P1
   Jing A., 2022, ACM SIGGRAPH 2022 PO, P1
   Kim D., 2022, Virtual Reality, P2
   Le Bars S, 2020, COGNITION, V195, DOI 10.1016/j.cognition.2019.104117
   Liu KY, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P330, DOI 10.1109/VR51125.2022.00052
   Loehr JD, 2022, PSYCHON B REV, V29, P1089, DOI 10.3758/s13423-021-02051-3
   Loehr JD, 2018, CONSCIOUS COGN, V66, P79, DOI 10.1016/j.concog.2018.11.001
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Martinez PIC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174115
   MCCLINTOCK CG, 1966, J PERS SOC PSYCHOL, V4, P606, DOI 10.1037/h0023986
   Muth FV, 2021, BEHAV RES METHODS, V53, P1322, DOI 10.3758/s13428-020-01474-5
   Obhi S, 2011, EXP BRAIN RES, V211, P655, DOI 10.1007/s00221-011-2675-2
   Osumi M, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219222
   Pacherie E, 2011, JOINT ATTENTION: NEW DEVELOPMENTS IN PSYCHOLOGY, PHILOSOPHY OF MIND, AND SOCIAL NEUROSCIENCE, P343
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009
   Seemann A, 2009, INQUIRY, V52, P500, DOI 10.1080/00201740903302634
   Shiraishi M, 2021, NEUROPSYCHOLOGIA, V154, DOI 10.1016/j.neuropsychologia.2021.107770
   Silver CA, 2021, PSYCHON B REV, V28, P434, DOI 10.3758/s13423-020-01845-1
   Smith HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173863
   Vesper C., 2017, Frontiers in psychology, P9
   Wang P, 2020, INT J HUM-COMPUT INT, V36, P1242, DOI 10.1080/10447318.2020.1732140
   Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071
   Zaadnoordijk L, 2020, DEV COGN NEUROS-NETH, V42, DOI 10.1016/j.dcn.2020.100760
   Zama T., 2019, Frontiers in human neuroscience, V13, P2
   Zhou C, 2022, NEUROIMAGE, V252, DOI 10.1016/j.neuroimage.2022.119028
   Zhou ZJ, 2023, CONSCIOUS COGN, V111, DOI 10.1016/j.concog.2023.103521
NR 50
TC 0
Z9 0
U1 14
U2 26
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4372
EP 4382
DI 10.1109/TVCG.2023.3320221
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100006
PM 37788201
DA 2024-11-06
ER

PT J
AU Liu, HM
   Xue, H
   Zhao, LS
   Chen, DP
   Peng, Z
   Zhang, GF
AF Liu, Haomin
   Xue, Hua
   Zhao, Linsheng
   Chen, Danpeng
   Peng, Zhen
   Zhang, Guofeng
TI MagLoc-AR: Magnetic-Based Localization for Visual-Free Augmented Reality
   in Large-Scale Indoor Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Location awareness; Magnetic field measurement; Navigation;
   Magnetometers; Magnetic resonance imaging; Robustness; Indoor
   environment; Indoor localization; Augmented reality; Inertial navigation
   system
ID MONOCULAR SLAM; FIELD
AB Accurate localization of a display device is essential for AR in large-scale environments. Visual-based localization is the most commonly used solution, but poses privacy risks, suffers from robustness issues and consumes high power. Wireless signal-based localization is a potential visual-free solution, but its accuracy is not enough for AR. In this paper, we present MagLoc-AR, a novel visual-free localization solution that achieves sufficient accuracy for some AR applications (e.g. AR navigation) in large-scale indoor environments. We exploit the location-dependent magnetic field interference that is ubiquitous indoors as a localization signal. Our method requires only a consumer-grade 9-axis IMU, with the gyroscope and acceleration measurements used to recover the motion trajectory, and the magnetic measurements used to register the trajectory to the global map. To meet the accuracy requirement of AR, we propose a mapping method to reconstruct a globally consistent magnetic field of the environment, and a localization method fusing the biased magnetic measurements with the network-predicted motion to improve localization accuracy. In addition, we provide the first dataset for both visual-based and geomagnetic-based localization in large-scale indoor environments. Evaluations on the dataset demonstrate that our proposed method is sufficiently accurate for AR navigation and has advantages over the visual-based methods in terms of power consumption and robustness.
C1 [Liu, Haomin] Peking Univ & Sensetime Res, Beijing, Peoples R China.
   [Xue, Hua; Zhao, Linsheng; Peng, Zhen] SenseTime Res, Beijing, Peoples R China.
   [Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD&CG, Sensetime Res & Tetras AI, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Sensetime Res & Tetras AI, Hangzhou, Peoples R China.
EM liuhaomin@sensetime.com; xuehua@sensetime.com;
   zhaolinsheng@sensetime.com; chendanpeng@tetras.ai;
   pengzhen1@sensetime.com; zhangguofeng@zju.edu.cn
RI Liu, Haomin/IXW-5373-2023; Zhang, Ge/K-9118-2019
OI Zhang, Guofeng/0000-0001-5661-8430; Liu, Haomin/0000-0001-9511-2416
FU China Postdoctoral Science Foundation; NSF of China [61932003]
FX This work was partially supported by China Postdoctoral Science
   Foundation, and NSF of China (No. 61932003).
CR Akai N, 2015, IEEE INT C INT ROBOT, P4459, DOI 10.1109/IROS.2015.7354010
   Bahl P., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P775, DOI 10.1109/INFCOM.2000.832252
   Beauregard S., 2006, 3 WORKSH POS NAV COM, P27
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chen C., 2018, AAAI C ARTIFICIAL IN, V32
   Chen DP, 2021, INT SYM MIX AUGMENT, P275, DOI 10.1109/ISMAR52148.2021.00043
   Chen DY, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P263, DOI 10.1145/3143361.3143385
   Chintalapudi K, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P173, DOI 10.1145/1859995.1860016
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Dickinson P, 2016, INT C INDOOR POSIT
   Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828
   Faragher R, 2015, IEEE J SEL AREA COMM, V33, P2418, DOI 10.1109/JSAC.2015.2430281
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forster C., 2015, IMU preintegration on manifold for efficient visual-inertial maximum-a-posteriori estimation, P4
   Frassl M, 2013, IEEE INT C INT ROBOT, P913, DOI 10.1109/IROS.2013.6696459
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Geppert Marcel, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P333, DOI 10.1007/978-3-030-58452-8_20
   Herath S, 2020, IEEE INT CONF ROBOT, P3146, DOI 10.1109/icra40945.2020.9196860
   Hu Y, 2022, PROCEEDINGS OF THE 2022 THE 28TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, ACM MOBICOM 2022, P82, DOI 10.1145/3495243.3517021
   Klein George, 2007, P1
   Kotaru M., 2015, ACM C SPECIAL INTERE, P2
   Lee D, 2021, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR46437.2021.00324
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li B., 2012, P INDOOR POSITIONING, P1, DOI [10.1109/IPIN.2012.6418880, DOI 10.1109/IPIN.2012.6418880]
   Lin QZ, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3300139
   Liu HM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P219, DOI 10.1109/ISMAR-Adjunct51615.2020.00065
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Pittaluga F, 2019, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2019.00023
   Qin T., 2019, VINS-Fusion: An optimizationbased multi-sensor state estimator, P2
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shu YC, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P512, DOI 10.1145/2789168.2790099
   Shu YC, 2015, IEEE J SEL AREA COMM, V33, P1443, DOI 10.1109/JSAC.2015.2430274
   Solin A, 2016, 2016 EUROPEAN NAVIGATION CONFERENCE (ENC)
   Solin A, 2018, IEEE T ROBOT, V34, P1112, DOI 10.1109/TRO.2018.2830326
   Soltanaghaei E, 2021, PROCEEDINGS OF THE 27TH ACM ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (ACM MOBICOM '21), P69, DOI 10.1145/3447993.3448627
   Speciale P, 2019, PROC CVPR IEEE, P5488, DOI 10.1109/CVPR.2019.00564
   Spera E, 2021, IEEE T CIRC SYST VID, V31, P1253, DOI 10.1109/TCSVT.2019.2941040
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Trawny N., 2005, Technical Report, V2, P7
   Xie Y., 2019, 25 ANN INT C MOBILE, P2
   Yang Z., 2015, 13 ANN INT C MOB SYS, P2
   Youssef M, 2005, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES (MOBISYS 2005), P205, DOI 10.1145/1067170.1067193
   Zhao M., 2021, The ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V5, P2
NR 51
TC 1
Z9 1
U1 3
U2 20
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4383
EP 4393
DI 10.1109/TVCG.2023.3321088
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100007
PM 37782616
DA 2024-11-06
ER

PT J
AU Mimnaugh, KJ
   Center, EG
   Suomalainen, M
   Becerra, I
   Lozano, E
   Murrieta-Cid, R
   Ojala, T
   Lavalle, SM
   Federmeier, KD
AF Mimnaugh, Katherine J.
   Center, Evan G.
   Suomalainen, Markku
   Becerra, Israel
   Lozano, Eliezer
   Murrieta-Cid, Rafael
   Ojala, Timo
   Lavalle, Steven M.
   Federmeier, Kara D.
TI Virtual Reality Sickness Reduces Attention During Immersive Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Task analysis; Resists; Electroencephalography; Particle measurements;
   Museums; Atmospheric measurements; Headphones; Virtual Reality;
   Cybersickness; Attention
ID MOTION SICKNESS; COGNITIVE WORKLOAD; TASK; RESOURCES; P300
AB In this paper, we show that Virtual Reality (VR) sickness is associated with a reduction in attention, which was detected with the P3b Event-Related Potential (ERP) component from electroencephalography (EEG) measurements collected in a dual-task paradigm. We hypothesized that sickness symptoms such as nausea, eyestrain, and fatigue would reduce the users' capacity to pay attention to tasks completed in a virtual environment, and that this reduction in attention would be dynamically reflected in a decrease of the P3b amplitude while VR sickness was experienced. In a user study, participants were taken on a tour through a museum in VR along paths with varying amounts of rotation, shown previously to cause different levels of VR sickness. While paying attention to the virtual museum (the primary task), participants were asked to silently count tones of a different frequency (the secondary task). Control measurements for comparison against the VR sickness conditions were taken when the users were not wearing the Head-Mounted Display (HMD) and while they were immersed in VR but not moving through the environment. This exploratory study shows, across multiple analyses, that the effect mean amplitude of the P3b collected during the task is associated with both sickness severity measured after the task with a questionnaire (SSQ) and with the number of counting errors on the secondary task. Thus, VR sickness may impair attention and task performance, and these changes in attention can be tracked with ERP measures as they happen, without asking participants to assess their sickness symptoms in the moment.
C1 [Mimnaugh, Katherine J.; Center, Evan G.; Suomalainen, Markku; Ojala, Timo; Lavalle, Steven M.] Univ Oulu, Oulu, Finland.
   [Suomalainen, Markku] VTT Tech Res Ctr Finland, Espoo, Finland.
   [Becerra, Israel; Lozano, Eliezer; Murrieta-Cid, Rafael] CIMAT, Guanajuato, Mexico.
   [Becerra, Israel] Conahcyt, Mexico City, Mexico.
   [Federmeier, Kara D.] Univ Illinois, Champaign, IL USA.
C3 University of Oulu; VTT Technical Research Center Finland; CIMAT -
   Centro de Investigacion en Matematicas; University of Illinois System;
   University of Illinois Urbana-Champaign
RP Mimnaugh, KJ (corresponding author), Univ Oulu, Oulu, Finland.
EM katherine.mimnaugh@oulu.fi; evan.center@oulu.fi;
   markku.suomalainen@vtt.fi; israelb@cimat.mx; eliezer.lozano@cimat.mx;
   murrieta@cimat.mx; timo.ojala@oulu.fi; steven.lavalle@oulu.fi;
   kfederme@illinois.edu
RI Murrieta-Cid, Rafael/AAA-4563-2022; Mimnaugh, Katherine/AAL-6536-2021;
   Federmeier, Kara/B-3180-2009; Murrieta-Cid, Rafael/O-7833-2017
OI Center, Evan/0009-0008-4541-713X; Suomalainen,
   Markku/0000-0002-2912-9292; Mimnaugh, Katherine/0000-0002-6306-1674;
   becerra, israel/0000-0002-9788-1128; Lozano,
   Eliezer/0000-0003-1637-9046; Murrieta-Cid, Rafael/0000-0002-8334-5287
FU European Research Council Advanced Grant (ERC AdG, ILLUSIVE: Foundations
   of Perception Engineering) [101020977]; Academy of Finland
   [PERCEPT322637]; Business Finland (project HUMOR ) [3656/31/2019];
   CONACYT [745]; Google; Finnish Foundation for Technology Promotion
FX The authors thank Ryan Hubbard, Melinh Lai, Melissa Troyer, and members
   of the CAB Lab for feedback on the project, as well as Michael N.
   Mimnaugh and Ba sak Sakcak for feedback on the manuscript. This work was
   supported by a European Research Council Advanced Grant (ERC AdG,
   ILLUSIVE: Foundations of Perception Engineering, 101020977), the Academy
   of Finland (project PERCEPT322637), Business Finland (project HUMOR
   3656/31/2019), CONACYT (project 745), and scholarships from Google and
   the Finnish Foundation for Technology Promotion
CR Ahn M. H., 2020, Frontiers in Neuroscience, V14, P1, DOI [10.3389/fnins.2020.6008398,9, DOI 10.3389/FNINS.2020.6008398,9]
   Aksoy M, 2021, EXP BRAIN RES, V239, P3007, DOI 10.1007/s00221-021-06158-w
   Allison BZ, 2008, BIOL PSYCHOL, V77, P277, DOI 10.1016/j.biopsycho.2007.10.014
   Allison BZ, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13569
   Baldwin CL, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00406
   Band GPH, 2006, EUR J COGN PSYCHOL, V18, P481, DOI 10.1080/09541440500422675
   Banz BC, 2020, NEUROREPORT, V31, P619, DOI 10.1097/WNR.0000000000001451
   Bashiri Azadeh, 2017, Korean J Pediatr, V60, P337, DOI 10.3345/kjp.2017.60.11.337
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Becerra I, 2020, IEEE ROBOT AUTOM LET, V5, P6489, DOI 10.1109/LRA.2020.3015191
   Bogle JM, 2022, CURR OPIN NEUROL, V35, P126, DOI 10.1097/WCO.0000000000001013
   Brooks ME, 2017, R J, V9, P378, DOI 10.32614/RJ-2017-066
   Caserman P, 2021, VIRTUAL REAL-LONDON, V25, P1153, DOI 10.1007/s10055-021-00513-6
   Chang E, 2023, VIRTUAL REAL-LONDON, V27, P2073, DOI 10.1007/s10055-023-00795-y
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chun MM, 2011, ANNU REV PSYCHOL, V62, P73, DOI 10.1146/annurev.psych.093008.100427
   Chung K, 2018, J MED INTERNET RES, V20, DOI 10.2196/11152
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Dimigen O, 2020, NEUROIMAGE, V207, DOI 10.1016/j.neuroimage.2019.116117
   Donchin E., 1978, Event-related brain potentials in man, P349
   Duncan CC, 2009, CLIN NEUROPHYSIOL, V120, P1883, DOI 10.1016/j.clinph.2009.07.045
   Duzmanska N, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02132
   Fang C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17155266
   Gavgani AM, 2018, J APPL PHYSIOL, V125, P1670, DOI 10.1152/japplphysiol.00338.2018
   Ghani U, 2020, NEUROSCI BIOBEHAV R, V118, P18, DOI 10.1016/j.neubiorev.2020.07.020
   Grassini S, 2021, BRAIN BEHAV, V11, DOI 10.1002/brb3.2269
   Groppe DM, 2009, NEUROIMAGE, V45, P1199, DOI 10.1016/j.neuroimage.2008.12.038
   Harjunen VJ, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00079
   Hommel B, 2019, ATTEN PERCEPT PSYCHO, V81, P2288, DOI 10.3758/s13414-019-01846-w
   Hubbard RJ, 2021, BRAIN RES, V1764, DOI 10.1016/j.brainres.2021.147466
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   ISREAL JB, 1980, PSYCHOPHYSIOLOGY, V17, P259, DOI 10.1111/j.1469-8986.1980.tb00146.x
   Jaquess KJ, 2017, INT J PSYCHOPHYSIOL, V121, P46, DOI 10.1016/j.ijpsycho.2017.09.007
   Jung TP, 2000, PSYCHOPHYSIOLOGY, V37, P163, DOI 10.1111/1469-8986.3720163
   Kahneman D., 1973, Attention and Effort, V2, P9
   Kappenman ES, 2021, NEUROIMAGE, V225, DOI 10.1016/j.neuroimage.2020.117465
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Kober SE, 2012, INT J HUM-COMPUT ST, V70, P577, DOI 10.1016/j.ijhcs.2012.03.004
   Kok A, 2001, PSYCHOPHYSIOLOGY, V38, P557, DOI 10.1017/S0048577201990559
   Kok A, 1997, BIOL PSYCHOL, V45, P19, DOI 10.1016/S0301-0511(96)05221-0
   KRAMER AF, 1987, HUM FACTORS, V29, P145, DOI 10.1177/001872088702900203
   Ladouce S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51996-y
   LAMBERT D, 1992, TECHNOMETRICS, V34, P1, DOI 10.2307/1269547
   LaValle S. M., 2023, Virtual reality, P2
   Lavie N, 2004, J EXP PSYCHOL GEN, V133, P339, DOI 10.1037/0096-3445.133.3.339
   Lee J, 2021, ASIAPAC SIGN INFO PR, P1465
   Lopez-Calderon J, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00213
   Luck S. J., 2014, An introduction to the event-related potential technique, V2, P5
   MAST TE, 1968, PERCEPT PSYCHOPHYS, V4, P237, DOI 10.3758/BF03206309
   Matsangas P., 2013, P HUMAN FACTORS ERGO, P788
   Miller MW, 2011, INT J PSYCHOPHYSIOL, V80, P75, DOI 10.1016/j.ijpsycho.2011.02.003
   Mumtaz W, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102741
   Narhi-Martinez W, 2023, WIRES COGN SCI, V14, DOI 10.1002/wcs.1633
   Nenna F, 2021, EUR J NEUROSCI, V54, P8158, DOI 10.1111/ejn.14956
   Nobre A.C., 2014, OXFORD HDB ATTENTION, P1201, DOI DOI 10.1093/OXFORDHB/9780199675111.013.040
   Nobre A.C., 2014, OXFORD HDB ATTENTION, P676, DOI [DOI 10.1093/OXFORDHB/9780199675111.001.0001, DOI 10.1093/OXFORDHB/9780199675111.013.036]
   OMAN CM, 1990, CAN J PHYSIOL PHARM, V68, P294, DOI 10.1139/y90-044
   Pion-Tonachini L, 2019, NEUROIMAGE, V198, P181, DOI 10.1016/j.neuroimage.2019.05.026
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Previc FH, 2018, AEROSP MED HUM PERF, V89, P130, DOI 10.3357/AMHP.4946.2018
   Reason J. T., 1975, Motion Sickness, P2
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Riccio G. E., 1991, Ecological Psychology, V3, P2
   Robles D, 2021, EUR J NEUROSCI, V54, P8196, DOI 10.1111/ejn.15163
   Rosseel Y, 2012, J STAT SOFTW, V48, P1, DOI 10.18637/jss.v048.i02
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Sepich NC, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943409
   Somrak A, 2019, FUTURE GENER COMP SY, V94, P302, DOI 10.1016/j.future.2018.11.041
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Strózak P, 2016, EXP BRAIN RES, V234, P3473, DOI 10.1007/s00221-016-4748-8
   Szpak A, 2019, IEEE ACCESS, V7, P130883, DOI 10.1109/ACCESS.2019.2940073
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Verleger R, 2020, PSYCHOPHYSIOLOGY, V57, DOI 10.1111/psyp.13542
   Vidulich M. A., 2012, Handbook of Human Factors and Ergonomics, P9
   Wei Y, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116028
   Wester AE, 2010, J PSYCHOPHARMACOL, V24, P1333, DOI 10.1177/0269881109348168
   Widmann A, 2015, J NEUROSCI METH, V250, P34, DOI 10.1016/j.jneumeth.2014.08.002
   Wu JT, 2020, INT J IND ERGONOM, V78, DOI 10.1016/j.ergon.2020.102981
NR 80
TC 3
Z9 3
U1 8
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4394
EP 4404
DI 10.1109/TVCG.2023.3320222
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100008
PM 37788212
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Malpica, S
   Martin, D
   Serrano, A
   Gutierrez, D
   Masia, B
AF Malpica, Sandra
   Martin, Daniel
   Serrano, Ana
   Gutierrez, Diego
   Masia, Belen
TI Task-Dependent Visual Behavior in Immersive Environments: A Comparative
   Study of Free Exploration, Memory and Visual Search
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Virtual reality; attention; viewing behavior; task-dependent behavior;
   eye tracking
ID EYE-MOVEMENTS; PERFORMANCE
AB Visual behavior depends on both bottom-up mechanisms, where gaze is driven by the visual conspicuity of the stimuli, and top-down mechanisms, guiding attention towards relevant areas based on the task or goal of the viewer. While this is well-known, visual attention models often focus on bottom-up mechanisms. Existing works have analyzed the effect of high-level cognitive tasks like memory or visual search on visual behavior; however, they have often done so with different stimuli, methodology, metrics and participants, which makes drawing conclusions and comparisons between tasks particularly difficult. In this work we present a systematic study of how different cognitive tasks affect visual behavior in a novel within-subjects design scheme. Participants performed free exploration, memory and visual search tasks in three different scenes while their eye and head movements were being recorded. We found significant, consistent differences between tasks in the distributions of fixations, saccades and head movements. Our findings can provide insights for practitioners and content creators designing task-oriented immersive applications.
C1 [Malpica, Sandra; Martin, Daniel; Serrano, Ana; Gutierrez, Diego; Masia, Belen] Univ Zaragoza I3A, Zaragoza, Spain.
RP Malpica, S (corresponding author), Univ Zaragoza I3A, Zaragoza, Spain.
EM smalpica@unizar.es; danims@unizar.es; anase@unizar.es; diegog@unizar.es;
   bmasia@unizar.es
RI Malpica, Sandra/LBH-5196-2024; Martin, Daniel/KLZ-9356-2024; Serrano
   Pacheu, Ana Belen/ABC-3358-2021
OI Martin, Daniel/0000-0002-0073-6398; Masia, Belen/0000-0003-0060-7278;
   Serrano Pacheu, Ana Belen/0000-0002-7796-3177; Malpica,
   Sandra/0000-0002-8016-7649
FU European Union [682080, 956585]; Spanish Agencia Estatal de
   Investigacion [PID2019-105004GB-I00, PID2022-141539NB-I00]; Gobierno de
   Aragon
FX We extend our gratitude to the participants of our user studies. We
   would also like to thank the anonymous reviewers for their insightful
   comments. Our work has received funding from the European Union's
   Horizon 2020 research and innovation programme (ERC project CHAMELEON,
   Grant No 682080, and Marie Sklodowska-Curie project PRIME, Grant No
   956585). This project was also funded by the Spanish Agencia Estatal de
   Investigacion (projects PID2019-105004GB-I00 and PID2022-141539NB-I00).
   Additionally, Sandra Malpica and Daniel Martin were supported by a
   Gobierno de Aragon predoctoral grant (2018-2022 and 2020-2024
   respectively).
CR Abeles D, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198242
   Assens M, 2017, IEEE INT CONF COMP V, P2331, DOI 10.1109/ICCVW.2017.275
   BALLARD DH, 1995, J COGNITIVE NEUROSCI, V7, P66, DOI 10.1162/jocn.1995.7.1.66
   Battista J., 2005, Clinical and Experimental Optometry, V88, P7
   Berger T., 2021, ACM S EYE TRACK RES, P1
   Bernal-Berdun E., 2022, Computers & Graphics, V106, P8
   Bolker BM, 2009, TRENDS ECOL EVOL, V24, P127, DOI 10.1016/j.tree.2008.10.008
   Bryan C, 2020, VIS INFORM, V4, P41, DOI 10.1016/j.visinf.2020.08.001
   Chao FY, 2020, IEEE I C VI COM I PR, P355, DOI 10.1109/vcip49819.2020.9301766
   Chao Fang-Yi, 2020, IEEE INT CONF MULTI, P1, DOI [DOI 10.1109/icmew46912.2020.9105956, 10.1109/ICMEW46912.2020.9105956]
   Dalmaijer ES, 2014, BEHAV RES METHODS, V46, P913, DOI 10.3758/s13428-013-0422-2
   Draschkow D, 2014, J VISION, V14, DOI 10.1167/14.8.10
   Enders LR, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.681042
   Fawcett JM, 2015, HANDBOOK OF ATTENTION, P1
   Flanagan J. R., 2008, Journal of Neurophysiology, V100, P2
   Goh JO, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0008238
   Hadnett-Hunter J, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3352763
   Hannula DE, 2010, FRONT HUM NEUROSCI, V4, DOI 10.3389/fnhum.2010.00166
   Haskins J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P57, DOI [10.1109/VRW50115.2020.00018, 10.1109/VRW50115.2020.0-258]
   Hayhoe M, 2005, TRENDS COGN SCI, V9, P188, DOI 10.1016/j.tics.2005.02.009
   Hayhoe MM, 2012, EXP BRAIN RES, V217, P125, DOI 10.1007/s00221-011-2979-2
   Hayhoe MM, 2003, J VISION, V3, P49, DOI 10.1167/3.1.6
   Hu Z., 2021, IEEE Transactions on Visualization and Computer Graphics, V29
   Hu ZM, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P543, DOI [10.1109/VRW50115.2020.0-153, 10.1109/VRW50115.2020.00123]
   Huang H., 2016, SIGGRAPH ASIA 2016 V, P1
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jin X, 2022, J INTERIOR DES, V47, P31, DOI 10.1111/joid.12209
   John B, 2019, INT J SEMANT COMPUT, V13, P329, DOI 10.1142/S1793351X19400142
   Johnstone E, 2000, J MARK COMMUN, V6, P141
   Kaakinen JK, 2007, MEM COGNITION, V35, P1323, DOI 10.3758/BF03193604
   Kafkas A, 2011, Q J EXP PSYCHOL, V64, P1971, DOI 10.1080/17470218.2011.588335
   Kamienkowski J. E., 2018, Discourse Processes, V55, P3
   Kit D, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094362
   Kothari R., 2020, Scientific Reports, V10, P7
   Koulieris GA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073622
   Kurz J, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00019
   LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0
   Land MF, 2001, VISION RES, V41, P3559, DOI 10.1016/S0042-6989(01)00102-X
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Li CL, 2016, J VISION, V16, DOI 10.1167/16.8.9
   Liao HI, 2012, NEUROSCIENCE OF PREFERENCE AND CHOICE: COGNITIVE AND NEURAL MECHANISMS, P277, DOI 10.1016/B978-0-12-381431-9.00022-X
   Llorach Gerard., 2014, P 20 ACM S VIRTUAL R, P137, DOI [10.1145/2671015.2671120, DOI 10.1145/2671015.2671120]
   Maranes C., 2020, IEEE C VIRT REAL 3D
   Martin D., 2022, PREPRINT
   Martin D., 2020, CVPR WORKSH COMP VIS, V2
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Matlab, Statistics and Machine Learning Toolbox
   Milisavljevic A., 2019, P ACM S EYE TRACK RE, P1
   Mustonen T, 2013, J EXP PSYCHOL-APPL, V19, P333, DOI 10.1037/a0034635
   Neider M. B., 2006, Vision Research, V46, P2
   Ozcinar C, 2018, INT WORK QUAL MULTIM, P1
   Pejic M, 2021, J EDUC COMPUT RES, V59, P896, DOI 10.1177/0735633120978617
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Rogers SL, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22726-7
   Schütz AC, 2011, J VISION, V11, DOI 10.1167/11.5.9
   Serrano A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073668
   Sitzmann V., 2017, IEEE Transactions on Visualization and Computer Graphics, V24, P1633
   Sullivan B., 2011, Journal of Vision, V11, P1
   Sun W., 2019, IEEE Transactions on Pattern Analysis and Machine Intelligence, V43, P1
   Syiem B. V., 2021, P 2021 CHI C HUM FAC, P1
   van Leeuwen PM, 2015, PROCEDIA MANUF, V3, P3325, DOI 10.1016/j.promfg.2015.07.422
   Woodman GF, 2003, J EXP PSYCHOL HUMAN, V29, P121, DOI 10.1037/0096-1523.29.1.121
   Xu RH, 2003, STAT MED, V22, P3527, DOI 10.1002/sim.1572
   Zhang Y., 2021, PREPRINT
   Zhu D., 2022, ACM Transactions on Multimedia Computing, Communications and Applications, V19, P2
   Ziv G, 2017, INT J AVIAT PSYCHOL, V26, P75, DOI 10.1080/10508414.2017.1313096
NR 67
TC 0
Z9 0
U1 4
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4417
EP 4425
DI 10.1109/TVCG.2023.3320259
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100009
PM 37788210
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Volmer, B
   Liu, JS
   Matthews, B
   Bornkessel-Schlesewsky, I
   Feiner, S
   Thomas, BH
AF Volmer, Benjamin
   Liu, Jen-Shuo
   Matthews, Brandon
   Bornkessel-Schlesewsky, Ina
   Feiner, Steven
   Thomas, Bruce H.
TI Multi-Level Precues for Guiding Tasks Within and Between Workspaces in
   Spatial Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Annotations; Color; Monitoring; Visualization; Image
   color analysis; Biomedical monitoring; Spatial augmented reality;
   predictive cues; precueing; cognitive load; multiple tasks; procedural
   task
ID PERFORMANCE
AB We explore Spatial Augmented Reality (SAR) precues (predictive cues) for procedural tasks within and between workspaces and for visualizing multiple upcoming steps in advance. We designed precues based on several factors: cue type, color transparency, and multi-level (number of precues). Precues were evaluated in a procedural task requiring the user to press buttons in three surrounding workspaces. Participants performed fastest in conditions where tasks were linked with line cues with different levels of color transparency. Precue performance was also affected by whether the next task was in the same workspace or a different one.
C1 [Volmer, Benjamin; Matthews, Brandon; Bornkessel-Schlesewsky, Ina; Thomas, Bruce H.] Univ South Australia, Adelaide, Australia.
   [Liu, Jen-Shuo; Feiner, Steven] Columbia Univ, New York, NY USA.
C3 University of South Australia; Columbia University
RP Volmer, B (corresponding author), Univ South Australia, Adelaide, Australia.
EM benjamin.volmer@mymail.unisa.edu.au; jl5004@columbia.edu;
   brandon.matthews@mymail.unisa.edu.au;
   ina.bornkessel-schlesewsky@unisa.edu.au; feiner@cs.columbia.edu;
   bruce.thomas@unisa.edu.au
RI Matthews, Brandon/AAX-4910-2021; Thomas, Bruce/A-1470-2008
OI Liu, Jen-Shuo/0000-0002-4109-5769; Matthews, Brandon
   J./0000-0002-8673-2434; Feiner, Steven/0000-0001-9978-7090; Thomas,
   Bruce/0000-0002-9148-085X
FU Australian Research Council Discovery Grant [DP180100755]; Australian
   Research Centre for Interactive and Virtual Environments at University
   of South Australia; National Science Foundation [CMMI-2037101]
FX Volmer and Thomas were partially funded by the Australian Research
   Council Discovery Grant DP180100755 and the Australian Research Centre
   for Interactive and Virtual Environments at the University of South
   Australia. Liu and Feiner were funded in part by National Science
   Foundation Grant CMMI-2037101.
CR Andersen D, 2016, VISUAL COMPUT, V32, P1481, DOI 10.1007/s00371-015-1135-6
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757
   Baudisch P., 2003, P SIGCHI C HUM FACT, P481, DOI 10.1145/642611.642695
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Baumeister J, 2016, IEEE T VIS COMPUT GR, V22, P1396, DOI 10.1109/TVCG.2016.2518133
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bimber O., 2005, SPATIAL AUGMENTED RE, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Condino S, 2020, IEEE T BIO-MED ENG, V67, P411, DOI 10.1109/TBME.2019.2914517
   Doshi A, 2017, INT J ADV MANUF TECH, V89, P1279, DOI 10.1007/s00170-016-9164-5
   Eiriksdottir E, 2011, HUM FACTORS, V53, P749, DOI 10.1177/0018720811419154
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   Furht B., 2011, Handbook of Augmented Reality, DOI [10.1007/978-1-4614-0064-61, DOI 10.1007/978-1-4614-0064-61]
   Hansen F.A., 2006, P 17 C HYPERTEXT HYP, P121, DOI DOI 10.1145/1149941.11499671,2
   Heinrich F, 2019, IEEE T VIS COMPUT GR, V25, P2157, DOI 10.1109/TVCG.2019.2903942
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Hertzum M, 2013, INT J HUM-COMPUT INT, V29, P338, DOI 10.1080/10447318.2012.711704
   Hoffmann R, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P929
   Krempien R, 2008, INT J RADIAT ONCOL, V70, P944, DOI 10.1016/j.ijrobp.2007.10.048
   Lee H, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11092630
   Liu C, 2012, P 2012 ACM ANN C HUM, P2973, DOI [10.1145/2207676.2208706, DOI 10.1145/2207676.2208706]
   Liu JS, 2022, IEEE T VIS COMPUT GR, V28, P3799, DOI 10.1109/TVCG.2022.3203111
   Liu JS, 2021, IEEE T VIS COMPUT GR, V27, P4311, DOI 10.1109/TVCG.2021.3106476
   Ludwig T., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34457241, DOI 10.1145/3411764.34457241]
   Marner MR, 2013, INT SYM MIX AUGMENT, P39, DOI 10.1109/ISMAR.2013.6671762
   MathWorks, MATLAB
   Mewes A, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1950
   NaturalPoint Inc, OptiTrack Flex 13
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   Parekh P, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-020-00057-7
   PASHLER H, 1994, PSYCHOL BULL, V116, P220, DOI 10.1037/0033-2909.116.2.220
   Pfeil K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445223
   Polvi J, 2018, IEEE T VIS COMPUT GR, V24, P2118, DOI 10.1109/TVCG.2017.2709746
   Putze F, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00144
   Raskar R, 1999, AUGMENTED REALITY, P63
   Rekimoto J., 1999, P SIGCHI C HUMAN FAC, P378, DOI [10.1145/302979.303113, DOI 10.1145/302979.303113]
   Serván J, 2012, AIP CONF PROC, V1431, P633, DOI 10.1063/1.4707618
   Tang A., 2003, COMP EFFECTIVENESS A, P73
   Thomas PC, 1992, ACM SIGCHI B, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   TUKEY JW, 1949, BIOMETRICS, V5, P99, DOI 10.2307/3001913
   un, About us
   Volmer B., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.31978102,9, DOI 10.1109/TVCG.2022.31978102,9]
   Volmer B, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P589, DOI 10.1109/VR51125.2022.00079
   Volmer B, 2018, IEEE T VIS COMPUT GR, V24, P2846, DOI 10.1109/TVCG.2018.2868587
   Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
   Yu CS, 2014, AVIAT SPACE ENVIR MD, V85, P708, DOI 10.3357/ASEM.3847.2014
   Zhou B, 2020, IEEE T VIS COMPUT GR, V26, P3514, DOI 10.1109/TVCG.2020.3023635
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 50
TC 1
Z9 1
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4449
EP 4459
DI 10.1109/TVCG.2023.3320246
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y0EV4
UT WOS:001102096500001
PM 37874709
DA 2024-11-06
ER

PT J
AU Zhang, HK
   Zhou, KH
   Shi, K
   Wang, YH
   Song, AG
   Zhu, LF
AF Zhang, Hongkun
   Zhou, Kehong
   Shi, Ke
   Wang, Yunhai
   Song, Aiguo
   Zhu, Lifeng
TI SmartSpring: A Low-Cost Wearable Haptic VR Display with Controllable
   Passive Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Passive haptic; wearable display; virtual reality
ID STIFFNESS
AB With the development of virtual reality, the practical requirements of the wearable haptic interface have been greatly emphasized. While passive haptic devices are commonly used in virtual reality, they lack generality and are difficult to precisely generate continuous force feedback to users. In this work, we present SmartSpring, a new solution for passive haptics, which is inexpensive, lightweight and capable of providing controllable force feedback in virtual reality. We propose a hybrid spring-linkage structure as the proxy and flexibly control the mechanism for adjustable system stiffness. By analyzing the structure and force model, we enable a smart transform of the structure for producing continuous force signals. We quantitatively examine the real-world performance of SmartSpring to verify our model. By asymmetrically moving or actively pressing the end-effector, we show that our design can further support rendering torque and stiffness. Finally, we demonstrate the SmartSpring in a series of scenarios with user studies and a just noticeable difference analysis. Experimental results show the potential of the developed haptic display in virtual reality.
C1 [Zhang, Hongkun; Zhou, Kehong; Song, Aiguo; Zhu, Lifeng] Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Digital Med Engn, Jiangsu Key Lab Remote Measurement & Control, Nanjing 210096, Peoples R China.
   [Shi, Ke] Natl Univ Singapore, Singapore, Singapore.
   [Wang, Yunhai] Shandong Univ, Jinan, Peoples R China.
C3 Southeast University - China; National University of Singapore; Shandong
   University
RP Zhu, LF (corresponding author), Southeast Univ, Sch Instrument Sci & Engn, State Key Lab Digital Med Engn, Jiangsu Key Lab Remote Measurement & Control, Nanjing 210096, Peoples R China.
EM H.K.Zhang5813@gmail.com; zhoukh97@163.com; shike@nus.edu.sg;
   cloudseawang@gmail.com; a.g.song@seu.edu.cn; lfzhulf@gmail.com
RI Zhang, Hong-Kun/AAQ-4481-2020; zhu, lifeng/IST-2069-2023
OI Song, Aiguo/0000-0002-1982-6780; Shi, Ke/0000-0002-6126-9818
FU NSFC [92148205, 62133009, 62132017, 62141217]; Natural Science
   Foundation of Jiangsu Province [BK20211159]; Shandong Provincial Natural
   Science Foundation [ZQ2022JQ32]; CIE-Tencent Robotics X Rhino-Bird
   Focused Research Program; Fundamental Research Funds for the Central
   Universities
FX The authors would like to thank anonymous reviewers for their valuable
   comments. This work has been supported by the NSFC under Grants
   No.92148205, 62133009, 62132017 and 62141217, the Natural Science
   Foundation of Jiangsu Province under Grants No. BK20211159, the Shandong
   Provincial Natural Science Foundation under Grants No. ZQ2022JQ32, the
   CIE-Tencent Robotics X Rhino-Bird Focused Research Program and the
   Fundamental Research Funds for the Central Universities.
CR Abdullah M, 2018, IEEE HAPTICS SYM, P334, DOI 10.1109/HAPTICS.2018.8357197
   An JN, 2006, INT J ROBOT RES, V25, P1121, DOI 10.1177/0278364906071034
   Awad MI, 2018, IEEE ACCESS, V6, P63045, DOI 10.1109/ACCESS.2018.2876802
   Bao X, 2021, IEEE ROBOT AUTOM LET, V6, P2547, DOI 10.1109/LRA.2021.3061329
   Basafa E, 2009, IEEE ENG MED BIO, P6054, DOI 10.1109/IEMBS.2009.5332616
   Benko H, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P717, DOI 10.1145/2984511.2984526
   Bilal OR, 2020, ADV MATER TECHNOL-US, V5, DOI 10.1002/admt.202000181
   Boys H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SOFT ROBOTICS (ROBOSOFT), P270, DOI 10.1109/ROBOSOFT.2018.8404931
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Choi I, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P119, DOI 10.1145/3126594.3126599
   Choi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P986, DOI 10.1109/IROS.2016.7759169
   Fang C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376470
   Frediani G, 2021, ADV MATER TECHNOL-US, V6, DOI 10.1002/admt.202100016
   Frediani G, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77591-0
   Ham Ronald, 2009, IEEE Robotics & Automation Magazine, V16, P81, DOI 10.1109/MRA.2009.933629
   Hayward V, 2007, IEEE ROBOT AUTOM MAG, V14, P88, DOI 10.1109/M-RA.2007.907921
   Heo YH, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155118
   Hinchet R, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P901, DOI 10.1145/3242587.3242657
   Horie A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P260, DOI 10.1109/VR50410.2021.00048
   Jadhav Saurabh, 2022, Soft Robotics, V9, P2
   Kikuchi T, 2016, J INTEL MAT SYST STR, V27, P859, DOI 10.1177/1045389X15596621
   Kovacs Robert, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1046, DOI 10.1145/3379337.3415854
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee C, 2017, ACTUATORS, V6, DOI 10.3390/act6030026
   Lee Yongseok, 2021, Applied Sciences, V11, P2
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Mazursky A., 2021, P 2021 CHI C HUM FAC, P1, DOI 10.1145/3411764.3445543
   Mazzotta A, 2021, MATER ADV, V2, P1787, DOI 10.1039/d0ma00817f
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   Neung Ryu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1035, DOI 10.1145/3379337.3415862
   Pacchierotti C, 2017, IEEE T HAPTICS, V10, P580, DOI 10.1109/TOH.2017.2689006
   Salazar SV, 2020, IEEE T HAPTICS, V13, P167, DOI 10.1109/TOH.2020.2967389
   Schulz A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201385
   Senin Pavel, 2008, Information and Computer Science Department University of Hawaii at Manoa Honolulu, USA, V855, P40
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Sinclair M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P815, DOI 10.1145/3332165.3347891
   Song K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45422-6
   Sousa E, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P335, DOI 10.1109/WHC49131.2021.9517204
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Swindells Colin, 2003, P 5 INT C MULT INT I, P7
   Teng SY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P5, DOI 10.1145/3242587.3242628
   Tsumura R, 2020, INT J COMPUT ASS RAD, V15, P1323, DOI 10.1007/s11548-020-02130-1
   WANG Dangxiao, 2019, Virtual Reality & Intelligent Hardware, V1, P2
   Wang Shuangyi, 2019, Applied Sciences, V9, P2
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Yang Humphrey, 2022, CHI C HUMAN FACTORS, P2
   Yoshida S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376358
   Zenner A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300441
   Zenner A, 2017, IEEE T VIS COMPUT GR, V23, P1312, DOI 10.1109/TVCG.2017.2656978
   Zenner Andre, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2
   Zhao Huichan, 2020, Soft robotics, V7, P1
   Zhu Lifeng, 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Zhu MJ, 2022, P IEEE, V110, P246, DOI 10.1109/JPROC.2021.3140049
NR 53
TC 1
Z9 1
U1 3
U2 25
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4460
EP 4471
DI 10.1109/TVCG.2023.3320249
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100012
PM 37782602
DA 2024-11-06
ER

PT J
AU Fantini, D
   Presti, G
   Geronazzo, M
   Bona, R
   Privitera, AG
   Avanzini, F
AF Fantini, Davide
   Presti, Giorgio
   Geronazzo, Michele
   Bona, Riccardo
   Privitera, Alessandro Giuseppe
   Avanzini, Federico
TI Co-Immersion in Audio Augmented Virtuality: The Case Study of a Static
   and Approximated Late Reverberation Algorithm
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Audio Augmented Virtuality; Co-immersion; Dynamic Binaural Synthesis;
   Reverberation; Virtual Acoustics
ID PLAUSIBILITY; AUTHENTICITY; REALITY; IMPACT
AB In immersive Audio Augmented Reality, a virtual sound source should be indistinguishable from the existing real ones. This property can be evaluated with the co-immersion criterion, which encompasses scenes constituted by arbitrary configurations of real and virtual objects. Thus, we introduce the term Audio Augmented Virtuality (AAV) to describe a fully virtual environment consisting of auditory content captured from the real world, augmented by synthetic sound generation. We propose an experimental design in AAV investigating how simplified late reverberation (LR) affects the co-immersion of a sound source. Participants listened to simultaneous virtual speakers dynamically rendered through spatial Room Impulse Responses, and were asked to detect the presence of an impostor, i.e., a speaker rendered with one of two simplified LR conditions. Detection rates were found to be close to chance level, especially for one condition, suggesting a limited influence on co-immersion of the simplified LR in the evaluated AAV scenes. This methodology can be straightforwardly extended and applied to different acoustics scenes, complexities, i.e., the number of simultaneous speakers, and rendering parameters in order to further investigate the requirements for immersive audio technologies in AAR and AAV applications.
C1 [Fantini, Davide; Presti, Giorgio; Bona, Riccardo; Avanzini, Federico] Univ Milan, Milan, Italy.
   [Geronazzo, Michele] Univ Padua, Padua, Italy.
   [Geronazzo, Michele] Imperial Coll London, London, England.
   [Privitera, Alessandro Giuseppe] Univ Udine, Udine, Italy.
C3 University of Milan; University of Padua; Imperial College London;
   University of Udine
RP Fantini, D (corresponding author), Univ Milan, Milan, Italy.
EM davide.fantini@unimi.it; giorgio.presti@unimi.it;
   michele.geronazzo@unipd.it; riccardo.bona@unimi.it;
   privitera.alessandrogiuseppe@spes.uniud.it; federico.avanzini@unimi.it
RI Avanzini, Federico/HCI-9135-2022; Fantini, Davide/GRS-3096-2022;
   Geronazzo, Michele/U-8886-2017
OI Privitera, Alessandro Giuseppe/0000-0001-9800-3020; Fantini,
   Davide/0000-0003-1332-0890; Geronazzo, Michele/0000-0002-0621-2704;
   PRESTI, GIORGIO/0000-0001-7643-9915
FU European Union [101017743]
FX This work is part of SONICOM, a project that has received funding from
   the European Union's Horizon 2020 research and innovation programme
   under grant agreement No 101017743.
CR Agus N, 2018, J AUDIO ENG SOC, V66, P791, DOI 10.17743/jaes.2018.0045
   Algazi VR, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P99, DOI 10.1109/ASPAA.2001.969552
   Arend JM, 2021, J AUDIO ENG SOC, V69, P557, DOI 10.17743/jaes.2021.0009
   Avanzini F., 2023, Procedural Modeling of Interactive Sound Sources in Virtual Reality, P49, DOI [10.1007/978-3-031-04021-4_2, DOI 10.1007/978-3-031-04021-4_2]
   Bahu H., 2018, AUDIO ENG SOC C 2018
   Bailey W., 2018, AUDIO ENG SOC CONVEN, P8
   Begault D. R., 2000, 3D sound for virtual reality and multimedia
   Begault DR, 2001, J AUDIO ENG SOC, V49, P904
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   Bergström I, 2017, IEEE T VIS COMPUT GR, V23, P1332, DOI 10.1109/TVCG.2017.2657138
   Bernschutz B., 2013, P 40 IT ANN C AC 39
   Best V., 2020, Trends in Hearing, V24, DOI [10.1177/23312165209483906, DOI 10.1177/23312165209483906]
   Blauert Jens, 1996, Spatial hearing: the psychophysics of human sound source localization, DOI DOI 10.7551/MITPRESS/6391.001.0001
   Bona Riccardo, 2022, AM'22: AudioMostly 2022, P36, DOI 10.1145/3561212.3561236
   Brinkmann F., 2020, AUDIO ENG SOC CONVEN
   Brinkmann F, 2017, J ACOUST SOC AM, V142, P1784, DOI 10.1121/1.5005606
   Brown AD, 2015, JARO-J ASSOC RES OTO, V16, P1, DOI 10.1007/s10162-014-0496-2
   De Sena E, 2015, IEEE-ACM T AUDIO SPE, V23, P1478, DOI 10.1109/TASLP.2015.2438547
   Eaton J, 2016, IEEE-ACM T AUDIO SPE, V24, P1681, DOI 10.1109/TASLP.2016.2577502
   Enge K., 2020, P DAGA, P13
   Engel I, 2021, J ACOUST SOC AM, V149, P895, DOI 10.1121/10.0003437
   Engel J., 2020, P INT C LEARN REPR
   Ewert S. D., 2021, Funded by the Deutsche Forschungs- gemeinschaft (DFG, German Research Foundation) - Projektnummer 352015383 - SFB 1330, Project C4 and C5., DOI [10.5281/zenodo.57477531,3, DOI 10.5281/ZENODO.57477531,3]
   Fantini D., 2023, Project's repository for: Co-immersion in Audio Augmented Virtuality: the Case Study of a Static and Approximated Late Reverberation Algorithm, DOI [10.5281/zenodo.80263572, DOI 10.5281/ZENODO.80263572]
   Farina Angelo, 2010, AURORA software
   Farina Angelo, 1995, ICA95 INT C AC TROND, P26
   Geronazzo M., 2023, Human-Computer Interaction Series, V1, DOI [10.1007/978-3-031-04021-41,9, DOI 10.1007/978-3-031-04021-41,9]
   Geronazzo M, 2020, INT CONF ACOUST SPEE, P411, DOI [10.1109/ICASSP40776.2020.9053873, 10.1109/icassp40776.2020.9053873]
   Geronazzo M, 2019, J AUDIO ENG SOC, V67, P414, DOI 10.17743/jaes.2019.0010
   Gonzalez-Franco M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04201-x
   Hacihabiboglu H, 2008, APPL ACOUST, V69, P715, DOI 10.1016/j.apacoust.2007.02.006
   Hak CCJM, 2012, ACTA ACUST UNITED AC, V98, P907, DOI 10.3813/AAA.918574
   Hautus M. J., 2021, Detection theory: A user's guide, P7
   HIDAKA T, 1995, J ACOUST SOC AM, V98, P988, DOI 10.1121/1.414451
   International Organization for Standardization, 2009, ISO 3382-1: International Standard ISO/DIS 3382-1: Acoustics-Measurement of room acoustic parameters-Part 1: Performance spaces
   JACK CE, 1973, PERCEPT MOTOR SKILL, V37, P967, DOI 10.2466/pms.1973.37.3.967
   Jerald J., 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [10.1145/27927901, DOI 10.1145/27927901]
   JUCE, 2022, Freeverb
   Killion MC, 2004, J ACOUST SOC AM, V116, P2395, DOI 10.1121/1.1784440
   KLEINER M, 1993, J AUDIO ENG SOC, V41, P861
   Laitinen Mikko-Ville, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P337, DOI 10.1109/ASPAA.2009.5346545
   Lee H., 2019, AUDIO ENG SOC CONVEN
   Lee H., 2019, 3D Microphone Array Recording Comparison (3DMARCo), DOI [10.5281/zenodo.34776021,3, DOI 10.5281/ZENODO.34776021,3]
   Lee S, 2022, IEEE-ACM T AUDIO SPE, V30, P2541, DOI 10.1109/TASLP.2022.3193298
   Lindau A., 2012, Journal of the Audio Engineering Society, V60, P2
   Lindau A, 2012, ACTA ACUST UNITED AC, V98, P804, DOI 10.3813/AAA.918562
   Lokki T., 2020, Auditory Spatial Impression in Concert Halls, P173, DOI [10.1007/978-3-030-00386-9_7, DOI 10.1007/978-3-030-00386-9_7]
   Marshall AH, 2001, APPL ACOUST, V62, P91, DOI 10.1016/S0003-682X(00)00050-5
   McCormack L., 2019, AUDIO ENG SOC C 2019, P4
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Moller H, 1996, J AUDIO ENG SOC, V44, P451
   Murphy KR, 1999, J APPL PSYCHOL, V84, P234, DOI 10.1037/0021-9010.84.2.234
   Neidhardt A., 2018, AUDIO ENG SOC CONVEN, V2, P9
   Neidhardt A, 2022, TRENDS HEAR, V26, DOI 10.1177/23312165221092919
   Neidhardt A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.678875
   Oberem J, 2016, APPL ACOUST, V114, P71, DOI 10.1016/j.apacoust.2016.07.009
   Olgun O., 2019, METU SPARG Eigenmike em32 Acoustic Impulse Response Dataset v0.1.0, DOI [10.5281/zenodo.26357581,3, DOI 10.5281/ZENODO.26357581,3]
   Pike C., 2014, AUD ENG SOC C 55 INT, V2, P8
   Raghuvanshi N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201339
   Rumsey F., 2018, Journal of the Audio Engineering Society, V66, P1
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   Slater M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778829
   Smith J. O., 2010, Physical Audio Signal Processing, P2
   Snoek J, 2012, NIPS 12 P 25 INT C N, V2, P3
   Stanislaw H, 1999, BEHAV RES METH INS C, V31, P137, DOI 10.3758/BF03207704
   Stecker G. C., 2018, AUD ENG SOC C 2018 A, V1, P2
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Williams C.K., 2006, GAUSSIAN PROCESSES M, V2, P3
   Wirler S. A., 2020, AUD ENG SOC C 2020 A, P2
   Yang J, 2022, J AUDIO ENG SOC, V70, P788, DOI 10.17743/jaes.2022.0048
   Zotter F., 2019, Ambisonics: A Practical 3D Audio Theory for Recording, Studio Production,Sound Reinforcement, and Virtual Reality, P1, DOI DOI 10.1007/978-3-030-17207-7
NR 71
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4472
EP 4482
DI 10.1109/TVCG.2023.3320213
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100013
PM 37782609
OA Green Published, hybrid
DA 2024-11-06
ER

PT J
AU Romano, S
   Laviola, E
   Gattullo, M
   Fiorentino, M
   Uva, AE
AF Romano, Sara
   Laviola, Enricoandrea
   Gattullo, Michele
   Fiorentino, Michele
   Uva, Antonio Emmanuele
TI More Arrows in the Quiver: Investigating the Use of Auxiliary Models to
   Localize In-View Components with Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Augmented reality; Localization; Authoring; Auxiliary model
ID AR
AB The creation and management of content are among the main open issues for the spread of Augmented Reality. In Augmented Reality interfaces for procedural tasks, a key authoring strategy is chunking instructions and using optimized visual cues, i.e., tailored to the specific information to convey. Nevertheless, research works rarely present rationales behind their choice. This work aims to provide design guidelines for the localization of in-view and not occluded components, which is recurrent information in technical documentation. Previous studies revealed that the most suited visual cues to convey this information are auxiliary models, i.e., abstract shapes that highlight the space region where the component is located. Among them, 3D arrows are widely used, but they may produce ambiguity of information. Furthermore, from the literature, it is unclear how to design auxiliary model shapes and if they are affected by the component shapes. To fill this gap, we conducted two user studies. In the first study, we collected the preference of 45 users regarding the shape, color, and animation of auxiliary models for the localization of various component shapes. According to the results of this study, we defined guidelines for designing optimized auxiliary models based on the component shapes. In the second user study, we validated these guidelines by evaluating the performance (localization time and recognition accuracy) and user experience of 24 users. The results of this study allowed us to confirm that designing auxiliary models following our guidelines leads to a higher recognition accuracy and user experience than using 3D arrows.
C1 [Romano, Sara; Laviola, Enricoandrea; Gattullo, Michele; Fiorentino, Michele; Uva, Antonio Emmanuele] Polytech Univ Bari, Dept Mech Math & Management, IT-70126 Bari, Italy.
C3 Politecnico di Bari
RP Romano, S (corresponding author), Polytech Univ Bari, Dept Mech Math & Management, IT-70126 Bari, Italy.
EM s.romano3@phd.poliba.it; enricoandrea.laviola@poliba.it;
   michele.gattullo@poliba.it; michele.fiorentino@poliba.it;
   antonio.uva@poliba.it
RI Gattullo, Michele/AAG-4866-2021; Uva, Antonio/A-9673-2012; Fiorentino,
   Michele/M-6976-2015
OI Gattullo, Michele/0000-0003-4487-0457; Fiorentino,
   Michele/0000-0003-2197-6574
FU Italian Ministry of University and Research under the Programme
   "Department of Excellence" [CUP - D93C23000100001]
FX This work was supported by the Italian Ministry of University and
   Research under the Programme "Department of Excellence" Legge 232/2016
   (Grant No. CUP - D93C23000100001). Finally, the authors would like to
   acknowledge also all the people involved in the experiment for their
   time spent in this research.
CR Abdi L., 2017, P ACM S APPL COMP, P228
   Arledge Curtis P., 2014, Filled-in vs. Outline Icons: The Impact of Icon Style on Usability, P68
   Bauckhage C, 2005, IEEE IMAGE PROC, P1489
   Blattgerste J, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P133, DOI 10.1145/3197768.3197778
   Blattgerste J, 2017, 10TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2017), P75, DOI 10.1145/3056540.3056547
   Bonanni L., 2005, C HUM FACT COMP SYST, P1228, DOI DOI 10.1145/1056808.1056883
   Buttner S., 2015, P 17 INT C HUM COMP, P1130, DOI [10.1145/2786567.2794342, DOI 10.1145/2786567.2794342]
   Chen S., 2013, Proceedings of the 4th Augmented Human Interaction Conference (AH'13), DOI DOI 10.1145/2459236.2459249
   D'Amico B, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181265
   Di Donato M, 2015, COMPUT IND, V70, P70, DOI 10.1016/j.compind.2015.02.008
   Dimitrov D, 2008, GRAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P15
   Eschen H, 2018, PROCEDIA MANUF, V19, P156, DOI 10.1016/j.promfg.2018.01.022
   Evangelista A, 2022, LECT N MECH ENG, P141, DOI 10.1007/978-3-030-91234-5_14
   Faroult S., 1978, Getting the message across, V78
   Fiorentino M, 2014, COMPUT IND, V65, P270, DOI 10.1016/j.compind.2013.11.004
   Fraga-Lamas P., 2021, Next Generation Auto-Identification and Traceability Technologies for Industry 5.0: A Methodology and Practical Use Case for the Shipbuilding Industry
   Fukiage T, 2012, INT SYM MIX AUGMENT, P129, DOI 10.1109/ISMAR.2012.6402549
   Funk M., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments-PETRA '16, P1, DOI [10.1145/2910674.2910730, DOI 10.1145/2910674.2910730]
   Funk M, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P934, DOI 10.1145/2971648.2971706
   Gattullo M, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P172, DOI 10.1109/ISMAR-Adjunct51615.2020.00054
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Gattullo M, 2019, ROBOT CIM-INT MANUF, V56, P276, DOI 10.1016/j.rcim.2018.10.001
   Geng JH, 2020, COMPUT IND, V119, DOI 10.1016/j.compind.2020.103229
   Gruenefeld U., 2018, Flyingarrow: Pointing towards out-of-view objects on augmented reality devices, V18, P1, DOI [10.1145/3205873.3205881, DOI 10.1145/3205873.3205881]
   Gruenefeld U, 2019, MUM 2019: 18TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA, DOI 10.1145/3365610.3365620
   Hahn J, 2015, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2015), P395, DOI 10.1145/2836041.2841215
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hincapié M, 2011, 2011 13TH INTERNATIONAL CONFERENCE ON TRANSPARENT OPTICAL NETWORKS (ICTON)
   Knopfle C., 2005, Template based authoring for AR based service scenarios
   Koch C, 2014, AUTOMAT CONSTR, V48, P18, DOI 10.1016/j.autcon.2014.08.009
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Laviola E, 2023, COMPUT IND, V144, DOI 10.1016/j.compind.2022.103795
   Laviola E, 2022, INT J ADV MANUF TECH, V119, P1769, DOI 10.1007/s00170-021-08449-6
   Lavric T., 2021, 2021 INT C INN INT S, P1, DOI [10.1109/INISTA52262.2021.9548570, DOI 10.1109/INISTA52262.2021.9548570]
   Li W., 2019, Virt. Real. Intell. Hardware., V1, P622, DOI 10.1016/j.vrih.2019.09.006
   Limbu BH, 2018, J UNIVERS COMPUT SCI, V24, P108
   Livingston Mark A., 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P3, DOI 10.1109/ISMAR.2006.297788
   Livingston MA, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P56, DOI 10.1109/ISMAR.2003.1240688
   Markov-Vetter D, 2020, PROCEEDINGS OF THE 2020 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2020, DOI 10.1145/3385959.3418449
   Merenda Coleman, 2016, 2016 IEEE VR 2016 Workshop on Perceptual and Cognitive Issues in AR (PERCAR), P1, DOI 10.1109/PERCAR.2016.7562419
   Morimoto T, 2022, J CLIN MED, V11, DOI 10.3390/jcm11020470
   Mulloni A., 2011, P 13 INT C HUMAN COM, P211, DOI DOI 10.1145/2037373.2037406
   Obermair F, 2020, 2020 IEEE 7TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA 2020), P942, DOI [10.1109/iciea49774.2020.9102078, 10.1109/ICIEA49774.2020.9102078]
   Paelke V, 2014, 2014 IEEE EMERGING TECHNOLOGY AND FACTORY AUTOMATION (ETFA)
   Palmarini R, 2023, IEEE ACCESS, V11, P8407, DOI 10.1109/ACCESS.2023.3235871
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Ping JM, 2020, J SOC INF DISPLAY, V28, P892, DOI 10.1002/jsid.947
   Radkowski R, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 1B
   Radkowski R, 2015, INT J HUM-COMPUT INT, V31, P337, DOI 10.1080/10447318.2014.994194
   Renner P, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P771, DOI 10.1109/VR.2018.8446396
   Sahu CK, 2021, INT J PROD RES, V59, P4903, DOI 10.1080/00207543.2020.1859636
   Sanna A, 2015, I SYMP CONSUM ELECTR, P178, DOI 10.1109/ICCE.2015.7066370
   Schmidt S, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P279, DOI 10.1145/3279778.3279806
   Schneider Philip J., 2003, Geometric Tools for Computer Graphics, P481, DOI [10.1016/B978-155860594-7/50014-X, DOI 10.1016/B978-155860594-7/50014-X]
   Schwerdtfeger B, 2008, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2008.4637331
   Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001
   Singh S., 2006, Management Decision, V44, P783, DOI [DOI 10.1108/00251740610673332, 10.1108/00251740610673332]
   Stork S, 2010, ADV ENG INFORM, V24, P320, DOI 10.1016/j.aei.2010.05.010
   STURGES J, 1995, COLOR RES APPL, V20, P364, DOI 10.1002/col.5080200605
   Subakti H, 2018, P INT COMP SOFTW APP, P63, DOI 10.1109/COMPSAC.2018.10204
   Thomas B, 2002, PERS UBIQUIT COMPUT, V6, P75, DOI 10.1007/s007790200007
   Uva AE, 2018, INT J ADV MANUF TECH, V94, P509, DOI 10.1007/s00170-017-0846-4
   Volmer B, 2018, IEEE T VIS COMPUT GR, V24, P2846, DOI 10.1109/TVCG.2018.2868587
   Wang J., 2014, An augmented reality based system for remote collaborative maintenance instruction of complex products
   Wang Y, 2021, COMPUT GRAPH FORUM, V40, P507, DOI 10.1111/cgf.14325
   Webel S, 2011, RECENT TRENDS OF MOBILE COLLABORATIVE AUGMENTED REALITY SYSTEMS, P69, DOI 10.1007/978-1-4419-9845-3_5
   Whitlock M., 2020, P GRAPH INT, V2020
   Wiedenmaier S, 2003, INT J HUM-COMPUT INT, V16, P497, DOI 10.1207/S15327590IJHC1603_7
   Wieland J, 2022, INT SYM MIX AUGMENT, P797, DOI 10.1109/ISMAR55827.2022.00098
   Wolfe J., 2004, What attributes guide the deployment of visual attention and how do they do it?
   Zauner J., ACM SIGGRAPH 2003 SK, V2003, DOI [10.1145/965400.965448, DOI 10.1145/965400.965448]
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 73
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4483
EP 4493
DI 10.1109/TVCG.2023.3320229
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100014
PM 37782614
DA 2024-11-06
ER

PT J
AU Kleinbeck, C
   Schieber, H
   Kreimeier, J
   Martin-Gomez, A
   Unberath, M
   Roth, D
AF Kleinbeck, Constantin
   Schieber, Hannah
   Kreimeier, Julian
   Martin-Gomez, Alejandro
   Unberath, Mathias
   Roth, Daniel
TI Injured Avatars: The Impact of Embodied Anatomies and Virtual Injuries
   on Well-Being and Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Virtual reality; Avatars; Virtual embodiment; Healthcare
ID LEARNING ANATOMY; REALITY; SENSE
AB Human cognition relies on embodiment as a fundamental mechanism. Virtual avatars allow users to experience the adaptation, control, and perceptual illusion of alternative bodies. Although virtual bodies have medical applications in motor rehabilitation and therapeutic interventions, their potential for learning anatomy and medical communication remains underexplored. For learners and patients, anatomy, procedures, and medical imaging can be abstract and difficult to grasp. Experiencing anatomies, injuries, and treatments virtually through one's own body could be a valuable tool for fostering understanding. This work investigates the impact of avatars displaying anatomy and injuries suitable for such medical simulations. We ran a user study utilizing a skeleton avatar and virtual injuries, comparing to a healthy human avatar as a baseline. We evaluate the influence on embodiment, well-being, and presence with self-report questionnaires, as well as motor performance via an arm movement task. Our results show that while both anatomical representation and injuries increase feelings of eeriness, there are no negative effects on embodiment, well-being, presence, or motor performance. These findings suggest that virtual representations of anatomy and injuries are suitable for medical visualizations targeting learning or communication without significantly affecting users' mental state or physical control within the simulation.
C1 [Kleinbeck, Constantin; Schieber, Hannah; Kreimeier, Julian; Roth, Daniel] Friedrich Alexander Univ Erlangen Nurnberg, Erlangen, Germany.
   [Martin-Gomez, Alejandro; Unberath, Mathias] Johns Hopkins Univ, Baltimore, MD USA.
   [Roth, Daniel] Tech Univ Munich, Sch Med & Hlth, Klinikum rechts der Isar, Orthopaed & Sport Orthopaed, Munich, Germany.
C3 University of Erlangen Nuremberg; Johns Hopkins University; Technical
   University of Munich
RP Kleinbeck, C (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Erlangen, Germany.
EM constantin.kleinbeck@fau.de; hannah.schieber@fau.de;
   julian.kreimeier@fau.de; alejandro.martin@jhu.edu; mathias@jhu.edu;
   d.roth@fau.de
RI Gil-Ley, Alejandro/J-5851-2012
OI Schieber, Hannah/0000-0002-5786-3283; Martin-Gomez,
   Alejandro/0000-0001-9341-3477; Kreimeier, Julian/0000-0001-6861-711X;
   Kleinbeck, Constantin/0000-0003-2800-0603
FU Siemens Healthineers via the Digital Health Innovation Platform (d.hip);
   d.hip
FX The authors wish to thank Vanessa Kern for her help organizing and
   running the user study. This research work was funded by Siemens
   Healthineers via the Digital Health Innovation Platform (d.hip). We
   thank d.hip for providing a campus stipend and gratefully acknowledge
   their support.
CR Antel R, 2022, PATIENT EDUC COUNS, V105, P3038, DOI 10.1016/j.pec.2022.06.006
   Bailenson J.N., 2004, Encyclopedia of Human-Computer Interaction, P64, DOI DOI 10.1108/095041206106853731
   Bartl A, 2022, INT SYM MIX AUGMENT, P260, DOI 10.1109/ISMAR55827.2022.00041
   Bertrams A., 2020, Open Psychology, V2, P57, DOI [10.1515/psych-2020-0005, DOI 10.1515/PSYCH-2020-0005]
   Bertrand P, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00026
   Bork F, 2019, ANAT SCI EDUC, V12, P585, DOI 10.1002/ase.1864
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Brugada-Ramentol V, 2019, CONSCIOUS COGN, V71, P123, DOI 10.1016/j.concog.2019.04.003
   Campo-Prieto P, 2021, VIRTUAL REAL-LONDON, V25, P801, DOI 10.1007/s10055-020-00495-x
   Caserman P, 2019, LECT NOTES COMPUT SC, V11863, P57, DOI 10.1007/978-3-030-34644-7_5
   Chandra S., 2018, Journal of healthcare communications, V3, P1, DOI [10.4172/2472-1654.100146, DOI 10.4172/2472-1654.100146]
   Diel A, 2022, ACM T HUM-ROBOT INTE, V11, DOI 10.1145/3470742
   Duarte M. L., 2020, Morphologie, V104, P254, DOI 10.1016/j.morpho.2020.08.004
   Emmelkamp PMG, 2021, ANNU REV CLIN PSYCHO, V17, P495, DOI 10.1146/annurev-clinpsy-081219-115923
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Fertleman C, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00044
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Giraud T., 2014, CHI 14 HUM FACT COMP, P845, DOI [10.1145/2559206.2578876, DOI 10.1145/2559206.2578876]
   Harrington CM, 2018, AM J SURG, V215, P42, DOI 10.1016/j.amjsurg.2017.02.011
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Jang S, 2017, COMPUT EDUC, V106, P150, DOI 10.1016/j.compedu.2016.12.009
   Keenaghan S, 2020, CONSCIOUS COGN, V78, DOI 10.1016/j.concog.2020.102882
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kocur Martin, 2020, 26 ACM S VIRT REAL S, DOI [10.1145/3385956.3418973, DOI 10.1145/3385956.3418973]
   Latoschik M. E., 2022, Frontiers in Virtual Reality, V3, P5
   Laver KE, 2017, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008349.pub4
   Lucas GM, 2016, LECT NOTES ARTIF INT, V10011, P351, DOI 10.1007/978-3-319-47665-0_31
   Mal D., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32470893, DOI 10.1109/TVCG.2023.32470893]
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Matamala-Gomez M, 2021, J CLIN MED, V10, DOI 10.3390/jcm10010139
   Matamala-Gomez M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9020291
   Matamala-Gomez M, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00279
   Meng Ma, 2016, Medical Imaging and Augmented Reality. 7th International Conference, MIAR 2016. Proceedings: LNCS 9805, P117, DOI 10.1007/978-3-319-43775-0_11
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Osumi M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107376
   Palanica A, 2019, PERSPECT MED EDUC, V8, P123, DOI 10.1007/s40037-019-0504-7
   Peña J, 2014, COMPUT HUM BEHAV, V41, P262, DOI 10.1016/j.chb.2014.09.038
   Peña J, 2016, J COMPUT-MEDIAT COMM, V21, P195, DOI 10.1111/jcc4.12151
   Perez-Marcos D, 2012, COGN NEURODYNAMICS, V6, P295, DOI 10.1007/s11571-011-9178-5
   Perin A, 2021, ACTA NEUROCHIR, V163, P301, DOI 10.1007/s00701-020-04303-y
   Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036
   Praetorius A. S., 2020, P 15 INT C FDN DIG G, P1, DOI [10.1145/3402942.34030193,8, DOI 10.1145/3402942.34030193,8]
   Provenzano L, 2020, J CLIN MED, V9, DOI 10.3390/jcm9010098
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Ratan R, 2015, COMPUT HUM BEHAV, V50, P367, DOI 10.1016/j.chb.2015.04.010
   Ratan RA, 2016, COMMUN RES, V43, P1065, DOI 10.1177/0093650215570652
   Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993
   Riva G, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00120
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Ryan RM, 1997, J PERS, V65, P529, DOI 10.1111/j.1467-6494.1997.tb00326.x
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schauer M, 2010, Z PSYCHOL, V218, P109, DOI 10.1027/0044-3409/a000018
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert Thomas W., 2003, Zeitschrift fur Medienpsychologie, V15, P69
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Seinfeld S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79255-5
   Serino S, 2019, J CLIN PSYCHOL, V75, P313, DOI 10.1002/jclp.22724
   Skarbez R, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281530
   Skarbez R, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3134301
   Skarbez R, 2017, IEEE T VIS COMPUT GR, V23, P1322, DOI 10.1109/TVCG.2017.2657158
   Slater M, 2017, SMART COMPUT INTELL, P19, DOI 10.1007/978-981-10-5490-7_2
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   Stern Y, 2020, J CLIN MED, V9, DOI 10.3390/jcm9092931
   Sylvia Z, 2014, COMPUT HUM BEHAV, V37, P183, DOI 10.1016/j.chb.2014.04.029
   Tran TQ, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139149
   Tieri G, 2015, SCI REP-UK, V5, DOI 10.1038/srep17139
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
NR 73
TC 0
Z9 0
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4503
EP 4513
DI 10.1109/TVCG.2023.3320224
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100016
PM 37788205
OA hybrid
DA 2024-11-06
ER

PT J
AU Huang, XC
   Riddell, J
   Xiao, RB
AF Huang, Xincheng
   Riddell, James
   Xiao, Robert
TI Virtual Reality Telepresence: 360-Degree Video Streaming with
   Edge-Compute Assisted Static Foveated Compression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Streaming media; 5G mobile communication; Servers; Telepresence;
   Headphones; Bandwidth; Visualization; 360-Degree Video; Virtual Reality
AB Real-time communication with immersive 360 degrees video can enable users to be telepresent within a remotely streamed environment. Increasingly, users are shifting to mobile devices and connecting to the Internet via mobile-cellular networks. As the ideal media for 360 degrees videos, some VR headsets now also come with cellular capacity, giving them potential for mobile applications. However, streaming high-quality 360 degrees live video poses challenges for network bandwidth, particularly on cellular connections. To reduce bandwidth requirements, videos can be compressed using viewport-adaptive streaming or foveated rendering techniques. Such approaches require very low latency in order to be effective, which has previously limited their applications on traditional cellular networks. In this work, we demonstrate an end-to-end virtual reality telepresence system that streams similar to 6K 360 degrees video over 5G millimeter-wave (mmW) radio. Our use of 5G technologies, in conjunction with mobile edge compute nodes, substantially reduces latency when compared with existing 4G networks, enabling high-efficiency foveated compression over modern cellular networks on par with WiFi. We performed a technical evaluation of our system's visual quality post-compression with peak signal-to-noise ratio (PSNR) and FOVVideoVDP. We also conducted a user study to evaluate users' sensitivity to compressed video. Our findings demonstrate that our system achieves visually indistinguishable video streams while using up to 80% less data when compared with un-foveated video. We demonstrate our video compression system in the context of an immersive, telepresent video calling application.
C1 [Huang, Xincheng; Riddell, James; Xiao, Robert] Univ British Columbia, Vancouver, BC, Canada.
C3 University of British Columbia
RP Huang, XC (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
EM xchuang@cs.ubc.ca; riddell6@student.ubc.ca; brx@cs.ubc.ca
OI Riddell, James/0009-0007-3261-5412; Huang, Xincheng/0000-0001-6923-6490;
   Xiao, Robert/0000-0003-4306-8825
FU Natural Science and Engineering Research Council of Canada (NSERC)
   [RGPIN-2019-05624]; Rogers Communications Inc. under the Rogers-UBC
   Collaborative Research Grant: Augmented and Virtual Reality. We thank
   Ailin Saggau-Lyons for invaluable help in the initial development of the
   system
FX This work was supported in part by the Natural Science and Engineering
   Research Council of Canada (NSERC) under Discovery Grant
   RGPIN-2019-05624 and by Rogers Communications Inc. under the Rogers-UBC
   Collaborative Research Grant: Augmented and Virtual Reality. We thank
   Ailin Saggau-Lyons for invaluable help in the initial development of the
   system.
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Alcabaza D. V. G., 2019, Real-time realistic telepresence using a 360 degree camera and a virtual reality box, V11, P46
   Antonov M., Asynchronous timewarp examined
   Chakareski J, 2020, CONF REC ASILOMAR C, P1051, DOI 10.1109/IEEECONF51394.2020.9443328
   Doppler K, 2017, EUR CONF NETW COMMUN
   Elbamby MS, 2018, IEEE WCNC
   Elbamby MS, 2018, IEEE NETWORK, V32, P78, DOI 10.1109/MNET.2018.1700268
   Geisler W. S., 1998, SPIE, V1, P2
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Gupta A, 2015, IEEE ACCESS, V3, P1206, DOI 10.1109/ACCESS.2015.2461602
   Gupta S, 2019, IEEE INT WORKSH MULT
   Hosseini M, 2017, P IEEE VIRT REAL ANN, P423, DOI 10.1109/VR.2017.7892357
   Hosseini M, 2016, IEEE INT SYM MULTIM, P107, DOI [10.1109/ISM.2016.0028, 10.1109/ISM.2016.45]
   Illahi G, 2018, Arxiv, DOI arXiv:1809.05823
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Kasahara S., 2015, P 21 ACM S VIRTUAL R, P2
   Khan MA, 2022, IEEE ACCESS, V10, P120514, DOI 10.1109/ACCESS.2022.3220694
   Kim H. J., 2018, 2018 IEEE 18th International Conference on Nanotechnology (IEEE-NANO), DOI 10.1109/NANO.2018.8626263
   Kim HW, 2019, T EMERG TELECOMMUN T, V30, DOI 10.1002/ett.3506
   Kim J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322987
   Le T.-T., 2018, 2018 INT C INFORM NE, P2
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Li Z., 2020, P 2020 ACM DES INT S, V1, P2
   Liu X., 2017, P 16 ACM WORKSHOP HO, V1, P2
   Liu Y., 2019, MEC-Assisted panoramic VR video streaming over millimeter wave mobile networks, P2
   Lyu PYJ, 2023, OPT EXPRESS, V31, P2088, DOI 10.1364/OE.480900
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Meng XX, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203199
   Nasrabadi AT, 2017, P IEEE VIRT REAL ANN, P347, DOI 10.1109/VR.2017.7892319
   Nguyen DV, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3373359
   Orlosky J., 2017, Journal of Information Processing, V25, P2
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Qian F., 2016, P 5 WORKSH ALL THING, V2, P9
   Qian F, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P99, DOI 10.1145/3241539.3241565
   qualcomm, Qualcomm snapdragon XR2 5G platform
   Ryoo J., 2016, P 7 INT C MULTIMEDIA, P1
   Saraiji M. Y., 2017, Virtual Reality Society of Japan, V1, P2
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Stern M. K., 2010, Just Noticeable Difference, P1, DOI [10.1002/9780470479216.corpsy04816, DOI 10.1002/9780470479216.CORPSY04816]
   Sun L., 2018, P 9 ACM MULTIMEDIA S, P2
   Tang A., 2017, P 2017 C DESIGNING I, V1, P2
   Teo T., 2019, P 2019 CHI C HUMAN F, V1, P2
   tobii, Essential concepts
   Le TT, 2018, IEEE ACCESS, V6, P66576, DOI 10.1109/ACCESS.2018.2878519
   Turner E., 2018, 2018 IEEE C VIRTUAL, P1
   Wiedemann O, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123080
   wiki.panotools, Fisheye projection
   Xianglong Feng, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328914
   Yen S.-C., 2019, P 24 ACM WORKSHOP PA, V1, P2
   Yu X., 2022, Computation efficiency optimization for Millimeter-Wave mobile edge computing networks with NOMA, P2
NR 51
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4525
EP 4534
DI 10.1109/TVCG.2023.3320255
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100018
PM 37788199
DA 2024-11-06
ER

PT J
AU Ullah, AKMA
   Delamare, W
   Hasan, K
AF Ullah, A. K. M. Amanat
   Delamare, William
   Hasan, Khalad
TI Exploring Users Pointing Performance on Large Displays with Different
   Curvatures in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Task analysis; Performance evaluation; Visualization; Data
   visualization; Focusing; Error analysis; Throughput; Virtual Large
   Display; Pointing Performance; Display Curvatures; Fitts Law
ID HUMAN MOTOR SYSTEM; INFORMATION CAPACITY; MOVEMENT; AMPLITUDE;
   SELECTION; TASKS
AB Large curved displays inside Virtual Reality environments are becoming popular for visualizing high-resolution content during analytical tasks, gaming or entertainment. Prior research showed that such displays provide a wide field of view and offer users a high level of immersion. However, little is known about users' performance (e.g., pointing speed and accuracy) on them. We explore users' pointing performance on large virtual curved displays. We investigate standard pointing factors (e.g., target width and amplitude) in combination with relevant curve-related factors, namely display curvature and both linear and angular measures. Our results show that the less curved the display, the higher the performance, i.e., faster movement time. This result holds for pointing tasks controlled via their visual properties (linear widths and amplitudes) or their motor properties (angular widths and amplitudes). Additionally, display curvatures significantly affect the error rate for both linear and angular conditions. Furthermore, we observe that curved displays perform better or similar to flat displays based on throughput analysis. Finally, we discuss our results and provide suggestions regarding pointing tasks on large curved displays in VR.
C1 [Ullah, A. K. M. Amanat; Hasan, Khalad] Univ British Columbia, Okanagan, BC, Canada.
   [Delamare, William] Univ Bordeaux, ESTIA Inst Technol, EstiaR, F-64210 Bidart, France.
C3 University of British Columbia; University of British Columbia Okanagan;
   Universite de Bordeaux
RP Ullah, AKMA (corresponding author), Univ British Columbia, Okanagan, BC, Canada.
EM amanat7@student.ubc.ca; william.delamare@acm.org; khalad.hasan@ubc.ca
RI Atique Ullah, A K M/M-8886-2018
OI Ullah, A. K. M. Amanat/0000-0001-5402-0160; Hasan, Mohammad
   Khalad/0000-0002-4815-5461; Delamare, William/0000-0002-1830-4294
FU Natural Sciences and Engineering Research Council (NSERC) grant
FX This research was partially funded by a Natural Sciences and Engineering
   Research Council (NSERC) grant. We thank Joel Thiessen and Garth Evans
   from UBC Okanagan's VISUALIZATION+ EMERGINGMEDIA STUDIO (VEMS) for
   providing access to the large curved display facility. We appreciate our
   colleagues: Sohan Chowdhury, Omang Baheti, and Marium-E- Jannat for
   their support and insights
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Andrews C, 2011, INFORM VISUAL, V10, P341, DOI 10.1177/1473871611415997
   [Anonymous], 2000, I. ISO. 9241-9 ergonomic requirements for office work with visual display terminals (vdts)-part 9: Requirements for non-keyboard input devices (fdis-final draft international standard)
   Ardito C, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2682623
   Batmaz AU, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565621
   Batmaz AU, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382796
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/VR.2019.8797975, 10.1109/vr.2019.8797975]
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Cao LZ, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811550
   Cao X, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1699
   CARD SK, 1978, ERGONOMICS, V21, P601, DOI 10.1080/00140137808931762
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Cavens D., 2002, CHI 02 HUM FACT COMP, P678, DOI [DOI 10.1145/506443.5065422, 10.1145/506443.506542, DOI 10.1145/506443.506542]
   Choi Kyungah, 2015, SID S, V46, P798, DOI DOI 10.1002/SDTP.10315
   CHOWDHURY S, 2022, 2022 IEEE INT S MIX, P317, DOI DOI 10.1109/ISMAR55827.2022.00047
   Crossman E., 1957, NATURE ACQUISITION I
   Crossman E., 1956, MEASUREMENT PERCEPTU
   Czerwinski Mary, 2003, Interact, V3, P9
   Davis J, 2002, DISPLAYS, V23, P205, DOI 10.1016/S0141-9382(02)00039-2
   Ens B, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P107, DOI 10.1145/2983310.2985756
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   FITTS PM, 1992, J EXP PSYCHOL GEN, V121, P262, DOI 10.1037/0096-3445.121.3.262
   Google, 2023, Firebase realtime database: store and SYNC data in Real time
   Gori J, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3231595
   Grossman T, 2004, P SIGCHI C HUM FACT, V6, P447, DOI [10.1145/985692.985749, DOI 10.1145/985692.985749]
   Hansen JP, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206344
   Hao Jiang, 2006, Conference on Human Factors in Computing Systems. CHI2006, P1107
   Haque F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3653, DOI 10.1145/2702123.2702133
   Hennecke F, 2013, LECT NOTES COMPUT SC, V8117, P720
   HOFFMANN ER, 1994, ERGONOMICS, V37, P1071, DOI 10.1080/00140139408963719
   HOFFMANN ER, 1995, ERGONOMICS, V38, P828, DOI 10.1080/00140139508925153
   Hoffmann ER, 2011, ERGONOMICS, V54, P1175, DOI 10.1080/00140139.2011.614356
   Hourcade Juan Pablo, 2012, P SIGCHI C HUM FACT, P213, DOI DOI 10.1145/2207676.2207706
   안성희, 2014, [Journal of the ergonomics society of Korea, 대한인간공학회지], V33, P191
   Janzen I, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P188, DOI 10.1145/2858036.2858244
   Jin SC, 2020, IEEE ACCESS, V8, P192597, DOI 10.1109/ACCESS.2020.3031957
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Jota R., 2010, P GRAPH INT 2010, DOI [DOI 10.11575/PRISM/35537, 10.5555/1839214.18392612,3, DOI 10.5555/1839214.18392612,3]
   KONDRASKE GV, 1994, PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY - ENGINEERING ADVANCES: NEW OPPORTUNITIES FOR BIOMEDICAL ENGINEERS, PTS 1&2, P307, DOI 10.1109/IEMBS.1994.412031
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kovacs AJ, 2008, EXP BRAIN RES, V190, P99, DOI 10.1007/s00221-008-1497-3
   Kulik A, 2020, IEEE T VIS COMPUT GR, V26, P2041, DOI 10.1109/TVCG.2020.2973034
   Kyung G, 2021, HUM FACTORS, V63, P1182, DOI 10.1177/0018720820922717
   Lee HJ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164022
   Leusmann Jan, 2021, A literature review on distant object selection methods, DOI [10.18419/opus-12060, DOI 10.18419/OPUS-12060]
   Lischke Lars, 2016, CHI EA '16), P1706, DOI [DOI 10.1145/2851581.2892479, 10.1145/2851581.28924791,3,4, DOI 10.1145/2851581.28924791,3,4]
   MacKenzie I. S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P219, DOI 10.1145/142750.142794
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   Meta, 2023, Meta quest 2: Advanced all-in-one VR headset
   Naceri Abdeldjallil, 2010, International Journ. on Advances in Intelligent Systems, V3
   Nancel Mathieu, 2013, P SIGCHI C HUM FACT, P831, DOI [10.1145/2470654., DOI 10.1145/2470654, 10.1145/2470654.24707731,2,3, DOI 10.1145/2470654.24707731,2,3]
   Novak Jasminko, 2008, CHI 08 HUM FACT COMP, P2877, DOI [DOI 10.1145/1358628.1358777, 10.1145/1358628.13587771, DOI 10.1145/1358628.13587771]
   Oh JY, 2002, PROC GRAPH INTERF, P141
   Poli Kopper Regis Augusto, 2011, Ph. D. Dissertation
   Raftery AE, 1995, SOCIOL METHODOL, V25, P111, DOI 10.2307/271063
   Rohs M, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1409
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shi MD, 2022, TRAIT SIGNAL, V39, P475, DOI 10.18280/ts.390209
   Shoemaker G, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395135
   Shupp L, 2009, HUM-COMPUT INTERACT, V24, P230, DOI 10.1080/07370020902739429
   Siddhpuria S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173747
   Soukoreff RW, 2004, INT J HUM-COMPUT ST, V61, P751, DOI 10.1016/j.ijhcs.2004.09.001
   Tan Desney S, 2003, P SIGCHI C HUM FACT, P217, DOI [10.1145/642611.642650, DOI 10.1145/642611.642650]
   Tao D, 2021, APPL ERGON, V93, DOI 10.1016/j.apergo.2021.103370
   Triantafyllidis E, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3443442
   U. technologies, 2023, Unity real-time development platform | 2d, 3d, vr ar engine
   Ullah AKMA, 2023, 29TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2023, DOI 10.1145/3611659.3615710
   Urakami J, 2021, APPL ERGON, V90, DOI 10.1016/j.apergo.2020.103271
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1639
   Wobbrock JO, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1613
   Zhai SM, 2004, INT J HUM-COMPUT ST, V61, P823, DOI 10.1016/j.ijhcs.2004.09.007
NR 71
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4535
EP 4545
DI 10.1109/TVCG.2023.3320242
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100019
PM 37782612
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lu, ZC
   Chen, XM
   Chung, VYY
   Cai, WD
   Shen, YR
AF Lu, Zhicheng
   Chen, Xiaoming
   Chung, Vera Yuk Ying
   Cai, Weidong
   Shen, Yiran
TI EV-LFV: Synthesizing Light Field Event Streams from an Event Camera and
   Multiple RGB Cameras
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Machine Learning; Computer Vision; Light Field Image Processing;
   Event-based Vision
ID RECONSTRUCTION
AB Light field videos captured in RGB frames (RGB-LFV) can provide users with a 6 degree-of-freedom immersive video experience by capturing dense multi-subview video. Despite its potential benefits, the processing of dense multi-subview video is extremely resource-intensive, which currently limits the frame rate of RGB-LFV (i.e., lower than 30 fps) and results in blurred frames when capturing fast motion. To address this issue, we propose leveraging event cameras, which provide high temporal resolution for capturing fast motion. However, the cost of current event camera models makes it prohibitive to use multiple event cameras for RGB-LFV platforms. Therefore, we propose EV-LFV, an event synthesis framework that generates full multi-subview event-based RGB-LFV with only one event camera and multiple traditional RGB cameras. EV-LFV utilizes spatial-angular convolution, ConvLSTM, and Transformer to model RGB-LFV's angular features, temporal features, and long-range dependency, respectively, to effectively synthesize event streams for RGB-LFV. To train EV-LFV, we construct the first event-to-LFV dataset consisting of 200 RGB-LFV sequences with ground-truth event streams. Experimental results demonstrate that EV-LFV outperforms state-of-the-art event synthesis methods for generating event-based RGB-LFV, effectively alleviating motion blur in the reconstructed RGB-LFV.
C1 [Lu, Zhicheng; Chen, Xiaoming] Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Lu, Zhicheng; Chen, Xiaoming; Chung, Vera Yuk Ying; Cai, Weidong] Univ Sydney, Sch Comp Sci, Sydney, Australia.
   [Shen, Yiran] Shandong Univ, Sch Software, Jinan, Peoples R China.
C3 Beijing Technology & Business University; University of Sydney; Shandong
   University
RP Chen, XM (corresponding author), Beijing Technol & Business Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.; Chen, XM (corresponding author), Univ Sydney, Sch Comp Sci, Sydney, Australia.; Shen, YR (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.
EM zhlu2106@uni.sydney.edu.au; xiaoming.chen@btbu.edu.cn;
   vera.chung@sydney.edu.au; tom.cai@sydney.edu.au; yiran.shen@sdu.edu.cn
RI Cai, Tingwei/AAJ-8822-2020
OI Cai, Weidong/0000-0003-3706-8896; Chen, Xiaoming/0000-0002-7503-3021;
   Lu, Zhicheng/0000-0002-2995-0996; Shen, Yiran/0000-0003-1385-1480
FU Beijing Natural Science Foundation [4222003]; National Natural Science
   Foundation of China [62177001]; Research Foundation for Advanced Talents
   of Beijing Technology and Business University [19008022321]
FX This work was supported in part by Beijing Natural Science Foundation
   under Grant 4222003, National Natural Science Foundation of China under
   Grant 62177001, and Research Foundation for Advanced Talents of Beijing
   Technology and Business University under Grant 19008022321.
CR Angelopoulos A. N., 2020, IEEE Transactions on Visualization and Computer Graphics, V1
   Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Carion N, 2020, EUR C COMP VIS, P213, DOI 10.1007/978-3-030-58452-813
   Carneiro J, 2013, NEURAL NETWORKS, V45, P27, DOI 10.1016/j.neunet.2013.03.006
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Dosovitskiy G., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Duan K., 2003, INT WORKSH MULT CLAS, P4
   Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413
   Gehrig D, 2021, IEEE ROBOT AUTOM LET, V6, P2822, DOI 10.1109/LRA.2021.3060707
   Gehrig D, 2020, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR42600.2020.00364
   Gu DX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1275, DOI 10.1145/3474085.3475229
   Hidalgo-Carrió J, 2020, INT CONF 3D VISION, P534, DOI 10.1109/3DV50981.2020.00063
   Jiang B, 2024, Arxiv, DOI arXiv:2204.05172
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Koniaris C., 2018, IEEE Transactions on Visualization and Computer Graphics, V3
   Lu Z., 2022, IEEE C VIRT REAL 3D
   Lu Z., 2019, Multimedia Tools and Applications, V78, P3
   Lu ZC, 2021, IEEE MULTIMEDIA, V28, P84, DOI 10.1109/MMUL.2021.3069912
   Lu ZC, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P605, DOI [10.1109/VRW50115.2020.0-122, 10.1109/VRW50115.2020.00153]
   Messikommer N., 2022, IEEE Robotics and Automation Letters, V2
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mitrokhin A., 2018, 2018 IEEE RSJ INT C, P1
   Munda G, 2018, INT J COMPUT VISION, V126, P1381, DOI 10.1007/s11263-018-1106-2
   Paliwal A, 2020, IEEE T PATTERN ANAL, V42, P1557, DOI 10.1109/TPAMI.2020.2987316
   Posch C, 2011, IEEE J SOLID-ST CIRC, V46, P259, DOI 10.1109/JSSC.2010.2085952
   Rebecq H., 2018, P MACHINE LEARNING R, V87, P969, DOI DOI 10.1007/978-3-319-24574-4_28
   Rebecq H., 2018, International Journal of Computer Vision, V126, P2
   Sun ZN, 2022, Arxiv, DOI arXiv:2203.10016
   Tulyakov S, 2022, PROC CVPR IEEE, P17734, DOI 10.1109/CVPR52688.2022.01723
   Tulyakov S, 2021, PROC CVPR IEEE, P16150, DOI 10.1109/CVPR46437.2021.01589
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang L, 2019, PROC CVPR IEEE, P10073, DOI 10.1109/CVPR.2019.01032
   Wang TC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073614
   Wang YL, 2018, LECT NOTES COMPUT SC, V11206, P340, DOI 10.1007/978-3-030-01216-8_21
   Weng WM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2543, DOI 10.1109/ICCV48922.2021.00256
   Yeung H.W.F., 2018, P EUR C COMP VIS, P137
   Yu JY, 2017, IEEE MULTIMEDIA, V24, P104, DOI 10.1109/MMUL.2017.24
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu AZ, 2021, IEEE INT CONF COMPUT, DOI 10.1109/ICCP51581.2021.9466265
NR 42
TC 1
Z9 1
U1 5
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4546
EP 4555
DI 10.1109/TVCG.2023.3320271
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100020
PM 37788211
DA 2024-11-06
ER

PT J
AU Wu, XL
   Hung, HC
   Babu, SV
   Chuang, JH
AF Wu, Xue-Liang
   Hung, Huan-Chang
   Babu, Sabarish V.
   Chuang, Jung-Hong
TI Novel Design and Evaluation of Redirection Controllers Using Optimized
   Alignment and Artificial Potential Field
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Alignment; Artificial Potential Field; Redirected Walking; Virtual
   Reality
ID MONOCULAR DISTANCE PERCEPTION; WALKING
AB Redirected walking allows users to naturally locomote within virtual environments that are larger than or different in layout from the physically tracked space. In this paper, we proposed novel optimization-driven alignment-based and Artificial Potential Field (APF) redirected walking controllers, as well as an integrated version of the two. The first two controllers employ objective functions of one variable, which is the included angle between the user's heading vector and the target vector originating from the user's physical position. The optimized angle represents the physical cell that is best aligned with the virtual cell or the target vector on which the designated point has the minimum APF value. The derived optimized angle is used to finely set RDW gains. The two objective functions can be optimized simultaneously, leading to an integrated controller that is potentially able to take advantage of the alignment-based controller and APF-based controller. Through extensive simulation-based studies, we found that the proposed alignment-based and integrated controllers significantly outperform the state-of-the-art controllers and the proposed APF based controller in terms of the number of resets. Furthermore, the proposed alignment controller and integrated controller provide a more uniform likelihood distribution across distance between resets, as compared to the other controllers.
C1 [Wu, Xue-Liang; Hung, Huan-Chang; Chuang, Jung-Hong] Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
   [Babu, Sabarish V.] Clemson Univ, Clemson, SC USA.
C3 National Yang Ming Chiao Tung University; Clemson University
RP Wu, XL (corresponding author), Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
EM xlwu.cs09@nycu.edu.tw; jhchuang@cs.nycu.edu.tw; sbabu@clemson.edu;
   hchuang@cs.nycu.edu.tw
OI Babu, Sabarish/0000-0002-8348-0534
FU Ministry of Science and Technology, R.O.C. [MOST 111-2221-E-A49-128]; US
   National Science Foundation [2007435]
FX This work was supported by the Ministry of Science and Technology,
   R.O.C., under Grant No. MOST 111-2221-E-A49-128 and the US National
   Science Foundation under Grant 2007435.
CR Azmandian M., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P9
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Babu SV, 2022, INT SYM MIX AUGMENT, P404, DOI 10.1109/ISMAR55827.2022.00056
   Babu Sabarish V., 2018, P 15 ACM S APPL PERC, P1
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bingham GP, 1998, J EXP PSYCHOL HUMAN, V24, P145, DOI 10.1037/0096-1523.24.1.145
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Grodzevich O., 2006, P FIELDS MITACS IND
   Hirt C., 2022, 2022 IEEE C VIRT REA
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Keller M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1012, DOI [10.1109/VR.2019.8798260, 10.1109/vr.2019.8798260]
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Krogh B., 1984, P SME C ROB RES NEXT, P11
   Kwon SU, 2022, INT SYM MIX AUGMENT, P758, DOI 10.1109/ISMAR55827.2022.00094
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Lin CE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376614
   Liu Huimin., 2021, Graphics and Visual Computing, V4, P200020, DOI DOI 10.1016/J.GVC.2021.200020
   Marini F, 2015, CHEMOMETR INTELL LAB, V149, P153, DOI 10.1016/j.chemolab.2015.08.020
   Marwecki S, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P511, DOI 10.1145/3242587.3242648
   Mavrotas G, 2009, APPL MATH COMPUT, V213, P455, DOI 10.1016/j.amc.2009.03.037
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Pagano C. C., 2001, Ecological Psychology, V13, P7
   Pagano CC, 1998, J EXP PSYCHOL HUMAN, V24, P1037, DOI 10.1037/0096-1523.24.4.1037
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque S., 2005, Redirected Walking
   Razzaque S., 2001, P EUR
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sing K H., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P180, DOI DOI 10.1145/2851581.2890370
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Suri S., 1986, 2 S COMPUTATIONAL GE, P14, DOI DOI 10.1145/10515.10517
   Thomas J., 2020, 26 ACM S VIRT REAL S, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.00-82, 10.1109/VR46266.2020.1581503942658]
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P419, DOI 10.1109/VR51125.2022.00061
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Xie X., 2010, Proc. 7th Symposium on Applied Perception in Graphics and Visualization (APGV), P65, DOI DOI 10.1145/1836248.1836260
   Xu S.-Z., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zhang S.-H., 2022, INT C MEDICAL IMAGE, P2
   Zmuda M. A., 2013, IEEE Transactions on Visualization and Computer Graphics, V19, P2
NR 59
TC 1
Z9 1
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4556
EP 4566
DI 10.1109/TVCG.2023.3320208
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100021
PM 37788204
DA 2024-11-06
ER

PT J
AU Dudley, JJ
   Zheng, JY
   Gupta, A
   Benko, H
   Longest, M
   Wang, RB
   Kristensson, PO
AF Dudley, John J.
   Zheng, Jingyao
   Gupta, Aakar
   Benko, Hrvoje
   Longest, Matt
   Wang, Robert
   Kristensson, Per Ola
TI Evaluating the Performance of Hand-Based Probabilistic Text Input
   Methods on a Mid-Air Virtual Qwerty Keyboard
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Keyboards; Probabilistic logic; Touch sensitive screens; Headphones;
   Decoding; Protocols; Performance evaluation; Virtual reality; text entry
AB Integrated hand-tracking on modern virtual reality (VR) headsets can be readily exploited to deliver mid-air virtual input surfaces for text entry. These virtual input surfaces can closely replicate the experience of typing on a Qwerty keyboard on a physical touchscreen, thereby allowing users to leverage their pre-existing typing skills. However, the lack of passive haptic feedback, unconstrained user motion, and potential tracking inaccuracies or observability issues encountered in this interaction setting typically degrades the accuracy of user articulations. We present a comprehensive exploration of error-tolerant probabilistic hand-based input methods to support effective text input on a mid-air virtual Qwerty keyboard. Over three user studies we examine the performance potential of hand-based text input under both gesture and touch typing paradigms. We demonstrate typical entry rates in the range of 20 to 30 wpm and average peak entry rates of 40 to 45 wpm.
C1 [Dudley, John J.; Zheng, Jingyao; Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
   [Gupta, Aakar; Benko, Hrvoje; Longest, Matt; Wang, Robert] Meta Inc, Real Labs Res, Menlo Pk, CA USA.
C3 University of Cambridge
RP Dudley, JJ (corresponding author), Univ Cambridge, Cambridge, England.
EM jjd50@cam.ac.uk; jz503@cam.ac.uk; aakarg@meta.com; benko@meta.com;
   matt.longest@meta.com; rywang@meta.com; pok21@cam.ac.uk
OI Benko, Hrvoje/0000-0002-2059-3558; Zheng, Jingyao/0000-0001-8920-308X;
   Kristensson, Per Ola/0000-0002-7139-871X; Gupta,
   Aakar/0000-0001-6435-3583
FU Reality Labs Research, Meta Inc
FX This work was supported by Reality Labs Research, Meta Inc. Supporting
   data for this publication is available
   athttps://doi.org/10.17863/CAM.97198
CR Adhikary J, 2021, LECT NOTES COMPUT SC, V12935, P132, DOI 10.1007/978-3-030-85610-6_9
   Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   Alsharif O, 2015, INT CONF ACOUST SPEE, P2076, DOI 10.1109/ICASSP.2015.7178336
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Benoit Garrett, 2017, P 2017 CHI C HUM FAC, P1500, DOI [10.1145/3027063.3053137, DOI 10.1145/3027063.3053137]
   Chen SB, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312762
   Dube TJ, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519679
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Dube Tafadzwa Joseph, 2023, P 17 INT C TANG EMB, DOI [10.1145/3569009.3573117, DOI 10.1145/3569009.3573117]
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Fowler A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P649, DOI 10.1145/2702123.2702503
   Foy C. R., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34456714, DOI 10.1145/3411764.34456714]
   Frutos-Pascual M, 2021, LECT NOTES COMPUT SC, V12932, P480, DOI 10.1007/978-3-030-85623-6_29
   Gaines D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445199
   Gaines Dylan, 2022, BAYESIAN METHODS INT, P188, DOI DOI 10.1017/9781108874830.009
   Goodman J., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P194
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   Gupta A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300244
   Han SC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392452
   Henderson J., 2020, 22 INT C HUM COMP IN, DOI [10.1145/3379503.34035493, DOI 10.1145/3379503.34035493]
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Kristensson P., 2004, P 17 ANN ACM S USER, P43, DOI DOI 10.1145/1029632.1029640
   Kristensson P. O., 2009, AI Magazine, V30, P2
   Kristensson P.-O., 2005, Proceedings of the 10th international conference on Intelligent user interfaces - IUI '05, P151
   Kristensson P. O., 2007, PhD thesis, P2
   Kristensson P. O., 2018, Computational Interaction, P4
   Kristensson PO, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P335, DOI 10.1145/2628363.2628405
   Kristensson PO, 2015, COMPUTER, V48, P84, DOI 10.1109/MC.2015.185
   Kristensson Per Ola, 2012, P 2012 ACM INT C INT, P29, DOI [DOI 10.1145/2166966.2166972, 10.1145/2166966.2166972]
   Lee Y., 2017, Virtual, Augmented and Mixed Reality, P3
   Leiva LA, 2021, PROCEEDINGS OF 23RD ACM INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447526.3472059
   Lu Xueshi, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P815, DOI 10.1145/3472749.3474788
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   Markussen A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1073, DOI 10.1145/2556288.2556964
   Mutasim A.K., 2023, CHI EA 23, P1, DOI [10.1145/3544549.3585647, DOI 10.1145/3544549.3585647]
   Ouyang T., 2017, CoRR, abs/1704.03987
   Paek T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2477
   Reyal S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P679, DOI 10.1145/2702123.2702597
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686, DOI DOI 10.1145/3379337.3415816
   Shen J., 2023, IEEE Transactions on Visualization and Computer Graphics, P2
   Shen JX, 2022, INT SYM MIX AUGMENT, P702, DOI 10.1109/ISMAR55827.2022.00088
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Spiess Florian, 2022, 2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR), P140, DOI 10.1109/AIVR56993.2022.00028
   Vertanen K, 2021, NAT LANG ENG, V27, P1, DOI 10.1017/S1351324919000548
   Vertanen K., 2011, P 13 INT C HUM COMP, P295, DOI [DOI 10.1145/2037373.2037418, 10.1145/2037373.2037418]
   Vertanen K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300821
   Vertanen K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P659, DOI 10.1145/2702123.2702135
   Vertanen K, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2555691
   Walker J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5457, DOI 10.1145/3025453.3025783
   Wang YH, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051582
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yanagihara N., 2019, 25 ACM S VIRT REAL S, P1, DOI [10.1145/3359996.33650262,3, DOI 10.1145/3359996.33650262,3]
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Young S. J., 1989, Token Passing: a Simple Conceptual Model for Connected Recognition Systems, V4
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Zhai S., 2003, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 2003), P97, DOI DOI 10.1145/642611.642630
   Zhai S., 2009, CHI EA '09 Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, P2667, DOI [10.1145/1520340.1520380, DOI 10.1145/1520340.1520380]
   Zhai SM, 2012, COMMUN ACM, V55, P91, DOI 10.1145/2330667.2330689
NR 61
TC 3
Z9 3
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4567
EP 4577
DI 10.1109/TVCG.2023.3320238
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100022
PM 37792648
DA 2024-11-06
ER

PT J
AU Yoon, B
   Shin, JE
   Kim, HI
   Oh, SY
   Kim, D
   Woo, W
AF Yoon, Boram
   Shin, Jae-eun
   Kim, Hyung-il
   Young Oh, Seo
   Kim, Dooyoung
   Woo, Woontack
TI Effects of Avatar Transparency on Social Presence in Task-Centric Mixed
   Reality Remote Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Telepresence; Avatars; Mixed Reality; Augmented Reality; Virtual
   Reality; Collaboration; Embodiment
ID COMMUNICATION; USER
AB Despite the importance of avatar representation on user experience for Mixed Reality (MR) remote collaboration involving various device environments and large amounts of task-related information, studies on how controlling visual parameters for avatars can benefit users in such situations have been scarce. Thus, we conducted a user study comparing the effects of three avatars with different transparency levels (Nontransparent, Semi-transparent, and Near-transparent) on social presence for users in Augmented Reality (AR) and Virtual Reality (VR) during task-centric MR remote collaboration. Results show that avatars with a strong visual presence are not required in situations where accomplishing the collaborative task is prioritized over social interaction. However, AR users preferred more vivid avatars than VR users. Based on our findings, we suggest guidelines on how different levels of avatar transparency should be applied based on the context of the task and device type for MR remote collaboration.
C1 [Yoon, Boram; Kim, Hyung-il; Young Oh, Seo; Kim, Dooyoung; Woo, Woontack] KAIST UVR Lab, Daejeon, South Korea.
   [Shin, Jae-eun; Woo, Woontack] Korea Adv Inst Sci & Technol, KI ITC ARRC, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), KAIST UVR Lab, Daejeon, South Korea.; Woo, W (corresponding author), Korea Adv Inst Sci & Technol, KI ITC ARRC, Daejeon, South Korea.
EM boram.yoon1206@kaist.ac.kr; jaeeunshin@kaist.ac.kr; hyungil@kaist.ac.kr;
   seoyoung.oh@kaist.ac.kr; dooyoung.kim@kaist.ac.kr; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012; Kim, Hyung-il/Y-3619-2019
OI Kim, Hyung-il/0000-0003-0926-4232; Kim, Dooyoung/0000-0002-6003-2181;
   Woo, Woontack/0000-0002-5501-4421
FU National Research Council of Science & Technology (NST) - Korea
   government (MSIT) [CRC21011]; Institute of Information & communications
   Technology Planning Evaluation (IITP) - Korea government (MSIT)
   [2019-0-01270]
FX This work was supported by the National Research Council of Science &
   Technology (NST) grant by the Korea government (MSIT) (No.CRC21011) and
   Institute of Information & communications Technology Planning Evaluation
   (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-01270,
   WISE AR UI/UX Platform Developmentfor Smartglasses)
CR Argelaguet F, 2011, INT J HUM-COMPUT ST, V69, P387, DOI 10.1016/j.ijhcs.2011.01.003
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bailenson JN, 2003, PERS SOC PSYCHOL B, V29, P819, DOI 10.1177/0146167203029007002
   Benda B, 2021, INT SYM MIX AUGMENT, P50, DOI 10.1109/ISMAR52148.2021.00019
   Benford S., 1998, ACM Transactions on computer-human interaction (TOCHI), V5, P2
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Cao YZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376688
   Cheng YF, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517452
   Cho S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P26, DOI [10.1109/VR46266.2020.1581170537418, 10.1109/VR46266.2020.00-84]
   Dubosc C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P438, DOI 10.1109/VRW52623.2021.00101
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Gamelin G, 2021, PERS UBIQUIT COMPUT, V25, P467, DOI 10.1007/s00779-020-01431-1
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Greenwald S. W., 2017, INT C IMM LEARN, P2
   Harms C., 2004, Internal consistency and reliability of the networked minds measure of social presence, V4, P8
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P4
   Hart S. G., 1988, Advances in psychology, V52, P4
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   He ZY, 2020, INT SYM MIX AUGMENT, P542, DOI 10.1109/ISMAR50242.2020.00082
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Jo D., 2017, P 30 C COMP AN SOC A, P27
   Kim S., 2019, P 2019 CHI C HUM FAC, P1
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Langbehn Eike, 2018, IEEE WORKSH EV VIRT
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Li Y., 2021, PRESENCE: Virtual and Augmented Reality, P1
   Lombard Matthew, 2009, P 12 ANN INT WORKSH, P1
   Martini M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13948
   Matamala-Gomez M, 2019, J PAIN, V20, P685, DOI 10.1016/j.jpain.2018.12.001
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Miller MR, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.656473
   Norman M., 2019, 17 INT C VIRT REAL C, P1
   Nowak KL, 2003, PRESENCE-TELEOP VIRT, V12, P481, DOI 10.1162/105474603322761289
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Osmers N., 2021, P 2021 CHI C HUM FAC, P1
   Pakanen M, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100457
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Peck TC, 2022, IEEE T VIS COMPUT GR, V28, P2179, DOI 10.1109/TVCG.2022.3150521
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Regenbrecht H, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P90, DOI 10.1109/ISMAR.2017.26
   Reinhardt J., 2020, P AUGM HUM INT C, P1
   Rhee T, 2020, IEEE T VIS COMPUT GR, V26, P1923, DOI 10.1109/TVCG.2020.2973065
   Schäfer A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533376
   Shin JE, 2022, INT SYM MIX AUGMENT, P394, DOI 10.1109/ISMAR55827.2022.00055
   Shin KS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101623
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P37, DOI 10.1162/105474600566600
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Tang A., 2004, Proceedings of Presence, Seventh Annual International Workshop on Presence, Valencia, Spain, P204
   Teo T, 2020, J MULTIMODAL USER IN, V14, P373, DOI 10.1007/s12193-020-00343-x
   Waldow K, 2019, LECT NOTES COMPUT SC, V11883, P246, DOI 10.1007/978-3-030-31908-3_15
   Weidner F., 2023, IEEE Transactions on Visualization and Computer Graphics, P4
   Weissker T., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wolf AEM, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P276, DOI 10.1145/3519391.3519392
   Wolf E, 2022, INT SYM MIX AUGMENT, P489, DOI 10.1109/ISMAR55827.2022.00065
   Wolf E, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P350, DOI 10.1109/VR51125.2022.00054
   Wu YJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.641296
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Yu K, 2021, IEEE T VIS COMPUT GR, V27, P4129, DOI 10.1109/TVCG.2021.3106480
NR 65
TC 0
Z9 0
U1 7
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4578
EP 4588
DI 10.1109/TVCG.2023.3320258
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100023
PM 37782600
DA 2024-11-06
ER

PT J
AU Lin, JH
   Cronjé, J
   Wienrich, C
   Pauli, P
   Latoschik, ME
AF Lin, Jinghuai
   Cronje, Johrine
   Wienrich, Carolin
   Pauli, Paul
   Latoschik, Marc Erich
TI Visual Indicators Representing Avatars' Authenticity in Social Virtual
   Reality and Their Impacts on Perceived Trustworthiness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE social VR; avatar; identity management; visual indicator; design
   guidelines; authenticity; trust
ID TRUST; PRIVACY; INTERACTIVITY
AB Photorealistic avatars show great potential in social VR and VR collaboration. However, identity and privacy issues are threatening avatars' authenticity in social VR. In addition to the necessary authentication and protection, effective solutions are needed to convey avatars' authenticity status to users and thereby enhance the overall trustworthiness. We designed several visual indicators (VIs) using static or dynamic visual effects on photorealistic avatars and evaluated their effectiveness in visualizing avatars' authenticity status. In this study we explored suitable attributes and designs for conveying the authenticity of photorealistic avatars and influencing their perceived trustworthiness. Furthermore, we investigated how different interactivity levels influence their effectiveness (the avatar was either presented in a static image, an animated video clip, or an immersive virtual environment). Our findings showed that using a full name can increase trust, while most other VIs could decrease users' trust. We also found that interactivity levels significantly impacted users' trust and the effectiveness of VIs. Based on our results, we developed design guidelines for visual indicators as effective tools to convey authenticity, as a first step towards the improvement of trustworthiness in social VR with identity management.
C1 [Lin, Jinghuai; Latoschik, Marc Erich] Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
   [Cronje, Johrine; Pauli, Paul] Univ Wurzburg, Dept Psychol Biol Psychol Clin Psychol & Psychothe, Wurzburg, Germany.
   [Wienrich, Carolin] Univ Wurzburg, Psychol Intelligent Interact Syst Grp, Wurzburg, Germany.
   [Pauli, Paul] Univ Wurzburg, Med Fac, Ctr Mental Hlth, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg;
   University of Wurzburg
RP Lin, JH (corresponding author), Univ Wurzburg, Human Comp Interact Grp, Wurzburg, Germany.
EM jinghuai.lin@uni-wuerzburg.de; johrine.cronje@uni-wuerzburg.de;
   carolin.wienrich@uni-wuerzburg.de; pauli@psychologie.uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
RI Lin, Jinghuai/JRW-7309-2023
OI Pauli, Paul/0000-0003-0692-6720; Cronje, Johrine/0000-0002-7764-4678;
   Wienrich, Carolin/0000-0003-3052-7172; Lin, Jinghuai/0000-0003-4205-3170
FU European Union [860315]
FX This work is part of the Privacy Matters (PriMa) project. The PriMa
   project has received funding from the European Union's Horizon 2020
   research and innovation programme under the Marie Sklodowska-Curie grant
   agreement No 860315. Special thanks to Dr. Jean-Luc Lugrin for providing
   feedback and suggestions on the manuscript.
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   Algina J, 2005, PSYCHOL METHODS, V10, P317, DOI 10.1037/1082-989X.10.3.317
   Arlati S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020261
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Babich N., 2019, Using Red and Green in UI Design
   Bailenson JN, 2004, PRESENCE-VIRTUAL AUG, V13, P428, DOI 10.1162/1054746041944803
   Beierlein C., 2012, Kurzskala zur Messung des zwischenmenschlichen Vertrauens: Die Kurzskala Interpersonales Vertrauen (KUSIV3)
   Ben-Ner A, 2010, J ECON PSYCHOL, V31, P64, DOI 10.1016/j.joep.2009.10.001
   Bente Gary, 2014, HCI in Business. First International Conference, HCIB 2014. Held as Part of HCI International 2014. Proceedings: LNCS 8527, P461, DOI 10.1007/978-3-319-07293-7_45
   Bente G., 2004, P 7 ANN INT WORKSH P, P54
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Blanca Mena M. J., 2017, Non-normal data: Is ANOVA still a valid option?, P6
   Chih-Hsiung Tu, 2002, American Journal of Distance Education, V16, P131, DOI 10.1207/S15389286AJDE1603_2
   Dionisio JDN, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2480741.2480751
   Falchuk B, 2018, IEEE TECHNOL SOC MAG, V37, P52, DOI 10.1109/MTS.2018.2826060
   Foerster K., 2021, INN LEARN SUMM ASS A, P1
   Fortin DR, 2005, J BUS RES, V58, P387, DOI 10.1016/S0148-2963(03)00106-1
   Gall D, 2020, COMPUT HUM BEHAV, V109, DOI 10.1016/j.chb.2020.106346
   Gerard R. M., 1958, Differential effects of colored lights on psychophysiological functions, P3
   Grace-Martin K., 2020, When Unequal Sample Sizes Are and Are NOT a Problem in ANOVA
   Hale J, 2018, Q J EXP PSYCHOL, V71, P989, DOI 10.1080/17470218.2017.1307865
   Heath A., 2021, Inside Facebook's metaverse for work
   Huang J., 2022, Frontiers in Virtual Reality, V3, P2
   Hurtienne J, 2017, INT J HUM-COMPUT INT, V33, P1, DOI 10.1080/10447318.2016.1232227
   Hurtienne Jorn, 2007, TEI'07. First International Conference on Tangible and Embedded Interaction, P127, DOI 10.1145/1226969.1226996
   John B, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3322868
   Joinson AN, 2010, HUM-COMPUT INTERACT, V25, P1, DOI 10.1080/07370020903586662
   Jorn H., 2007, Proceedings of the 16th International Conference on Engineering Design, P829
   Lake J., 2020, EMORY LAW JOURNAL, V69, P48
   Latoschik ME, 2022, Arxiv, DOI arXiv:2104.04846
   Liebers M., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34455282, DOI 10.1145/3411764.34455282]
   Lin J., 2023, C NAME IEEE T VISUAL, P1, DOI [10.1109/TVCG.2023.32470952,9, DOI 10.1109/TVCG.2023.32470952,9]
   Lin JH, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.974652
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   Mal D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P779, DOI 10.1109/VRW55335.2022.00245
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   McCreery MP, 2015, COMPUT HUM BEHAV, V51, P203, DOI 10.1016/j.chb.2015.04.044
   McVeigh-Schultz J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300794
   Meier A., 2017, How Ghosts Became Transparent, and Other Spectral Evolutions
   MILLER LC, 1983, J PERS SOC PSYCHOL, V44, P1234, DOI 10.1037/0022-3514.44.6.1234
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Morey Richard D, 2024, CRAN
   Morton J., 1997, A guide to color symbolism, V28, P3
   Mukherjee S, 2020, PUBLIC FINANC REV, V48, P778, DOI 10.1177/1091142120960801
   O'Brolcháin F, 2016, SCI ENG ETHICS, V22, P1, DOI 10.1007/s11948-014-9621-1
   Or CKL, 2014, COLOR RES APPL, V39, P630, DOI 10.1002/col.21832
   Pakanen M, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100457
   Pan Y, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0189078
   Picchi A., 2018, A problem for Facebook users: Identity scams
   Racoma B., 2019, Color Symbolism - Psychology Across Cultures
   Ripka G., 2020, P SITE INTERACTIVE 2, P549
   Rotter J. B., 1967, Journal of personality, P2
   Schell C, 2022, Arxiv, DOI arXiv:2210.00527
   Sluganovic I, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1056, DOI 10.1145/2976749.2978311
   Su LX, 2019, J MARKET THEORY PRAC, V27, P269, DOI 10.1080/10696679.2019.1616560
   Surprenant A. M., 2012, Measuring trust in virtual worlds: Avatar-mediated self-disclosure, V2, P5
   Taddei S, 2013, COMPUT HUM BEHAV, V29, P821, DOI 10.1016/j.chb.2012.11.022
   Volonte M, 2016, IEEE T VIS COMPUT GR, V22, P1326, DOI 10.1109/TVCG.2016.2518158
   Wang MH, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012032
   Wenninger S., 2020, 26 ACM S VIRT REAL S, P1, DOI [10.1145/3385956.34189402, DOI 10.1145/3385956.34189402]
   Wu Y, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00225
   Zach, 2021, How to Perform an ANOVA with Unequal Sample Sizes
   Zhao N, 2015, SOC BEHAV PERSONAL, V43, P855, DOI 10.2224/sbp.2015.43.5.855
   Zlatolas LN, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080772
NR 64
TC 1
Z9 1
U1 10
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4589
EP 4599
DI 10.1109/TVCG.2023.3320234
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100024
PM 37788202
OA hybrid
DA 2024-11-06
ER

PT J
AU Song, ZM
   Dudley, JJ
   Kristensson, PO
AF Song, Zhaomou
   Dudley, John J.
   Kristensson, Per Ola
TI HotGestures: Complementing Command Selection and Use with Delimiter-Free
   Gesture-Based Shortcuts in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Gesture interaction; neural networks; gesture recognition; virtual
   reality
AB Conventional desktop applications provide users with hotkeys as shortcuts for triggering different functionality. In this paper we consider what constitutes an effective parallel to hotkeys in a 3D interaction space where the input modality is no longer limited to the use of a keyboard. We propose HotGestures: a gesture-based interaction system for rapid tool selection and usage. Hand gestures are frequently used during human communication to convey information and provide natural associations with meaning. HotGestures provide shortcuts for users to seamlessly activate and use virtual tools by performing hand gestures. This approach naturally complements conventional menu interactions. We evaluate the potential of HotGestures in a set of two user studies and observe that our gesture-based technique provides fast and effective shortcuts for tool selection and usage. Participants found HotGestures to be distinctive, fast, and easy to use while also complementing conventional menu-based interaction.
C1 [Song, Zhaomou; Dudley, John J.; Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Song, ZM (corresponding author), Univ Cambridge, Cambridge, England.
EM zs323@cam.ac.uk; jjd50@cam.ac.uk; pok21@cam.ac.uk
OI Song, Zhaomou/0000-0001-7705-0928; Kristensson, Per
   Ola/0000-0002-7139-871X
FU EPSRC [EP/S027432/1, EP/W02456X/1]; EPSRC [EP/W02456X/1, EP/S027432/1]
   Funding Source: UKRI
FX John Dudley and Per Ola Kristensson were supported by EPSRC (grants
   EP/S027432/1 and EP/W02456X/1). The source code and datasetpresented in
   this paper can be found athttps://doi.org/10.17863/CAM.97131.
CR Aigner R., 2012, Microsoft Research Technical Report MSR-TR-2012-111, P1
   Alanwar A., 2017, Selecon: Scalable iot device selection and control using hand gestures, P47, DOI [10.1145/3054977.30549812, DOI 10.1145/3054977.30549812]
   [Anonymous], 2005, Project report
   Arora R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P463, DOI 10.1145/3332165.3347942
   Ban RG, 2022, INT SYM MIX AUGMENT, P748, DOI 10.1109/ISMAR55827.2022.00093
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bevilacqua F., 2010, Continuous realtime gesture following and recognition, P73, DOI DOI 10.1007/978-3-642-12553-9_7
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P3810, DOI 10.1109/TVCG.2022.3203103
   Biener V, 2020, IEEE T VIS COMPUT GR, V26, P3490, DOI 10.1109/TVCG.2020.3023567
   Brooke J., 1995, Usability Eval. Ind., V189, P8
   Chen Y., 2019, 30 BRIT MACH VIS C, DOI [10.48550/ARXIV.1907.088712,4, DOI 10.48550/ARXIV.1907.088712,4]
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   De Araujo B. R., 2012, P GRAPHICS INTERFACE, P2
   Devineau G, 2018, IEEE INT CONF AUTOMA, P106, DOI 10.1109/FG.2018.00025
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Dudley JJ, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P241, DOI 10.1145/3196709.3196737
   Feyereisen P, 2006, EUR J COGN PSYCHOL, V18, P185, DOI 10.1080/09541440540000158
   Guimbretiere F., 2005, ACM Transactions on Computer-Human Interaction, V12, P460, DOI 10.1145/1096737.1096742
   Guo C, 2017, Arxiv, DOI arXiv:1706.04599
   HART S G, 1988, P139
   Hayatpur D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1185, DOI 10.1145/3332165.3347916
   HOLM S, 1979, SCAND J STAT, V6, P65
   Kang S, 2016, COGN RES, V1, DOI 10.1186/s41235-016-0004-9
   Kopuklu O., 2019, 2019 14 IEEE INT C A, P1, DOI [10.1109/FG.2019.87565762, DOI 10.1109/FG.2019.87565762]
   Kristensson P.O., 2012, P 2012 ACM INT C INT, P89
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li Y.X., 2019, VRIH, V56, P84, DOI DOI 10.3724/SP.J.2096-5796.2018.0006
   Liu J., 2020, P IEEECVF C COMPUTER, P2
   Madan CR, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00507
   Marquardt N., 2011, Human-Computer Interaction - INTERACT 2011, P2
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   Mcneill D., 1994, Hand and mind: What gestures reveal about thought, V27, DOI [10.2307/15760151, DOI 10.2307/15760151]
   Mo G. B., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34457662, DOI 10.1145/3411764.34457662]
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Ong EJ, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P889
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Park C, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P361, DOI 10.1145/3343055.3360752
   Park T., 2011, E-gesture: A collaborative architecture for energy-efficient gesture recognition with hand-worn sensor and mobile devices, P359, DOI [10.1145/1999995.20000342, DOI 10.1145/1999995.20000342]
   Pei SY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501898
   Pook S., 2000, Proceedings of ACM Conference on Human Factors in Computing Systems (CHI). (The Hague, P263, DOI [DOI 10.1145/633292.6334461, 10.1145/633292.633446, DOI 10.1145/633292.633446]
   Ruiz J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P197
   Sapienza S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351065
   Schmitz M., 2022, P 2022 CHI C HUMAN F, DOI [10.1145/3491102.35019812, DOI 10.1145/3491102.35019812]
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Seol E., 2019, HCI International 2019 - Posters, P432, DOI DOI 10.1007/978-3-030-23528-4_582
   Shen J., 2022, IEEE transactions on visualization and computer graphics, PP, DOI [10.1109/tvcg.2022.32030043, DOI 10.1109/TVCG.2022.32030043]
   Shen JX, 2021, IEEE INT CONF AUTOMA
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Shi L., 2020, ACCV
   Song Peng., 2012, P 2012 ACM ANN C HUM, P1297, DOI DOI 10.1145/2207676.2208585
   Song S., 2017, P AAAI C ARTIFICIAL, V31, DOI [10.1609/aaai.v31i1.112122, DOI 10.1609/AAAI.V31I1.112122]
   Song ZM, 2022, INT SYM MIX AUGMENT, P864, DOI 10.1109/ISMAR55827.2022.00105
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300426
   Surale HB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300243
   Tai TM, 2018, IEEE SENSOR LETT, V2, DOI 10.1109/LSENS.2018.2864963
   Tomitsch M., 2012, P 2012 INT S PERV DI, DOI [10.1145/2307798.23078042, DOI 10.1145/2307798.23078042]
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   van Amsterdam B, 2020, IEEE INT CONF ROBOT, P1380, DOI [10.1109/ICRA40945.2020.9197301, 10.1109/icra40945.2020.9197301]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vu T. H., 2018, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., V2, DOI [10.1145/31917712, DOI 10.1145/31917712]
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Xu X., P 2022 CHI C HUMAN F
   Xu X., 2016, COMPUTER VISION ECCV, P3
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yan YK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173652
   Yasen M., 2019, PeerJ Computer Science, V5, P2
   Yuan CF, 2013, PROC CVPR IEEE, P423, DOI 10.1109/CVPR.2013.61
NR 69
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4600
EP 4610
DI 10.1109/TVCG.2023.3320257
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100025
PM 37782601
OA Green Published
DA 2024-11-06
ER

PT J
AU Kim, HI
   Yoon, B
   Oh, SY
   Woo, W
AF Kim, Hyung-il
   Yoon, Boram
   Oh, Seo Young
   Woo, Woontack
TI Visualizing Hand Force with Wearable Muscle Sensing for Enhanced Mixed
   Reality Remote Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Remote collaboration; mixed reality; sensing; visualization; remote
   assistance
ID FOREARM; CUES
AB In this paper, we present a prototype system for sharing a user's hand force in mixed reality (MR) remote collaboration on physical tasks, where hand force is estimated using wearable surface electromyography (sEMG) sensor. In a remote collaboration between a worker and an expert, hand activity plays a crucial role. However, the force exerted by the worker's hand has not been extensively investigated. Our sEMG-based system reliably captures the worker's hand force during physical tasks and conveys this information to the expert through hand force visualization, overlaid on the worker's view or on the worker's avatar. A user study was conducted to evaluate the impact of visualizing a worker's hand force on collaboration, employing three distinct visualization methods across two view modes. Our findings demonstrate that sensing and sharing hand force in MR remote collaboration improves the expert's awareness of the worker's task, significantly enhances the expert's perception of the collaborator's hand force and the weight of the interacting object, and promotes a heightened sense of social presence for the expert. Based on the findings, we provide design implications for future mixed reality remote collaboration systems that incorporate hand force sensing and visualization.
C1 [Kim, Hyung-il; Yoon, Boram; Oh, Seo Young; Woo, Woontack] KAIST UVR Lab, Daejeon, South Korea.
   [Woo, Woontack] KAIST KI ITC ARRC, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), KAIST UVR Lab, Daejeon, South Korea.; Woo, W (corresponding author), KAIST KI ITC ARRC, Daejeon, South Korea.
EM hyungil@kaist.ac.kr; boram.yoon1206@kaist.ac.kr;
   seoyoung.oh@kaist.ac.kr; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012; Kim, Hyung-il/Y-3619-2019
OI Kim, Hyung-il/0000-0003-0926-4232; Woo, Woontack/0000-0002-5501-4421
FU National Research Council of Science & Technology (NST) - Korea
   government (MSIT) [CRC21011]; Institute of Information & communications
   Technology Planning Evaluation (IITP) - Korea government (MSIT)
   [2019-0-01270]
FX This work was supported by the National Research Council of Science &
   Technology (NST) grant by the Korea government (MSIT) (No. CRC21011) and
   Institute of Information & communications Technology Planning Evaluation
   (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-01270,
   WISE AR UI/UX Platform Development for Smartglasses)
CR Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Becker V, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P1, DOI 10.1145/3267242.3267250
   Benko H., 2009, P ACM INT C INT TABL, P93, DOI [DOI 10.1145/1731903.1731924, DOI 10.1145/1731903.17319242,3]
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Buddhika T, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311839
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Dey A, 2018, INT SYM MIX AUGMENT, P165, DOI 10.1109/ISMAR.2018.00052
   Dey A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4045, DOI 10.1145/3025453.3026028
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Harms P. C., 2004, Internal consistency and reliability of the networked minds measure of social presence, V5, P6
   Hoozemans MJM, 2005, J ELECTROMYOGR KINES, V15, P358, DOI 10.1016/j.jelekin.2004.09.001
   IJsselsteijn WA, 2000, PROC SPIE, V3959, P520, DOI 10.1117/12.387188
   Iravantchi Y, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300506
   Jing A, 2022, INT SYM MIX AUGMENT, P837, DOI 10.1109/ISMAR55827.2022.00102
   Kasahara S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1561, DOI 10.1145/2858036.2858495
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kim M, 2020, INT J HUM-COMPUT INT, V36, P685, DOI 10.1080/10447318.2019.1680920
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kim S, 2014, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2014.6948412
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Latoschik M. E., 2017, VRST 17 P 23 ACM S V, P1, DOI DOI 10.1145/3139131.3139156
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P9, DOI 10.1109/3DCVE.2016.7563559
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lee J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300301
   Lee S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517451
   Lee Y, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P342, DOI 10.1109/ISMAR-Adjunct.2016.0112
   Lim CG, 2020, TEI'20: PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, P255, DOI 10.1145/3374920.3374943
   Lin L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P510, DOI 10.1109/vr.2019.8797787
   Liu HX, 2017, IEEE INT C INT ROBOT, P6617, DOI 10.1109/IROS.2017.8206575
   Noh S.-T., 2015, ICAT EGVE 2015 INT C, DOI [10.2312/egve.20151311, DOI 10.2312/EGVE.20151311]
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Punpongsanon P, 2015, IEEE T VIS COMPUT GR, V21, P1279, DOI 10.1109/TVCG.2015.2459792
   Rietzler M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P913, DOI 10.1145/3332165.3347871
   Rudolph JCR, 2022, TEI'22: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, DOI 10.1145/3490149.3501320
   Tan CSS, 2014, PRESENCE-TELEOP VIRT, V23, P90, DOI 10.1162/PRES_a_00168
   Tarchanidis KN, 2003, IEEE T INSTRUM MEAS, V52, P984, DOI 10.1109/TIM.2003.809484
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Pham TH, 2018, IEEE T PATTERN ANAL, V40, P2883, DOI 10.1109/TPAMI.2017.2759736
   Pham TH, 2015, PROC CVPR IEEE, P2810, DOI 10.1109/CVPR.2015.7298898
   Wininger M, 2008, J REHABIL RES DEV, V45, P883, DOI 10.1682/JRRD.2007.11.0187
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yoon B, 2020, INT SYM MIX AUGMENT, P520, DOI 10.1109/ISMAR50242.2020.00080
   Zhang YX, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555461
   Zijlstra F., 1993, Efficiency in Work Behavior: A Design Approach for Modern Tools, P5
NR 48
TC 2
Z9 2
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4611
EP 4621
DI 10.1109/TVCG.2023.3320210
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100026
PM 37788213
DA 2024-11-06
ER

PT J
AU Mori, S
   Schmalstieg, D
   Kalkofen, D
AF Mori, Shohei
   Schmalstieg, Dieter
   Kalkofen, Denis
TI Exemplar-Based Inpainting for 6DOF Virtual Reality Photos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Rendering (computer graphics); Three-dimensional displays; Head;
   Photography; Image color analysis; Virtual reality; Cameras; Multi-layer
   images; inpainting; virtual reality; image-based rendering
ID LIGHT; FIELDS
AB Multi-layer images are currently the most prominent scene representation for viewing natural scenes under full-motion parallax in virtual reality. Layers ordered in diopter space contain color and transparency so that a complete image is formed when the layers are composited in a view-dependent manner. Once baked, the same limitations apply to multi-layer images as to conventional single-layer photography, making it challenging to remove obstructive objects or otherwise edit the content. Object removal before baking can benefit from filling disoccluded layers with pixels from background layers. However, if no such background pixels have been observed, an inpainting algorithm must fill the empty spots with fitting synthetic content. We present and study a multi-layer inpainting approach that addresses this problem in two stages: First, a volumetric area of interest specified by the user is classified with respect to whether the background pixels have been observed or not. Second, the unobserved pixels are filled with multi-layer inpainting. We report on experiments using multiple variants of multi-layer inpainting and compare our solution to conventional inpainting methods that consider each layer individually.
C1 [Mori, Shohei; Schmalstieg, Dieter; Kalkofen, Denis] Graz Univ Technol, Graz, Austria.
   [Kalkofen, Denis] Flinders Univ S Australia, Adelaide, Australia.
C3 Graz University of Technology; Flinders University South Australia
RP Mori, S (corresponding author), Graz Univ Technol, Graz, Austria.
EM s.mori.jp@ieee.org; schmalstieg@tugraz.at; kalkofen@icg.tugraz.at
RI Mori, Shohei/AAL-6642-2020
OI Mori, Shohei/0000-0003-0540-7312; Kalkofen, Denis/0000-0002-0359-206X;
   Schmalstieg, Dieter/0000-0003-2813-2235
FU Austrian Science Fund FWF [P33634]; Austrian Science Fund (FWF) [P33634]
   Funding Source: Austrian Science Fund (FWF)
FX This work was supported by the Austrian Science Fund FWF (grant no.
   P33634).
CR Attal B., 2020, ECCV, P441, DOI DOI 10.1007/978-3-030-58452-8_26
   Baek SH, 2016, PROC CVPR IEEE, P488, DOI 10.1109/CVPR.2016.59
   Barnes C, 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   BEATON AE, 1974, TECHNOMETRICS, V16, P147, DOI 10.2307/1267936
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Buyssens P, 2015, IEEE T IMAGE PROCESS, V24, P1809, DOI 10.1109/TIP.2015.2411437
   Cicek O, 2016, 3D UNet: Learning dense volumetric segmentation from sparse annotation
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dai A, 2018, PROC CVPR IEEE, P4578, DOI 10.1109/CVPR.2018.00481
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   Debevec P., 1998, EUR WORKSH REND TECH, P2
   Ebner C., 2022, IEEE Transactions on Visualization and Computer Graphics (TVCG), V28, P2
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Gkitsas V, 2021, IEEE COMPUT SOC CONF, P3711, DOI 10.1109/CVPRW53098.2021.00412
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Ishikawa R., 2023, IEEE Transactions on Visualization and Computer Graphics (TVCG), P2
   Jambon C., 2023, PROC ACM S INTERACTI, V6, P2
   Jampani V, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12498, DOI 10.1109/ICCV48922.2021.01229
   Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601125
   Kai-En Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P328, DOI 10.1007/978-3-030-58601-0_20
   Kawai N, 2012, INT C PATT RECOG, P2744
   Kawai N, 2009, LECT NOTES COMPUT SC, V5414, P271, DOI 10.1007/978-3-540-92957-4_24
   Kellnhofer P, 2021, PROC CVPR IEEE, P4285, DOI 10.1109/CVPR46437.2021.00427
   Kuffner dos Anjos R., 2022, IEEE T VISUALIZATION, P1
   Kurz D., 2012, Computers & Graphics, V36, P9
   Le Pendu M, 2018, IEEE T IMAGE PROCESS, V27, P1981, DOI 10.1109/TIP.2018.2791864
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270
   Li J., 2019, IEEE Robotics and Automation Letters, V5, P2
   Li JN, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102171
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mohr P., 2020, PROC ACM C HUMAN FAC, P1
   Mori S, 2020, IEEE T VIS COMPUT GR, V26, P2994, DOI 10.1109/TVCG.2020.3003768
   Mori S, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P1, DOI 10.1109/ISMAR-Adjunct.2018.00020
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031
   Park S., 2006, The Visual Computer, V22, P2
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Peng Y., 2020, ACM Transactions on Graphics (TOG), V39, P2
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Philip J, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190846
   Porter T., 1984, P C COMP GRAPH INT, P3
   Richard M., 2001, P INT C VIS IM IM PR, P106, DOI DOI 10.1109/ICITA.2005.169
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Serrano A., 2019, IEEE Transactions on Visualization and Computer Graphics (TVCG), V25, P2
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shih ML, 2020, PROC CVPR IEEE, P8025, DOI 10.1109/CVPR42600.2020.00805
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Sitzmann Vincent, 2021, arXiv
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1109/APCAP.2017.8420330, 10.1007/978-3-030-01216-8_1]
   Srinivasan PP, 2019, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2019.00026
   Szeliski R, 1999, INT J COMPUT VISION, V32, P45, DOI 10.1023/A:1008192912624
   Thatte J., 2018, Electronic Imaging, V2018, P352
   Thonat T, 2016, INT CONF 3D VISION, P351, DOI 10.1109/3DV.2016.44
   Vaish V, 2004, PROC CVPR IEEE, P2
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Yi ZL, 2020, PROC CVPR IEEE, P7505, DOI 10.1109/CVPR42600.2020.00753
   Yu Alex, 2021, pixelnerf: Neural radiance fields from one or few images, P2
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu P., 2012, Advances on Digital Television and Wireless Multimedia Communications, P5
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 70
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4644
EP 4654
DI 10.1109/TVCG.2023.3320220
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100029
PM 37788207
OA hybrid
DA 2024-11-06
ER

PT J
AU Sermarini, J
   Michlowitz, RA
   LaViola, JJ Jr
   Walters, LC
   Azevedo, R
   Kider, JT
AF Sermarini, John
   Michlowitz, Robert A.
   LaViola, Joseph J.
   Walters, Lori C.
   Azevedo, Roger
   Kider, Joseph T.
TI Investigating the Impact of Augmented Reality and BIM on Retrofitting
   Training for Non-Experts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; AR; building information modeling; BIM; retrofitting;
   training
ID MIXED REALITY; CONSTRUCTION; BARRIERS
AB Augmented Reality (AR) tools have shown significant potential in providing on-site visualization of Building Information Modeling (BIM) data and models for supporting construction evaluation, inspection, and guidance. Retrofitting existing buildings, however, remains a challenging task requiring more innovative solutions to successfully integrate AR and BIM. This study aims to investigate the impact of AR+BIM technology on the retrofitting training process and assess the potential for future on-site usage. We conducted a study with 64 non-expert participants, who were asked to perform a common retrofitting procedure of an electrical outlet installation using either an AR+BIM system or a standard printed blueprint documentation set. Our findings indicate that AR+BIM reduced task time significantly and improved performance consistency across participants, while also decreasing the physical and cognitive demands of the training. This study provides a foundation for augmenting future retrofitting construction research that can extend the use of AR+BIM technology, thus facilitating more efficient retrofitting of existing buildings. A video presentation of this article and all supplemental materials are available at https://github.com/DesignLabUCF/SENSEable_RetrofittingTraining.
C1 [Sermarini, John; Michlowitz, Robert A.; LaViola, Joseph J.; Walters, Lori C.; Azevedo, Roger; Kider, Joseph T.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Sermarini, J (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM john.sermarini@ucf.edu; robert.michlowitz@ucf.edu; jjl@ucf.edu;
   lori.walters@ucf.edu; roger.azevedo@ucf.edu; joseph.kider@ucf.edu
OI Kider, Joseph/0000-0002-4818-115X; Sermarini, John/0000-0001-6499-4356;
   LaViola Jr., Joseph J./0000-0003-1186-4130; Michlowitz,
   Robert/0000-0003-1513-6923; Azevedo, Roger/0000-0002-5018-6232
FU National Science Foundation [1917728]
FX This material is based upon work supported by the National Science
   Foundation under Grant No. 1917728. Any opinions, findings, and
   conclusions or recommendations expressed in this material are those of
   the author(s) and do not necessarily reflect the views of the National
   Science Foundation. We also thank the anonymous reviewers for their
   insightful feedback.
CR Abdelhameed WA, 2014, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON COMPUTER-AIDED ARCHITECTURAL DESIGN RESEARCH IN ASIA (CAADRIA 2014), P719
   Alizadehsalehi S, 2020, AUTOMAT CONSTR, V116, DOI 10.1016/j.autcon.2020.103254
   Ayer SK, 2016, J ARCHIT ENG, V22, DOI 10.1061/(ASCE)AE.1943-5568.0000195
   Azhar S., 2011, LEADERSHIP MANAGE EN, V11, DOI [DOI 10.1061/(ASCE)LM.1943-5630.0000127, 10.1061/(ASCE)LM.1943-5630.0000127]
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Brooke J., 1995, USABILITY EVAL IND, P189
   Bryde D, 2013, INT J PROJ MANAG, V31, P971, DOI 10.1016/j.ijproman.2012.12.001
   Caldas Luisa., 2019, Technology|Architecture + Design, V3, P249, DOI [DOI 10.1080/24751448.2019.1640544, 10.1080/24751448.2019.16405442, DOI 10.1080/24751448.2019.16405442]
   Carmichael G., 2012, P E LEARN 2012 WORLD, V1, P2
   Ceglia D, 2017, J ENVIRON MANAGE, V187, P375, DOI 10.1016/j.jenvman.2016.10.064
   Chalhoub J, 2018, AUTOMAT CONSTR, V86, P1, DOI 10.1016/j.autcon.2017.10.028
   Chernick A., 2021, P 2020 DIGITALFUTURE, P46, DOI [10.1007/978-981-33-4400-6_5, DOI 10.1007/978-981-33-4400-6_5]
   Clark A, 1999, TRENDS COGN SCI, V3, P345, DOI 10.1016/S1364-6613(99)01361-3
   Crosbie T, 2011, AUTOMAT CONSTR, V20, P205, DOI 10.1016/j.autcon.2010.09.018
   Dinis FM, 2020, J BUILD ENG, V30, DOI 10.1016/j.jobe.2020.101287
   Du J, 2018, J CONSTR ENG M, V144, DOI 10.1061/(ASCE)CO.1943-7862.0001426
   El Ammari K, 2019, AUTOMAT CONSTR, V107, DOI 10.1016/j.autcon.2019.102940
   FEINER S, 1993, COMMUN ACM, V36, P53, DOI 10.1145/159544.159587
   Fukuda T, 2019, J COMPUT DES ENG, V6, P179
   Gibson J. J., 1979, The Ecological Approach To Visual Perception: Classic Edition, P2
   Gu N, 2010, AUTOMAT CONSTR, V19, P988, DOI 10.1016/j.autcon.2010.09.002
   Hart S. G., 1986, NASA Task Load Index (TLX), P5
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Hrovatin N, 2018, ENERG BUILDINGS, V180, P42, DOI 10.1016/j.enbuild.2018.09.029
   IBAIndustria Brasileira de Arvores, 2019, Technical report, P1
   Jagarajan R, 2017, RENEW SUST ENERG REV, V67, P1360, DOI 10.1016/j.rser.2016.09.091
   Karaaslan E, 2019, TRANSPORT RES REC, V2673, P413, DOI 10.1177/0361198119839988
   Khalek IA, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/8547928
   Khan A, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11030126
   LaViola J. J., 2015, P INT IND TRAIN SIM, P2
   Lee S, 2011, AUTOMAT CONSTR, V20, P338, DOI 10.1016/j.autcon.2010.11.004
   Liu G, 2020, ENERG POLICY, V139, DOI 10.1016/j.enpol.2020.111356
   Liu TY, 2022, ENERG BUILDINGS, V276, DOI 10.1016/j.enbuild.2022.112486
   Liu Y, 2017, INT J PROJ MANAG, V35, P686, DOI 10.1016/j.ijproman.2016.06.007
   Liu ZS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125739
   Livingston MA, 2011, VIRTUAL REAL-LONDON, V15, P175, DOI 10.1007/s10055-010-0179-1
   Ma ZJ, 2012, ENERG BUILDINGS, V55, P889, DOI 10.1016/j.enbuild.2012.08.018
   Matejka P, 2017, PROCEDIA ENGINEER, V196, P1080, DOI 10.1016/j.proeng.2017.08.065
   May KW, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12020140
   Meeks S. K., 2017, Technical report, P1
   Meeks S. K., 2014, Technical report, P1
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mitterberger D., 2020, Constr Robot, V4, P151, DOI DOI 10.1007/S41693-020-00035-8
   Motamedi A, 2017, ADV ENG INFORM, V32, P248, DOI 10.1016/j.aei.2017.03.005
   Newen A., 2018, The Oxford Handbook of 4E Cognition
   Nguyen D. C., 2020, Developing a mixed -reality based application for bridge inspection and maintenance, P2
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Polzin F, 2018, RENEW SUST ENERG REV, V88, P99, DOI 10.1016/j.rser.2018.02.012
   Riexinger G, 2018, PROC CIRP, V72, P1124, DOI 10.1016/j.procir.2018.03.160
   Sangiorgio V, 2020, IEEE SYS MAN CYBERN, P760, DOI [10.1109/smc42975.2020.9283420, 10.1109/SMC42975.2020.9283420]
   Schmalstieg D., 2016, Augmented Reality: Principles and Practice, P2
   Sermarini J, 2022, PROCEEDINGS OF THE 2022 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2022, DOI 10.1145/3565970.3567688
   Shafique M, 2017, OPEN GEOSCI, V9, P240, DOI 10.1515/geo-2017-0020
   Shapiro L., 2021, STANFORD ENCY PHILOS
   Sielhorst T, 2008, J DISP TECHNOL, V4, P451, DOI 10.1109/JDT.2008.2001575
   Sorrell S., 2004, EC ENERGY EFFICIENCY
   Tang SL, 1998, IEEE ENG MED BIOL, V17, P49, DOI 10.1109/51.677169
   United States Department of Energy, 2015, Technical Report 2015, P1, DOI DOI 10.1097/NT.0B013E31826C50AF
   Varela F. J., 1991, The Embodied Mind: Cognitive Science and Human Experience, P2
   Wang XY, 2013, AUTOMAT CONSTR, V32, P1, DOI 10.1016/j.autcon.2012.11.021
   Webster A, 1996, COMPUTING IN CIVIL ENGINEERING, P913
   Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322
   Winn W., 2002, Technology, Instruction, Cognition and Learning, V1, P2
   Xu X, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58445
   Yang X, 2015, BUILDINGS, V5, P1302, DOI 10.3390/buildings5041302
   Yifan Liu, 2014, 2014 International Conference on Computing in Civil and Building Engineering. Proceedings, P801
   Zaker Reza, 2018, Visualization in Engineering, V6, DOI 10.1186/s40327-018-0065-6
NR 68
TC 0
Z9 0
U1 1
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4655
EP 4665
DI 10.1109/TVCG.2023.3320223
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y0EV4
UT WOS:001102096500002
PM 37788209
DA 2024-11-06
ER

PT J
AU Mahmud, MR
   Cordova, A
   Quarles, J
AF Mahmud, M. Rasel
   Cordova, Alberto
   Quarles, John
TI Visual Cues for a Steadier You: Visual Feedback Methods Improved
   Standing Balance in Virtual Reality for People with Balance Impairments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; visual feedback; balance; VR accessibility;
   Head-Mounted Display; VR usability; postural stability
ID REACH-TO-GRASP; POSTURAL CONTROL; OLDER-ADULTS; GAIT; BIOFEEDBACK;
   ABILITY; STROKE; YOUNG
AB Users of head-mounted displays (HMDs) for virtual reality (VR) sometimes have balance issues since HMDs impede their view of the outside world. This has a greater impact on people with balance impairments since many rely more heavily on their visual cues to keep their balance. This is a significant obstacle to the universal usability and accessibility of VR. Although previous studies have verified the imbalance issue, not much work has been done to diminish it. In this study, we investigated how to increase VR balance by utilizing additional visual cues. To examine how different visual approaches (static, rhythmic, spatial, and center of pressure (CoP) based feedback) affect balance in VR, we recruited 100 people (50 with balance impairments due to multiple sclerosis and 50 without balance impairments) across two different geographic locations (United States and Bangladesh). All people completed both standing visual exploration as well as standing reach and grasp tasks. Results demonstrated that static, rhythmic, and CoP visual feedback approaches enhanced balance significantly ($p <. 05$) in VR for people with balance impairments. The methods described in this study could be applied to design more accessible virtual environments for people with balance impairments.
C1 [Mahmud, M. Rasel; Quarles, John] Univ Texas San Antonio, Comp Sci, San Antonio, TX 78249 USA.
   [Cordova, Alberto] Univ Texas San Antonio, Kinesiol, San Antonio, TX USA.
C3 University of Texas System; University of Texas at San Antonio (UTSA);
   University of Texas System; University of Texas at San Antonio (UTSA)
RP Mahmud, MR (corresponding author), Univ Texas San Antonio, Comp Sci, San Antonio, TX 78249 USA.
EM m.raselmahmud1@gmail.com; Alberto.Cordova@utsa.edu;
   John.Quarles@utsa.edu
OI Mahmud, M. Rasel/0000-0003-2094-8192
FU National Science Foundation [IIS 2007041]
FX National Science Foundation (IIS 2007041) supported the research. All of
   our participants greatly cooperate to successfully complete the study.
CR Agrawal Y, 2009, ARCH INTERN MED, V169, P938, DOI 10.1001/archinternmed.2009.66
   Bergeron M., 2015, Advances in medicine, V2015, P2
   Bisson E, 2007, CYBERPSYCHOL BEHAV, V10, P16, DOI 10.1089/cpb.2006.9997
   Bolton DAE, 2019, CORTEX, V117, P135, DOI 10.1016/j.cortex.2019.03.001
   Cˇakrt O., 2010, European archives of oto-rhino-laryngology, V267, P2
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chang E, 2013, INT WINT WORKSH BR, P62, DOI 10.1109/IWW-BCI.2013.6506631
   Cho C, 2016, TOHOKU J EXP MED, V238, P213, DOI 10.1620/tjem.238.213
   Cordova A, 2014, EXP AGING RES, V40, P578, DOI 10.1080/0361073X.2014.956627
   COREN S, 1993, B PSYCHONOMIC SOC, V31, P1, DOI 10.3758/bf03334122
   de Rooij IJM, 2016, PHYS THER, V96, P1905, DOI 10.2522/ptj.20160054
   Duque G, 2013, CLIN INTERV AGING, V8, P257, DOI 10.2147/CIA.S41453
   Epure P., 2014, 10 INT C DIS VIRT RE, P7
   Ferdous S. M. S., 2018, P 24 ACM S VIRT REAL, P1
   Ferdous SMS, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582169
   Ferdous SMS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P121, DOI 10.1109/3DUI.2016.7460041
   Gandemer L., 2017, Frontiers in neuroscience, V11, P2
   Ghai S, 2018, AGING DIS, V9, P901, DOI 10.14336/AD.2017.1031
   Guo Rongkai., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P59, DOI [10.1145/2503713.2503719, DOI 10.1145/2503713.2503719]
   Hamilton N. P., 2011, Kinesiology: Scientific basis of human motion, P1
   Hasegawa N, 2017, GAIT POSTURE, V58, P188, DOI 10.1016/j.gaitpost.2017.08.001
   Huang MH, 2015, GAIT POSTURE, V41, P276, DOI 10.1016/j.gaitpost.2014.10.018
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Kelly JW, 2008, PERCEPT PSYCHOPHYS, V70, P158, DOI 10.3758/PP.70.1.158
   Kelly JW, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3313902
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Ketterer J, 2022, FRONT PHYSIOL, V13, DOI 10.3389/fphys.2022.803185
   Kim H., 2021, Scientific reports, V11, P8
   Lee SW, 2013, J PHYS THER SCI, V25, P635, DOI 10.1589/jpts.25.635
   Li Z, 2016, J PHYS THER SCI, V28, P1364, DOI 10.1589/jpts.28.1364
   Mahmud M. R., Auditory feedback to make walking in virtual reality more accessible, V2
   Mahmud MR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P782, DOI 10.1109/VR51125.2022.00100
   Martinez A., 2018, Journal on Interactive Systems, V9
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P8
   Meldrum D, 2012, BMC EAR NOSE THROAT, V12, DOI 10.1186/1472-6815-12-3
   Mohebbi A, 2022, J NEUROPHYSIOL, V127, P1159, DOI 10.1152/jn.00283.2021
   Moreno R, 2002, J EDUC PSYCHOL, V94, P598, DOI 10.1037//0022-0663.94.3.598
   Murata A, 2004, INT J HUM-COMPUT INT, V17, P463, DOI 10.1207/s15327590ijhc1704_2
   Park EC, 2015, J PHYS THER SCI, V27, P1157, DOI 10.1589/jpts.27.1157
   Peck TC, 2021, IEEE COMPUT GRAPH, V41, P133, DOI 10.1109/MCG.2021.3113455
   POWELL LE, 1995, J GERONTOL A-BIOL, V50, pM28, DOI 10.1093/gerona/50A.1.M28
   Prothero J. D., 1998, University of Washington, P3
   Rasel Mahmud M., 2022, Standing Balance Improvement Using Vibrotactile Feedback in Virtual Reality
   Rendon AA, 2012, AGE AGEING, V41, P549, DOI 10.1093/ageing/afs053
   Ruhe A, 2011, EUR SPINE J, V20, P358, DOI 10.1007/s00586-010-1543-2
   Salavati M., Gait
   Samaraweera G, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P23, DOI 10.1109/3DUI.2013.6550192
   Schepens S, 2010, ARCH GERONTOL GERIAT, V51, P9, DOI 10.1016/j.archger.2009.06.003
   Soffel F, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P351, DOI 10.1145/2993369.2996341
   Soltani Pooya, 2020, Frontiers in sports and active living., V2, P233
   Sondell B., 2005, Presence, V14, P2
   Sütbeyaz S, 2007, ARCH PHYS MED REHAB, V88, P555, DOI 10.1016/j.apmr.2007.02.034
   Takahashi Y, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P642, DOI 10.1109/ROMAN.2001.981977
   Tan C, 2012, NEUROREHAB NEURAL RE, V26, P957, DOI 10.1177/1545968312437938
   Thikey H., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P379, DOI 10.4108/icst.pervasivehealth.2011.246127
   Thompson LA, 2017, SPORTS, V5, DOI 10.3390/sports5040086
   Triantafyllidis E, 2020, IEEE ACCESS, V8, P78213, DOI 10.1109/ACCESS.2020.2990080
   Wang Dangxiao, 2019, Virtual Reality & Intelligent Hardware, V1, P136, DOI [DOI 10.3724/SP.J.2096-5796.2019.0008, 10.3724/sp.j.2096-5796.2019.0008]
   Wang I.-L., 2021, International Journal of Environmental Research and Public Health, V18, P2
   Young W, 2011, GAIT POSTURE, V33, P303, DOI 10.1016/j.gaitpost.2010.10.089
NR 61
TC 2
Z9 2
U1 6
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4666
EP 4675
DI 10.1109/TVCG.2023.3320244
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y0EV4
UT WOS:001102096500003
PM 37788203
DA 2024-11-06
ER

PT J
AU Skreinig, LR
   Kalkofen, D
   Stanescu, A
   Mohr, P
   Heyen, F
   Mori, S
   Sedlmair, M
   Schmalstieg, D
   Plopski, A
AF Skreinig, Lucchas Ribeiro
   Kalkofen, Denis
   Stanescu, Ana
   Mohr, Peter
   Heyen, Frank
   Mori, Shohei
   Sedlmair, Michael
   Schmalstieg, Dieter
   Plopski, Alexander
TI guitARhero: Interactive Augmented Reality Guitar Tutorials
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Visualization; Monitoring; Instruments; Neck; Resists; Three-dimensional
   displays; Mirrors; Augmented reality; Computer-assisted instruction;
   Graphical user interfaces
AB This paper presents guitARhero, an Augmented Reality application for interactively teaching guitar playing to beginners through responsive visualizations overlaid on the guitar neck. We support two types of visual guidance, a highlighting of the frets that need to be pressed and a 3D hand overlay, as well as two display scenarios, one using a desktop magic mirror and one using a video see-through head-mounted display. We conducted a user study with 20 participants to evaluate how well users could follow instructions presented with different guidance and display combinations and compare these to a baseline where users had to follow video instructions. Our study highlights the trade-off between the provided information and visual clarity affecting the user's ability to interpret and follow instructions for fine-grained tasks. We show that the perceived usefulness of instruction integration into an HMD view highly depends on the hardware capabilities and instruction details.
C1 [Skreinig, Lucchas Ribeiro; Kalkofen, Denis; Stanescu, Ana; Mohr, Peter; Mori, Shohei; Schmalstieg, Dieter; Plopski, Alexander] Graz Univ Technol, Graz, Austria.
   [Kalkofen, Denis] Flinders Univ S Australia, Adelaide, Australia.
   [Heyen, Frank; Sedlmair, Michael] Univ Stuttgart, Stuttgart, Germany.
C3 Graz University of Technology; Flinders University South Australia;
   University of Stuttgart
RP Skreinig, LR (corresponding author), Graz Univ Technol, Graz, Austria.
EM lucchas.ribeiroskreinig@icg.tugraz.at; denis.kalkofen@flinders.edu.au;
   ana.stanescu@icg.tugraz.at; mohr@icg.tugraz.at;
   frank.heyen@visus.uni-stuttgart.de; shohei.mori@icg.tugraz.at;
   schmalstieg@icg.tugraz.at; michael.sedlmair@visus.uni-stuttgart.de;
   alexander.plopski@icg.tugraz.at
RI Mori, Shohei/AAL-6642-2020
OI Schmalstieg, Dieter/0000-0003-2813-2235; Ribeiro Skreinig,
   Lucchas/0000-0002-3746-8630; Kalkofen, Denis/0000-0002-0359-206X;
   Stanescu, Ana/0000-0002-6203-1238; Plopski,
   Alexander/0000-0003-1354-0279; Mori, Shohei/0000-0003-0540-7312; Heyen,
   Frank/0000-0002-5090-0133
FU Austrian Science Fund FWF [P30694]; Deutsche Forschungsgemeinschaft DFG
   [EXC 2075 - 390740016]; Cyber Valley Research Fund; Snap, Inc.; Austrian
   Science Fund (FWF) [P30694] Funding Source: Austrian Science Fund (FWF)
FX This work was partly supported by the Austrian Science Fund FWF (grant
   no. P30694), by Deutsche Forschungsgemeinschaft DFG under the Excellence
   Strategy (EXC 2075 - 390740016), the Cyber Valley Research Fund, and by
   Snap, Inc.
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bai Z, 2013, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR.2013.6671784
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Brooke J., 1995, USABILITY EVAL IND, P189
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Fiala M, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P251
   Goodman TA, 2018, IEEE INT SYMP SIGNAL, P656, DOI 10.1109/ISSPIT.2018.8642626
   Harrison Eli., 2010, Music Educators Journal, V97, P50, DOI DOI 10.1177/00274321093344211
   HART S G, 1988, P139
   Heyen F., 2022, INT SOC MUSIC INFORM
   Kay M., 2021, R Package Version 0.11.1, V11, DOI [10.5281/zenodo.5945118, DOI 10.5281/ZENODO.5945118]
   Keebler JR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00471
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Liarokapis F., 2010, Eurographics 2010 - Education Papers., DOI [10.2312/eged.201010102, DOI 10.2312/EGED.201010102]
   Liarokapis F., 2005, P THEOR PRACT COMP G, P163
   Lin L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P510, DOI 10.1109/vr.2019.8797787
   Liu JS, 2022, IEEE T VIS COMPUT GR, V28, P3799, DOI 10.1109/TVCG.2022.3203111
   Löchtefeld M, 2011, LECT NOTES COMPUT SC, V6815, P103, DOI 10.1007/978-3-642-22571-0_9
   Marky K., 2021, P ACM C HUM FACT COM, P1, DOI [10.1145/3411764.34455952,3, DOI 10.1145/3411764.34455952,3]
   Martin-Gutierrez J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072425
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Motokawa Yoichi, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P243, DOI 10.1109/ISMAR.2006.297825
   Patzer B., 2014, HUMAN FACTORS ERGONO, V58, P1164, DOI [10.1177/15419312145812431,2,3, DOI 10.1177/15419312145812431,2,3]
   Pongnumkul Suporn, 2011, P 24 ANN ACM S US IN, P135, DOI [DOI 10.1145/2047196.2047213, 10.1145/]
   Skreinig LR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P386, DOI 10.1109/VRW55335.2022.00086
   Spencer R., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P353, DOI 10.1145/332040.332456
   Stanescu A, 2022, IEEE T VIS COMPUT GR, V28, P3821, DOI 10.1109/TVCG.2022.3203104
   Del Rio-Guerra MS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214527
   Torres C, 2018, 2018 XLIV LATIN AMERICAN COMPUTER CONFERENCE (CLEI 2018), P606, DOI 10.1109/CLEI.2018.00078
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang B, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445162
   Wharton C., 1994, The Cognitive Walkthrough Method: A Practitioner's Guide, P5
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Young RW, 1939, J ACOUST SOC AM, V11, P134, DOI 10.1121/1.1916017
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
NR 35
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4676
EP 4685
DI 10.1109/TVCG.2023.3320266
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100030
PM 37773918
OA hybrid
DA 2024-11-06
ER

PT J
AU Lohesara, FG
   Freitas, DR
   Guillemot, C
   Eguiazarian, K
   Knorr, S
AF Lohesara, Fatemeh Ghorbani
   Freitas, Davi Rabbouni
   Guillemot, Christine
   Eguiazarian, Karen
   Knorr, Sebastian
TI HEADSET: Human Emotion Awareness under Partial Occlusions Multimodal
   DataSET
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Extended reality; multimodal dataset; virtual reality; volumetric video;
   light field
ID EXPRESSION RECOGNITION; FACE; RECONSTRUCTION; DATABASE
AB The volumetric representation of human interactions is one of the fundamental domains in the development of immersive media productions and telecommunication applications. Particularly in the context of the rapid advancement of Extended Reality (XR) applications, this volumetric data has proven to be an essential technology for future XR elaboration. In this work, we present a new multimodal database to help advance the development of immersive technologies. Our proposed database provides ethically compliant and diverse volumetric data, in particular 27 participants displaying posed facial expressions and subtle body movements while speaking, plus 11 participants wearing head-mounted displays (HMDs). The recording system consists of a volumetric capture (VoCap) studio, including 31 synchronized modules with 62 RGB cameras and 31 depth cameras. In addition to textured meshes, point clouds, and multi-view RGB-D data, we use one Lytro Illum camera for providing light field (LF) data simultaneously. Finally, we also provide an evaluation of our dataset employment with regard to the tasks of facial expression classification, HMDs removal, and point cloud reconstruction. The dataset can be helpful in the evaluation and performance testing of various XR algorithms, including but not limited to facial expression recognition and reconstruction, facial reenactment, and volumetric video. HEADSET and its all associated raw data and license agreement will be publicly available for research purposes.
C1 [Lohesara, Fatemeh Ghorbani] Tech Univ Berlin, Commun Syst Grp, Berlin, Germany.
   [Freitas, Davi Rabbouni; Guillemot, Christine] INRIA, Paris, France.
   [Eguiazarian, Karen] Tampere Univ, Computat Imaging Grp, Tampere, Finland.
   [Knorr, Sebastian] Ernst Abbe Univ Appl Sci Jena, Jena, Germany.
C3 Technical University of Berlin; Inria; Tampere University
RP Lohesara, FG (corresponding author), Tech Univ Berlin, Commun Syst Grp, Berlin, Germany.
EM ghorbani.lohesara@tu-berlin.de;
   davi-rabbouni.de-carvalho-freitas@inria.fr;
   christine.guillemot@inria.fr; karen.eguiazarian@tuni.fi;
   sebastian.knorr@eah-jena.de
RI Eguiazarian, Karen/G-4299-2014; Ghorbani, Fatemeh/ABD-5406-2021
OI , Karen/0000-0002-8135-1085; Knorr, Sebastian/0000-0001-9745-8605;
   Ghorbani, Fatemeh/0000-0002-5121-3052
FU European Union [956770]
FX This project has received funding from the European Union's Horizon 2020
   research and innovation program under the Marie Sklodowska-Curie grant
   agreement No 956770. The data collection part was carried out with the
   support of Centre for Immersive Visual Technologies (CIVIT) research
   infrastructure, Tampere University, Finland. We want to especially thank
   Jani Kaepylae, for his help during the capturing.
CR Alexiadis DS, 2017, IEEE T CIRC SYST VID, V27, P798, DOI 10.1109/TCSVT.2016.2576922
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chang YL, 2019, Arxiv, DOI arXiv:1907.01131
   Chatzitofis A, 2020, IEEE ACCESS, V8, P176241, DOI 10.1109/ACCESS.2020.3026276
   Chen S.-Y., 2022, IEEE Transactions on Multimedia
   Chhokra P, 2018, INFORM FUSION, V44, P113, DOI 10.1016/j.inffus.2017.09.002
   Chiesa V, 2018, EUR SIGNAL PR CONF, P2250, DOI 10.23919/EUSIPCO.2018.8553572
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Dhall A, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P546, DOI 10.1145/3340555.3355710
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Fard AP, 2022, IEEE ACCESS, V10, P26756, DOI 10.1109/ACCESS.2022.3156598
   Galdi C, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122687
   Gerig T, 2018, IEEE INT CONF AUTOMA, P75, DOI 10.1109/FG.2018.00021
   Girardeau-Montaut Daniel., 2016, CloudCompare, V11
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Graziosi D, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.12
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Guo KW, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3083722
   HTC, Vive pro eye overview
   Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6
   Joo H, 2015, IEEE I CONF COMP VIS, P3334, DOI 10.1109/ICCV.2015.381
   Kazhdan M, 2020, COMPUT GRAPH FORUM, V39, P173, DOI 10.1111/cgf.14077
   Krivokuca M., 2018, ISO/IEC JTC1/SC29 WG11 (MPEG) input document m42914
   Kyrlitsias C, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.786665
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liu Y., 2023, ACM Trans. Multimedia Comput., V19, P1
   Lou JW, 2020, IEEE T MULTIMEDIA, V22, P730, DOI 10.1109/TMM.2019.2933338
   Pham L, 2021, INT C PATT RECOG, P4513, DOI 10.1109/ICPR48806.2021.9411919
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Numan N, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P109, DOI 10.1109/VRW52623.2021.00028
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Pages R., 2021, ISO/IEC JTC1/SC29/WG07 MPEG2021/m56767
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Raghavendra R, 2016, IEEE T INF FOREN SEC, V11, P922, DOI 10.1109/TIFS.2015.2512559
   Reimat I, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P300, DOI 10.1145/3458305.3478452
   R”ssler A, 2018, Arxiv, DOI [arXiv:1803.09179, 10.48550/ARXIV.1803.09179]
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Savchenko Andrey V., 2021, 2021 IEEE 19th International Symposium on Intelligent Systems and Informatics (SISY), P119, DOI 10.1109/SISY52375.2021.9582508
   Savchenko AV, 2022, IEEE COMPUT SOC CONF, P2358, DOI 10.1109/CVPRW56347.2022.00263
   Savchenko AV, 2022, IEEE T AFFECT COMPUT, V13, P2132, DOI 10.1109/TAFFC.2022.3188390
   Schwarz S., IEEE Journal on
   Sepas-Moghaddam A, 2021, IEEE T IMAGE PROCESS, V30, P2627, DOI 10.1109/TIP.2021.3054476
   Sepas-Moghaddam A, 2017, I W BIOMETRIC FORENS
   Sharma G., 2021, IEEE Transactions on Affective Computing
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Verpaalen IAM, 2019, COGNITION EMOTION, V33, P1531, DOI 10.1080/02699931.2019.1577220
   Wang M, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P251, DOI 10.1109/ISMAR-Adjunct.2019.00-36
   Yu ZX, 2020, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR42600.2020.00306
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang JJ, 2016, INT CONF BIOMETR
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao YJ, 2018, Arxiv, DOI arXiv:1807.08772
   Zheng HY, 2022, LECT NOTES COMPUT SC, V13141, P339, DOI 10.1007/978-3-030-98358-1_27
   Zhuo Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P246, DOI 10.1007/978-3-030-58548-8_15
NR 60
TC 0
Z9 0
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4686
EP 4696
DI 10.1109/TVCG.2023.3320236
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100031
PM 37788215
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Pintore, G
   Bettio, F
   Agus, M
   Gobbetti, E
AF Pintore, Giovanni
   Bettio, Fabio
   Agus, Marco
   Gobbetti, Enrico
TI Deep Scene Synthesis of Atlanta-World Interiors from a Single
   Omnidirectional Image
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Omnidirectional; 360; immersive view; AR/MR/VR for architecture;
   Computer vision; Machine learning
AB We present a new data-driven approach for extracting geometric and structural information from a single spherical panorama of an interior scene, and for using this information to render the scene from novel points of view, enhancing 3D immersion in VR applications. The approach copes with the inherent ambiguities of single-image geometry estimation and novel view synthesis by focusing on the very common case of Atlanta-world interiors, bounded by horizontal floors and ceilings and vertical walls. Based on this prior, we introduce a novel end-to-end deep learning approach to jointly estimate the depth and the underlying room structure of the scene. The prior guides the design of the network and of novel domain-specific loss functions, shifting the major computational load on a training phase that exploits available large-scale synthetic panoramic imagery. An extremely lightweight network uses geometric and structural information to infer novel panoramic views from translated positions at interactive rates, from which perspective views matching head rotations are produced and upsampled to the display size. As a result, our method automatically produces new poses around the original camera at interactive rates, within a working area suitable for producing depth cues for VR applications, especially when using head-mounted displays connected to graphics servers. The extracted floor plan and 3D wall structure can also be used to support room exploration. The experimental results demonstrate that our method provides low-latency performance and improves over current state-of-the-art solutions in prediction accuracy on available commonly used indoor panoramic benchmarks.
C1 [Pintore, Giovanni; Bettio, Fabio; Gobbetti, Enrico] CRS4, Turin, Italy.
   [Agus, Marco] HBKU, Doha, Qatar.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar
RP Pintore, G (corresponding author), CRS4, Turin, Italy.
EM giovanni.pintore@crs4.it; fabio.bettio@crs4.it; MAgus@hbku.edu.qa;
   enrico.gobbetti@crs4.it
RI Gobbetti, Enrico/O-2188-2015; Agus, Marco/AAM-5898-2020; Pintore,
   Giovanni/AFV-0023-2022
OI Agus, Marco/0000-0003-2752-3525
FU Qatar National Research Fund (Qatar Foundation) [NPRP14S-0403-210132]
FX This publication was made possible by NPRP-S grant NPRP14S-0403-210132
   by Qatar National Research Fund (a member of Qatar Foundation) and by
   Sardinian Regional Authorities through project XDATA. The findings
   herein reflect the work, and are solely the responsibility of the
   authors.
CR Aly M., 2012, P WACV, P1
   Attal B., 2020, ECCV, P441, DOI DOI 10.1007/978-3-030-58452-8_26
   Bertel T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417770
   Bertel T, 2019, IEEE T VIS COMPUT GR, V25, P1828, DOI 10.1109/TVCG.2019.2898799
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   Deng X, 2021, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR46437.2021.00907
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gkitsas V, 2021, IEEE COMPUT SOC CONF, P3711, DOI 10.1109/CVPRW53098.2021.00412
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hedman P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201384
   Hedman P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130828
   Hsu C.-Y., 2021, arXiv
   Huang JW, 2017, P IEEE VIRT REAL ANN, P37, DOI 10.1109/VR.2017.7892229
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jia HJ, 2022, IEEE COMPUT SOC CONF, P5188, DOI 10.1109/CVPRW56347.2022.00567
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Jiang ZG, 2022, PROC CVPR IEEE, P1644, DOI 10.1109/CVPR52688.2022.00170
   Jin L, 2020, PROC CVPR IEEE, P886, DOI 10.1109/CVPR42600.2020.00097
   Kai-En Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P328, DOI 10.1007/978-3-030-58601-0_20
   Kelkkanen V, 2021, INT J COMPUT GAMES T, V2021, DOI 10.1155/2021/6676644
   Kingma DP, 2014, ADV NEUR IN, V27
   Lai PK, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P405, DOI [10.1109/vr.2019.8798016, 10.1109/VR.2019.8798016]
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lambert-Lacroix S, 2016, J NONPARAMETR STAT, V28, P487, DOI 10.1080/10485252.2016.1190359
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   Li YY, 2022, PROC CVPR IEEE, P2791, DOI 10.1109/CVPR52688.2022.00282
   Luo BC, 2018, IEEE T VIS COMPUT GR, V24, P1545, DOI 10.1109/TVCG.2018.2794071
   Matterport, 2017, MATTERPORT3D
   Matzen K, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073645
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Nah JH, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417787
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   NVIDIA, 2023, nvJPEG Libraries: GPU-accelerated JPEG decoder, encoder and transcoder
   Paszke A., 2017, AUT WORKSH LONG BEAC
   Pintore Giovanni, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P432, DOI 10.1007/978-3-030-58598-3_26
   Pintore G, 2022, IEEE T VIS COMPUT GR, V28, P3629, DOI 10.1109/TVCG.2022.3202999
   Pintore G, 2021, PROC CVPR IEEE, P11531, DOI 10.1109/CVPR46437.2021.01137
   Pintore G, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480480
   Pintore G, 2020, COMPUT GRAPH FORUM, V39, P667, DOI 10.1111/cgf.14021
   Rey-Area M, 2022, PROC CVPR IEEE, P3752, DOI 10.1109/CVPR52688.2022.00374
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Serrano A, 2019, IEEE T VIS COMPUT GR, V25, P1817, DOI 10.1109/TVCG.2019.2898757
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su Y.-C., 2017, Advances in Neural Information Processing Systems, V30, P2
   Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967
   Sun C, 2021, PROC CVPR IEEE, P2573, DOI 10.1109/CVPR46437.2021.00260
   Sun C, 2019, PROC CVPR IEEE, P1047, DOI 10.1109/CVPR.2019.00114
   Tateno K, 2018, LECT NOTES COMPUT SC, V11220, P732, DOI 10.1007/978-3-030-01270-0_43
   Tucker R, 2020, PROC CVPR IEEE, P548, DOI 10.1109/CVPR42600.2020.00063
   Tukur M, 2023, GRAPH MODELS, V128, DOI 10.1016/j.gmod.2023.101182
   Tulsiani S, 2018, PROC CVPR IEEE, P302, DOI 10.1109/CVPR.2018.00039
   Vaswani A, 2017, ADV NEUR IN, V30
   Waidhofer J, 2022, INT SYM MIX AUGMENT, P584, DOI 10.1109/ISMAR55827.2022.00075
   Wang FE, 2021, PROC CVPR IEEE, P12951, DOI 10.1109/CVPR46437.2021.01276
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiles O, 2020, PROC CVPR IEEE, P7465, DOI 10.1109/CVPR42600.2020.00749
   Xu JL, 2021, PROC CVPR IEEE, P16433, DOI 10.1109/CVPR46437.2021.01617
   Xu M, 2020, IEEE J-STSP, V14, P5, DOI 10.1109/JSTSP.2020.2966864
   Yang ST, 2019, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2019.00348
   Yi ZL, 2020, PROC CVPR IEEE, P7505, DOI 10.1109/CVPR42600.2020.00753
   Yu F., 2015, ARXIV
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
   Zhao Y, 2022, LECT NOTES COMPUT SC, V13661, P637, DOI [10.1007/978-3-031-19769-7_37, 10.1145/3573428.3573541]
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
   Zhu PH, 2020, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR42600.2020.00515
   Zioulis N, 2019, INT CONF 3D VISION, P690, DOI 10.1109/3DV.2019.00081
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
   Zou CH, 2020, Arxiv, DOI arXiv:1910.04099
   Zou CH, 2021, INT J COMPUT VISION, V129, P1410, DOI 10.1007/s11263-020-01426-8
   Zou CH, 2018, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2018.00219
NR 77
TC 3
Z9 3
U1 1
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4708
EP 4718
DI 10.1109/TVCG.2023.3320219
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100033
PM 37782610
DA 2024-11-06
ER

PT J
AU Ishikawa, R
   Saito, H
   Kalkofen, D
   Mori, S
AF Ishikawa, Reina
   Saito, Hideo
   Kalkofen, Denis
   Mori, Shohei
TI Multi-Layer Scene Representation from Composed Focal Stacks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Multi-layered scene representation; focal stack; view synthesis;
   AR-supported imaging
AB Multi-layer images are a powerful scene representation for high-performance rendering in virtual/augmented reality (VR/AR). The major approach to generate such images is to use a deep neural network trained to encode colors and alpha values of depth certainty on each layer using registered multi-view images. A typical network is aimed at using a limited number of nearest views. Therefore, local noises in input images from a user-navigated camera deteriorate the final rendering quality and interfere with coherency over view transitions. We propose to use a focal stack composed of multi-view inputs to diminish such noises. We also provide theoretical analysis for ideal focal stacks to generate multi-layer images. Our results demonstrate the advantages of using focal stacks in coherent rendering, memory footprint, and AR-supported data capturing. We also show three applications of imaging for VR.
C1 [Ishikawa, Reina; Saito, Hideo; Mori, Shohei] Keio Univ, Minato City, Japan.
   [Kalkofen, Denis] Flinders Univ S Australia, Adelaide, Australia.
   [Kalkofen, Denis; Mori, Shohei] Graz Univ Technol, Graz, Austria.
C3 Keio University; Flinders University South Australia; Graz University of
   Technology
RP Mori, S (corresponding author), Keio Univ, Minato City, Japan.; Mori, S (corresponding author), Graz Univ Technol, Graz, Austria.
EM reina-ishikawa@keio.jp; hs@keio.jp; kalkofen@icg.tugraz.at;
   s.mori.jp@ieee.org
RI Saito, Hideo/D-6223-2014; Mori, Shohei/AAL-6642-2020; Saito,
   Hideo/ADZ-2013-2022
OI Saito, Hideo/0000-0002-2421-9862; Kalkofen, Denis/0000-0002-0359-206X;
   Mori, Shohei/0000-0003-0540-7312
FU Austrian Science Fund FWF [P33634]; Austrian Science Fund (FWF) [P33634]
   Funding Source: Austrian Science Fund (FWF)
FX This work was supported by the Austrian Science Fund FWF (grant
   no.P33634). The authors used the computational resource of AI Bridging
   Cloud Infrastructure (ABCI) provided by the National Institute of
   Advanced Industrial Science and Technology (AIST). The authors thank
   Shiori Ueda for her support on synthetic dataset generation. The authors
   also thank Thomas Layer for providing light field data inFig. 2.
CR Attal B., 2020, ECCV, P441, DOI DOI 10.1007/978-3-030-58452-8_26
   B. O. Community, 2018, Blender - a 3D modelling and rendering package, P5
   Birklbauer C., Computers and Graphics (C&G), V53, P127
   Birklbauer C., 2014, Computer Graphics Forum, V33, P9
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chai JX, 2000, COMP GRAPH, P307, DOI 10.1145/344779.344932
   Dai P., 2020, P IEEE CVF C COMP VI, P7830
   Davis A, 2012, COMPUT GRAPH FORUM, V31, P305, DOI 10.1111/j.1467-8659.2012.03009.x
   Ebner C, 2022, IEEE T VIS COMPUT GR, V28, P2256, DOI 10.1109/TVCG.2022.3150504
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Fujii T, 1996, PICT COD S 96, V2, P447
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Inagaki Y., 2018, PROC EUROPEAN C COMP, V2, P9
   Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929
   Jambon C, 2023, P ACM COMPUT GRAPH, V6, DOI 10.1145/3585499
   Kai-En Lin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P328, DOI 10.1007/978-3-030-58601-0_20
   Kellnhofer P, 2021, PROC CVPR IEEE, P4285, DOI 10.1109/CVPR46437.2021.00427
   Khakhulin T, 2022, PROC CVPR IEEE, P8677, DOI 10.1109/CVPR52688.2022.00849
   Kim H., 2016, 2016 4 INT C 3D VISI, P2
   Klein George, 2007, P1
   Krizhevsky A., Learning Multiple Layers of Features from Tiny Images
   Kuthirummal S, 2011, IEEE T PATTERN ANAL, V33, P58, DOI 10.1109/TPAMI.2010.66
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12558, DOI 10.1109/ICCV48922.2021.01235
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Luvizon D. C., P IEEE CVF WINT C AP, P2556
   Maximov M, 2020, PROC CVPR IEEE, P1068, DOI 10.1109/CVPR42600.2020.00115
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mohr P., 2020, PROC ACM C HUMAN FAC, P1
   Mori S., 2023, IEEE Transactions on Visualization and Computer Graphics (TVCG), P2
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Ng R, 2005, ACM T GRAPHIC, V24, P735, DOI 10.1145/1073204.1073256
   Ng R., 2005, Tech. Report CSTR 2005-02, P2
   Overbeck RS, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275031
   Paszke A, 2019, ADV NEUR IN, V32
   Penner E., Journal of Mathematical Imaging and Vision, V56, P573
   Porter T., 1984, P C COMP GRAPH INT, P3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Skreinig LR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P386, DOI 10.1109/VRW55335.2022.00086
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Srinivasan PP, 2019, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2019.00026
   Szeliski R, 1999, INT J COMPUT VISION, V32, P45, DOI 10.1023/A:1008192912624
   Tewari A, 2022, COMPUT GRAPH FORUM, V41, P703, DOI 10.1111/cgf.14507
   Thatte J., 2018, Electronic Imaging, P1
   Tucker R, 2020, PROC CVPR IEEE, P548, DOI 10.1109/CVPR42600.2020.00063
   Vaish V, 2004, PROC CVPR IEEE, P2
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wang Z., 2016, COMPUTER VISION ECCV, P3
   Xiao L., 2018, Deepfocus: Learned image synthesis for computational displays, V37, P5
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
   Zhou W., 2020, Image Vision Comput., V95, P2
NR 60
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4719
EP 4729
DI 10.1109/TVCG.2023.3320248
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100034
PM 37782615
OA hybrid
DA 2024-11-06
ER

PT J
AU Reyes-Aviles, F
   Fleck, P
   Schmalstieg, D
   Arth, C
AF Reyes-Aviles, Fernando
   Fleck, Philipp
   Schmalstieg, Dieter
   Arth, Clemens
TI Bag of World Anchors for Instant Large-Scale Localization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Camera localization; Correspondence problem; 3D registration; Augmented
   Reality; Computer vision; Cross-platform; Collaborative; Structural
   modeling
AB In this work, we present a novel scene description to perform large-scale localization using only geometric constraints. Our work extends compact world anchors with a search data structure to efficiently perform localization and pose estimation of mobile augmented reality devices across multiple platforms (e.g., HoloLens 2, iPad). The algorithm uses a bag-of-words approach to characterize distinct scenes (e.g., rooms). Since the individual scene representations rely on compact geometric (rather than appearance-based) features, the resulting search structure is very lightweight and fast, lending itself to deployment on mobile devices. We present a set of experiments demonstrating the accuracy, performance and scalability of our novel localization method. In addition, we describe several use cases demonstrating how efficient cross-platform localization facilitates sharing of augmented reality experiences.
C1 [Reyes-Aviles, Fernando] VRVis Competence Ctr Vienna, Vienna, Austria.
   [Fleck, Philipp; Schmalstieg, Dieter; Arth, Clemens] Graz Univ Technol, Graz, Austria.
C3 Graz University of Technology
RP Reyes-Aviles, F (corresponding author), VRVis Competence Ctr Vienna, Vienna, Austria.
EM fernando.reyes-aviles@icg.tugraz.at; philipp.fleck@icg.tugraz.at;
   schmalstieg@icg.tugraz.at; arth@icg.tugraz.at
OI Reyes-Aviles, Fernando/0000-0002-4299-597X; Schmalstieg,
   Dieter/0000-0003-2813-2235
FU BMK; BMAW; Styria; SFG; Tyrol; Vienna Business Agency [879730]; European
   Community [101092861]; Horizon Europe - Pillar II [101092861] Funding
   Source: Horizon Europe - Pillar II
FX The authors wish to thank Christina Gsaxner and Georg Krispel for their
   support. This work was enabled by the Competence Centre VRVis. VRVis is
   funded by BMK, BMAW, Styria, SFG, Tyrol and Vienna Business Agency in
   the scope of COMET -Competence Centers for Excellent Technologies
   (879730) which is managed by FFG. This work was also supported by the
   European Community's Horizon Europe program under grant agreement no.
   101092861 (THEIAXR), coordinated by Martijn Rooker, TTControl (TTC),
   Vienna, Austria.
CR Aarthi S., 2017, INT C COMP COMM SIGN, P2
   Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Arth C., 2011, INT S MIX AUGM REAL, P2
   Arth C, 2009, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2009.5336494
   Cabral R, 2014, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2014.546
   centralpark, Chess - Central Park
   Chang A. X., 2015, CoRR, abs/1512.03012, P2
   developer.apple, Apple - ARWorldMap
   developers.google, Google - Cloud Anchors
   Drost B., 2010, C COMP VIS PATT REC
   Dubé R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Garg S., 2021, INT JOINT C ART INT, P2
   Glocker B, 2013, INT SYM MIX AUGMENT, P173, DOI 10.1109/ISMAR.2013.6671777
   Huo K, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P19, DOI 10.1145/3242587.3242595
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/CVPRW.2009.5206587
   Kähler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Klein G., 2007, INT S MIX AUGM REAL, P2
   Li W., 2023, C COMP VIS PATT REC
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Lianos K., 2018, EUR C COMP VIS, P2
   library.vuforia, PTC Vuforia - Area Targets
   Liebers J., 2022, International Journal of Human-Computer Interaction, V0, P8
   Liu C, 2019, PROC CVPR IEEE, P4445, DOI 10.1109/CVPR.2019.00458
   Liu C, 2018, PROC CVPR IEEE, P2579, DOI 10.1109/CVPR.2018.00273
   Liu D., 2021, AAAI C ART INT, V35, P2
   Barros AM, 2022, ROBOTICS, V11, DOI 10.3390/robotics11010024
   Merzlyakov A, 2021, IEEE INT C INT ROBOT, P9190, DOI 10.1109/IROS51168.2021.9636615
   Mokssit S, 2023, IEEE ACCESS, V11, P20026, DOI 10.1109/ACCESS.2023.3249661
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205
   Reyes-Aviles F., 2022, IEEE Transactions on Visualization and Computer Graphics (TVCG), V1
   Salas-Moreno R. F., 2013, C COMP VIS PATT REC, P2
   Schmalstieg D., 2016, Augmented Reality: Principles and Practice, P2
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sommer C., 2020, INT C ROB AUT ICRA
   Stanescu A., 2018, INT S MIX AUGM REAL
   Stewenius H., 2006, C COMP VIS PATT REC, V2
   Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881
   Teed Z., 2021, Advances in Neural Information Processing Systems (NIPS), V34, P2
   vgis, VGis - Tracking
   Wuest H., 2016, INT S MIX AUGM REAL, P2
   Xia Y., 2021, C COMP VIS PATT REC
   Zhang L, 2018, IEEE ACCESS, V6, P75545, DOI [10.1109/ACCESS.2018.2873617, 10.1109/TCBB.2018.2848633]
   Zou CH, 2018, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2018.00219
NR 50
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4730
EP 4739
DI 10.1109/TVCG.2023.3320264
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100035
PM 37782608
OA hybrid
DA 2024-11-06
ER

PT J
AU Sidenmark, L
   Prummer, F
   Newn, J
   Gellersen, H
AF Sidenmark, Ludwig
   Prummer, Franziska
   Newn, Joshua
   Gellersen, Hans
TI Comparing Gaze, Head and Controller Selection of Dynamically Revealed
   Targets in Head-Mounted Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Mathematical models; Three-dimensional displays; Task analysis; Resists;
   Lenses; Performance evaluation; Visualization; Pointing; Selection
   Performance; Virtual Reality; 3D Interaction
AB This paper presents a head-mounted virtual reality study that compared gaze, head, and controller pointing for selection of dynamically revealed targets. Existing studies on head-mounted 3D interaction have focused on pointing and selection tasks where all targets are visible to the user. Our study compared the effects of screen width (field of view), target amplitude and width, and prior knowledge of target location on modality performance. Results show that gaze and controller pointing are significantly faster than head pointing and that increased screen width only positively impacts performance up to a certain point. We further investigated the applicability of existing pointing models. Our analysis confirmed the suitability of previously proposed two-component models for all modalities while uncovering differences for gaze at known and unknown target positions. Our findings provide new empirical evidence for understanding input with gaze, head, and controller and are significant for applications that extend around the user.
C1 [Sidenmark, Ludwig] Univ Toronto, Toronto, ON, Canada.
   [Prummer, Franziska; Newn, Joshua; Gellersen, Hans] Univ Lancaster, Lancaster, England.
   [Gellersen, Hans] Aarhus Univ, Aarhus, Denmark.
C3 University of Toronto; Lancaster University; Aarhus University
RP Sidenmark, L (corresponding author), Univ Toronto, Toronto, ON, Canada.
EM lsidenmark@dgp.toronto.edu; f.prummer@lancaster.ac.uk;
   j.newn@lancaster.ac.uk; h.gellersen@lancaster.ac.uk
OI Sidenmark, Ludwig/0000-0002-7965-0107; Gellersen,
   Hans/0000-0003-2233-2121; Prummer, Franziska/0000-0003-4784-5580; Newn,
   Joshua/0000-0001-5769-6297
FU European Research Council (ERC) under European Union [101021229];
   European Research Council (ERC) [101021229] Funding Source: European
   Research Council (ERC)
FX This work was supported by the European Research Council (ERC)under the
   European Union's Horizon 2020 research and innovation programme (Grant
   No. 101021229, GEMINI: Gaze and Eye Movement in Interaction).
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Batmaz Anil Ufuk, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382796
   Batmaz AU, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P585, DOI [10.1109/VR.2019.8797975, 10.1109/vr.2019.8797975]
   Belo J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445349
   Blattgerste J, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206349
   Bolt R. A., 1981, Computer Graphics, V15, P109, DOI 10.1145/965161.806796
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Byers JC, 1989, Advances in Industrial Ergonomics and Safety I, P481
   Cao X, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1699
   Carpenter RHS, 1988, Movements of the eyes
   Chen Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376592
   Drewes H., 2010, PhD thesis
   Einhäuser W, 2007, NETWORK-COMP NEURAL, V18, P267, DOI 10.1080/09548980701671094
   Ens B, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P107, DOI 10.1145/2983310.2985756
   Epps B. W., 1986, Proceedings of the Human Factors Society 30th Annual Meeting, P327
   Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599
   Fernandes A. S, 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32470581,2,4,5, DOI 10.1109/TVCG.2023.32470581,2,4,5]
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Forlines C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P647
   Gori J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173770
   Grinyer K, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P139, DOI 10.1109/VR51125.2022.00032
   Grossman T, 2004, P SIGCHI C HUM FACT, V6, P447, DOI [10.1145/985692.985749, DOI 10.1145/985692.985749]
   Gruenefeld U, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P109, DOI 10.1145/3131277.3132175
   Gruenefeld U, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3122124
   Hansen JP, 2018, COMMUNICATION BY GAZE INTERACTION (COGAIN 2018), DOI 10.1145/3206343.3206344
   Hou BJ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581201
   Hurst W., 2010, P 9 INT C MOB UB MUL, DOI [10.1145/1899475.18995002, DOI 10.1145/1899475.18995002]
   JAGACINSKI RJ, 1985, J MOTOR BEHAV, V17, P77
   Kaufmann B., 2012, P 14 INT C HUM COMP, P211, DOI [10.1145/2371574.2371607, DOI 10.1145/2371574.2371607]
   Kerber F, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P291, DOI 10.1145/2628363.2628393
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lin YT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P255, DOI 10.1145/3126594.3126656
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P11, DOI 10.1109/3DUI.2014.6798834
   MacKenzie I. S., 1992, Human-Computer Interaction, V7, P91, DOI 10.1207/s15327051hci0701_3
   McCullagh P., 1989, Generalized Linear Models, P4
   Mehra S., 2006, ACM Transactions on Computer-Human Interaction, V13, P448, DOI 10.1145/1188816.1188818
   Mine M. R., 1995, Technical report, V1, P2
   Miniotas D., 2000, CHI 00 EXTENDED ABST, P339, DOI [10.1145/633292.633496, DOI 10.1145/633292.633496, 10.1145/633292.6334962]
   Mutasim Aunnoy K., 2021, ACM Symposium on Eye Tracking Research and Applications, P1, DOI DOI 10.1145/3448018.3457998
   Nacenta MiguelA., 2006, P SIGCHI C HUMAN FAC, P289, DOI DOI 10.1145/1124772.1124817
   Pagano R.R., 2008, UNDERSTANDING STAT B, V9th
   Petford J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174107
   Poupyrev I, 1998, COMPUT GRAPH FORUM, V17, pC41
   Qian Y, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P91, DOI 10.1145/3131277.3132182
   Radle R, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P4127, DOI 10.1145/2556288.2557071
   Rohs M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2725
   Rohs M, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1409
   Schuetz I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300765
   Shoemaker G, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395135
   Sidenmark L, 2022, IEEE T VIS COMPUT GR, V28, P3585, DOI 10.1109/TVCG.2022.3203096
   Sidenmark L, 2020, ETRA'20 FULL PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3379155.3391312
   Sidenmark L, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3361218
   Sidenmark L, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1161, DOI 10.1145/3332165.3347921
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Vertegaal R., 2008, P 10 INT C MULT INT, P241, DOI [DOI 10.1145/1452392.1452443, 10.1145/1452392.1452443]
   Wagner U, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581423
   Wingrave C., 2005, P HCI INT, P61
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 63
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4740
EP 4750
DI 10.1109/TVCG.2023.3320235
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100036
PM 37782604
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Choudhary, ZD
   Bruder, G
   Welch, GF
AF Choudhary, Zubin Datta
   Bruder, Gerd
   Welch, Gregory F.
TI Visual Facial Enhancements Can Significantly Improve Speech Perception
   in the Presence of Noise
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lips; Visualization; Speech enhancement; Faces; Face recognition; Signal
   resolution; Resists; Speech perception; background noise; hearing; human
   faces; enhancement methods; user study
ID RECEPTION THRESHOLD; HEARING; DISTANCE; FACE
AB Human speech perception is generally optimal in quiet environments, however it becomes more difficult and error prone in the presence of noise, such as other humans speaking nearby or ambient noise. In such situations, human speech perception is improved by speech reading, i.e., watching the movements of a speaker's mouth and face, either consciously as done by people with hearing loss or subconsciously by other humans. While previous work focused largely on speech perception of two-dimensional videos of faces, there is a gap in the research field focusing on facial features as seen in head-mounted displays, including the impacts of display resolution, and the effectiveness of visually enhancing a virtual human face on speech perception in the presence of noise. In this paper, we present a comparative user study (N = 21) in which we investigated an audio-only condition compared to two levels of head-mounted display resolution (1832x1920 or 916x960 pixels per eye) and two levels of the native or visually enhanced appearance of a virtual human, the latter consisting of an up-scaled facial representation and simulated lipstick (lip coloring) added to increase contrast. To understand effects on speech perception in noise, we measured participants' speech reception thresholds (SRTs) for each audio-visual stimulus condition. These thresholds indicate the decibel levels of the speech signal that are necessary for a listener to receive the speech correctly 50% of the time. First, we show that the display resolution significantly affected participants' ability to perceive the speech signal in noise, which has practical implications for the field, especially in social virtual environments. Second, we show that our visual enhancement method was able to compensate for limited display resolution and was generally preferred by participants. Specifically, our participants indicated that they benefited from the head scaling more than the added facial contrast from the simulated lipstick. We discuss relationships, implications, and guidelines for applications that aim to leverage such enhancements.
C1 [Choudhary, Zubin Datta; Bruder, Gerd; Welch, Gregory F.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Choudhary, ZD (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM zubin.choudhary@ucf.edu; bruder@ucf.edu; welch@ucf.edu
RI Choudhary, Zubin/AAX-7407-2021
OI Welch, Gregory/0000-0002-8243-646X
FU National Science Foundation [2235066, 1800961]; Office of Naval Research
   [N00014-21-1-2578, N00014-21-1-2882]; Advent Health Endowed Chair in
   Healthcare Simulation
FX This material includes work supported in part by the National Science
   Foundation under Award Numbers 2235066 and 1800961 (Dr. Ephraim P.
   Glinert, IIS); the Office of Naval Research under Award Numbers
   N00014-21-1-2578 and N00014-21-1-2882 (Dr. Peter Squire, Code 34); and
   the Advent Health Endowed Chair in Healthcare Simulation (Prof. Welch).
CR Bouserhal RE, 2017, J SPEECH LANG HEAR R, V60, P3393, DOI 10.1044/2017_JSLHR-S-17-0052
   Calvert GA, 1997, SCIENCE, V276, P593, DOI 10.1126/science.276.5312.593
   Choudhary Z, 2023, Symposium Virtual Re, P571, DOI 10.1109/VR55154.2023.00072
   Choudhary Z, 2023, ACM T APPL PERCEPT, V20, DOI 10.1145/3571074
   Choudhary Z, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3488286
   Choudhary Z, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P425, DOI [10.1109/VR46266.2020.00-41, 10.1109/VR46266.2020.1581089101511]
   Choudhary Zubin, 2021, WORKSH US EMB INT VI
   Dodd B., 1987, Hearing by Eye: The psychology of lip-reading
   Erickson A., 2020, P 2020 ACM S SPAT US, P1
   FOWLER CA, 1991, J EXP PSYCHOL HUMAN, V17, P816, DOI 10.1037/0096-1523.17.3.816
   Fribourg R, 2021, INT SYM MIX AUGMENT, P470, DOI 10.1109/ISMAR52148.2021.00064
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Gonzalez-Franco M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04201-x
   Jones A. L., 2015, Facial cosmetics have little effect on attractiveness judgments compared with identity
   Jones AL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164218
   Jordan T. R., 1998, Effects of facial image size on visual and audio-visual speech recognition
   Jordan TR, 2000, LANG SPEECH, V43, P107, DOI 10.1177/00238309000430010401
   Jordan TR, 2001, J EXP PSYCHOL HUMAN, V27, P1386, DOI 10.1037//0096-1523.27.6.1386
   Kanzaki R., 1999, AVSP 99 INT C AUDITO
   Kitagawa N, 2002, NATURE, V416, P172, DOI 10.1038/416172a
   Kiyokawa K., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P48, DOI 10.1109/ICSMC.1999.816444
   Kobayashi Y, 2017, I-PERCEPTION, V8, P1, DOI 10.1177/2041669517717500
   Kopp S, 2008, LECT NOTES ARTIF INT, V4930, P18
   KRAUSKOPF J, 1991, VISION RES, V31, P735, DOI 10.1016/0042-6989(91)90012-T
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   Krishnamurthy N, 2009, IEEE T AUDIO SPEECH, V17, P1394, DOI 10.1109/TASL.2009.2015084
   Lander K, 2013, SPEECH COMMUN, V55, P600, DOI 10.1016/j.specom.2013.01.003
   Lee Jinhee, 2006, INTERNATIONAL JOURNAL OF HUMAN ECOLOGY, V7, P77
   Lee M, 2021, IEEE T VIS COMPUT GR, V27, P3534, DOI 10.1109/TVCG.2019.2959575
   MACDONALD J, 1978, PERCEPT PSYCHOPHYS, V24, P253, DOI 10.3758/BF03206096
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Michelson A., 1995, Studies in Optics
   MIDDELWEERD MJ, 1987, J ACOUST SOC AM, V82, P2145, DOI 10.1121/1.395659
   Musacchia G, 2006, EXP BRAIN RES, V168, P1, DOI 10.1007/s00221-005-0071-5
   Norouzi N., 2020, P INT C ART REAL TEL
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   PLOMP R, 1979, AUDIOLOGY, V18, P43
   POLLACK I, 1975, J ACOUST SOC AM, V57, pS5, DOI 10.1121/1.1995329
   Rosenblum Lawrence, 2019, Audiovisual speech perception and the McGurk effect
   Rosenblum LD, 2008, CURR DIR PSYCHOL SCI, V17, P405, DOI 10.1111/j.1467-8721.2008.00615.x
   Rosenblum LD, 2000, J EXP PSYCHOL HUMAN, V26, P806, DOI 10.1037//0096-1523.26.2.806
   Sams M, 2005, COGNITIVE BRAIN RES, V23, P429, DOI 10.1016/j.cogbrainres.2004.11.006
   SEKIYAMA K, 1993, J PHONETICS, V21, P427, DOI 10.1016/S0095-4470(19)30229-3
   SLATER M, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P90, DOI 10.1109/VRAIS.1993.380793
   Smits C, 2004, INT J AUDIOL, V43, P15, DOI 10.1080/14992020400050004
   Strand EA, 1999, J LANG SOC PSYCHOL, V18, P86, DOI 10.1177/0261927X99018001006
   SUMMERFIELD Q, 1992, PHILOS T ROY SOC B, V335, P71, DOI 10.1098/rstb.1992.0009
   Tanaka H, 2021, J INTEGR NEUROSCI, V20, P1029, DOI 10.31083/j.jin2004104
   Tanaka H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01359
   Tsao DY, 2008, ANNU REV NEUROSCI, V31, P411, DOI 10.1146/annurev.neuro.30.051606.094238
   Van den Borre E, 2021, INT J AUDIOL, V60, P946, DOI [10.1080/14992027.2021.1902579, 10.17159/2617-3255/2021/n35a4]
   Wilson RichardH., 2007, An evaluation of the BKB-SIN, HINT, QuickSIN, and WIN materials on listeners with normal hearing and listeners with hearing loss
   Woodhouse L, 2009, INT J LANG COMM DIS, V44, P253, DOI 10.1080/13682820802090281
NR 53
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4751
EP 4760
DI 10.1109/TVCG.2023.3320247
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y0EV4
UT WOS:001102096500004
PM 37782611
DA 2024-11-06
ER

PT J
AU Hiroi, Y
   Watanabe, A
   Mikawa, Y
   Itoh, Y
AF Hiroi, Yuichi
   Watanabe, Akira
   Mikawa, Yuri
   Itoh, Yuta
TI Low-Latency Beaming Display: Implementation of Wearable, 133 μs
   Motion-to-Photon Latency Near-eye Display
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Low-Latency Display; Beaming Display; Motion-to-Photon Latency;
   Lateral-effect Photodiodes
ID TRACKING
AB This paper presents a low-latency Beaming Display system with a 133 mu s motion-to-photon (M2P) latency, the delay from head motion to the corresponding image motion. The Beaming Display represents a recent near-eye display paradigm that involves a steerable remote projector and a passive wearable headset. This system aims to overcome typical trade-offs of Optical See-Through Head-Mounted Displays (OST-HMDs), such as weight and computational resources. However, since the Beaming Display projects a small image onto a moving, distant viewpoint, M2P latency significantly affects displacement. To reduce M2P latency, we propose a low-latency Beaming Display system that can be modularized without relying on expensive high-speed devices. In our system, a 2D position sensor, which is placed coaxially on the projector, detects the light from the IR-LED on the headset and generates a differential signal for tracking. An analog closed-loop control of the steering mirror based on this signal continuously projects images onto the headset. We have implemented a proof-of-concept prototype, evaluated the latency and the augmented reality experience through a user-perspective camera, and discussed the limitations and potential improvements of the prototype.
C1 [Hiroi, Yuichi; Mikawa, Yuri; Itoh, Yuta] Univ Tokyo, Tokyo, Japan.
   [Watanabe, Akira] Tokyo Inst Technol, Tokyo, Japan.
C3 University of Tokyo; Institute of Science Tokyo; Tokyo Institute of
   Technology
RP Hiroi, Y (corresponding author), Univ Tokyo, Tokyo, Japan.
EM yuichi.hiroi.1@gmail.com; akira.watanabe@ar.c.titech.ac.jp;
   yuri.mikawa@gmail.com; yuta.itoh@iii.u-tokyo.ac.jp
RI Hiroi, Yuichi/KGM-7451-2024
FU JST FOREST [JPMJFR206E]; JSPS KAKENHI, Japan [JP22J01340, JP20H05958]
FX This project was partially supported by JST FOREST Grant Number
   JPMJFR206E, and JSPS KAKENHI Grant Number JP22J01340, and JP20H05958,
   Japan.
CR Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Azuma R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P401, DOI 10.1145/218380.218496
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bapat A, 2018, PROC CVPR IEEE, P4824, DOI 10.1109/CVPR.2018.00507
   Bapat A, 2016, IEEE T VIS COMPUT GR, V22, P2358, DOI 10.1109/TVCG.2016.2593757
   Blate A, 2019, IEEE T VIS COMPUT GR, V25, P1970, DOI 10.1109/TVCG.2019.2899233
   Dibene JC, 2022, IEEE T VIS COMPUT GR, V28, P2201, DOI 10.1109/TVCG.2022.3150485
   Gül S, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3632, DOI 10.1145/3394171.3413699
   Guimard Q, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P12, DOI 10.1145/3524273.3528176
   Hamasaki T, 2018, IEEE T VIS COMPUT GR, V24, P1457, DOI 10.1109/TVCG.2018.2793659
   Hiroi Y., 2020, P AUGMENTED HUMANS I, P1
   Hiroi Y, 2022, 28TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2022, DOI 10.1145/3562939.3565616
   Hisaichi S., SIGGRAPH ASIA 2021 E, P1
   Holloway RL, 1997, PRESENCE-VIRTUAL AUG, V6, P413, DOI 10.1162/pres.1997.6.4.413
   Huber M., 2014, Journal of Virtual Reality and Broadcasting, V11
   it K. Aks, 2023, arXiv
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P2659, DOI 10.1109/TVCG.2021.3067764
   Itoh Y, 2016, P IEEE VIRT REAL ANN, P189, DOI 10.1109/VR.2016.7504717
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jota Ricardo, 2013, P SIGCHI C HUM FACT, P2291, DOI DOI 10.1145/2470654.2481317
   Kress B, 2013, PROC SPIE, V8720, DOI 10.1117/12.2015654
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Mikawa Y., 2021, IEEE Transactions on Visualization & Computer Graphics, P1
   Mikawa Y, 2021, 2021 60TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P137
   Mine M., 1995, Just-in-time pixels
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Miyazaki D, 2018, PROC INT WORKSH ADV
   Nabiyouni M., 2017, Frontiers in ICT, V3
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Nguyen TT, 2011, PROC SPIE, V8065, DOI 10.1117/12.883999
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Okumura K., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P699, DOI 10.1109/ICME.2012.34
   Olano M., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P19, DOI 10.1145/199404.199407
   Popescu V, 2000, COMP GRAPH, P433, DOI 10.1145/344779.344979
   Regan M, 2017, IEEE T VIS COMPUT GR, V23, P1295, DOI 10.1109/TVCG.2017.2656979
   Rolland JP, 2001, FUNDAMENTALS OF WEARABLE COMPUTERS AND AUGMENTED REALITY, P67
   Rondón MFR, 2022, IEEE T PATTERN ANAL, V44, P5681, DOI 10.1109/TPAMI.2021.3070520
   Sueishi T, 2016, PRESENCE-VIRTUAL AUG, V25, P299, DOI 10.1162/PRES_a_00275
   Sun XL, 2019, APPL OPTICS, V58, P9259, DOI 10.1364/AO.58.009259
   Sutherland I., 1965, The ultimate display
   SUTHERLAND IE, 1974, P IEEE, V62, P453, DOI 10.1109/PROC.1974.9449
   Syed T. A., 2022, Sensors, V23
   Tran Trung Nguyen, 2011, Proceedings of the 2011 IEEE International Conference on Control System, Computing and Engineering (ICCSCE), P409, DOI 10.1109/ICCSCE.2011.6190561
   Wang C, 2017, PRECIS ENG, V48, P133, DOI 10.1016/j.precisioneng.2016.11.013
   Warburton M, 2023, BEHAV RES METHODS, V55, P3658, DOI 10.3758/s13428-022-01983-5
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Welch G., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P1, DOI 10.1145/323663.323664
   Zheng F, 2014, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR.2014.6948427
   Ziegelberger G, 2013, HEALTH PHYS, V105, P74, DOI 10.1097/HP.0b013e318289a611
NR 51
TC 2
Z9 2
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4761
EP 4771
DI 10.1109/TVCG.2023.3320212
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100037
PM 37788208
DA 2024-11-06
ER

PT J
AU Giovannelli, A
   Thomas, J
   Lane, L
   Rodrigues, F
   Bowman, DA
AF Giovannelli, Alexander
   Thomas, Jerald
   Lane, Logan
   Rodrigues, Francielly
   Bowman, Doug A.
TI Gestures vs. Emojis: Comparing Non-Verbal Reaction Visualizations for
   Immersive Collaboration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Human-computer interaction (HCI); virtual humans and avatars;
   telepresence; collaborative interfaces
ID IMPACT
AB Collaborative virtual environments afford new capabilities in telepresence applications, allowing participants to co-inhabit an environment to interact while being embodied via avatars. However, shared content within these environments often takes away the attention of collaborators from observing the non-verbal cues conveyed by their peers, resulting in less effective communication. Exaggerated gestures, abstract visuals, as well as a combination of the two, have the potential to improve the effectiveness of communication within these environments in comparison to familiar, natural non-verbal visualizations. We designed and conducted a user study where we evaluated the impact of these different non-verbal visualizations on users' identification time, understanding, and perception. We found that exaggerated gestures generally perform better than non-exaggerated gestures, abstract visuals are an effective means to convey intentional reactions, and the combination of gestures with abstract visuals provides some benefits compared to their standalone counterparts.
C1 [Giovannelli, Alexander; Thomas, Jerald; Lane, Logan; Bowman, Doug A.] Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
   [Rodrigues, Francielly] Natl Lab Sci Comp, Blacksburg, VA USA.
C3 Virginia Polytechnic Institute & State University
RP Giovannelli, A (corresponding author), Virginia Tech, Ctr Human Comp Interact, Blacksburg, VA 24061 USA.
EM agiovannelli@vt.edu; jeraldlt@vt.edu; logantl@vt.edu;
   fmunique@posgrad.lncc.br; dbowman@vt.edu
OI Rodrigues, Francielly/0000-0002-8987-2299; Bowman,
   Doug/0000-0003-0491-5067; Lane, Logan/0009-0009-4385-160X; Giovannelli,
   Alexander/0000-0002-0265-8143
FU Office of Naval Research
FX This work was supported by a grant from the Office of Naval Research.
CR Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Billinghurst M, 2002, COMMUN ACM, V45, P64, DOI 10.1145/514236.514265
   Bourne RRA, 2017, LANCET GLOB HEALTH, V5, pE888, DOI 10.1016/S2214-109X(17)30293-0
   Choudhary Z, 2023, ACM T APPL PERCEPT, V20, DOI 10.1145/3571074
   Damian I, 2014, INT SYM MIX AUGMENT, P261, DOI 10.1109/ISMAR.2014.6948440
   Drey T, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517641
   Eerden B., 2009, Multimodal metaphor, P2
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Fischer B, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.645173
   Forceville C, 2009, APPL COGN LINGUIST, V11, P3
   Gelb D., 2011, 2011 IEEE WORKSH PER, P1, DOI [10.1109/POV.2011.57123681, DOI 10.1109/POV.2011.57123681]
   Gonzalez-Franco M, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.561558
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Hassenzahl M, 2012, ACM T COMPUT-HUM INT, V19, DOI 10.1145/2395131.2395137
   Irlitti A, 2013, INT SYM MIX AUGMENT
   Kaya N., 2004, College Student Journal, V38, P396
   Kaye LK, 2021, COMPUT HUM BEHAV, V116, DOI 10.1016/j.chb.2020.106648
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kiyokawa K, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P139, DOI 10.1109/ISMAR.2002.1115083
   Latoschik M. E., 2017, VRST 17 P 23 ACM S V, P1, DOI DOI 10.1145/3139131.3139156
   Oh SY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161794
   Pakanen M, 2022, ENTERTAIN COMPUT, V40, DOI 10.1016/j.entcom.2021.100457
   Pidel C., 2020, Collaboration in Virtual and Augmented Reality: A Systematic Overview, P141, DOI [10.1007/978-3-030-58465-8_101,2, DOI 10.1007/978-3-030-58465-8_101,2]
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schafer A., 2022, ACM Comput. Surv., DOI [10.1145/35333762, DOI 10.1145/35333762]
   Seidel EM, 2010, J EXP PSYCHOL HUMAN, V36, P500, DOI 10.1037/a0018169
   Semsioglu S, 2022, AUGMENTED HUMAN 2022: PROCEEDINGS OF THE 13TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE, AH2022, DOI 10.1145/3532525.3532527
   Semsioglu S, 2021, COMM COM INF SC, V1498, P377, DOI 10.1007/978-3-030-90176-9_49
   Shinohara K., 2009, Multimodal metaphor, P2
   Stefan L, 2012, PROCD SOC BEHV, V51, P1056, DOI 10.1016/j.sbspro.2012.08.287
   Valente A, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P158, DOI 10.1109/VR51125.2022.00034
   Walker ME, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/vr.2019.8798152
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang TY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1221, DOI [10.1109/VR.2019.8798044, 10.1109/vr.2019.8798044]
   Wiseman S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173726
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
NR 41
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4772
EP 4781
DI 10.1109/TVCG.2023.3320254
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100038
PM 37782597
DA 2024-11-06
ER

PT J
AU Kim, H
   Park, J
   Lee, IK
AF Kim, Hayeon
   Park, Jinhyung
   Lee, In-Kwon
TI "To be or Not to be Me?: Exploration of Self-Similar Effects of Avatars
   on Social Virtual Reality Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Avatars; Visualization; Games; Virtual environments; Social networking
   (online); Psychology; Mirrors; social virtual reality; virtual reality
   experience; embodiment; self-similar avatar; representation of avatar;
   anonymity; gender effect; presence; social presence; immersion;
   self-awareness
ID BODY; EMBODIMENT; APPEARANCE; REPRESENTATION; COMMUNICATION; VALIDATION;
   OWNERSHIP; IMMERSION; STRANGER; IMPACT
AB The growing interest in the self-similarity effect of avatars in virtual reality (VR) has spurred the creation of realistic avatars that closely mirror their users. However, despite extensive research on the self-similarity effect in single-user VR environments, our understanding of its impact in social VR settings remains underdeveloped. This shortfall exists despite the unique socio-psychological phenomena arising from the illusion of embodiment that could potentially alter these effects. To fill this gap, this paper provides an in-depth empirical investigation of how avatars' self-similarity influences social VR experiences. Our research uncovers several notable findings: 1) A high level of avatar self-similarity boosts users' sense of embodiment and social presence but has minimal effects on the overall presence and even slightly hinders immersion. These results are driven by increased self-awareness. 2) Among various factors that contribute to the self-similarity of avatars, voice stands out as a significant influencer of social VR experiences, surpassing other representational factors. 3) The impact of avatar self-similarity shows negligible differences between male and female users. Based on these findings, we discuss the pros and cons of incorporating self-similarity into social VR avatars. Our study serves as a foundation for further research in this field.
C1 [Kim, Hayeon; Park, Jinhyung; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
C3 Yonsei University
RP Kim, H (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM qoocrab@gmail.com; jh9604@yonsei.ac.kr; iklee@yonsei.ac.kr
RI Kim, Hayeon/AAY-5003-2021; Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882; Kim, Hayeon/0000-0002-6529-0921
FU MSIT(Ministry of Science and ICT), Korea, under the ITRC(Information
   Technology Research Center) support program [IITP-2021-2018-0-01419];
   National Research Foundation of Korea(NRF) grant - Korea
   government(MSIT) [NRF-2020R1A2C2014622]
FX This research was supported by the MSIT(Ministry of Science and ICT),
   Korea, under the ITRC(Information Technology Research Center) support
   program(IITP-2021-2018-0-01419) supervised by the IITP(Institute for
   Information and Communications Technology Planning and Evaluation) and
   the National Research Foundation of Korea(NRF) grant funded by the Korea
   government(MSIT). (No. NRF-2020R1A2C2014622)
CR Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Aymerich-Franch L., 2012, P INT SOC PRES RES A, P24
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   Bakeman R, 2005, BEHAV RES METHODS, V37, P379, DOI 10.3758/BF03192707
   Baker Steven, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359251
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   [卞玉龙 Bian Yulong], 2015, [心理学报, Acta Psychologica Sinica], V47, P363
   Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Birk MV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2982, DOI 10.1145/2858036.2858062
   Blackwell Lindsay, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359202
   Blascovich J, 2002, COMP SUPP COMP W SER, P127
   Carter Marcus, 2015, P 2015 ANN S COMP HU, P265, DOI [10.1145/2793107.2793144, DOI 10.1145/2793107.2793144]
   Crenshaw Nicole., 2014, Proceedings of CHIPlay '14, P67, DOI DOI 10.1145/2658537.2658685
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Dong ZJ, 2022, PROC CVPR IEEE, P20438, DOI 10.1109/CVPR52688.2022.01982
   Ducheneaut N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1151
   Felnhofer A., 2012, P INT SOC PRES RES A, P103
   FENIGSTEIN A, 1975, J CONSULT CLIN PSYCH, V43, P522, DOI 10.1037/h0076760
   Freeman Guo, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512932
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Frostling-Henningsson M, 2009, CYBERPSYCHOL BEHAV, V12, P557, DOI 10.1089/cpb.2008.0345
   Geser H., 2007, Me, my self and my avatar: some microsociological reflections on"second life
   Giannopoulos E, 2008, LECT NOTES COMPUT SC, V5024, P301, DOI 10.1007/978-3-540-69057-3_36
   Goffman E., 1959, DOUBLEDAY
   Gonzalez-Franco M, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00074
   Govern JM, 2001, CONSCIOUS COGN, V10, P366, DOI 10.1006/ccog.2001.0506
   Grimshaw M, 2007, PROCEEDINGS OF CGAMES'2007: 11TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES: AI, ANIMATION, MOBILE, EDUCATIONAL AND SERIOUS GAMES, 2007, P119
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Hooi R, 2014, COMPUT HUM BEHAV, V39, P20, DOI 10.1016/j.chb.2014.06.019
   Hussain Z, 2008, CYBERPSYCHOL BEHAV, V11, P47, DOI 10.1089/cpb.2007.0020
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jin SAA, 2009, CYBERPSYCHOL BEHAV, V12, P761, DOI 10.1089/cpb.2009.0130
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Johnson RD, 2011, J ORGAN END USER COM, V23, P79, DOI 10.4018/joeuc.2011010105
   Joinson A, 1999, BEHAV RES METH INS C, V31, P433, DOI 10.3758/BF03200723
   Kang Ruogu, 2013, P SIGCHI C HUM FACT, P2657, DOI DOI 10.1145/2470654.2481368
   Kao Dominic, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3474665
   Kao D, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501848
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Konijn EA., 2009, Serious Games, P201
   Koulouris J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376661
   Kruse B, 2016, CORTEX, V83, P86, DOI 10.1016/j.cortex.2016.07.010
   Latoschik M. E., 2017, VRST 17 P 23 ACM S V, P1, DOI DOI 10.1145/3139131.3139156
   Lombard Matthew, 2009, P 12 ANN INT WORKSH, P1
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   MacArthur C., 2021, P 2021 CHI C HUM FAC
   Makransky G, 2017, COMPUT HUM BEHAV, V72, P276, DOI 10.1016/j.chb.2017.02.066
   Maloney Divine, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P472, DOI 10.1145/3410404.3414268
   Maloney Divine, 2020, VRST '20: 26th ACM Symposium on Virtual Reality Software and Technology, DOI 10.1145/3385956.3418967
   Maloney Divine, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P510, DOI 10.1145/3410404.3414266
   Maloney D., 2020, Proc. ACM Human-Comput. Interact., V4, P1, DOI [10.1145/3415246, DOI 10.1145/3415246]
   Martey RM, 2011, POP COMMUN, V9, P165, DOI 10.1080/15405702.2011.583830
   Matheson K., 1988, Computers in Human Behaviour, V4, P221, DOI 10.1016/0747-5632(88)90015-5
   Merola N., 2009, Journal For Virtual Worlds Research, V2
   Midha V, 2012, COMPUT HUM BEHAV, V28, P929, DOI 10.1016/j.chb.2011.12.013
   Narayan Michael, 2005, P ACM S VIRT REAL SO, P78, DOI DOI 10.1145/1101616.1101632
   Nenon T., 2002, New Yearbook for Phenomenology and Phenomenological Philosophy, V2, P1
   Nordahl R., 2005, 8 ANN INT WORKSH PRE, P5
   Nordahl R., 2014, Oxford Handbook of Interactive Audio
   Nordahl Rolf, 2006, P 9 INT WORKSH PRES, P57
   Peck TC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376419
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Przybylski AK, 2012, PSYCHOL SCI, V23, P69, DOI 10.1177/0956797611418676
   Rahill KM, 2021, COMPUT HUM BEHAV REP, V4, DOI 10.1016/j.chbr.2021.100131
   Ratan R., 2011, 61 ANN C INT COMM AS, P1
   Roth D, 2016, P IEEE VIRT REAL ANN, P277, DOI 10.1109/VR.2016.7504761
   RUBIN Z, 1975, J EXP SOC PSYCHOL, V11, P233, DOI 10.1016/S0022-1031(75)80025-4
   Ruytjens L, 2006, EUR J NEUROSCI, V24, P1835, DOI 10.1111/j.1460-9568.2006.05072.x
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Sibilla F, 2018, CYBERPSYCHOLOGY, V12, DOI 10.5817/CP2018-3-4
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Sung E, 2012, COMPUT HUM BEHAV, V28, P1738, DOI 10.1016/j.chb.2012.04.014
   Tonndorf J., 1976, HDB SENSORY PHYSL, P37, DOI [10.1007/978-3-642-66082-52, DOI 10.1007/978-3-642-66082-52]
   Trepte S., 2010, J MEDIA PSYCHOL-GER, V22, P171, DOI [10.1027/1864-1105/a000022, DOI 10.1027/1864-1105/A000022, https://doi.org/10.1027/1864-1105/a000022]
   Tsakiris M, 2010, NEUROPSYCHOLOGIA, V48, P703, DOI 10.1016/j.neuropsychologia.2009.09.034
   van der Land SF, 2015, HUM COMMUN RES, V41, P128, DOI 10.1111/hcre.12044
   Wadley G, 2015, HUM-COMPUT INTERACT, V30, P336, DOI 10.1080/07370024.2014.987346
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Watson R., 2013, INTEGRATING FACE VOI, P135, DOI 10.1007/978-1-4614-3585-3_7
   Wauck H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174059
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Zhang K., 2022, 24 INT ACM SIGACCESS, P1
NR 86
TC 5
Z9 5
U1 8
U2 31
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4794
EP 4804
DI 10.1109/TVCG.2023.3320240
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100040
PM 37812546
DA 2024-11-06
ER

PT J
AU Gorisse, G
   Wellenreiter, S
   Fleury, S
   Lécuyer, A
   Richir, S
   Christmann, O
AF Gorisse, Geoffrey
   Wellenreiter, Simon
   Fleury, Sylvain
   Lecuyer, Anatole
   Richir, Simon
   Christmann, Olivier
TI I am a Genius! Influence of Virtually Embodying Leonardo da Vinci on
   Creative Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Virtual Reality; Avatar; Embodiment; Body Ownership; Proteus Effect
ID SELF-REPRESENTATION; ILLUSORY OWNERSHIP; BODY OWNERSHIP; AVATAR;
   EMBODIMENT; SENSE; PERCEPTION; AGENCY; ONLINE; IDEAS
AB Virtual reality (VR) provides users with the ability to substitute their physical appearance by embodying virtual characters (avatars) using head-mounted displays and motion-capture technologies. Previous research demonstrated that the sense of embodiment toward an avatar can impact user behavior and cognition. In this paper, we present an experiment designed to investigate whether embodying a well-known creative genius could enhance participants' creative performance. Following a preliminary online survey (N = 157) to select a famous character suited to the purpose of this study, we developed a VR application allowing participants to embody Leonardo da Vinci or a self-avatar. Self-avatars were approximately matched with participants in terms of skin tone and morphology. 40 participants took part in three tasks seamlessly integrated in a virtual workshop. The first task was based on a Guilford's Alternate Uses test (GAU) to assess participants' divergent abilities in terms of fluency and originality. The second task was based on a Remote Associates Test (RAT) to evaluate convergent abilities. Lastly, the third task consisted in designing potential alternative uses of an object displayed in the virtual environment using a 3D sketching tool. Participants embodying Leonardo da Vinci demonstrated significantly higher divergent thinking abilities, with a substantial difference in fluency between the groups. Conversely, participants embodying a self-avatar performed significantly better in the convergent thinking task. Taken together, these results promote the use of our virtual embodiment approach, especially in applications where divergent creativity plays an important role, such as design and innovation.
C1 [Gorisse, Geoffrey; Wellenreiter, Simon; Fleury, Sylvain; Richir, Simon; Christmann, Olivier] Arts & Metiers Inst Technol, LAMPA, F-53810 Change, France.
   [Lecuyer, Anatole] Univ Rennes, Inria, CNRS, IRISA, F-35042 Rennes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   de Rennes
RP Gorisse, G (corresponding author), Arts & Metiers Inst Technol, LAMPA, F-53810 Change, France.
EM geoffrey.gorisse@ensam.eu; simon.wellenreiter@ensam.eu;
   sylvain.fleury@ensam.eu; anatole.lecuyer@inria.fr;
   simon.richir@ensam.eu; olivier.christmann@ensam.eu
RI Fleury, Sylvain/ABF-7924-2022
OI Richir, Simon/0000-0003-2075-6609; Gorisse, Geoffrey/0000-0003-1613-927X
CR Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   BARON RM, 1965, SCIENCE, V147, P140, DOI 10.1126/science.147.3654.140
   Basu A, 2019, ENVIRON BEHAV, V51, P1055, DOI 10.1177/0013916518774400
   Benedek M, 2013, PSYCHOL AESTHET CREA, V7, P341, DOI 10.1037/a0033644
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bowden EM, 2003, BEHAV RES METH INS C, V35, P634, DOI 10.3758/BF03195543
   Buisine S, 2020, BEHAV INFORM TECHNOL, V39, P594, DOI 10.1080/0144929X.2019.1605408
   Caspar EA, 2015, CONSCIOUS COGN, V33, P226, DOI 10.1016/j.concog.2015.01.007
   Cropley A, 2006, CREATIVITY RES J, V18, P391, DOI 10.1207/s15326934crj1803_13
   Cropley D.H., 2008, PSYCHOL AESTHET CREA, V2, P155, DOI [10.1037/1931-3896.2.3.155, DOI 10.1037/1931-3896.2.3.155, 10.1037=1931-3896.2.3.155]
   De Dreu CKW, 2012, PERS SOC PSYCHOL B, V38, P656, DOI 10.1177/0146167211435795
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Ehrsson HH, 2007, SCIENCE, V317, P1048, DOI 10.1126/science.1142175
   Fleury S, 2021, THINK SKILLS CREAT, V40, DOI 10.1016/j.tsc.2021.100828
   Fleury S, 2020, THINK SKILLS CREAT, V36, DOI 10.1016/j.tsc.2020.100661
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gorisse G, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00008
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Guegan J, 2016, COMPUT HUM BEHAV, V61, P165, DOI 10.1016/j.chb.2016.03.024
   GUILFORD JP, 1967, J CREATIVE BEHAV, V1, P3, DOI 10.1002/j.2162-6057.1967.tb00002.x
   Hass RW, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01343
   Hennessey B.A., 2011, ENCY CREATIVITY, V2nd, P253, DOI DOI 10.1016/B978-0-12-375038-9.00046-7
   Jeunet C, 2018, IEEE T VIS COMPUT GR, V24, P1486, DOI 10.1109/TVCG.2018.2794598
   JOHNSON RD, 1979, J PERS SOC PSYCHOL, V37, P1532, DOI 10.1037/0022-3514.37.9.1532
   Kaufman JC, 2012, PSYCHOL AESTHET CREA, V6, P298, DOI 10.1037/a0029751
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kocur Martin, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P193, DOI 10.1145/3410404.3414261
   Kocur M., 2020, ACM, P1, DOI DOI 10.1145/3385956.3418969
   Kocur M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445160
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Koulouris J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376661
   Latoschik M. E., 2017, VRST 17 P 23 ACM S V, P1, DOI DOI 10.1145/3139131.3139156
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Lin JHT, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.693543
   Mal D, 2023, IEEE T VIS COMPUT GR, V29, P2358, DOI 10.1109/TVCG.2023.3247089
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Mednick SA., 1971, Remote associates test
   Michalko M., 2006, Thinkertoys: A handbook of creative-thinking techniques
   Oppezzo M, 2014, J EXP PSYCHOL LEARN, V40, P1142, DOI 10.1037/a0036577
   Osimo SA, 2015, SCI REP-UK, V5, DOI 10.1038/srep13899
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   SHALLICE T, 1982, PHILOS T R SOC B, V298, P199, DOI 10.1098/rstb.1982.0082
   Slater M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46877-3
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater M, 2009, FRONT NEUROSCI-SWITZ, V3, P214, DOI 10.3389/neuro.01.029.2009
   Slater M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010564
   Slater M, 2008, FRONT HUM NEUROSCI, V2, DOI 10.3389/neuro.09.006.2008
   SNYDER M, 1977, J PERS SOC PSYCHOL, V35, P656, DOI 10.1037/0022-3514.35.9.656
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Torrance E. P., 1974, Torrance Tests of Creative Thinking (TTCT)
   Van Looy J, 2012, MEDIA PSYCHOL, V15, P197, DOI 10.1080/15213269.2012.674917
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Xia TS, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.695002
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yee N, 2009, MEDIA PSYCHOL, V12, P195, DOI 10.1080/15213260902849943
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
NR 63
TC 4
Z9 4
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4328
EP 4338
DI 10.1109/TVCG.2023.3320225
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100003
PM 37782593
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cheymol, A
   Fribourg, R
   Lécuyer, A
   Normand, JM
   Argelaguet, F
AF Cheymol, Antonin
   Fribourg, Rebecca
   Lecuyer, Anatole
   Normand, Jean-Marie
   Argelaguet, Ferran
TI Beyond my Real Body: Characterization, Impacts, Applications and
   Perspectives of "Dissimilar" Avatars in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Virtual Reality; HCI; Avatar
ID SELF; EMBODIMENT; HAND; SENSE; PERFORMANCE; APPEARANCE; OWNERSHIP;
   AGENCY
AB In virtual reality, the avatar - the user's digital representation - is an important element which can drastically influence the immersive experience. In this paper, we especially focus on the use of "dissimilar" avatars i.e., avatars diverging from the real appearance of the user, whether they preserve an anthropomorphic aspect or not. Previous studies reported that dissimilar avatars can positively impact the user experience, in terms for example of interaction, perception or behaviour. However, given the sparsity and multi-disciplinary character of research related to dissimilar avatars, it tends to lack common understanding and methodology, hampering the establishment of novel knowledge on this topic. In this paper, we propose to address these limitations by discussing: (i) a methodology for dissimilar avatars characterization, (ii) their impacts on the user experience, (iii) their different fields of application, and finally, (iv) future research direction on this topic. Taken together, we believe that this paper can support future research related to dissimilar avatars, and help designers of VR applications to leverage dissimilar avatars appropriately.
C1 [Cheymol, Antonin; Lecuyer, Anatole; Argelaguet, Ferran] Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
   [Fribourg, Rebecca; Normand, Jean-Marie] Nantes Univ, Ecole Cent Nantes, LS2N PACCE, UMR 6004, F-44000 Nantes, France.
   [Lecuyer, Anatole] AAU CRENAU, UMR 1563, F-44000 Nantes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Inria; Nantes Universite; Ecole Centrale de Nantes; Centre
   National de la Recherche Scientifique (CNRS); CNRS - Institute for
   Humanities & Social Sciences (INSHS)
RP Cheymol, A (corresponding author), Univ Rennes, Inria, CNRS, IRISA, Rennes, France.
EM antonin.cheymol@inria.fr; rebecca.fribourg@ec-nantes.fr;
   anatole.lecuyer@inria.fr; jean-marie.normand@ec-nantes.fr;
   ferran.argelaguet@inria.fr
OI Normand, Jean-Marie/0000-0003-0557-4356
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Adam H, 2012, J EXP SOC PSYCHOL, V48, P918, DOI 10.1016/j.jesp.2012.02.008
   Ahn SJG, 2016, J COMPUT-MEDIAT COMM, V21, P399, DOI 10.1111/jcc4.12173
   Alkemade R, 2017, INT J HUM-COMPUT INT, V33, P882, DOI 10.1080/10447318.2017.1296074
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Aymerich-Franch L, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00944
   Baker S., 2021, P CHI C HUM FACT COM, P1
   Ballendat Till, 2010, ACM INT C INT TABL S, P121, DOI DOI 10.1145/1936652.1936676
   Baloup M., 2021, P 27 ACM S VIRT REAL, P1
   Ban RG, 2022, INT SYM MIX AUGMENT, P748, DOI 10.1109/ISMAR55827.2022.00093
   Banakou D, 2016, FRONT HUM NEUROSCI, V10, DOI 10.3389/fnhum.2016.00601
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bernal Guillermo, 2017, P 2017 CHI C HUM FAC, P2395, DOI DOI 10.1145/3027063.3053207
   Bovet S, 2018, IEEE T VIS COMPUT GR, V24, P1428, DOI 10.1109/TVCG.2018.2794658
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Buetler KA, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.787487
   Busselle R.W., 2000, MASS COMMUN SOC, V3, P249, DOI [DOI 10.1207/S15327825MCS0323_05, DOI 10.1207/S15327825MCS0323_]
   Chatain Julia, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P374, DOI 10.1145/3410404.3414260
   Cheymol A., 2022, IEEE INT S MIXED AUG
   Christou C, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON GAMES AND VIRTUAL WORLDS FOR SERIOUS APPLICATIONS (VS-GAMES)
   Clark O. J., 2020, arXiv
   Cole J, 2009, DISABIL REHABIL, V31, P846, DOI 10.1080/09638280802355197
   Czub M, 2021, CYBERPSYCHOLOGY, V15, DOI 10.5817/CP2021-3-10
   Eden J, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28725-7
   Egeberg MCS, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927940
   Faleel SAM, 2021, IEEE T VIS COMPUT GR, V27, P4215, DOI 10.1109/TVCG.2021.3106493
   Fang Cathy Mengying, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1109, DOI 10.1145/3472749.3474810
   Fiedler M. L., 2023, IEEE C VIRTUAL REALI, P1
   Fox J, 2013, COMPUT HUM BEHAV, V29, P930, DOI 10.1016/j.chb.2012.12.027
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fukuoka M., 2023, IEEE Transactions on Visualization and Computer Graphics
   Galinsky AD, 2000, J PERS SOC PSYCHOL, V78, P708, DOI 10.1037//0022-3514.78.4.708
   Garau M., 2003, IMPACT AVATAR FIDELI
   Glowacki DR, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12637-z
   Goffman E., 2002, The Presentation of Self in Everyday Life. 1959, P259
   Guegan J, 2016, COMPUT HUM BEHAV, V61, P165, DOI 10.1016/j.chb.2016.03.024
   Guy M., 2022, ICAT EGVE
   Hapuarachchi H, 2022, IEEE INT SYMP M AU R, P772, DOI 10.1109/ISMAR-Adjunct57072.2022.00163
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Herrera F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204494
   Hoyet L, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00027
   Inoue K, 2017, CONSCIOUS COGN, V48, P246, DOI 10.1016/j.concog.2016.12.003
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jingjing Zhang, 2022, 2022 1st IEEE International Conference on Cognitive Aspects of Virtual Reality (CVR), P000017, DOI 10.1109/CVR55417.2022.9967571
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Joy T, 2022, VIRTUAL REAL-LONDON, V26, P615, DOI 10.1007/s10055-021-00511-8
   Kadri A., 2007, IEEE S 3D USER INTER
   Kammerlander RK, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P402, DOI 10.1109/VR50410.2021.00063
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kocur M., 2021, PROC CHI C HUMAN FAC, P1
   Kocur M., 2023, PROC CHI C HUMAN FAC
   Kodaka K, 2022, I-PERCEPTION, V13, DOI 10.1177/20416695221137731
   Krekhov A, 2019, CHI PLAY'19: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P439, DOI 10.1145/3311350.3347172
   Kwon E, 2009, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2009.5336463
   Laha B, 2016, PRESENCE-VIRTUAL AUG, V25, P129, DOI 10.1162/PRES_a_00251
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Lee S., 2022, CHI C HUMAN FACTORS, P1
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Lin H, 2014, COMPUT HUM BEHAV, V34, P213, DOI 10.1016/j.chb.2013.10.005
   Lin JH, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.974652
   Lin Lorraine., 2016, Proceedings of the ACM Symposium on Applied Perception, P69, DOI DOI 10.1145/2931002.2931006
   Lopez S., 2019, PROC CHI C HUMAN FAC, P1
   Lugrin JL, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P17, DOI 10.1109/VR.2018.8446229
   Lugrin JL, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P315, DOI 10.1145/2993369.2996313
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P229, DOI 10.1109/VR.2015.7223379
   Mal D., 2023, IEEE Transactions on Visualization and Computer Graphics
   Mal D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P779, DOI 10.1109/VRW55335.2022.00245
   Martini M, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00438
   Matamala-Gomez M., 2018, Journal of Pain, V12
   McIntosh Jess, 2020, P 33 ANN ACM S US IN, P709, DOI DOI 10.1145/3379337.3415832
   Mejia-Puig L, 2023, J INTERIOR DES, V48, P29, DOI 10.1111/joid.12234
   Mercier-Ganady J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P33, DOI 10.1109/VR.2014.6802047
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morie J F., 2008, P INT C ADV COMP ENT, P365
   Newport R, 2015, I-PERCEPTION, V6, DOI 10.1177/2041669515599310
   Norman D. A., 1999, Interactions, V6, P38, DOI 10.1145/301153.301168
   Norman Donald A., 2008, Interactions, V15, P18, DOI 10.1145/1409040.1409044
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Nowak KL, 2018, REV COMMUN RES, V6, P30, DOI 10.12840/issn.2255-4165.2018.06.01.015
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Ogawa N, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875246
   Otono R., 2023, IEEE C VIRT REAL 3D
   Oyanagi A, 2019, ICIGP 2019: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING / 2019 5TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY, P145, DOI 10.1145/3313950.3313976
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pei SY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501898
   Penaloza CI, 2018, IEEE SYS MAN CYBERN, P1011, DOI 10.1109/SMC.2018.00180
   Piryankova IV, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0103428
   Porras-Garcia B, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00956
   Pouke M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.655744
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Prachyabrued M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P19, DOI 10.1109/3DUI.2014.6798835
   Resnik L., 2011, Journal of Rehabilitation Research & Development, V48
   Rosa N, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3341225
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Rubo M, 2019, CONSCIOUS COGN, V73, DOI 10.1016/j.concog.2019.05.006
   Schjerlund J., 2021, P CHI C HUM FACT COM, P1
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Seinfeld S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19987-7
   Seinfeld S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79255-5
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Skarbez R., 2016, PhD thesis, DOI 10.17615/2mg3-gh93
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   STEELE CM, 1995, J PERS SOC PSYCHOL, V69, P797, DOI 10.1037/0022-3514.69.5.797
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tacikowski P, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71467-z
   Takizawa R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1175, DOI [10.1109/vr.2019.8798351, 10.1109/VR.2019.8798351]
   Tambone R, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07515
   Hoang TN, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P253, DOI 10.1145/3196709.3196724
   Tiggemann M, 2020, BODY IMAGE, V33, P175, DOI 10.1016/j.bodyim.2020.03.002
   Tosi G, 2020, EXP BRAIN RES, V238, P2125, DOI 10.1007/s00221-020-05874-z
   Tran A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188683
   Tseng WJ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517728
   Van Veldhuizen M, 2021, IEEE ACCESS, V9, P17572, DOI 10.1109/ACCESS.2021.3050881
   Vatsal V, 2018, IEEE INT CONF ROBOT, P5489
   Venkatakrishnan R., 2023, IEEE Transactions on Visualization and Computer Graphics
   Wen W, 2022, NAT REV PSYCHOL, V1, P211, DOI 10.1038/s44159-022-00030-6
   Wick MR, 2020, INT J EAT DISORDER, V53, P864, DOI 10.1002/eat.23263
   Wolf E., 2022, Frontiers in Virtual Reality, P187
   Won Andrea Stevenson., 2015, Emerging Trends in the Social and Behavioral Sciences: An Interdisciplinary, Searchable, and Linkable Resource, P1
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Yoon J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION EXTENDED ABSTRACTS (CHI PLAY 2018), P309, DOI 10.1145/3270316.3273043
   Yuan Y, 2010, P IEEE VIRT REAL ANN, P95, DOI 10.1109/VR.2010.5444807
   Zell E, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818126
   Zhang K., 2022, P 24 INT ACM SIGACCE
   Zhang Y, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1151, DOI 10.1145/3332165.3347869
NR 128
TC 5
Z9 5
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4426
EP 4437
DI 10.1109/TVCG.2023.3320209
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100010
PM 37782594
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Fourrier, N
   Moreau, G
   Benaouicha, M
   Norm, JM
AF Fourrier, Nicolas
   Moreau, Guillaume
   Benaouicha, Mustapha
   Norm, Jean-Marie
TI Handwriting for Efficient Text Entry in Industrial VR Applications:
   Influence of Board Orientation and Sensory Feedback on Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Keyboards; Training; Handwriting recognition; Error analysis; Usability;
   Task analysis; Speech recognition; Virtual reality; handwriting; text
   entry; industry
AB Text entry in Virtual Reality (VR) is becoming an increasingly important task as the availability of hardware increases and the range of VR applications widens. This is especially true for VR industrial applications where users need to input data frequently. Large-scale industrial adoption of VR is still hampered by the productivity gap between entering data via a physical keyboard and VR data entry methods. Data entry needs to be efficient, easy-to-use and to learn and not frustrating. In this paper, we present a new data entry method based on handwriting recognition (HWR). Users can input text by simply writing on a virtual surface. We conduct a user study to determine the best writing conditions when it comes to surface orientation and sensory feedback. This feedback consists of visual, haptic, and auditory cues. We find that using a slanted board with sensory feedback is best to maximize writing speeds and minimize physical demand. We also evaluate the performance of our method in terms of text entry speed, error rate, usability and workload. The results show that handwriting in VR has high entry speed, usability with little training compared to other controller-based virtual text entry techniques. The system could be further improved by reducing high error rates through the use of more efficient handwriting recognition tools. In fact, the total error rate is 9.28% in the best condition. After 40 phrases of training, participants reach an average of 14.5 WPM, while a group with high VR familiarity reach 16.16 WPM after the same training. The highest observed textual data entry speed is 21.11 WPM.
C1 [Fourrier, Nicolas; Benaouicha, Mustapha] Segula Technol Naval & Energy Engn Res & Innovat U, Rueil Malmaison, France.
   [Fourrier, Nicolas] Ecole Cent Nantes, AAU CRENAU, UMR 1563, Nantes, France.
   [Fourrier, Nicolas] LS2N PACCE, UMR 6004, Nantes, France.
   [Moreau, Guillaume] STICC, IMT Atlantique Lab, UMR 6285, Brest, France.
   [Benaouicha, Mustapha] Univ Caen Normandy, Cherbourg Univ, Lab Appl Sci LUSAC, Caen, France.
   [Norm, Jean-Marie] Nantes Univ, Ecole Cent Nantes, AAU CRENAU, UMR 1563, F-44000 Nantes, France.
   [Norm, Jean-Marie] LS2N PACCE, UMR 6004, F-44000 Nantes, France.
C3 Nantes Universite; Ecole Centrale de Nantes; Centre National de la
   Recherche Scientifique (CNRS); CNRS - Institute for Humanities & Social
   Sciences (INSHS); Universite de Bretagne Occidentale; Universite de Caen
   Normandie; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Humanities & Social Sciences (INSHS); Nantes Universite;
   Ecole Centrale de Nantes
RP Fourrier, N (corresponding author), Segula Technol Naval & Energy Engn Res & Innovat U, Rueil Malmaison, France.; Fourrier, N (corresponding author), Ecole Cent Nantes, AAU CRENAU, UMR 1563, Nantes, France.; Fourrier, N (corresponding author), LS2N PACCE, UMR 6004, Nantes, France.
EM nicolas.fourrier@segula.fr; guillaume.moreau@imt-atlantique.fr;
   mustapha.benaouicha@segula.fr; jean-marie.normand@ec-nantes.fr
RI BENAOUICHA, Mustapha/AAA-2236-2019; Moreau, Guillaume/I-3153-2013
OI BENAOUICHA, Mustapha/0000-0002-5332-2439; Moreau,
   Guillaume/0000-0003-2215-1865; Fourrier, Nicolas/0009-0000-7349-9752;
   Normand, Jean-Marie/0000-0003-0557-4356
CR Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Badamasi AA, 2022, ENG CONSTR ARCHIT MA, V29, P1307, DOI 10.1108/ECAM-09-2020-0685
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Boletsis Costas., 2019, INT J VIRTUAL REALIT, V19, P2, DOI DOI 10.20870/IJVR.2019.19.3.2917
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen SB, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312762
   Dash S., 2017, BlueTap - The Ultimate Virtual-Reality (VR) Keyboard
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Elmgren Rasmus., 2017, Handwriting in VR as a Text Input Method
   Erickson A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P434, DOI [10.1109/VR46266.2020.1580695145399, 10.1109/VR46266.2020.00-40]
   Fu ZJ, 2019, IEEE T MOBILE COMPUT, V18, P473, DOI 10.1109/TMC.2018.2831709
   github, WritePadSDK
   González G, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P109, DOI 10.1007/978-1-84882-352-5_11
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P159, DOI 10.1109/VR.2018.8446059
   Han YS, 2019, INT J COMPUT INTEG M, V32, P658, DOI 10.1080/0951192X.2019.1599440
   HART S G, 1988, P139
   Hsu CH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P635, DOI 10.1109/VR50410.2021.00089
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kim MJ, 2013, J INF TECHNOL CONSTR, V18, P279
   Knierim P., 2018, P 2018 CHI C HUMAN F, P1
   Kristensson Per Ola, 2012, P 2012 ACM INT C INT, P29, DOI [DOI 10.1145/2166966.2166972, 10.1145/2166966.2166972]
   Law T, 2020, IEEE INT CONF INF VI, P751, DOI 10.1109/IV51561.2020.00133
   Leng JY, 2022, IEEE T VIS COMPUT GR, V28, P3662, DOI 10.1109/TVCG.2022.3203101
   Lu XS, 2020, INT SYM MIX AUGMENT, P344, DOI 10.1109/ISMAR50242.2020.00061
   MacKenzie I. S., 2007, The Morgan Kaufmann series in interactive technologies
   MacKenzie I. S., 2003, NEW HORIZONS, P2
   Morais D., 2017, P COMPIT 2017, P12
   Nooruddin, 2020, IEEE SYS MAN CYBERN, P744, DOI [10.1109/smc42975.2020.9283348, 10.1109/SMC42975.2020.9283348]
   Outerelo R., 2020, Meta-review of text input approaches within VR - A study on the platform's viability as a productivity workspace
   Pick S, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P109, DOI 10.1109/3DUI.2016.7460039
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Rajanna V, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204541
   SeokRyul Kim, 2006, Computer-Aided Design and Applications, V3, P547
   Shen JX, 2022, INT SYM MIX AUGMENT, P702, DOI 10.1109/ISMAR55827.2022.00088
   Song ZM, 2022, INT SYM MIX AUGMENT, P864, DOI 10.1109/ISMAR55827.2022.00105
   Soukoreff R. W., 2003, P SIGCHI C HUM FACT, P113, DOI DOI 10.1145/642611.642632
   Stark R, 2010, CIRP ANN-MANUF TECHN, V59, P179, DOI 10.1016/j.cirp.2010.03.102
   Summers J., 2003, Australian Occupational Therapy Journal, V50, P148, DOI [DOI 10.1046/J.1440-1630.2003.00310.X, 10.1046/j.14401630.2003.00310.x, DOI 10.1046/J.14401630.2003.00310.X]
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Vertanen Keith, 2009, Ph.D. Dissertation
   Whyte J, 2000, AUTOMAT CONSTR, V10, P43, DOI 10.1016/S0926-5805(99)00012-6
   Xu WG, 2019, IEEE T VIS COMPUT GR, V25, P1991, DOI 10.1109/TVCG.2019.2898736
   Yanagihara N, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P170, DOI 10.1145/3267782.3274687
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yong Tang, 2010, Proceedings of the Third International Conference on Information and Computing Science (ICIC 2010), P265, DOI 10.1109/ICIC.2010.338
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Yu DF, 2018, IEEE T VIS COMPUT GR, V24, P2927, DOI 10.1109/TVCG.2018.2868581
   Zhang ZG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P530, DOI [10.1109/ICPADS53394.2021.00072, 10.1109/VRW52623.2021.00147]
NR 52
TC 2
Z9 2
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4438
EP 4448
DI 10.1109/TVCG.2023.3320215
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100011
PM 37782596
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Fischer, M
   Rosenberg, J
   Leuze, C
   Hargreaves, B
   Daniel, B
AF Fischer, Marc
   Rosenberg, Jarrett
   Leuze, Christoph
   Hargreaves, Brian
   Daniel, Bruce
TI The Impact of Occlusion on Depth Perception at Arm's Length
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Extended reality; AR; augmented reality; mixed reality; hybrid-AR;
   spatial AR; depth perception; arms-length interaction; near-field
   distance; perceptual accuracy; perceptual matching; egocentric depth;
   alignment; depth estimation; visualization techniques; occlusion;
   accommodation; vergence; HoloLens; optical-see-through HMD; x-ray vision
ID AUGMENTED REALITY
AB This paper investigates the accuracy of Augmented Reality (AR) technologies, particularly commercially available optical see-through displays, in depicting virtual content inside the human body for surgical planning. Their inherent limitations result in inaccuracies in perceived object positioning. We examine how occlusion, specifically with opaque surfaces, affects perceived depth of virtual objects at arm's length working distances. A custom apparatus with a half-silvered mirror was developed, providing accurate depth cues excluding occlusion, differing from commercial displays. We carried out a study, contrasting our apparatus with a HoloLens 2, involving a depth estimation task under varied surface complexities and illuminations. In addition, we explored the effects of creating a virtual "hole" in the surface. Subjects' depth estimation accuracy and confidence were a ssessed. Results showed more depth estimation variation with HoloLens and significant depth error beneath complex occluding surfaces. However, creating a virtual hole significantly reduced depth errors and increased subjects' confidence, irrespective of accuracy enhancement. These findings have important implications for the design and use of mixed-reality technologies in surgical applications, and industrial applications such as using virtual content to guide maintenance or repair of components hidden beneath the opaque outer surface of equipment. A free copy of this paper and all supplemental materials are available at https://bit.ly/3YbkwjU.
C1 [Fischer, Marc; Hargreaves, Brian; Daniel, Bruce] Stanford Univ, Radiol, Stanford, CA 94305 USA.
   [Rosenberg, Jarrett; Leuze, Christoph] Stanford Univ, Stanford, CA USA.
C3 Stanford University; Stanford University
RP Fischer, M (corresponding author), Stanford Univ, Radiol, Stanford, CA 94305 USA.
EM mjf1@stanford.edu; jarrettr@stanford.edu; cleuze@stanford.edu;
   bah@stanford.edu; bdaniel@stanford.edu
RI , Brian Hargreaves/KRQ-6309-2024
OI Daniel, Bruce/0000-0003-0475-5892
CR Avveduto G, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139150
   BAJURA M, 1992, COMP GRAPH, V26, P203, DOI 10.1145/142920.134061
   Bichlmeier C., 2007, P 2007 6 IEEE ACM IN, P1, DOI [10.1109/ISMAR.2007.45388372, DOI 10.1109/ISMAR.2007.45388372]
   Bimber O., 2002, Occlusion shadows: using projected light to generate realistic occlusion effects for view-dependent optical see-through displays, P186, DOI [10.1109/ISMAR.2002.1115088, DOI 10.1109/ISMAR.2002.1115088]
   Curtis K. R., 2022, SPIE AR VR MR IND TA, V11932, DOI [10.1117/12.26324952, DOI 10.1117/12.26324952]
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Doughty M, 2022, J IMAGING, V8, DOI 10.3390/jimaging8020033
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Ellis SR, 1998, HUM FACTORS, V40, P415, DOI 10.1518/001872098779591278
   Fischer M, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P45, DOI 10.1109/ISMAR-Adjunct51615.2020.00027
   HARVEY AC, 1976, ECONOMETRICA, V44, P461, DOI 10.2307/1913974
   Hilliges O., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '12, P2421
   Johnson L, 2004, P SOC PHOTO-OPT INS, V5372, P263, DOI 10.1117/12.535138
   Kalia M., 2016, Interactive depth of focus for improved depth perception, P221, DOI [10.1007/978-3-319-43775-0_20, DOI 10.1007/978-3-319-43775-0_20]
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Livingston M. A., 2013, for Augmented Reality, P67, DOI [DOI 10.1007/978-1-4614-4205-9_41, 10.1007/978-1-4614-4205-9_4, DOI 10.1007/978-1-4614-4205-9_4]
   Martin-Gomez A, 2022, IEEE T VIS COMPUT GR, V28, P4156, DOI 10.1109/TVCG.2021.3079849
   Martin-Gomez A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P735, DOI [10.1109/vr.2019.8798135, 10.1109/VR.2019.8798135]
   Microsoft Corp, Comfort in mixed reality design
   Otsuki Mai, 2015, P 25 INT C ART REAL, P45, DOI [10.2312/egve.20151309, DOI 10.2312/EGVE.20151309]
   Perkins SL, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P269, DOI 10.1109/ISMAR-Adjunct.2017.92
   Robinett W., 1991, Whole Earth Review Magazine, P1
   Sielhorst T, 2006, LECT NOTES COMPUT SC, V4190, P364
   Singh G, 2020, IEEE T VIS COMPUT GR, V26, P1385, DOI 10.1109/TVCG.2018.2869729
   State A., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P364, DOI 10.1109/VISUAL.1994.346295
   State A, 2003, STUD HEALTH TECHNOL, V94, P325
   State A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P439, DOI 10.1145/237170.237283
   Swan JE, 2015, IEEE T VIS COMPUT GR, V21, P1289, DOI 10.1109/TVCG.2015.2459895
   West B. T., 2015, Linear Mixed Models: A Practical Guide Using Statistical Software, V2nd, P5
NR 30
TC 1
Z9 1
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4494
EP 4502
DI 10.1109/TVCG.2023.3320239
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100015
PM 37782607
DA 2024-11-06
ER

PT J
AU Bozgeyikli, L
   Bozgeyikli, E
   Schnell, C
   Clark, J
AF Bozgeyikli, Lal Lila
   Bozgeyikli, Evren
   Schnell, Christopher
   Clark, Jaclynn
TI Exploring Horizontally Flipped Interaction in Virtual Reality for
   Improving Spatial Ability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Cognition; interaction styles; usability testing; virtual reality
ID EVENT-RELATED DESYNCHRONIZATION; MENTAL ROTATION; CORTICAL ACTIVATION;
   EEG; THETA; SYNCHRONIZATION; VISUALIZATION; METAANALYSIS; RESEMBLANCE;
   PERFORMANCE
AB Virtual reality (VR) is a high-fidelity medium that can offer experiences that are close to real-life. Spatial ability plays an important role in human life, including academic achievement and advancement in work settings. Spatial ability is known to be improved by practicing relevant tasks. Mental rotation and spatial perception are among such tasks that improve spatial skills. In this research, we investigated a "mirror-reversed" interaction technique in a cup stacking task in VR and looked into its effects on spatial ability, brain activity regarding spatial processing and attention (measured with EEG), performance, and user experience in male participants. Participants stacked cups according to given patterns using direct manipulation with horizontally flipped controls, similar to looking in a mirror while performing object manipulation in real life. In a between-subjects user study, we compared this novel interaction with a baseline where the participants completed the same task with regular controls. Although there was no significant main effect of group on the mental rotation and perspective taking/spatial orientation tests scores, within-group analysis indicated a trend toward an improvement in the mirror-reversed group in spatial orientation, while both groups showed a trend toward improvement in mental rotation. Participants in both groups got better at the task over time (their task completion durations decreased). EEG data revealed significant theta band power increase in the mirror-reversed group whereas there was no difference in the alpha band power between the two groups. Our results are encouraging for exploring spatially challenging interactions in VR for spatial skills training. We share the implementation and user study results, and discuss the implications.
C1 [Bozgeyikli, Lal Lila; Bozgeyikli, Evren; Schnell, Christopher; Clark, Jaclynn] Univ Arizona, Sch Informat, Tucson, AZ 85721 USA.
C3 University of Arizona
RP Bozgeyikli, L (corresponding author), Univ Arizona, Sch Informat, Tucson, AZ 85721 USA.
EM rboz@arizona.edu; rboz@arizona.edu; cschnell4@arizona.edu;
   jaclarkent@arizona.edu
CR Anderson L., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P57, DOI 10.1145/769953.769960
   [Anonymous], Unity real-time development platform 3D, 2D VR & AR engine
   Bailey Shannon K. T., 2019, Proceedings of the 20th Congress of the International Ergonomics Association (IEA 2018), Advances in Intelligent Systems and Computing, P663, DOI [10.1007/978-3-319-96065-4_70, DOI 10.1007/978-3-319-96065-4_70]
   Bek J, 2010, J EXP PSYCHOL LEARN, V36, P646, DOI 10.1037/a0018281
   BERRY JW, 1966, INT J PSYCHOL, V1, P207, DOI 10.1080/00207596608247156
   Blade MF, 1955, PSYCHOL MONOGR-GEN A, V69, P1
   Bodner GM., 1997, CHEM ED, V2, P1, DOI [10.1007/s00897970138a, DOI 10.1007/S00897970138A]
   BRINKMANN EH, 1966, J APPL PSYCHOL, V50, P179, DOI 10.1037/h0023068
   Campbell DaceA., 1994, CRITIQUE VIRTUAL REA
   Casasanto D, 2010, LECT NOTES ARTIF INT, V6222, P335
   Chang JSK, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1239, DOI 10.1145/3064663.3064675
   Chang JSK, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P68, DOI 10.1145/3131277.3132171
   Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055
   Dan A, 2017, INT J PSYCHOPHYSIOL, V122, P75, DOI 10.1016/j.ijpsycho.2016.08.013
   DERAMBURE P, 1993, ELECTROEN CLIN NEURO, V89, P197, DOI 10.1016/0168-5597(93)90133-A
   Dnser A., 2006, P 7 ACM SIGCHI NZ CH, P125
   Ekstrom R.B., 1976, MANUAL KIT FACTOR RE, V102
   Fogarty J, 2018, J PROF ISS ENG ED PR, V144, DOI 10.1061/(ASCE)EI.1943-5541.0000349
   French J.W., 1951, The description of aptitude and achievement tests in terms of rotated factors
   Frick A, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00386
   Gevins A, 1997, CEREB CORTEX, V7, P374, DOI 10.1093/cercor/7.4.374
   Gevins A., 2003, Theoretical issues in ergonomics science, V4, P113, DOI DOI 10.1080/14639220210159717
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Guilford J.P., 1947, Printed Classification Tests. Vol. 5. Army Air Forces Aviation Psychology Program Research Reports, V5
   Hart MA, 2005, RES Q EXERCISE SPORT, V76, pA57
   Hausmann M, 2000, BEHAV NEUROSCI, V114, P1245, DOI 10.1037/0735-7044.114.6.1245
   Hegarty M, 2004, INTELLIGENCE, V32, P175, DOI 10.1016/j.intell.2003.12.001
   Hubbard R, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P398, DOI 10.1145/3027385.3027390
   Jhaver S, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3338243
   Jiang E., 2019, Practicing in Virtual Reality Improves Mental Rotation Ability: Lower Scorers Benefit More
   Kahana MJ, 1999, NATURE, V399, P781, DOI 10.1038/21645
   Kaufmann H., 2000, Education and Information Technologies, V5, P263, DOI 10.1023/A:1012049406877
   KERSHNER JR, 1974, PERCEPT MOTOR SKILL, V39, P1283, DOI 10.2466/pms.1974.39.3.1283
   Keskin M, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8120546
   Kimura D., 1967, Cortex, V3, P163, DOI [10.1016/S0010-9452(67)80010-8, DOI 10.1016/S0010-9452(67)80010-8]
   Klarkowski Madison, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3549519
   Klimesch W, 2005, EXP PSYCHOL, V52, P99, DOI 10.1027/1618-3169.52.2.99
   Klimesch W, 1996, NEUROREPORT, V7, P1235, DOI 10.1097/00001756-199605170-00002
   Klimesch W, 1999, BRAIN RES REV, V29, P169, DOI 10.1016/S0165-0173(98)00056-3
   Kober SE, 2012, INT J PSYCHOPHYSIOL, V83, P365, DOI 10.1016/j.ijpsycho.2011.12.003
   Kober SE, 2011, INT J PSYCHOPHYSIOL, V79, P347, DOI 10.1016/j.ijpsycho.2010.12.002
   Kozhevnikov Maria, 2008, Proceedings of the Human Factors and Ergonomics Society. 52nd Annual Meeting, P2132
   Krigolson OE, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00109
   Krokos E, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON COMPUTER AND AUTOMATION ENGINEERING (ICCAE 2018), P27, DOI 10.1145/3192975.3193023
   Lee EAL, 2014, COMPUT EDUC, V79, P49, DOI 10.1016/j.compedu.2014.07.010
   Leocani L, 1997, EVOKED POTENTIAL, V104, P199, DOI 10.1016/S0168-5597(96)96051-7
   LINN MC, 1985, CHILD DEV, V56, P1479, DOI 10.2307/1130467
   Lok B, 2003, P IEEE VIRT REAL ANN, P125, DOI 10.1109/VR.2003.1191130
   Maeda Y, 2013, EDUC PSYCHOL REV, V25, P69, DOI 10.1007/s10648-012-9215-x
   Marks J. W., 2021, Medical Definition of Working memory
   MCGEE MG, 1979, PSYCHOL BULL, V86, P889, DOI 10.1037/0033-2909.86.5.889
   Mind Monitor, About us
   Mohler J.L., 2001, WebNet Journal: Internet Technologies, Applications Issues, V3, P28
   Muse2, Brain Sensing Headband.
   NYBORG H, 1983, ADV BEHAV RES THER, V5, P89, DOI 10.1016/0146-6402(83)90019-X
   Oman Charles M, 2002, Spat Cogn Comput, V2, P355, DOI 10.1023/A:1015548105563
   PARK J, 1978, BEHAV GENET, V8, P43, DOI 10.1007/BF01067703
   Passig D, 2001, CYBERPSYCHOL BEHAV, V4, P681, DOI 10.1089/109493101753376623
   PETERSEN AC, 1976, DEV PSYCHOL, V12, P524, DOI 10.1037/0012-1649.12.6.524
   PFURTSCHELLER G, 1977, ELECTROEN CLIN NEURO, V42, P817, DOI 10.1016/0013-4694(77)90235-8
   PFURTSCHELLER G, 1989, ELECTROEN CLIN NEURO, V72, P250, DOI 10.1016/0013-4694(89)90250-2
   PFURTSCHELLER G, 1992, ELECTROEN CLIN NEURO, V83, P62, DOI 10.1016/0013-4694(92)90133-3
   Pfurtscheller G, 1999, CLIN NEUROPHYSIOL, V110, P1842, DOI 10.1016/S1388-2457(99)00141-8
   PFURTSCHELLER G, 1979, ELECTROEN CLIN NEURO, V46, P138, DOI 10.1016/0013-4694(79)90063-4
   Qualtrics XM, About us
   Raghupathy Phanidhar Bezawada, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P180, DOI 10.1007/978-3-642-24031-7_18
   Rana KD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107715
   Regian J. W., 1992, Journal of communication
   Rescher B, 1999, INT J PSYCHOPHYSIOL, V33, P209, DOI 10.1016/S0167-8760(99)00063-X
   Rizzo A.A., 1998, CyberPsychology and Behavior, V1, P113, DOI [10.1089/cpb.1998.1.113, DOI 10.1089/CPB.1998.1.113]
   Roca-González C, 2017, EURASIA J MATH SCI T, V13, P441, DOI 10.12973/eurasia.2017.00625a
   Sanchez-Ku ML, 2000, HUM FACTORS, V42, P512, DOI 10.1518/001872000779698169
   Schmierbach M, 2012, CYBERPSYCH BEH SOC N, V15, P364, DOI 10.1089/cyber.2012.0025
   Searle J. A., 2017, Wiley Interdisciplinary Reviews: Cognitive Science, V8, P1443
   STERMAN MB, 1994, INT J PSYCHOPHYSIOL, V16, P49, DOI 10.1016/0167-8760(94)90041-8
   TORO C, 1994, ELECTROEN CLIN NEURO, V93, P380, DOI 10.1016/0013-4694(94)00177-M
   Uttal DH, 2013, PSYCHOL BULL, V139, P352, DOI 10.1037/a0028446
   van Asselen M, 2006, NEUROPSYCHOLOGIA, V44, P1185, DOI 10.1016/j.neuropsychologia.2005.10.005
   VANDENBERG SG, 1978, PERCEPT MOTOR SKILL, V47, P599, DOI 10.2466/pms.1978.47.2.599
   VIVE, VR Headsets, Games, and Metaverse Life
   Wai J, 2009, J EDUC PSYCHOL, V101, P817, DOI 10.1037/a0016127
   WILLIAMS T, 1975, BEHAV GENET, V5, P405, DOI 10.1007/BF01073209
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 83
TC 0
Z9 0
U1 6
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4514
EP 4524
DI 10.1109/TVCG.2023.3320241
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100017
PM 37831578
DA 2024-11-06
ER

PT J
AU Shen, JX
   Dudley, J
   Kristensson, PO
AF Shen, Junxiao
   Dudley, John
   Kristensson, Per Ola
TI Fast and Robust Mid-Air Gesture Typing for AR Headsets using 3D
   Trajectory Decoding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Text Entry; Machine Learning; Augmented Reality
AB We present a fast mid-air gesture keyboard for head-mounted optical see-through augmented reality (OST AR) that supports users in articulating word patterns by merely moving their own physical index finger in relation to a virtual keyboard plane without a need to indirectly control a visual 2D cursor on a keyboard plane. To realize this, we introduce a novel decoding method that directly translates users' three-dimensional fingertip gestural trajectories into their intended text. We evaluate the efficacy of the system in three studies that investigate various design aspects, such as immediate efficacy, accelerated learning, and whether it is possible to maintain performance without providing visual feedback. We find that the new 3D trajectory decoding design results in significant improvements in entry rates while maintaining low error rates. In addition, we demonstrate that users can maintain their performance even without fingertip and gesture trace visualization.
C1 [Shen, Junxiao; Dudley, John; Kristensson, Per Ola] Univ Cambridge, Cambridge, England.
C3 University of Cambridge
RP Shen, JX (corresponding author), Univ Cambridge, Cambridge, England.
EM js2283@cam.ac.uk; jjd50@cam.ac.uk; pok21@cam.ac.uk
OI Shen, Junxiao/0000-0002-1552-4689; Kristensson, Per
   Ola/0000-0002-7139-871X
CR Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   Alsharif O., 2015, Long short term memory neural network for keyboard gesture decoding, P2076
   Bi XJ, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P137
   Biju Emil, 2020, P 28 INT C COMP LING, P999, DOI DOI 10.18653/V1/2020.COLING-MAIN.87
   Castellucci S. J., 2011, CHI EA 11
   Chan W, 2016, INT CONF ACOUST SPEE, P4960, DOI 10.1109/ICASSP.2016.7472621
   Dahlback N., 1993, Knowledge-Based Systems, V6, P258, DOI 10.1016/0950-7051(93)90017-N
   Dong LH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5884, DOI 10.1109/ICASSP.2018.8462506
   Dudley J., 2023, IEEE T VISUALIZATION
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Gordon M., 2016, WATCHWRITER TAP GEST, P3817
   Graves A., 2012, ARXIV
   Graves A., 2006, P ICML, P369
   Hu JH, 2022, IEEE INT SYMP M AU R, P640, DOI 10.1109/ISMAR-Adjunct57072.2022.00132
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Klimt B, 2004, LECT NOTES COMPUT SC, V3201, P217
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kristensson P., 2004, P 17 ANN ACM S USER, P43, DOI DOI 10.1145/1029632.1029640
   Kristensson P. O., 2021, P 2021 CHI C HUMAN F, P1
   Kristensson P.O., 2012, ETRA 12, P241, DOI DOI 10.1145/2168556.2168605
   Kristensson Per., 2007, Discrete and continuous shape writing for text entry and control
   Kristensson PO, 2023, PROCEEDINGS OF 2023 28TH ANNUAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2023, P607, DOI 10.1145/3581641.3584093
   Kristensson PO, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376525
   Kristensson PO, 2015, COMPUTER, V48, P84, DOI 10.1109/MC.2015.185
   Kristensson PO, 2009, AI MAG, V30, P85, DOI 10.1609/aimag.v30i4.2269
   Leiva L. A., 2021, WE SWIPE LARGE SCALE
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   Markussen A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1073, DOI 10.1145/2556288.2556964
   Mehra A, 2020, INT CONF ACOUST SPEE, P8174, DOI [10.1109/ICASSP40776.2020.9052978, 10.1109/icassp40776.2020.9052978]
   Reyal S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P679, DOI 10.1145/2702123.2702597
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686, DOI DOI 10.1145/3379337.3415816
   Shen JX, 2021, IEEE INT CONF AUTOMA
   Shen JX, 2022, INT SYM MIX AUGMENT, P702, DOI 10.1109/ISMAR55827.2022.00088
   Shen JX, 2022, IEEE T VIS COMPUT GR, V28, P3618, DOI 10.1109/TVCG.2022.3203004
   Shen JX, 2021, INT SYM MIX AUGMENT, P393, DOI 10.1109/ISMAR52148.2021.00056
   Vertanen K, 2021, NAT LANG ENG, V27, P1, DOI 10.1017/S1351324919000548
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yi X., 2023, P ACM INTERACTIVE MO, V7, P1
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Zhai S., 2012, COMMUNICATIONS ACM C, V55
   Zhai S., 2003, Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 2003), P97, DOI DOI 10.1145/642611.642630
   Zhai S., 2009, CHI EA '09 Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, P2667, DOI [10.1145/1520340.1520380, DOI 10.1145/1520340.1520380]
   Zhai SM, 2012, COMMUN ACM, V55, P91, DOI 10.1145/2330667.2330689
NR 44
TC 6
Z9 6
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4622
EP 4632
DI 10.1109/TVCG.2023.3320218
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100027
PM 37782613
DA 2024-11-06
ER

PT J
AU Luong, T
   Cheng, YF
   Mobus, M
   Fender, A
   Holz, C
AF Luong, Tiffany
   Cheng, Yi Fei
   Mobus, Max
   Fender, Andreas
   Holz, Christian
TI Controllers or Bare Hands? A Controlled Evaluation of Input Techniques
   on Interaction Performance and Exertion in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Virtual Reality; Input Modality; Controllers; Hand Tracking; Raycast;
   Touch; Physical Exertion; Performance; Behavior
ID SELECTION; DESIGN
AB Virtual Reality (VR) systems have traditionally required users to operate the user interface with controllers in mid-air. More recent VR systems, however, integrate cameras to track the headset's position inside the environment as well as the user's hands when possible. This allows users to directly interact with virtual content in mid-air just by reaching out, thus discarding the need for hand-held physical controllers. However, it is unclear which of these two modalities-controller-based or free-hand interaction-is more suitable for efficient input, accurate interaction, and long-term use under reliable tracking conditions. While interacting with hand-held controllers introduces weight, it also requires less finger movement to invoke actions (e.g., pressing a button) and allows users to hold on to a physical object during virtual interaction.In this paper, we investigate the effect of VR input modality (controller vs. free-hand interaction) on physical exertion, agency, task performance, and motor behavior across two mid-air interaction techniques (touch, raycast) and tasks (selection, trajectory-tracing). Participants reported less physical exertion, felt more in control, and were faster and more accurate when using VR controllers compared to free-hand interaction in the raycast setting. Regarding personal preference, participants chose VR controllers for raycast but free-hand interaction for mid-air touch. Our correlation analysis revealed that participants' physical exertion increased with selection speed, quantity of arm motion, variation in motion speed, and bad postures, following ergonomics metrics such as consumed endurance and rapid upper limb assessment. We also found a negative correlation between physical exertion and the participant's sense of agency, and between physical exertion and task accuracy.
C1 [Luong, Tiffany; Cheng, Yi Fei; Mobus, Max; Fender, Andreas; Holz, Christian] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Luong, T; Holz, C (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
EM tiffany.luong@inf.ethz.ch; yifei.cheng@inf.ethz.ch;
   max.mobus@inf.ethz.ch; andreas.fender@inf.ethz.ch;
   christian.holz@inf.ethz.ch
RI Cheng, yifei/JAX-5063-2023; Holz, Christian/AAV-4925-2020
OI Moebus, Max/0000-0003-3414-7142; Holz, Christian/0000-0001-9655-9519
CR Abdlkarim D., 2022, METHODOLOGICAL FRAME, V2
   Adkins A, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486582
   [Anonymous], 2000, I. ISO. 9241-9 ergonomic requirements for office work with visual display terminals (vdts)-part 9: Requirements for non-keyboard input devices (fdis-final draft international standard)
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Bansal A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40870-6
   Batmaz AU, 2022, IEEE T VIS COMPUT GR, V28, P3939, DOI 10.1109/TVCG.2022.3203105
   Batmaz AU, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364249
   Belo J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445349
   Borg G., 1998, Borgs Perceived Exertion and Pain Scales, DOI DOI 10.1249/00005768-199809000-00018
   Bowman D., 2001, USING PINCH GLOVES T
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Caggianese Giuseppe, 2019, INTELLIGENT INTERACT, P24, DOI [DOI 10.1007/978-3-319-92231-73, DOI 10.1007/978-3-319-92231, DOI 10.1007/978-3-319-92231-7_3]
   Casiez G., 2012, P SIGCHI C HUM FACT, P2527, DOI DOI 10.1145/2207676.2208639
   Cheema N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376701
   Chen JL, 2023, COMPANION OF THE ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI 2023, P644, DOI 10.1145/3568294.3580165
   Cheng YF, 2022, INT SYM MIX AUGMENT, P150, DOI 10.1109/ISMAR55827.2022.00029
   Choi I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174228
   Craig C., 2017, J. Am. Coll. Health, V65, P492
   Fahmi F., 2020, IOP Conference Series: Materials Science and Engineering, V851, DOI 10.1088/1757-899X/851/1/012024
   Feiner S., 1993, Sixth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P145, DOI 10.1145/168642.168657
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Forlines C, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P647
   Gabbard JL, 1999, IEEE COMPUT GRAPH, V19, P51, DOI 10.1109/38.799740
   Galais T, 2019, IHM19:ANNEXES DES ACTES DE LA 31E CONFERENCE FRANCOPHONE SUR I'INTERACTION HOMME-MACHINE, DOI 10.1145/3366551.3370342
   Gusai E, 2017, LECT NOTES COMPUT SC, V10590, P290, DOI 10.1007/978-3-319-70742-6_27
   Habibi P, 2021, INT J HUM-COMPUT ST, V149, DOI 10.1016/j.ijhcs.2021.102600
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hoddes E., 1972, Enzyklopadie der Schlafmedizin, V1184
   Jang SJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3328, DOI 10.1145/3025453.3025523
   Jankowski Jacek., 2013, EUROGRAPHICS 2013 ST
   Johansson RS, 2001, J NEUROSCI, V21, P6917, DOI 10.1523/JNEUROSCI.21-17-06917.2001
   Johnson Cheryl I., 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P1294, DOI 10.1177/1071181322661371
   Kangas J, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6010006
   Kari M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580677
   Kelly Jonathan W., 2022, Frontiers in Virtual Reality, V3, P27
   Khundam C, 2021, INFORMATICS-BASEL, V8, DOI 10.3390/informatics8030060
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Lee JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186524
   Li JL, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P120, DOI 10.1145/3267782.3267797
   Li Y.X., 2019, VRIH, V56, P84, DOI DOI 10.3724/SP.J.2096-5796.2018.0006
   Lin L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P510, DOI 10.1109/vr.2019.8797787
   Liu L, 2012, IEEE T VIS COMPUT GR, V18, P1017, DOI 10.1109/TVCG.2012.31
   Masurovsky A, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040091
   Mayer S., 2018, P 2018 CHI C HUMAN F, P1
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   McMahan RP, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P11, DOI 10.1109/3DUI.2010.5444727
   Meier M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P519, DOI 10.1109/VR50410.2021.00076
   Mendes D, 2019, COMPUT GRAPH FORUM, V38, P21, DOI 10.1111/cgf.13390
   Mey J., 2006, Encyclopedia of Language & Linguistics, VSecond, P49, DOI [10.1016/B0-08-044854-2/00394-1, DOI 10.1016/B0-08-044854-2/00394-1]
   Mottelson A, 2021, VACCINE, V39, P6746, DOI 10.1016/j.vaccine.2021.10.004
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P759, DOI 10.1145/3126594.3126605
   Navarro D, 2019, HUCAPP: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 2: HUCAPP, P103, DOI 10.5220/0007362401030110
   Optitrack, about us
   Oudah M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6080073
   Pei SY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501898
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Rantamaa HR, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13042251
   Rutkowski S, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18031297
   Schwind V, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P477, DOI 10.1145/3242671.3242675
   Streli P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581468
   Streli P, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501878
   Teather R. J., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P87, DOI 10.1109/3DUI.2011.5759222
   Vandeweerdt C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08120-4
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Zhou XZ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11136146
NR 73
TC 3
Z9 3
U1 7
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4633
EP 4643
DI 10.1109/TVCG.2023.3320211
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100028
PM 37788200
DA 2024-11-06
ER

PT J
AU Khan, T
   Zhu, TS
   Downes, T
   Cheng, L
   Kass, NM
   Andrews, EG
   Biehl, JT
AF Khan, Talha
   Zhu, Toby S.
   Downes, Thomas
   Cheng, Lucille
   Kass, Nicolas M.
   Andrews, Edward G.
   Biehl, Jacob T.
TI Understanding Effects of Visual Feedback Delay in AR on Fine Motor
   Surgical Tasks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Augmented Reality; Mixed Reality; HoloLens; Visual Delay; Latency;
   Medicine; Surgical Display
ID LATENCY; PERFORMANCE; DISPLAYS; REALITY
AB Latency is a pervasive issue in various systems that can significantly impact motor performance and user perception. In medical settings, latency can hinder surgeons' ability to quickly correct movements, resulting in an experience that doesn't align with user expectations and standards of care. Despite numerous studies reporting on the negative effects of latency, there is still a gap in understanding how it impacts the use of augmented reality (AR) in medical settings. This study aims to address this gap by examining how latency impacts motor task performance and subjective perceptions, such as cognitive load, on two display types: a monitor display, traditionally used inside an operating room (OR), and a Microsoft HoloLens 2 display. Our findings indicate that both level of latency and display type impact motor performance, and higher latencies on the HoloLens result in relatively poor performance. However, cognitive load was found to be unrelated to display type or latency, but was dependent on the surgeon's training level. Surgeons did not compromise accuracy to gain more speed and were generally well aware of the latency in the system irrespective of their performance on task. Our study provides valuable insights into acceptable thresholds of latency for AR displays and proposes design implications for the successful implementation and use of AR in surgical settings.
C1 [Khan, Talha; Downes, Thomas; Biehl, Jacob T.] Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA 15260 USA.
   [Zhu, Toby S.; Cheng, Lucille; Kass, Nicolas M.; Andrews, Edward G.] Univ Pittsburgh, Med Ctr, Sch Med, Pittsburgh, PA USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh; Pennsylvania Commonwealth System of Higher Education
   (PCSHE); University of Pittsburgh
RP Khan, T (corresponding author), Univ Pittsburgh, Sch Comp & Informat, Pittsburgh, PA 15260 USA.
EM muk21@pitt.edu; zhuts@upmc.edu; tad85@pitt.edu; chengl2@upmc.edu;
   kassn@upmc.edu; andrewse2@upmc.edu; biehl@pitt.edu
RI Khan, Talha/KTI-4732-2024; Kass, Nicolás/JPL-3535-2023
OI Cheng, Lucille/0000-0003-2407-0516; Khan, Talha/0000-0003-1552-2728;
   Kass, Nicolas/0009-0009-2968-1253; Downes, Thomas/0009-0006-9877-7601
CR Allison RS, 2001, P IEEE VIRT REAL ANN, P247, DOI 10.1109/VR.2001.913793
   Anvari Mehran, 2005, Comput Aided Surg, V10, P93, DOI 10.1080/10929080500228654
   Ayoub A, 2019, BMC ORAL HEALTH, V19, DOI 10.1186/s12903-019-0937-8
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Barfield W, 1997, P IEEE VIRT REAL ANN, P114, DOI 10.1109/VRAIS.1997.583052
   Bowman D. A., 2012, INT IND TRAIN SIM ED, V4, P44
   Butner SE, 2003, IEEE T ROBOTIC AUTOM, V19, P818, DOI 10.1109/TRA.2003.817214
   Calisto FM, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P390, DOI 10.1145/3132272.3134111
   Calisto FM, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399744
   Castelan Enrique, 2021, IMX '21: ACM International Conference on Interactive Media Experiences, P329, DOI 10.1145/3452918.3468005
   Christensen NH, 2017, PROCEEDINGS OF THE 21ST INTERNATIONAL ACADEMIC MINDTREK CONFERENCE (ACADEMIC MINDTREK), P120, DOI 10.1145/3131085.3131123
   Dick M., 2005, P 4 ACM SIGCOMM WORK
   Ellis SR, 1997, P IEEE VIRT REAL ANN, P138, DOI 10.1109/VRAIS.1997.583063
   Engadget, 2022, Nvidia and medtronic are building an ai-enhanced endoscopy tool
   Fabrizio MD, 2000, J ENDOUROL, V14, P133, DOI 10.1089/end.2000.14.133
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   FITTS PM, 1992, J EXP PSYCHOL GEN, V121, P262, DOI 10.1037/0096-3445.121.3.262
   Friston S., 2015, IEEE transactions on visualization and computer graphics, V22, P2
   Gallagher S, 2000, TRENDS COGN SCI, V4, P14, DOI 10.1016/S1364-6613(99)01417-5
   Gasques D  ..., 2021, P CHI, DOI [DOI 10.1145/3411764.3445576, 10.1145/3411764.3445576]
   Ghaednia H, 2021, SPINE J, V21, P1617, DOI 10.1016/j.spinee.2021.03.018
   Gsaxner C., 2021, P 27 ACM S VIRT REAL, P1
   Ivkovic Z, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P135, DOI 10.1145/2702123.2702432
   Jorg S., 2012, Proceedings of the ACM Symposium on Applied Perception, SAP '12, P33, DOI DOI 10.1145/2338676.2338683
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kennedy-Metz LR, 2020, SURG INNOV, V27, P602, DOI 10.1177/1553350620934931
   Khan T, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P267, DOI 10.1145/3505284.3532970
   Khan T, 2022, HEALTHC TECHNOL LETT, V9, P91, DOI 10.1049/htl2.12036
   Kim T, 2005, SURG ENDOSC, V19, P683, DOI 10.1007/s00464-004-8926-6
   Knörlein B, 2009, INT SYM MIX AUGMENT, P49, DOI 10.1109/ISMAR.2009.5336501
   Kumcu A, 2017, INT J MED ROBOT COMP, V13, DOI 10.1002/rcs.1758
   Lee C, 2010, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2010.5444820
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Lincoln Peter., 2017, P 21 ACM SIGGRAPH S, DOI DOI 10.1364/OE.18.011562
   Long M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300438
   Lum MJH, 2009, IEEE ENG MED BIO, P6860, DOI 10.1109/IEMBS.2009.5333120
   Mauve M, 2004, IEEE T MULTIMEDIA, V6, P47, DOI 10.1109/TMM.2003.819751
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Mine M. R., 1993, TR93-001, P1
   Nabiyouni Mahdi., 2017, Frontiers in ICT, V3, P34
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Nguyen T., 2020, Computing On Network Infrastructure for Pervasive Perception, Cognition and Action, V2, P9
   Orosco R. K., 2021, Surgical endoscopy, V35, P9
   P. Medicine, Brain tumor surgery faq
   Pantel Lothar., 2002, NOSSDAV 02 P 12 INT, P23
   Park KS, 1999, P IEEE VIRT REAL ANN, P104, DOI 10.1109/VR.1999.756940
   Pavlovych Andriy., 2012, P GRAPHICS INTERFACE, P109
   Perez M, 2016, INT J COMPUT ASS RAD, V11, P581, DOI 10.1007/s11548-015-1306-y
   Psotka J, 1995, INSTR SCI, V23, P405, DOI 10.1007/BF00896880
   Raaen K, 2014, ANN WORK NETW
   Richter F, 2019, IEEE INT CONF ROBOT, P444, DOI [10.1109/icra.2019.8794051, 10.1109/ICRA.2019.8794051]
   Robertson G., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P11, DOI 10.1145/263407.263409
   Rohde M, 2014, J VISION, V14, DOI 10.1167/14.3.4
   Rolland JP, 2000, PRESENCE-VIRTUAL AUG, V9, P287, DOI 10.1162/105474600566808
   Schaefer C., 2002, Proc. ACM NetGames, P74
   Schulze J., 2005, P HCI INT, V5, P2
   So RHY, 2005, P ANN INT IEEE EMBS, P5006, DOI 10.1109/IEMBS.2005.1615599
   Steed A., 2008, P 2008 ACM S VIRT RE, P123, DOI [10.1145/1450579.1450606, DOI 10.1145/1450579.1450606]
   Kim DT, 2022, GRAEF ARCH CLIN EXP, V260, P471, DOI 10.1007/s00417-021-05388-6
   Tan Desney S, 2003, P SIGCHI C HUM FACT, P217, DOI [10.1145/642611.642650, DOI 10.1145/642611.642650]
   Todd Nelson W., 2000, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V44, P3
   Verhey JT, 2020, INT J MED ROBOT COMP, V16, DOI 10.1002/rcs.2067
   Vovk A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173783
   Waltemate T., 2015, P 21 ACM S VIRT REAL, P139, DOI DOI 10.1145/2821592.2821607
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Wilson MR, 2011, WORLD J SURG, V35, P1961, DOI 10.1007/s00268-011-1141-4
   Xu S, 2015, INT J MED ROBOT COMP, V11, P290, DOI 10.1002/rcs.1623
   Xu S, 2014, SURG ENDOSC, V28, P2569, DOI 10.1007/s00464-014-3504-z
   Yarrow K., 2013, Journal of Experimental Psychology: Human Perception and Performance, V39, P1
   Zheng F, 2014, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR.2014.6948427
NR 71
TC 2
Z9 2
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4697
EP 4707
DI 10.1109/TVCG.2023.3320214
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100032
PM 37788206
DA 2024-11-06
ER

PT J
AU Tran, TTM
   Brown, S
   Weidlich, O
   Billinghurst, M
   Parker, C
AF Minh Tran, Tram Thi
   Brown, Shane
   Weidlich, Oliver
   Billinghurst, Mark
   Parker, Callum
TI Wearable Augmented Reality: Research Trends and Future Directions from
   Three Major Venues
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Market research; Headphones; Ethics; Augmented reality; Rendering
   (computer graphics); Calibration; Biomedical monitoring; mixed reality;
   head-mounted displays; survey; trends
ID BEHAVIOR; TRACKING
AB Wearable Augmented Reality (AR) has attracted considerable attention in recent years, as evidenced by the growing number of research publications and industry investments. With swift advancements and a multitude of interdisciplinary research areas within wearable AR, a comprehensive review is crucial for integrating the current state of the field. In this paper, we present a review of 389 research papers on wearable AR, published between 2018 and 2022 in three major venues: ISMAR, TVCG, and CHI. Drawing inspiration from previous works by Zhou et al. and Kim et al., which summarized AR research at ISMAR over the past two decades (1998-2017), we categorize the papers into different topics and identify prevailing trends. One notable finding is that wearable AR research is increasingly geared towards enabling broader consumer adoption. From our analysis, we highlight key observations related to potential future research areas essential for capitalizing on this trend and achieving widespread adoption. These include addressing challenges in Display, Tracking, Interaction, and Applications, and exploring emerging frontiers in Ethics, Accessibility, Avatar and Embodiment, and Intelligent Virtual Agents.
C1 [Minh Tran, Tram Thi; Parker, Callum] Univ Sydney, Camperdown, NSW, Australia.
   [Brown, Shane; Weidlich, Oliver] Contxtual, Sydney, Australia.
   [Billinghurst, Mark] Univ South Australia, Adelaide, Australia.
C3 University of Sydney; University of South Australia
RP Tran, TTM (corresponding author), Univ Sydney, Camperdown, NSW, Australia.
EM tram.tran@sydney.edu.au; shane@contxtu.al; oliver@contxtu.al;
   mark.billinghurst@unisa.edu.au; callum.parker@sydney.edu.au
RI Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Weidlich,
   Oliver/0009-0006-5907-2908; Parker, Callum/0000-0002-2173-9213; Tran,
   Tram/0000-0002-4958-2465
CR Aksit K, 2019, IEEE T VIS COMPUT GR, V25, P1928, DOI 10.1109/TVCG.2019.2898781
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Arora R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173759
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Azuma RT, 2019, HUM BEHAV EMERG TECH, V1, P26, DOI 10.1002/hbe2.113
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Bai HD, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376550
   Bang K, 2021, IEEE T VIS COMPUT GR, V27, P2545, DOI 10.1109/TVCG.2021.3067758
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Bhattacharya U, 2020, INT SYM MIX AUGMENT, P24, DOI [10.1109/ISMAR50242.2020.00020, 10.1109/1SMA1R50242.2020.00020]
   Billinghurst M, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.578080
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Bressa N., 2021, IEEE Trans. Vis. Comput. Graph., V28, P6
   Burova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376405
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Cao YZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376688
   Cassidy B, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300289
   Cha YW, 2018, IEEE T VIS COMPUT GR, V24, P2993, DOI 10.1109/TVCG.2018.2868527
   Chakravarthula P, 2018, IEEE T VIS COMPUT GR, V24, P2906, DOI 10.1109/TVCG.2018.2868532
   Chalmers A., 2020, IEEE Trans. Vis. Comput. Graph., V27, P4
   Chen H., 2020, IEEE Trans. Vis. Comput. Graph., V26, P4
   Cho W., 2020 IEEE INT S MIXE
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Dogan M. D., 2022, PROC 2022 CHI C HUMA, P1
   Dudley J. J., 2021, P 2021 CHI C HUM FAC, P1
   Eom S, 2022, INT SYM MIX AUGMENT, P355, DOI 10.1109/ISMAR55827.2022.00051
   Fender A. R., 2022, PROC 2022 CHI C HUMA, P1
   Fuhl W, 2021, INT SYM MIX AUGMENT, P367, DOI 10.1109/ISMAR52148.2021.00053
   Gabbard J. L., 2018, IEEE Trans. Vis. Comput. Graph., V25, P4
   Gasques D  ..., 2021, P CHI, DOI [DOI 10.1145/3411764.3445576, 10.1145/3411764.3445576]
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Genay A, 2022, IEEE T VIS COMPUT GR, V28, P5071, DOI 10.1109/TVCG.2021.3099290
   Grubert J., 2017, IEEE Trans. Vis. Comput. Graph., V24, P4
   Gruenefeld U., 2022, PROC 2022 CHI C HUMA, P1
   Guo KW, 2018, IEEE T VIS COMPUT GR, V24, P1770, DOI 10.1109/TVCG.2017.2688331
   Gupta A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300244
   Hamasaki T, 2019, IEEE T VIS COMPUT GR, V25, P1961, DOI 10.1109/TVCG.2019.2899249
   Heller F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174211
   Hirzle T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300855
   Hong J., 2013, Considering privacy issues in the context of google glass, P9
   Htike HM, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445327
   Huang G., 2021, PROC2021 CHI C HUMAN, P1
   Ibrahim A, 2018, IEEE T VIS COMPUT GR, V24, P2867, DOI 10.1109/TVCG.2018.2868568
   Itoh Y., 2019, IEEE Trans. Vis. Comput. Graph., V25, P3
   Kienzle W, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445094
   Kim H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174075
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim S., 2019, PROC 2019 CHI C HUMA, P1
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   Kress BC, 2019, PROC SPIE, V11062, DOI 10.1117/12.2527680
   Krösl K, 2020, INT SYM MIX AUGMENT, P682, DOI 10.1109/ISMAR50242.2020.00098
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Langlotz T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173964
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee M, 2021, IEEE T VIS COMPUT GR, V27, P3534, DOI 10.1109/TVCG.2019.2959575
   Lee M, 2018, IEEE T VIS COMPUT GR, V24, P1525, DOI 10.1109/TVCG.2018.2794074
   Li X., 2021, IEEE Trans. Vis. Comput. Graph., V27, P4
   Li Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300917
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Lopes P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174020
   Lu FY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517723
   Mandl D, 2021, INT SYM MIX AUGMENT, P508, DOI 10.1109/ISMAR52148.2021.00068
   Marques B., 2021, IEEE Trans. Vis. Comput. Graph., V28, P6
   Matviienko A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517560
   McGill M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376702
   Medeiros D, 2022, IEEE T VIS COMPUT GR, V28, P3640, DOI 10.1109/TVCG.2022.3203002
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Mhaidli AH, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445253
   Mostajeran F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376565
   Muller Leon, 2021, P 2021 CHI C HUM FAC, P1
   Muthukumarana S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376491
   Nakano K, 2019, INT SYM MIX AUGMENT, P212, DOI 10.1109/ISMAR.2019.000-1
   Nebeling M., 2020, PROC 2020 CHI C HUMA, P1
   Nebeling M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300826
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Norouzi N, 2019, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2019.000-8
   Park G, 2020, INT SYM MIX AUGMENT, P588, DOI 10.1109/ISMAR50242.2020.00086
   Peck TC, 2022, IEEE T VIS COMPUT GR, V28, P2179, DOI 10.1109/TVCG.2022.3150521
   Pei SY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501898
   Peillard E, 2020, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR50242.2020.00028
   Peng H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174153
   Peng Y.-H., PROC 2018 CHI C HUMA, P1
   Pfeil K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445223
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Popovici I, 2019, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR.2019.00024
   Qian X, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517665
   Radu I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300774
   Ratcliffe J, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445170
   Rathinavel K, 2019, IEEE T VIS COMPUT GR, V25, P3125, DOI 10.1109/TVCG.2019.2933120
   Rathinavel K, 2018, IEEE T VIS COMPUT GR, V24, P2857, DOI 10.1109/TVCG.2018.2868570
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rixen J. O., 2022, PROC 2022 CHI C HUMA, P1
   Rixen J. O., 2021, PROC2021 CHI C HUMAN, P1
   Rünz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024
   Schissler C, 2018, IEEE T VIS COMPUT GR, V24, P1246, DOI 10.1109/TVCG.2017.2666150
   Schmitz M., 2022, PROC 2022 CHI C HUMA, P1
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Si-Mohammed H., 2018, IEEE Trans. Vis. Comput. Graph., V26, P5
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Sidenmark L., 2021, P 2021 CHI C HUM FAC, P1
   Singh G., 2018, IEEE Trans. Vis. Comput. Graph., V26, P4
   Spjut J, 2020, IEEE T VIS COMPUT GR, V26, P2126, DOI 10.1109/TVCG.2020.2973053
   Starner T, 1997, PRESENCE-VIRTUAL AUG, V6, P386, DOI 10.1162/pres.1997.6.4.386
   Teng S.-Y., 2021, PROC 2021 CHI C HUMA, P1
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Vatavu RD, 2022, INT SYM MIX AUGMENT, P685, DOI 10.1109/ISMAR55827.2022.00086
   Vinayagamoorthy V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300762
   Wang I, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300511
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P2910, DOI 10.1109/TVCG.2018.2865363
   Willett W., 2021, IEEE Trans. Vis. Comput. Graph., V28, P6
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Williams TJ, 2021, P 2021 CHI C HUM FAC
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Xu WP, 2019, IEEE T VIS COMPUT GR, V25, P2093, DOI 10.1109/TVCG.2019.2898650
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yoon L, 2022, IEEE T VIS COMPUT GR, V28, P1619, DOI 10.1109/TVCG.2020.3018458
   Yu G., 2020, IEEE Trans. Vis. Comput. Graph., V27, P3
   Zhang JH, 2019, IEEE T VIS COMPUT GR, V25, P3052, DOI 10.1109/TVCG.2019.2932216
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
   Zhu FY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376233
   Zollmann S., 2020, IEEE Trans. Vis. Comput. Graph., V27, P6
NR 126
TC 5
Z9 5
U1 3
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4782
EP 4793
DI 10.1109/TVCG.2023.3320231
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100039
PM 37782599
DA 2024-11-06
ER

PT J
AU El Ali, A
   Ney, R
   van Berlo, ZMC
   Cesar, P
AF El Ali, Abdallah
   Ney, Rayna
   van Berlo, Zeph M. C.
   Cesar, Pablo
TI Is that My Heartbeat? Measuring and Understanding Modality-Dependent
   Cardiac Interoception in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article; Proceedings Paper
CT 17th International Conference on High Speed Machining (HSM)
CY OCT 25-28, 2023
CL Nanjing, PEOPLES R CHINA
DE Interoception; heart rate; virtual reality; cardiac; biofeedback;
   modality
ID FALSE DISCOVERY RATE; BODY-OWNERSHIP; EXPERIENCE; ENVIRONMENTS;
   IMMERSION
AB Measuring interoception ('perceiving internal bodily states') has diagnostic and wellbeing implications. Since heartbeats are distinct and frequent, various methods aim at measuring cardiac interoceptive accuracy (CIAcc). However, the role of exteroceptive modalities for representing heart rate (HR) across screen-based and Virtual Reality (VR) environments remains unclear. Using a PolarH10 HR monitor, we develop a modality-dependent cardiac recognition task that modifies displayed HR. In a mixed-factorial design (N=50), we investigate how task environment (Screen, VR), modality (Audio, Visual, Audio-Visual), and real-time HR modifications (+/- 15%, +/- 30%, None) influence CIAcc, interoceptive awareness, mind-body measures, VR presence, and post-experience responses. Findings showed that participants confused their HR with underestimates up to 30%; environment did not affect CIAcc but influenced mind-related measures; modality did not influence CIAcc, however including audio increased interoceptive awareness; and VR presence inversely correlated with CIAcc. We contribute a lightweight and extensible cardiac interoception measurement method, and implications for biofeedback displays.
C1 [El Ali, Abdallah; Cesar, Pablo] Ctr Wiskunde & Informat, Amsterdam, Netherlands.
   [Ney, Rayna; van Berlo, Zeph M. C.] Univ Amsterdam, Amsterdam, Netherlands.
   [Cesar, Pablo] Delft Univ Technol, Delft, Netherlands.
C3 University of Amsterdam; Delft University of Technology
RP El Ali, A (corresponding author), Ctr Wiskunde & Informat, Amsterdam, Netherlands.
EM aea@cwi.nl; raynaney@gmail.com; z.m.c.vanBerlo@uva.nl; p.s.cesar@cwi.nl
RI van Berlo, Zeph/O-1903-2019
OI Ney, Rayna/0009-0000-9732-9176; Cesar, Pablo/0000-0003-1752-6837; van
   Berlo, Zeph/0000-0002-1008-8654; El Ali, Abdallah/0000-0002-9954-4088
CR Akoglu H, 2018, TURK J EMERG MED, V18, P91, DOI 10.1016/j.tjem.2018.08.001
   Azevedo RT, 2016, SCI REP-UK, V6, DOI 10.1038/srep26545
   Benjamini Y, 2001, ANN STAT, V29, P1165
   BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x
   Bessa M, 2016, PROCEEDINGS OF THE XVII INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTION INTERACCION 2016, DOI 10.1145/2998626.2998669
   Brener J, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2016.0015
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chen H., 2017, Proceedings of the 29th Australian conference on computer-human interaction, P108, DOI DOI 10.1145/3152771.3152783
   Clarke V., 2015, Qualitative psychology: A practical guide to research methods, V222, P7
   Costa J, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P758, DOI 10.1145/2971648.2971752
   Craig AD, 2002, NAT REV NEUROSCI, V3, P655, DOI 10.1038/nrn894
   Desmedt O, 2020, BIOL PSYCHOL, V154, DOI 10.1016/j.biopsycho.2020.107904
   Dey A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P101, DOI 10.1145/3242671.3242676
   Dey A, 2019, INT SYM MIX AUGMENT, P248, DOI 10.1109/ISMAR.2019.00022
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Dollinger N., 2021, Frontiers in Virtual Reality, V2, P9
   Dollinger N., 2022, P CHI EA 22
   El Ali A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376682
   Elkin L. A., 2021, An aligned rank transform procedure for multifactor contrast tests, P7
   Feick M., 2020, ADJUNCT P ANN ACM S, P68, DOI DOI 10.1145/3379350.3416188
   Feijt MA, 2023, HUM-COMPUT INTERACT, V38, P49, DOI 10.1080/07370024.2021.1913164
   Ferentzi E., 2022, Trends in Cognitive Sciences, V2
   Filippetti ML, 2017, COGNITION, V159, P1, DOI 10.1016/j.cognition.2016.11.002
   Garau M., 2008, Temporal and spatial variations in presence: Qualitative analysis of interviews from an experiment on breaks in presence, P8
   Garfinkel SN, 2015, BIOL PSYCHOL, V104, P65, DOI 10.1016/j.biopsycho.2014.11.004
   George C, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313082
   Gradl S, 2018, INT CONF WEARAB IMPL, P152, DOI 10.1109/BSN.2018.8329681
   Hassib M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2239, DOI 10.1145/3025453.3025758
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Hirsch L., 2019, MENSCH COMP 2019 WOR, DOI [10.18420/muc2019-ws-4079, DOI 10.18420/MUC2019-WS-4079]
   Hodossy L, 2021, BIOL PSYCHOL, V165, DOI 10.1016/j.biopsycho.2021.108198
   Hong U., 2021, The Asian Journal of Kinesiology, V23
   Ishihara S., 1918, American Journal of Ophthalmology, V1, P5
   Janssen J. H., Int. J. Synth. Emot., V4, P65
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Khalsa Sahib S, 2018, Biol Psychiatry Cogn Neurosci Neuroimaging, V3, P501, DOI 10.1016/j.bpsc.2017.12.004
   Khalsa SS, 2009, NAT NEUROSCI, V12, P1494, DOI 10.1038/nn.2411
   Kothgassner OD, 2022, WIEN KLIN WOCHENSCHR, V134, P49, DOI 10.1007/s00508-021-01991-z
   Kutscheidt K, 2019, ADHD-ATTEND DEFICIT, V11, P395, DOI 10.1007/s12402-019-00299-3
   Lee S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517451
   Legrand N, 2022, BIOL PSYCHOL, V168, DOI 10.1016/j.biopsycho.2021.108239
   Lüddecke R, 2022, APPL PSYCHOPHYS BIOF, V47, P1, DOI 10.1007/s10484-021-09529-9
   Lux E, 2018, COMMUN ASSOC INF SYS, V43, P257, DOI 10.17705/1CAIS.04318
   Macmillan N., 2004, Detection Theory: A User's Guide, V2, P6
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   Mehling W, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2016.0013
   Mehling WE, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0208034
   Meissner K, 2011, BIOL PSYCHOL, V86, P289, DOI 10.1016/j.biopsycho.2011.01.001
   Milgram P., 1995, Telemanipulator and Telepresence Technologies, V2351, P2
   Miller HL, 2016, CYBERPSYCH BEH SOC N, V19, P246, DOI 10.1089/cyber.2014.0682
   Moge C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517495
   Moullec Y, 2022, IEEE T VIS COMPUT GR, V28, P3596, DOI 10.1109/TVCG.2022.3203120
   Murphy J, 2019, BIOL PSYCHOL, V148, DOI 10.1016/j.biopsycho.2019.107765
   Murphy J, 2020, Q J EXP PSYCHOL, V73, P115, DOI 10.1177/1747021819879826
   Murray CD, 2001, CYBERPSYCHOL BEHAV, V4, P365, DOI 10.1089/109493101300210268
   Oppenheimer S, 2016, COMPR PHYSIOL, V6, P1081, DOI 10.1002/cphy.c140076
   Palmer C., 2019, PsyArXiv, P2
   Paulus MP, 2010, BRAIN STRUCT FUNCT, V214, P451, DOI 10.1007/s00429-010-0258-9
   Plews DJ, 2017, INT J SPORT PHYSIOL, V12, P1324, DOI 10.1123/ijspp.2016-0668
   Ponzo S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.712896
   Putze S., 2020, PROC CHI 20, P1
   Quintero L, 2021, INT SYM MIX AUGMENT, P357, DOI 10.1109/ISMAR52148.2021.00052
   Ring C, 2015, BIOL PSYCHOL, V104, P193, DOI 10.1016/j.biopsycho.2014.12.010
   Riva G, 2012, VIRTUAL REALITY IN PSYCHOLOGICAL, MEDICAL AND PEDAGOGICAL APPLICATIONS, P3, DOI 10.5772/46411
   Roquet CD, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445137
   Schaffarczyk M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176536
   SCHANDRY R, 1981, PSYCHOPHYSIOLOGY, V18, P483, DOI 10.1111/j.1469-8986.1981.tb02486.x
   Schoeller F., 2022, PsyArXiv, V2
   Schoeller F, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02741
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schulz A, 2021, BIOL PSYCHOL, V164, DOI 10.1016/j.biopsycho.2021.108168
   Sedeño L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098769
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Slater M, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.914392
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Smith G. D., 2002, Data dredging, bias, or confounding: They can all get you into the bmj and the friday papers, P7
   Suzuki K, 2013, NEUROPSYCHOLOGIA, V51, P2909, DOI 10.1016/j.neuropsychologia.2013.08.014
   Tajadura-Jimenez A, 2008, CYBERPSYCHOL BEHAV, V11, P33, DOI 10.1089/cpb.2007.0002
   Tanay G, 2013, PSYCHOL ASSESSMENT, V25, P1286, DOI 10.1037/a0034044
   Tsakiris M, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2016.0002
   Tsakiris M, 2011, P ROY SOC B-BIOL SCI, V278, P2470, DOI 10.1098/rspb.2010.2547
   Ueoka R., 2016, SIGGRAPH ASIA 16 EME, DOI [10.1145/2988240.29882473,5, DOI 10.1145/2988240.29882473,5]
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van Gent P, 2019, TRANSPORT RES F-TRAF, V66, P368, DOI 10.1016/j.trf.2019.09.015
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   WHITEHEAD WE, 1977, BIOFEEDBACK SELF-REG, V2, P371, DOI 10.1007/BF00998623
   Wickens CD, 2008, HUM FACTORS, V50, P449, DOI 10.1518/001872008X288394
   Wiederhold BK, 1998, ST HEAL T, V58, P52
   Winters R. M., 2021, P CHI 21
   Wobbrock J.O., 2011, The Aligned Rank Transform for Nonparametric Factorial Analyses Using Only Anova Procedures, P143, DOI [10.1145/1978942.1978963, DOI 10.1145/1978942.1978963, 10.1145/1978942, DOI 10.1145/1978942]
   Xue T., 2021, PROC CHI EA 21
   Yu B, 2018, PERS UBIQUIT COMPUT, V22, P787, DOI 10.1007/s00779-018-1141-6
   Zamariola G, 2018, BIOL PSYCHOL, V137, P12, DOI 10.1016/j.biopsycho.2018.06.006
   Zhou YZ, 2020, IEEE HAPTICS SYM, P677, DOI 10.1109/HAPTICS45997.2020.ras.HAP20.157.5a2e1551
NR 94
TC 4
Z9 4
U1 1
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
BP 4805
EP 4815
DI 10.1109/TVCG.2023.3320228
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA X6ZW5
UT WOS:001099919100041
PM 37782606
OA Green Published
DA 2024-11-06
ER

PT J
AU Fiorentino, M
   Gabbard, JL
   Lee, G
   Marchal, M
   Moreau, G
AF Fiorentino, Michele
   Gabbard, Joseph L.
   Lee, Gun
   Marchal, Maud
   Moreau, Guillaume
TI Message from the ISMAR 2023 Science and Technology Journal Program
   Chairs and TVCG Guest Editors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
DE Special issues and sections; Meetings; Visualization; Computer graphics
AB In this special issue of IEEE Transactions on Visualization and Computer Graphics (TVCG), we are pleased to present the journal papers from the 22nd IEEE International Symposium on Mixed and Augmented Reality (ISMAR 2023), which will be held as a hybrid conference between October 16 and 20, 2023 in Sydney, Australia. ISMAR continues the over twenty-year long tradition of IWAR, ISMR, and ISAR, and is the premier conference for Mixed and Augmented Reality in the world.
C1 [Fiorentino, Michele] Polytech Univ Bari, Bari, Italy.
   [Gabbard, Joseph L.] Virginia Tech, Blacksburg, VA USA.
   [Lee, Gun] Univ South Australia, Adelaide, Australia.
   [Marchal, Maud] Univ Rennes, IRISA, INSA, Rennes, France.
   [Moreau, Guillaume] IMT Atlantique, Nantes, France.
C3 Politecnico di Bari; Virginia Polytechnic Institute & State University;
   University of South Australia; Universite de Rennes; IMT - Institut
   Mines-Telecom; IMT Atlantique
RP Fiorentino, M (corresponding author), Polytech Univ Bari, Bari, Italy.
EM michele.fiorentino@poliba.it; jgabbard@vt.edu; Gun.Lee@unisa.edu.au;
   Maud.Marchal@irisa.fr; guillaume.moreau@imt-atlantique.fr
RI Lee, Gun/AAS-9903-2021; Fiorentino, Michele/M-6976-2015; Moreau,
   Guillaume/I-3153-2013
OI Lee, Gun/0000-0002-1644-6934
NR 0
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD NOV
PY 2023
VL 29
IS 11
DI 10.1109/TVCG.2023.3322308
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X6ZW5
UT WOS:001099919100002
OA Bronze
DA 2024-11-06
ER

PT J
AU Mao, AH
   Du, ZH
   Hou, JH
   Duan, YQ
   Liu, YJ
   He, Y
AF Mao, Aihua
   Du, Zihui
   Hou, Junhui
   Duan, Yaqi
   Liu, Yong-Jin
   He, Ying
TI PU-Flow: A Point Cloud Upsampling Network With Normalizing Flows
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Interpolation; Feature extraction; Task
   analysis; Pipelines; Three-dimensional displays; Surface treatment;
   Point cloud analysis; upsampling; normalizing flows; weight prediction
AB Point cloud upsampling aims to generate dense point clouds from given sparse ones, which is a challenging task due to the irregular and unordered nature of point sets. To address this issue, we present a novel deep learning-based model, called PU-Flow, which incorporates normalizing flows and weight prediction techniques to produce dense points uniformly distributed on the underlying surface. Specifically, we exploit the invertible characteristics of normalizing flows to transform points between euclidean and latent spaces and formulate the upsampling process as ensemble of neighbouring points in a latent space, where the ensemble weights are adaptively learned from local geometric context. Extensive experiments show that our method is competitive and, in most test cases, it outperforms state-of-the-art methods in terms of reconstruction quality, proximity-to-surface accuracy, and computation efficiency. The source code will be publicly available at https://github.com/unknownue/puflow.
C1 [Mao, Aihua; Du, Zihui; Duan, Yaqi] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Peoples R China.
   [Hou, Junhui] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Hou, Junhui] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
   [Liu, Yong-Jin] Tsinghua Univ, BNRist, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, Beijing 100190, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 South China University of Technology; City University of Hong Kong; City
   University of Hong Kong; Shenzhen Research Institute, City University of
   Hong Kong; Tsinghua University; Nanyang Technological University
RP Mao, AH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Peoples R China.; Hou, JH (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM ahmao@scut.edu.cn; csusami@mail.scut.edu.cn; jh.hou@cityu.edu.hk;
   csduanyaqi@mail.scut.edu.cn; liuyongjin@tsinghua.edu.cn; yhe@ntu.edu.sg
RI He, Ying/A-3708-2011
OI Hou, Junhui/0000-0003-3431-2021
FU NSF of Guangdong Province [2019A1515010833, 2022A1515011573]; Natural
   Science Foundation of China [61725204, 61871342]; Hong Kong Research
   Grants Council [11202320, 11218121]; Ministry of Education, Singapore
   under its Academic Research Fund [MOE-T2EP20220-0005, RG20/20]
FX This work was supported in part by the NSF of Guangdong Province under
   Grants 2019A1515010833 and 2022A1515011573, in part by the Natural
   Science Foundation of China under Grants 61725204 and 61871342, in part
   by the Hong Kong Research Grants Council under Grants 11202320 and
   11218121, and in part by the Ministry of Education, Singapore under its
   Academic Research Fund Tier 1 (RG20/20) and Tier 2 (MOE-T2EP20220-0005).
CR Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Ardizzone L, 2019, Arxiv, DOI arXiv:1907.02392
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bletterer A, 2022, IEEE T VIS COMPUT GR, V28, P2822, DOI 10.1109/TVCG.2020.3042588
   Cgal, 2022, About us
   Chen RTQ, 2018, 32 C NEURAL INFORM P, V31
   Chen YB, 2021, PROC CVPR IEEE, P8624, DOI 10.1109/CVPR46437.2021.00852
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Corsini M, 2012, IEEE T VIS COMPUT GR, V18, P914, DOI 10.1109/TVCG.2012.34
   Dinh L., 2017, INT C LEARN REPR
   Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]
   Durkan C, 2019, ADV NEUR IN, V32
   Elbaz G, 2017, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2017.265
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Grathwohl W., 2019, INT C LEARN REPR
   Grover A., 2019, P DEEP GEN MOD HIGHL, P1
   Guerrero P, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13343
   Hu SM, 2020, IEEE T VIS COMPUT GR, V26, P2485, DOI 10.1109/TVCG.2018.2889944
   Hu XC, 2019, PROC CVPR IEEE, P1575, DOI 10.1109/CVPR.2019.00167
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Huang H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618522
   Huang ZT, 2020, PROC CVPR IEEE, P7659, DOI 10.1109/CVPR42600.2020.00768
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kim S., 2019, PR MACH LEARN RES, P3370
   Kingma DP, 2018, ADV NEUR IN, V31
   Kingma DP, 2016, 30 C NEURAL INFORM P, V29
   Klokov Roman, 2020, EUR C COMP VIS, P694
   Kumar M., 2020, P INT C LEARN LEARN, P1
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li YS, 2022, IEEE T VIS COMPUT GR, V28, P3499, DOI 10.1109/TVCG.2021.3069195
   Lipman Y, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239473, 10.1145/1276377.1276405]
   Liu J, 2019, ADV NEUR IN, V32
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Lugmayr Andreas, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P715, DOI 10.1007/978-3-030-58558-7_42
   Oliva J., 2018, INT C MACHINE LEARNI, P3898
   Postels J, 2021, INT CONF 3D VISION, P1249, DOI 10.1109/3DV53792.2021.00132
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI [10.1109/icassp.2019.8683143, 10.1109/ICASSP.2019.8683143]
   Pumarola A, 2020, PROC CVPR IEEE, P7946, DOI 10.1109/CVPR42600.2020.00797
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qian G., 2021, P IEEE CVF C COMP VI, p11 683
   Qian Y, 2021, IEEE T IMAGE PROCESS, V30, P8354, DOI 10.1109/TIP.2021.3115385
   Rakotosaona MJ, 2021, PROC CVPR IEEE, P22, DOI 10.1109/CVPR46437.2021.00009
   Rempe Davis, 2020, ADV NEUR IN, V33
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Sketchfab, 2022, About us
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Te GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P746, DOI 10.1145/3240508.3240621
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   van den Berg R, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P393
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Winkler C, 2023, Arxiv, DOI arXiv:1912.00042
   Wu SH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818073
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xu MT, 2021, PROC CVPR IEEE, P3172, DOI 10.1109/CVPR46437.2021.00319
   Xu ZW, 2021, IEEE T VIS COMPUT GR, V27, P2851, DOI 10.1109/TVCG.2019.2959761
   Yan ZH, 2022, IEEE T VIS COMPUT GR, V28, P4304, DOI 10.1109/TVCG.2021.3086113
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Yue Qian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P752, DOI 10.1007/978-3-030-58529-7_44
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhou QN, 2016, Arxiv, DOI arXiv:1605.04797
NR 70
TC 7
Z9 8
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4964
EP 4977
DI 10.1109/TVCG.2022.3196334
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300011
PM 35925853
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, GZ
   Yuan, XR
AF Li, Guozheng
   Yuan, Xiaoru
TI GoTreeScape: Navigate and Explore the Tree Visualization Design Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Layout; Space exploration; Grammar;
   Navigation; Shape; Tree visualization; design space exploration; deep
   learning
AB Declarative grammar is becoming an increasingly important technique for understanding visualization design spaces. The GoTreeScape system presented in the paper allows users to navigate and explore the vast design space implied by GoTree, a declarative grammar for visualizing tree structures. To provide an overview of the design space, GoTreeScape, which is based on an encoder-decoder architecture, projects the tree visualizations onto a 2D landscape. Significantly, this landscape takes the relationships between different design features into account. GoTreeScape also includes an exploratory framework that allows top-down, bottom-up, and hybrid modes of exploration to support the inherently undirected nature of exploratory searches. Two case studies demonstrate the diversity with which GoTreeScape expands the universe of designed tree visualizations for users. The source code associated with GoTreeScape is available at https://github.com/bitvis2021/gotreescape.
C1 [Li, Guozheng] Peking Univ, Sch AI, Beijing 100871, Peoples R China.
   [Li, Guozheng] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100811, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Sch AI, Minist Educ, Lab Machine Percept, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Peking University; Beijing Institute of Technology; Peking University;
   Peking University
RP Yuan, XR (corresponding author), Peking Univ, Sch AI, Minist Educ, Lab Machine Percept, Beijing 100871, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
EM guozhg.li@gmail.com; xiaoru.yuan@pku.edu.cn
RI Li, Guo-Zheng/D-5744-2011; Yuan, Xiaoru/E-1798-2013
OI Yuan, Xiaoru/0000-0002-7233-980X; Li, Guozheng/0000-0001-6663-6712
FU National Key Research and Development Program of China [2021YFB3301502];
   NSFC [61872013]; Beijing Institute of Technology Research Fund Program
   for Young Scholars
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2021YFB3301502, in part by NSFC
   under Grant 61872013, and in part by the Beijing Institute of Technology
   Research Fund Program for Young Scholars.
CR Auber David., 2002, International Conference on Computer Vision and Graphics, P56
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Baudel T, 2012, IEEE T VIS COMPUT GR, V18, P2593, DOI 10.1109/TVCG.2012.205
   Beham M, 2014, IEEE T VIS COMPUT GR, V20, P1693, DOI 10.1109/TVCG.2014.2346626
   Blades M, 1998, T I BRIT GEOGR, V23, P269, DOI 10.1111/j.0020-2754.1998.00269.x
   Block F, 2012, IEEE T VIS COMPUT GR, V18, P2789, DOI 10.1109/TVCG.2012.272
   Bolte F, 2021, IEEE T VIS COMPUT GR, V27, P3153, DOI 10.1109/TVCG.2019.2963651
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Card SK, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P92, DOI 10.1109/INFVIS.1997.636792
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chi EH, 1997, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P17, DOI 10.1109/INFVIS.1997.636761
   Fabrikant SI, 2010, J AM SOC INF SCI TEC, V61, P253, DOI 10.1002/asi.21227
   Guo HQ, 2014, IEEE PAC VIS SYMP, P262, DOI 10.1109/PacificVis.2014.24
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Jankun-Kelly TJ, 2007, IEEE T VIS COMPUT GR, V13, P357, DOI 10.1109/TVCG.2007.28
   Jankun-Kelly TJ, 2000, IEEE VISUAL, P69, DOI 10.1109/VISUAL.2000.885678
   Jankun-Kelly TJ, 2001, IEEE T VIS COMPUT GR, V7, P275, DOI 10.1109/2945.942695
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   JOHNSON B, 1991, VISUALIZATION 91, P284
   Jolliffe I., 2022, Principal Component Analysis, P150, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1007/0-387-22440-87, 10.1007/b98835]
   Kerr B, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P211, DOI 10.1109/INFVIS.2003.1249028
   Kerren A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187341
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Kristiansen YS, 2020, COMPUT GRAPH-UK, V92, P13, DOI 10.1016/j.cag.2020.08.007
   Kruskal J. B., 1978, Multidimensional Scaling
   Kusner MJ, 2017, PR MACH LEARN RES, V70
   Kwan-Liu Ma, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P81, DOI 10.1109/VISUAL.1999.809871
   Lee DJL, 2020, IEEE T VIS COMPUT GR, V26, P1267, DOI 10.1109/TVCG.2019.2934666
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li GZ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383150
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   Li S., 2015, Visualization and Data Analysis, P68
   MacNeil S, 2013, COMPUT GRAPH FORUM, V32, P38, DOI 10.1111/cgf.12013
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meulemans W, 2021, IEEE T VIS COMPUT GR, V27, P1236, DOI 10.1109/TVCG.2020.3028953
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T, 2003, ACM T GRAPHIC, V22, P453, DOI 10.1145/882262.882291
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Real R, 1996, SYST BIOL, V45, P380, DOI 10.2307/2413572
   Rodrigues J.F., 2007, Information Visualization, V6, P261, DOI [10.1145/1375935.1375937, DOI 10.1145/1375935.1375937]
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Schulz HJ, 2015, J VISUAL LANG COMPUT, V31, P9, DOI 10.1016/j.jvlc.2015.09.004
   Schulz HJ, 2013, IEEE PAC VIS SYMP, P225, DOI 10.1109/PacificVis.2013.6596149
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Slingsby A, 2009, IEEE T VIS COMPUT GR, V15, P977, DOI 10.1109/TVCG.2009.128
   Talton JO, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618513
   Tory M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P151, DOI 10.1109/INFVIS.2004.59
   Tukey JW., 1977, EXPLORATORY DATA ANA
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wilkinson L., 2005, The Grammar of Graph
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu Y.Z., 2007, P 2007 JOINT C EMPIR, P33
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhao SD, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P57, DOI 10.1109/INFVIS.2005.1532129
NR 65
TC 6
Z9 7
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5451
EP 5467
DI 10.1109/TVCG.2022.3215070
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300044
PM 36251894
DA 2024-11-06
ER

PT J
AU Walchshofer, C
   Hinterreiter, A
   Xu, K
   Stitz, H
   Streit, M
AF Walchshofer, Conny
   Hinterreiter, Andreas
   Xu, Kai
   Stitz, Holger
   Streit, Marc
TI Provectories: Embedding-Based Analysis of Interaction Provenance Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Layout; Cognition; Visual analytics; Time series
   analysis; Task analysis; Collaboration; Visualization techniques;
   information visualization; visual analytics; interaction provenance;
   sensemaking
ID VISUALIZATION; EXPLORATION; USERS
AB Understanding user behavior patterns and visual analysis strategies is a long-standing challenge. Existing approaches rely largely on time-consuming manual processes such as interviews and the analysis of observational data. While it is technically possible to capture a history of user interactions and application states, it remains difficult to extract and describe analysis strategies based on interaction provenance. In this article, we propose a novel visual approach to the meta-analysis of interaction provenance. We capture single and multiple user sessions as graphs of high-dimensional application states. Our meta-analysis is based on two different types of two-dimensional embeddings of these high-dimensional states: layouts based on (i) topology and (ii) attribute similarity. We applied these visualization approaches to synthetic and real user provenance data captured in two user studies. From our visualizations, we were able to extract patterns for data types and analytical reasoning strategies.
C1 [Walchshofer, Conny; Hinterreiter, Andreas] Johannes Kepler Univ Linz, A-4040 Linz, Austria.
   [Xu, Kai] Middlesex Univ London, London NW4 4BT, England.
   [Stitz, Holger] Datavisyn GmbH, A-4040 Linz, Austria.
   [Streit, Marc] Johannes Kepler Univ Linz, A-4040 Linz, Austria.
   [Streit, Marc] Datavisyn GmbH, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz; Middlesex University; Johannes Kepler
   University Linz
RP Walchshofer, C (corresponding author), Johannes Kepler Univ Linz, A-4040 Linz, Austria.
EM conny.walchshofer@jku.at; andreas.hinterreiter@jku.at; k.xu@mdx.ac.uk;
   holger.stitz@datavisyn.io; marc.streit@jku.at
OI Reis, Conny/0000-0003-3942-8445; Streit, Marc/0000-0001-9186-2092;
   Stitz, Holger/0000-0002-4742-2636
FU FFG within the Austrian COMET Program Competence Centers for Excellent
   Technologies under the auspices of the Austrian Federal Ministry for
   Climate Action, Environment, Energy, Mobility, Innovation and Technology
   [881844]; Austrian Federal Ministry for Digital and Economic Affairs;
   Province of Upper Austria; Province of Styria; Federal State of Upper
   Austria; Austrian Federal Ministry of Education, Science and Research
   via the LIT -Linz Institute of Technology [LIT-2019-7-SEE-117]; Federal
   State of Upper Austria (Human-Interpretable Machine Learning)
FX This work was supported in part by the FFG, Contract under Grant 881844:
   "Pro<SUP>2</SUP> Future is funded within the Austrian COMET Program
   Competence Centers for Excellent Technologies under the auspices of the
   Austrian Federal Ministry for Climate Action, Environment, Energy,
   Mobility, Innovation and Technology, the Austrian Federal Ministry for
   Digital and Economic Affairs and of the Provinces of Upper Austria and
   Styria. COMET is managed by the Austrian Research Promotion Agency FFG."
   Additional support was granted in part by the Federal State of Upper
   Austria and the Austrian Federal Ministry of Education, Science and
   Research via the LIT -Linz Institute of Technology under Grant
   LIT-2019-7-SEE-117 and in part by the Federal State of Upper Austria
   (Human-Interpretable Machine Learning).
CR Anaconda Inc. Datashader, 2016, Accurately render even the largest data
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Blascheck T, 2016, IEEE CONF VIS ANAL, P141, DOI 10.1109/VAST.2016.7883520
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brown E.T., 2018, P MACH LEARN US INT
   Brown ET, 2014, IEEE T VIS COMPUT GR, V20, P1663, DOI 10.1109/TVCG.2014.2346575
   Callahan S.P., 2006, INT C MAN DAT 2005 A, P745, DOI 10.1145/1142473.1142574
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Cowley P., 2005, Proceedings of IEEE Hawaii International Conference on System Sciences (HICSS '05), P296
   Cutler Z, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P116, DOI 10.1109/VIS47514.2020.00030
   Dou WW, 2009, IEEE COMPUT GRAPH, V29, P52, DOI 10.1109/MCG.2009.49
   Dunne C., 2012, P SIGCHI C HUMAN FAC, P1663, DOI [10.1145/2207676.2208293, DOI 10.1145/2207676.2208293]
   Eckelt K., 2021, Open Sci. Framework
   Feng M, 2019, IEEE T VIS COMPUT GR, V25, P501, DOI 10.1109/TVCG.2018.2865117
   Fock V, 1932, Z PHYS, V75, P622, DOI 10.1007/BF01344458
   Gadhave K, 2021, INFORM VISUAL, V20, P207, DOI 10.1177/14738716211038604
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gomez S., 2012, CHI 2012 ITS EXPERIE, P2465
   Gotz D, 2009, INFORM VISUAL, V8, P42, DOI 10.1057/ivs.2008.31
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Haeyong Chung, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P107, DOI 10.1109/VAST.2010.5652932
   Heer J, 2008, IEEE T VIS COMPUT GR, V14, P1189, DOI 10.1109/TVCG.2008.137
   Hinterreiter A, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387165
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Karpathy A., 2014, tSNEJS
   Kerracher N, 2015, IEEE T VIS COMPUT GR, V21, P1160, DOI 10.1109/TVCG.2015.2424889
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Madanagopal K, 2019, IEEE COMPUT GRAPH, V39, P30, DOI 10.1109/MCG.2019.2933419
   Mankowski WC, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1323
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Nguyen PH, 2016, IEEE T VIS COMPUT GR, V22, P41, DOI 10.1109/TVCG.2015.2467611
   Nobre C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445382
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pandey A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P55, DOI 10.1109/BELIV51497.2020.00014
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   People+AI Research (PAIR) Initiative, 2019, UMAP-JS
   Plique G., 2016, Graphology ForceAtlas2
   Pohl M., 2017, Multimodal Technol. Int., V1
   Pohl M, 2012, IEEE T VIS COMPUT GR, V18, P2908, DOI 10.1109/TVCG.2012.273
   Policar P. G., 2019, bioRxiv
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Rosling H, 2011, J EPIDEMIOL GLOB HEA, V1, P11, DOI 10.1016/j.jegh.2011.07.001
   Setlur V, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P365, DOI 10.1145/2984511.2984588
   Stitz H, 2016, COMPUT GRAPH FORUM, V35, P481, DOI 10.1111/cgf.12924
   Stitz H, 2019, IEEE T VIS COMPUT GR, V25, P120, DOI 10.1109/TVCG.2018.2865024
   van den Elzen S, 2016, IEEE T VIS COMPUT GR, V22, P1, DOI 10.1109/TVCG.2015.2468078
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wei JS, 2012, IEEE CONF VIS ANAL, P3, DOI 10.1109/VAST.2012.6400494
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   Zhao J, 2018, IEEE T VIS COMPUT GR, V24, P340, DOI 10.1109/TVCG.2017.2745279
NR 55
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4816
EP 4831
DI 10.1109/TVCG.2021.3135697
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300001
PM 34910635
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Jadhav, S
   Kaufman, AE
AF Jadhav, Shreeraj
   Kaufman, Arie E.
TI <i>MD</i>-<i>Cave</i>: An Immersive Visualization Workbench for
   Radiologists
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Visualization; Stereo image processing; Data
   visualization; Task analysis; Head; Radiology; Immersive diagnosis;
   stereoscopic visualization; volume rendering; 3D selection
ID STEREOSCOPIC 3D DISPLAYS; VIRTUAL-REALITY; TECHNOLOGIES; SURGERY;
   PERFORMANCE; ENVIRONMENT; SIMULATION; NAVIGATION; SYSTEM; TOOL
AB The MD-Cave is an immersive analytics system that provides enhanced stereoscopic visualizations to support visual diagnoses performed by radiologists. The system harnesses contemporary paradigms in immersive visualization and 3D interaction, which are better suited for investigating 3D volumetric data. We retain practicality through efficient utilization of desk space and comfort for radiologists in terms of frequent long duration use. MD-Cave is general and incorporates: (1) high resolution stereoscopic visualizations through a surround triple-monitor setup, (2) 3D interactions through head and hand tracking, (3) and a general framework that supports 3D visualization of deep-seated anatomical structures without the need for explicit segmentation algorithms. Such a general framework expands the utility of our system to many diagnostic scenarios. We have developed MD-Cave through close collaboration and feedback from two expert radiologists who evaluated the utility of MD-Cave and the 3D interactions in the context of radiological examinations. We also provide evaluation of MD-Cave through case studies performed by an expert radiologist and concrete examples on multiple real-world diagnostic scenarios, such as pancreatic cancer, shoulder-CT, and COVID-19 Chest CT examination.
C1 [Jadhav, Shreeraj; Kaufman, Arie E.] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University
RP Jadhav, S (corresponding author), SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
EM sdjadhav@cs.stonybrook.edu; ari@cs.stonybrook.edu
OI Kaufman, Arie/0000-0002-0796-6196; Jadhav, Shreeraj/0000-0003-0520-4857
FU NSF [CNS1650499, OAC1919752, ICER1940302, IIS2107224]
FX This work was supported in part by the NSF under Grants CNS1650499,
   OAC1919752, ICER1940302, and IIS2107224.
CR Andriole KP, 2011, RADIOLOGY, V259, P346, DOI 10.1148/radiol.11091276
   Bacim F, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P185
   Besancon L, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13710
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Bhattacherjee A., 2007, Proceedings of the HICSS 2007 40th Annual Hawaii International Conference on System Sciences, P141
   Büschel W, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P62, DOI 10.1145/3132272.3134125
   Cecotti H, 2020, PROCEEDINGS OF 2020 6TH INTERNATIONAL CONFERENCE OF THE IMMERSIVE LEARNING RESEARCH NETWORK (ILRN 2020), P205, DOI [10.23919/ilrn47897.2020.9155206, 10.23919/iLRN47897.2020.9155206]
   Chan S, 2013, NEUROSURGERY, V72, pA154, DOI 10.1227/NEU.0b013e3182750d26
   Chapoulie Emmanuelle, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P109, DOI 10.1109/3DUI.2015.7131734
   Coffey D, 2012, IEEE T VIS COMPUT GR, V18, P1614, DOI 10.1109/TVCG.2011.283
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cutler L. D., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P107, DOI 10.1145/253284.253315
   D'Orsi CJ, 2013, RADIOLOGY, V266, P81, DOI 10.1148/radiol.12120382
   Ebert DS, 1996, IEEE VISUAL, P205, DOI 10.1109/VISUAL.1996.568109
   Elsayed M, 2020, ACTA RADIOL, V61, P1258, DOI 10.1177/0284185119897362
   Farahani Navid, 2016, J Pathol Inform, V7, P22, DOI 10.4103/2153-3539.181766
   Faynshteyn L, 2012, LECT NOTES COMPUT SC, V7431, P336, DOI 10.1007/978-3-642-33179-4_33
   Ferrari V, 2009, IEEE T BIO-MED ENG, V56, P2627, DOI 10.1109/TBME.2009.2028013
   Gallotti P., 2011, 2011 XIII Symposium on Virtual Reality (SVR), P242, DOI 10.1109/SVR.2011.21
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Held RT, 2011, ACAD RADIOL, V18, P1035, DOI 10.1016/j.acra.2011.04.005
   Huber T, 2017, SURG ENDOSC, V31, P4472, DOI 10.1007/s00464-017-5500-6
   Hurter C, 2014, IEEE PAC VIS SYMP, P225, DOI 10.1109/PacificVis.2014.61
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Jadhav S, 2022, IEEE T VIS COMPUT GR, V28, P1457, DOI 10.1109/TVCG.2020.3020958
   Jadhav S, 2019, IEEE T VIS COMPUT GR, V25, P2725, DOI 10.1109/TVCG.2018.2856744
   Johnsen K, 2005, P IEEE VIRT REAL ANN, P179
   Johnson A, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.127
   Kim Y, 2017, ARCH PLAST SURG-APS, V44, P179, DOI 10.5999/aps.2017.44.3.179
   King Franklin, 2016, Journal of Medical Robotics Research, V1, DOI DOI 10.1142/S2424905X16400031
   Laha B., 2014, IEEE VR WORKSHOP IMM
   LaViola JJ, 2008, IEEE COMPUT GRAPH, V28, P10, DOI 10.1109/MCG.2008.92
   Lebiedz J, 2021, IEEE T HUM-MACH SYST, V51, P535, DOI 10.1109/THMS.2021.3102520
   Li L, 2017, AM J TRANSL RES, V9, P3867
   Livatino S, 2015, IEEE T IND ELECTRON, V62, P525, DOI 10.1109/TIE.2014.2334675
   López D, 2016, IEEE T VIS COMPUT GR, V22, P1616, DOI 10.1109/TVCG.2015.2440233
   Lundström C, 2011, IEEE T VIS COMPUT GR, V17, P1775, DOI 10.1109/TVCG.2011.224
   Mandalika VBH, 2018, J DIGIT IMAGING, V31, P56, DOI 10.1007/s10278-017-0002-6
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   Mirhosseini K, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P75, DOI 10.1109/3DVis.2014.7160105
   Mirhosseini S, 2019, IEEE T VIS COMPUT GR, V25, P2011, DOI 10.1109/TVCG.2019.2898763
   Mirhosseini S, 2017, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2017.7892228
   Monclus E., 2009, PROC ACM S VIRTUAL R, P119, DOI [10.1145/1643928.1643955, DOI 10.1145/1643928.1643955]
   Nair A, 2018, EUR RADIOL, V28, P226, DOI 10.1007/s00330-017-4903-z
   Ni T, 2006, P IEEE VIRT REAL ANN, P223
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Özdemir-Güngör D, 2020, PALGR STUD INT EMERG, P163, DOI 10.1007/978-3-030-27285-2_6
   Papadopoulos C, 2015, IEEE COMPUT GRAPH, V35, P33, DOI 10.1109/MCG.2014.80
   Petkov K, 2012, IEEE T VIS COMPUT GR, V18, P1027, DOI 10.1109/TVCG.2011.278
   Schultheis U., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P117, DOI 10.1109/3DUI.2012.6184195
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Usher W, 2018, IEEE T VIS COMPUT GR, V24, P994, DOI 10.1109/TVCG.2017.2744079
   van Beurden MHPH, 2012, 3D RES, V3, DOI 10.1007/3DRes.01(2012)3
   Wang S, 2020, IEEE PAC VIS SYMP, P166, DOI 10.1109/PacificVis48177.2020.1001
   WARE C, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P37
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Wirth M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P867, DOI 10.1145/3242587.3242636
   Wong PC, 1997, VISUALIZATION '97 - PROCEEDINGS, P429, DOI 10.1109/VISUAL.1997.663914
   Wu J, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P439, DOI 10.1109/CIT.2008.Workshops.24
   Zhang F, 2020, Arxiv, DOI [arXiv:2006.10214, 10.48550/arXiv.2006.10214, DOI 10.48550/ARXIV.2006.10214]
   Zhang S, 2001, IEEE VISUAL, P437, DOI 10.1109/VISUAL.2001.964545
   Zhu Y, 1999, P IEEE VIRT REAL ANN, P84, DOI 10.1109/VR.1999.756936
NR 64
TC 3
Z9 3
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4832
EP 4844
DI 10.1109/TVCG.2022.3193672
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300002
PM 35914058
DA 2024-11-06
ER

PT J
AU Esmaeili, S
   Kabir, S
   Colas, AM
   Linder, RP
   Ragan, ED
AF Esmaeili, Shaghayegh
   Kabir, Samia
   Colas, Anthony M.
   Linder, Rhema P.
   Ragan, Eric D.
TI Evaluating Graphical Perception of Visual Motion for Quantitative Data
   Encoding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Encoding; Visualization; Data visualization; Animation; Image color
   analysis; Task analysis; Synchronization; Information visualization;
   animation and motion-related techniques; empirical study; graphical
   perception; evaluation
ID ANIMATED TRANSITIONS; TEMPORAL-CHANGES; SEARCH; MAPS; VISUALIZATION;
   EXPLORATION; DESIGN; TIME
AB Information visualization uses various types of representations to encode data into graphical formats. Prior work on visualization techniques has evaluated the accuracy of perceived numerical data values from visual data encodings such as graphical position, length, orientation, size, and color. Our work aims to extend the research of graphical perception to the use of motion as data encodings for quantitative values. We present two experiments implementing multiple fundamental aspects of motion such as type, speed, and synchronicity that can be used for numerical value encoding as well as comparing motion to static visual encodings in terms of user perception and accuracy. We studied how well users can assess the differences between several types of motion and static visual encodings and present an updated ranking of accuracy for quantitative judgments. Our results indicate that non-synchronized motion can be interpreted more quickly and more accurately than synchronized motion. Moreover, our ranking of static and motion visual representations shows that motion, especially expansion and translational types, has great potential as a data encoding technique for quantitative value. Finally, we discuss the implications for the use of animation and motion for numerical representations in data visualization.
C1 [Esmaeili, Shaghayegh; Colas, Anthony M.; Ragan, Eric D.] Univ Florida, Gainesville, FL 32611 USA.
   [Kabir, Samia] Purdue Univ, W Lafayette, IN 47907 USA.
   [Linder, Rhema P.] Univ Tennessee, Knoxville, TN 37996 USA.
C3 State University System of Florida; University of Florida; Purdue
   University System; Purdue University; University of Tennessee System;
   University of Tennessee Knoxville
RP Ragan, ED (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM esmaeili@ufl.edu; kabirs@purdue.edu; acolas1@ufl.edu; rlinder@utk.edu;
   eragan@ufl.edu
RI Esmaeili, Shaghayegh/AAP-5700-2021
OI Esmaeili, Shaghayegh/0000-0002-1547-2700; Linder,
   Rhema/0000-0003-4720-6818
CR Amano K, 2006, J NEUROSCI, V26, P3981, DOI 10.1523/JNEUROSCI.4343-05.2006
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Bach B, 2014, IEEE T VIS COMPUT GR, V20, P740, DOI 10.1109/TVCG.2013.254
   Badger Emily., 2018, Income mobility charts for girls, asian-americans and other groups. Or make your own
   Bartram L., 2002, Information Visualization, V1, P66, DOI 10.1057/palgrave/ivs/9500005
   Bartram L., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P468, DOI 10.1109/PSIVT.2010.85
   Bartram L, 2003, INT J HUM-COMPUT ST, V58, P515, DOI 10.1016/S1071-5819(03)00021-1
   Bartram L., 1997, P WORKSH NEW PAR INF, P3
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyandin I, 2012, COMPUT GRAPH FORUM, V31, P1005, DOI 10.1111/j.1467-8659.2012.03093.x
   Bui Q., 2015, The fall and rise of u.s. inequality, in 2 graphs
   Byrne L, 2016, IEEE T VIS COMPUT GR, V22, P509, DOI 10.1109/TVCG.2015.2467321
   Chalbi A, 2020, IEEE T VIS COMPUT GR, V26, P386, DOI 10.1109/TVCG.2019.2934288
   Chen HL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173991
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   Chyi HI, 2017, JOURNAL PRACT, V11, P798, DOI 10.1080/17512786.2016.1208056
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   DIBIASE D, 1992, CARTOGR GEOGR INFORM, V19, P201, DOI 10.1559/152304092783721295
   DRIVER J, 1992, PERCEPT PSYCHOPHYS, V51, P79, DOI 10.3758/BF03205076
   Du F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P289
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Etemadpour R, 2017, INFORM VISUAL, V16, P3, DOI 10.1177/1473871615606187
   G. Foundation, 2005, Gapminder tools
   Godau C, 2016, COMPUT HUM BEHAV, V59, P67, DOI 10.1016/j.chb.2016.01.036
   Griffin AL, 2006, ANN ASSOC AM GEOGR, V96, P740, DOI 10.1111/j.1467-8306.2006.00514.x
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hornbæk K, 2011, INT J HUM-COMPUT ST, V69, P509, DOI 10.1016/j.ijhcs.2011.02.007
   Huber DE, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P527
   Itoh M, 2012, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2012.6183574
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   KERLICK GD, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P124
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   MATEEFF S, 1995, VISION RES, V35, P355, DOI 10.1016/0042-6989(94)00130-E
   Matejka J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5421, DOI 10.1145/2858036.2858063
   NAKAYAMA K, 1986, NATURE, V320, P264, DOI 10.1038/320264a0
   Nowell L, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P43, DOI 10.1109/INFVIS.2002.1173146
   PETERSON MP, 1994, GIS/LIS '94 ANNUAL CONFERENCE AND EXPOSITION, PROCEEDINGS, P619
   Robbins N.B., 2012, Creating more effective graphs
   Romat H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173761
   Rufiange S, 2013, IEEE T VIS COMPUT GR, V19, P2556, DOI 10.1109/TVCG.2013.149
   Saket B, 2018, IEEE T VIS COMPUT GR, V24, P1316, DOI 10.1109/TVCG.2017.2680452
   SHORTRIDGE BG, 1982, AM CARTOGRAPHER, V9, P155, DOI 10.1559/152304082783948501
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Takeuchi T, 1997, VISION RES, V37, P2083, DOI 10.1016/S0042-6989(96)00225-8
   TREISMAN A, 1991, J EXP PSYCHOL HUMAN, V17, P652, DOI 10.1037/0096-1523.17.3.652
   van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646
   Velloso E, 2017, ACM T COMPUT-HUM INT, V24, DOI 10.1145/3064937
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P2487, DOI 10.1109/TVCG.2017.2750689
   Ware Colin., 2006, P 3 S APPL PERC GRAP, P107
   Windyty S., 2014, Windy as forecasted
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Yau N., 2020, A day in the life of americans
NR 54
TC 0
Z9 0
U1 5
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4845
EP 4857
DI 10.1109/TVCG.2022.3193756
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300003
PM 35877801
DA 2024-11-06
ER

PT J
AU Yang, FM
   Tompkin, J
   Harrison, L
   Laidlaw, DH
AF Yang, Fumeng
   Tompkin, James
   Harrison, Lane
   Laidlaw, David H.
TI Visual Cue Effects on a Classification Accuracy Estimation Task in
   Immersive Scatterplots
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Data visualization; Three-dimensional
   displays; Neural networks; Monitoring; Training; Virtual reality;
   cluster perception; information visualization; immersive analytics;
   dimension reduction; classification
ID ECOLOGICAL VALIDITY; BINOCULAR VISION; 3D SHAPE; PERFORMANCE;
   PERCEPTION; VISUALIZATION; INFORMATION; DEPTH; DISPLAY; STEREO
AB Immersive visualization in virtual reality (VR) allows us to exploit visual cues for perception in 3D space, yet few existing studies have measured the effects of visual cues. Across a desktop monitor and a head-mounted display (HMD), we assessed scatterplot designs which vary their use of visual cues-motion, shading, perspective (graphical projection), and dimensionality-on two sets of data. We conducted a user study with a summary task in which 32 participants estimated the classification accuracy of an artificial neural network from the scatterplots. With Bayesian multilevel modeling, we capture the intricate visual effects and find that no cue alone explains all the variance in estimation error. Visual motion cues generally reduce participants' estimation error; besides this motion, using other cues may increase participants' estimation error. Using an HMD, adding visual motion cues, providing a third data dimension, or showing a more complicated dataset leads to longer response times. We speculate that most visual cues may not strongly affect perception in immersive analytics unless they change people's mental model about data. In summary, by studying participants as they interpret the output from a complicated machine learning model, we advance our understanding of how to use the visual cues in immersive analytics.
C1 [Yang, Fumeng] Northwestern Univ, Dept Comp Sci, Evanston, IL 60208 USA.
   [Tompkin, James; Laidlaw, David H.] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
   [Harrison, Lane] Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
C3 Northwestern University; Brown University; Worcester Polytechnic
   Institute
RP Laidlaw, DH (corresponding author), Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
EM fy@northwestern.edu; james_tompkin@brown.edu; ltharrison@wpi.edu;
   dhl@cs.brown.edu
RI Yang, Fumeng/HME-2828-2023
OI Tompkin, James/0000-0003-2218-2899; Laidlaw, David/0000-0002-3411-7376;
   Harrison, Lane/0000-0003-3029-2799
FU NSF [IIS-2107409, 2127309]
FX This work was supported in part by hardware donations from NVIDIA, in
   part by NSF under Grant IIS-2107409, and in part by the NSF under Grant
   2127309 to the Computing Research Association for the CIFellows Project.
   This work involved human subjects or animals in its research. Approval
   of all ethical and experimental procedures and protocols was granted by
   the Brown University Human Research Protection Program under Application
   No. #0005990214, and performed in line with the federal regulations (45
   CFR 46.110).
CR Aitsiselmi Y., 2009, P STEREOSCOPIC DISPL, P229
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2325, DOI 10.1109/TVCG.2011.234
   Andrade C, 2018, INDIAN J PSYCHOL MED, V40, P498, DOI 10.4103/IJPSYM.IJPSYM_334_18
   [Anonymous], 2019, Flashing grey screen
   Artero AO, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P340, DOI 10.1109/SIBGRA.2004.1352979
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Barfield W, 1999, PRESENCE-TELEOP VIRT, V8, P237, DOI 10.1162/105474699566198
   Bastanlar Y, 2007, P IEEE 3DTV C, P1
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Belcher D, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P84, DOI 10.1109/ISMAR.2003.1240691
   BEMIS SV, 1988, HUM FACTORS, V30, P163, DOI 10.1177/001872088803000204
   Brehmer M, 2014, P 5 WORKSH TIM ERR N, P1
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BULTHOFF HH, 1988, J OPT SOC AM A, V5, P1749, DOI 10.1364/JOSAA.5.001749
   Chalmers D. J., 1992, Journal of Experimental and Theoretical Artificial Intelligence, V4, P185, DOI 10.1080/09528139208953747
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Diaz C, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P111, DOI 10.1109/ISMAR.2017.28
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Etemadpour Ronak, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P276
   Etemadpour Ronak, 2013, 2013 17th International Conference on Information Visualisation, P389, DOI 10.1109/IV.2013.51
   Falleti MG, 2006, J CLIN EXP NEUROPSYC, V28, P1095, DOI 10.1080/13803390500205718
   Farahani Navid, 2016, J Pathol Inform, V7, P22, DOI 10.4103/2153-3539.181766
   Fujisaki H., 2012, P SID S, P1190
   Gaggioli A., 2001, EMERG COMMUNICAT, P71
   Gelman A, 2012, J RES EDUC EFF, V5, P189, DOI 10.1080/19345747.2011.618213
   Georgieva SS, 2008, CEREB CORTEX, V18, P2416, DOI 10.1093/cercor/bhn002
   Gershon N, 1997, IEEE COMPUT GRAPH, V17, P29, DOI 10.1109/MCG.1997.595265
   Gracia A, 2016, INFORM VISUAL, V15, P3, DOI 10.1177/1473871614556393
   Greffard N, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P19, DOI 10.1109/3DVis.2014.7160095
   Gribble ChristiaanP., 2006, P 3 S APPL PERCEPTIO, P111
   Grottel S, 2012, IEEE PAC VIS SYMP, P209, DOI 10.1109/PacificVis.2012.6183593
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-Orallo J, 2012, J MACH LEARN RES, V13, P2813
   Huttner JP, 2017, AMCIS 2017 PROCEEDINGS
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kay M., 2020, TIDYBAYES TIDY DATA
   Kihara K., 2013, P SID S, P501
   Kirk R. E., 1995, Experimental Design, V3rd, P512
   Klein J. P., 2006, Survival analysis: techniques for censored and truncated data
   Koffka K., 1935, PRINCIPLES GESTALT P
   KOHLER W, 1967, PSYCHOL FORSCH, V31, pR18, DOI 10.1007/BF00422382
   Kosara R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P101, DOI [10.1109/VISUAL.2019.8933547, 10.1109/visual.2019.8933547]
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2018, P WORKSH CREAT CUR C, P1
   Krizhevsky A., 2009, CIFAR-10 (Canadian Institute for Advanced Research)
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Langer MS, 2000, PERCEPTION, V29, P649, DOI 10.1068/p3060
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee C, 2013, IEEE T VIS COMPUT GR, V19, P547, DOI 10.1109/TVCG.2013.41
   Legge ELG, 2012, ACTA PSYCHOL, V141, P380, DOI 10.1016/j.actpsy.2012.09.002
   Lewkowicz DJ, 2001, INFANCY, V2, P437, DOI 10.1207/S15327078IN0204_03
   LIVINGSTONE M, 1988, SCIENCE, V240, P740, DOI 10.1126/science.3283936
   Luboschik M, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P47, DOI 10.1145/3009939.3009947
   Luo X, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P59
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   McDermott Rose., 2011, CAMBRIDGE HDB EXPT P, DOI DOI 10.1017/CB09780511921452
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   McIntire J. P, 2012, Proc. SPIE, V8383
   McIntire JP, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P1, DOI 10.1109/3DVis.2014.7160093
   McIntire JP, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0020-9
   McIntire JP, 2014, DISPLAYS, V35, P18, DOI 10.1016/j.displa.2013.10.004
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   McTighe J., 2013, ESSENTIAL QUESTIONS
   Melmoth DR, 2006, EXP BRAIN RES, V171, P371, DOI 10.1007/s00221-005-0273-x
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Norman JF, 1996, J EXP PSYCHOL HUMAN, V22, P173, DOI 10.1037/0096-1523.22.1.173
   Ntuen CA, 2009, INT J IND ERGONOM, V39, P388, DOI 10.1016/j.ergon.2008.07.001
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Patla AE, 2002, EXP BRAIN RES, V142, P551, DOI 10.1007/s00221-001-0948-x
   Pinheiro J., 2017, Linear and Nonlinear Mixed Effects Models, P1
   Poco J, 2011, COMPUT GRAPH FORUM, V30, P1111, DOI 10.1111/j.1467-8659.2011.01960.x
   Prabhat, 2008, IEEE T VIS COMPUT GR, V14, P551, DOI 10.1109/TVCG.2007.70433
   Price A, 2010, J SCI EDUC TECHNOL, V19, P90, DOI 10.1007/s10956-009-9182-2
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Raja D., 2004, PROC IMMERSIVE PROJE, P61
   Raja D., 2006, Master's thesis
   Rauber PE, 2018, INFORM VISUAL, V17, P282, DOI 10.1177/1473871617713337
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Redmond S, 2019, P IEEE VIS C, P1
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Rosenbaum R., 2011, Advances in Visual Computing, P530
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Scheer F., 2010, J. WSCG, V18, P113
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   SHOEMAKE K, 1992, GRAPH INTER, P151
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Simpson M, 2017, WORKSH IMM AN IA IEE, P1
   Smilkov D., 2020, Embedding projector-Visualization of high-dimensional data
   Staib J, 2015, COMPUT GRAPH FORUM, V34, P151, DOI 10.1111/cgf.12627
   Stan Development Team, 2021, Stan modeling language users guide and reference manual
   Stinson C, 2011, P HUM SYST INT S, P1
   Sukhbaatar S, 2015, Arxiv, DOI arXiv:1503.08895
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tatarchuk N, 2009, P ACM SIGGRAPH COURS
   Todd JT, 2003, PERCEPT PSYCHOPHYS, V65, P31, DOI 10.3758/BF03194781
   Tory M, 2007, IEEE T VIS COMPUT GR, V13, P1262, DOI 10.1109/TVCG.2007.70596
   Tory M, 2009, IEEE T VIS COMPUT GR, V15, P1033, DOI 10.1109/TVCG.2009.127
   Trommershauser J., 2012, SENSORY CUE INTEGRAT, DOI [10.1093/acprof:oso/9780195387247.001.0001, DOI 10.1093/ACPROF:OSO/9780195387247.001.0001]
   van Beurden M. H., 2009, P HUM VIS EL IM, V7240, P74
   van Beurden Maurice H. P. H., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P176, DOI 10.1109/QOMEX.2010.5516268
   van Beurden MHPH, 2011, PROC SPIE, V7863, DOI 10.1117/12.872566
   Van Schooten B W., 2010, Proceedings of the international conference on advanced visual interfaces, P167, DOI [DOI 10.1145/1842993, 10.1145/1842993]
   Vuong QC, 2006, PERCEPTION, V35, P145, DOI 10.1068/p5315
   Wagner JA, 2018, COMPUT GRAPH FORUM, V37, P415, DOI 10.1111/cgf.13430
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wang B, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P37, DOI 10.1109/3DVis.2014.7160098
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   Wanger L., 1992, ACM I3D Symposium on Interactive 3D Graphics, P39, DOI [10.1145/147156.147161, DOI 10.1145/147156.147161]
   WANGER LR, 1992, IEEE COMPUT GRAPH, V12, P44, DOI 10.1109/38.135913
   Ware C., 2005, Proceedings of the 2nd Symposium on Applied Perception in Graphics and Visualization (A Corona, Spain, August 26 - 28, V95, P51
   Wässle H, 2004, NAT REV NEUROSCI, V5, P747, DOI 10.1038/nrn1497
   Welchman AE, 2005, NAT NEUROSCI, V8, P820, DOI 10.1038/nn1461
   Weston J., 2015, P INT C LEARN REPR, P1
   Whitlock M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P41, DOI 10.1109/VR.2018.8446381
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   Xiao H, 2017, Arxiv, DOI arXiv:1708.07747
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
NR 128
TC 0
Z9 0
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4858
EP 4873
DI 10.1109/TVCG.2022.3192364
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300004
PM 35857736
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, CY
   Yang, L
   Chen, N
   Vining, N
   Sheffer, A
   Lau, FCM
   Wang, GP
   Wang, WP
AF Zhang, Congyi
   Yang, Lei
   Chen, Nenglun
   Vining, Nicholas
   Sheffer, Alla
   Lau, Francis C. M.
   Wang, Guoping
   Wang, Wenping
TI CreatureShop: Interactive 3D Character Modeling and Texturing From a
   Single Color Drawing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Solid modeling; Shape; Surface texture;
   Geometry; Electronic mail; Annotations; Character modeling; character
   texturing; interactive techniques
ID RECONSTRUCTION; ANIMALS
AB Creating 3D shapes from 2D drawings is an important problem with applications in content creation for computer animation and virtual reality. We introduce a new sketch-based system, CreatureShop, that enables amateurs to create high-quality textured 3D character models from 2D drawings with ease and efficiency. CreatureShop takes an input bitmap drawing of a character (such as an animal or other creature), depicted from an arbitrary descriptive pose and viewpoint, and creates a 3D shape with plausible geometric details and textures from a small number of user annotations on the 2D drawing. Our key contributions are a novel oblique view modeling method, a set of systematic approaches for producing plausible textures on the invisible or occluded parts of the 3D character (as viewed from the direction of the input drawing), and a user-friendly interactive system. We validate our system and methods by creating numerous 3D characters from various drawings, and compare our results with related works to show the advantages of our method. We perform a user study to evaluate the usability of our system, which demonstrates that our system is a practical and efficient approach to create fully-textured 3D character models for novice users.
C1 [Zhang, Congyi; Yang, Lei; Chen, Nenglun; Lau, Francis C. M.] Univ Hong Kong, Hong Kong, Peoples R China.
   [Vining, Nicholas] NVIDIA, Toronto, ON, Canada.
   [Vining, Nicholas; Sheffer, Alla] Univ British Columbia, Vancouver, BC, Canada.
   [Wang, Guoping] Peking Univ, Beijing 100871, Peoples R China.
   [Wang, Wenping] Texas A&M Univ, College Stn, TX 77843 USA.
C3 University of Hong Kong; University of British Columbia; Peking
   University; Texas A&M University System; Texas A&M University College
   Station
RP Wang, GP (corresponding author), Peking Univ, Beijing 100871, Peoples R China.; Wang, WP (corresponding author), Texas A&M Univ, College Stn, TX 77843 USA.
EM cyzhang@cs.hku.hk; lyang@cs.hku.hk; nolenc@hku.hk; nvining@cs.ubc.ca;
   sheffa@cs.ubc.ca; fcmlau@cs.hku.hk; wgp@pku.edu.cn; wenping@tamu.edu
RI wang, guoping/KQU-3394-2024
OI Sheffer, Alla/0000-0001-9251-3716; Zhang, Congyi/0000-0002-4259-2863
FU Research Council of Hong Kong [GRF 17211017]; National Sciences and
   Engineering Research Council of Canada (NSERC) [RGPIN-2018-03944]
FX The work of Wenping Wang was supported in part by the Research Council
   of Hong Kong, under Grant GRF 17211017. The work of Alla Sheffer was
   supported in part by Adobe, and in part by the National Sciences and
   Engineering Research Council of Canada (NSERC) under Grant
   RGPIN-2018-03944 (Broad-Based Computational Shape Design).
CR 3DS MAX, 2021, About us
   Andrews J, 2011, COMPUT GRAPH FORUM, V30, P1850, DOI 10.1111/j.1467-8659.2011.01966.x
   [Anonymous], 2011, P 8 EUR S SKETCH BAS, DOI [10.1145/2021164.2021189, DOI 10.1145/2021164.2021189]
   Bae SH, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P151
   Barnes Connelly, 2017, [Computational Visual Media, 计算可视媒体], V3, P3
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bessmeltsev M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2801134
   Borosán P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366217
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI [10.1371/journal.pone.0170531, DOI 10.1371/JOURNAL.PONE.0170531]
   Buchanan P., 2013, Proceedings of the international symposium on sketch-based interfaces and modeling, P5, DOI 10.1145/2487381.2487385
   Carr NA, 2004, ACM T GRAPHIC, V23, P845, DOI 10.1145/1015706.1015809
   Chen X., 2012, Adobe Tech. Rep. 2012-2
   Cordier F, 2011, IEEE T VIS COMPUT GR, V17, P1650, DOI 10.1109/TVCG.2010.258
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Dvoroznák M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417805
   Entem E, 2015, COMPUT GRAPH-UK, V46, P221, DOI 10.1016/j.cag.2014.09.037
   Feng LL, 2017, P IEEE VIRT REAL ANN, P195, DOI 10.1109/VR.2017.7892247
   Gal R, 2010, COMPUT GRAPH FORUM, V29, P479, DOI 10.1111/j.1467-8659.2009.01617.x
   Gingold Y, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1618452.1616494, 10.1145/1618452.1618494]
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   IGARASHI T., 2001, P 2001 S INTERACTIVE, P209
   Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23
   Kanazawa A, 2016, COMPUT GRAPH FORUM, V35, P365, DOI 10.1111/cgf.12838
   Karpenko OA, 2006, ACM T GRAPHIC, V25, P589, DOI 10.1145/1141911.1141928
   Kraevoy Vladislav, 2009, P 6 EUR S SKETCH BAS, P37, DOI DOI 10.1145/1572741.1572749]
   Li CJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275051
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Melvær EL, 2012, COMPUT GRAPH FORUM, V31, P2423, DOI 10.1111/j.1467-8659.2012.03187.x
   Nealen A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276429, 10.1145/1239451.1239492]
   Olsen L, 2011, IEEE COMPUT GRAPH, V31, P24, DOI 10.1109/MCG.2011.84
   Rabinovich M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2983621
   Ramos S, 2018, COMPUT GRAPH-UK, V77, P97, DOI 10.1016/j.cag.2018.09.009
   Schmidt R., 2009, P 6 EUR S SKETCH BAS, P133, DOI [10.1145/1572741.1572765, DOI 10.1145/1572741.1572765]
   Schmidt R, 2006, ACM T GRAPHIC, V25, P605, DOI 10.1145/1141911.1141930
   Turk G, 2001, COMP GRAPH, P347, DOI 10.1145/383259.383297
   Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298
   Wu SZ, 2020, PROC CVPR IEEE, P1, DOI 10.1109/CVPR42600.2020.00008
   Yeh CK, 2017, IEEE T VIS COMPUT GR, V23, P1796, DOI 10.1109/TVCG.2016.2574705
   ZBrush, 2021, About us
   Zhou K, 2005, ACM T GRAPHIC, V24, P1148, DOI 10.1145/1073204.1073325
   Zuffi S, 2019, IEEE I CONF COMP VIS, P5358, DOI 10.1109/ICCV.2019.00546
NR 41
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4874
EP 4890
DI 10.1109/TVCG.2022.3197560
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300005
PM 35944000
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, H
   Li, F
   Zhao, JH
   Tan, C
   Shen, DM
   Liu, YB
   Yu, T
AF Zhang, He
   Li, Fan
   Zhao, Jianhui
   Tan, Chao
   Shen, Dongming
   Liu, Yebin
   Yu, Tao
TI Controllable Free Viewpoint Video Reconstruction Based on Neural
   Radiance Fields and Motion Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Training; Surface reconstruction; Shape;
   Image reconstruction; Dynamics; Aerospace electronics; Controllable free
   viewpoint video; NeRF; motion graph; surface-guided volumetric rendering
AB In this paper, we propose a controllable high-quality free viewpoint video generation method based on the motion graph and neural radiance fields (NeRF). Different from existing pose-driven NeRF or time/structure conditioned NeRF works, we propose to first construct a directed motion graph of the captured sequence. Such a sequence-motion-parameterization strategy not only enables flexible pose control for free viewpoint video rendering but also avoids redundant calculation of similar poses and thus improves the overall reconstruction efficiency. Moreover, to support body shape control without losing the realistic free viewpoint rendering performance, we improve the vanilla NeRF by combining explicit surface deformation and implicit neural scene representations. Specifically, we train a local surface-guided NeRF for each valid frame on the motion graph, and the volumetric rendering was only performed in the local space around the real surface, thus enabling plausible shape control ability. As far as we know, our method is the first method that supports both realistic free viewpoint video reconstruction and motion graph-based user-guided motion traversal. The results and comparisons further demonstrate the effectiveness of the proposed method.
C1 [Zhang, He; Li, Fan; Zhao, Jianhui] Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing 100191, Peoples R China.
   [Tan, Chao] Weilan Tech Co, Beijing 100083, Peoples R China.
   [Shen, Dongming] Univ Southern Calif, Los Angeles, CA 90089 USA.
   [Liu, Yebin; Yu, Tao] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Liu, Yebin; Yu, Tao] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
C3 Beihang University; University of Southern California; Tsinghua
   University; Tsinghua University
RP Zhao, JH (corresponding author), Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing 100191, Peoples R China.
EM zhanghebuaa@163.com; lifan@buaa.edu.cn; zhaojianhui@buaa.edu.cn;
   chao.tan333@139.com; alvinshe@usc.edu; liuyebin@tsinghua.edu.cn;
   ytrock@126.com
RI Zhang, Guo-Hua/AAM-7264-2021
OI Zhao, Jianhui/0000-0002-5275-4846; Zhang, He/0000-0002-7280-6746; Li,
   Fan/0000-0002-1128-7559
FU National Natural Science Foundation of China [62171255, 62125107];
   National Key R&D Program of China [2022YFF0902201]; Guoqiang Institute,
   Tsinghua University [2021GQG0001]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62171255 and 62125107, in part by the
   National Key R&D Program of China under Grant 2022YFF0902201, and in
   part by Guoqiang Institute, Tsinghua University under Grant 2021GQG0001.
CR Alldieck T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5441, DOI 10.1109/ICCV48922.2021.00541
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Doshi A, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P73
   Gafni G, 2021, PROC CVPR IEEE, P8645, DOI 10.1109/CVPR46437.2021.00854
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Gu J., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Habermann M, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459749
   Hensel M, 2017, ADV NEUR IN, V30
   Li K, 2017, IEEE T CIRC SYST VID, V27, P771, DOI 10.1109/TCSVT.2016.2556419
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu L., 2021, ACM T GRAPHIC, V40, P1
   Liu YM, 2021, ADJUNCT PROCEEDINGS OF THE 34TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2021, P26, DOI 10.1145/3474349.3480219
   Lombardi S, 2021, ACM T GRAPHIC, V40, DOI [10.1145/3450626.3459863, 10.1145/3476576.3476608]
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mordatch I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185539
   Neff T., 2021, COMPUT GRAPH FORUM, V40, P45, DOI [10.1111/cgf.14340, DOI 10.1111/CGF.14340]
   Ost J, 2021, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR46437.2021.00288
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Prada F, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925967
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Raj A, 2021, Arxiv, DOI arXiv:2101.02697
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Schwarz K, 2020, ARXIV200702442, V33
   Shao R., 2022, P IEEECVF C COMPUTER, P15872
   Su SY, 2021, ADV NEUR IN, V34
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Wang JS, 2021, PROC CVPR IEEE, P9396, DOI 10.1109/CVPR46437.2021.00928
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2021, PROC CVPR IEEE, P5700, DOI 10.1109/CVPR46437.2021.00565
   Weng CY, 2020, Arxiv, DOI arXiv:2012.12884
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Xu Hongyi, 2021, Advances in Neural Information Processing Systems (NeurIPS), V34, P14955
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu T, 2020, IEEE T PATTERN ANAL, V42, P2523, DOI 10.1109/TPAMI.2019.2928296
   Zhang JK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459756
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 43
TC 2
Z9 2
U1 6
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4891
EP 4905
DI 10.1109/TVCG.2022.3192713
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300006
PM 35914057
DA 2024-11-06
ER

PT J
AU Yuan, GZQ
   Fu, QC
   Mi, ZX
   Luo, YM
   Tao, WB
AF Yuan, Ganzhangqin
   Fu, Qiancheng
   Mi, Zhenxing
   Luo, Yiming
   Tao, Wenbing
TI SSRNet: Scalable 3D Surface Reconstruction Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surface reconstruction; Point cloud compression; Octrees; Surface
   treatment; Learning systems; Three-dimensional displays; Reconstruction
   algorithms; Surface reconstruction; implicit function; oriented point
   clouds; large-scale point clouds
ID POINTS
AB Learning-based surface reconstruction methods have received considerable attention in recent years due to their excellent expressiveness. However, existing learning-based methods lack scalability in processing large-scale point clouds. This paper proposes a novel scalable learning-based 3D surface reconstruction method based on octree, called SSRNet. SSRNet works in a scalable reconstruction pipeline, which divides oriented point clouds into different local parts and then processes them in parallel. Accommodating this scalable design pattern, SSRNet constructs local geometric features for octree vertices. Such features comprise the relation between the vertices and the implicit surface, ensuring geometric perception. Focusing on local geometric information also enables the network to avoid the overfitting problem and generalize well on different datasets. Finally, as a learning-based method, SSRNet can process large-scale point clouds in a short time. And to further solve the efficiency problem, we provide a lightweight and efficient version that is about five times faster while maintaining reconstruction performance. Experiments show that our methods achieve state-of-the-art performance with outstanding efficiency.
C1 [Yuan, Ganzhangqin; Fu, Qiancheng; Tao, Wenbing] Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Sch Artificial Intelligence & Automat, Wuhan 430074, Hubei, Peoples R China.
   [Mi, Zhenxing] Hong Kong Univ Sci & Technol, Kowloon Tong, Hong Kong, Peoples R China.
   [Luo, Yiming] Imperial Coll London, London SW7 2AZ, England.
C3 Huazhong University of Science & Technology; Hong Kong University of
   Science & Technology; Imperial College London
RP Tao, WB (corresponding author), Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Sch Artificial Intelligence & Automat, Wuhan 430074, Hubei, Peoples R China.
EM gzq_yuan@hust.edu.cn; fqc98@hust.edu.cn; zmiaa@connect.ust.hk;
   yiming_luo@163.com; wenbingtao@hust.edu.cn
OI Tao, Wenbing/0000-0003-3284-864X; Mi, Zhenxing/0000-0001-6526-1621
FU National Natural Science Foundation of China [62176096]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62176096.
CR Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Badki A, 2020, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR42600.2020.00292
   Barhak J, 2001, IEEE T VIS COMPUT GR, V7, P1, DOI 10.1109/2945.910817
   BAUMGART B., 1975, NATL COMPUTER C AFIP, P589, DOI DOI 10.1145/1499949.1500071
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   BOISSONNAT JD, 1993, P SOC PHOTO-OPT INS, V1905, P964, DOI 10.1117/12.148710
   Boltcheva D, 2017, COMPUT AIDED DESIGN, V90, P123, DOI 10.1016/j.cad.2017.05.011
   Brock A, 2016, Arxiv, DOI [arXiv:1608.04236, 10.48550/arXiv.1608.04236]
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Chen ZQ, 2020, PROC CVPR IEEE, P42, DOI 10.1109/CVPR42600.2020.00012
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Duan Yueqi, 2020, P EUR C COMP VIS, V16, P51, DOI [DOI 10.1007/978-3-030-58598-34, 10.1007/978-3-030-58598-3]
   EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635
   Erler Philipp, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P108, DOI 10.1007/978-3-030-58558-7_7
   Evrard F, 2019, IEEE T VIS COMPUT GR, V25, P1629, DOI 10.1109/TVCG.2018.2809751
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   Hanocka R, 2020, Arxiv, DOI arXiv:2005.11084
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M., 2005, PROC 3 EUROGRAPH S G
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Labatut P, 2009, COMPUT GRAPH FORUM, V28, P2275, DOI 10.1111/j.1467-8659.2009.01530.x
   Labatut P, 2007, IEEE I CONF COMP VIS, P504
   Levin D, 2004, MATH VISUAL, P37
   Liao YY, 2018, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR.2018.00308
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Manson J, 2008, COMPUT GRAPH FORUM, V27, P1411, DOI 10.1111/j.1467-8659.2008.01281.x
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Metzer G, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459835
   Mi ZX, 2020, PROC CVPR IEEE, P967, DOI 10.1109/CVPR42600.2020.00105
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nie YY, 2020, PROC CVPR IEEE, P52, DOI 10.1109/CVPR42600.2020.00013
   Ohtake Y, 2005, GRAPH MODELS, V67, P150, DOI 10.1016/j.gmod.2004.06.003
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Peng S., 2020, ECCV, P523
   Peng SY, 2021, ADV NEUR IN, V34
   Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017
   Rocchini C, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P296, DOI 10.1109/SMA.2001.923401
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Stanford 3D, 2013, The Stanford 3D scanning repository
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Vakalopoulou M, 2018, LECT NOTES COMPUT SC, V11073, P658, DOI 10.1007/978-3-030-00937-3_75
   Williams F, 2019, PROC CVPR IEEE, P10122, DOI 10.1109/CVPR.2019.01037
   Wu JJ, 2016, ADV NEUR IN, V29
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xu Q., 2020, PROC AAAI C ARTIF IN, p12 508
   Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563
   Yao Y, 2020, PROC CVPR IEEE, P528, DOI 10.1109/CVPR42600.2020.00061
   Zhou K, 2011, IEEE T VIS COMPUT GR, V17, P669, DOI 10.1109/TVCG.2010.75
NR 61
TC 3
Z9 3
U1 8
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4906
EP 4919
DI 10.1109/TVCG.2022.3193406
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300007
PM 35877800
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cárdenas, JL
   Ogayar, CJ
   Feito, FR
   Jurado, JM
AF Cardenas, Jose L.
   Ogayar, Carlos J.
   Feito, Francisco R.
   Jurado, Juan M.
TI Modeling of the 3D Tree Skeleton Using Real-World Data: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Vegetation; Three-dimensional displays; Solid modeling; Data models;
   Skeleton; Image reconstruction; Geometry; Tree modeling; 3D
   reconstruction; real-world data processing; computational geometry;
   realistic rendering
ID CROWN DELINEATION; RECONSTRUCTION; TERRESTRIAL; EFFICIENT; SYSTEMS;
   IMAGES; LIDAR
AB Tree modeling has been extensively studied in computer graphics. Recent advances in the development of high-resolution sensors and data processing techniques are extremely useful for collecting 3D datasets of real-world trees and generating increasingly plausible branching structures. The wide availability of versatile acquisition platforms allows us to capture multi-view images and scanned data that can be used for guided 3D tree modeling. In this paper, we carry out a comprehensive review of the state-of-the-art methods for the 3D modeling of botanical tree geometry by taking input data from real scenarios. A wide range of studies has been proposed following different approaches. The most relevant contributions are summarized and classified into three categories: (1) procedural reconstruction, (2) geometry-based extraction, and (3) image-based modeling. In addition, we describe other approaches focused on the reconstruction process by adding additional features to achieve a realistic appearance of the tree models. Thus, we provide an overview of the most effective procedures to assist researchers in the photorealistic modeling of trees in geometry and appearance. The article concludes with remarks and trends for promising research opportunities in 3D tree modeling using real-world data.
C1 [Cardenas, Jose L.; Ogayar, Carlos J.; Feito, Francisco R.] Univ Jaen, Dept Comp Sci, Jaen 23071, Spain.
   [Jurado, Juan M.] Univ Granada, Dept Software Engn, Granada 18014, Spain.
C3 Universidad de Jaen; University of Granada
RP Jurado, JM (corresponding author), Univ Granada, Dept Software Engn, Granada 18014, Spain.
EM jcdonoso@ujaen.es; cogayar@ujaen.es; ffeito@ujaen.es; jjurado@ugr.es
RI ; Feito, Francisco/M-1672-2014; Ogayar Anguita, Carlos
   Javier/K-2166-2017
OI Jurado, Juan M./0000-0002-8009-9033; Cardenas-Donoso, Jose
   Luis/0000-0002-0315-4094; Feito, Francisco/0000-0001-8230-6529; Ogayar
   Anguita, Carlos Javier/0000-0003-0958-990X
FU MCIN/AEI; Junta de Andaluci'a (Spain); European Union's ERDF funds
   [PID2021-126339OB-I00, 1381202-GEU, PYC20-RE-005-UJA]; Spanish Ministry
   of Science, Innovation and Universities [FPU17/01902]
FX This work was supported in part by MCIN/AEI/10.13039/501100011033, Junta
   de Andaluci ' a (Spain), and European Union's ERDF funds under Projects
   PID2021-126339OB-I00, 1381202-GEU, and PYC20-RE-005-UJA, and in part by
   the Spanish Ministry of Science, Innovation and Universities through the
   Doctoral Grant to the first author under Grant FPU17/01902.
CR Argudo O, 2020, COMPUT GRAPH FORUM, V39, P174, DOI 10.1111/cgf.13752
   Argudo O, 2016, COMPUT GRAPH-UK, V57, P55, DOI 10.1016/j.cag.2016.03.005
   Bartolozzi J, 2017, ACM SIGGRAPH 2017 TALKS, DOI 10.1145/3084363.3085065
   Benes B, 2011, COMPUT GRAPH FORUM, V30, P325, DOI 10.1111/j.1467-8659.2011.01886.x
   Benes B, 2002, COMP ANIM CONF PROC, P33, DOI 10.1109/CA.2002.1017504
   Binney J, 2009, IEEE INT CONF ROBOT, P3183
   Blum H., 1967, Models for Perception of Speech and Visual Form
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Boudon F., 2006, LIRIS UMR CNRS5205, Res. Rep. 2301
   Bradley D, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461952
   Bucksch A, 2008, ISPRS J PHOTOGRAMM, V63, P115, DOI 10.1016/j.isprsjprs.2007.10.004
   Bucksch A, 2014, APPL PLANT SCI, V2, DOI 10.3732/apps.1400005
   Cao C, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338130
   Chaudhury Ayan, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P244, DOI 10.1007/978-3-030-65414-6_18
   Chen XJ, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409062
   Cheng ZL, 2007, J COMPUT SCI TECH-CH, V22, P846, DOI 10.1007/s11390-007-9095-6
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013
   Delagrange S, 2014, SENSORS-BASEL, V14, P4271, DOI 10.3390/s140304271
   Deussen O., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P275, DOI 10.1145/280814.280898
   Douglas D. H., 1973, Cartogr. Int. J. Geogr. Inf. Geovis, V10, P112, DOI DOI 10.3138/FM57-6770-U75U-7727
   Du SL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11182074
   Ecormier-Nocca P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459952
   Favorskaya M. N., 2017, Handbook on Advances in Remote Sensing and Geographic Information Systems, P181
   Fu LX, 2020, IEEE ACCESS, V8, P27327, DOI 10.1109/ACCESS.2020.2971549
   Gao LM, 2019, EARTH SCI INFORM, V12, P161, DOI 10.1007/s12145-018-0365-3
   Gatziolis D, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137765
   Gong Y., 2018, INT ARCH PHOTOGRAMM, V42, P403, DOI [10.5194/isprs-archives-XLII-3-403-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-3-403-2018]
   Gorte B., 2004, International Archives of Photogrammetry and Remote Sensing, V35, P929
   Graciano A, 2021, IEEE T VIS COMPUT GR, V27, P3733, DOI 10.1109/TVCG.2020.2981565
   Guanbo Bao, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P217, DOI 10.1109/ISVRI.2011.5759637
   Guenard Jerome, 2014, Mathematical Methods for Curves and Surfaces. 8th International Conference, MMCS 2012. Revised Selected Papers: LNCS 8177, P213, DOI 10.1007/978-3-642-54382-1_12
   Guénard J, 2013, LECT NOTES COMPUT SC, V8033, P322, DOI 10.1007/978-3-642-41914-0_32
   Guo JW, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3394105
   Guo JW, 2020, IEEE T VIS COMPUT GR, V26, P1372, DOI 10.1109/TVCG.2018.2869784
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Hädrich T, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13106
   He GZ, 2018, PERS UBIQUIT COMPUT, V22, P903, DOI 10.1007/s00779-018-1153-2
   Hinks T, 2013, J SURV ENG, V139, P72, DOI 10.1061/(ASCE)SU.1943-5428.0000097
   Huang H, 2007, LECT NOTES COMPUT SC, V4713, P385
   Huang HY, 2015, PROCEEDINGS 2015 SECOND IEEE INTERNATIONAL CONFERENCE ON SPATIAL DATA MINING AND GEOGRAPHICAL KNOWLEDGE SERVICES (ICSDM 2015), P152, DOI 10.1109/ICSDM.2015.7298043
   Isokane T, 2018, PROC CVPR IEEE, P2906, DOI 10.1109/CVPR.2018.00307
   Jaskierniak D, 2021, ISPRS J PHOTOGRAMM, V171, P171, DOI 10.1016/j.isprsjprs.2020.10.016
   Junjie Cao, 2010, Proceedings of the Shape Modeling International (SMI 2010), P187, DOI 10.1109/SMI.2010.25
   Jurado JM, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091430
   Jurado JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082244
   Kolmanic S, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106931
   Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235
   Kuzelka K, 2021, ISPRS J PHOTOGRAMM, V178, P259, DOI 10.1016/j.isprsjprs.2021.06.013
   Lee D, 2018, INT CONF IMAG VIS
   Li BS, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480525
   Li C, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024161
   Li RH, 2017, INT J OPT, V2017, DOI 10.1155/2017/5408503
   Lin Y., 2020, arXiv
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P300, DOI 10.1016/0022-5193(68)90080-5
   Lindenmayer A, 1974, Adding Continuous Components to L-Systems, P53
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Lisein J, 2013, FORESTS, V4, P922, DOI 10.3390/f4040922
   Liu YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480486
   Liu ZH, 2021, GRAPH MODELS, V117, DOI 10.1016/j.gmod.2021.101115
   Livny Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866177
   Long J, 2013, INT J COMPUT GAMES T, V2013, DOI 10.1155/2013/363160
   Longay A., 2012, P INT S SBIM, P107, DOI [DOI 10.2312/SBM/SBM12/107-120, 10.2312/SBM/ SBM12/107-120]
   López A, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3165746
   Lopez LD, 2010, COMPUT GRAPH FORUM, V29, P2075, DOI 10.1111/j.1467-8659.2010.01794.x
   Lou L, 2014, LECT NOTES COMPUT SC, V8815, P349, DOI 10.1007/978-3-319-11755-3_39
   Lu YW, 2021, MULTIMED TOOLS APPL, V80, P17315, DOI 10.1007/s11042-020-10069-3
   Makowski M., 2021, PROC EGU GEN ASSEM C, pEGU2116
   Makowski M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323039
   Mech R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P397, DOI 10.1145/237170.237279
   Mongus D, 2015, ISPRS J PHOTOGRAMM, V108, P219, DOI 10.1016/j.isprsjprs.2015.08.004
   Mündermann L, 2003, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P60, DOI 10.1109/CGI.2003.1214448
   Neubert B, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239539
   Okabe M, 2005, COMPUT GRAPH FORUM, V24, P487, DOI 10.1111/j.1467-8659.2005.00874.x
   Palubicki W, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531364
   Palubicki W, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530146
   Pirk S., 2016, P ACM SIGGRAPH COURS
   Pirk S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661252
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366188
   Pirk S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185546
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814
   Pollefeys M, 2002, COMMUN ACM, V45, P50, DOI 10.1145/514236.514263
   Pradal C, 2009, GRAPH MODELS, V71, P1, DOI 10.1016/j.gmod.2008.10.001
   Preuksakarn C., 2010, 6th International Workshop on Functional-Structural Plant Models, P12
   Prusinkiewicz P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P351, DOI 10.1145/192161.192254
   Prusinkiewicz Przemyslaw, 1996, The Algorithmic Beauty of Plants
   Qi CR, 2017, ADV NEUR IN, V30
   Qi JB, 2018, INT GEOSCI REMOTE SE, P3975, DOI 10.1109/IGARSS.2018.8517627
   Qing Xiong, 2010, Proceedings of the 2010 International Conference on Electrical and Control Engineering (ICECE 2010), P3033, DOI 10.1109/iCECE.2010.738
   Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929
   Reche A, 2004, ACM T GRAPHIC, V23, P720, DOI 10.1145/1015706.1015785
   Reeves W. T., 1985, Computer Graphics, V19, P313, DOI 10.1145/325165.325250
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI [10.1145/357318.357320, 10.1145/964967.801167]
   Rodkaew Y, 2003, PLANT GROWTH MODELING AND APPLICATIONS, PROCEEDINGS, P210
   Runions Adam, 2007, P EUR C NAT PHEN, P63
   Saha PK, 2016, PATTERN RECOGN LETT, V76, P3, DOI 10.1016/j.patrec.2015.04.006
   Sakaguchi T, 1998, PROC ACM SIGGRAPH C
   Santos TT, 2015, LECT NOTES COMPUT SC, V8928, P247, DOI 10.1007/978-3-319-16220-1_18
   Sen SI, 2005, COMPUT GRAPH-UK, V29, P805, DOI 10.1016/j.cag.2005.08.025
   Shao J, 2020, ISPRS J PHOTOGRAMM, V163, P214, DOI 10.1016/j.isprsjprs.2020.03.008
   Sherbrooke EC, 1996, GRAPH MODEL IM PROC, V58, P574, DOI 10.1006/gmip.1996.0047
   Shlyakhter I, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.920627
   Smith A. R., 1984, Computers & Graphics, V18, P1
   Spezialetti R, 2020, INT CONF 3D VISION, P160, DOI 10.1109/3DV50981.2020.00026
   Stam J, 1997, COMPUT GRAPH FORUM, V16, pC159, DOI 10.1111/1467-8659.00152
   Stava O, 2014, COMPUT GRAPH FORUM, V33, P118, DOI 10.1111/cgf.12282
   Su ZX, 2011, MATH COMPUT MODEL, V54, P1115, DOI 10.1016/j.mcm.2010.11.043
   Su ZH, 2019, INT GEOSCI REMOTE SE, P6091, DOI [10.1109/IGARSS.2019.8900614, 10.1109/igarss.2019.8900614]
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Surovy P, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8020123
   Tan P, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409061
   Tan P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239538
   Teng C.-H., 2005, PROC IAPR C MACH VIS, P59
   Teng CH, 2009, VISUAL COMPUT, V25, P297, DOI 10.1007/s00371-008-0269-1
   Tu YH, 2020, ISPRS J PHOTOGRAMM, V160, P83, DOI 10.1016/j.isprsjprs.2019.12.006
   Ulam S., 1962, P S APPL MATH, V14, P215
   Verroust A, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P194, DOI 10.1109/SMA.1999.749340
   Wang BH, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073655
   Wang G, 2018, COMPUT GRAPH FORUM, V37, P185, DOI 10.1111/cgf.13501
   Wang G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3144456
   Wang XY, 2014, INT GEOSCI REMOTE SE, P796, DOI 10.1109/IGARSS.2014.6946544
   Wang Z, 2014, IEEE T GEOSCI REMOTE, V52, P5653, DOI 10.1109/TGRS.2013.2291815
   Xie K, 2016, IEEE T VIS COMPUT GR, V22, P2608, DOI 10.1109/TVCG.2015.2513409
   Xu H, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289610
   Xu SB, 2015, IEEE T IMAGE PROCESS, V24, P2182, DOI 10.1109/TIP.2015.2416654
   Yan DM, 2009, INT C COMP AID DES C, P572, DOI 10.1109/CADCG.2009.5246837
   Yuan Q, 2021, COMPUT GRAPH-UK, V94, P132, DOI 10.1016/j.cag.2020.12.001
   Zeng JG, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P445
   Zhang XP, 2014, IEEE T VIS COMPUT GR, V20, P1214, DOI 10.1109/TVCG.2014.2316001
   Zhu C., 2009, PROC PLANT GROWTH MO, P352, DOI [10.1109/PMA.2009.19, DOI 10.1109/PMA.2009.19]
NR 130
TC 4
Z9 4
U1 5
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4920
EP 4935
DI 10.1109/TVCG.2022.3193018
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300008
PM 35862319
DA 2024-11-06
ER

PT J
AU Erickson, A
   Bruder, G
   Welch, GF
AF Erickson, Austin
   Bruder, Gerd
   Welch, Gregory F.
TI Analysis of the Saliency of Color-Based Dichoptic Cues in Optical
   See-Through Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Observers; Image color analysis; Optical
   saturation; Optical imaging; Color; Augmented reality; optical
   see-through displays; visual perception; attention cues; preattentive
   cues; dichoptic cues; human-computer interaction (HCI)
ID VISUAL-SEARCH; EYE; BINOCULARITY; CONTRAST
AB In a future of pervasive augmented reality (AR), AR systems will need to be able to efficiently draw or guide the attention of the user to visual points of interest in their physical-virtual environment. Since AR imagery is overlaid on top of the user's view of their physical environment, these attention guidance techniques must not only compete with other virtual imagery, but also with distracting or attention-grabbing features in the user's physical environment. Because of the wide range of physical-virtual environments that pervasive AR users will find themselves in, it is difficult to design visual cues that "pop out" to the user without performing a visual analysis of the user's environment, and changing the appearance of the cue to stand out from its surroundings. In this article, we present an initial investigation into the potential uses of dichoptic visual cues for optical see-through AR displays, specifically cues that involve having a difference in hue, saturation, or value between the user's eyes. These types of cues have been shown to be preattentively processed by the user when presented on other stereoscopic displays, and may also be an effective method of drawing user attention on optical see-through AR displays. We present two user studies: one that evaluates the saliency of dichoptic visual cues on optical see-through displays, and one that evaluates their subjective qualities. Our results suggest that hue-based dichoptic cues or "Forbidden Colors" may be particularly effective for these purposes, achieving significantly lower error rates in a pop out task compared to value-based and saturation-based cues.
C1 [Erickson, Austin; Bruder, Gerd; Welch, Gregory F.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Erickson, A (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM ericksona@knights.ucf.edu; gerd.bruder@ucf.edu; welch@ucf.edu
RI Erickson, Austin/AAV-9677-2020
OI Welch, Gregory/0000-0002-8243-646X; Erickson, Austin/0000-0002-3146-8023
FU National Science Foundation [1800961]; Office of Naval Research
   [N00014-21-1-2578]; Advent Health Endowed Chair in Healthcare Simulation
FX This work was supported in part by National Science Foundation under
   Grant 1800961 (Dr. Ephraim P. Glinert, IIS) in part by the Office of
   Naval Research under Grant N00014-21-1-2578 (Dr. Peter Squire, Code 34),
   and in part by Advent Health Endowed Chair in Healthcare Simulation
   (Prof. Welch).
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bayle E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256766
   Billock VA, 2001, J OPT SOC AM A, V18, P2398, DOI 10.1364/JOSAA.18.002398
   Blake RA, 2001, Brain and Mind, V2, P5, DOI DOI 10.1152/jn.00814.2009
   Browne M. P., 2010, Headand Helmet-Mounted Displays XV: Design and Applications, P99
   Casco C, 2006, VISION RES, V46, P1091, DOI 10.1016/j.visres.2005.09.032
   CRANE HD, 1983, SCIENCE, V221, P1078, DOI 10.1126/science.221.4615.1078
   Engmann S, 2009, ATTEN PERCEPT PSYCHO, V71, P1337, DOI 10.3758/APP.71.6.1337
   Erickson A., 2020, P ACM S SPAT US INT
   Etchebehere S., 2017, ELECT IMAGING, V2017, P58, DOI [https://doi.org/10.2352/.2470-1173.2017.14.HVEI-119, DOI 10.2352/.2470-1173.2017.14.HVEI-119, 10.2352/]
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2022, IEEE T VIS COMPUT GR, V28, P2834, DOI 10.1109/TVCG.2020.3044715
   Gabbard JL, 2013, P IEEE VIRT REAL ANN, P157, DOI 10.1109/VR.2013.6549410
   Gabbard JL, 2010, P IEEE VIRT REAL ANN, P79, DOI 10.1109/VR.2010.5444808
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Hassani N, 2019, COLOR RES APPL, V44, P492, DOI 10.1002/col.22380
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Hsieh PJ, 2006, VISION RES, V46, P2251, DOI 10.1016/j.visres.2005.11.030
   Huang LQ, 2005, VISION RES, V45, P1909, DOI 10.1016/j.visres.2005.01.013
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Kamkar S, 2018, FRONT SYST NEUROSCI, V12, DOI 10.3389/fnsys.2018.00054
   Krekhov A, 2020, IEEE T VIS COMPUT GR, V26, P547, DOI 10.1109/TVCG.2019.2934370
   Krekhov A, 2019, IEEE T VIS COMPUT GR, V25, P936, DOI 10.1109/TVCG.2018.2864498
   Lange D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376803
   Langlotz T, 2016, IEEE T VIS COMPUT GR, V22, P2385, DOI 10.1109/TVCG.2016.2593781
   Laramee R. S., 2002, ACM Transactions on Computer-Human Interaction, V9, P238, DOI 10.1145/568513.568516
   Lee J., 2019, Virtual Reality Intell. Hardware, V1
   Lee W., 2009, P INT WORKSH UB VIRT, P32
   Livingston M. A., 2013, Basic Perception in Head-Worn Augmented Reality Displays, P35
   Livingston MA, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P115, DOI 10.1109/VR.2009.4811009
   Logothetis NK, 1996, NATURE, V380, P621, DOI 10.1038/380621a0
   McElree B, 1999, J EXP PSYCHOL HUMAN, V25, P1517, DOI 10.1037/0096-1523.25.6.1517
   Nielsen LT, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P229, DOI 10.1145/2993369.2993405
   Nothdurft HC, 2000, VISION RES, V40, P1183, DOI 10.1016/S0042-6989(00)00031-6
   NOTHDURFT HC, 1992, PERCEPT PSYCHOPHYS, V52, P355, DOI 10.3758/BF03206697
   Ooi TL, 2020, EYE BRAIN, V12, P25, DOI 10.2147/EB.S176931
   Orlosky J, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P22, DOI 10.1109/ISMAR.2017.19
   Pramod RT, 2014, J VISION, V14, DOI 10.1167/14.4.6
   Rothe S, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010019
   Roumani D, 2012, FRONT HUM NEUROSCI, V6, DOI 10.3389/fnhum.2012.00035
   Shen JY, 2003, CAN J EXP PSYCHOL, V57, P76, DOI 10.1037/h0087415
   Shneor E, 2008, VISION RES, V48, P1592, DOI 10.1016/j.visres.2008.04.021
   Shneor E, 2006, VISION RES, V46, P4258, DOI 10.1016/j.visres.2006.08.006
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Stanley Jody, 2011, Front Hum Neurosci, V5, P140, DOI 10.3389/fnhum.2011.00140
   Sugano N, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2003.1240690
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Turatto M, 2000, VISION RES, V40, P1639, DOI 10.1016/S0042-6989(00)00061-4
   Van Krevelen D., 2010, INT J VIRT REAL, V9, P1, DOI [DOI 10.20870/IJVR.2010.9.2.2767, https://doi.org/10.20870/IJVR.2010.9.2.2767]
   Ware C., 2019, Information Visualization: Perception for Design
   WOLFE JM, 1988, PERCEPT PSYCHOPHYS, V44, P81, DOI 10.3758/BF03207480
   Xiao R, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1221, DOI 10.1145/2858036.2858212
   Yang E, 2010, INVEST OPHTH VIS SCI, V51, P588, DOI 10.1167/iovs.08-3076
   Zhang H., 2012, P SIGCHI C HUM FACT, P2523, DOI [10.1145/2207676.2208638, DOI 10.1145/2207676.2208638]
   Zou BC, 2017, ATTEN PERCEPT PSYCHO, V79, P473, DOI 10.3758/s13414-016-1247-8
NR 55
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4936
EP 4950
DI 10.1109/TVCG.2022.3195111
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300009
PM 35905060
DA 2024-11-06
ER

PT J
AU Han, J
   Wang, CL
AF Han, Jun
   Wang, Chaoli
TI CoordNet: Data Generation and Visualization Generation for Time-Varying
   Volumes via a Coordinate-Based Neural Network
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Data visualization; Rendering (computer graphics); Deep
   learning; Superresolution; Neural networks; Decoding; Volume
   visualization; implicit neural representation; data generation;
   visualization generation
ID SUPERRESOLUTION; FLOW
AB Although deep learning has demonstrated its capability in solving diverse scientific visualization problems, it still lacks generalization power across different tasks. To address this challenge, we propose CoordNet, a single coordinate-based framework that tackles various tasks relevant to time-varying volumetric data visualization without modifying the network architecture. The core idea of our approach is to decompose diverse task inputs and outputs into a unified representation (i.e., coordinates and values) and learn a function from coordinates to their corresponding values. We achieve this goal using a residual block-based implicit neural representation architecture with periodic activation functions. We evaluate CoordNet on data generation (i.e., temporal super-resolution and spatial super-resolution) and visualization generation (i.e., view synthesis and ambient occlusion prediction) tasks using time-varying volumetric data sets of various characteristics. The experimental results indicate that CoordNet achieves better quantitative and qualitative results than the state-of-the-art approaches across all the evaluated tasks. Source code and pre-trained models are available at https://github.com/stevenhan1991/CoordNet.
C1 [Han, Jun] Chinese Univ Hong Kong, Sch Data Sci, Shenzhen 518172, Guangdong, Peoples R China.
   [Wang, Chaoli] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 The Chinese University of Hong Kong, Shenzhen; University of Notre Dame
RP Han, J (corresponding author), Chinese Univ Hong Kong, Sch Data Sci, Shenzhen 518172, Guangdong, Peoples R China.
EM hanjun@cuhk.edu.cn; chaoli.wang@nd.edu
RI Wang, Chaoli/AAJ-5173-2020
OI Wang, Chaoli/0000-0002-0859-3619; Han, Jun/0000-0002-7286-062X
FU Chinese University of Hong Kong, Shenzhen, Shenzhen Science and
   Technology Program [ZDSYS20211021111415025]; U.S. National Science
   Foundation [IIS-1455886, CNS-1629914, DUE-1833129, IIS-1955395,
   IIS-2101696, OAC-2104158];  [UDF01002679]
FX This work was supported in part by the start-up under Grant UDF01002679,
   in part by the Chinese University of Hong Kong, Shenzhen, Shenzhen
   Science and Technology Program under Grant ZDSYS20211021111415025, and
   in part by U.S. National Science Foundation through under Grants
   IIS-1455886, CNS-1629914, DUE-1833129, IIS-1955395, IIS-2101696, and
   OAC-2104158.
CR Barrow H.G., 1977, P 5 INT JOINT C ART, P659
   Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Chan ER, 2021, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR46437.2021.00574
   Chen H., 2021, P ADV NEUR INF PROC
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Guo MCL, 2020, Arxiv, DOI arXiv:2012.08503
   Han J, 2022, VIS INFORM, V6, P62, DOI 10.1016/j.visinf.2022.04.004
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2021, IEEE T VIS COMPUT GR, V27, P1290, DOI 10.1109/TVCG.2020.3030346
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Hashimoto K., 2017, P 2017 C EMP METH NA, P1923, DOI DOI 10.18653/V1/D17-1206
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hu RH, 2021, Arxiv, DOI arXiv:2102.10772
   Jakob J, 2021, IEEE T VIS COMPUT GR, V27, P1279, DOI 10.1109/TVCG.2020.3028947
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Kaiser L, 2017, Arxiv, DOI arXiv:1706.05137
   Kingma D.P., 2014, P INT C LEARNING REP
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Loshchilov I., 2019, P 7 INT C LEARN REPR
   Lu J, 2020, PROC CVPR IEEE, P10434, DOI 10.1109/CVPR42600.2020.01045
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   McCann B, 2018, Arxiv, DOI arXiv:1806.08730
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Popinet S, 2004, J ATMOS OCEAN TECH, V21, P1575, DOI 10.1175/1520-0426(2004)021<1575:EANSOT>2.0.CO;2
   Pramanik S, 2020, Arxiv, DOI arXiv:1907.07804
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Shi N, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3309993
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sitzmann V., 2020, Advances in Neural Information Processing Systems, V33, P7462
   Sitzmann V, 2019, ADV NEUR IN, V32
   Tancik M, 2021, PROC CVPR IEEE, P2845, DOI 10.1109/CVPR46437.2021.00287
   Wang CL, 2008, IEEE T VIS COMPUT GR, V14, P1547, DOI 10.1109/TVCG.2008.140
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Whalen D, 2008, ASTROPHYS J, V673, P664, DOI 10.1086/524400
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
NR 41
TC 10
Z9 10
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4951
EP 4963
DI 10.1109/TVCG.2022.3197203
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300010
PM 35939482
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kelly, JW
AF Kelly, Jonathan W.
TI Distance Perception in Virtual Reality: A Meta-Analysis of the Effect of
   Head-Mounted Display Characteristics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Resists; Image resolution; Head; Virtual environments; Head-mounted
   displays; Task analysis; Surface texture; Distance perception;
   egocentric distance; field of view; head-mounted display; meta-analysis;
   resolution; virtual environment; virtual reality; weight
ID DEPTH-PERCEPTION; PERCEIVED DISTANCES; ENVIRONMENTS; INFORMATION;
   JUDGMENTS; UNDERESTIMATION; RECALIBRATION; TRANSFERS; GRAPHICS; EXTENTS
AB Distances are commonly underperceived in virtual reality (VR), and this finding has been documented repeatedly over more than two decades of research. Yet, there is evidence that perceived distance is more accurate in modern compared to older head-mounted displays (HMDs). This meta-analysis, based on 137 samples from 61 publications, describes egocentric distance perception across 20 HMDs and examines the relationship between perceived distance and technical HMD characteristics. Judged distance was positively associated with HMD field of view (FOV), positively associated with HMD resolution, and negatively associated with HMD weight. The effects of FOV and resolution were more pronounced among heavier HMDs. These findings suggest that future improvements in these technical characteristics may be central to resolving the problem of distance underperception in VR.
C1 [Kelly, Jonathan W.] Iowa State Univ, Dept Psychol, Ames, IA 50011 USA.
C3 Iowa State University
RP Kelly, JW (corresponding author), Iowa State Univ, Dept Psychol, Ames, IA 50011 USA.
EM jonkelly@iastate.edu
RI Kelly, Jonathan/A-4793-2013
OI Kelly, Jonathan/0000-0002-4317-273X
CR Ahn S, 2021, INT J HUM-COMPUT INT, V37, P36, DOI 10.1080/10447318.2020.1805875
   Anderson D.R., 2008, MODEL BASED INFERENC, DOI [DOI 10.1111/j.1365-2699.2006.01584.x, 10.1007/978-0-387-74075-1, DOI 10.1007/978-0-387-74075-1]
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Aseeri S, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00044
   Bhargava A, 2020, VIRTUAL REAL-LONDON, V24, P713, DOI 10.1007/s10055-020-00432-y
   Bingham GP, 2005, ECOL PSYCHOL, V17, P55, DOI 10.1207/s15326969eco1702_1
   Bodenheimer B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P35
   Buck L, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.728667
   Buck LE, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3196885
   Burnham K. P., 2001, Model selection and multimodel inference a practical information-theoretic approach, V2nd, DOI [10.1007/b97636, DOI 10.1007/B97636]
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Cheung MWL, 2019, NEUROPSYCHOL REV, V29, P387, DOI 10.1007/s11065-019-09415-6
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.0070, 10.1109/ISMAR-Adjunct.2016.61]
   Creem-Regehr SH, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P47, DOI 10.1145/2804408.2804422
   Cutting J. E., 1995, Perception of space and motion, P69, DOI DOI 10.1016/B978-012240530-3/50005-5
   Dey A, 2012, INT SYM MIX AUGMENT, P187, DOI 10.1109/ISMAR.2012.6402556
   Ding F, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407929
   Ehrlich J. A., 1999, ProQuest Diss. Theses,, P90
   Feldstein IT, 2020, PERCEPTION, V49, P940, DOI 10.1177/0301006620951997
   Foley JM, 2021, J VISION, V21, DOI 10.1167/jov.21.5.25
   Gagnon H, 2021, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2021), DOI 10.1145/3474451.3476238
   Geuss Michael., 2010, P 7 S APPL PERCEPTIO, P61, DOI 10.1145/1836248.1836259
   Geuss MN, 2012, J EXP PSYCHOL HUMAN, V38, P1242, DOI 10.1037/a0027524
   Grechkin TY, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1823738.1823744
   Interrante V, 2008, PRESENCE-TELEOP VIRT, V17, P176, DOI 10.1162/pres.17.2.176
   Interrante V, 2006, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2006.52
   JaaAro KM, 1997, P SOC PHOTO-OPT INS, V3012, P319, DOI 10.1117/12.274474
   Jones J. A., 2011, P ACM SIGGRAPH S APP, P29, DOI [10.1145/2077451.2077457, DOI 10.1145/2077451.2077457]
   Jones JA, 2013, IEEE T VIS COMPUT GR, V19, P701, DOI 10.1109/TVCG.2013.37
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kelly J. W., 2022, Meta-analysis of distance perception in virtual reality
   Kelly JW, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.850471
   Kelly JW, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3165285
   Kelly JW, 2017, ACM T APPL PERCEPT, V15, DOI 10.1145/3106155
   Kelly JW, 2015, ATTEN PERCEPT PSYCHO, V77, P1848, DOI 10.3758/s13414-015-0948-8
   Kelly JW, 2014, IEEE T VIS COMPUT GR, V20, P588, DOI 10.1109/TVCG.2014.36
   Kelly JW, 2013, ATTEN PERCEPT PSYCHO, V75, P1473, DOI 10.3758/s13414-013-0503-4
   Kelly JW, 2004, PERCEPTION, V33, P443, DOI 10.1068/p5218
   Kline PB, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1112
   Knapp JM, 2004, PRESENCE-TELEOP VIRT, V13, P572, DOI 10.1162/1054746042545238
   Knapp JM, 1999, Visual Perception of Egocentric Distance in Virtual Environments
   Kuhl SA, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1577755.1577762
   Kuhl ScottA., 2006, P 3 S APPL PERCEPTIO, P15, DOI [DOI 10.1145/1140491.1140494, DOI 10.1145/1140491.1140493]
   Kunz BR, 2015, PERCEPTION, V44, P446, DOI 10.1068/p7929
   Kunz BR, 2009, ATTEN PERCEPT PSYCHO, V71, P1284, DOI 10.3758/APP.71.6.1284
   Langbehn E, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P241, DOI 10.1145/2993369.2993379
   Leyrer M., 2011, P ACM SIGGRAPH S APP, P67, DOI [10.1145/2077451.20774642, DOI 10.1145/2077451.20774642, 10.1145/2077451.2077464]
   Leyrer M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127000
   Leyrer M, 2015, ACM T APPL PERCEPT, V12, P3, DOI 10.1145/2699254
   Li BC, 2016, SAP 2015: ACM SIGGRAPH SYMPOSIUM ON APPLIED PERCEPTION, P55, DOI 10.1145/2804408.2804427
   Li Bochao., 2014, P ACM S APPL PERCEPT, P91, DOI [DOI 10.1145/2628257.2628273, 10.1145/2628257.2628273]
   Li Z, 2013, J EXP PSYCHOL HUMAN, V39, P477, DOI 10.1037/a0029405
   Li Z, 2011, ATTEN PERCEPT PSYCHO, V73, P2205, DOI 10.3758/s13414-011-0170-2
   Linkenauger SA, 2015, NEUROPSYCHOLOGIA, V70, P393, DOI 10.1016/j.neuropsychologia.2014.10.034
   Loyola M, 2018, VIRTUAL REAL-LONDON, V22, P235, DOI 10.1007/s10055-017-0331-2
   Martens KAE, 2015, EXP BRAIN RES, V233, P787, DOI 10.1007/s00221-014-4154-z
   Maruhn P, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224651
   Masnadi S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517548
   Masnadi S, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P542, DOI 10.1109/VRW52623.2021.00153
   Mine D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.726114
   Moehring M, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P223, DOI 10.1109/VR.2009.4811027
   Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005
   Mohler BettyJ., 2006, P 3 S APPL PERCEPTIO, P9
   Murgia Alessio, 2009, International Journal of Virtual Reality, V8, P67
   Naceri A, 2011, PRESENCE-TELEOP VIRT, V20, P254, DOI 10.1162/PRES_a_00048
   Napieralski PE, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2010325.2010328
   Nilsson NC, 2015, P IEEE VIRT REAL ANN, P249, DOI 10.1109/VR.2015.7223389
   Peer A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P244, DOI [10.1109/vr.2019.8797911, 10.1109/VR.2019.8797911]
   Peer A, 2017, IEEE SYMP 3D USER, P83, DOI 10.1109/3DUI.2017.7893321
   Peer A, 2016, P IEEE VIRT REAL ANN, P261, DOI 10.1109/VR.2016.7504753
   Peillard E, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P227, DOI [10.1109/VR.2019.8797826, 10.1109/vr.2019.8797826]
   Phillips L, 2011, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2011.5759485
   Phillips L, 2010, P IEEE VIRT REAL ANN, P115, DOI 10.1109/VR.2010.5444802
   Phillips Lane., 2009, P 6 S APPL PERCEPTIO, P11, DOI [10.1145/1620993.1620996, DOI 10.1145/1620993.1620996]
   Richardson AR, 2007, HUM FACTORS, V49, P507, DOI 10.1518/001872007X200139
   Ries Brian, 2008, P 2008 ACM S VIRT RE, P167, DOI DOI 10.1145/1450579.1450614
   Riley RD, 2009, J ROY STAT SOC A, V172, P789, DOI 10.1111/j.1467-985X.2008.00593.x
   ROLLAND JP, 1995, PRESENCE-TELEOP VIRT, V4, P24, DOI 10.1162/pres.1995.4.1.24
   Ryu J, 2005, 2005 International Conference on Cyberworlds, Proceedings, P43
   Sahm C. S., 2005, ACM Transactions on Applied Perception, V2, P35, DOI [https://doi.org/10.1145/1048687.1048690, DOI 10.1145/1048687.1048690, 10.1145/1048687.1048690]
   Siegel ZD, 2017, J EXP PSYCHOL HUMAN, V43, P1805, DOI 10.1037/xhp0000401
   Siegel ZD, 2017, ATTEN PERCEPT PSYCHO, V79, P39, DOI 10.3758/s13414-016-1243-z
   Souza AMD, 2015, SYMP VIRTUAL AUGMENT, P33, DOI 10.1109/SVR.2015.13
   Steinicke F, 2010, COMPUT GRAPH-UK, V34, P26, DOI 10.1016/j.cag.2009.12.003
   Symonds MRE, 2011, BEHAV ECOL SOCIOBIOL, V65, P13, DOI 10.1007/s00265-010-1037-6
   Thompson WB, 2004, PRESENCE-TELEOP VIRT, V13, P560, DOI 10.1162/1054746042545292
   Nguyen TD, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043608
   Valkov D, 2016, P IEEE VIRT REAL ANN, P305, DOI 10.1109/VR.2016.7504775
   von Castell C, 2021, J EXP PSYCHOL HUMAN, V47, P1132, DOI 10.1037/xhp0000933
   Waller D, 2008, J EXP PSYCHOL-APPL, V14, P61, DOI 10.1037/1076-898X.14.1.61
   Willemsen P, 2002, P IEEE VIRT REAL ANN, P275, DOI 10.1109/VR.2002.996536
   Willemsen P, 2008, PRESENCE-TELEOP VIRT, V17, P91, DOI 10.1162/pres.17.1.91
   Willemsen P, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1498700.1498702
   Witmer BG, 1998, HUM FACTORS, V40, P478, DOI 10.1518/001872098779591340
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P144, DOI 10.1162/105474698565640
   Zhang JF, 2021, INSIGHTS IMAGING, V12, DOI 10.1186/s13244-021-00970-2
   Zhang RM, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2325722.2325727
NR 98
TC 26
Z9 28
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4978
EP 4989
DI 10.1109/TVCG.2022.3196606
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300012
PM 35925852
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Volmer, B
   Baumeister, J
   Von Itzstein, S
   Schlesewsky, M
   Bornkessel-Schlesewsky, I
   Thomas, BH
AF Volmer, Benjamin
   Baumeister, James
   Von Itzstein, Stewart
   Schlesewsky, Matthias
   Bornkessel-Schlesewsky, Ina
   Thomas, Bruce H.
TI Event Related Brain Responses Reveal the Impact of Spatial Augmented
   Reality Predictive Cues on Mental Effort
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Electroencephalography; Monitoring;
   Pressing; Costs; Resists; Spatial augmented reality; predictive cues;
   EEG; mental effort; cognitive load
ID COMPUTER INTERFACE; DUAL-TASK; P300; DETERMINANTS; PERFORMANCE;
   TOPOGRAPHY; WORKLOAD
AB This article presents the results from a Spatial Augmented Reality (SAR) study which evaluated the cognitive cost of several predictive cues. Participants performed a validated procedural button pressing task, where the predictive cue annotations guided them to the upcoming task. While existing research has evaluated predictive cues based on their performance and self-rated mental effort, actual cognitive cost has yet to be investigated. To measure the user's brain activity, this study utilized electroencephalogram (EEG) recordings. Cognitive load was evaluated by measuring brain responses for a secondary auditory oddball task, with reduced brain responses to oddball tones expected when cognitive load in the primary task is highest. A simple monitor n-back task and procedural task comparing monitor versus SAR were conducted, followed by a version of the procedural task comparing the SAR predictive cues. Results from the brain responses were able to distinguish between performance enhancing cues with a high and low cognitive load. Electrical brain responses also revealed that having an arc or arrow guide towards the upcoming task required the least amount of mental effort.
C1 [Volmer, Benjamin; Baumeister, James; Von Itzstein, Stewart; Schlesewsky, Matthias; Bornkessel-Schlesewsky, Ina; Thomas, Bruce H.] Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Adelaide, SA 5000, Australia.
C3 University of South Australia
RP Volmer, B (corresponding author), Univ South Australia, Australian Res Ctr Interact & Virtual Environm, Adelaide, SA 5000, Australia.
EM benjamin.volmer@mymail.unisa.edu.au; james@jmeister.net;
   stewart.vonitzstein@unisa.edu.au; matthias.schlesewsky@unisa.edu.au;
   ina.bornkessel-schlesewsky@unisa.edu.au; bruce.thomas@unisa.edu.au
RI ; Thomas, Bruce/A-1470-2008
OI Von Itzstein, G Stewart/0000-0003-1173-4424; Baumeister,
   James/0000-0002-9079-4072; Thomas, Bruce/0000-0002-9148-085X
FU Australian Research Council; University of South Australia
FX The authors wish to thank the members of the Australian Research Centre
   for Interactive and Virtual Environments and the Cognitive and Systems
   Neuroscience Research Hub for their assistance in running the study and
   their assistance with the analysis. We wish to thank the Australian
   Research Council and the University of South Australia for partially
   funding this project.
CR Alday PM, 2019, PSYCHOPHYSIOLOGY, V56, DOI 10.1111/psyp.13451
   Angrisani L, 2020, IEEE T INSTRUM MEAS, V69, P1530, DOI 10.1109/TIM.2019.2914712
   Austin PC, 2002, J VASC SURG, V36, P194, DOI 10.1067/mva.2002.125015
   Ayaz H, 2007, 2007 3RD INTERNATIONAL IEEE/EMBS CONFERENCE ON NEURAL ENGINEERING, VOLS 1 AND 2, P342, DOI 10.1109/CNE.2007.369680
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   Baumeister J, 2017, IEEE T VIS COMPUT GR, V23, P2378, DOI 10.1109/TVCG.2017.2735098
   Baumeister J, 2016, IEEE T VIS COMPUT GR, V22, P1396, DOI 10.1109/TVCG.2016.2518133
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Brouwer AM, 2012, J NEURAL ENG, V9, DOI 10.1088/1741-2560/9/4/045008
   Causse M, 2015, PROCEDIA MANUF, V3, P5230, DOI 10.1016/j.promfg.2015.07.594
   Dahl D. B., 2019, XTABLE EXPORT TABLES
   Debener S, 2005, COGNITIVE BRAIN RES, V22, P309, DOI 10.1016/j.cogbrainres.2004.09.006
   Dey A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P220, DOI [10.1109/VR.2019.8797840, 10.1109/vr.2019.8797840]
   Dhindsa K, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222276
   Escolano C, 2012, IEEE T SYST MAN CY B, V42, P793, DOI 10.1109/TSMCB.2011.2177968
   Fox J., 2019, An R Companion to Applied Regression, V3rd
   Garrido MI, 2009, CLIN NEUROPHYSIOL, V120, P453, DOI 10.1016/j.clinph.2008.11.029
   Gevins A., 2003, Theoretical issues in ergonomics science, V4, P113, DOI DOI 10.1080/14639220210159717
   Gramfort A, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00267
   Haegens S, 2014, NEUROIMAGE, V92, P46, DOI 10.1016/j.neuroimage.2014.01.049
   Hansen F.A., 2006, P 17 C HYPERTEXT HYP, P121, DOI DOI 10.1145/1149941.11499671,2
   HART S G, 1988, P139
   Heinrich F, 2019, IEEE T VIS COMPUT GR, V25, P2157, DOI 10.1109/TVCG.2019.2903942
   Izzetoglu M, 2007, IEEE ENG MED BIOL, V26, P38, DOI 10.1109/MEMB.2007.384094
   Jas M., 2016, P INT WORKSH PATT RE, P1
   Jas M, 2017, NEUROIMAGE, V159, P417, DOI 10.1016/j.neuroimage.2017.06.030
   Jensen O, 2012, TRENDS COGN SCI, V16, P200, DOI 10.1016/j.tics.2012.03.002
   KOK A, 1990, ACTA PSYCHOL, V74, P203
   KRAMER AF, 1988, BIOL PSYCHOL, V26, P231, DOI 10.1016/0301-0511(88)90022-1
   KRAMER AF, 1995, BIOL PSYCHOL, V40, P83, DOI 10.1016/0301-0511(95)05108-2
   Krempien R, 2008, INT J RADIAT ONCOL, V70, P944, DOI 10.1016/j.ijrobp.2007.10.048
   Kretzschmar F, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056178
   Lenhardt A, 2010, LECT NOTES COMPUT SC, V6444, P58, DOI 10.1007/978-3-642-17534-3_8
   Lenth Russell V, 2024, CRAN
   Liebherr M., 2021, Additive effects of cognitive load, motor demand, and environmental complexity on attention: A real-world eeg-study
   Liu JS, 2021, IEEE T VIS COMPUT GR, V27, P4311, DOI 10.1109/TVCG.2021.3106476
   Luck SJ, 2014, INTRODUCTION TO THE EVENT-RELATED POTENTIAL TECHNIQUE, 2ND EDITION, P1
   MacGregor-Fors I, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0056794
   Markov-Vetter D., 2020, P S SPAT US INT, P1
   Marner MR, 2013, INT SYM MIX AUGMENT, P39, DOI 10.1109/ISMAR.2013.6671762
   Marner MR, 2009, INT SYM MIX AUGMENT, P205, DOI 10.1109/ISMAR.2009.5336458
   Mewes A, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1950
   Naatanen R, 1995, Int J Neurosci, V80, P317, DOI 10.3109/00207459508986107
   Nieuwenhuis S, 2005, PSYCHOL BULL, V131, P510, DOI 10.1037/0033-2909.131.4.510
   PAAS FGWC, 1992, J EDUC PSYCHOL, V84, P429, DOI 10.1037/0022-0663.84.4.429
   PASHLER H, 1994, PSYCHOL BULL, V116, P220, DOI 10.1037/0033-2909.116.2.220
   POLICH J, 1986, ELECTROEN CLIN NEURO, V63, P251, DOI 10.1016/0013-4694(86)90093-3
   POLICH J, 1995, BIOL PSYCHOL, V41, P103, DOI 10.1016/0301-0511(95)05130-9
   Polich J, 1997, BRAIN TOPOGR, V9, P275, DOI 10.1007/BF01464482
   Putze F, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00144
   Raats M. M., 1992, Food Quality and Preference, V3, P89, DOI 10.1016/0950-3293(91)90028-D
   Renard Y, 2010, PRESENCE-VIRTUAL AUG, V19, P35, DOI 10.1162/pres.19.1.35
   Sabbagh D, 2020, NEUROIMAGE, V222, DOI 10.1016/j.neuroimage.2020.116893
   Si-Mohammed H., 2017, P GRAZ BRAIN COMP IN
   Si-Mohammed H, 2020, IEEE T VIS COMPUT GR, V26, P1608, DOI 10.1109/TVCG.2018.2873737
   SMITH ME, 1990, ELECTROEN CLIN NEURO, V76, P235, DOI 10.1016/0013-4694(90)90018-F
   Tang A., 2003, COMP EFFECTIVENESS A, P73
   Uno K, 2015, ELECTR COMMUN JPN, V98, P9, DOI 10.1002/ecj.11715
   Volmer B, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P589, DOI 10.1109/VR51125.2022.00079
   Volmer B, 2018, IEEE T VIS COMPUT GR, V24, P2846, DOI 10.1109/TVCG.2018.2868587
   WICKENS C, 1983, SCIENCE, V221, P1080, DOI 10.1126/science.6879207
   Wickham H., 2019, J. Open Source Softw, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 65
TC 2
Z9 2
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 4990
EP 5007
DI 10.1109/TVCG.2022.3197810
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300013
PM 35947568
DA 2024-11-06
ER

PT J
AU Zhang, YW
   Luo, P
   Zhou, H
   Ji, ZP
   Liu, H
   Chen, YZ
   Zhang, CM
AF Zhang, Yu-Wei
   Luo, Ping
   Zhou, Hao
   Ji, Zhongping
   Liu, Hui
   Chen, Yanzhao
   Zhang, Caiming
TI Neural Modeling of Portrait Bas-Relief From a Single Photograph
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Hair; Image reconstruction; Shape;
   Pipelines; Faces; Solid modeling; Bas-relief modeling; depth
   reconstruction; image-to-depth translation; portrait bas-relief
ID GENERATION; IMAGE; RECONSTRUCTION
AB In this paper, we present an end-to-end neural solution to model portrait bas-relief from a single photograph, which is cast as a problem of image-to-depth translation. The main challenge is the lack of bas-relief data for network training. To solve this problem, we propose a semi-automatic pipeline to synthesize bas-relief samples. The main idea is to first construct normal maps from photos, and then generate bas-relief samples by reconstructing pixel-wise depths. In total, our synthetic dataset contains 23 k pixel-wise photo/bas-relief pairs. Since the process of bas-relief synthesis requires a certain amount of user interactions, we propose end-to-end solutions with various network architectures, and train them on the synthetic data. We select the one that gave the best results through qualitative and quantitative comparisons. Experiments on numerous portrait photos, comparisons with state-of-the-art methods and evaluations by artists have proven the effectiveness and efficiency of the selected network.
C1 [Zhang, Yu-Wei; Luo, Ping; Zhou, Hao; Chen, Yanzhao] Qilu Univ Technol, Shandong Acad Sci, Sch Mech & Automot Engn, Jinan 250353, Peoples R China.
   [Ji, Zhongping] Hangzhou Dianzi Univ, Inst Graph & Image, Hangzhou 310005, Peoples R China.
   [Liu, Hui] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Caiming] Shandong Univ, Sch Comp Sci & Technol, Jinan 250102, Peoples R China.
C3 Qilu University of Technology; Hangzhou Dianzi University; Shandong
   University of Finance & Economics; Shandong University
RP Zhang, YW (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Mech & Automot Engn, Jinan 250353, Peoples R China.
EM zhangyuwei_scott@126.com; luo18325713395@163.com; zhouhao957@163.com;
   jzp@zju.edu.cn; liuh_lh@sdufe.edu.cn; chyzh_ql@126.com;
   czhang@sdu.edu.cn
RI Zhang, Caiming/AHD-6558-2022; chen, yanzhao/GWC-1464-2022
OI Liu, Hui/0000-0003-3911-7751; Zhang, Yu-Wei/0000-0001-6566-5714; zhang,
   caiming/0000-0003-0217-1543; Chen, Yanzhao/0000-0002-5657-413X
FU National Natural Science Foundation of China [61772293, 62072274];
   Zhejiang Provincial Natural Science Foundation of China [LY22F020025]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61772293 and 62072274 and in part by
   the Zhejiang Provincial Natural Science Foundation of China under Grant
   LY22F020025. (Corresponding author: Yu-Wei Zhang.)
CR Abrevaya VF, 2020, PROC CVPR IEEE, P4978, DOI 10.1109/CVPR42600.2020.00503
   Alexa M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778797
   Bian Z, 2011, COMPUT AIDED GEOM D, V28, P245, DOI 10.1016/j.cagd.2011.03.003
   Chai ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925961
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Chen SY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392386
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   Fu YF, 2019, IEEE T VIS COMPUT GR, V25, P2763, DOI 10.1109/TVCG.2018.2860004
   Gao C, 2021, Arxiv, DOI arXiv:2012.05903
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu LW, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3130800.31310887, 10.1145/3130800.3130887]
   Hu LW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766931
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hudon M, 2019, LECT NOTES COMPUT SC, V11131, P246, DOI 10.1007/978-3-030-11015-4_20
   Jayaraman PK, 2018, IEEE T VIS COMPUT GR, V24, P2103, DOI 10.1109/TVCG.2017.2705182
   Ji ZP, 2021, GRAPH MODELS, V114, DOI 10.1016/j.gmod.2021.101099
   Ji ZP, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102928
   Ji ZP, 2014, IEEE T VIS COMPUT GR, V20, P675, DOI 10.1109/TVCG.2013.267
   Judd T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239470
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Karras T, 2020, PROC CVPR IEEE, P8107, DOI 10.1109/CVPR42600.2020.00813
   Ke ZH, 2022, Arxiv, DOI arXiv:2011.11961
   Kingma DP, 2014, ADV NEUR IN, V27
   Kolomenkin M, 2011, PROC CVPR IEEE, P993, DOI 10.1109/CVPR.2011.5995643
   Kyprianidis Jan Eric, 2008, TPCG, P51
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li CJ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275051
   Li CJ, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073632
   Li ZW, 2012, IEEE T VIS COMPUT GR, V18, P177, DOI 10.1109/TVCG.2011.26
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Luo HW, 2021, PROC CVPR IEEE, P11657, DOI 10.1109/CVPR46437.2021.01149
   Nestmeyer T, 2020, PROC CVPR IEEE, P5123, DOI 10.1109/CVPR42600.2020.00517
   Pandey R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459872
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schüller C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661267
   Sengupta S, 2018, PROC CVPR IEEE, P6296, DOI 10.1109/CVPR.2018.00659
   Shen YF, 2021, IEEE T VIS COMPUT GR, V27, P3250, DOI 10.1109/TVCG.2020.2968433
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Sykora D, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591011
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Wang ML, 2021, NEUROCOMPUTING, V453, P825, DOI 10.1016/j.neucom.2020.06.130
   Wang ML, 2019, MULTIMED TOOLS APPL, V78, P4989, DOI 10.1007/s11042-018-5826-7
   Wei MQ, 2019, IEEE T VIS COMPUT GR, V25, P1651, DOI 10.1109/TVCG.2018.2818146
   Weyrich T, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239483
   Wu J, 2014, GRAPH MODELS, V76, P202, DOI 10.1016/j.gmod.2014.02.002
   Wu J, 2013, COMPUT AIDED DESIGN, V45, P671, DOI 10.1016/j.cad.2012.11.002
   Wu SZ, 2020, PROC CVPR IEEE, P1, DOI 10.1109/CVPR42600.2020.00008
   Xu Sicheng, 2020, P IEEE CVF C COMP VI, P7710
   Yang HT, 2020, PROC CVPR IEEE, P598, DOI 10.1109/CVPR42600.2020.00068
   Yang ZJ, 2022, IEEE T VIS COMPUT GR, V28, P4558, DOI 10.1109/TVCG.2021.3092877
   Yeh CK, 2017, IEEE T VIS COMPUT GR, V23, P1796, DOI 10.1109/TVCG.2016.2574705
   Zeng XX, 2019, IEEE I CONF COMP VIS, P2315, DOI 10.1109/ICCV.2019.00240
   Zhang M, 2019, VIS INFORM, V3, P102, DOI 10.1016/j.visinf.2019.06.001
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang X, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392390
   Zhang Y, 2021, Comput. Graph. Forum, V40, P1
   Zhang YW, 2020, IEEE T VIS COMPUT GR, V26, P2659, DOI 10.1109/TVCG.2019.2892439
   Zhang YW, 2020, VISUAL COMPUT, V36, P2241, DOI 10.1007/s00371-020-01917-2
   Zhang YW, 2019, COMPUT GRAPH FORUM, V38, P521, DOI 10.1111/cgf.13655
   Zhang YW, 2019, GRAPH MODELS, V102, P10, DOI 10.1016/j.gmod.2019.01.002
   Zhang YW, 2018, COMPUT GRAPH-UK, V70, P300, DOI 10.1016/j.cag.2017.07.022
   Zhang YW, 2016, COMPUT GRAPH FORUM, V35, P311, DOI 10.1111/cgf.13028
   Zhang YW, 2015, IEEE T VIS COMPUT GR, V21, P328, DOI 10.1109/TVCG.2014.2377773
   Zhang Z., 2021, P IEEECVF C COMPUTER, P14214
   Zhou Y, 2018, LECT NOTES COMPUT SC, V11215, P249, DOI 10.1007/978-3-030-01252-6_15
NR 69
TC 1
Z9 1
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5008
EP 5019
DI 10.1109/TVCG.2022.3197354
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300014
PM 35939483
DA 2024-11-06
ER

PT J
AU Chen, KY
   Yin, F
   Du, B
   Wu, BC
   Nguyen, TQ
AF Chen, Kunyao
   Yin, Fei
   Du, Bang
   Wu, Baichuan
   Nguyen, Truong Q.
TI Efficient Registration for Human Surfaces via Isometric Regularization
   on Embedded Deformation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Strain; Optimization; Three-dimensional displays; Deformable models;
   Rigidity; Real-time systems; Shape; 3D registration; mesh alignment;
   non-rigid deformation; regularization; 3D segmentation
ID NONRIGID REGISTRATION; POSE
AB 3D registration is a fundamental step to obtain the correspondences between surfaces. Traditional mesh alignment methods tackle this problem through non-rigid deformation, mostly accomplished by applying ICP-based (Iterative Closest Point) optimization. The embedded deformation method is proposed for the purpose of acceleration, which enables various real-time applications. However, it regularizes on an underlying simplified structure, which could be problematic for intricate cases when the simplified graph doesn't fully represent the surface attributes. Moreover, without elaborate parameter-tuning, deformation usually performs suboptimally, leading to slow convergence or a local minimum if all regions on the surface are assumed to share the same rigidity during the optimization. In this article, we propose a novel solution that decouples regularization from the underlying deformation model by explicitly managing the rigidity of vertex clusters. We further design an efficient two-step solution that alternates between isometric deformation and embedded deformation with cluster-based regularization. Our method can easily support region-adaptive regularization with cluster refinement and execute efficiently. Extensive experiments demonstrate the effectiveness of our approach for mesh alignment tasks even under large-scale deformation and imperfect data. Our method outperforms state-of-the-art methods both numerically and visually.
C1 [Chen, Kunyao; Yin, Fei; Du, Bang; Nguyen, Truong Q.] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
   [Wu, Baichuan] Univ Calif San Diego, Jacobs Sch Engn, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego;
   University of California System; University of California San Diego
RP Chen, KY (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM kunyao@ucsd.edu; fyin@ucsd.edu; bangdu@ucsd.edu; bwu@ucsd.edu;
   tqn001@eng.ucsd.edu
RI Nguyen, Truong/F-3730-2012
OI Nguyen, Truong/0000-0002-5022-063X; Wu, Baichuan/0000-0003-3856-5595;
   Chen, Kunyao/0000-0003-4527-1114; Yin, Fei/0000-0002-7986-1617
CR Amberg B, 2007, IEEE I CONF COMP VIS, P1326
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanco J. L., 2014, nanoflann: a C++header-only fork of FLANN, a library for Nearest Neighbor (NN) with KD-trees
   Bozic A, 2021, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR46437.2021.00150
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Devito Z, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3132188
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Hontani H, 2012, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2012.6247673
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Levenberg K., 1944, Q. Appl. Math, V2, P164, DOI [10.1090/QAM/10666, 10.1090/qam/10666, DOI 10.1090/QAM/10666]
   Li H, 2008, COMPUT GRAPH FORUM, V27, P1421, DOI 10.1111/j.1467-8659.2008.01282.x
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li K, 2019, IEEE T VIS COMPUT GR, V25, P2255, DOI 10.1109/TVCG.2018.2832136
   Lin K, 2021, IEEE T CIRC SYST VID, V31, P1066, DOI 10.1109/TCSVT.2020.2995122
   Lipman Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P181, DOI 10.1109/SMI.2004.1314505
   Lipman Y, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360677
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Mitra N. J., 2007, P S GEOM PROC, P173
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sorkine M., 2007, P S GEOM PROC, P109, DOI DOI 10.1145/1073204.1073323
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Takayama K., 2010, PROC ACM SIGGRAPH AS, P1
   Tam GKL, 2014, COMPUT GRAPH FORUM, V33, P137, DOI 10.1111/cgf.12439
   Tevs A, 2009, PROC CVPR IEEE, P1185, DOI 10.1109/CVPRW.2009.5206775
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wei LY, 2016, PROC CVPR IEEE, P1544, DOI 10.1109/CVPR.2016.171
   Xian CH, 2012, VISUAL COMPUT, V28, P21, DOI 10.1007/s00371-011-0595-6
   Yu ZX, 2020, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR42600.2020.00306
   Yuxin Yao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7597, DOI 10.1109/CVPR42600.2020.00762
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
NR 44
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5020
EP 5032
DI 10.1109/TVCG.2022.3197383
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300015
PM 35943999
DA 2024-11-06
ER

PT J
AU Liu, SG
   Hao, JQ
AF Liu, Shiguang
   Hao, Jiaqi
TI Generating Talking Face With Controllable Eye Movements by Disentangled
   Blinking Feature
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Faces; Videos; Mouth; Training; Three-dimensional displays; Feature
   extraction; Decoding; Talking face generation; eye blink generation;
   blink feature; virtual character
ID QUALITY
AB In virtual reality, talking face generation is committed to using voice and face images to generate real face speech videos to improve the communication experience in the case of limited user information exchange. In a real video, blinking is an action often accompanied by speech, and it is also one of the indispensable actions in real face speech videos. However, the current methods either do not pay attention to the generation of eye movements, or cannot control the blinking in the generated results. To this end, this article proposes a novel system which produces vivid talking face with controllable eye blinks driven by the joint features including identity feature, audio feature, and blink feature. In order to disentangle the blinking action, we designed three independent features to individually drive the main components in the generated frame, namely the facial appearance, mouth movements, and eye movements. Through the adversarial training of the identity encoder, we filter out the information of the eye state from the identity feature, thereby strengthening the independence of the blinking feature. We introduced the blink score as the leading information of the blink feature, and through training, the value can be consistent with human perception to form a complete and independent control of the eyes. Experimental results on multiple datasets show that our method can not only reproduce real talking faces, but also ensure that the blinking pattern and time are fully controllable.
C1 [Liu, Shiguang; Hao, Jiaqi] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn; 2019216063@tju.edu.cn
RI hao, jiaqi/LGY-1836-2024
FU Natural Science Foundation of China [62072328]
FX This work was supported by the Natural Science Foundation of China under
   Grant 62072328.
CR Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Chatfield K., 2014, PROC BRIT MACH VIS C
   Chen LL, 2019, PROC CVPR IEEE, P7824, DOI 10.1109/CVPR.2019.00802
   Cheng HN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P111, DOI [10.1109/vr.2019.8797906, 10.1109/VR.2019.8797906]
   Chung J., 2017, P BRIT MACH VIS C, P1
   Chung JS, 2018, INTERSPEECH, P1086
   Chung JS, 2017, LECT NOTES COMPUT SC, V10117, P251, DOI 10.1007/978-3-319-54427-4_19
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Fan B, 2015, INT CONF ACOUST SPEE, P4884, DOI 10.1109/ICASSP.2015.7178899
   Fried O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323028
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Gong X, 2020, COMPUT GRAPH FORUM, V39, P66, DOI 10.1111/cgf.13904
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Gu SY, 2019, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2019.00355
   Han XJ, 2020, IEEE T MULTIMEDIA, V22, P1619, DOI 10.1109/TMM.2019.2945197
   Hao JQ, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 TECHNICAL COMMUNICATIONS, DOI 10.1145/3478512.3488610
   Huang X, 2021, VISUAL COMPUT, V37, P95, DOI 10.1007/s00371-020-01982-7
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim H, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201283
   Leal S, 2008, J NONVERBAL BEHAV, V32, P187, DOI 10.1007/s10919-008-0051-0
   Li PF, 2019, IEEE INT CON MULTI, P910, DOI 10.1109/ICME.2019.00161
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu SG, 2022, IEEE T MULTIMEDIA, V24, P1299, DOI 10.1109/TMM.2021.3063605
   Liu S, 2020, IEEE ACCESS, V8, P34854, DOI 10.1109/ACCESS.2020.2974043
   Luo R, 2017, P IEEE VIRT REAL ANN, P112, DOI 10.1109/VR.2017.7892238
   Nakamoto T, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P713, DOI [10.1109/VR46266.2020.1581303036097, 10.1109/VR46266.2020.00-10]
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Schwartz G, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392493
   Shen YJ, 2020, PROC CVPR IEEE, P9240, DOI 10.1109/CVPR42600.2020.00926
   Sinha S, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206665
   Song Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P919
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tkachev M. A., 2001, Sleep Hypnosis, V3, P93
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Wang LJ, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P446
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yu J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1259, DOI [10.1109/vr.2019.8798288, 10.1109/VR.2019.8798288]
   Yu J, 2017, IEEE INT CON MULTI, P511, DOI 10.1109/ICME.2017.8019362
   Yu LY, 2021, IEEE T CIRC SYST VID, V31, P203, DOI 10.1109/TCSVT.2020.2973374
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
   Zhang CX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3847, DOI 10.1109/ICCV48922.2021.00384
   Zhang JN, 2020, INT CONF ACOUST SPEE, P4402, DOI [10.1109/icassp40776.2020.9052977, 10.1109/ICASSP40776.2020.9052977]
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
   Zhu L, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102931
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P523, DOI 10.1111/cgf.13382
NR 55
TC 1
Z9 1
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5050
EP 5061
DI 10.1109/TVCG.2022.3199412
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300016
PM 35976839
DA 2024-11-06
ER

PT J
AU Butaslac, IM III
   Fujimoto, Y
   Sawabe, T
   Kanbara, M
   Kato, H
AF Butaslac, Isidro Mendoza, III
   Fujimoto, Yuichiro
   Sawabe, Taishi
   Kanbara, Masayuki
   Kato, Hirokazu
TI Systematic Review of Augmented Reality Training Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Training; Subspace constraints; Task analysis; Market research;
   Augmented reality; Systematics; Real-time systems; Augmented reality
   training systems; training method; evaluation; narrative synthesis;
   systematic review
ID MIXED REALITY; VIRTUAL-REALITY; NEEDLE PLACEMENT; SIMULATION; DESIGN;
   HOME; REHABILITATION; VISUALIZATION; STRENGTH; BALANCE
AB Recent augmented reality (AR) advancements have enabled the development of effective training systems, especially in the medical, rehabilitation, and industrial fields. However, it is unclear from the literature what the intrinsic value of AR to training is and how it differs across multiple application fields. In this work, we gathered and reviewed the prototypes and applications geared towards training the intended user's knowledge, skills, and abilities. Specifically, from IEEE Xplore plus other digital libraries, we collected 64 research papers present in high-impact publications about augmented reality training systems (ARTS). All 64 papers were then categorized according to the training method used, and each paper's evaluations were identified by validity. The summary of the results shows trends in the training methods and evaluations that incorporate ARTS in each field. The narrative synthesis illustrates the different implementations of AR for each of the training methods. In addition, examples of the different evaluation types of the current ARTS are described for each of the aforementioned training methods. We also investigated the different training strategies used by the prevailing ARTS. The insights gleaned from this review can suggest standards for designing ARTS regarding training strategy, and recommendations are provided for the implementation and evaluation of future ARTS.
C1 [Butaslac, Isidro Mendoza, III; Fujimoto, Yuichiro; Sawabe, Taishi; Kanbara, Masayuki; Kato, Hirokazu] Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Butaslac, IM III (corresponding author), Nara Inst Sci & Technol, Grad Sch Sci & Technol, Ikoma, Nara 6300192, Japan.
EM isidro.butaslac.hw2@is.naist.jp; yfujimoto@is.naist.jp;
   t.sawabe@is.naist.jp; kanbara@is.naist.jp; kato@is.naist.jp
RI Butaslac, Isidro/LNQ-0072-2024; Fujimoto, Yuichiro/HTS-3801-2023;
   Kanbara, Masayuki/ABD-7780-2021
OI Sawabe, Taishi/0000-0001-9244-479X; Kato, Hirokazu/0000-0003-3921-2871;
   Kanbara, Masayuki/0000-0002-1877-996X; Butaslac,
   Isidro/0000-0003-1172-7611; Fujimoto, Yuichiro/0000-0002-8270-2609
FU JSPS KAKENHI [JP20H00608]
FX This work was supported by the JSPS KAKENHI under Grant JP20H00608.
CR Abhari K, 2015, IEEE T BIO-MED ENG, V62, P1466, DOI 10.1109/TBME.2014.2385874
   Ada L, 2006, AUST J PHYSIOTHER, V52, P241, DOI 10.1016/S0004-9514(06)70003-4
   Aebersold M, 2018, CLIN SIMUL NURS, V15, P34, DOI 10.1016/j.ecns.2017.09.008
   Alaraj A, 2013, NEUROSURGERY, V72, pA115, DOI 10.1227/NEU.0b013e3182753093
   Alsawaier RS, 2018, INT J INF LEARN TECH, V35, P56, DOI 10.1108/IJILT-02-2017-0009
   Andersen D, 2016, SURGERY, V159, P1646, DOI 10.1016/j.surg.2015.12.016
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Babbitt B., 1985, PROC HUM FACTORS ERG, P198
   Balian S, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02205
   Barsom EZ, 2016, SURG ENDOSC, V30, P4174, DOI 10.1007/s00464-016-4800-6
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Bianchi I, 2020, SYMP VIRTUAL AUGMENT, P129, DOI 10.1109/SVR51698.2020.00032
   Bifulco P, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-153
   Black J. M, 1961, Developing Competent Subordinates
   Blomqvist S, 2021, BMC GERIATR, V21, DOI 10.1186/s12877-021-02061-9
   Botden SMBI, 2007, WORLD J SURG, V31, P764, DOI 10.1007/s00268-006-0724-y
   Bovermann K, 2020, RES PRACT TECH ENHAN, V15, DOI 10.1186/s41039-019-0121-4
   Boyaci MG, 2020, TURK NEUROSURG, V30, P937, DOI 10.5137/1019-5149.JTN.30733-20.2
   Brij Yassine, 2021, 2021 Third International Conference on Transportation and Smart Technologies (TST), P16, DOI 10.1109/TST52996.2021.00010
   Chen ML, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17197208
   Chen PJ, 2020, J EXERC SCI FIT, V18, P142, DOI 10.1016/j.jesf.2020.05.003
   Chiang IA., 2015, Research Methods of Psychology
   Chinthammit W, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/646347
   Chollet M, 2022, J MULTIMODAL USER IN, V16, P17, DOI 10.1007/s12193-021-00371-1
   Chowriappa A, 2015, BJU INT, V115, P336, DOI 10.1111/bju.12704
   Condino S, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5435097
   Culatta R., 2018, Sequencing of instruction
   Desselle MR, 2020, COMPUT SCI ENG, V22, P18, DOI 10.1109/MCSE.2020.2972822
   Dey A, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00037
   Duff M, 2010, IEEE T NEUR SYS REH, V18, P531, DOI 10.1109/TNSRE.2010.2055061
   Espay AJ, 2010, J REHABIL RES DEV, V47, P573, DOI 10.1682/JRRD.2009.10.0165
   Ferrari V, 2016, INT J MED ROBOT COMP, V12, P231, DOI 10.1002/rcs.1681
   Ferrer-Torregrosa J, 2016, BMC MED EDUC, V16, DOI 10.1186/s12909-016-0757-3
   Fitts P., 1964, CATEGORIES HUM LEARN, P243
   Friedman N, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-76
   Gallagher AG, 2005, ANN SURG, V241, P364, DOI 10.1097/01.sla.0000151982.85062.80
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Ghandorh H, 2017, CAN CON EL COMP EN
   GLYNN SM, 1977, J EDUC PSYCHOL, V69, P89, DOI 10.1037/0022-0663.69.2.89
   Goldstein I.L., 2002, TRAINING ORG NEEDS A, V4th
   González ANV, 2019, INT SYM MIX AUGMENT, P339, DOI 10.1109/ISMAR.2019.00032
   Goto M., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P83, DOI 10.1109/ISMAR.2010.5643554
   Hafsa Sayera, 2021, 2021 International Conference on Software Engineering & Computer Systems and 4th International Conference on Computational Science and Information Management (ICSECS-ICOCSIM), P371, DOI 10.1109/ICSECS52883.2021.00074
   Halic T, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S6-S11
   Held JPO, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/17804
   Hermann Thomas, 2011, The sonification handbook
   Hirsch JE, 2005, P NATL ACAD SCI USA, V102, P16569, DOI 10.1073/pnas.0507655102
   Horejsi P, 2020, IEEE ACCESS, V8, P94330, DOI 10.1109/ACCESS.2020.2994650
   Hughes CE, 2005, IEEE COMPUT GRAPH, V25, P24, DOI 10.1109/MCG.2005.139
   Hulin T, 2010, 2010 IEEE RO-MAN, P440, DOI 10.1109/ROMAN.2010.5598611
   Im DJ, 2015, ANN REHABIL MED-ARM, V39, P462, DOI 10.5535/arm.2015.39.3.462
   Ingrassia PL, 2020, J MED INTERNET RES, V22, DOI 10.2196/14910
   Jarc AM, 2017, WORLD J UROL, V35, P957, DOI 10.1007/s00345-016-1944-x
   Javaux A, 2018, INT J COMPUT ASS RAD, V13, P1949, DOI 10.1007/s11548-018-1822-7
   Jeon S, 2012, IEEE T HAPTICS, V5, P77, DOI [10.1109/ToH.2011.40, 10.1109/TOH.2011.40]
   Johnsen K, 2014, IEEE T VIS COMPUT GR, V20, P523, DOI 10.1109/TVCG.2014.33
   Kao PY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1457, DOI [10.1109/VR.2019.8797986, 10.1109/vr.2019.8797986]
   Keebler JR, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00471
   Kielhofner G., 2009, Conceptual foundations of occupational therapy practice, V4th
   Kim S, 2020, IEEE ACCESS, V8, P45996, DOI 10.1109/ACCESS.2020.2977688
   Kim Y, 2017, ARCH PLAST SURG-APS, V44, P179, DOI 10.5999/aps.2017.44.3.179
   Laha B, 2013, IEEE T VIS COMPUT GR, V19, P529, DOI 10.1109/TVCG.2013.43
   Lee GA, 2020, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR50242.2020.00078
   Lehrer N, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-54
   Limbu BH, 2018, EDUC RES REV-NETH, V25, P1, DOI 10.1016/j.edurev.2018.07.001
   Lin CY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P212, DOI [10.1109/VR46266.2020.1580934001692, 10.1109/VR46266.2020.00-64]
   LORCH RF, 1985, J EDUC PSYCHOL, V77, P137, DOI 10.1037/0022-0663.77.2.137
   Magee D, 2007, MED BIOL ENG COMPUT, V45, P957, DOI 10.1007/s11517-007-0231-9
   Andújar JM, 2011, IEEE T EDUC, V54, P492, DOI 10.1109/TE.2010.2085047
   Martin BO, 2014, HUM RESOUR DEV REV, V13, P11, DOI 10.1177/1534484313497947
   Mayer RE, 2009, MULTIMEDIA LEARNING, 2ND EDITION, P1, DOI 10.1017/CBO9780511811678
   Mercier-Ganady J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P33, DOI 10.1109/VR.2014.6802047
   Merrill M.D., 1983, INSTRUCTIONAL DESIGN
   Molenda M, 2008, TECHTRENDS, V52, P52
   Muangpoon T, 2020, J MED INTERNET RES, V22, DOI 10.2196/18637
   Munoz-Montoya F, 2019, IEEE ACCESS, V7, P2453, DOI 10.1109/ACCESS.2018.2886627
   Naidu S., 1995, Res. Learn. Technol., V3, P63
   NELSON AA, 1980, AM J HOSP PHARM, V37, P851, DOI 10.1093/ajhp/37.6.851
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Paillard J, 2005, ADV CONSC RES, V62, P89
   Palmarini R, 2018, ROBOT CIM-INT MANUF, V49, P215, DOI 10.1016/j.rcim.2017.06.002
   Papakostas C, 2021, INFORM EDUC, V20, P107, DOI 10.15388/infedu.2021.06
   Park E, 2019, COGN BEHAV NEUROL, V32, P172, DOI 10.1097/WNN.0000000000000197
   Pisoni T, 2016, IEEE SECOND INTERNATIONAL SMART CITIES CONFERENCE (ISC2 2016), P400
   Qin ZB, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/6813719
   Quarles J, 2008, INT SYM MIX AUGMENT, P107, DOI 10.1109/ISMAR.2008.4637335
   Rodrigues TB, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0230570
   Roessel J, 2020, P INT COMP SOFTW APP, P489, DOI 10.1109/COMPSAC48688.2020.0-204
   Rojas-Muñoz E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0284-9
   Sailer M, 2017, COMPUT HUM BEHAV, V69, P371, DOI 10.1016/j.chb.2016.12.033
   Salas E, 2012, PSYCHOL SCI PUBL INT, V13, P74, DOI 10.1177/1529100612436661
   Sankaran NK, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P664, DOI 10.1109/vr.2019.8798089
   Santos MEC, 2014, IEEE T LEARN TECHNOL, V7, P38, DOI 10.1109/TLT.2013.37
   Sappenfield JW, 2018, ANESTH ANALG, V127, P83, DOI 10.1213/ANE.0000000000002572
   Sari RC, 2021, EDUC INF TECHNOL, V26, P441, DOI 10.1007/s10639-020-10263-8
   Schmalstieg D., 2016, AUGMENTED REALITY PR
   SCHMIDT RA, 1975, PSYCHOL REV, V82, P225, DOI 10.1037/h0076770
   Schoeb DS, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02450-5
   Vergel RS, 2020, IEEE T HUM-MACH SYST, V50, P337, DOI 10.1109/THMS.2020.2984746
   Sielhorst T, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P38
   Sigrist R, 2015, EXP BRAIN RES, V233, P909, DOI 10.1007/s00221-014-4167-7
   Sinha B., 2019, Int. Educ. Sci. Res. J., V5, P34
   Somasundaram UV., 2004, Proceedings of the Academy of Human Resource Development International Conference (AHRD), VED491481, P850
   Sportillo D, 2019, ACMIEEE INT CONF HUM, P182, DOI [10.1109/hri.2019.8673277, 10.1109/HRI.2019.8673277]
   Sutherland C, 2013, IEEE T BIO-MED ENG, V60, P3009, DOI 10.1109/TBME.2012.2236091
   Thomas PC, 1992, ACM SIGCHI B, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317]
   Trojan J, 2014, BEHAV RES METHODS, V46, P634, DOI 10.3758/s13428-013-0412-4
   VANPATTEN J, 1986, REV EDUC RES, V56, P437, DOI 10.3102/00346543056004437
   Von Koch L, 1998, DISABIL REHABIL, V20, P367, DOI 10.3109/09638289809166095
   Wang S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102294
   Wright T, 2017, HEALTHC TECHNOL LETT, V4, P210, DOI 10.1049/htl.2017.0070
   Yeo CT, 2011, IEEE T BIO-MED ENG, V58, P2031, DOI 10.1109/TBME.2011.2132131
   Zhao S, 2020, INT SYM MIX AUGMENT, P672, DOI [10.1109/ismar50242.2020.00097, 10.1109/ISMAR50242.2020.00097]
   Zhou C, 2020, IEEE ACCESS, V8, P73791, DOI 10.1109/ACCESS.2020.2988678
   Zolotas M, 2018, IEEE INT C INT ROBOT, P1823, DOI 10.1109/IROS.2018.8594002
NR 115
TC 7
Z9 8
U1 10
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5062
EP 5082
DI 10.1109/TVCG.2022.3201120
PG 21
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300017
PM 36001512
OA hybrid
DA 2024-11-06
ER

PT J
AU Li, XZ
   Huang, J
   Zhang, JS
   Sun, XK
   Xuan, HB
   Lai, YK
   Xie, YD
   Yang, JY
   Li, K
AF Li, Xiongzheng
   Huang, Jing
   Zhang, Jinsong
   Sun, Xiaokun
   Xuan, Haibiao
   Lai, Yu-Kun
   Xie, Yingdi
   Yang, Jingyu
   Li, Kun
TI Learning to Infer Inner-Body Under Clothing From Monocular Video
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Shape; Clothing; Image reconstruction;
   Cameras; Transformers; Solid modeling; Inner-body; under clothing;
   reconstruction; single RGB camera; transformer
ID SHAPE
AB Accurately estimating the human inner-body under clothing is very important for body measurement, virtual try-on and VR/AR applications. In this article, we propose the first method to allow everyone to easily reconstruct their own 3D inner-body under daily clothing from a self-captured video with the mean reconstruction error of 0.73cm within 15s. This avoids privacy concerns arising from nudity or minimal clothing. Specifically, we propose a novel two-stage framework with a Semantic-guided Undressing Network (SUNet) and an Intra-Inter Transformer Network (IITNet). SUNet learns semantically related body features to alleviate the complexity and uncertainty of directly estimating 3D inner-bodies under clothing. IITNet reconstructs the 3D inner-body model by making full use of intra-frame and inter-frame information, which addresses the misalignment of inconsistent poses in different frames. Experimental results on both public datasets and our collected dataset demonstrate the effectiveness of the proposed method. The code and dataset is available for research purposes at http://cic.tju.edu.cn/faculty/likun/projects/Inner-Body
C1 [Li, Xiongzheng; Huang, Jing; Zhang, Jinsong; Sun, Xiaokun; Xuan, Haibiao; Li, Kun] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 4AG, Wales.
   [Xie, Yingdi] VRC Inc, Tokyo 1920046, Japan.
   [Yang, Jingyu] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University; Cardiff University; Tianjin University
RP Li, K (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lxz@tju.edu.cn; hj00@tju.edu.cn; jinszhang@tju.edu.cn;
   2021244139@tju.edu.cn; hbxuan@tju.edu.cn; Yukun.Lai@cs.cardiff.ac.uk;
   yingdi.xie@vrcjp.com; yjy@tju.edu.cn; lik@tju.edu.cn
RI Yang, jingyu/AAA-2088-2021; Lai, Yu-Kun/D-2343-2010; Zhang,
   Liang/F-7144-2015
OI Jinsong, Zhang/0000-0001-9619-5030; Lai, Yukun/0000-0002-2094-5680;
   Huang, Jing/0009-0003-3833-7629
FU National Natural Science Foundation of China [62171317, 62122058]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 62171317 and 62122058.
CR Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Balan AO, 2008, LECT NOTES COMPUT SC, V5303, P15, DOI 10.1007/978-3-540-88688-4_2
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   C. V. F. LLC, 2010, CLO3D
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen X, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3478518
   Choi H, 2020, EUR C COMP VIS, P769
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Ferrari C, 2021, J IMAGING, V7, DOI 10.3390/jimaging7120257
   Gao ZP, 2020, IEEE COMPUT SOC CONF, P1426, DOI 10.1109/CVPRW50498.2020.00182
   Genay A, 2022, IEEE T VIS COMPUT GR, V28, P5071, DOI 10.1109/TVCG.2021.3099290
   Guan P, 2009, IEEE I CONF COMP VIS, P1381, DOI 10.1109/iccv.2009.5459300
   Gyeongsik Moon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P752, DOI 10.1007/978-3-030-58571-6_44
   He T, 2020, Arxiv, DOI arXiv:2006.08072
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Ke ZH, 2022, Arxiv, DOI arXiv:2011.11961
   Kingma DP, 2014, ADV NEUR IN, V27
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11585, DOI 10.1109/ICCV48922.2021.01140
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Li JF, 2021, PROC CVPR IEEE, P3382, DOI 10.1109/CVPR46437.2021.00339
   Li K, 2021, IEEE T IMAGE PROCESS, V30, P5239, DOI 10.1109/TIP.2021.3080177
   Li PK, 2022, IEEE T PATTERN ANAL, V44, P3260, DOI 10.1109/TPAMI.2020.3048039
   Liang JB, 2019, IEEE I CONF COMP VIS, P4351, DOI 10.1109/ICCV.2019.00445
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Liu W, 2019, IEEE I CONF COMP VIS, P5903, DOI 10.1109/ICCV.2019.00600
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Luan T., 2021, arXiv
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pujades S, 2019, IEEE T VIS COMPUT GR, V25, P1887, DOI 10.1109/TVCG.2019.2898748
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rui Zhu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P316, DOI 10.1007/978-3-030-58621-8_19
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Sarakatsanos O, 2021, INT SYM MIX AUGMENT, P40, DOI 10.1109/ISMAR-Adjunct54149.2021.00018
   Su ZQ, 2022, IEEE T VIS COMPUT GR, V28, P1862, DOI 10.1109/TVCG.2020.3027763
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Wuhrer S, 2014, COMPUT VIS IMAGE UND, V127, P31, DOI 10.1016/j.cviu.2014.06.012
   Xu Y, 2019, INT SYM MIX AUGMENT, P37, DOI 10.1109/ISMAR.2019.00-28
   Yang S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3026479
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
   Zhang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11426, DOI 10.1109/ICCV48922.2021.01125
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
NR 51
TC 3
Z9 3
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5083
EP 5096
DI 10.1109/TVCG.2022.3202240
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300018
PM 36037448
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Wang, KK
   Peng, SD
   Zhou, XW
   Yang, J
   Zhang, GF
AF Wang, Kangkan
   Peng, Sida
   Zhou, Xiaowei
   Yang, Jian
   Zhang, Guofeng
TI NerfCap: Human Performance Capture With Dynamic Neural Radiance Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Strain; Videos; Geometry; Three-dimensional displays; Deformable models;
   Clothing; Image reconstruction; Human performance capture; dynamic
   neural radiance fields; human deformation fields
ID DEFORMATION
AB This paper addresses the challenge of human performance capture from sparse multi-view or monocular videos. Given a template mesh of the performer, previous methods capture the human motion by non-rigidly registering the template mesh to images with 2D silhouettes or dense photometric alignment. However, the detailed surface deformation cannot be recovered from the silhouettes, while the photometric alignment suffers from instability caused by appearance variation in the videos. To solve these problems, we propose NerfCap, a novel performance capture method based on the dynamic neural radiance field (NeRF) representation of the performer. Specifically, a canonical NeRF is initialized from the template geometry and registered to the video frames by optimizing the deformation field and the appearance model of the canonical NeRF. To capture both large body motion and detailed surface deformation, NerfCap combines linear blend skinning with embedded graph deformation. In contrast to the mesh-based methods that suffer from fixed topology and texture, NerfCap is able to flexibly capture complex geometry and appearance variation across the videos, and synthesize more photo-realistic images. In addition, NerfCap can be pre-trained end to end in a self-supervised manner by matching the synthesized videos with the input videos. Experimental results on various datasets show that NerfCap outperforms prior works in terms of both surface reconstruction accuracy and novel-view synthesis quality.
C1 [Wang, Kangkan; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens In, Minist Educ, Nanjing 210094, Jiangsu, Peoples R China.
   [Peng, Sida; Zhou, Xiaowei; Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD&CG, Zijingang Campus, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Nanjing University of Science & Technology; Zhejiang University
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Zijingang Campus, Hangzhou 310058, Zhejiang, Peoples R China.
EM wangkangkan@njust.edu.cn; pengsida@zju.edu.cn; xwzhou@zju.edu.cn;
   csjyang@njust.edu.cn; zhangguofeng@cad.zju.edu.cn
RI zhang, Guofeng/H-4991-2011
OI Zhang, Guofeng/0000-0001-5661-8430; Peng, Sida/0000-0001-6546-4525
FU Natural Science Foundation of China [62172364, U1713208]; Program for
   Changjiang Scholars; Fundamental Research Funds for the Central
   Universities [NJ2022028]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 62172364 and U1713208, in part by the Program for
   Changjiang Scholars, and in part by the Fundamental Research Funds for
   the Central Universities under Grant NJ2022028.
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Arnab A, 2019, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2019.00351
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Boyi Jiang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P18, DOI 10.1007/978-3-030-58565-5_2
   Chen X, 2021, INT J COMPUT VISION, V129, P2846, DOI 10.1007/s11263-021-01486-4
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Dou MS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925969
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Habermann M, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459749
   Habermann M, 2020, PROC CVPR IEEE, P5051, DOI 10.1109/CVPR42600.2020.00510
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Jiang B., 2022, P IEEE CVF C COMP VI, P5605
   Jiang HY, 2019, IEEE I CONF COMP VIS, P5430, DOI 10.1109/ICCV.2019.00553
   Joo H, 2018, PROC CVPR IEEE, P8320, DOI 10.1109/CVPR.2018.00868
   Kanazawa A, 2019, PROC CVPR IEEE, P5597, DOI 10.1109/CVPR.2019.00576
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kingma D.P., 2014, P INT C LEARNING REP
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Lassner C, 2017, PROC CVPR IEEE, P4704, DOI 10.1109/CVPR.2017.500
   Lewis JP, 2000, COMP GRAPH, P165, DOI 10.1145/344779.344862
   Liu L., 2021, ACM T GRAPHIC, V40, P1
   Liu YB, 2011, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2011.5995424
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma QL, 2021, PROC CVPR IEEE, P16077, DOI 10.1109/CVPR46437.2021.01582
   Ma QL, 2020, PROC CVPR IEEE, P6468, DOI 10.1109/CVPR42600.2020.00650
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Oechsle M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5569, DOI 10.1109/ICCV48922.2021.00554
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Patel C, 2020, PROC CVPR IEEE, P7363, DOI 10.1109/CVPR42600.2020.00739
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Peng SD, 2021, Arxiv, DOI arXiv:2105.02872
   Peng SD, 2021, PROC CVPR IEEE, P9050, DOI 10.1109/CVPR46437.2021.00894
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pons-Moll G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073711
   Prokudin S, 2019, IEEE I CONF COMP VIS, P4331, DOI 10.1109/ICCV.2019.00443
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Saito S, 2021, PROC CVPR IEEE, P2885, DOI 10.1109/CVPR46437.2021.00291
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Vlasic D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618520
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang KK, 2020, PROC CVPR IEEE, P7273, DOI 10.1109/CVPR42600.2020.00730
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Xu Hongyi, 2021, Advances in Neural Information Processing Systems (NeurIPS), V34, P14955
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yu T, 2018, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR.2018.00761
   Yu T, 2017, IEEE I CONF COMP VIS, P910, DOI 10.1109/ICCV.2017.104
   Zhang JY, 2019, IEEE I CONF COMP VIS, P7113, DOI 10.1109/ICCV.2019.00721
   Zhao FQ, 2022, PROC CVPR IEEE, P7733, DOI 10.1109/CVPR52688.2022.00759
   Zhao H, 2022, PROC CVPR IEEE, P15883, DOI 10.1109/CVPR52688.2022.01544
   Zheng ZR, 2018, LECT NOTES COMPUT SC, V11213, P389, DOI 10.1007/978-3-030-01240-3_24
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462
NR 60
TC 3
Z9 3
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5097
EP 5110
DI 10.1109/TVCG.2022.3202503
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300019
PM 36040949
DA 2024-11-06
ER

PT J
AU Jiao, B
   Lu, X
   Xia, JB
   Gupta, BB
   Bao, L
   Zhou, QS
AF Jiao, Bo
   Lu, Xin
   Xia, Jingbo
   Gupta, Brij Bhooshan
   Bao, Lei
   Zhou, Qingshan
TI Hierarchical Sampling for the Visualization of Large Scale-Free Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Partitioning algorithms; Scalability; Generators; Shape
   measurement; Clustering algorithms; Analytical models; Graph sampling;
   large scale-free graph; graph visualization
ID NETWORKS
AB Graph sampling frequently compresses a large graph into a limited screen space. This paper proposes a hierarchical structure model that partitions scale-free graphs into three blocks: the core, which captures the underlying community structure, the vertical graph, which represents minority structures that are important in visual analysis, and the periphery, which describes the connection structure between low-degree nodes. A new algorithm named hierarchical structure sampling (HSS) was then designed to preserve the characteristics of the three blocks, including complete replication of the connection relationship between high-degree nodes in the core, joint node/degree distribution between high- and low-degree nodes in the vertical graph, and proportional replication of the connection relationship between low-degree nodes in the periphery. Finally, the importance of some global statistical properties in visualization was analyzed. Both the global statistical properties and local visual features were used to evaluate the proposed algorithm, which verify that the algorithm can be applied to sample scale-free graphs with hundreds to one million nodes from a visualization perspective.
C1 [Jiao, Bo; Xia, Jingbo; Bao, Lei] Xiamen Univ, Sch Informat Sci & Technol, Tan Kah Kee Coll, Zhangzhou 361005, Fujian, Peoples R China.
   [Lu, Xin; Zhou, Qingshan] Foshan Univ, Sch Math & Big Data, Foshan 528011, Guangdong, Peoples R China.
   [Gupta, Brij Bhooshan] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 413, Taiwan.
   [Gupta, Brij Bhooshan] Lebanese Amer Univ, Beirut 1102, Lebanon.
   [Gupta, Brij Bhooshan] King Abdulaziz Univ, Jeddah 21589, Saudi Arabia.
C3 Xiamen University; Foshan University; Asia University Taiwan; Lebanese
   American University; King Abdulaziz University
RP Jiao, B (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Tan Kah Kee Coll, Zhangzhou 361005, Fujian, Peoples R China.
EM bjluoyang@hotmail.com; luxin1024@126.com; jbxiad@xujc.com;
   gupta.brij@ieee.org; blnj2000@xujc.com; q476308142@qq.com
RI Jiao, Bo/GOG-8250-2022
FU Guangdong Basic and Applied Basic Research Foundation [2021A1515012289,
   2019A1515110279]; National Natural Science Foundation of China
   [61402485, 12001104, 61802063, 61901116]; Natural Science Foundation of
   Fujian Province of China [2022J01047]
FX Thisworkwas supported in part by Guangdong Basic and Applied Basic
   Research Foundation under Grants 2021A1515012289 and 2019A1515110279, in
   part by the National Natural Science Foundation of China under Grants
   61402485, 12001104, 61802063, and 61901116, and in part by the Natural
   Science Foundation of Fujian Province of China underGrant 2022J01047.
CR Accongiagioco G, 2015, COMPUT NETW, V77, P73, DOI 10.1016/j.comnet.2014.11.007
   Angori L, 2022, IEEE T VIS COMPUT GR, V28, P1288, DOI 10.1109/TVCG.2020.3016055
   Barabási AL, 2001, PHYSICA A, V299, P559, DOI 10.1016/S0378-4371(01)00369-7
   Buccafurri F, 2014, INFORM SCIENCES, V256, P126, DOI 10.1016/j.ins.2013.08.046
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen C, 2016, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2903148
   Chen M, 2007, PHYSICA A, V385, P707, DOI 10.1016/j.physa.2007.07.032
   Cooperative Association for Internet Data Analysis, About us
   Csermely P, 2013, J COMPLEX NETW, V1, P93, DOI 10.1093/comnet/cnt016
   Czégel D, 2015, SCI REP-UK, V5, DOI 10.1038/srep17994
   Du X., 2019, Int. J. Inf. Technol. Manage., V18, P227
   Du ZY, 2022, BIOINFORMATICS, V38, P962, DOI 10.1093/bioinformatics/btab781
   Dzwinel W, 2017, J COMPUT SCI-NETH, V21, P448, DOI 10.1016/j.jocs.2016.09.001
   github, 2021, about us
   Haddadi H, 2008, IEEE COMMUN SURV TUT, V10, P49, DOI 10.1109/COMST.2008.4564479
   Jiao B, 2016, PHYSICA A, V451, P632, DOI 10.1016/j.physa.2016.01.096
   Jiao B, 2016, TELECOMMUN SYST, V62, P231, DOI 10.1007/s11235-015-0077-7
   Jiao B, 2014, IET COMMUN, V8, P2845, DOI 10.1049/iet-com.2014.0183
   Krishnamurthy V, 2007, COMPUT NETW, V51, P4284, DOI 10.1016/j.comnet.2007.06.004
   Lee C., 2012, P ACM SIGMETRICS, P19
   Leskovec J., 2006, P 12 ACM SIGKDD INT, P631
   Leskovec J., 2005, P 11 ACM SIGKDD INT, P177, DOI DOI 10.1145/1081870.1081893
   Liang RZ, 2021, PHYSICA A, V567, DOI 10.1016/j.physa.2020.125726
   Liao HC, 2014, INT J INTELL SYST, V29, P971, DOI 10.1002/int.21672
   Mahadevan P, 2007, ACM SIGCOMM COMP COM, V37, P325, DOI 10.1145/1282427.1282417
   Mohammadi M, 2021, J SUPERCOMPUT, V77, P6056, DOI 10.1007/s11227-020-03510-9
   Náther P, 2009, PHYSICA A, V388, P5036, DOI 10.1016/j.physa.2009.08.027
   Pan JC, 2021, IEEE T VIS COMPUT GR, V27, P1655, DOI 10.1109/TVCG.2020.3030393
   Nguyen QH, 2017, IEEE T VIS COMPUT GR, V23, P1600, DOI 10.1109/TVCG.2017.2674999
   Rombach P, 2017, SIAM REV, V59, P619, DOI 10.1137/17M1130046
   stanford, 2014, Stanford Large Network Dataset Collection
   Stumpf MPH, 2005, P NATL ACAD SCI USA, V102, P4221, DOI 10.1073/pnas.0501179102
   Trusina A, 2004, PHYS REV LETT, V92, DOI 10.1103/PhysRevLett.92.178702
   Tudisco F, 2019, SIAM J MATH DATA SCI, V1, P269, DOI 10.1137/18M1183558
   Voudigari E, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P120, DOI 10.1109/ASONAM.2016.7752223
   Winick J., 2002, Inet-3.0: Internet topology generator
   Wu YH, 2017, IEEE T VIS COMPUT GR, V23, P401, DOI 10.1109/TVCG.2016.2598867
   Yang XH, 2013, PHYSICA A, V392, P2547, DOI 10.1016/j.physa.2013.01.038
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Yoon SH, 2015, INFORM SCIENCES, V306, P53, DOI 10.1016/j.ins.2015.02.014
   Yousuf MI, 2020, DATA MIN KNOWL DISC, V34, P905, DOI 10.1007/s10618-020-00683-y
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhou S, 2004, IEEE COMMUN LETT, V8, P180, DOI 10.1109/LCOMM.2004.823426
   Zhou ZG, 2021, IEEE T VIS COMPUT GR, V27, P1709, DOI 10.1109/TVCG.2020.3030440
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 45
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5111
EP 5123
DI 10.1109/TVCG.2022.3201567
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300020
PM 36006887
DA 2024-11-06
ER

PT J
AU Yang, GW
   Zhou, WY
   Peng, HY
   Liang, D
   Mu, TJ
   Hu, SM
AF Yang, Guo-Wei
   Zhou, Wen-Yang
   Peng, Hao-Yang
   Liang, Dun
   Mu, Tai-Jiang
   Hu, Shi-Min
TI Recursive-NeRF: An Efficient and Dynamically Growing NeRF
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Neural networks; Complexity theory;
   Uncertainty; Training; Three-dimensional displays; Image color analysis;
   Scene representation; view synthesis; image-based rendering; volume
   rendering; 3D deep learning
ID REPRESENTATION
AB View synthesis methods using implicit continuous shape representations learned from a set of images, such as the Neural Radiance Field (NeRF) method, have gained increasing attention due to their high quality imagery and scalability to high resolution. However, the heavy computation required by its volumetric approach prevents NeRF from being useful in practice; minutes are taken to render a single image of a few megapixels. Now, an image of a scene can be rendered in a level-of-detail manner, so we posit that a complicated region of the scene should be represented by a large neural network while a small neural network is capable of encoding a simple region, enabling a balance between efficiency and quality. Recursive-NeRF is our embodiment of this idea, providing an efficient and adaptive rendering and training approach for NeRF. The core of Recursive-NeRF learns uncertainties for query coordinates, representing the quality of the predicted color and volumetric intensity at each level. Only query coordinates with high uncertainties are forwarded to the next level to a bigger neural network with a more powerful representational capability. The final rendered image is a composition of results from neural networks of all levels. Our evaluation on public datasets and a large-scale scene dataset we collected shows that Recursive-NeRF is more efficient than NeRF while providing state-of-the-art quality. The code will be available at https://github.com/Gword/Recursive-NeRF
C1 [Yang, Guo-Wei; Zhou, Wen-Yang; Peng, Hao-Yang; Liang, Dun; Mu, Tai-Jiang; Hu, Shi-Min] Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Hu, SM (corresponding author), Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
EM ygw19@mails.tsinghua.edu.cn; zhouwy19@mails.tsinghua.edu.cn;
   phy18@mails.tsinghua.edu.cn; randonlang@gmail.com;
   taijiang@tsinghua.edu.cn; shimin@tsinghua.edu.cn
RI Hu, Shi-Min/AAW-1952-2020; Mu, Tai-Jiang/JWO-1381-2024; Wenyang,
   Zhou/GSD-3239-2022
OI Hu, Shi-Min/0000-0001-7507-6542; Mu, Tai-Jiang/0000-0002-9197-346X
FU National Key R&D Program of China [2021ZD0112902]
FX This work was supported by the National Key R&D Program of China under
   Grant 2021ZD0112902.
CR Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chen Wenzheng, 2019, ADV NEURAL INFORM PR, P9605
   Cornell.edu, 2021, The cornell box
   Dosovitskiy A., 2021, Int. Conf. Learn. Represent, P1
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Google earth studio, 2018, About us
   Gu J., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Guo MH, 2022, Arxiv, DOI arXiv:2202.09741
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Hu SM, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-020-3097-4
   Huang G., 2018, PROC INT C LEARN REP
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kato H, 2020, Arxiv, DOI arXiv:2006.12057
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Li TM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275109
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Luebke D., 2003, ser. TheMorganKaufmann Series inComputerGraphics
   Ma SJ, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3024-5
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Neff T., 2021, COMPUT GRAPH FORUM, V40, P45, DOI [10.1111/cgf.14340, DOI 10.1111/CGF.14340]
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Nimier-David M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356498
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Rebain D, 2021, PROC CVPR IEEE, P14148, DOI 10.1109/CVPR46437.2021.01393
   Reizenstein J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10881, DOI 10.1109/ICCV48922.2021.01072
   Ren ZM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421637
   Schwarz K, 2020, ARXIV200702442, V33
   Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526
   Sitzmann V, 2019, ADV NEUR IN, V32
   Sitzmann V, 2019, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2019.00254
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Williams F, 2020, IEEE COMPUT SOC CONF, P1069, DOI 10.1109/CVPRW50498.2020.00140
   Xiangli Y., 2022, EUR C COMP VIS
   Xiao YP, 2020, COMPUT VIS MEDIA, V6, P113, DOI 10.1007/s41095-020-0174-8
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu YF, 2022, COMPUT VIS MEDIA, V8, P33, DOI 10.1007/s41095-021-0247-3
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Yu J., 2019, PROC INT C LEARN REP
   Yu JH, 2019, Arxiv, DOI [arXiv:1903.11728, 10.48550/ARXIV.1903.11728, DOI 10.48550/ARXIV.1903.11728]
   Yu JH, 2019, IEEE I CONF COMP VIS, P1803, DOI 10.1109/ICCV.2019.00189
   Zhang C, 2004, SIGNAL PROCESS-IMAGE, V19, P1, DOI 10.1016/j.image.2003.07.001
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 57
TC 5
Z9 6
U1 14
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5124
EP 5136
DI 10.1109/TVCG.2022.3204608
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300021
PM 36194712
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shin, JE
   Yoon, B
   Kim, D
   Woo, W
AF Shin, Jae-eun
   Yoon, Boram
   Kim, Dooyoung
   Woo, Woontack
TI The Effects of Spatial Complexity on Narrative Experience in
   Space-Adaptive AR Storytelling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Complexity theory; Visualization; Affordances; Games; Layout; Usability;
   Task analysis; Augmented reality; head mounted displays; space
   adaptivity; spatial affordance; spatial mapping; narrative experience
ID REALITY; TRANSPORTATION; AFFORDANCES
AB A critical yet unresolved challenge in designing space-adaptive narratives for Augmented Reality (AR) is to provide consistently immersive user experiences anywhere, regardless of physical features specific to a space. For this, we present a comprehensive analysis on a series of user studies investigating how the size, density, and layout of real indoor spaces affect users playing Fragments, a space-adaptive AR detective game. Based on the studies, we assert that moderate levels of traversability and visual complexity afforded in counteracting combinations of size and complexity are beneficial for narrative experience. To confirm our argument, we combined the experimental data of the studies (n=112) to compare how five different spatial complexity conditions impact narrative experience when applied to contrasting room sizes. Results show that whereas factors of narrative experience are rated significantly higher in relatively simple settings for a small space, they are less affected by complexity in a large space. Ultimately, we establish guidelines on the design and placement of space-adaptive augmentations in location-independent AR narratives to compensate for the lack or excess of affordances in various real spaces and enhance user experiences therein.
C1 [Shin, Jae-eun] KAIST ARRC, Daejeon 34051, South Korea.
   [Yoon, Boram; Kim, Dooyoung; Woo, Woontack] KAIST UVR Lab, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Woo, W (corresponding author), KAIST UVR Lab, Daejeon 34141, South Korea.
EM jaeeunshin@kaist.ac.kr; boram.yoon1206@kaist.ac.kr;
   dooyoung.kim@kaist.ac.kr; wwoo@kaist.ac.kr
RI Woo, Woontack/C-3696-2012
OI Woo, Woontack/0000-0002-5501-4421
FU National Research Council of Science and Technology - Ministry of
   Science and ICT, Republic of Korea [CRC 21011]; Institute of Information
   & Communications Technology Planning and Evaluation - Korea Government
   [2019-0-01270]; KAIST Institutional Review Board [KH2019-51, KH2020-113]
FX This work was supported in part by the National Research Council of
   Science and Technology funded by the Ministry of Science and ICT,
   Republic of Korea under Grant CRC 21011, and in part by the Institute of
   Information & Communications Technology Planning and Evaluation funded
   by the Korea Government under Grant 2019-0-01270, WISE AR UI/UX Platform
   Development for Smartglasses. This work involved human subjects or
   animals in its research. Approval of all ethical and experimental
   procedures and protocols was granted by the KAIST Institutional Review
   Board under Application Nos. KH2019-51 and KH2020-113.
CR [Anonymous], 2004, PROC 12 ANN ACM INT
   Azuma R., 2015, Fundamentals of Wearable Computers and Augmented Reality, P259, DOI DOI 10.1201/B18703-15
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bal M., 2009, Narratology: Introduction to the Theory of Narrative
   Balakrishnan B, 2011, HUM-COMPUT INTERACT, V26, P161, DOI 10.1080/07370024.2011.601689
   Bindman SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174031
   Busselle R, 2009, MEDIA PSYCHOL, V12, P321, DOI 10.1080/15213260903287259
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Chemero A, 2003, ECOL PSYCHOL, V15, P181, DOI 10.1207/S15326969ECO1502_5
   Colley A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1179, DOI 10.1145/3025453.3025495
   Domsch S., 2013, Storyplaying: Agency and Narrative in Video Games
   Dow S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1475
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Evans G, 2017, PROC SPIE, V10197, DOI 10.1117/12.2262626
   Furlan R, 2016, IEEE SPECTRUM, V53, P21, DOI 10.1109/MSPEC.2016.7473143
   Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9
   Green MC, 2004, DISCOURSE PROCESS, V38, P247, DOI 10.1207/s15326950dp3802_5
   Guo B, 2012, MULTIMED TOOLS APPL, V59, P259, DOI 10.1007/s11042-010-0711-z
   Hammady R., 2019, Augmented Reality and Virtual Reality, P217
   Harrell D.Fox., 2009, AAAI SPRING S INTELL, P44
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hidalgo F, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P306, DOI 10.1109/ICARA.2015.7081165
   Jung Yeon Ma, 2007, Journal of Multimedia, V2, P32
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim K, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1771
   Ko SM, 2013, INT J HUM-COMPUT INT, V29, P501, DOI 10.1080/10447318.2012.722466
   Lewis JR, 2002, INT J HUM-COMPUT INT, V14, P463, DOI 10.1080/10447318.2002.9669130
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Longo L, 2017, LECT NOTES COMPUT SC, V10514, P202, DOI 10.1007/978-3-319-67684-5_13
   MacIntyre B, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P197, DOI 10.1109/ISAR.2001.970538
   Mackay W.E., 1998, Proceedings of the working conference on Advanced visual interfaces, P13
   Manovich Lev., 2006, Visual Communications, V5, P219
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   McNamara N, 2005, 2005 IEEE International Professional Communication Conference (IPCC), P200
   Miller CarolynHandler., 2014, Digital Storytelling: A Creator's Guide to Interactive Storytelling A Creator's Guide to Interactive Entertainment
   Miller J, 2020, INT J ADV MANUF TECH, V109, P1741, DOI 10.1007/s00170-020-05768-y
   Nagata K, 2018, LECT NOTES COMPUT SC, V11112, P260, DOI 10.1007/978-3-319-99426-0_27
   Ng G, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P409, DOI 10.1145/3173225.3173230
   Nordin A. I., 2014, PROC INT C FOUND DIG, P1
   Pavlik JohnV., 2013, JOURNALISM COMMUNICA, V15, P4, DOI DOI 10.1177/1522637912470819
   Prince G., 1987, Dictionary of narratology
   Pyae A., 2016, PROC 28 AUSTR C COMP, P11
   Saeedi S, 2018, P IEEE, V106, P2020, DOI 10.1109/JPROC.2018.2856739
   Shilkrot R, 2014, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR-AMH.2014.6935436
   Shin J., 2021, PROC CHI C HUM FACTO, P1
   Shin JE, 2019, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2019.00-11
   Steffen JH, 2019, J MANAGE INFORM SYST, V36, P683, DOI 10.1080/07421222.2019.1628877
   Tang A., 2004, Proceedings of Presence, Seventh Annual International Workshop on Presence, Valencia, Spain, P204
   Thoss J, 2018, POETICS TODAY, V39, P623, DOI 10.1215/03335372-7032788
   Tuliper A., 2017, Hololens-Introduction to the hololens, part 2: Spatial mapping
   Wineman JD, 2010, ENVIRON BEHAV, V42, P86, DOI 10.1177/0013916509335534
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
NR 54
TC 3
Z9 3
U1 5
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5137
EP 5148
DI 10.1109/TVCG.2022.3201934
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300022
PM 36054403
DA 2024-11-06
ER

PT J
AU Ke, PC
   Cai, SY
   Gao, HC
   Zhu, KN
AF Ke, Pingchuan
   Cai, Shaoyu
   Gao, Haichen
   Zhu, Kening
TI PropelWalker: A Leg-Based Wearable System With Propeller-Based Force
   Feedback for Walking in Fluids in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Propulsion; Force; Force feedback; Foot; Propellers;
   Fans; Virtual reality; haptic; propeller; fluid
ID LOCOMOTION
AB There has been an increasing focus on haptic interfaces for virtual reality (VR), to support a high-quality touch experience. However, it is still challenging to haptically simulate the real-world walking experience in different fluid mediums. To tackle this problem, we present PropelWalker, a pair of calf-worn haptic devices for simulating the buoyancy and the resistant force when the human's lower limbs are interacting with different fluids and materials in VR. By using four ducted fans, two installed on each calf, the system can control the strength and the direction of the airflow in real time to provide different levels of force. Our technical evaluation shows that PropelWalker can generate vertical forces up to 27N in two directions (i.e., upward and downward) within 0.85 seconds. Furthermore, the system can stably maintain the generated force with minor turbulence. We further conducted three user-perception studies to understand the capability of PropelWalker to generate distinguishable force stimuli. First, we conducted the just-noticeable-difference (JND) experiments to investigate the threshold of the human perception of on-leg air-flow force feedback. Our second perception study showed that users could distinguish four PropelWalker-generated force levels for simulating different walking mediums (i.e., dry ground, water, mud, and sand), with an average accuracy of 94.2%. Lastly, our VR user study showed that PropelWalker could significantly improve the users' sense of presence in VR.
C1 [Ke, Pingchuan; Cai, Shaoyu; Gao, Haichen; Zhu, Kening] City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
   [Zhu, Kening] City Univ Hong Kong, Shenzhen Res Inst, Shenzhen 518057, Peoples R China.
C3 City University of Hong Kong; Shenzhen Research Institute, City
   University of Hong Kong; City University of Hong Kong
RP Zhu, KN (corresponding author), City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
EM pingchke-c@my.cityu.edu.hk; shaoyu.cai@my.cityu.edu.hk;
   aarongao1109@outlook.com; keninzhu@cityu.edu.hk
RI Zhu, Kening/AAI-8826-2020
OI ZHU, Kening/0000-0001-6740-4921; GAO, Haichen/0000-0001-6194-3094; KE,
   Pingchuan/0000-0003-2509-9046; CAI, Shaoyu/0000-0001-8808-3442
FU Centre for Applied Computing and Interactive Media (ACIM) of School of
   Creative Media, City University of Hong Kong; National Key Research and
   Development Program of China [2019B010149001]; National Natural Science
   Foundation of China [62172346, 61907037]; Guangdong Basic and Applied
   Basic Research Foundation [2021A1515011893]
FX This work was supported in part by the Centre for Applied Computing and
   Interactive Media (ACIM) of School of Creative Media, City University of
   Hong Kong, in part by the National Key Research and Development Program
   of China under Grant 2019B010149001, in part by the National Natural
   Science Foundation of China under Grants 62172346 and 61907037, and in
   part by Guangdong Basic and Applied Basic Research Foundation under
   Grant 2021A1515011893.
CR Abdullah M, 2018, IEEE HAPTICS SYM, P334, DOI 10.1109/HAPTICS.2018.8357197
   Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   Banala SK, 2007, INT C REHAB ROBOT, P401, DOI 10.1109/ICORR.2007.4428456
   Basdogan C, 2002, HUM FAC ER, P117
   Burdea G. C, 1996, Force and Touch Feedback for Virtual Reality
   Cai SY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P248, DOI [10.1109/VR46266.2020.00-60, 10.1109/VR46266.2020.1580801081068]
   Dobashi Y, 2007, IEEE COMPUT GRAPH, V27, P90, DOI 10.1109/MCG.2007.52
   Dreyfuss Henry., 1967, The Measure of Man: Human Factors in Design
   DRILLIS R, 1964, Artif Limbs, V8, P44
   Elvitigala DS, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P228, DOI 10.1145/3458709.3458958
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Freiwald JP, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376574
   Gibbs JK, 2022, INT J HUM-COMPUT ST, V157, DOI 10.1016/j.ijhcs.2021.102717
   Green D. M., 1966, Signal detection theory and psychophysics, V1
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Heo S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174099
   Homma K, 2003, IEEE ASME INT C ADV, P908
   Hoppe Matthias, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3461734
   Ito K, 2019, SIGGRAPH ASIA 2019 EMERGING TECHNOLOGIES, P3, DOI 10.1145/3355049.3360525
   Ito K, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P622, DOI [10.1109/WHC.2019.8816111, 10.1109/whc.2019.8816111]
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Je S., 2021, P CHI C HUM FACT COM, P1
   Je SWO, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P763, DOI 10.1145/3332165.3347926
   Jones LA, 2013, IEEE T HAPTICS, V6, P268, DOI 10.1109/TOH.2012.74
   Ke PC, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365718
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P1379, DOI 10.1109/TVCG.2017.2657139
   Kojio Y, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P658, DOI 10.1109/IROS.2016.7759123
   KOLLMEIER B, 1988, J ACOUST SOC AM, V83, P1852, DOI 10.1121/1.396521
   Leek MR, 2001, PERCEPT PSYCHOPHYS, V63, P1279, DOI 10.3758/BF03194543
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Li Y, 2004, 9TH INTERNATIONAL SYMPOSIUM ON ADVANCED PACKAGING MATERIALS: PROCESSES, PROPERTIES AND INTERFACES, 2004 PROCEEDINGS, P1
   Liu SG, 2019, VIRTUAL REAL-LONDON, V23, P33, DOI 10.1007/s10055-018-0351-6
   Luo JZ, 2022, ADV SCI, V9, DOI 10.1002/advs.202105219
   Miller Robert B., 1968, P DEC 9 11 1968 FA 1, P267, DOI DOI 10.1145/1476589.1476628
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Ranasinghe N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1731, DOI 10.1145/3025453.3025723
   Roston GP, 1997, IEEE INT CONF ROBOT, P3006, DOI 10.1109/ROBOT.1997.606744
   Sasaki T, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214913
   Schmidt D, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2157, DOI 10.1145/2702123.2702253
   Schmidt H., 2005, ACM T APPL PERCEPT, V2, P166
   Serafin S., 2010, Proceedings of Eurohaptics, P61
   Shigeyama J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300241
   Son H, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P241, DOI [10.1109/WHC.2019.8816165, 10.1109/whc.2019.8816165]
   Strohmeier Paul, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P579, DOI 10.1145/3379337.3415828
   Sun YQ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300682
   Takeuchi Y., 2010, P 23 ANN ACM S US IN
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Teng SY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P5, DOI 10.1145/3242587.3242628
   Tsutomu Miyasato HaruoNoma., 1999, P ASME INT MECH ENG, P405
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Wang C., 2020, P CHI C HUM FACT COM, P1
   Wang TH, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 EMERGING TECHNOLOGIES, DOI 10.1145/3476122.3484837
   Whitmire E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173660
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Yang TH, 2021, IEEE T HAPTICS, V14, P83, DOI 10.1109/TOH.2020.3017099
   Yokota T., 2015, P 6 AUGM HUM INT C, P45, DOI 10.1145/2735711.2735829
   Yoshida S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376358
   Zhao L, 2021, IEEE T VIS COMPUT GR, V27, P2618, DOI 10.1109/TVCG.2021.3067778
   Zhu KN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300923
NR 60
TC 4
Z9 4
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5149
EP 5164
DI 10.1109/TVCG.2022.3205181
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300023
PM 36074874
DA 2024-11-06
ER

PT J
AU Mörth, E
   Bruckner, S
   Smit, NN
AF Morth, Eric
   Bruckner, Stefan
   Smit, Noeska N.
TI ScrollyVis: Interactive Visual Authoring of Guided Dynamic Narratives
   for Scientific Scrollytelling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Media; Motion pictures; Authoring
   systems; Writing; Web servers
AB Visual stories are an effective and powerful tool to convey specific information to a diverse public. Scrollytelling is a recent visual storytelling technique extensively used on the web, where content appears or changes as users scroll up or down a page. By employing the familiar gesture of scrolling as its primary interaction mechanism, it provides users with a sense of control, exploration and discoverability while still offering a simple and intuitive interface. In this article, we present a novel approach for authoring, editing, and presenting data-driven scientific narratives using scrollytelling. Our method flexibly integrates common sources such as images, text, and video, but also supports more specialized visualization techniques such as interactive maps as well as scalar field and mesh data visualizations. We show that scrolling navigation can be used to traverse dynamic narratives and demonstrate how it can be combined with interactive parameter exploration. The resulting system consists of an extensible web-based authoring tool capable of exporting stand-alone stories that can be hosted on any web server. We demonstrate the power and utility of our approach with case studies from several diverse scientific fields and with a user study including 12 participants of diverse professional backgrounds. Furthermore, an expert in creating interactive articles assessed the usefulness of our approach and the quality of the created stories.
C1 [Morth, Eric; Bruckner, Stefan; Smit, Noeska N.] Univ Bergen, Dept Informat, N-5007 Bergen, Norway.
   [Morth, Eric; Bruckner, Stefan; Smit, Noeska N.] Haukeland Hosp, Dept Radiol, Mohn Med Imaging & Visualizat Ctr, N-5021 Bergen, Norway.
C3 University of Bergen; University of Bergen; Haukeland University
   Hospital
RP Mörth, E (corresponding author), Univ Bergen, Dept Informat, N-5007 Bergen, Norway.
EM eric.moerth@uib.no; stefan.bruckner@uib.no; noeska.smit@uib.no
RI Moerth, Eric/HNT-0446-2023
OI Morth, Eric/0000-0003-1625-0146; Bruckner, Stefan/0000-0002-0885-8402;
   Smit, Noeska/0000-0002-3719-4625
FU Trond Mohn Foundation [813558, 811255]
FX This work was supported by Trond Mohn Foundation under Grants 811255 and
   813558.
CR Bangor A, 2009, J USABILITY STUD, V4, P114
   Blastland M, 2020, NATURE, V587, P362, DOI 10.1038/d41586-020-03189-1
   Bostock M., 2014, How to scroll
   Brooke J., 2004, Usability Evaluation in Industry, P266
   Cabello R., 2021, Three.js
   Conlen Matthew, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1, DOI 10.1145/3472749.3474731
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Dahlstrom MF, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2006720
   Dahlstrom MF, 2014, P NATL ACAD SCI USA, V111, P13614, DOI 10.1073/pnas.1320645111
   Dasu K, 2021, IEEE T VIS COMPUT GR, V27, P935, DOI 10.1109/TVCG.2020.3030412
   Demeusy V., 2021, Volume Rendering in Three.js
   Diehl A, 2021, COMPUT GRAPH FORUM, V40, P299, DOI 10.1111/cgf.14308
   Economist T., 2021, Unearthing the truth: A zimbabwean archaeologist reimagines the story of a momentous african civilisation
   Eenige C. V., 2019, Update on scroll (uos)
   Fields E., 2014, Build narratives in your dashboards with story points in Tableau 8.2
   Genette G., 1980, Comp. Literature, V32
   Godulla A., 2017, Digitale Langformen im Journalismus und Corporate Publishing, DOI [10.1007/978-3-658-17556-6, DOI 10.1007/978-3-658-17556-6]
   Hohman F., 2020, Distill.
   I. Sketchfab, 2021, Sketchfab
   Joubert M, 2019, JCOM-J SCI COMMUN, V18, DOI 10.22323/2.18050501
   Kim NW, 2018, IEEE T VIS COMPUT GR, V24, P595, DOI 10.1109/TVCG.2017.2744118
   Knightley S., 2021, jszip
   Kosara R., 2016, The Scrollytelling Scourge
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kouril D, 2023, IEEE T VIS COMPUT GR, V29, P1733, DOI 10.1109/TVCG.2021.3130670
   L_oll C., 2015, Mission jurassic: Searching for dinosaur bones
   Lancaster JL, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00023
   Lancaster JL, 2011, NEUROINFORMATICS, V9, P371, DOI 10.1007/s12021-011-9108-z
   Lancaster JL, 2010, NEUROINFORMATICS, V8, P171, DOI 10.1007/s12021-010-9074-x
   Lidal E. M., 2012, P INT S SKETCH BAS I, P11, DOI DOI 10.2312/SBM/SBM12/011-020
   Ma J, 2012, IEEE T VIS COMPUT GR, V18, P2799, DOI 10.1109/TVCG.2012.244
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Munday Rob., 2016, A guide to interactive documentary: Structure, tools and narrative
   Pettersen M., 2019, What is scrollytelling? (+Its impact on digital content): An interview
   Pimbaud B., 2012, Scrollytelling: Storytelling for the next decade
   Pimbaud B., 2020, Scrollytelling: Storytelling for the next decade
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Soler J., 2021, Drawflow
   Srivas C., 2021, Interpretable adaptive optimization
   Stornaway.io, 2021, Stornaway.io
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   TOMASULO FP, 1980, J UNIV FILM ASSOC, V32, P71
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Twine, 2021, Twine
   Vaih-Baur C., 2017, Textspiele in Der Wirtschaftskommunikation, P343, DOI [10.1007/978-3-658-18899-3_14, DOI 10.1007/978-3-658-18899-3_14]
   van Wijk JJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P15, DOI 10.1109/INFVIS.2003.1249004
   Wang ZZ, 2022, IEEE T VIS COMPUT GR, V28, P944, DOI 10.1109/TVCG.2021.3114849
   Wohlfart Michael., 2007, P JOINT EUROGRAPHICS, P91, DOI [DOI 10.2312/VISSYM/EUROVIS07/091-098, 10.2312/VisSym/EuroVis07/091-098]
NR 50
TC 5
Z9 5
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5165
EP 5177
DI 10.1109/TVCG.2022.3205769
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300024
PM 36094999
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Cao, AQ
   Lan, J
   Xie, X
   Chen, H
   Zhang, XL
   Zhang, H
   Wu, YC
AF Cao, Anqi
   Lan, Ji
   Xie, Xiao
   Chen, Hongyu
   Zhang, Xiaolong
   Zhang, Hui
   Wu, Yingcai
TI Team-Builder: Toward More Effective Lineup Selection in Soccer
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports; Data visualization; Analytical models; Trajectory; Computational
   modeling; Visual analytics; Videos; Sports visualization; lineup
   selection; design study
ID PLAYER SELECTION; VISUAL ANALYTICS; VISUALIZATION; SYSTEM; SPORT
AB Lineup selection is an essential and important task in soccer matches. To win a match, coaches must consider various factors and select appropriate players for a planned formation. Computation-based tools have been proposed to help coaches on this complex task, but they are usually based on over-simplified models on player performances, do not support interactive analysis, and overlook the inputs by coaches. In this article, we propose a method for visual analytics of soccer lineup selection by tackling two challenges: characterizing essential factors involved in generating optimal lineup, and supporting coach-driven visual analytics of lineup selection. We develop a lineup selection model that integrates such important factors, such as spatial regions of player actions and defensive interactions with opponent players. A visualization system, Team-Builder, is developed to help coaches control the process of lineup generation, explanation, and comparison through multiple coordinated views. The usefulness and effectiveness of our system are demonstrated by two case studies on a real-world soccer event dataset.
C1 [Cao, Anqi; Lan, Ji; Chen, Hongyu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
   [Zhang, Xiaolong] Penn State Univ, Coll Informat Sci & Technol, State Coll, PA 16801 USA.
C3 Zhejiang University; Zhejiang University; Pennsylvania Commonwealth
   System of Higher Education (PCSHE); Pennsylvania State University
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
EM caoanqi@zju.edu.cn; lanjizju@zju.edu.cn; xxie@zju.edu.cn;
   chenhy7820@zju.edu.cn; lzhang@ist.psu.edu; zhang_hui@zju.edu.cn;
   ycwu@zju.edu.cn
RI Lu, Yi/KEJ-2560-2024; Zhang, Xiaolong/HMD-9038-2023; LAN, JI/M-2006-2018
OI LAN, JI/0000-0002-8658-8620; Cao, Anqi/0000-0003-1794-4510; ,
   Hui/0000-0003-0601-3905
FU NSFC [62072400]; Collaborative Innovation Center of Artificial
   Intelligence by MOE and Zhejiang ProvincialGovernment (ZJU); Zhejiang
   Lab [2021KE0AC02]
FX The work was supported in part by NSFC under Grant 62072400, in part by
   the Collaborative Innovation Center of Artificial Intelligence by MOE
   and Zhejiang ProvincialGovernment (ZJU), and in part by Zhejiang Lab
   (2021KE0AC02). (Corresponding author: Xiao Xie.)
CR Al-Shboul R, 2017, INT J ADV COMPUT SC, V8, P457
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Beal R, 2020, AAAI CONF ARTIF INTE, V34, P7063
   Santos AB, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02416
   Bialkowski A, 2014, IEEE DATA MINING, P725, DOI 10.1109/ICDM.2014.133
   Boon BH, 2003, EUR J OPER RES, V148, P277, DOI 10.1016/S0377-2217(02)00684-7
   Bransen L, 2020, Arxiv, DOI arXiv:2003.01712
   Cao AQ, 2021, VIS INFORM, V5, P102, DOI 10.1016/j.visinf.2021.09.002
   Decroos T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1851, DOI 10.1145/3292500.3330758
   Decroos T, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P223, DOI 10.1145/3219819.3219832
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Eccles D., 2010, INT REV SPORT EXER P, V3, P154
   Eccles DW, 2004, J SPORT EXERCISE PSY, V26, P542, DOI 10.1123/jsep.26.4.542
   Fernandez-Navarro J, 2016, J SPORT SCI, V34, P2195, DOI 10.1080/02640414.2016.1169309
   Franks A., 2015, MIT SLOAN SPORTS AN
   Ishikawa Y, 2018, VIS INFORM, V2, P60, DOI 10.1016/j.visint2018.04.007
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Kuehn J, 2016, P MIT SLOAN SPORTS A, P1
   Lage M, 2016, IEEE COMPUT GRAPH, V36, P28, DOI 10.1109/MCG.2016.101
   Lan J, 2022, J VISUAL-JAPAN, V25, P143, DOI 10.1007/s12650-021-00772-0
   Latif S, 2019, VIS INFORM, V3, P27, DOI 10.1016/j.visinf.2019.03.004
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   Machado V, 2017, COMPUT GRAPH-UK, V68, P84, DOI 10.1016/j.cag.2017.08.006
   Maymin AllanZ., 2013, INT J COMPUTER SCI S, V12, P4, DOI DOI 10.2139/SSRN.1935972
   McEwan D, 2014, INT REV SPORT EXER P, V7, P229, DOI 10.1080/1750984X.2014.932423
   Merigó JM, 2011, EXPERT SYST APPL, V38, P10408, DOI 10.1016/j.eswa.2011.02.104
   Moon B., 2013, P WORKSH SPORTS DAT, P11
   Ni B, 2017, VIS INFORM, V1, P57, DOI 10.1016/j.visinf.2017.01.007
   Ono JP, 2018, COMPUT GRAPH FORUM, V37, P491, DOI 10.1111/cgf.13436
   Ozceylan E, 2016, S AFR J IND ENG, V27, P190, DOI 10.7166/27-2-1265
   Pappalardo L, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0247-7
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Perin C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P887, DOI 10.1145/2556288.2557379
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Perl J, 2016, ADV INTELL SYST, V392, P77, DOI 10.1007/978-3-319-24560-7_10
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Power P, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1605, DOI 10.1145/3097983.3098051
   Ruiz H, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1991, DOI 10.1145/3097983.3098121
   Rusu A, 2011, IEEE INT CONF INF VI, P194, DOI 10.1109/IV.2011.57
   Rusu A, 2010, IEEE INT CONF INF VI, P207, DOI 10.1109/IV.2010.39
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Salles Sérgio Augusto Faria, 2019, Pesqui. Oper., V39, P277
   Shao L, 2016, Electron. Imag., P1
   Shaw L., 2019, Barca Sports Analytics Summit, P1
   Malqui JLS, 2019, COMPUT GRAPH-UK, V84, P122, DOI 10.1016/j.cag.2019.08.010
   Stein M, 2019, J SPORT SCI, V37, P2774, DOI 10.1080/02640414.2019.1652541
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   Tavana M, 2013, SPORT MANAG REV, V16, P97, DOI 10.1016/j.smr.2012.06.002
   UEFA, 2021, EURO 2020 technical report
   Wang WT, 2016, J VISUAL-JAPAN, V19, P515, DOI 10.1007/s12650-015-0337-3
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zeng W, 2017, VIS INFORM, V1, P81, DOI 10.1016/j.visinf.2017.07.001
NR 61
TC 3
Z9 3
U1 11
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5178
EP 5193
DI 10.1109/TVCG.2022.3207147
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300025
PM 36112553
DA 2024-11-06
ER

PT J
AU Song, ZX
   Wang, X
   Zhu, H
   Zhou, GQ
   Wang, Q
AF Song, Zhengxi
   Wang, Xue
   Zhu, Hao
   Zhou, Guoqing
   Wang, Qing
TI Learning Reliable Gradients From Undersampled Circular Light Field for
   3D Reconstruction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Trajectory; Light fields; Reliability;
   Cameras; Image reconstruction; Estimation; 3d reconstruction; circular
   light field; CNN plus LSTM; circular epipolar plane volume (CEPV)
ID NETWORK; REGISTRATION; STEREO; DEPTH
AB The paper presents a 3D reconstruction algorithm from an undersampled circular light field (LF). With an ultra-dense angular sampling rate, every scene point captured by a circular LF corresponds to a smooth trajectory in the circular epipolar plane volume (CEPV). Thus per-pixel disparities can be calculated by retrieving the local gradients of the CEPV-trajectories. However, the continuous curve will be broken up into discrete segments in an undersampled circular LF, which leads to a noticeable deterioration of the 3D reconstruction accuracy. We observe that the coherent structure is still embedded in the discrete segments. With less noise and ambiguity, the scene points can be reconstructed using gradients from reliable epipolar plane image (EPI) regions. By analyzing the geometric characteristics of the coherent structure in the CEPV, both the trajectory itself and its gradients could be modeled as 3D predictable series. Thus a mask-guided CNN+LSTM network is proposed to learn the mapping from the CEPV with a lower angular sampling rate to the gradients under a higher angular sampling rate. To segment the reliable regions, the reliable-mask-based loss that assesses the difference between learned gradients and ground truth gradients is added to the loss function. We construct a synthetic circular LF dataset with ground truth for depth and foreground/background segmentation to train the network. Moreover, a real-scene circular LF dataset is collected for performance evaluation. Experimental results on both public and self-constructed datasets demonstrate the superiority of the proposed method over existing state-of-the-art methods.
C1 [Song, Zhengxi; Wang, Xue; Zhou, Guoqing; Wang, Qing] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Zhu, Hao] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
C3 Northwestern Polytechnical University; Nanjing University
RP Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
EM songzx@nwpu.edu.cn; xwang@nwpu.edu.cn; zhuhao_photo@nju.edu.cn;
   zhouguoqing@nwpu.edu.cn; qwang@nwpu.edu.cn
RI Zhou, Guoqing/AAY-2007-2020
OI Zhu, Hao/0000-0002-6756-9571; Wang, Qing/0000-0003-3439-0644; Wang,
   Xue/0009-0003-5224-906X
FU NSFC [62031023, 61801396]
FX This work was supported by NSFC under Grants 62031023 and 61801396.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   B. Foundation, 2017, Blender
   Baker S, 2003, IEEE T PATTERN ANAL, V25, P100, DOI 10.1109/TPAMI.2003.1159949
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5
   Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197
   Chen PH, 2020, IEEE T IMAGE PROCESS, V29, P7261, DOI 10.1109/TIP.2020.3000611
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Cignoni P., 2008, 6 EUR IT CHAPT C 200, P129, DOI [DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALCHAPCONF/129-138, 10.2312/LocalChapterEvents/ItalChap, 10.2312/LocalChapterEvents/ItalChap/ItalianChapConf2008/ 129-136, DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136]
   Criminisi A, 2005, COMPUT VIS IMAGE UND, V97, P51, DOI 10.1016/j.cviu.2004.06.001
   Cserkaszky A, 2018, EUR SIGNAL PR CONF, P241, DOI 10.23919/EUSIPCO.2018.8552998
   Feldmann I, 2004, IEEE IMAGE PROC, P1947
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Heber S, 2017, IEEE I CONF COMP VIS, P2271, DOI 10.1109/ICCV.2017.247
   Heber S, 2016, PROC CVPR IEEE, P3746, DOI 10.1109/CVPR.2016.407
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Kingma DP, 2014, ADV NEUR IN, V27
   Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270
   Li Y, 2021, IEEE T IMAGE PROCESS, V30, P2288, DOI 10.1109/TIP.2021.3051761
   Li ZX, 2020, IEEE T IMAGE PROCESS, V29, P7176, DOI 10.1109/TIP.2020.2999853
   Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394
   P. of Vision Raytracer Pty. Ltd Ltd, 2022, Pov-ray
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Shin C, 2018, PROC CVPR IEEE, P4748, DOI 10.1109/CVPR.2018.00499
   Song Z., 2019, P C OPT IM MULT TECH, VVI, P133
   Song ZX, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102847
   Tao MW, 2015, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2015.7298804
   Vianello A., 2017, Ph.D. dissertation
   Vianello A, 2018, PROC CVPR IEEE, P7327, DOI 10.1109/CVPR.2018.00765
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Wu GC, 2022, IEEE T PATTERN ANAL, V44, P5430, DOI 10.1109/TPAMI.2021.3073739
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yücer K, 2016, INT CONF 3D VISION, P249, DOI 10.1109/3DV.2016.33
   Yücer K, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2876504
   Zhang YL, 2017, IEEE INT CONF COMPUT, P67
   Zhu H, 2021, IEEE T VIS COMPUT GR, V27, P3019, DOI 10.1109/TVCG.2019.2957761
   Zhu H, 2020, IEEE T IMAGE PROCESS, V29, P85, DOI 10.1109/TIP.2019.2927330
NR 47
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5194
EP 5207
DI 10.1109/TVCG.2022.3206207
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300026
PM 36099223
DA 2024-11-06
ER

PT J
AU Prinz, LM
   Mathew, T
   Weyers, B
AF Prinz, Lisa Marie
   Mathew, Tintu
   Weyers, Benjamin
TI A Systematic Literature Review of Virtual Reality Locomotion Taxonomies
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Review
DE Taxonomy; Systematics; Bibliographies; Virtual environments; Task
   analysis; Planning; Databases; Systematic literatur review; survey;
   virtual reality; immersive virtual environments; locomotion; travel;
   taxonomies; classification; semantic similarity computation
ID TRAVEL
AB The change of the user's viewpoint in an immersive virtual environment, called locomotion, is one of the key components in a virtual reality interface. Effects of locomotion, such as simulator sickness or disorientation, depend on the specific design of the locomotion method and can influence the task performance as well as the overall acceptance of the virtual reality system. Thus, it is important that a locomotion method achieves the intended effects. The complexity of this task has increased with the growing number of locomotion methods and design choices in recent years. Locomotion taxonomies are classification schemes that group multiple locomotion methods and can aid in the design and selection of locomotion methods. Like locomotion methods themselves, there exist multiple locomotion taxonomies, each with a different focus and, consequently, a different possible outcome. However, there is little research that focuses on locomotion taxonomies. We performed a systematic literature review to provide an overview of possible locomotion taxonomies and analysis of possible decision criteria such as impact, common elements, and use cases for locomotion taxonomies. We aim to support future research on the design, choice, and evaluation of locomotion taxonomies and thereby support future research on virtual reality locomotion.
C1 [Prinz, Lisa Marie; Mathew, Tintu] Fraunhofer FKIE, Intelligent & Immers Syst Grp, D-53177 Bonn, Germany.
   [Weyers, Benjamin] Trier Univ, Human Comp Interact Grp, D-54296 Trier, Germany.
C3 Universitat Trier
RP Prinz, LM (corresponding author), Fraunhofer FKIE, Intelligent & Immers Syst Grp, D-53177 Bonn, Germany.
EM lisa.marie.prinz@fkie.fraunhofer.de; tintu.mathew@fkie.fraunhofer.de;
   weyers@uni-trier.de
OI Prinz, Lisa Marie/0000-0002-0704-7771
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Allen Institute for AI. (AI2, Semantic scholar
   Alsuhaibani M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193094
   [Anonymous], ACM digital library
   [Anonymous], 2010, DIN EN ISO 9241-210:2010
   Aranha RV, 2018, SYMP VIRTUAL AUGMENT, P47, DOI 10.1109/SVR.2018.00019
   Arns L., 2004, ACM SIGGRAPH INT C V, P104, DOI DOI 10.1145/1044588.1044608
   Arns L. L., 2002, A new taxonomy for locomotion in virtual environments
   B.V. Elsevier, Scopus
   Badampudi D., 2015, P 19 INT C EV ASS SO, P1, DOI DOI 10.1145/2745802.2745818
   Boell SK, 2015, J INF TECHNOL-UK, V30, P161, DOI 10.1057/jit.2014.26
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Booth A., 2012, Systematic approaches to a successful literature review
   Bowman D., 2004, 3D USER INTERFACES T
   Bowman D. A, 1996, Tech. Rep. GIT-GVU-96-23
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Brument H., 2021, Ph.D. dissertation
   Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259
   Cherni H., 2020, International Journal of Virtual Reality, V20, P1, DOI [DOI 10.20870/IJVR.2020.20.1.3183, 10.20870/IJVR.2020.20.1.3183, 10.20870/ijvr.2020.20.1, DOI 10.20870/IJVR.2020.20.1]
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   CHURCH KW, 1990, 27TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P76
   Correa dos Santos Alinne C., 2013, Proceedings of the 2013 XV Symposium on Virtual and Augmented Reality (SVR), P53, DOI 10.1109/SVR.2013.52
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Dewez D, 2020, INT SYM MIX AUGMENT, P452, DOI 10.1109/ISMAR50242.2020.00070
   Di Luca M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445319
   Dietz EA, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P58, DOI 10.1109/WI-IAT.2012.129
   Ferracani Andrea, 2016, P 1 INT WORKSH MULT, P21
   Fisher JA, 2017, P IEEE VIRT REAL ANN, P379, DOI 10.1109/VR.2017.7892335
   Günther T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P613, DOI [10.1109/vr.2019.8798119, 10.1109/VR.2019.8798119]
   Hale M. M., 1998, arXiv
   Hand C, 1997, COMPUT GRAPH FORUM, V16, P269, DOI 10.1111/1467-8659.00194
   Higgins J.P.T., 2019, Cochrane Handbook for Systematic Reviews of Interventions, V2nd
   Hollerbach JM, 2002, HUM FAC ER, P239
   Horrocks I, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1409360.1409377
   I. ISO, 2019, 9241-210: 2019 ergonomics of human-system interaction
   Institute of Electrical and Electronics Engineers (IEEE), IEEE Xplore
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jalali S, 2012, INT SYMP EMP SOFTWAR, P29, DOI 10.1145/2372251.2372257
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality
   JIANG Jay, 1997, INT C RES COMP LING
   Kersten-Oertel M, 2012, IEEE T VIS COMPUT GR, V18, P332, DOI 10.1109/TVCG.2011.50
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   L_ammel R., 2013, PROC 25 S IMPLEMENTA, P25, DOI [10.1145/2620678.2620681, DOI 10.1145/2620678.2620681]
   Lao C, 2021, PROCEEDINGS OF THE 2021 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2021, DOI 10.1145/3485279.3485290
   LLC Google, Google Scholar
   LLC Google, Google code archive-WordNet-blast
   Martinez ES, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P270, DOI 10.1109/VR51125.2022.00046
   McMahan RP, 2015, HUM FACTORS ERGON, P285
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mine M. R, 1995, Tech. Rep. TR95-018
   Nabiyouni M., 2017, How does interaction fidelity influence user experience in VR locomotion?
   Nabiyouni Mahdi, 2016, P 2016 ACM COMP INT, P115, DOI DOI 10.1145/3009939.3010076
   Nickerson RC, 2013, EUR J INFORM SYST, V22, P336, DOI 10.1057/ejis.2012.26
   Nilsson N. C., 2015, Ph.D. dissertation
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Oberlander A. M., 2019, PROC 27 EUR C INF SY
   Page M. J., 2021, Systematic Rev., V10, P1
   Palermo D.S., 1964, WORD ASS NORMS GRADE
   Pennsylvania State University College of Information Sciences and Technology, CiteSeerX
   Princeton University, Princeton University-WordNet
   Prinz Lisa Marie, 2022, Zenodo, DOI 10.5281/ZENODO.6389320
   Prinz LM, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P385, DOI 10.1109/VRW52623.2021.00080
   Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99
   Resnik P., 1995, INT JOINT CONF ARTIF
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Schloss Dagstuhl-Leibniz-Zentrum fur Informatik GmbH, DBLP computer science bibliography
   Schöbel SM, 2020, EUR J INFORM SYST, V29, P641, DOI 10.1080/0960085X.2020.1796531
   Schweiss T., 2019, MENSCH COMPUTER 2019, P206
   Silva R., 2019, The international journal of virtual reality, V19, P11, DOI DOI 10.20870/IJVR.2019.19.1.2908
   Slater M, 1994, Artificial Life and Virtual Reality
   Srikant R, 1997, FUTURE GENER COMP SY, V13, P161, DOI 10.1016/S0167-739X(97)00019-8
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Stevenson A., 2010, OXFORD DICT ENGLISH
   Stoev S. L., 2002, PROC ACM S VIRTUAL R, P57, DOI [10.1145/585740.585751, DOI 10.1145/585740.585751]
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Suma EA, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P27, DOI 10.1109/3DUI.2010.5444726
   Szopinski D., 2019, PROC 27 EUR C INF SY, P2
   Szopinski D., 2020, PROC 53 HAWAII INT C, P1
   Tacconelli E, 2010, The Lancet Infectious Diseases, V10, P226, DOI DOI 10.1016/S1473-3099(10)70065-7
   Tan D. S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P418, DOI 10.1145/365024.365307
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Usman M, 2017, INFORM SOFTWARE TECH, V85, P43, DOI 10.1016/j.infsof.2017.01.006
   Van Rees R., 2003, CIB Report, V284, P1
   Wang C., 2017, P 2017 C EMP METH NA, P1190
   Ware C., 1990, Computer Graphics, V24, P175, DOI 10.1145/91394.91442
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Wendt J. D., 2010, Real-walking models improve walking-in-place systems
   Yi DC, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P767, DOI [10.1109/VRW50115.2020.00234, 10.1109/VRW50115.2020.00-41]
   Zanbaka CA, 2005, IEEE T VIS COMPUT GR, V11, P694, DOI 10.1109/TVCG.2005.92
   Zhang YY, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P253, DOI 10.1145/3322276.3322357
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
NR 93
TC 5
Z9 5
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5208
EP 5223
DI 10.1109/TVCG.2022.3206915
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300027
PM 36107897
OA hybrid
DA 2024-11-06
ER

PT J
AU Kang, H
   Kang, T
   Wallraven, C
AF Kang, Hyeokmook
   Kang, Taeho
   Wallraven, Christian
TI Putting Vision and Touch into Conflict: Results From a Multimodal Mixed
   Reality Setup
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Visualization; Haptic interfaces; Resists; Task analysis;
   Real-time systems; Mixed reality; Mixed reality; perception; vision;
   haptics; dominance; hand tracking; multisensory perception
ID LEAP MOTION CONTROLLER; SHAPE INFORMATION; PERCEPTION; CATEGORIZATION;
   INTEGRATION; DOMINANCE; ACCURACY
AB What happens if we put vision and touch into conflict? Which modality "wins"? Although several previous studies have addressed this topic, they have solely focused on integration of vision and touch for low-level object properties (such as curvature, slant, or depth). In the present study, we introduce a multimodal mixed-reality setup based on real-time hand-tracking, which was used to display real-world, haptic exploration of objects in a virtual environment through a head-mounted-display (HMD). With this setup we studied multimodal conflict situations of objects varying along higher-level, parametrically-controlled global shape properties. Participants explored these objects in both unimodal and multimodal settings with the latter including congruent and incongruent conditions and differing instructions for weighting the input modalities. Results demonstrated a surprisingly clear touch dominance throughout all experiments, which in addition was only marginally influenceable through instructions to bias their modality weighting. We also present an initial analysis of the hand-tracking patterns that illustrates the potential for our setup to investigate exploration behavior in more detail.
C1 [Kang, Hyeokmook; Kang, Taeho] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.
   [Wallraven, Christian] Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.
   [Wallraven, Christian] Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea.
C3 Korea University; Korea University; Korea University
RP Wallraven, C (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Seoul 02841, South Korea.; Wallraven, C (corresponding author), Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea.
EM khm812@korea.ac.kr; tae1324@korea.ac.kr; wallraven@korea.ac.kr
OI , Taeho/0000-0003-4483-0447; Wallraven, Christian/0000-0002-2604-9115
FU National Research Foundation of Korea under Grants BK21 FOUR
   [NRF-2017M3C7A1041824, NRF-2019R1A2C2007612]; Institute of Information &
   Communications Technology Planning & Evaluation (IITP); Korea Government
   [2017-0-00451, 2019-0-00079, 2021-0-02068]
FX This work was supported in part by the National Research Foundation of
   Korea under Grants BK21 FOUR, NRF-2017M3C7A1041824, and
   NRF-2019R1A2C2007612, in part by the three Institute of Information &
   Communications Technology Planning & Evaluation (IITP), in part by Korea
   Government (2017-0-00451, Development of BCI based Brain and Cognitive
   Computing Technology for Recognizing User's Intentions using Deep
   Learning; 2019-0-00079, Department of Artificial Intelligence, Korea
   University; 2021-0-02068, Artificial Intelligence Inovation Hub).
CR Atkins JE, 2003, VISION RES, V43, P2603, DOI 10.1016/S0042-6989(03)00470-X
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Ban YK, 2015, P IEEE VIRT REAL ANN, P321, DOI 10.1109/VR.2015.7223425
   Behera SK, 2018, MULTIMED TOOLS APPL, V77, P14029, DOI 10.1007/s11042-017-5011-4
   Berger CC, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aar7010
   Bresciani JP, 2006, J VISION, V6, P554, DOI 10.1167/6.5.2
   Bulthoff H., 1996, ATTENTION PERFORM, P49
   CANON LK, 1970, J EXP PSYCHOL, V84, P141, DOI 10.1037/h0028925
   Cooke T, 2007, NEUROPSYCHOLOGIA, V45, P484, DOI 10.1016/j.neuropsychologia.2006.02.009
   de la Rosa S, 2018, BRIT J PSYCHOL, V109, P427, DOI 10.1111/bjop.12302
   de Siqueira AG, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P606, DOI 10.1109/VR50410.2021.00086
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   Dinse Hubert R, 2008, Human haptic perception: Basics and applications, P165
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Ernst MO, 2000, NAT NEUROSCI, V3, P69, DOI 10.1038/71140
   Gaissert N, 2010, J VISION, V10, DOI 10.1167/10.11.2
   Gibson JJ, 1933, J EXP PSYCHOL, V16, P1, DOI 10.1037/h0074626
   Gielis J, 2003, AM J BOT, V90, P333, DOI 10.3732/ajb.90.3.333
   Gonzalez Eric J., 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P236, DOI 10.1145/3379337.3415870
   Helbig HB, 2007, EXP BRAIN RES, V179, P595, DOI 10.1007/s00221-006-0814-y
   Helbig HB, 2012, NEUROIMAGE, V60, P1063, DOI 10.1016/j.neuroimage.2011.09.072
   Henriques DYP, 2003, EXP BRAIN RES, V150, P95, DOI 10.1007/s00221-003-1402-z
   Hillis JM, 2002, SCIENCE, V298, P1627, DOI 10.1126/science.1075396
   Jin HY, 2016, CAAI T INTELL TECHNO, V1, P104, DOI 10.1016/j.trit.2016.03.010
   Kang ZH, 2018, MULTIMED TOOLS APPL, V77, P2209, DOI 10.1007/s11042-017-4392-8
   KINNEY JS, 1970, PERCEPT PSYCHOPHYS, V8, P189, DOI 10.3758/BF03210203
   KLATZKY RL, 1985, PERCEPT PSYCHOPHYS, V37, P299, DOI 10.3758/BF03211351
   Kohli L, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P79, DOI 10.1109/3DUI.2013.6550201
   Kritsis K, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8902973
   Kwon E, 2009, INT SYM MIX AUGMENT, P201, DOI 10.1109/ISMAR.2009.5336463
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lee H., 2013, J. Vis., V13
   LEVITT H, 1971, J ACOUST SOC AM, V49, P467, DOI 10.1121/1.1912375
   Lupinetti K, 2020, LECT NOTES COMPUT SC, V12242, P420, DOI 10.1007/978-3-030-58465-8_31
   Masson HL, 2017, HUM BRAIN MAPP, V38, P842, DOI 10.1002/hbm.23422
   McCartney Robert., 2015, Proceedings of the International Conference on Image Processing, Computer Vision, and Pattern Recognition (IPCV), P3
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Phillips F, 2009, ACTA PSYCHOL, V132, P259, DOI 10.1016/j.actpsy.2009.07.010
   POWER RP, 1981, PERCEPTION, V10, P29, DOI 10.1068/p100029
   POWER RP, 1980, PERCEPTION, V9, P457, DOI 10.1068/p090457
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Rock I, 1966, NATURE PERCEPTUAL AD
   Sharma Anshul, 2018, Procedia Computer Science, V132, P551, DOI 10.1016/j.procs.2018.05.008
   Stilla R, 2008, HUM BRAIN MAPP, V29, P1123, DOI 10.1002/hbm.20456
   Todd JT, 2004, TRENDS COGN SCI, V8, P115, DOI 10.1016/j.tics.2004.01.006
   Tung JY, 2015, PHYSIOL MEAS, V36, P1025, DOI 10.1088/0967-3334/36/5/1025
   van der Horst BJ, 2008, EXP BRAIN RES, V190, P361, DOI 10.1007/s00221-008-1478-6
   Walk R. D., Intersensory Perception and Sensory Integration
   Wallraven C, 2014, PSYCHON B REV, V21, P976, DOI 10.3758/s13423-013-0563-4
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   WELCH RB, 1980, PSYCHOL BULL, V88, P638, DOI 10.1037/0033-2909.88.3.638
   Yang LC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072106
NR 52
TC 0
Z9 0
U1 1
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5224
EP 5234
DI 10.1109/TVCG.2022.3207241
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300028
PM 36112552
DA 2024-11-06
ER

PT J
AU Cheng, HJ
   Xu, CX
   Wang, JJ
   Chen, ZX
   Zhao, LX
AF Cheng, Haojie
   Xu, Chunxiao
   Wang, Jiajun
   Chen, Zhenxin
   Zhao, Lingxiao
TI Fast and Accurate Illumination Estimation Using LDR Panoramic Images for
   Realistic Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Light sources; Rendering (computer graphics); Estimation;
   Cameras; Dynamic range; Attenuation; Illumination estimation; LDR
   panoramic image; image-based lighting; realistic rendering
ID OBJECT; STATE
AB A high dynamic range (HDR) image is commonly used to reveal stereo illumination, which is crucial for generating high-quality realistic rendering effects. Compared to the high-cost HDR imaging technique, low dynamic range (LDR) imaging provides a low-cost alternative and is preferable for interactive graphics applications. However, the limited LDR pixel bit depth significantly bothers accurate illumination estimation using LDR images. The conflict between the realism and promptness of illumination estimation for realistic rendering is yet to be resolved. In this paper, an efficient method that accurately infers illuminations of real-world scenes using LDR panoramic images is proposed. It estimates multiple lighting parameters, including locations, types and intensities of light sources. In our approach, a new algorithm that extracts illuminant characteristics during the exposure attenuation process is developed to locate light sources and outline their boundaries. To better predict realistic illuminations, a new deep learning model is designed to efficiently parse complex LDR panoramas and classify detected light sources. Finally, realistic illumination intensities are calculated by recovering the inverse camera response function and extending the dynamic range of pixel values based on previously estimated parameters of light sources. The reconstructed radiance map can be used to compute high-quality image-based lighting of virtual models. Experimental results demonstrate that the proposed method is capable of efficiently and accurately computing comprehensive illuminations using LDR images. Our method can be used to produce better realistic rendering results than existing approaches.
C1 [Cheng, Haojie; Xu, Chunxiao; Wang, Jiajun; Zhao, Lingxiao] Univ Sci & Technol China, Hefei 230052, Peoples R China.
   [Cheng, Haojie; Xu, Chunxiao; Wang, Jiajun; Chen, Zhenxin; Zhao, Lingxiao] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Suzhou 215123, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Suzhou Institute of Biomedical
   Engineering & Technology, CAS
RP Zhao, LX (corresponding author), Univ Sci & Technol China, Hefei 230052, Peoples R China.
EM cmm0418@mail.ustc.edu.cn; feimos@mail.ustc.edu.cn; wangjj@sibet.ac.cn;
   chenzhenxin@sibet.ac.cn; hitic@sibet.ac.cn
RI han, yang/KHX-8947-2024; Wang, Jiajun/B-7287-2017
OI Zhao, Lingxiao/0000-0002-1952-3026; Cheng, Haojie/0000-0002-9885-763X
FU China National Key RD Plan [2020YFC2003900]
FX This work was supported in part by the China National Key R&D Plan under
   Grant 2020YFC2003900.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Barrow H., 1978, Comput. Vis. Syst., V2, P2
   Bertel T., 2020, PROC SIGGRAPH ASIA E, P1
   Calian DA, 2018, COMPUT GRAPH FORUM, V37, P51, DOI 10.1111/cgf.13341
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Debevec P.E., 2008, Recovering High Dynamic Range Radiance Maps from Photographs, P31
   Eilertsen G, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130816
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Fu G, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1873, DOI 10.1145/3394171.3413586
   Gardner MA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130891
   Gibson S, 2001, COMPUT GRAPH FORUM, V20, pC203, DOI 10.1111/1467-8659.00513
   Grossberg MD, 2004, IEEE T PATTERN ANAL, V26, P1272, DOI 10.1109/TPAMI.2004.88
   Guibas L. J., 1997, Ph.D. dissertation
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hold-Geoffroy Y, 2019, PROC CVPR IEEE, P6920, DOI 10.1109/CVPR.2019.00709
   Jung B, 2019, LIGHTING RES TECHNOL, V51, P742, DOI 10.1177/1477153518792597
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Karsch K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602146
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kingma D.P., 2014, P INT C LEARNING REP
   Knecht M., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P99, DOI 10.1109/ISMAR.2010.5643556
   Lalonde Jean-Francois, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P131, DOI 10.1109/3DV.2014.112
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee S, 2018, LECT NOTES COMPUT SC, V11206, P613, DOI 10.1007/978-3-030-01216-8_37
   LeGendre C, 2019, PROC CVPR IEEE, P5911, DOI 10.1109/CVPR.2019.00607
   Levenberg K., 1944, Q. Appl. Math, V2, P164, DOI [10.1090/QAM/10666, 10.1090/qam/10666, DOI 10.1090/QAM/10666]
   Li ZQ, 2020, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR42600.2020.00255
   Lin S, 2004, PROC CVPR IEEE, P938
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu YL, 2020, PROC CVPR IEEE, P1648, DOI 10.1109/CVPR42600.2020.00172
   Lopez-Moreno J, 2013, COMPUT GRAPH FORUM, V32, P170, DOI 10.1111/cgf.12195
   Mantiuk R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360667
   Matsushita Y., 2007, P IEEE C COMPUTER VI, P1
   Morgand A, 2017, IEEE T VIS COMPUT GR, V23, P2485, DOI 10.1109/TVCG.2017.2734538
   Mukundan R., 1998, MOMENT FUNCTIONS IMA, V100, DOI DOI 10.1142/3838
   Nimeroff J. S., 1995, Photorealistic Rendering Techniques, P373
   Park J, 2020, IEEE T VIS COMPUT GR, V26, P2002, DOI 10.1109/TVCG.2020.2973050
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd
   Rempel AG, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239490, 10.1145/1276377.1276426]
   Rhee T, 2017, IEEE T VIS COMPUT GR, V23, P1302, DOI 10.1109/TVCG.2017.2657178
   Salomon David., 2011, The Computer Graphics Manual
   Santos MS, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392403
   Sharma A., 2020, P INT C LEARN REPR
   Srinivasan PP, 2020, PROC CVPR IEEE, P8077, DOI 10.1109/CVPR42600.2020.00810
   Wang WJ, 2017, IEEE T BIO-MED ENG, V64, P1479, DOI 10.1109/TBME.2016.2609282
   Weber H, 2018, INT CONF 3D VISION, P199, DOI 10.1109/3DV.2018.00032
   Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991
   Yi RJ, 2018, LECT NOTES COMPUT SC, V11213, P321, DOI 10.1007/978-3-030-01240-3_20
   Zhan FN, 2022, IEEE T IMAGE PROCESS, V31, P2268, DOI 10.1109/TIP.2022.3151997
   Zhan FN, 2021, AAAI CONF ARTIF INTE, V35, P3287
   Zhang JS, 2019, PROC CVPR IEEE, P10150, DOI 10.1109/CVPR.2019.01040
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
NR 52
TC 2
Z9 2
U1 4
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5235
EP 5249
DI 10.1109/TVCG.2022.3205614
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300029
PM 36094998
DA 2024-11-06
ER

PT J
AU Mao, AH
   Dong, WB
   Xie, CQ
   Wang, HM
   Liu, YJ
   Li, GQ
   He, Y
AF Mao, Aihua
   Dong, Wenbo
   Xie, Chaoqiang
   Wang, Huamin
   Liu, Yong-Jin
   Li, Guiqing
   He, Ying
TI Yarn-Level Simulation of Hygroscopicity of Woven Textiles
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Textiles; Liquids; Computational modeling; Yarn; Fluids; Fabrics;
   Visualization; Anisotropic textile; fluid dynamics; physical models;
   microscopic simulation; liquid-textile interaction
ID MOISTURE DIFFUSION; COUPLED DIFFUSION; HEAT; DYNAMICS; SORPTION;
   FABRICS; MODEL
AB Simulating liquid-textile interaction has received great attention in computer graphics recently. Most existing methods take textiles as particles or parameterized meshes. Although these methods can generate visually pleasing results, they cannot simulate water content at a microscopic level due to the lack of geometrically modeling of textile's anisotropic structure. In this paper, we develop a method for yarn-level simulation of hygroscopicity of textiles and evaluate it using various quantitative metrics. We model textiles in a fiber-yarn-fabric multi-scale manner and consider the dynamic coupled physical mechanisms of liquid spreading, including wetting, wicking, moisture sorption/desorption, and transient moisture-heat transfer in textiles. Our method can accurately simulate liquid spreading on textiles with different fiber materials and geometrical structures with consideration of air temperatures and humidity conditions. It visualizes the hygroscopicity of textiles to demonstrate their moisture management ability. We conduct qualitative and quantitative experiments to validate our method and explore various factors to analyze their influence on liquid spreading and hygroscopicity of textiles.
C1 [Mao, Aihua; Dong, Wenbo; Li, Guiqing] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Xie, Chaoqiang] South China Univ Technol, Sch Software Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Wang, Huamin] Style3D Res, Shanghai 200001, Peoples R China.
   [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, BNRist, Beijing 100084, Peoples R China.
   [He, Ying] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 South China University of Technology; South China University of
   Technology; Tsinghua University; Nanyang Technological University
RP Wang, HM (corresponding author), Style3D Res, Shanghai 200001, Peoples R China.
EM ahmao@scut.edu.cn; 875158248@scut.edu.cn; 201921043082@mail.scut.edu.cn;
   wanghmin@style3d.com; liuyongjin@tsinghua.edu.cn; ligq@scut.edu.cn;
   yhe@ntu.edu.sg
RI He, Ying/A-3708-2011; Wang, Huamin/D-2600-2012; Dong,
   Wenbo/ABC-7930-2021
OI Wang, Huamin/0000-0002-8153-2337; Aihua, Mao/0000-0001-6861-9414
FU NSF of Guangdong Province [2019A1515010833, 2022A1515011573]; Natural
   Science Foundation of China [61725204, 61972160]; Tsinghua University
   Initiative Scientific Research Program [20211080093]; Ministry of
   Education, Singapore, under its Academic Research Fund Tier 1 [RG20/20]
FX This work was partially supported in part by the NSF of Guangdong
   Province under Grants 2019A1515010833 and 2022A1515011573, in part by
   the Natural Science Foundation of China under Grants 61725204 and
   61972160, in part by Tsinghua University Initiative Scientific Research
   Program under Grant 20211080093, and in part by the Ministry of
   Education, Singapore, under its Academic Research Fund Tier 1 (RG20/20).
CR A. T. M, 2009, Tech. Rep. 195-2011.
   Adabala N., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P178
   [Anonymous], 2011, PROC 27 SPRING C COM
   Baraff D., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P43, DOI 10.1145/280814.280821
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J., 2015, ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P147
   Chen YJ, 2012, VISUAL COMPUT, V28, P765, DOI 10.1007/s00371-012-0687-y
   Cirio G, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661279
   De Gennes P.-G., 2004, Capillarity and Wetting Phenomena: Drops, Bubbles, Pearls, Waves, V315
   de Goes F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766901
   FARNWORTH B, 1986, TEXT RES J, V56, P653, DOI 10.1177/004051758605601101
   Fei Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201392
   Gerszewski D., 2009, PROC ACM SIGGRAPHEUR, P133, DOI DOI 10.1145/1599470.1599488
   Gregson J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185548
   Haghi A.K., 2011, Heat Mass Transfer in Textiles, VSecond
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   HOUSE DH, 2000, CLOTH MODELING ANIMA
   HSIEH YL, 1995, TEXT RES J, V65, P299, DOI 10.1177/004051759506500508
   Huber M., 2011, P ACM SIGGRAPH
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ihmsen Markus, 2014, EUROGRAPHICS 2014 ST
   Jakob W, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778790
   Kaldor JM, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360664
   Khungurn P, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2818648
   Kim T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360649
   Kissa E, 1996, TEXT RES J, V66, P660, DOI 10.1177/004051759606601008
   Lee JJ, 2017, TEXT RES J, V87, P1752, DOI 10.1177/0040517516659374
   Lenaerts T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360648
   LI Y, 1992, TEXT RES J, V62, P211, DOI 10.1177/004051759206200405
   Li Y, 2003, TEXT RES J, V73, P515
   Li Y, 2000, J TEXT I, V91, P302, DOI 10.1080/00405000008659508
   Liu YJ, 2010, COMPUT IND, V61, P576, DOI 10.1016/j.compind.2010.03.007
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Lukas D, 1997, J TEXT I, V88, P149, DOI 10.1080/00405009708658539
   Mao AH, 2009, NUMER HEAT TR A-APPL, V56, P246, DOI 10.1080/10407780903163330
   Mercier O, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818115
   Morris JP, 2000, INT J NUMER METH FL, V33, P333, DOI 10.1002/1097-0363(20000615)33:3<333::AID-FLD11>3.0.CO;2-7
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Narayanan V, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322995
   Nielsen F, 2005, INFORM PROCESS LETT, V93, P263, DOI 10.1016/j.ipl.2004.12.006
   NORDON P, 1967, INT J HEAT MASS TRAN, V10, P853, DOI 10.1016/0017-9310(67)90065-8
   Patkar S, 2013, IEEE T VIS COMPUT GR, V19, P1592, DOI 10.1109/TVCG.2013.8
   Patnaik A, 2006, TEXT PROG, V38, P1, DOI [10.1533/jotp.2006.38.1.1, 10.1533/tepr.2006.0001]
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Wang HM, 2005, ACM T GRAPHIC, V24, P921, DOI 10.1145/1073204.1073284
   Washburn EW, 1921, PHYS REV, V17, P273, DOI 10.1103/PhysRev.17.273
   Watt I.C., 1960, TEXTILE RES J, V30, P644, DOI DOI 10.1177/004051756003000902
   Yan X, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925897
   Yao BG, 2006, POLYM TEST, V25, P677, DOI 10.1016/j.polymertesting.2006.03.014
   Zhang JH, 2013, IEEE T VIS COMPUT GR, V19, P420, DOI 10.1109/TVCG.2012.66
   Zhao S, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925932
   Zhao S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185571
   Zheng Y, 2019, IEEE T VIS COMPUT GR, V25, P2471, DOI 10.1109/TVCG.2018.2832039
NR 53
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5250
EP 5264
DI 10.1109/TVCG.2022.3206579
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300030
PM 36103450
DA 2024-11-06
ER

PT J
AU Adhikari, A
   Zielasko, D
   Aguilar, I
   Bretin, A
   Kruijff, E
   von der Heyde, M
   Riecke, BE
AF Adhikari, Ashu
   Zielasko, Daniel
   Aguilar, Ivan
   Bretin, Alexander
   Kruijff, Ernst
   von der Heyde, Markus
   Riecke, Bernhard E.
TI Integrating Continuous and Teleporting VR Locomotion into a Seamless
   HyperJump Paradigm
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teleportation; Cybersickness; Optical flow; Task analysis; Navigation;
   Animation; Virtual environments; Virtual reality; spatial updating;
   leaning; teleportation; locomotion; semi-continuous locomotion
ID VIRTUAL ENVIRONMENTS; SPATIAL ORIENTATION; PATH-INTEGRATION; NAVIGATION;
   REALITY; TRAVEL
AB Continuous locomotion in VR provides uninterrupted optical flow, which mimics real-world locomotion and supports path integration. However, optical flow limits the maximum speed and acceleration that can be effectively used without inducing cybersickness. In contrast, teleportation provides neither optical flow nor acceleration cues, and users can jump to any length without increasing cybersickness. However, teleportation cannot support continuous spatial updating and can increase disorientation. Thus, we designed 'HyperJump' in an attempt to merge benefits from continuous locomotion and teleportation. HyperJump adds iterative jumps every half a second on top of the continuous movement and was hypothesized to facilitate faster travel without compromising spatial awareness/orientation. In a user study, Participants travelled around a naturalistic virtual city with and without HyperJump (equivalent maximum speed). They followed waypoints to new landmarks, stopped near them and pointed back to all previously visited landmarks in random order. HyperJump was added to two continuous locomotion interfaces (controller- and leaning-based). Participants had better spatial awareness/orientation with leaning-based interfaces compared to controller-based (assessed via rapid pointing). With HyperJump, participants travelled significantly faster, while staying on the desired course without impairing their spatial knowledge. This provides evidence that optical flow can be effectively limited such that it facilitates faster travel without compromising spatial orientation. In future design iterations, we plan to utilize audio-visual effects to support jumping metaphors that help users better anticipate and interpret jumps, and use much larger virtual environments requiring faster speeds, where cybersickness will become increasingly prevalent and thus teleporting will become more important.
C1 [Adhikari, Ashu; Aguilar, Ivan; Bretin, Alexander; Kruijff, Ernst; von der Heyde, Markus; Riecke, Bernhard E.] Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
   [Zielasko, Daniel] Univ Trier, D-54296 Trier, Germany.
   [Kruijff, Ernst] Bonn Rhein Sieg Univ Appl Sci, Inst Visual Comp, D-53757 St Augustin, Germany.
   [von der Heyde, Markus] vdH IT, D-99425 Weimar, Germany.
C3 Simon Fraser University; Universitat Trier; Hochschule Bonn Rhein Sieg
RP Adhikari, A (corresponding author), Simon Fraser Univ, Sch Interact Arts & Technol, Burnaby, BC V5A 1S6, Canada.
EM ashua@sfu.ca; zielasko@uni-trier.de; ivan_aguilar@sfu.ca;
   alexanderbretin@sfu.ca; ernst.kruijff@h-brs.de; info@vdh-it.de;
   ber1@sfu.ca
RI Aguilar, Ivan/AAO-4316-2020; von der Heyde, Markus/HJA-0319-2022;
   Riecke, Bernhard/C-6399-2011
OI Kruijff, Ernst/0000-0003-1625-0955; Zielasko,
   Daniel/0000-0003-3451-4977; Aguilar, Ivan/0000-0002-8735-4041; Riecke,
   Bernhard/0000-0001-7974-0850; von der Heyde, Markus/0000-0002-6026-082X;
   Adhikari, Ashu/0000-0002-2540-6344
CR Adhikari A., 2021, Front. Virt. Reality
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Barhorst-Cates EM, 2021, MEM COGNITION, V49, P572, DOI 10.3758/s13421-020-01111-8
   Beckhaus S., 2007, Concepts and technologies for pervasive games: a reader for pervasive gaming research, V1, P231
   Bhandari Jiwan, 2018, GRAPHICS INTERFACE, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018, DOI 10.20380/GI2018, 10. 20380/GI2018.22]
   Bolte Benjamin, 2011, P VIRT REAL INT C
   Bos JE, 2008, DISPLAYS, V29, P47, DOI 10.1016/j.displa.2007.09.002
   Bowman D., 2004, 3D USER INTERFACES T
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 1999, PRESENCE-TELEOP VIRT, V8, P618, DOI 10.1162/105474699566521
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Danyluk K, 2019, LECT NOTES COMPUT SC, V11542, P203, DOI 10.1007/978-3-030-22514-8_17
   Farmani Y, 2020, VIRTUAL REAL-LONDON, V24, P645, DOI 10.1007/s10055-020-00425-x
   Farrell MJ, 1998, J EXP PSYCHOL LEARN, V24, P227, DOI 10.1037/0278-7393.24.1.227
   Grechkin T.Y., 2014, ACM International Conference Proceedings Series, Proceedings, SAP 2014: Vancouver, British Columbia, Canada, August 08-09, 2014, P99, DOI [10.1145/2628257, DOI 10.1145/2628257]
   Harris A., 2014, P 13 ACM SIGGRAPH IN, P231
   HART S G, 1988, P139
   Hashemian A. M., 2017, Swivel-chair: Evaluating seated full-rotational interfaces for virtual reality navigation
   Hashemian AM, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P395, DOI 10.1109/VRW52623.2021.00084
   Hashemian AM, 2022, IEEE T VIS COMPUT GR, V28, P1792, DOI 10.1109/TVCG.2020.3025084
   Hashemian AM, 2023, IEEE T VIS COMPUT GR, V29, P1748, DOI 10.1109/TVCG.2021.3131422
   Kelly JW, 2020, IEEE T VIS COMPUT GR, V26, P1841, DOI 10.1109/TVCG.2020.2973051
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kitson A, 2017, IEEE SYMP 3D USER, P73, DOI 10.1109/3DUI.2017.7893320
   Klatzky RL, 1998, PSYCHOL SCI, V9, P293, DOI 10.1111/1467-9280.00058
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Loomis J.M., 2008, EMBODIMENT EGO SPACE, P1, DOI DOI 10.1145/1498700.1498702
   Malekmakan M., 2020, PROC 26 ACM S VIRT R, P1
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   McNamara T.P., 2008, Learning and memory: A comprehensive reference: Vol. 2. Cognitive psychology of memory, V2, P157, DOI DOI 10.1016/B978-012370509-9.00176-5
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Nguyen-Vo T, 2021, IEEE T VIS COMPUT GR, V27, P165, DOI 10.1109/TVCG.2019.2935730
   PRESSON CC, 1994, PERCEPTION, V23, P1447, DOI 10.1068/p231447
   Riecke B. E., 2022, Proc. ACM SIGGRAPH Immersive Pavilion
   Riecke B.E., 2005, ACM Transactions on Applied Perception, V2, P183, DOI [10.1145/1077399.1077401, DOI 10.1145/1077399.1077401]
   RIECKE B.E., 2004, APGV '04: Proceedings of the 1st symposium on Applied perception in graphics and visualization, P9, DOI DOI 10.1145/1012551.1012553
   Riecke BE, 2008, PRESENCE-TELEOP VIRT, V17, P143, DOI 10.1162/pres.17.2.143
   Riecke BE, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P373, DOI 10.1109/VRW52623.2021.00075
   Riecke BE, 2017, COGNITION, V169, P1, DOI 10.1016/j.cognition.2017.07.014
   Riecke BE, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01174
   Riecke BE, 2010, LECT NOTES ARTIF INT, V6222, P234, DOI 10.1007/978-3-642-14749-4_21
   RIESER JJ, 1989, J EXP PSYCHOL LEARN, V15, P1157, DOI 10.1037/0278-7393.15.6.1157
   Ruddle RA, 2005, P IEEE VIRT REAL ANN, P115
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Wang R.F., 1999, SPAT COGN COMPUT, V1, P431
   Wang RF, 2016, PSYCHON B REV, V23, P692, DOI 10.3758/s13423-015-0952-y
   Wang RF, 2002, TRENDS COGN SCI, V6, P376, DOI 10.1016/S1364-6613(02)01961-7
   Wang RXF, 2004, PERCEPT PSYCHOPHYS, V66, P68, DOI 10.3758/BF03194862
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Witmer BG, 1996, INT J HUM-COMPUT ST, V45, P413, DOI 10.1006/ijhc.1996.0060
   Zielasko D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P398, DOI [10.1109/VR46266.2020.1581426770550, 10.1109/VR46266.2020.00-44]
   Zielasko D, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P113, DOI 10.1109/3DUI.2016.7460040
NR 58
TC 6
Z9 6
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5265
EP 5281
DI 10.1109/TVCG.2022.3207157
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300031
PM 36112551
DA 2024-11-06
ER

PT J
AU Patnaik, B
   Peng, HS
   Elmqvist, N
AF Patnaik, Biswaksen
   Peng, Huaishu
   Elmqvist, Niklas
TI Sensemaking Sans Power: Interactive Data Visualization Using
   Color-Changing Ink
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Ink; Image color analysis; Three-dimensional
   displays; Visualization; Media; Paints; Physical computing;
   color-changing inks; design space; data physicalization; data
   visualization
ID INFORMATION; COMPUTER
AB We present an approach for interactively visualizing data using color-changing inks without the need for electronic displays or computers. Color-changing inks are a family of physical inks that change their color characteristics in response to an external stimulus such as heat, UV light, water, and pressure. Visualizations created using color-changing inks can embed interactivity in printed material without external computational media. In this article, we survey current color-changing ink technology and then use these findings to derive a framework for how it can be used to construct interactive data representations. We also enumerate the interaction techniques possible using this technology. We then show some examples of how to use color-changing ink to create interactive visualizations on paper. While obviously limited in scope to situations where no power or computing is present, or as a complement to digital displays, our findings can be employed for paper, data physicalization, and embedded visualizations.
C1 [Patnaik, Biswaksen; Peng, Huaishu; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Patnaik, B (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM bpatnaik@umd.edu; huaishu@cs.umd.edu; elm@umd.edu
OI PATNAIK, BISWAKSEN/0000-0001-9081-032X; Elmqvist,
   Niklas/0000-0001-5805-5301
FU U.S. National Science Foundation [IIS-1901485]
FX This work was supported by U.S. National Science Foundation under Grant
   IIS-1901485.
CR Afzal S, 2012, IEEE T VIS COMPUT GR, V18, P2556, DOI 10.1109/TVCG.2012.264
   Agrawala M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P327, DOI 10.1145/258734.258875
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Becker R. A., 1987, Statistical Science, V4, P355, DOI [DOI 10.1214/SS/1177013104, 10.1214/ ss/1177013104.]
   Berzowska J., 2004, Proceedings SIGGRAPH '04 ACM SIGGRAPH 2004 Sketches, P34, DOI DOI 10.1145/1186223.1186266
   Dahley A., 1998, CHI 98, P269
   Endert A., 2011, Proc. of Graph, P103
   Harrison Chris., 2011, ACM S USER INTERFACE, P537
   Hashida T., 2010, P ACM C COMP GRAPH I, P1
   Hashida T., 2011, P ACM C COMP GRAPH I
   Heer J, 2012, COMMUN ACM, V55, P45, DOI 10.1145/2133806.2133821
   Heiner J., 1999, Proc. UIST '99, P141, DOI [10.1145/320719.322595, DOI 10.1145/320719.322595]
   Holmquist L.E., 2003, P 1 INT C COMPUTER G, P229
   Hsin-Liu Kao., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems. CHI EA'16, P3703
   Isenberg P, 2013, IEEE T VIS COMPUT GR, V19, P2346, DOI 10.1109/TVCG.2013.163
   Ishii Hiroshi, 1997, Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/258549.258715
   Izadi S, 2008, UIST 2008: PROCEEDINGS OF THE 21ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P269, DOI 10.1145/1449715.1449760
   Jin YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P701, DOI 10.1145/3332165.3347905
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kaihou T., 2013, Proceedings of the Second International Workshop on Smart Material Interfaces: Another Step to a Material Future, SMI'13, (New York, NY, USA), P7, DOI DOI 10.1145/2534688.2534690
   Kim KyungTae, 2011, P HAWAII INT C SYSTE, P1, DOI DOI 10.1109/HICSS.2011.499
   Kim S., 2012, PROC ACM ANN C HUMAN, P2175
   Köpper M, 2016, ERGONOMICS, V59, P615, DOI 10.1080/00140139.2015.1100757
   Lam H, 2007, IEEE T VIS COMPUT GR, V13, P1278, DOI 10.1109/TVCG.2007.70583
   Lanman D, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866164
   Liu LY, 2007, APPL PHYS LETT, V90, DOI 10.1063/1.2742781
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Matusik W., 2008, Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '08). ACM, P363
   Moere AV, 2008, IEEE INT CONF INF VI, P469, DOI 10.1109/IV.2008.84
   Munzner T., 2014, AK Peters Visualization Series
   Offenhuber D, 2020, IEEE T VIS COMPUT GR, V26, P98, DOI 10.1109/TVCG.2019.2934788
   Oliva A, 2006, ACM T GRAPHIC, V25, P527, DOI 10.1145/1141911.1141919
   PAHR D., 2021, P EUR WORKSH VIS COM, P19, DOI [10.2312/vcbm.20211341.2,3, DOI 10.2312/VCBM.20211341.2,3]
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Porter T., 1984, Computers & Graphics, V18, P253
   Pousman Z., 2006, P WORK C ADV VIS INT, P67, DOI DOI 10.1145/1133265.1133277
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Punpongsanon P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173787
   Raidou RG, 2020, COMPUT GRAPH FORUM, V39, P623, DOI 10.1111/cgf.14173
   Saakes Daniel, 2013, Advances in Computer Entertainment. 10th International Conference, ACE 2013. Proceedings: LNCS 8253, P622, DOI 10.1007/978-3-319-03161-3_67
   Saakes D., 2012, P ACM C COMP GRAPH I
   Sakurai S, 2009, PERS UBIQUIT COMPUT, V13, P619, DOI 10.1007/s00779-009-0243-6
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Sellen A.J., 2001, MYTH PAPERLESS OFFIC
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stasko J, 2004, LECT NOTES COMPUT SC, V3205, P18
   Stoppel S, 2017, IEEE T VIS COMPUT GR, V23, P861, DOI 10.1109/TVCG.2016.2599211
   Trithemius J., 1721, Steganographia
   Tsuji K, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Varghese C., 2007, PASSENGER VEHICLE OC
   Viégas FB, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P105, DOI 10.1109/INFVIS.2004.8
   Viégas FB, 2007, LECT NOTES COMPUT SC, V4564, P182
   Vogel D., 2004, P ACM S US INT SOFTW, P137
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Xiong R., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P37, DOI 10.1145/320719.322581
   Yamada H, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENTERTAINMENT TECHNOLOGY (ACE 2011)
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 59
TC 1
Z9 1
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5282
EP 5293
DI 10.1109/TVCG.2022.3209631
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300032
PM 36170400
DA 2024-11-06
ER

PT J
AU Davidson, K
   Lisle, L
   Whitley, K
   Bowman, DA
   North, C
AF Davidson, Kylie
   Lisle, Lee
   Whitley, Kirsten
   Bowman, Doug A.
   North, Chris
TI Exploring the Evolution of Sensemaking Strategies in Immersive Space to
   Think
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Data visualization; Cognition; Prototypes; Visual
   analytics; Three-dimensional displays; Keyboards; Human-computer
   interaction; immersive analytics; virtual reality; information
   visualization; sensemaking
ID VISUAL ANALYTICS
AB Existing research on immersive analytics to support the sensemaking process focuses on single-session sensemaking tasks. However, in the wild, sensemaking can take days or months to complete. In order to understand the full benefits of immersive analytic systems, we need to understand how immersive analytic systems provide flexibility for the dynamic nature of the sensemaking process. In our work, we build upon an existing immersive analytic system - Immersive Space to Think, to evaluate how immersive analytic systems can support sensemaking tasks over time. We conducted a user study with eight participants with three separate analysis sessions each. We found significant differences between analysis strategies between sessions one, two, and three, which suggest that immersive space to think can benefit analysts during multiple stages in the sensemaking process.
C1 [Davidson, Kylie; Lisle, Lee; Bowman, Doug A.; North, Chris] Virginia Polytech Inst & State Univ, Dept Comp Sci, Blacksburg, VA 24060 USA.
   [Whitley, Kirsten] US Dept Def, Alexandria, VA 22350 USA.
C3 Virginia Polytechnic Institute & State University; United States
   Department of Defense
RP Davidson, K (corresponding author), Virginia Polytech Inst & State Univ, Dept Comp Sci, Blacksburg, VA 24060 USA.
EM kyliedavidson@vt.edu; llisle@vt.edu; visual.tycho@gmail.com;
   dbowman@vt.edu; north@cs.vt.edu
OI Davidson, Kylie/0000-0002-9888-5278; Bowman, Doug/0000-0003-0491-5067;
   Whitley, Kirsten/0000-0003-1356-326X
FU Laboratory for Analytic Sciences (LAS); NSF under Grant I/UCRC via the
   NSF Center for Space, High-performance, and Resilient Computing (SHREC)
   [CNS-1822080]
FX This work was supported in part by the Laboratory for Analytic Sciences
   (LAS). Any opinions, findings, conclusions, or recommendations expressed
   in this material are those of the authors and do not necessarily reflect
   the views of the LAS and/or any agency of the United States Government.
   This work was supported in part by the NSF under Grant I/UCRC
   CNS-1822080 via the NSF Center for Space, High-performance, and
   Resilient Computing (SHREC).
CR Andrews C, 2011, INFORM VISUAL, V10, P341, DOI 10.1177/1473871611415997
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Bandyopadhyay P., 2022, P CHI C HUM FACT COM, P1
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Bier EA, 2006, LECT NOTES COMPUT SC, V3975, P466
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Bradel L, 2014, IEEE CONF VIS ANAL, P163, DOI 10.1109/VAST.2014.7042492
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Endert Alex, 2013, 2013 IEEE International Conference on Big Data, P17, DOI 10.1109/BigData.2013.6691709
   Feiner S., 1991, UIST Fourth Annual Symposium on User Interface Software and Technology. Proceedings of the ACM Symposium on User Interface Software and Technology, P9, DOI 10.1145/120782.120783
   Fiaux P, 2013, COMPUTER, V46, P90, DOI 10.1109/MC.2013.269
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Hong Y.-L., 2021, P EUROVIS WORKSH VIS, P1
   Kang J., 2011, 2011 IEEE C VIS AN S, P21, DOI DOI 10.1109/VAST.2011.6102438
   Kang YA, 2012, IEEE T VIS COMPUT GR, V18, P2869, DOI 10.1109/TVCG.2012.224
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Kobayashi D., 2021, P S SPAT US INT, P1
   Lisle L, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P331, DOI [10.1109/VRW50115.2020.0-203, 10.1109/VRW50115.2020.00073]
   Lisle L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI 10.1109/VR50410.2021.00077
   Luo WZ, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451588
   Marriott K., 2018, IMMERSIVE ANAL, V11190, DOI 10/kt9x
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Sagiroglu S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P42
   Satriadi K. A., 2020, Proc. ACM Hum.Comput. Interact., V4
   Shneiderman B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168158
   Skarbez R, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00082
   Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Weick KE, 2005, ORGAN SCI, V16, P409, DOI 10.1287/orsc.1050.0133
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
NR 34
TC 5
Z9 5
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5294
EP 5307
DI 10.1109/TVCG.2022.3207357
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300033
PM 36112554
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Li, HY
   Fan, LW
AF Li, Huiyu
   Fan, Linwei
TI A Segmented Redirection Mapping Method for Roadmaps of Large Constrained
   Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Roads; Planning; Navigation; Space exploration;
   Virtual environments; Visualization; Virtual reality; redirected
   walking; real walking; dynamic planning; voronoi diagram
ID WALKING; SPACES
AB Redirected walking (RDW) enables users to explore large virtual spaces by real walking in small real spaces. How to effectively reduce physical collisions and decrease user perceptions of redirection are important for most RDW methods. This article proposes a segmented redirection mapping method to calculate and map the roadmap of a large virtual space with inner obstacles to a mapped roadmap within a small real space. We adopt a Voronoi-based pruning method to extract the roadmap of the virtual space and design an RDW platform to interactively modify the virtual roadmap. We propose a roadmap mapping method based on divide-and-conquer and dynamic planning strategies to subdivide the virtual roadmap into several sub-virtual roads that are mapped individually. By recording connections of different sub-virtual roads, our method is applicable to virtual roadmaps with loop structures. During mapping, we apply the reset and redirection gains of the RDW technique as optimal aims and restrict conditions to obtain the mapped roadmap, which has small path curving and contains as few resets as possible. By real walking along the mapped roadmap, users perceive moving along the virtual roadmap to explore the entire virtual space. The experiment shows that our method works effectively for various virtual spaces with or without inner obstacles. Furthermore, our method is flexible in obtaining mapped roadmaps of different real spaces when the virtual space is fixed. Compared to prevalent RDW methods, our method can significantly reduce physical boundary collisions and maintain user experience of virtual roaming.
C1 [Li, Huiyu; Fan, Linwei] Shandong Univ Finance & Econ, Jinan 250014, Peoples R China.
C3 Shandong University of Finance & Economics
RP Fan, LW (corresponding author), Shandong Univ Finance & Econ, Jinan 250014, Peoples R China.
EM huiyl91@163.com; lwfan129@163.com
RI Fan, Linwei/ABG-8736-2021
OI Fan, Linwei/0000-0001-9986-2396; Li, Huiyu/0000-0003-2272-0984
FU National Nature Science Foundation of China [62202268, 62002200];
   Natural Science Foundation of Shandong Province [ZR2020QF012,
   ZR2021QF134]; Shandong Social Science Planning Fund Program [22DGLJO11];
   Shandong Provincial Science and Technology Support Program of Youth
   Innovation Team in Colleges [2021KJ069]; NSFC-Zhejiang Joint Fund of the
   Integration of Informatization and Industrialization [U1909210];
   Introduction and Education Plan of Young Creative Talents in Colleges
FX This work was supported in part by the National Nature Science
   Foundation of China under Grants 62202268 and 62002200, in part by the
   Natural Science Foundation of Shandong Province under Grants ZR2020QF012
   and ZR2021QF134, in part by the Shandong Social Science Planning Fund
   Program under Grant 22DGLJO11, in part by the Shandong Provincial
   Science and Technology Support Program of Youth Innovation Team in
   Colleges under Grant 2021KJ069, in part by the NSFC-Zhejiang Joint Fund
   of the Integration of Informatization and Industrialization under Grant
   U1909210, and in part by the Introduction and Education Plan of Young
   Creative Talents in Colleges.
CR Azmandian M, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P63, DOI 10.1109/3DUI.2016.7460032
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Cao AT, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P137, DOI [10.1109/VR46266.2020.1581044610731, 10.1109/VR46266.2020.00-72]
   Dong ZC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130893
   Engel David., 2008, P 2008 ACM S VIRTUAL, P157, DOI 10.1145/1450579.1450612
   Fan LW, 2023, IEEE T VIS COMPUT GR, V29, P4104, DOI 10.1109/TVCG.2022.3179269
   Felzenszwalb PF, 2011, IEEE T PATTERN ANAL, V33, P721, DOI 10.1109/TPAMI.2010.135
   Field T., 2004, P ART INT SCI TECHN, P21
   Gai W, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5016, DOI 10.1145/3025453.3025494
   Hanson AJ, 1997, VISUALIZATION '97 - PROCEEDINGS, P175, DOI 10.1109/VISUAL.1997.663876
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2014, IEEE T VIS COMPUT GR, V20, P579, DOI 10.1109/TVCG.2014.34
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Li HY, 2021, PROCEEDINGS OF 23RD ACM INTERNATIONAL CONFERENCE ON MOBILE HUMAN-COMPUTER INTERACTION (MOBILEHCI 2021): MOBILE APART, MOBILE TOGETHER, DOI 10.1145/3447526.3472018
   Li HY, 2020, IEEE ACCESS, V8, P180210, DOI 10.1109/ACCESS.2020.3027985
   Li HY, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-1517-3
   Liu ZG, 2017, IEEE T MULTIMEDIA, V19, P874, DOI 10.1109/TMM.2016.2636750
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Neth CT, 2011, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2011.5759454
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Nitzsche N, 2004, PRESENCE-TELEOP VIRT, V13, P44, DOI 10.1162/105474604774048225
   Peck TC, 2012, IEEE T VIS COMPUT GR, V18, P1053, DOI 10.1109/TVCG.2011.289
   Qi M, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P518, DOI 10.1109/VRW52623.2021.00141
   Razzaque S., 2005, Redirected Walking
   Razzaque S., 2001, P 22 ANN C EUR ASS C, P289, DOI DOI 10.2312/EGS.20011036
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Sebastian M., 2018, P ACM C HUM FACT COM
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.14506112[45]F
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Wernert E.A., 1997, SCI VISUALIZATION C, P95
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Xiaoting Wang, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P175, DOI 10.1109/ISVRI.2011.5759626
   Xing H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1245, DOI [10.1109/vr.2019.8798050, 10.1109/VR.2019.8798050]
   Yang Cheng-Lei, 2006, Journal of Software, V17, P1527, DOI 10.1360/jos171527
   Yang DH, 2007, ADV ROBOTICS, V21, P51, DOI 10.1163/156855307779293724
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zank M, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P229, DOI 10.1109/CW.2015.20
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 47
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5308
EP 5324
DI 10.1109/TVCG.2022.3207004
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300034
PM 36107898
DA 2024-11-06
ER

PT J
AU Gao, D
   Mu, HY
   Xu, K
AF Gao, Duan
   Mu, Haoyuan
   Xu, Kun
TI Neural Global Illumination: Interactive Indirect Illumination Prediction
   Under Dynamic Area Lights
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Rendering (computer graphics); Light sources; Reflection;
   Real-time systems; Probes; Neural networks; Global illumination; deep
   learning
ID RADIANCE TRANSFER
AB We propose neural global illumination, a novel method for fast rendering full global illumination in static scenes with dynamic viewpoint and area lighting. The key idea of our method is to utilize a deep rendering network to model the complex mapping from each shading point to global illumination. To efficiently learn the mapping, we propose a neural-network-friendly input representation including attributes of each shading point, viewpoint information, and a combinational lighting representation that enables high-quality fitting with a compact neural network. To synthesize high-frequency global illumination effects, we transform the low-dimension input to higher-dimension space by positional encoding and model the rendering network as a deep fully-connected network. Besides, we feed a screen-space neural buffer to our rendering network to share global information between objects in the screen-space to each shading point. We have demonstrated our neural global illumination method in rendering a wide variety of scenes exhibiting complex and all-frequency global illumination effects such as multiple-bounce glossy interreflection, color bleeding, and caustics.
C1 [Gao, Duan; Mu, Haoyuan; Xu, Kun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
C3 Tsinghua University
RP Xu, K (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
EM gaoduan0306@gmail.com; muhy17@mails.tsinghua.edu.cn;
   xukun@tsinghua.edu.cn
OI Gao, Duan/0000-0002-0647-6160
FU National Natural Science Foundation of China [61932003]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61932003.
CR Abadi M., 2015, Tensorflow: Large-scale machine learning on heterogeneous distributed systems, DOI DOI 10.48550/ARXIV.1603.04467
   Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073708, 10.1145/3072959.3073703]
   Bitterli B., 2016, Rendering resources
   Bitterli B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392481
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Cohen M.F., 1993, Radiosity and realistic image synthesis
   Cook RL., 1982, ACM T GRAPHIC, V1, P7, DOI [DOI 10.1145/357290.357293, 10.1145/357290.357293]
   Crassin C, 2011, COMPUT GRAPH FORUM, V30, P1921, DOI 10.1111/j.1467-8659.2011.02063.x
   Dachsbacher C., 2005, Proc. Symp. Interactive Graph. and Games, P203
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Diolatzis S, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3522735
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Granskog J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392475
   Green P., 2006, P 2006 S INTERACTIVE, P7
   Greger G, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.656788
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409083
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   Hasselgren J, 2020, COMPUT GRAPH FORUM, V39, P147, DOI 10.1111/cgf.13919
   Heitz E, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190852
   Heitz E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925895
   id Software,, 1999, Quake
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kallweit Simon, 2022, The Falcor Rendering Framework (version 5.2)
   Kaplanyan A., 2009, ACM SIGGRAPH Courses, V7, P2
   Kaplanyan A., 2010, P 2010 ACM SIGGRAPH, P99, DOI [10.1145/1730804.1730821, 10.1145/1730804.1730821.24, DOI 10.1145/1730804.1730821.24]
   Kingma DP, 2014, ADV NEUR IN, V27
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239547, 10.1145/1276377.1276497]
   Kristensen AW, 2005, ACM T GRAPHIC, V24, P1208, DOI 10.1145/1073204.1073334
   Lafortune E. P., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P91
   Lai WS, 2018, LECT NOTES COMPUT SC, V11219, P179, DOI 10.1007/978-3-030-01267-0_11
   Li X, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073641
   McGuire M., 2017, PROC 21 ACM SIGGRAPH, P1
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2021, Arxiv, DOI arXiv:2106.12372
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Nalbach O, 2017, COMPUT GRAPH FORUM, V36, P65, DOI 10.1111/cgf.13225
   Ng R, 2004, ACM T GRAPHIC, V23, P477, DOI 10.1145/1015706.1015749
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Rainer G, 2022, COMPUT GRAPH FORUM, V41, P365, DOI 10.1111/cgf.14480
   Ramamoorthi Ravi, 2009, PrecomputationBased Rendering
   Ren ZM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421637
   Ritschel T., 2009, P S INT 3D GRAPH GAM, P75, DOI [10.1145/1507149.1507161, DOI 10.1145/1507149.1507161, 10.1145/1507149.1507161.5,7]
   Robison Austin., 2009, HPG 09 P C HIGH PERF, P91
   Rodriguez S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417823
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitzmann V., 2020, P ADV NEUR INF PROC
   Sloan PP, 2003, ACM T GRAPHIC, V22, P382, DOI 10.1145/882262.882281
   Sloan PP, 2002, ACM T GRAPHIC, V21, P527, DOI 10.1145/566570.566612
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun TC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323008
   Sun X, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239478
   Tancik M, 2020, Arxiv, DOI [arXiv:2006.10739, 10.48550/arXiv.2006.10739, DOI 10.48550/ARXIV.2006.10739]
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Vaswani A, 2017, ADV NEUR IN, V30
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Wang JW, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201291
   Wang R, 2006, ACM T GRAPHIC, V25, P293, DOI 10.1145/1138450.1138456
   Wu LF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392373
   Wyman C., 2019, Ray Tracing Gems, P21, DOI DOI 10.1145/3214834.3231814
   Xin HG, 2022, IEEE T VIS COMPUT GR, V28, P1824, DOI 10.1109/TVCG.2020.3023129
   Xu B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356547
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng Q, 2019, COMPUT GRAPH FORUM, V38, P169, DOI 10.1111/cgf.13628
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 72
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5325
EP 5341
DI 10.1109/TVCG.2022.3209963
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300035
PM 36166556
DA 2024-11-06
ER

PT J
AU Wang, J
   Mueller, K
AF Wang, Jun
   Mueller, Klaus
TI DOMINO: Visual Causal Reasoning With Time-Dependent Phenomena
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Time series analysis; Delay effects; Task analysis;
   Visual systems; Testing; Prototypes; Causality analysis; hypothesis
   generation; hypothesis testing; time series; visual analytics
ID VISUALIZATION; ANALYTICS; EXPLORATION
AB Current work on using visual analytics to determine causal relations among variables has mostly been based on the concept of counterfactuals. As such the derived static causal networks do not take into account the effect of time as an indicator. However, knowing the time delay of a causal relation can be crucial as it instructs how and when actions should be taken. Yet, similar to static causality, deriving causal relations from observational time-series data, as opposed to designed experiments, is not a straightforward process. It can greatly benefit from human insight to break ties and resolve errors. We hence propose a set of visual analytics methods that allow humans to participate in the discovery of causal relations associated with windows of time delay. Specifically, we leverage a well-established method, logic-based causality, to enable analysts to test the significance of potential causes and measure their influences toward a certain effect. Furthermore, since an effect can be a cause of other effects, we allow users to aggregate different temporal cause-effect relations found with our method into a visual flow diagram to enable the discovery of temporal causal networks. To demonstrate the effectiveness of our methods we constructed a prototype system named DOMINO and showcase it via a number of case studies using real-world datasets. Finally, we also used DOMINO to conduct several evaluations with human analysts from different science domains in order to gain feedback on the utility of our system in practical scenarios.
C1 [Wang, Jun; Mueller, Klaus] SUNY Stony Brook, Comp Sci Dept, Visual Analyt & Imaging Lab, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; Stony Brook University
RP Mueller, K (corresponding author), SUNY Stony Brook, Comp Sci Dept, Visual Analyt & Imaging Lab, Stony Brook, NY 11794 USA.
EM junwang2@cs.stonybrook.com; mueller@cs.stonybrook.com
OI Wang, Jun/0000-0002-7457-9807; Mueller, Klaus/0000-0002-0996-8590
FU NSF [IIS 1527200, 1941613]
FX This work was supported by NSF under Grants IIS 1527200 and 1941613.
CR [Anonymous], 2009, P 18 ACM C INF KNOWL
   archive.ics.uci, Diabetes dataset
   Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   Bui N, 2016, IEEE TRANS COMPUT SO, V3, P75, DOI 10.1109/TCSS.2016.2591880
   Chang R, 2007, IEEE CONF VIS ANAL, P155, DOI 10.1109/VAST.2007.4389009
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   Eells E., 1991, Probabilistic Causality, VVolume 1, DOI DOI 10.1152/japplphysiol.01172.2012
   Efron B, 2004, J AM STAT ASSOC, V99, P96, DOI 10.1198/016214504000000089
   Elmqvist N., 2004, Information Visualization, V3, P154, DOI 10.1057/palgrave.ivs.9500074
   Forbes AG, 2018, IEEE T VIS COMPUT GR, V24, P184, DOI 10.1109/TVCG.2017.2745280
   Friedman N., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P139
   Friedman N, 2003, MACH LEARN, V50, P95, DOI 10.1023/A:1020249912095
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   GRANGER CWJ, 1969, ECONOMETRICA, V37, P424, DOI 10.2307/1912791
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Heintzman N, 2016, J BIOMED INFORM, V63, P259, DOI 10.1016/j.jbi.2016.08.022
   Hoque MN, 2022, IEEE T VIS COMPUT GR, V28, P4728, DOI 10.1109/TVCG.2021.3102051
   Hripcsak G, 2011, J AM MED INFORM ASSN, V18, pI109, DOI 10.1136/amiajnl-2011-000463
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   kaggle, Pm2.5 data of five chinese cities
   Katarya R, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P116, DOI 10.1109/ICISC.2018.8399024
   Kiernan J, 2009, ACM T KNOWL DISCOV D, V3, DOI 10.1145/1631162.1631169
   Kleinberg S., 2011, IJCAI Proceedings-International Joint Conference on Artificial Intelli- gence, V22, P943
   Kleinberg S, 2010, Arxiv, DOI arXiv:1006.1791
   Kleinberg Samantha., 2009, P 25 C UNCERTAINTY A, P303
   Lee TY, 2009, IEEE T VIS COMPUT GR, V15, P1359, DOI 10.1109/TVCG.2009.200
   Li KM, 2012, NEUROIMAGE, V61, P82, DOI 10.1016/j.neuroimage.2012.02.075
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Murphy KP, 2000, ADV NEUR IN, V12, P1015
   Pearl J, 2000, CAUSALITY: MODELS, REASONING, AND INFERENCE
   Pearl J., 2001, Tech. Rep. R281
   Plaisant C., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P221, DOI 10.1145/238386.238493
   Karthir,, 2010, PROC CVPR IEEE, P1967, DOI 10.1109/CVPR.2010.5539871
   Rodrigues PP, 2008, IEEE T KNOWL DATA EN, V20, P615, DOI 10.1109/TKDE.2007.190727
   Spirtes P., 2000, Causation, prediction, and search
   Stanton A, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2137, DOI 10.1145/2783258.2788591
   Vigueras G, 2008, LECT NOTES ARTIF INT, V4908, P190
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2017, INFORMATICS-BASEL, V4, DOI 10.3390/informatics4030024
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wang TD, 2009, IEEE T VIS COMPUT GR, V15, P1049, DOI 10.1109/TVCG.2009.187
   Williamson J., 2009, Oxf. Handb. Causation, P185
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yan JN, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376447
   Zgraggen E, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2683, DOI 10.1145/2702123.2702262
   Zhang Hao, 2015, P 2015 ACM INT WORKS, P37, DOI DOI 10.1145/2713579.2713583
   Zhao J, 2017, IEEE T VIS COMPUT GR, V23, P261, DOI 10.1109/TVCG.2016.2598543
NR 49
TC 3
Z9 3
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5342
EP 5356
DI 10.1109/TVCG.2022.3207929
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300036
PM 36121965
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hergl, C
   Witt, C
   Nsonga, B
   Menzel, A
   Scheuermann, G
AF Hergl, Chiara
   Witt, Carina
   Nsonga, Baldwin
   Menzel, Andreas
   Scheuermann, Gerik
TI Electromechanical Coupling in Electroactive Polymers a Visual Analysis
   of a Third-Order Tensor Field
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tensors; Couplings; Visualization; Strain; Behavioral sciences; Shape;
   Plastics; Tensor visualization; third-order tensor; deviatoric
   decomposition; electro-active polymer
ID GLYPHS
AB Electroactive polymers are frequently used in engineering applications due to their ability to change their shape and properties under the influence of an electric field. This process also works vice versa, such that mechanical deformation of the material induces an electric field in the EAP device. This specific behavior makes such materials highly attractive for the construction of actuators and sensors in various application areas. The electromechanical behaviour of electroactive polymers can be described by a third-order coupling tensor, which represents the sensitivity of mechanical stresses concerning the electric field, i.e., it establishes a relation between a second-order and a first-order tensor field. Due to this coupling tensor's complexity and the lack of meaningful visualization methods for third-order tensors in general, an interpretation of the tensor is rather difficult. Thus, the central engineering research question that this contribution deals with is a deeper understanding of electromechanical coupling by analyzing the third-order coupling tensor with the help of specific visualization methods. Starting with a deviatoric decomposition of the tensor, the multipoles of each deviator are visualized, which allows a first insight into this highly complex third-order tensor. In the present contribution, four examples, including electromechanical coupling, are simulated within a finite element framework and subsequently analyzed using the tensor visualization method.
C1 [Hergl, Chiara; Nsonga, Baldwin; Scheuermann, Gerik] Univ Leipzig, Inst Comp Sci, D-04109 Leipzig, Germany.
   [Witt, Carina; Menzel, Andreas] TU Dortmund, Inst Mech, D-44227 Dortmund, Germany.
   [Menzel, Andreas] Lund Univ, Div Solid Mech, S-22100 Lund, Sweden.
C3 Leipzig University; Dortmund University of Technology; Lund University
RP Hergl, C (corresponding author), Univ Leipzig, Inst Comp Sci, D-04109 Leipzig, Germany.
EM hergl@informatik.uni-leipzig.de; carina.witt@tu-dortmund.de;
   nsonga@informatik.uni-leipzig.de; andreas.menzel@udo.edu;
   scheuermann@informatik.uni-leipzig.de
RI Menzel, Andreas/C-4769-2008
OI Menzel, Andreas/0000-0002-7819-9254; Witt, Carina/0000-0001-6085-7418;
   Scheuermann, Gerik/0000-0001-5200-8870; Hergl,
   Chiara/0000-0002-4016-9113; Nsonga, Baldwin/0000-0002-0651-952X
CR Antoniadis IA, 2013, SMART MATER STRUCT, V22, DOI 10.1088/0964-1726/22/10/104007
   Ask A, 2015, PROC IUTAM, P134, DOI 10.1016/j.piutam.2014.12.015
   Ask A, 2013, INT J NUMER METH ENG, V94, P554, DOI 10.1002/nme.4462
   Auffray N., 2013, Generalized continua as models for materials, P17
   BACKUS G, 1970, REV GEOPHYS SPACE GE, V8, P633, DOI 10.1029/RG008i003p00633
   Bogue R, 2012, IND ROBOT, V39, P535, DOI 10.1108/01439911211268642
   Bujack R, 2018, IEEE T VIS COMPUT GR, V24, P923, DOI 10.1109/TVCG.2017.2743978
   Carpi F, 2011, ADV FUNCT MATER, V21, P4152, DOI 10.1002/adfm.201101253
   Christianson C, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00126
   DELMARCELLE T, 1993, IEEE COMPUT GRAPH, V13, P25, DOI 10.1109/38.219447
   Dickinson R. R., 1989, Proceedings of the SPIE - The International Society for Optical Engineering, V1083, P173, DOI 10.1117/12.952885
   Dickinson R. R., 1991, Extracting Meaning from Complex Data: Processing, Display, Interaction II, V1459, P166
   Dogruer D, 2007, PROC SPIE, V6524, DOI 10.1117/12.715330
   Dorfmann L., 2014, NONLINEAR THEORY ELE
   Florack L, 2010, J MATH IMAGING VIS, V38, P171, DOI 10.1007/s10851-010-0217-3
   Franke M, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.510757
   Gerrits T, 2017, IEEE T VIS COMPUT GR, V23, P980, DOI 10.1109/TVCG.2016.2598998
   Hamermesh M., 1963, Group Theory and its Application to Physical Problems
   Hergl C, 2020, Arxiv, DOI arXiv:2009.11723
   Hergl C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P291, DOI [10.1109/VISUAL.2019.8933592, 10.1109/visual.2019.8933592]
   Hlawitschka M, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P27
   Hossain M, 2015, ARCH APPL MECH, V85, P523, DOI 10.1007/s00419-014-0928-9
   JERPHAGNON J, 1978, ADV PHYS, V27, P609, DOI 10.1080/00018737800101454
   KRIZ R.D., 2005, COMPUT GRAPH-UK, V21, P1
   Li YL, 2018, SMART MATER STRUCT, V27, DOI 10.1088/1361-665X/aab996
   Lu TQ, 2020, EXTREME MECH LETT, V38, DOI 10.1016/j.eml.2020.100752
   Nardini P, 2021, IEEE T VIS COMPUT GR, V27, P3048, DOI 10.1109/TVCG.2019.2961674
   Neeman A. G., 2008, Proceedings of the Fifth Eurographics/IEEE VGTC Conference on PointBased Graphics, P121
   Ren HW, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071085
   Roberts JC, 2000, PROC SPIE, V3960, P176, DOI 10.1117/12.378894
   Rustighi E, 2018, ACTUATORS, V7, DOI 10.3390/act7020028
   Scheuermann G., 2005, Visualization Handbook, V341, P6
   Schultz T, 2010, COMPUT GRAPH FORUM, V29, P1143, DOI 10.1111/j.1467-8659.2009.01675.x
   Schultz T, 2010, IEEE T VIS COMPUT GR, V16, P1595, DOI 10.1109/TVCG.2010.199
   Sikulskyi S., 2019, P EL POL ACT DEV EAP
   Sylvester J. J., 1876, London Edinburgh Dublin Philos. Mag. J. Sci., V2, P291, DOI DOI 10.1080/14786447608639108
   Thylander S, 2017, SMART MATER STRUCT, V26, DOI 10.1088/1361-665X/aa7255
   Thylander S, 2016, SMART MATER STRUCT, V25, DOI 10.1088/0964-1726/25/9/095034
   Tricoche X, 2004, MATH VISUAL, P275
   Vu DK, 2007, INT J NUMER METH ENG, V70, P685, DOI 10.1002/nme.1902
   Wang TS, 2016, INTERFACE FOCUS, V6, DOI 10.1098/rsfs.2016.0026
   Wissler M, 2007, SENSOR ACTUAT A-PHYS, V134, P494, DOI 10.1016/j.sna.2006.05.024
   World M. R., 2020, Tech. Rep. SKU ID: GIR- 16427354
   Zhou FH, 2019, SENSOR ACTUAT A-PHYS, V292, P112, DOI 10.1016/j.sna.2019.02.017
   Zobel V., 2017, Modeling, Analysis, and Visualization of Anisotropy, P65
   Zou WN, 2013, INT J SOLIDS STRUCT, V50, P2457, DOI 10.1016/j.ijsolstr.2013.03.037
NR 46
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5357
EP 5371
DI 10.1109/TVCG.2022.3209328
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300037
PM 36170402
OA hybrid
DA 2024-11-06
ER

PT J
AU Newburger, E
   Correll, M
   Elmqvist, N
AF Newburger, Eric
   Correll, Michael
   Elmqvist, Niklas
TI Fitting Bell Curves to Data Distributions Using Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Shape; Histograms;
   Bars; Strips; Graphical inference; visual statistics; statistics by eye;
   fitting distributions; crowdsourcing
ID REPRESENTATION; INFERENCE
AB Idealized probability distributions, such as normal or other curves, lie at the root of confirmatory statistical tests. But how well do people understand these idealized curves? In practical terms, does the human visual system allow us to match sample data distributions with hypothesized population distributions from which those samples might have been drawn? And how do different visualization techniques impact this capability? This article shares the results of a crowdsourced experiment that tested the ability of respondents to fit normal curves to four different data distribution visualizations: bar histograms, dotplot histograms, strip plots, and boxplots. We find that the crowd can estimate the center (mean) of a distribution with some success and little bias. We also find that people generally overestimate the standard deviation-which we dub the "umbrella effect" because people tend to want to cover the whole distribution using the curve, as if sheltering it from the heavens above-and that strip plots yield the best accuracy.
C1 [Newburger, Eric; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Correll, Michael] Tableau Res, Seattle, WA 98103 USA.
C3 University System of Maryland; University of Maryland College Park
RP Elmqvist, N (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM enewburg@terpmail.umd.edu; mcorrell@tableau.com; elm@umd.edu
OI Elmqvist, Niklas/0000-0001-5805-5301; Newburger,
   Eric/0000-0001-8777-0363
CR Ahlberg C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P619, DOI 10.1145/142750.143054
   Aigner W, 2012, COMPUT GRAPH FORUM, V31, P995, DOI 10.1111/j.1467-8659.2012.03092.x
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Albrecht AR, 2010, PSYCHOL SCI, V21, P560, DOI 10.1177/0956797610363543
   Alvarez GA, 2011, TRENDS COGN SCI, V15, P122, DOI 10.1016/j.tics.2011.01.003
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   Ariely D, 2001, PSYCHOL SCI, V12, P157, DOI 10.1111/1467-9280.00327
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Chong SC, 2003, VISION RES, V43, P393, DOI 10.1016/S0042-6989(02)00596-5
   Cleveland WS., 1993, VISUALIZING DATA
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   Correll M.A., 2015, THESIS U WISCONSIN M
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Crilly N., 2006, Qualitative Research, V6, P341, DOI [10.1177/1468794106065007, DOI 10.1177/1468794106065007]
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Fouriezos G, 2008, PERCEPT PSYCHOPHYS, V70, P456, DOI 10.3758/PP.70.3.456
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Hulman J, 2018, IEEE T VIS COMPUT GR, V24, P446, DOI 10.1109/TVCG.2017.2743898
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Lehmann EL, 2005, Testing Statistical Hypotheses
   Mansmann F, 2013, P SIGCHI C HUM FACT, DOI DOI 10.1145/2470654.2466443
   Melcher D, 1999, VISION RES, V39, P2929, DOI 10.1016/S0042-6989(99)00029-2
   Moon K.-W., 2016, Learn Ggplot2 Using Shiny App, P103, DOI [10.1007/978-3-319-53019-212, DOI 10.1007/978-3-319-53019-212]
   MORGAN MJ, 1991, VISION RES, V31, P2075, DOI 10.1016/0042-6989(91)90165-2
   Nguyen F, 2020, COMPUT GRAPH FORUM, V39, P33, DOI 10.1111/cgf.13902
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Rensink R. A, 2014, On the Prospects for a Science of Visualization, P147
   Ross J., 2010, CHI 10 EXTENDED ABST, P2863, DOI [DOI 10.1145/1753846.1753873, 10.1145/1753846.1753873]
   Schervish M. J., 1995, THEORY STAT
   SCOTT EL, 1954, ASTROPHYS J, V119, P91, DOI 10.1086/145799
   Spalek TM, 2005, PSYCHOL SCI, V16, P15, DOI 10.1111/j.0956-7976.2005.00774.x
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Tukey JW., 1977, EXPLORATORY DATA ANA
   WHITAKER D, 1988, VISION RES, V28, P777, DOI 10.1016/0042-6989(88)90024-7
   Wickham H., 2011, Am. Statistician, P1
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Yuan L, 2019, PSYCHON B REV, V26, P669, DOI 10.3758/s13423-018-1525-7
NR 49
TC 2
Z9 2
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5372
EP 5383
DI 10.1109/TVCG.2022.3210763
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300038
PM 36173772
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Abdelrahman, H
   Tong, YY
AF Abdelrahman, Hayam
   Tong, Yiying
TI Fast Computation of Neck-Like Features
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neck; Shape; Laplace equations; Filtration; Three-dimensional displays;
   Smoothing methods; Computational modeling; And object modeling;
   computational geometry; computer graphics; curve; object
   representations; surface
ID MORSE; SEGMENTATION; LOOPS
AB Locating neck-like features, or locally narrow parts, of a surface is crucial in various applications such as segmentation, shape analysis, path planning, and robotics. Topological methods are often utilized to find the set of shortest loops around handles and tunnels. However, there are abundant neck-like features on genus-0 shapes without any handles. While 3D geometry-aware topological approaches exist to find neck loops, their construction can be cumbersome and may even lead to geometrically wide loops. Thus we propose a "topology-aware geometric approach" to compute the tightest loops around neck features on surfaces, including genus-0 surfaces. Our algorithm starts with a volumetric representation of an input surface and then calculates the distance function of mesh points to the boundary surface as a Morse function. All neck features induce critical points of this Morse function where the Hessian matrix has precisely one positive eigenvalue, i.e., type-2 saddles. As we focus on geometric neck features, we bypass a topological construction such as the Morse-Smale complex or a lower-star filtration. Instead, we directly create a cutting plane through each neck feature. Each resulting loop can then be tightened to form a closed geodesic representation of the neck feature. Moreover, we offer criteria to measure the significance of a neck feature through the evolution of critical points when smoothing the distance function. Furthermore, we speed up the detection process through mesh simplification without compromising the quality of the output loops.
C1 [Abdelrahman, Hayam; Tong, Yiying] Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
C3 Michigan State University
RP Abdelrahman, H (corresponding author), Michigan State Univ, Dept Comp Sci & Engn, E Lansing, MI 48824 USA.
EM abdelr14@msu.edu; ytong@msu.edu
OI Abdelrahman, Hayam/0000-0002-0387-6687
FU NSF [IIS-1900473]
FX This work was supported by NSF under Grant IIS-1900473.
CR Bauer U., 2014, Dipha (a distributed persistent homology algorithm)
   Boltcheva D, 2011, COMPUT AIDED DESIGN, V43, P1457, DOI 10.1016/j.cad.2011.08.015
   Cabello S, 2010, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'10), P156, DOI 10.1145/1810959.1810988
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   de Verdière ÉC, 2005, DISCRETE COMPUT GEOM, V33, P507, DOI 10.1007/s00454-004-1150-2
   De Verdiére ÉC, 2007, J ACM, V54, DOI 10.1145/1255443.1255446
   Dey TK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462017
   Dey TK, 2011, SIAM J COMPUT, V40, P1026, DOI 10.1137/100800245
   Dey TK, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360644
   EDELSBRUNNER H., 2010, Computational Topology: An Introduction (Applied Mathematics)
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Fang XZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201354
   Fasy B. T., 2022, Package 'TDA'
   Favreau JM, 2011, COMPUT GRAPH-UK, V35, P35, DOI 10.1016/j.cag.2010.11.001
   Feng X, 2013, IEEE T VIS COMPUT GR, V19, P1298, DOI 10.1109/TVCG.2013.9
   Fugacci U, 2020, COMPUT GRAPH-UK, V90, P43, DOI 10.1016/j.cag.2020.05.020
   H~etroy F., 2005, PROC ANN C EUR ASS C, P1
   Hajij M, 2016, GRAPH MODELS, V88, P12, DOI 10.1016/j.gmod.2016.09.003
   Dey TK, 2018, Arxiv, DOI arXiv:1803.05093
   Lazarus F., 2001, P 17 ANN ACM S COMP, P80, DOI DOI 10.1145/378583.378630
   Letscher D, 2007, LECT NOTES COMPUT SC, V4673, P587
   Liu JW, 2021, ACTA OPT SIN, V41, DOI 10.3788/AOS202141.1810001
   Milosavljevic N, 2011, COMPUTATIONAL GEOMETRY (SCG 11), P216
   Ni XL, 2004, ACM T GRAPHIC, V23, P613, DOI 10.1145/1015706.1015769
   Sharp N, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417839
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Tong YY, 2003, ACM T GRAPHIC, V22, P445, DOI 10.1145/882262.882290
   Varava A, 2016, IEEE T ROBOT, V32, P1479, DOI 10.1109/TRO.2016.2602374
   Wang B, 2016, J COMPUT PHYS, V305, P276, DOI 10.1016/j.jcp.2015.10.036
   Weinrauch A., 2021, A variational loop shrinking analogy for handle and tunnel detection and reeb graph construction on surfaces
   Xin SQ, 2012, IEEE T VIS COMPUT GR, V18, P879, DOI 10.1109/TVCG.2011.119
   Zeng D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417854
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zhao RD, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356546
NR 34
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5384
EP 5393
DI 10.1109/TVCG.2022.3211781
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300039
PM 36194707
DA 2024-11-06
ER

PT J
AU Shao, H
   Huang, LB
   Michels, DL
AF Shao, Han
   Huang, Libo
   Michels, Dominik L.
TI A Current Loop Model for the Fast Simulation of Ferrofluids
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Computational modeling; Mathematical models; Force; Numerical models;
   Surface tension; Magnetomechanical effects; Magnetic forces;
   Computational electromagnetics; divergence-free SPH (DFSPH);
   ferrofluids; fluid mechanics; implicit incompressible SPH (IISPH);
   large-scale simulations; magnetic fluids; maxwell's equations; natural
   phenomena; navier-stokes equations; numerical simulations; smoothed
   particle hydrodynamics (SPH)
ID MAGNETIC FLUID
AB Ferrofluids are oil-based liquids containing magnetic particles that interact with magnetic fields without solidifying. Leveraging the exploration of new applications of these promising materials (such as in optics, medicine and engineering) requires high fidelity modeling and simulation capabilities in order to accurately explore ferrofluids in silico. While recent work addressed themacroscopic simulation of large-scale ferrofluids using smoothed-particle hydrodynamics (SPH), such simulations are computationally expensive. In their work, the Kelvin force model has been used to calculate interactions between different SPH particles. The application of this model results in a force pointing outwards with respect to the fluid surface causing significant levitation problems. This drawback limits the application of more advanced and efficient SPH frameworks such as divergence-free SPH(DFSPH) or implicit incompressible SPH(IISPH). In this contribution, we propose a current loopmagnetic force model which enables the fast macroscopic simulation of ferrofluids. Our new force model results in a force term pointing inwards allowing for more stable and fast simulations of ferrofluids using DFSPH and IISPH.
C1 [Shao, Han; Huang, Libo; Michels, Dominik L.] KAUST, Computat Sci Grp, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
C3 King Abdullah University of Science & Technology
RP Michels, DL (corresponding author), KAUST, Computat Sci Grp, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
EM han.shao@kaust.edu.sa; libo.huang@kaust.edu.sa;
   dominik.michels@kaust.edu.sa
FU KAUST through the baseline funding of the Computational Sciences Group
   within the Visual Computing Center
FX The authors would like to thank Jan Bender for publishing the DFSPH
   framework open-source. This work was supported and funded in part by
   KAUST through the baseline funding of the Computational Sciences Group
   within the Visual Computing Center.
CR Adami S, 2012, J COMPUT PHYS, V231, P7057, DOI 10.1016/j.jcp.2012.05.005
   Akinci N, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508395
   Akinci N, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185558
   Batty C, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239551, 10.1145/1276377.1276502]
   Becker M, 2009, IEEE T VIS COMPUT GR, V15, P493, DOI 10.1109/TVCG.2008.107
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2019, P MOT INT GAM
   Bender J., 2015, ACM SIGGRAPH / Eurographics Symposium on Computer Animation, P147
   Bender J, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099578
   Boyd L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159522
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Bridgeman R., 2007, ACM SIGGRAPH 2007, P1, DOI DOI 10.1145/1281500.1281681
   Bridson R., 2015, Fluid simulation for computer graphics
   BYRNE JV, 1977, P I ELECTR ENG, V124, P1089, DOI 10.1049/piee.1977.0222
   Cao Y, 2014, J MAGN MAGN MATER, V355, P93, DOI 10.1016/j.jmmm.2013.11.042
   Desbrun M., 1996, Computer Animation and Simulation '96. Proceedings of the Eurographics Workshop, P61
   Fedkiw R, 2001, COMP GRAPH, P15, DOI 10.1145/383259.383260
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P225, DOI 10.1111/cgf.12825
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gollwitzer C, 2007, J FLUID MECH, V571, P455, DOI 10.1017/S0022112006003466
   Hädrich T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459954
   Hädrich T, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417801
   Harlow F.H., 1963, Experimental arithmetic, high-speed computations and mathematics
   He XW, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682630
   Herrera JAA, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480532
   Huang LB, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480495
   Huang LB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417799
   Huang LB, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322973
   Huang T, 2021, FRONT EARTH SC-SWITZ, V9, DOI 10.3389/feart.2021.693531
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Ishikawa T., 2012, P IM EL VIS COMP WOR
   Ishikawa Tomokazu, 2013, Computer Vision, Imaging and Computer Graphics. Theory and Application, P112
   Kass M., 1990, Computer Graphics, V24, P49, DOI 10.1145/97880.97884
   Kim SW, 2020, COMPUT GRAPH FORUM, V39, P119, DOI 10.1111/cgf.14131
   Kim SW, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201402
   Koschier D, 2019, P EUR TUT, P1
   Koschier D, 2017, ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM ON COMPUTER ANIMATION (SCA 2017), DOI 10.1145/3099564.3099565
   Lavrova O, 2006, J PHYS-CONDENS MAT, V18, pS2657, DOI 10.1088/0953-8984/18/38/S09
   Lavrova O, 2008, COMMUN NONLINEAR SCI, V13, P1302, DOI 10.1016/j.cnsns.2006.12.006
   Liu J., 2011, Numerical study of the formation process of ferrofluid droplets
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   Ng YT, 2009, J COMPUT PHYS, V228, P8807, DOI 10.1016/j.jcp.2009.08.032
   Ni XY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392445
   Padilla M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322962
   Rosensweig R., 1997, Ferrohydrodynamics, DOI DOI 10.1038/nature08906
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shao H, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530109
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Sun YC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480541
   Terzopoulos Demetri, 1987, COMPUTER GRAPHICS PR, V21, P205
   Thomaszewski B, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409115
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Zhu GP, 2011, LANGMUIR, V27, P14834, DOI 10.1021/la203931q
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
   Zorilla F, 2020, COMPUTERS, V9, DOI 10.3390/computers9020023
NR 58
TC 3
Z9 3
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5394
EP 5405
DI 10.1109/TVCG.2022.3211414
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300040
PM 36191100
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Liang, X
   Di, S
   Cappello, F
   Raj, M
   Liu, CH
   Ono, K
   Chen, ZZ
   Peterka, T
   Guo, HQ
AF Liang, Xin
   Di, Sheng
   Cappello, Franck
   Raj, Mukund
   Liu, Chunhui
   Ono, Kenji
   Chen, Zizhong
   Peterka, Tom
   Guo, Hanqi
TI Toward Feature-Preserving Vector Field Compression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Topology; Iterative methods; Data
   visualization; Image coding; Error correction; Jacobian matrices;
   Critical points; lossy compression; vector field visualization
ID MULTILEVEL TECHNIQUES; FLOW VISUALIZATION; TOPOLOGY; REDUCTION
AB The objective of this work is to develop error-bounded lossy compression methods to preserve topological features in 2D and 3D vector fields. Specifically, we explore the preservation of critical points in piecewise linear and bilinear vector fields. We define the preservation of critical points as, without any false positive, false negative, or false type in the decompressed data, (1) keeping each critical point in its original cell and (2) retaining the type of each critical point (e.g., saddle and attracting node). The key to our method is to adapt a vertex-wise error bound for each grid point and to compress input data together with the error bound field using a modified lossy compressor. Our compression algorithm can be also embarrassingly parallelized for large data handling and in situ processing. We benchmark our method by comparing it with existing lossy compressors in terms of false positive/negative/type rates, compression ratio, and various vector field visualizations with several scientific applications.
C1 [Liang, Xin] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.
   [Di, Sheng; Cappello, Franck; Peterka, Tom] Argonne Natl Lab, Math & Comp Sci Div, Lemont, IL 60439 USA.
   [Raj, Mukund] Broad Inst MIT & Harvard, Stanley Ctr Psychiat Res, Cambridge, MA 02142 USA.
   [Liu, Chunhui] Kyoto Univ, Dept Math, Kyoto 6068501, Japan.
   [Ono, Kenji] Kyushu Univ, Dept Informat, Fukuoka, Japan.
   [Chen, Zizhong] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
   [Guo, Hanqi] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 University of Kentucky; United States Department of Energy (DOE);
   Argonne National Laboratory; Harvard University; Massachusetts Institute
   of Technology (MIT); Broad Institute; Kyoto University; Kyushu
   University; University of California System; University of California
   Riverside; University System of Ohio; Ohio State University
RP Guo, HQ (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM xliang@uky.edu; sdi1@anl.gov; cappello@mcs.anl.gov; mraj@anl.gov;
   chunhui.liu@math.kyoto-u.ac.jp; keno@cc.kyushu-u.ac.jp; chen@cs.ucr.edu;
   tpeterka@anl.gov; guo.2154@osu.edu
RI Liang, Xin/LGY-5316-2024; Guo, Hanqi/AAL-1929-2021; Guo,
   Hanqi/ADW-4234-2022
OI Guo, Hanqi/0000-0001-7776-1834; Liang, Xin/0000-0002-0630-1600; ,
   Sheng/0000-0002-9935-5674; Chen, Zizhong/0000-0003-2578-4940
FU JSPS KAKENHI [16H06335, JP17F17730]; JSPS [16H06335]; Laboratory
   Directed Research and Development (LDRD) funding from Argonne National
   Laboratory; Office of Science, of the U.S. Department of Energy
   [DE-AC02-06CH11357]; U.S. Department of Energy, Office of Advanced
   Scientific Computing Research, Scientific Discovery through Advanced
   Computing (SciDAC) program; Exascale Computing Project under Grant (ECP)
   [17-SC-20-SC]; DOE organizations - the Office of Science; National
   Nuclear Security Administration; U.S. National Science Foundation
   [OAC-2003709, OAC-2104023, IIS-1955764]
FX The Work of Chunhui Liu was supported in part by JSPS KAKENHI under
   Grant JP17F17730 and in part by JSPS under Grant (S) 16H06335. This work
   was supported in part by Laboratory Directed Research and Development
   (LDRD) funding from Argonne National Laboratory, provided by the
   Director, Office of Science, of the U.S. Department of Energy under
   Grant DE-AC02-06CH11357 and in part by the U.S. Department of Energy,
   Office of Advanced Scientific Computing Research, Scientific Discovery
   through Advanced Computing (SciDAC) program and the Exascale Computing
   Project under Grant (ECP, Project Number: 17-SC-20-SC), a collaborative
   effort of two DOE organizations - the Office of Science and the National
   Nuclear Security Administration. This work was also supported by U.S.
   National Science Foundation under Grants OAC-2003709, OAC-2104023, and
   IIS-1955764.
CR Ainsworth M, 2019, SIAM J SCI COMPUT, V41, pA2146, DOI [10.1137/18M1166651, 10.1137/18M1208885]
   Ainsworth M, 2019, SIAM J SCI COMPUT, V41, pA1278, DOI 10.1137/18M1166651
   Ainsworth M, 2018, COMPUT VIS SCI, V19, P65, DOI 10.1007/s00791-018-00303-9
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Burtscher M, 2009, IEEE T COMPUT, V58, P18, DOI 10.1109/TC.2008.131
   Dey TK, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P281, DOI 10.1109/PG.2007.34
   Gzip, About us
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   Ibarria L, 2003, COMPUT GRAPH FORUM, V22, P343, DOI 10.1111/1467-8659.00681
   Koch S, 2016, VISUAL COMPUT, V32, P1563, DOI 10.1007/s00371-015-1140-9
   Laramee RS, 2007, MATH VIS, P1, DOI 10.1007/978-3-540-70823-0_1
   Laramee RS, 2004, COMPUT GRAPH FORUM, V23, P203, DOI 10.1111/j.1467-8659.2004.00753.x
   Li S, 2018, COMPUT GRAPH FORUM, V37, P422, DOI 10.1111/cgf.13336
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Liang X, 2018, IEEE INT C CL COMP, P179, DOI 10.1109/CLUSTER.2018.00036
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Lodha SK, 2000, IEEE VISUAL, P343, DOI 10.1109/VISUAL.2000.885714
   McLoughlin T, 2010, COMPUT GRAPH FORUM, V29, P1807, DOI 10.1111/j.1467-8659.2010.01650.x
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Skraba P, 2016, IEEE T VIS COMPUT GR, V22, P1683, DOI 10.1109/TVCG.2016.2534538
   Tao DW, 2017, INT PARALL DISTRIB P, P1129, DOI 10.1109/IPDPS.2017.115
   Telea A., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P35, DOI 10.1109/VISUAL.1999.809865
   Theisel H, 2003, COMPUT GRAPH FORUM, V22, P333, DOI 10.1111/1467-8659.00680
   Theisel H, 2008, MATH VIS, P215, DOI 10.1007/978-3-540-33265-7_7
   Underwood R, 2020, INT PARALL DISTRIB P, P567, DOI 10.1109/IPDPS47924.2020.00065
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   ZSTD, ABOUT US
NR 29
TC 4
Z9 4
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5434
EP 5450
DI 10.1109/TVCG.2022.3214821
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300043
PM 36251895
DA 2024-11-06
ER

PT J
AU van Onzenoodt, C
   Vázquez, PP
   Ropinski, T
AF van Onzenoodt, Christian
   Vazquez, Pere-Pau
   Ropinski, Timo
TI Out of the Plane: Flower versus Star Glyphs to Support High-Dimensional
   Exploration in Two-Dimensional Embeddings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Stars; Visualization; Encoding; Data visualization;
   Dimensionality reduction; Image color analysis; Glyph visualization;
   high-dimensional data visualization; two-dimensional embeddings
ID SHAPE CHARACTERISTICS; COLOR; PERCEPTION
AB Exploring high-dimensional data is a common task in many scientific disciplines. To address this task, two-dimensional embeddings, such as tSNE and UMAP, are widely used. While these determine the 2D position of data items, effectively encoding the first two dimensions, suitable visual encodings can be employed to communicate higher-dimensional features. To investigate such encodings, we have evaluated two commonly used glyph types, namely flower glyphs and star glyphs. To evaluate their capabilities for communicating higher-dimensional features in two-dimensional embeddings, we ran a large set of crowd-sourced user studies using real-world data obtained from data.gov. During these studies, participants completed a broad set of relevant tasks derived from related research. This article describes the evaluated glyph designs, details our tasks, and the quantitative study setup before discussing the results. Finally, we will present insights and provide guidance on the choice of glyph encodings when exploring high-dimensional data.
C1 [van Onzenoodt, Christian; Ropinski, Timo] Ulm Univ, Visual Comp Grp, D-89081 Ulm, Germany.
   [Vazquez, Pere-Pau] UPC Barcelona, ViRVIG Grp, Barcelona 08034, Spain.
C3 Ulm University
RP van Onzenoodt, C (corresponding author), Ulm Univ, Visual Comp Grp, D-89081 Ulm, Germany.
EM christian.van-onzenoodt@uni-ulm.de; pere.pau.vazquez@upc.edu;
   timo.ropinski@uni-ulm.de
RI Vázquez, Pere-Pau/HTP-9691-2023
OI van Onzenoodt, Christian/0000-0002-5951-6795; Ropinski,
   Timo/0000-0002-7857-5512
CR Albuquerque G., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P19, DOI 10.1109/VAST.2010.5652433
   [Anonymous], 2014, P 9 AUD MOSTL C INT
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Borgo R., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   CLEVELAND WS, 1983, AM STAT, V37, P101, DOI 10.2307/2685868
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   Fuchs J, 2014, IEEE T VIS COMPUT GR, V20, P2251, DOI 10.1109/TVCG.2014.2346426
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Kammer D, 2020, IEEE T VIS COMPUT GR, V26, P1661, DOI 10.1109/TVCG.2020.2969060
   Keck M., 2017, P 10 INT S VIS INF C, P129, DOI [10.1145/3105971.3105979, DOI 10.1145/3105971.3105979]
   Klippel A., 2009, Cartographica: The International Journal for Geographic Information and Geovisualization, V44, P217, DOI DOI 10.3138/CARTO.44.3.217
   Klippel A, 2009, CARTOGR GEOGR INF SC, V36, P149, DOI 10.1559/152304009788188808
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Lee M. D, 2003, P AS PAC S INF VIS, P1
   Lewis J., 2012, Proceedings of the 34th Annual Conference of the Cognitive Science Society, P671
   Lewis J., 2012, P ANN M COGN SCI SOC, P1870
   Li J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2553
   Li J, 2009, IEEE PAC VIS SYMP, P97, DOI 10.1109/PACIFICVIS.2009.4906843
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mansmann F, 2013, P SIGCHI C HUM FACT, DOI DOI 10.1145/2470654.2466443
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Miller M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P91, DOI [10.1109/visual.2019.8933656, 10.1109/VISUAL.2019.8933656]
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Peng W, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P89
   Pickett R. M., 1988, Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics (IEEE Cat. No.88CH2556-9), P514
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Tatu A., 2010, P AVI, P49, DOI DOI 10.1145/1842993.1843002
   TEDFORD WH, 1977, J GEN PSYCHOL, V97, P145, DOI 10.1080/00221309.1977.9918511
   Tremmel L., 1995, J. Comput. Graphical Statist., V4, P101
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Ward Matthew O, 2008, HDB DATA VISUALIZATI, P179, DOI [DOI 10.1007/978-3-540-33037-0_8, 10.1007/978-3-540-33037-083, DOI 10.1007/978-3-540-33037-083]
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Yang J, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P105
NR 41
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5468
EP 5482
DI 10.1109/TVCG.2022.3216919
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300045
PM 36288226
OA Green Published, hybrid
DA 2024-11-06
ER

PT J
AU Reda, K
AF Reda, Khairi
TI Rainbow Colormaps: What are They <i>Good</i> and <i>Bad</i> for?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Task analysis; Encoding; Costs; Observers;
   Standards; Sensitivity; Quantitative color encoding; rainbow colormaps;
   scalar fields; perception
ID RUSSIAN BLUES; INFERENCE; MAPS; VISUALIZATION; GUIDELINES; SCHEMES
AB Guidelines for color use in quantitative visualizations have strongly discouraged the use of rainbow colormaps, arguing instead for smooth designs that do not induce visual discontinuities or implicit color categories. However, the empirical evidence behind this argument has been mixed and, at times, even contradictory. In practice, rainbow colormaps are widely used, raising questions about the true utility or dangers of such designs. We study how color categorization impacts the interpretation of scalar fields. We first introduce an approach to detect latent categories in colormaps. We hypothesize that the appearance of color categories in scalar visualizations can be beneficial in that they enhance the perception of certain features, although at the cost of rendering other features less noticeable. In three crowdsourced experiments, we show that observers are more likely to discriminate global, distributional features when viewing colorful scales that induce categorization (e.g., rainbow or diverging schemes). Conversely, when seeing the same data through a less colorful representation, observers are more likely to report localized features defined by small variations in the data. Participants showed awareness of these different affordances, and exhibited bias for exploiting the more discriminating colormap, given a particular feature type. Our results demonstrate costs and benefits for rainbows (and similarly colorful schemes), suggesting that their complementary utility for analyzing scalar data should not be dismissed. In addition to explaining potentially valid uses of rainbow, our study provides actionable guidelines, including on when such designs can be more harmful than useful. Data and materials are available at https://osf.io/xjhtf
C1 [Reda, Khairi] Indiana Univ Purdue Univ, Indianapolis, IN 46208 USA.
C3 Purdue University System; Purdue University
RP Reda, K (corresponding author), Indiana Univ Purdue Univ, Indianapolis, IN 46208 USA.
EM redak@iu.edu
OI Reda, Khairi/0000-0002-8096-658X
FU National Science Foundation [1942429]
FX This work was supported by the National Science Foundation under Grant
   1942429.
CR Bergman LD, 1995, VISUALIZATION '95 - PROCEEDINGS, P118, DOI 10.1109/VISUAL.1995.480803
   Berlin B., 1991, Basic Color Terms: Their Universality and Evolution
   Borkin MA, 2011, IEEE T VIS COMPUT GR, V17, P2479, DOI 10.1109/TVCG.2011.192
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Borland D, 2011, IEEE COMPUT GRAPH, V31, P7, DOI 10.1109/MCG.2011.55
   Brewer C., 1997, Cartography Geographic Informat. Syst., V24, P203, DOI 10.1559/152304097782439231
   Brewer CA, 1996, CARTOGR J, V33, P79
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Bujack R, 2018, IEEE T VIS COMPUT GR, V24, P923, DOI 10.1109/TVCG.2017.2743978
   Crameri F, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19160-7
   Dasgupta A, 2020, IEEE T VIS COMPUT GR, V26, P1577, DOI 10.1109/TVCG.2018.2876539
   Derefeldt G, 2004, COLOR RES APPL, V29, P7, DOI 10.1002/col.10209
   FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q
   Golebiowska IM, 2022, IEEE T VIS COMPUT GR, V28, P2722, DOI 10.1109/TVCG.2020.3035823
   Green DA, 2011, B ASTRON SOC INDIA, V39, P289
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   HAYS DG, 1972, AM ANTHROPOL, V74, P1107, DOI 10.1525/aa.1972.74.5.02a00050
   Heer J., 2012, P SIGCHI C HUM FACT, P1007, DOI [DOI 10.1145/2207676.22085472,4, 10.1145/2207676.2208547, DOI 10.1145/2207676.2208547, 10.1145/2207676.22085472,4]
   Hofmann H, 2012, IEEE T VIS COMPUT GR, V18, P2441, DOI 10.1109/TVCG.2012.230
   Huang LQ, 2007, PSYCHOL REV, V114, P599, DOI 10.1037/0033-295X.114.3.599
   Kalvin AD, 2000, P SOC PHOTO-OPT INS, V3959, P323, DOI 10.1117/12.387169
   Kaye NR, 2012, GEOSCI MODEL DEV, V5, P245, DOI 10.5194/gmd-5-245-2012
   Light A., 2004, Eos Trans. AGU, V85, P385, DOI [10.1029/2004EO400002, DOI 10.1029/2004EO400002, 10.10291200480400002]
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   Moreland K., 2016, Electron. Imag., V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.16.HVEI-133, DOI 10.2352/ISSN.2470-1173.2016.16.HVEI-133]
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nardini P, 2021, IEEE T VIS COMPUT GR, V27, P1043, DOI 10.1109/TVCG.2020.3028955
   Paramei GV, 2005, CROSS-CULT RES, V39, P10, DOI 10.1177/1069397104267888
   Quinan PS, 2019, COMPUT GRAPH FORUM, V38, P363, DOI 10.1111/cgf.13695
   Reda K, 2021, COMPUT GRAPH FORUM, V40, P49, DOI 10.1111/cgf.14288
   Reda K, 2021, IEEE T VIS COMPUT GR, V27, P1032, DOI 10.1109/TVCG.2020.3030439
   Reda K, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P271, DOI [10.1109/VISUAL.2019.8933760, 10.1109/visual.2019.8933760]
   Reda K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173846
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Rogowitz BE, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P321
   Rogowitz BE, 1998, IEEE SPECTRUM, V35, P52, DOI 10.1109/6.736450
   Rogowitz E. E., 1996, Computers in Physics, V10, P268
   Silva S, 2011, COMPUT GRAPH-UK, V35, P320, DOI 10.1016/j.cag.2010.11.015
   Skelton AE, 2017, P NATL ACAD SCI USA, V114, P5545, DOI 10.1073/pnas.1612881114
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Sun MD, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.679627
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Thyng KM, 2016, OCEANOGRAPHY, V29, P9, DOI 10.5670/oceanog.2016.66
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   van der Walt Stefan, 2015, MATPLOTLIB COLORMAPS
   VanderPlas S, 2017, J COMPUT GRAPH STAT, V26, P231, DOI 10.1080/10618600.2016.1209116
   VanderPlas S, 2016, IEEE T VIS COMPUT GR, V22, P459, DOI 10.1109/TVCG.2015.2469125
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [DOI 10.1145/345513.345271, 10/cqq2cj]
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Ware C., 2019, Information Visualization: Perception for Design
   Ware C, 2019, IEEE T VIS COMPUT GR, V25, P2777, DOI 10.1109/TVCG.2018.2855742
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
   Winawer J, 2007, P NATL ACAD SCI USA, V104, P7780, DOI 10.1073/pnas.0701644104
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 55
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5496
EP 5510
DI 10.1109/TVCG.2022.3214771
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300047
PM 36240035
OA Green Submitted
DA 2024-11-06
ER

PT J
AU dos Anjos, RK
   Walton, D
   Aksit, K
   Friston, S
   Swapp, D
   Steed, A
   Ritschel, T
AF dos Anjos, Rafael Kuffner
   Walton, David
   Aksit, Kaan
   Friston, Sebastian
   Swapp, David
   Steed, Anthony
   Ritschel, Tobias
TI Metameric Inpainting for Image Warping
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Real-time systems; Visualization; Rendering (computer graphics); Neural
   networks; Image color analysis; Task analysis; Visual perception;
   Inpainting; warping; perception; real-time rendering
AB Image-warping, a per-pixel deformation of one image into another, is an essential component in immersive visual experiences such as virtual reality or augmented reality. The primary issue with image warping is disocclusions, where occluded (and hence unknown) parts of the input image would be required to compose the output image. We introduce a new image warping method, Metameric image inpainting - an approach for hole-filling in real-time with foundations in human visual perception. Our method estimates image feature statistics of disoccluded regions from their neighbours. These statistics are inpainted and used to synthesise visuals in real-time that are less noticeable to study participants, particularly in peripheral vision. Our method offers speed improvements over the standard structured image inpainting methods while improving realism over colour-based inpainting such as push-pull. Hence, our work paves the way towards future applications such as depth image-based rendering, 6-DoF 360 rendering, and remote render-streaming.
C1 [dos Anjos, Rafael Kuffner] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
   [Walton, David; Aksit, Kaan; Friston, Sebastian; Swapp, David; Steed, Anthony; Ritschel, Tobias] UCL, London WC1E 6BT, England.
C3 University of Leeds; University of London; University College London
RP dos Anjos, RK (corresponding author), Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
EM r.kuffnerdosanjos@leeds.ac.uk; david.walton.13@ucl.ac.uk;
   kunguz@gmail.com; Sebastian.friston@ucl.ac.uk; d.swapp@ucl.ac.uk;
   a.steed@ucl.ac.uk; t.ritschel@ucl.ac.uk
RI Aksit, Kaan/AAY-6704-2020
OI Swapp, David/0000-0002-9335-8663; Walton, David/0000-0001-5879-9714;
   Steed, Anthony/0000-0001-9034-3020; AKSIT, KAAN/0000-0002-5934-5500;
   Kuffner dos Anjos, Rafael/0000-0002-2616-7541
FU EPSRC/UKRI project [EP/T01346X/1]; EPSRC [EP/T01346X/1] Funding Source:
   UKRI
FX This work was supported by EPSRC/UKRI project under Grant EP/T01346X/1.
CR [Anonymous], 2010, P VIS MOD VIS WORKSH
   [Anonymous], 2017, P SID S DIG TECH PAP
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   Denes G, 2019, IEEE T VIS COMPUT GR, V25, P2072, DOI 10.1109/TVCG.2019.2898741
   Didyk P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366203
   Donnelly W., 2006, P 2006 S INT 3D GRAP, P161
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Evangelakos D, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P193, DOI 10.1145/2856400.2876015
   Freeman J, 2011, NAT NEUROSCI, V14, P1195, DOI 10.1038/nn.2889
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gautier J, 2011, 3DTV CONF
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Greenwood JA, 2009, P NATL ACAD SCI USA, V106, P13130, DOI 10.1073/pnas.0901352106
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   Herling J, 2014, IEEE T VIS COMPUT GR, V20, P866, DOI 10.1109/TVCG.2014.2298016
   Horry Y., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P225, DOI 10.1145/258734.258854
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081
   Kopf J, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392420
   Lagae A, 2010, COMPUT GRAPH-UK, V34, P312, DOI 10.1016/j.cag.2010.05.004
   Liang L, 2001, ACM T GRAPHIC, V20, P127, DOI 10.1145/501786.501787
   Lottes Timothy, 2009, White Paper
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Mark W. R., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P7, DOI 10.1145/253284.253292
   Marroquim R., 2007, P S POINT BAS GRAPH, P101
   Mori S, 2020, IEEE T VIS COMPUT GR, V26, P2994, DOI 10.1109/TVCG.2020.3003768
   Mueller JH, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275087
   Nehab D, 2007, GRAPHICS HARDWARE 2007: ACM SIGGRAPH / EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P25
   Okahe M, 2020, IEEE COMPUT GRAPH, V40, P127, DOI 10.1109/MCG.2019.2950176
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Poynton C, 2012, DIGITAL VIDEO AND HD: ALGORITHMS AND INTERFACES, 2ND EDITION, P1
   Reinert B, 2016, COMPUT GRAPH FORUM, V35, P353, DOI 10.1111/cgf.13032
   Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006
   Rosenholtz R, 2016, ANNU REV VIS SCI, V2, P437, DOI 10.1146/annurev-vision-082114-035733
   Rosenholtz R, 2012, J VISION, V12, DOI 10.1167/12.4.14
   Schmid AM, 2009, FRONT SYST NEUROSCI, V3, DOI 10.3389/neuro.06.015.2009
   Schöps T, 2017, IEEE T VIS COMPUT GR, V23, P2455, DOI 10.1109/TVCG.2017.2734578
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Shih ML, 2020, PROC CVPR IEEE, P8025, DOI 10.1109/CVPR42600.2020.00805
   Strasburger H, 2011, J VISION, V11, DOI 10.1167/11.5.13
   Tauber Z, 2007, IEEE T SYST MAN CY C, V37, P527, DOI 10.1109/TSMCC.2006.886967
   Walton DR, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459943
   Wei Li-Yi, 2009, Eurographics'09 State of the Art Reports (STARs), P93
   Yang L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024184
   Yi ZL, 2020, PROC CVPR IEEE, P7505, DOI 10.1109/CVPR42600.2020.00753
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 53
TC 0
Z9 0
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5511
EP 5522
DI 10.1109/TVCG.2022.3216712
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300048
PM 36279345
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Zhang, SK
   Tam, H
   Li, YX
   Mu, TJ
   Zhang, SH
AF Zhang, Shao-Kui
   Tam, Hou
   Li, Yi-Xiao
   Mu, Tai-Jiang
   Zhang, Song-Hai
TI SceneViewer: Automating Residential Photography in Virtual Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Cameras; Photography; Shape; Probes; Solid
   modeling; Rendering (computer graphics); Interior photography; view
   selection; 3D interior scene
ID ALGORITHMS; OCCLUSION
AB Selecting views is one of the most common but overlooked procedures in topics related to 3D scenes. Typically, existing applications and researchers manually select views through a trial-and-error process or "preset" a direction, such as the top-down views. For example, literature for scene synthesis requires views for visualizing scenes. Research on panorama and VR also require initial placements for cameras, etc. This article presents SceneViewer, an integrated system for automatic view selections. Our system is achieved by applying rules of interior photography, which guides potential views and seeks better views. Through experiments and applications, we show the potentiality and novelty of the proposed method.
C1 [Zhang, Shao-Kui; Tam, Hou; Mu, Tai-Jiang; Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Li, Yi-Xiao] Tsinghua Univ, Acad Arts & Design, Beijing 100084, Peoples R China.
   [Zhang, Song-Hai] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University; Tsinghua University
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.; Zhang, SH (corresponding author), Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing 100084, Peoples R China.
EM zhangsk18@mails.tsinghua.edu.cn; th21@mails.tsinghua.edu.cn;
   liyixiao20@mails.tsinghua.edu.cn; taijiang@tsinghua.edu.cn;
   shz@tsinghua.edu.cn
RI Mu, Tai-Jiang/JWO-1381-2024
OI Zhang, Shao-Kui/0000-0003-0353-1977; Tam, Hou/0009-0009-3107-9552; Mu,
   Tai-Jiang/0000-0002-9197-346X
FU Natural Science Foundation of China [62132012]; Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 62132012, and in part by the Tsinghua-Tencent Joint
   Laboratory for Internet Innovation Technology.
CR Andújar C, 2004, COMPUT GRAPH FORUM, V23, P499, DOI 10.1111/j.1467-8659.2004.00781.x
   ANGLUIN D, 1979, J COMPUT SYST SCI, V18, P155, DOI 10.1016/0022-0000(79)90045-X
   Barral P., 2000, PROC INT C 3IA, P3
   Bonaventura X, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20050370
   Bordoloi UD, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P487
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7
   Christie M, 2008, COMPUT GRAPH FORUM, V27, P2197, DOI 10.1111/j.1467-8659.2008.01181.x
   Claassens M., 1997, Ph.D. dis- sertation,
   Cohen-Or D, 1998, COMPUT GRAPH FORUM, V17, pC243, DOI 10.1111/1467-8659.00271
   D'Amelio J., 2004, Perspective Drawing Handbook
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Freitag S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P355, DOI 10.1109/VR.2018.8447553
   Freitag S, 2017, IEEE SYMP 3D USER, P134, DOI 10.1109/3DUI.2017.7893330
   Fu H., 2020, arXiv
   Fu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10913, DOI 10.1109/ICCV48922.2021.01075
   Fu Q, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130805
   Gooch B, 2001, SPRING EUROGRAP, P83
   Handa A, 2016, PROC CVPR IEEE, P4077, DOI 10.1109/CVPR.2016.442
   Harris M. G., 2003, Professional Interior Photography
   He Y, 2020, Arxiv, DOI arXiv:2003.04187
   Hicks R., Interiors: A Guide to Professional Lighting Techniques Interior Shots (Pro-lighting)
   Jakob Wenzel, 2010, Mitsuba Renderer
   Jaubert B, 2006, 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND ARTIFICIAL INTELLIGENCE, P31
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Kim YM, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366157
   Krages B., 2005, The Art of Composition
   Krages B., 2012, Photography: the art of composition
   kujiale.com, 2020, Kujiale
   Lewis H. R., J. Symbolic Log., V48, P498
   Li WB, 2018, COMM COM INF SC, V779, P77, DOI 10.1007/978-3-319-71734-0_7
   Liang Y, 2021, IEEE T VIS COMPUT GR, V27, P3438, DOI 10.1109/TVCG.2020.2972897
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   Liu ZS, 2016, GRAPH MODELS, V85, P22, DOI 10.1016/j.gmod.2016.03.001
   Luo A, 2020, PROC CVPR IEEE, P3753, DOI 10.1109/CVPR42600.2020.00381
   Nagarnaik P, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1603, DOI 10.1109/ECS.2015.7124857
   Nan LL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366156
   Neumann L., 2005, Computational Aesthetics in Graphics, Visualization and Imaging, P185
   Pantazopoulos I, 2002, J INTELL ROBOT SYST, V35, P123, DOI 10.1023/A:1021175220384
   planner5d.com, 2020, Planner5D
   Prakel D., 2006, Basics Photography 01: Composition, V1
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   RUBIN F, 1974, J ACM, V21, P576, DOI 10.1145/321850.321854
   Ruiz M, 2010, COMPUT GRAPH-UK, V34, P351, DOI 10.1016/j.cag.2010.01.006
   Satkin S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.128
   Savva M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925867
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Takahashi S, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P495
   Tao J, 2013, IEEE T VIS COMPUT GR, V19, P393, DOI 10.1109/TVCG.2012.143
   Vu T, 2022, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR52688.2022.00273
   Vázquez PP, 2004, PROCEEDINGS OF THE FOURTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P625
   Vázquez PP, 2003, COMPUT GRAPH FORUM, V22, P689, DOI 10.1111/j.1467-8659.2003.00717.x
   Wang K, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322941
   Wang K, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201362
   Webb J., 2017, Basics Creative Photography 01: Design Principles
   WEGHORST H, 1984, ACM T GRAPHIC, V3, P52, DOI 10.1145/357332.357335
   Wilf H.S., 1986, ALGORITHMS COMPLEXIT, V986
   Xu K, 2014, IEEE IPCCC, DOI 10.1109/PCCC.2014.7017103
   Yan M, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095169
   Yang Sheng, 2017, [Computational Visual Media, 计算可视媒体], V3, P131
   Yew ZJ, 2020, PROC CVPR IEEE, P11821, DOI 10.1109/CVPR42600.2020.01184
   Yu LF, 2016, IEEE T VIS COMPUT GR, V22, P1138, DOI 10.1109/TVCG.2015.2417575
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhang SK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P965, DOI 10.1145/3474085.3475194
   Zhang SK, 2021, GRAPH MODELS, V116, DOI 10.1016/j.gmod.2021.101104
   Zhang SH, 2022, IEEE T VIS COMPUT GR, V28, P3082, DOI 10.1109/TVCG.2021.3050143
   Zhang SH, 2019, J COMPUT SCI TECH-CH, V34, P594, DOI 10.1007/s11390-019-1929-5
   Zhang SY, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P353, DOI 10.1145/3013971.3014002
   ziroom.com, 2022, Ziroom
NR 71
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5523
EP 5537
DI 10.1109/TVCG.2022.3214836
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300049
PM 36251891
DA 2024-11-06
ER

PT J
AU Wang, ZY
   Liu, CY
   Chen, JL
   Yao, Y
   Fang, DZ
   Shi, ZY
   Yan, R
   Wang, YY
   Zhang, KJ
   Wang, H
   Wei, HK
AF Wang, Ziyao
   Liu, Chiyi
   Chen, Jialiang
   Yao, Yao
   Fang, Dazheng
   Shi, Zhiyi
   Yan, Rui
   Wang, Yiye
   Zhang, KanJian
   Wang, Hai
   Wei, Haikun
TI Strolling in Room-Scale VR: Hex-Core-MK1 Omnidirectional Treadmill
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Aerospace electronics; User experience; Delays;
   Torso; Spirals; Space technology; Omnidirectional treadmill; locomotion
   devices; locomotion interfaces; room-scale VR
ID WALKING; LOCOMOTION; LATENCY; MOTION
AB The natural locomotion interface is critical to the development of many VR applications. For household VR applications, there are two basic requirements: natural immersive experience and minimized space occupation. The existing locomotion strategies generally do not simultaneously satisfy these two requirements well. This article presents a novel omnidirectional treadmill (ODT) system named Hex-Core-MK1 (HCMK1). By implementing two kinds of mirror-symmetrical spiral rollers to generate the omnidirectional velocity field, this proposed system is capable of providing real walking experiences with a full-degree of freedom in an area as small as 1.76 m(2), while delivering great advantages over several existing ODT systems in terms of weight, volume, latency and dynamic performance. Compared with the sizes of Infinadeck and HCP, the two best motor-driven ODTs so far, the 8 cm height of HCMK1 is only 20% of Infinadeck and 50% of HCP. In addition, HCMK1 is a lightweight device weighing only 110 kg, which provides possibilities for further expanding VR scenarios, such as terrain simulation. The system latency of HCMK1 is only 9ms. The experiments show that HCMK1 can deliver a starting acceleration of 16.00 m/s(2) and a braking acceleration of 30.00 m/s(2).
C1 [Wang, Ziyao; Liu, Chiyi; Chen, Jialiang; Yao, Yao; Fang, Dazheng; Shi, Zhiyi; Yan, Rui; Wang, Yiye; Zhang, KanJian; Wei, Haikun] Southeast Univ, Nanjing 211189, Peoples R China.
   [Wang, Hai] St Marys Univ, Halifax, NS B3H 3C3, Canada.
C3 Southeast University - China; Saint Marys University - Canada
RP Wei, HK (corresponding author), Southeast Univ, Nanjing 211189, Peoples R China.
EM zy_wang@seu.edu.cn; cy_liu@seu.edu.cn; chenjialiang@seu.edu.cn;
   yaoyao@seu.edu.cn; fangdazheng@seu.edu.cn; shizhiyi@seu.edu.cn;
   yan_rui@seu.edu.cn; wangyiye@seu.edu.cn; kjzhang@seu.edu.cn;
   hwang@smu.ca; hkwei@seu.edu.cn
FU National Natural Science Foundation of China [61773118, 61973083];
   Science and Technology Project of State Grid Corporation of China
   (Intelligent operation and maintenance technology of distributed
   photovoltaic system) [SGTJDK00DYJS2000148]; Key Laboratory of
   Measurement and Control of Complex Systems of Engineering, Ministry of
   Education, Nanjing, China
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61773118 and 61973083, in part by the
   Science and Technology Project of State Grid Corporation of China
   (Intelligent operation and maintenance technology of distributed
   photovoltaic system) under Grant SGTJDK00DYJS2000148, in part by the Key
   Laboratory of Measurement and Control of Complex Systems of Engineering,
   Ministry of Education, Nanjing, China.
CR Adelstein B. D., 2003, P HUMAN FACTORS ERGO, V47, P2083, DOI DOI 10.1177/154193120304702001
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Ang YY, 2018, ADV INTELL SYST, V696, P367, DOI 10.1007/978-981-10-7386-1_32
   Asl HJ, 2018, IEEE INT CONF ROBOT, P1639
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Benjamin A., 2021, EB/OL
   Bölling L, 2019, IEEE T VIS COMPUT GR, V25, P2032, DOI 10.1109/TVCG.2019.2899228
   Brinks H., 2016, Redesign of the Omnideck platform: With respect to DfA and modularity
   Buker TJ, 2012, HUM FACTORS, V54, P235, DOI 10.1177/0018720811428734
   Cakmak T., 2014, ACM SIGGRAPH 2014 Emerging Technologies, P1, DOI DOI 10.1145/2614066.2614105
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   De Luca A, 2013, IEEE T CONTR SYST T, V21, P410, DOI 10.1109/TCST.2012.2185051
   De Luca A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5051, DOI 10.1109/IROS.2009.5354610
   Ellis S.R., 2004, Proceedings of the Human Factors and Ergonomics Society 48th annual meeting, P2632, DOI DOI 10.1177/154193120404802306
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Gamble J.G., 2006, Human Walking
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Hollerbach J. M., 2002, Handbook of Virtual Environments, P279
   Huang JY, 2003, IEEE T MULTIMEDIA, V5, P39, DOI 10.1109/TMM.2003.808822
   Ilon B. E., 1975, US Patent, Patent No. [3,876,255, 3876255]
   Iwata H, 2005, IEEE COMPUT GRAPH, V25, P64, DOI 10.1109/MCG.2005.5
   Iwata H, 2000, ROBOTICS RESEARCH, P275
   Iwata H, 1999, P IEEE VIRT REAL ANN, P286, DOI 10.1109/VR.1999.756964
   Iwata H., 2007, ACM SIGGRAPH 2007 emerging technologies, P20, DOI 10.1145/1278280.1278301
   Jenkins A., 2019, The fall and rise of VR: The struggle to make virtual reality get real
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jones JA, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1000, DOI [10.1109/vr.2019.8798361, 10.1109/VR.2019.8798361]
   Kolasinski E. M., 1995, Simulator sickness in virtual environments, V1027
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lawson BD, 2015, HUM FACTORS ERGON, P531
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Lee H, 2016, INT CONF UBIQ ROBOT, P889, DOI 10.1109/URAI.2016.7734002
   Lee J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092832
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Metsis V, 2017, 2017 INTERNATIONAL SYMPOSIUM ON WEARABLE ROBOTICS AND REHABILITATION (WEROB), P33
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Okreylos, 2016, Lighthouse tracking examined
   Pai YS, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P189, DOI 10.1145/3152832.3152864
   Parrish K., 2018, Pricing and lack of content are still barriers against the adoption of VR
   Pyo SH, 2018, IEEE INT CONF ROBOT, P760
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Schwaiger M., 2007, Proc. IEEE International Workshop on Haptic Audio Visual Environments and their Applications, P50
   Schwaiger MC, 2007, World Haptics 2007: Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, Proceedings, P415
   Slater M., 1994, Virtual Reality Software and Technology. Proceedings of the VRST '94 Conference, P45
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Steinicke F., 2013, Human Walking in Virtual Environments, V2
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Teknomo K., 2016, MICROSCOPIC PEDESTRI
   Templeman J. N., 2006, Immersive Simulation to Train Urban Infantry Combat
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Tregillus S, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1250, DOI 10.1145/2858036.2858084
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vlachos A., 2015, AdvancedVRrendering
   Waller D, 2007, BEHAV RES METHODS, V39, P835, DOI 10.3758/BF03192976
   Wang CZ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281536
   Wang F, 2010, IEEE ENG MED BIO, P2225, DOI 10.1109/IEMBS.2010.5626100
   Wang ZY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P382, DOI [10.1109/VR46266.2020.1580802970259, 10.1109/VR46266.2020.00-46, 10.1109/ICEDME50972.2020.00092]
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
NR 64
TC 3
Z9 3
U1 9
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5538
EP 5555
DI 10.1109/TVCG.2022.3216211
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300050
PM 36264727
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zeng, Y
   Wang, L
   Xu, YM
   Meng, XX
AF Zeng, Yan
   Wang, Lu
   Xu, Yanning
   Meng, Xiangxu
TI Neural Temporal Denoising for Indirect Illumination
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Noise reduction; Real-time systems; Lighting; Kernel; Image
   reconstruction; Image color analysis; Rendering (computer graphics);
   Dual motion vector; neural temporal denoising; real-time ray tracing
AB Various temporal denoising methods have been proposed to clean up the noise for real-time ray tracing (RTRT). These methods rely on the temporal correspondences of pixels between the current and previous frames, i.e. per-pixel screen-space motion vectors. However, the state-of-the-art temporal reuse methods with traditional motion vectors cause artifacts in motion occlusions. We accordingly propose a novel neural temporal denoising method for indirect illumination of Monte Carlo (MC) ray tracing at 1 sample per pixel. Based on end-to-end multi-scale kernel-based reconstruction, we apply temporally reliable dual motion vectors to facilitate better reconstruction of the occlusions, and also introduce additional motion occlusion loss to reduce ghosting artifacts. Experiments show that our method significantly reduces the over-blurring and ghosting artifacts while generating high-quality images at real-time rates.
C1 [Zeng, Yan; Wang, Lu; Xu, Yanning; Meng, Xiangxu] Shandong Univ, Dept Sch Software, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University
RP Wang, L (corresponding author), Shandong Univ, Dept Sch Software, Jinan 250101, Shandong, Peoples R China.
EM yanzeng@mail.sdu.edu.cn; luwang_hcivr@sdu.edu.cn; xyn@sdu.edu.cn;
   mxx@sdu.edu.cn
OI Zeng, Yan/0000-0003-0840-5259
FU National Key R&D Program of China [2020YFB1708903]; National Natural
   Science Foundation of China [61872223, 62272275, 61902202]; Shandong
   Provincial Natural Science Foundation of China [ZR2020LZH016]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020YFB1708903, in part by the National Natural Science
   Foundation of China under Grants 61872223, 62272275 and 61902202 and in
   part by the Shandong Provincial Natural Science Foundation of China
   under Grant ZR2020LZH016.
CR Bako S, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073708, 10.1145/3072959.3073703]
   Chaitanya CRA, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073601
   Gharbi M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322954
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow I. J., 2019, ACM Trans. Graph., V38, P12
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480531
   Hasselgren J, 2020, COMPUT GRAPH FORUM, V39, P147, DOI 10.1111/cgf.13919
   Heitz E, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925895
   Huo Y, 2021, COMPUT VIS MEDIA, V7, P169, DOI 10.1007/s41095-021-0209-9
   Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902
   Kingma D.P., 2014, P INT C LEARNING REP
   Kuznetsov A, 2018, COMPUT GRAPH FORUM, V37, P35, DOI 10.1111/cgf.13473
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Moon B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925936
   Moon B, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2641762
   Munkberg J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982407
   Parker SG, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778803
   Paszke A, Automatic differentiation in pytorch
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rousselle F, 2013, COMPUT GRAPH FORUM, V32, P121, DOI 10.1111/cgf.12219
   Rubinstein R.Y., 2016, Simulation and the Monte Carlo method
   Schied C, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3233301
   Schied C, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105770
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2167076.2167083
   Tatarchuk N., 2014, Advances in Real-Time Rendering in Games
   Uday M. S., 2014, ACM Trans. Graph, V33
   Vogels T, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201388
   Xu B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356547
   Yan LQ, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2816814
   Zeng Z, 2021, COMPUT GRAPH FORUM, V40, P79, DOI 10.1111/cgf.142616
   Zwicker M, 2015, COMPUT GRAPH FORUM, V34, P667, DOI 10.1111/cgf.12592
NR 32
TC 1
Z9 1
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5569
EP 5578
DI 10.1109/TVCG.2022.3217305
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300052
PM 36327190
DA 2024-11-06
ER

PT J
AU Saint-Aubert, J
   Manson, J
   Bonan, I
   Launey, Y
   Lécuyer, A
   Cogné, M
AF Saint-Aubert, Justine
   Manson, Julien
   Bonan, Isabelle
   Launey, Yoann
   Lecuyer, Anatole
   Cogne, Melanie
TI Effect of Vibrations on Impression of Walking and Embodiment With First-
   and Third-Person Avatar
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Rendering (computer graphics); Legged locomotion; Foot;
   Visualization; Vibrations; Loading; Action observation; avatar;
   embodiment; impression of walking; vibrotactile feedback; virtual
   reality
ID SENSE
AB We investigate how underfoot vibrotactile feedback can be used to increase the impression of walking and embodiment of static users represented by a first- or third-person avatar. We designed a multi-sensory setup involving avatar displayed on an HMD, and a set of vibrotactile effects displayed at every footstep. In a first study (N = 44), we compared the impression of walking in 3 vibrotactile conditions : 1) with a "constant" vibrotactile rendering reproducing simple contact information, 2) with a more sophisticated "phase-based" vibrotactile rendering the successive contacts of a walking cycle and 3) without vibrotactile feedback. The results show that overall both constant and phase-based rendering significantly improve the impression of walking in first and third-person perspective. Interestingly, the more realistic phase-based rendering seems to increase significantly the impression of walking in the third-person condition, but not in the first-person condition. In a second study (N=28), we evaluated the embodiment towards first- and third-person avatar while receiving no vibrotactile feedback or by receiving vibrotactile feedback. The results show that vibrotactile feedback improves embodiment in both perspectives of the avatar. Taken together, our results support the use of vibrotactile feedback when users observe first- and third-person avatar. They also suggest that constant and phase-based rendering could be used with first-person avatar and support the use of phase-based rendering with third-person avatar. They provide valuable insight for stimulations in any VR applications in which the impression of walking is prominent such as for virtual visits, walking rehabilitation, video games, etc.
C1 [Saint-Aubert, Justine; Manson, Julien; Lecuyer, Anatole; Cogne, Melanie] Inria Rennes, F-35042 Rennes, France.
   [Bonan, Isabelle; Launey, Yoann; Cogne, Melanie] Rennes Univ Hosp, F-35000 Rennes, France.
C3 Universite de Rennes; CHU Rennes; Universite de Rennes
RP Saint-Aubert, J (corresponding author), Inria Rennes, F-35042 Rennes, France.
EM justine.saint-aubert@inria.fr; julien.manson@ens-rennes.fr;
   isabelle.bonan@chu-rennes.fr; yoann.launey@chu-rennes.fr;
   anatole.lecuyer@inria.fr; Melanie.COGNE@chu-rennes.fr
RI Launey, Yoann/AAN-7176-2020
OI Launey, Yoann/0000-0001-9105-8862; Saint-Aubert,
   Justine/0000-0001-8412-653X; Manson, Julien/0000-0001-6916-2129
FU Research and Innovation Department of the University Hospital of Rennes
FX We thank the Research and Innovation Department of the University
   Hospital of Rennes for supporting our study.
CR Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Dobricki M., 2020, Locomotor illusions can arise from perceiving multisensory stimuli configuring into a sensorimotor body-environment structure
   Farkhatdinov I, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P677, DOI 10.1109/WHC.2013.6548490
   Freiwald JP, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376574
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   González I, 2015, SENSORS-BASEL, V15, P16589, DOI 10.3390/s150716589
   Gorisse G, 2017, FRONT ROBOT AI, V4, DOI 10.3389/frobt.2017.00033
   Ikei Y, 2015, P IEEE VIRT REAL ANN, P195, DOI 10.1109/VR.2015.7223362
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kitazaki M, 2019, I-PERCEPTION, V10, DOI 10.1177/2041669519882448
   Kitazaki M, 2016, LECT NOTES COMPUT SC, V9734, P501, DOI 10.1007/978-3-319-40349-6_48
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Kruijff E, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P149, DOI 10.1145/2983310.2985759
   Lécuyer A, 2006, P IEEE VIRT REAL ANN, P11, DOI 10.1109/VR.2006.31
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Matsuda Y, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.654088
   Medeiros D, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281511
   Okamura AM, 1998, IEEE INT CONF ROBOT, P674, DOI 10.1109/ROBOT.1998.677050
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Richard G, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P186, DOI 10.1109/VR51125.2022.00037
   Rosenbaum D., 1994, GAIT POSTURE, V2, P191, DOI [10.1016/0966-6362(94)90007-8, DOI 10.1016/0966-6362(94)90007-8, 10.1016/0966-6362, DOI 10.1016/0966-6362]
   Saint-Aubert J, 2023, IEEE T VIS COMPUT GR, V29, P3507, DOI 10.1109/TVCG.2022.3161130
   Soave F, 2020, LECT NOTES COMPUT SC, V12242, P461, DOI 10.1007/978-3-030-58465-8_34
   Terziman L., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P19, DOI 10.1109/3DUI.2012.6184179
   Turchet L, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2536764.2536770
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Vaughan CL, 1992, Dynamics of human gait, V2nd
   Visell Y, 2009, IEEE T HAPTICS, V2, P148, DOI [10.1109/TOH.2009.31, 10.1109/ToH.2009.31]
NR 30
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5579
EP 5585
DI 10.1109/TVCG.2022.3212089
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300053
PM 36197855
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yamamoto, K
   Iwai, D
   Tani, I
   Sato, K
AF Yamamoto, Kenta
   Iwai, Daisuke
   Tani, Ikuho
   Sato, Kosuke
TI A Monocular Projector-Camera System Using Modular Architecture
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lenses; Cameras; Relays; Optics; Mirrors; Optical imaging; Optical
   sensors; Augmented reality; projection mapping; projector-camera system
ID NONRIGID SURFACE
AB This paper presents a monocular projector-camera (procam) system using modular architecture based on relay optics. Conventional coaxial procam systems cannot support (1) online changes to lens settings (zoom and focus) and (2) wide-angle projection mapping. We develop design guidelines for a proposed procam system that would solve these restrictions and address the proposed system's unique technical issue of crosstalk between the camera and projector pixels. We conducted experiments using prototypes to validate the feasibility of the proposed framework. First, we confirmed that the proposed crosstalk reduction technique worked well. Second, we found our technique could achieve correct alignment of a projected image onto a moving surface while changing the zoom and focus of the objective lens. The monocular procam system also achieved radiometric compensation where a surface texture was visually concealed by pixel-wise control of a projection color based on the captured results of offline color pattern projections. Finally, we demonstrated the high expandability of our modular architecture, through the creation of a high dynamic range projection.
C1 [Yamamoto, Kenta; Iwai, Daisuke; Tani, Ikuho; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka 5650871, Japan.
C3 Osaka University
RP Iwai, D (corresponding author), Osaka Univ, Grad Sch Engn Sci, Osaka 5650871, Japan.
EM yamamoto@sens.sys.es.osaka-u.ac.jp; daisuke.iwai@sys.es.osaka-u.ac.jp;
   ikuho.tani@sens.sys.es.osaka-u.ac.jp; sato@sys.es.osaka-u.ac.jp
RI Iwai, Daisuke/R-8174-2019
OI Iwai, Daisuke/0000-0002-3493-5635; Sato, Kosuke/0000-0003-1429-9990
FU JSPS KAKENHI [JP20H05958]; JST, PRESTO, Japan [JPMJPR19J2]
FX This work was supported in part by JSPS KAKENHI under Grant JP20H05958,
   and in part by JST, PRESTO under Grant JPMJPR19J2, Japan.
CR Amano T, 2014, IEEE COMPUT SOC CONF, P449, DOI 10.1109/CVPRW.2014.72
   Amano T, 2012, INT C PATT RECOG, P13
   Asayama H, 2018, IEEE T VIS COMPUT GR, V24, P1077, DOI 10.1109/TVCG.2017.2657634
   Bando Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451239
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Choi S, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480542
   Damberg G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2857051
   Fujii K, 2005, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.2005.41
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601120
   Huang SJ, 2015, APPL OPTICS, V54, P789, DOI 10.1364/AO.54.000789
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Iwai D., 2006, P ACM S VIRT REAL SO, P112, DOI DOI 10.1145/1180495.1180519
   Iwai D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48900-z
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Iwai D, 2015, IEEE T VIS COMPUT GR, V21, P462, DOI 10.1109/TVCG.2015.2391861
   Iwai D, 2010, INFRARED PHYS TECHN, V53, P162, DOI 10.1016/j.infrared.2009.11.001
   Jones B., 2013, P SIGCHI C HUM FACT, P869, DOI DOI 10.1145/2470654.2466112
   Li YQ, 2015, COMPUT GRAPH FORUM, V34, P337, DOI 10.1111/cgf.12564
   Li ZQ, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1427, DOI 10.1145/3322276.3322314
   Li ZQ, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P845, DOI 10.1145/3196709.3196753
   Li ZW, 2020, CURR EYE RES, V45, P1240, DOI 10.1080/02713683.2020.1730404
   Maeda K, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P311, DOI 10.1145/3279778.3279911
   Matsushita K., 2011, P 2 AUG HUM INT C, P1
   Mignard-Debise L, 2019, IEEE T COMPUT IMAG, V5, P585, DOI 10.1109/TCI.2019.2911856
   Mihara S, 2014, IEEE T CIRC SYST VID, V24, P1631, DOI 10.1109/TCSVT.2014.2309832
   Mine M, 2012, COMPUTER, V45, P32, DOI 10.1109/MC.2012.154
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Punpongsanon P, 2015, VIRTUAL REAL-LONDON, V19, P45, DOI 10.1007/s10055-014-0256-y
   Pyo S., 2007, P HUM FACT COMP SYST, P2615
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Sueishi T, 2016, PRESENCE-VIRTUAL AUG, V25, P299, DOI 10.1162/PRES_a_00275
   Taketomi T, 2013, INT SYM MIX AUGMENT, P295, DOI 10.1109/ISMAR.2013.6671812
   Takezawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI [10.1109/vr.2019.8797923, 10.1109/VR.2019.8797923]
   Tone D, 2020, IEEE T VIS COMPUT GR, V26, P2030, DOI 10.1109/TVCG.2020.2973444
   Toyohara S, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281532
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Yoshida T., 2003, P INT C VIRT SYST MU, P161
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 42
TC 1
Z9 1
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5586
EP 5592
DI 10.1109/TVCG.2022.3217266
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300054
PM 36288225
OA hybrid
DA 2024-11-06
ER

PT J
AU Reimann, D
   Schulz, A
   Ram, N
   Gaschler, R
AF Reimann, Daniel
   Schulz, Andre
   Ram, Nilam
   Gaschler, Robert
TI Color-Encoded Links Improve Homophily Perception in Node-Link Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Layout; Image color analysis; Standards;
   Psychology; Color; Information visualization; node-link diagrams;
   homophily; perception
ID VISUAL DATA COMMUNICATION
AB Node-link diagrams enable visual assessment of homophily when viewers can identify and evaluate the relative number of intra-cluster and inter-cluster links. Our online experiment shows that a new design with link type encoded edge color leads to more accurate perception of homophily than a design with same-color edges.
C1 [Reimann, Daniel; Gaschler, Robert] Fern Univ Hagen, Dept Psychol, D-58097 Hagen, Germany.
   [Schulz, Andre] Fern Univ Hagen, Dept Math & Comp Sci, D-58097 Hagen, Germany.
   [Ram, Nilam] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.
   [Ram, Nilam] Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
C3 Fern University Hagen; Fern University Hagen; Stanford University;
   Stanford University
RP Reimann, D (corresponding author), Fern Univ Hagen, Dept Psychol, D-58097 Hagen, Germany.
EM daniel.reimann@fernuni-hagen.de; andre.schulz@fernuni-hagen.de;
   nilamram@stanford.edu; robert.gaschler@fernuni-hagen.de
OI Gaschler, Robert/0000-0002-8576-5330; Ram, Nilam/0000-0003-1671-5257;
   Schulz, Andre/0000-0002-2134-4852
CR [Anonymous], 1933, Emotions Mapped by New Geography
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bracegirdle C, 2022, J PERS SOC PSYCHOL, V122, P1, DOI 10.1037/pspa0000240
   Burch M, 2021, IEEE ACCESS, V9, P4173, DOI 10.1109/ACCESS.2020.3047616
   Carney RN, 2002, EDUC PSYCHOL REV, V14, P5, DOI 10.1023/A:1013176309260
   Dwyer T, 2009, COMPUT GRAPH FORUM, V28, P991, DOI 10.1111/j.1467-8659.2009.01449.x
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Huang WD, 2009, INFORM VISUAL, V8, P139, DOI 10.1057/ivs.2009.10
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   McGrath C., 1996, Connections, V19, P22
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Meulemans W, 2015, LECT NOTES COMPUT SC, V9411, P489, DOI 10.1007/978-3-319-27261-0_40
   Nothelfer C, 2017, J EXP PSYCHOL HUMAN, V43, P1667, DOI 10.1037/xhp0000314
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Reimann D., 2022, Color-encoded links improve homophily perception in nodelink diagrams
   Reimann D., 2021, SN Social Sci., V1, DOI [10.1007/s43545-021-00153-2, DOI 10.1007/S43545-021-00153-2]
   Schwabish J, 2021, PSYCHOL SCI PUBL INT, V22, P97, DOI 10.1177/15291006211057899
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Ware C., 2019, Information Visualization: Perception for Design
   Wolfe JM, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0058
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yoghourdjian V, 2021, IEEE T VIS COMPUT GR, V27, P1677, DOI 10.1109/TVCG.2020.3030459
   Yoghourdjian V, 2018, VIS INFORM, V2, P264, DOI 10.1016/j.visinf.2018.12.006
   Zacks JM, 2020, POL INS BEH BRAIN SC, V7, P52, DOI 10.1177/2372732219893712
NR 27
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5593
EP 5598
DI 10.1109/TVCG.2022.3221014
PG 6
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300055
PM 36355720
DA 2024-11-06
ER

PT J
AU Deng, DZ
   Cui, WW
   Meng, XY
   Xu, MY
   Liao, Y
   Zhang, HD
   Wu, YC
AF Deng, Dazhen
   Cui, Weiwei
   Meng, Xiyu
   Xu, Mengye
   Liao, Yu
   Zhang, Haidong
   Wu, Yingcai
TI Revisiting the Design Patterns of Composite Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Taxonomy; Task analysis; Layout;
   Grammar; Bars; Datasets; visual analytics; visualization specification;
   visualization design
ID OF-THE-ART; VISUAL ANALYSIS; GUIDELINES; DIFFUSION; NETWORKS; SPACE;
   SCALE; VEGA; SETS
AB Composite visualization is a popular design strategy that represents complex datasets by integrating multiple visualizations in a meaningful and aesthetic layout, such as juxtaposition, overlay, and nesting. With this strategy, numerous novel designs have been proposed in visualization publications to accomplish various visual analytic tasks. However, there is a lack of understanding of design patterns of composite visualization, thus failing to provide holistic design space and concrete examples for practical use. In this article, we opted to revisit the composite visualizations in IEEE VIS publications and answered what and how visualizations of different types are composed together. To achieve this, we first constructed a corpus of composite visualizations from the publications and analyzed common practices, such as the pattern distributions and co-occurrence of visualization types. From the analysis, we obtained insights into different design patterns on the utilities and their potential pros and cons. Furthermore, we discussed usage scenarios of our taxonomy and corpus and how future research on visualization composition can be conducted on the basis of this study.
C1 [Deng, Dazhen; Meng, Xiyu; Xu, Mengye; Liao, Yu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310000, Zhejiang, Peoples R China.
   [Cui, Weiwei; Zhang, Haidong] Microsoft Res Asia, Beijing 100000, Peoples R China.
C3 Zhejiang University; Microsoft Research Asia; Microsoft
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310000, Zhejiang, Peoples R China.; Cui, WW (corresponding author), Microsoft Res Asia, Beijing 100000, Peoples R China.
EM dengdazhen@zju.edu.cn; weiweicu@microsoft.com; mengxiyu@zju.edu.cn;
   mengyexu@zju.edu.cn; yuliao@zju.edu.cn; haizhang@microsoft.com;
   ycwu@zju.edu.cn
RI Zhang, Haidong/J-9302-2019; Deng, Dazhen/JXW-7493-2024
OI Deng, Dazhen/0000-0002-9057-8353
FU NSFC [62072400]; Collaborative Innovation Center of Artificial
   Intelligence by MOE; Zhejiang Provincial Government (ZJU); Zhejiang Lab
   [2021KE0AC02]
FX This work was supported in part by NSFC under Grant 62072400, in part by
   the Collaborative Innovation Center of Artificial Intelligence by MOE
   and Zhejiang Provincial Government (ZJU), and in part by Zhejiang Lab
   under Grant 2021KE0AC02.
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Andrienko Gennady, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P59, DOI 10.1109/VAST.2010.5652478
   Andrienko N, 2019, IEEE T VIS COMPUT GR, V25, P54, DOI 10.1109/TVCG.2018.2864811
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Beck F., 2014, EuroVis-STARs
   Blackwell A, 2000, DIAGRAMMATIC REPRESENTATION AND REASONING, P47
   Borgo R., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bruna J., 2011, 2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis, P99, DOI 10.1109/IVMSPW.2011.5970362
   Cao N, 2018, IEEE T VIS COMPUT GR, V24, P23, DOI 10.1109/TVCG.2017.2744419
   Cao N, 2012, IEEE T VIS COMPUT GR, V18, P2649, DOI 10.1109/TVCG.2012.291
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen M, 2019, COMPUT GRAPH FORUM, V38, P131, DOI 10.1111/cgf.13677
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Dong Hyun Jeong, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P285, DOI 10.1109/VAST.2011.6102476
   Eick SG, 2007, IEEE S VIS ANAL, P51, DOI 10.1109/VAST.2007.4388996
   El-Assady M, 2018, IEEE T VIS COMPUT GR, V24, P382, DOI 10.1109/TVCG.2017.2745080
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Engelhardt Y, 2018, LECT NOTES ARTIF INT, V10871, P201, DOI 10.1007/978-3-319-91376-6_20
   Farrugia M, 2011, INFORM VISUAL, V10, P47, DOI 10.1057/ivs.2010.10
   Fekete J.-D., 2003, Proceedings of the IEEE Symposium on Information Visualization (InfoVis'03), P82
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gotz D, 2008, IEEE S VIS ANAL, P123, DOI 10.1109/VAST.2008.4677365
   Gratzl S, 2014, IEEE T VIS COMPUT GR, V20, P2023, DOI 10.1109/TVCG.2014.2346260
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Hao Ming C., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P229, DOI 10.1109/VAST.2009.5333420
   Harris R. L, 1999, Information Graph.: A Comprehensive Illustrated Reference
   Heer J, 2010, COMMUN ACM, V53, P59, DOI 10.1145/1743546.1743567
   Henry N, 2008, IEEE T VIS COMPUT GR, V14, P1317, DOI 10.1109/TVCG.2008.141
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Isenberg P, 2011, IEEE T VIS COMPUT GR, V17, P2469, DOI 10.1109/TVCG.2011.160
   Itoh M, 2015, IEEE CONF VIS ANAL, P199, DOI 10.1109/VAST.2015.7347677
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Johansson J, 2016, IEEE T VIS COMPUT GR, V22, P579, DOI 10.1109/TVCG.2015.2466992
   Johansson S, 2009, IEEE T VIS COMPUT GR, V15, P993, DOI 10.1109/TVCG.2009.153
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kim B, 2009, IEEE T VIS COMPUT GR, V15, P905, DOI 10.1109/TVCG.2009.146
   Ko S, 2014, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2014.7042484
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   Laramee RS, 2004, COMPUT GRAPH FORUM, V23, P203, DOI 10.1111/j.1467-8659.2004.00753.x
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048
   Li Q, 2015, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2015.7347633
   Li R, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P26, DOI 10.1109/SciVis.2018.8823764
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Lokuge I., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P409
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Meirelles Isabel, 2013, DESIGN INFORM INTRO
   Migut M. A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P141, DOI 10.1109/VAST.2011.6102451
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Orban D, 2019, IEEE T VIS COMPUT GR, V25, P256, DOI 10.1109/TVCG.2018.2865051
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Peca I., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P291, DOI 10.1109/VAST.2011.6102479
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Robertson G, 2009, INFORM VISUAL, V8, P247, DOI 10.1057/ivs.2009.23
   Rosenholtz R, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1331
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Sedig K., 2016, Design of visualizations for human-information interaction: A pattern-based framework, DOI DOI 10.1007/978-3-031-02602-7
   Shi DQ, 2022, Arxiv, DOI arXiv:2201.05194
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Srinivasan A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173878
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P399, DOI 10.1109/TVCG.2015.2467911
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Tufte E. R, 1985, J. Healthcare Qual., V7, P1
   van den Elzen S, 2013, COMPUT GRAPH FORUM, V32, P191, DOI 10.1111/cgf.12106
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   von Engelhardt J, 2002, Lists of Illustrations, Maps, Charts, and Diagrams
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [DOI 10.1145/345513.345271, 10/cqq2cj]
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wilkinson L., 2012, Handbook of Computational Statistics, P375, DOI [10.1007/978-3-642-21551-3_13, DOI 10.1007/978-3-642-21551-3_13]
   Wu Aoyu, 2023, IEEE Trans Vis Comput Graph, V29, P1026, DOI 10.1109/TVCG.2022.3209360
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Wu YC, 2014, IEEE T VIS COMPUT GR, V20, P1763, DOI 10.1109/TVCG.2014.2346920
   Wu YC, 2010, IEEE T VIS COMPUT GR, V16, P1109, DOI 10.1109/TVCG.2010.183
   Xia JZ, 2018, IEEE T VIS COMPUT GR, V24, P236, DOI 10.1109/TVCG.2017.2744098
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Yuan XR, 2009, IEEE T VIS COMPUT GR, V15, P1001, DOI 10.1109/TVCG.2009.179
   Yue XW, 2019, IEEE T VIS COMPUT GR, V25, P162, DOI 10.1109/TVCG.2018.2864814
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zhong ZS, 2020, IEEE CONF VIS ANAL, P95, DOI 10.1109/VAST50239.2020.00014
NR 108
TC 3
Z9 3
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5406
EP 5421
DI 10.1109/TVCG.2022.3213565
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300041
PM 36219659
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cao, CX
   An, ZL
   Ren, Z
   Manocha, D
   Zhou, K
AF Cao, Chunxiao
   An, Zili
   Ren, Zhong
   Manocha, Dinesh
   Zhou, Kun
TI A Psychoacoustic Quality Criterion for Path-Traced Sound Propagation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Signal to noise ratio; Psychoacoustic models; Solid modeling;
   Mathematical models; Band-pass filters; Spectral analysis; Resonant
   frequency; Psychoacoustics; sound simulation; path tracing; virtual
   reality
ID AUDITORY FILTER SHAPES; LOUDNESS; COMPLEX; BANDS
AB In developing virtual acoustic environments, it is important to understand the relationship between the computation cost and the perceptual significance of the resultant numerical error. In this article, we propose a quality criterion that evaluates the error significance of path-tracing-based sound propagation simulators. We present an analytical formula that estimates the error signal power spectrum. With this spectrum estimation, we can use a modified Zwicker's loudness model to calculate the relative loudness of the error signal masked by the ideal output. Our experimental results show that the proposed criterion can explain the human perception of simulation error in a variety of cases.
C1 [Cao, Chunxiao; An, Zili; Ren, Zhong; Zhou, Kun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Manocha, Dinesh] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
C3 Zhejiang University; University System of Maryland; University of
   Maryland College Park
RP Ren, Z (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM ccx4graphics@gmail.com; 22021151@zju.edu.cn; renzhong@cad.zju.edu.cn;
   dmanocha@umd.edu; kunzhou@acm.org
RI zhou, kun/KRP-1631-2024; Cao, Chunxiao/GRY-1846-2022
OI Cao, Chunxiao/0000-0002-6292-0975; Manocha, Dinesh/0000-0001-7047-9801
FU NSFC [61732016, 61772458]
FX The work of Chunxiao Cao, Zili An, Zhong Ren, and Kun Zhou was supported
   by the NSFC under Grants 61732016 and 61772458.
CR [Anonymous], 2017, Acoustics-Methods for calculating loudness-Part 1: Zwicker method, P58
   [Anonymous], 1949, Time Series
   BLAUERT J, 1986, J ACOUST SOC AM, V80, P533, DOI 10.1121/1.394048
   Bracewell, 1986, FOURIER TRANSFORM IT, P267
   Cao CX, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982431
   Chandak A, 2008, IEEE T VIS COMPUT GR, V14, P1707, DOI 10.1109/TVCG.2008.111
   Cirio G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982400
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   HOUTGAST T, 1977, J ACOUST SOC AM, V62, P409, DOI 10.1121/1.381541
   KEMP DT, 1978, J ACOUST SOC AM, V64, P1386, DOI 10.1121/1.382104
   King AJ, 2020, CURR OPIN PHYSIOL, V18, P63, DOI 10.1016/j.cophys.2020.09.001
   Larsson P, 2002, VIRTUAL, SYNTHETIC, AND ENTERTAINMENT AUDIO, P31
   Lauterbach C, 2007, IEEE T VIS COMPUT GR, V13, P1672, DOI 10.1109/TVCG.2007.70567
   Li DZY, 2015, ACM T GRAPHIC, V35, DOI 10.1145/2820612
   Liu SG, 2021, Arxiv, DOI arXiv:2011.05538
   Mehra R, 2015, IEEE T VIS COMPUT GR, V21, P434, DOI 10.1109/TVCG.2015.2391858
   Moore BCJ, 1996, ACUSTICA, V82, P335
   MOORE BCJ, 1990, J ACOUST SOC AM, V88, P132, DOI 10.1121/1.399960
   MOORE BCJ, 1985, J ACOUST SOC AM, V77, P1505, DOI 10.1121/1.392045
   Moss W, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805965
   Oxenham AJ, 1998, J ACOUST SOC AM, V104, P3500, DOI 10.1121/1.423933
   Rindel J. H., 1995, Acoustics Australia, V23, P81
   ROSNER B, 1983, TECHNOMETRICS, V25, P165, DOI 10.2307/1268549
   Rungta A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI [10.1109/VR.2019.8797914, 10.1109/vr.2019.8797914]
   Rungta A, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2947508
   Schissler C, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2943779
   Schissler C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601216
   Schuitman J. V. D., 2008, J. Audio Eng. Soc., V3, P1
   STEVENS SS, 1987, AM J PSYCHOL, V100, P664, DOI 10.2307/1422700
   STEVENS SS, 1967, PERCEPT PSYCHOPHYS, V2, P459, DOI 10.3758/BF03208795
   Trammell L., 2007, Improved pink noise generator algorithm
   Yeh HC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508420
   Zahorik P, 2005, ACTA ACUST UNITED AC, V91, P409
   Zhou HY, 2021, GRAPH MODELS, V116, DOI 10.1016/j.gmod.2021.101109
   ZWICKER E, 1957, J ACOUST SOC AM, V29, P548, DOI 10.1121/1.1908963
   ZWICKER E, 1980, J ACOUST SOC AM, V68, P1523, DOI 10.1121/1.385079
   ZWICKER E, 1965, PSYCHOL REV, V72, P3, DOI 10.1037/h0021703
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
   Zwicker E., 2013, Psychoacoustics: Facts and Models
NR 39
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5422
EP 5433
DI 10.1109/TVCG.2022.3213514
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300042
PM 36219658
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wurster, SW
   Guo, HQ
   Shen, HW
   Peterka, T
   Xu, JY
AF Wurster, Skylar W.
   Guo, Hanqi
   Shen, Han-Wei
   Peterka, Tom
   Xu, Jiayi
TI Deep Hierarchical Super Resolution for Scientific Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial resolution; Rendering (computer graphics); Octrees; Data models;
   Computational modeling; Interpolation; Isosurfaces; Deep learning;
   super-resolution; hierarchical data
ID ADAPTIVE MESH REFINEMENT; SUPERRESOLUTION; VISUALIZATION; FRAMEWORK;
   EFFICIENT
AB We present a novel technique for hierarchical super resolution (SR) with neural networks (NNs), which upscales volumetric data represented with an octree data structure to a high-resolution uniform gridwith minimal seam artifacts on octree node boundaries. Our method uses existing state-of-the-art SR models and adds flexibility to upscale input data with varying levels of detail across the domain, instead of only uniform grid data that are supported in previous approaches.The key is to use a hierarchy of SR NNs, each trained to perform 2x SR between two levels of detail, with a hierarchical SR algorithm that minimizes seam artifacts by starting from the coarsest level of detail and working up.We show that our hierarchical approach outperforms baseline interpolation and hierarchical upscaling methods, and demonstrate the usefulness of our proposed approach across three use cases including data reduction using hierarchical downsampling+SR instead of uniform downsampling+SR, computation savings for hierarchical finite-time Lyapunov exponent field calculation, and super-resolving low-resolution simulation results for a high-resolution approximation visualization.
C1 [Wurster, Skylar W.; Guo, Hanqi; Shen, Han-Wei; Xu, Jiayi] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43201 USA.
   [Peterka, Tom] Argonne Natl Lab, Math & Comp Sci Div, Argonne, IL 60439 USA.
C3 University System of Ohio; Ohio State University; United States
   Department of Energy (DOE); Argonne National Laboratory
RP Wurster, SW (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43201 USA.
EM wurster.18@osu.edu; guo.2154@osu.edu; shen.94@osu.edu;
   tpeterka@mcs.anl.gov; xu.2205@buckeyemail.osu.edu
RI Guo, Hanqi/AAL-1929-2021; Shen, Han-wei/A-4710-2012; Guo,
   Hanqi/ADW-4234-2022
OI Wurster, Skylar/0000-0001-6685-615X; Shen, Han-Wei/0000-0002-1211-2320;
   Xu, Jiayi/0000-0002-9091-6412; Guo, Hanqi/0000-0001-7776-1834
FU US Department of Energy SciDAC program [DE-SC0021360]; National Science
   Foundation Division of Information and Intelligent Systems
   [IIS-1955764]; National Science Foundation Office of Advanced
   Cyberinfrastructure [OAC-2112606]; Advanced Scientific Computing
   Research, Office of Science, U.S. Department of Energy
   [DE-AC02-06CH11357]; U.S. Department of Energy (DOE) [DE-SC0021360]
   Funding Source: U.S. Department of Energy (DOE)
FX This work was supported in part by the US Department of Energy SciDAC
   program under Grant DE-SC0021360, in part by the National Science
   Foundation Division of Information and Intelligent Systems under Grant
   IIS-1955764, in part by the National Science Foundation Office of
   Advanced Cyberinfrastructure under Grant OAC-2112606, and in part by the
   Advanced Scientific Computing Research, Office of Science, U.S.
   Department of Energy, under Grant DE-AC02-06CH11357, program manager
   Margaret Lentz.
CR Adams M., 2015, Lawrence Berkeley National Laboratory Technical Report LBNL-6616E
   Ainsworth M, 2018, COMPUT VIS SCI, V19, P65, DOI 10.1007/s00791-018-00303-9
   Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Barakat S, 2012, IEEE T VIS COMPUT GR, V18, P1368, DOI 10.1109/TVCG.2012.33
   BERGER MJ, 1989, J COMPUT PHYS, V82, P64, DOI 10.1016/0021-9991(89)90035-1
   BERGER MJ, 1984, J COMPUT PHYS, V53, P484, DOI 10.1016/0021-9991(84)90073-1
   Bhatia H, 2022, Arxiv, DOI arXiv:2007.15219
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Fogal Thomas, 2013, Proc IEEE Symp Large Scale Data Anal Vis, V2013, P43, DOI 10.1109/LDAV.2013.6675157
   Fukami K, 2021, J FLUID MECH, V909, DOI 10.1017/jfm.2020.948
   Fukami K, 2019, J FLUID MECH, V870, P106, DOI 10.1017/jfm.2019.238
   Gobbetti E, 2008, VISUAL COMPUT, V24, P797, DOI 10.1007/s00371-008-0261-9
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hoang D, 2021, IEEE T VIS COMPUT GR, V27, P603, DOI 10.1109/TVCG.2020.3030381
   Höhlein K, 2020, METEOROL APPL, V27, DOI 10.1002/met.1961
   Jakob J, 2021, IEEE T VIS COMPUT GR, V27, P1279, DOI 10.1109/TVCG.2020.3028947
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kiris C. C., 2014, P 52 AER SCI M, P1
   Knoll A., 2006, SURVEY OCTREE VOLUME
   Knoll A, 2006, RT 06: IEEE SYMPOSIUM ON INTERACTIVE RAY TRACING 2006, PROCEEDINGS, P115
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Y, 2008, J TURBUL, V9, P1, DOI 10.1080/14685240802376389
   Liang X, 2022, IEEE T COMPUT, V71, P1522, DOI 10.1109/TC.2021.3092201
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu BQ, 2013, IEEE T VIS COMPUT GR, V19, P1732, DOI 10.1109/TVCG.2012.151
   Liu JY, 2021, IEEE INT C CL COMP, P294, DOI 10.1109/Cluster48925.2021.00034
   Ljung P., 2006, P EUR IEEE VGTC S VI, P259
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   MEAGHER D, 1982, COMPUT VISION GRAPH, V19, P129, DOI 10.1016/0146-664X(82)90104-6
   O'Shea BW, 2005, LECT NOTES COMP SCI, V41, P341
   Popinet S, 2003, J COMPUT PHYS, V190, P572, DOI 10.1016/S0021-9991(03)00298-5
   Popinet S., 2004, ClusterWorld, V2, P1
   Raissi M, 2017, Arxiv, DOI arXiv:1711.10561
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Sadlo F, 2007, IEEE T VIS COMPUT GR, V13, P1456, DOI 10.1109/TVCG.2007.70554
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K., 2021, P C COMP VIS PATT RE, P1
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Velasco F., 2001, P VIS MOD VIS C, P151
   Wald I, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139305
   Wang F, 2019, IEEE T VIS COMPUT GR, V25, P1142, DOI 10.1109/TVCG.2018.2864850
   Wang H, 2019, IEEE ACCESS, V7, P177734, DOI 10.1109/ACCESS.2019.2958030
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   WILHELMS J, 1992, ACM T GRAPHIC, V11, P201, DOI 10.1145/130881.130882
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Zhang W., 2019, JOSS, V4, P1370, DOI DOI 10.21105/JOSS.01370
   Zhou ZL, 2017, CGI'17: PROCEEDINGS OF THE COMPUTER GRAPHICS INTERNATIONAL CONFERENCE, DOI 10.1145/3095140.3095178
NR 64
TC 6
Z9 7
U1 3
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5483
EP 5495
DI 10.1109/TVCG.2022.3214420
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300046
PM 36251892
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, YY
   Long, CJ
   Zhang, ZX
   Liu, BK
   Zhang, Q
   Yin, BC
   Yang, X
AF Liu, Yuanyuan
   Long, Chengjiang
   Zhang, Zhaoxuan
   Liu, Bokai
   Zhang, Qiang
   Yin, Baocai
   Yang, Xin
TI Explore Contextual Information for 3D Scene Graph Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature extraction; Three-dimensional displays; Task analysis;
   Visualization; Skeleton; Cognition; Message passing; Context
   exploration; graph skeleton; scene graph generation; scene understanding
ID NETWORK
AB 3D scene graph generation (SGG) has been of high interest in computer vision. Although the accuracy of 3D SGG on coarse classification and single relation label has been gradually improved, the performance of existing works is still far from being perfect for fine-grained and multi-label situations. In this article, we propose a framework fully exploring contextual information for the 3D SGG task, which attempts to satisfy the requirements of fine-grained entity class, multiple relation labels, and high accuracy simultaneously. Our proposed approach is composed of a Graph Feature Extraction module and a Graph Contextual Reasoning module, achieving appropriate information-redundancy feature extraction, structured organization, and hierarchical inferring. Our approach achieves superior or competitive performance over previous methods on the 3DSSG dataset, especially on the relationship prediction sub-task.
C1 [Liu, Yuanyuan; Zhang, Zhaoxuan; Liu, Bokai; Yang, Xin] Dalian Univ Technol, Dept Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
   [Long, Chengjiang] Meta Real Labs, Burlingame, CA 94010 USA.
   [Zhang, Qiang; Yin, Baocai] Dalian Univ Technol, Dept Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
   [Zhang, Qiang] Dalian Univ, Minist Educ, Key Lab Adv Design & Intelligent Comp, Dalian 116622, Peoples R China.
   [Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Inst Artificial Intelligence, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University; Beijing University of Technology
RP Yang, X (corresponding author), Dalian Univ Technol, Dept Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
EM Liuyy990415@gmail.com; clong1@meta.com; zhangzx@mail.dlut.edu.cn;
   liubokai2021@mail.dlut.edu.cn; zhangq@dlut.edu.cn; ybc@dlut.edu.cn;
   xinyang@dlut.edu.cn
RI Zhang, Qiang/IWU-5000-2023
OI , Liu/0000-0002-7326-9655; Zhang, Qiang/0000-0003-3776-9799; Zhang,
   Zhaoxuan/0000-0002-9366-859X
FU National Key Research and Development Program of China [2022ZD0210500,
   2021ZD0112400, 2018AAA0102003]; National Natural Science Foundation of
   China [61972067, U21A20491, U1908214]; Innovation Technology Funding of
   Dalian [2020JJ26GX036]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grants 2022ZD0210500, 2021ZD0112400,
   and 2018AAA0102003, in part by the National Natural Science Foundation
   of China under Grant 61972067/U21A20491/U1908214, and in part by the
   Innovation Technology Funding of Dalian unde Grant 2020JJ26GX036.
CR Armeni I, 2019, IEEE I CONF COMP VIS, P5663, DOI 10.1109/ICCV.2019.00576
   Cai SF, 2021, PROC CVPR IEEE, P6653, DOI 10.1109/CVPR46437.2021.00659
   Chen L, 2019, IEEE I CONF COMP VIS, P4612, DOI 10.1109/ICCV.2019.00471
   Chen TS, 2019, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2019.00632
   Chiou MJ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1581, DOI 10.1145/3474085.3475297
   Cho KYHY, 2014, Arxiv, DOI arXiv:1406.1078
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai B, 2017, PROC CVPR IEEE, P3298, DOI 10.1109/CVPR.2017.352
   Dhamo H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16332, DOI 10.1109/ICCV48922.2021.01604
   Dhingra N, 2021, IEEE COMPUT SOC CONF, P2150, DOI 10.1109/CVPRW53098.2021.00244
   Dieckmann A, 2007, MEM COGNITION, V35, P1801, DOI 10.3758/BF03193511
   Eigen D, 2014, ADV NEUR IN, V27
   Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207
   Guo YY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3090, DOI 10.1145/3394171.3414025
   Han XG, 2019, PROC CVPR IEEE, P234, DOI 10.1109/CVPR.2019.00032
   Herzig R, 2018, ADV NEUR IN, V31
   Hu RZ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766914
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Wang TJJ, 2020, Arxiv, DOI arXiv:2008.07832
   Khandelwal S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15859, DOI 10.1109/ICCV48922.2021.01558
   Kim UH, 2020, IEEE T CYBERNETICS, V50, P4921, DOI 10.1109/TCYB.2019.2931042
   Li RJ, 2021, PROC CVPR IEEE, P11104, DOI 10.1109/CVPR46437.2021.01096
   Li YK, 2018, LECT NOTES COMPUT SC, V11205, P346, DOI 10.1007/978-3-030-01246-5_21
   Li YK, 2017, IEEE I CONF COMP VIS, P1270, DOI 10.1109/ICCV.2017.142
   Li YJ, 2017, Arxiv, DOI arXiv:1511.05493
   Li YS, 2022, IEEE T VIS COMPUT GR, V28, P3499, DOI 10.1109/TVCG.2021.3069195
   Lin X, 2020, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR42600.2020.00380
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu XQ, 2018, IEEE T VIS COMPUT GR, V24, P2315, DOI 10.1109/TVCG.2017.2725948
   Lu YC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15911, DOI 10.1109/ICCV48922.2021.01563
   Lv YL, 2020, Arxiv, DOI arXiv:2005.02153
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, 10.48550/arXiv.1609.02907]
   Newell A, 2018, Arxiv, DOI arXiv:1706.07365
   Qi MS, 2019, PROC CVPR IEEE, P3952, DOI 10.1109/CVPR.2019.00408
   Ren GH, 2021, IEEE T NEUR NET LEAR, V32, P909, DOI 10.1109/TNNLS.2020.2979270
   Sarafyazd M, 2019, SCIENCE, V364, P652, DOI 10.1126/science.aav8911
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sharifzadeh S, 2021, AAAI CONF ARTIF INTE, V35, P5025
   Shu ZY, 2019, IEEE T VIS COMPUT GR, V25, P2583, DOI 10.1109/TVCG.2018.2848628
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Suhail M, 2021, PROC CVPR IEEE, P13931, DOI 10.1109/CVPR46437.2021.01372
   Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678
   Teng Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13668, DOI 10.1109/ICCV48922.2021.01343
   Wald J, 2020, PROC CVPR IEEE, P3960, DOI 10.1109/CVPR42600.2020.00402
   Wald J, 2019, IEEE I CONF COMP VIS, P7657, DOI 10.1109/ICCV.2019.00775
   Wang WB, 2019, PROC CVPR IEEE, P8180, DOI 10.1109/CVPR.2019.00838
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wenbin Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P222, DOI 10.1007/978-3-030-58601-0_14
   Woo S, 2018, Arxiv, DOI arXiv:1811.06410
   Wu SC, 2021, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR46437.2021.00743
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yang GC, 2021, PROC CVPR IEEE, P12522, DOI 10.1109/CVPR46437.2021.01234
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang X, 2018, Arxiv, DOI arXiv:1805.03081
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao Y., 2021, arXiv
   Yin GJ, 2018, LECT NOTES COMPUT SC, V11207, P330, DOI 10.1007/978-3-030-01219-9_20
   Yuren Cong, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P636, DOI 10.1007/978-3-030-58565-5_38
   Zareian Alireza, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P642, DOI 10.1007/978-3-030-58592-1_38
   Zareian Alireza, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P606, DOI 10.1007/978-3-030-58592-1_36
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhan YB, 2019, PROC CVPR IEEE, P5123, DOI 10.1109/CVPR.2019.00527
   Zhang CY, 2021, PROC CVPR IEEE, P9700, DOI 10.1109/CVPR46437.2021.00958
   Zhang J, 2019, PROC CVPR IEEE, P11527, DOI 10.1109/CVPR.2019.01180
   Zhang S, 2021, ADV NEUR IN, V34
   Zhang WX, 2023, IEEE T VIS COMPUT GR, V29, P4229, DOI 10.1109/TVCG.2022.3185247
   Zhou Y, 2019, IEEE I CONF COMP VIS, P7383, DOI 10.1109/ICCV.2019.00748
NR 68
TC 6
Z9 6
U1 10
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5556
EP 5568
DI 10.1109/TVCG.2022.3219451
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1U2
UT WOS:001130270300051
PM 36367917
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, JH
   Li, Y
   Zhou, ZY
   Wang, CS
   Hou, YJ
   Zhang, L
   Xue, XY
   Kamp, M
   Zhang, XL
   Chen, SM
AF Wang, Junhong
   Li, Yun
   Zhou, Zhaoyu
   Wang, Chengshun
   Hou, Yijie
   Zhang, Li
   Xue, Xiangyang
   Kamp, Michael
   Zhang, Xiaolong (Luke)
   Chen, Siming
TI When, Where and How Does it Fail? A Spatial-Temporal Visual Analytics
   Approach for Interpretable Object Detection in Autonomous Driving
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Autonomous driving; spatial-temporal visual analytics; interpretability
ID VISUALIZATION; AWARE; SEGMENTATION; DESIGN; TIME
AB Arguably the most representative application of artificial intelligence, autonomous driving systems usually rely on computer vision techniques to detect the situations of the external environment. Object detection underpins the ability of scene understanding in such systems. However, existing object detection algorithms often behave as a black box, so when a model fails, no information is available on When, Where and How the failure happened. In this paper, we propose a visual analytics approach to help model developers interpret the model failures. The system includes the micro- and macro-interpreting modules to address the interpretability problem of object detection in autonomous driving. The micro-interpreting module extracts and visualizes the features of a convolutional neural network (CNN) algorithm with density maps, while the macro-interpreting module provides spatial-temporal information of an autonomous driving vehicle and its environment. With the situation awareness of the spatial, temporal and neural network information, our system facilitates the understanding of the results of object detection algorithms, and helps the model developers better understand, tune and develop the models. We use real-world autonomous driving data to perform case studies by involving domain experts in computer vision and autonomous driving to evaluate our system. The results from our interviews with them show the effectiveness of our approach.
C1 [Wang, Junhong; Li, Yun; Zhou, Zhaoyu; Wang, Chengshun; Hou, Yijie; Zhang, Li; Xue, Xiangyang; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
   [Kamp, Michael] Ruhr Univ Bochum, Inst Med IKIM, UK Essen, D-44801 Bochum, Germany.
   [Kamp, Michael] Monash Univ, Fac IT, Dept Data Sci & AI, Clayton, Vic 3800, Australia.
   [Zhang, Xiaolong (Luke)] Penn State Univ, State Coll, PA 16801 USA.
C3 Fudan University; Ruhr University Bochum; Monash University;
   Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200437, Peoples R China.
EM junhongwang@fudan.edu.cn; yunli@fudan.edu.cn; zhaoyuzhou@fudan.edu.cn;
   chengshunwang@fudan.edu.cn; yijiehou@fudan.edu.cn;
   lizhangfd@fudan.edu.cn; xyxue@fudan.edu.cn; michael.kamp@uk-essen.de;
   lzhang@ist.psu.edu; simingchen@fudan.edu.cn
RI Wang, Pengcheng/JYQ-2527-2024; Wang, Junhong/AAO-6392-2021; ZHANG,
   XIAOLONG/IZQ-4553-2023; Kamp, Michael/ACC-1261-2022; Chen,
   Siming/AAK-1874-2020
OI Wang, Junhong/0000-0002-5889-5842; , Hui/0000-0003-0601-3905; Li,
   Yun/0000-0001-6760-3699; Xue, Xiangyang/0000-0002-4897-9209
FU Shanghai Municipal Science and Technology Major Project [2018SHZDZX01,
   2021SHZDZX0103]; General Program [21ZR1403300, 21YF1402900]; ZJLab;
   Sailing Program
FX This work was supported in part by Shanghai Municipal Science and
   Technology Major Project under Grants 2018SHZDZX01 and 2021SHZDZX0103,in
   part by General Program under Grants 21ZR1403300 and 21YF1402900,in part
   by ZJLab, and in part by Sailing Program under Grant 21YF1402900.
CR Abadi M., 2015, Tensorflow: Large-scale machine learning on heterogeneous distributed systems, DOI DOI 10.48550/ARXIV.1603.04467
   Achberger A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399862
   Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   [Anonymous], 2001, about us
   Avs, About us
   Bojarski M., 2016, arXiv
   Butkiewicz T, 2008, IEEE T VIS COMPUT GR, V14, P1165, DOI 10.1109/TVCG.2008.149
   Chang R, 2007, IEEE T VIS COMPUT GR, V13, P1169, DOI 10.1109/TVCG.2007.70574
   Chen L., 2005, P ACM SIGMOD INT C M, P491, DOI [10.1145/1066157.1066213, DOI 10.1145/1066157.1066213]
   Chen SM, 2018, J VISUAL LANG COMPUT, V48, P187, DOI 10.1016/j.jvlc.2018.06.007
   Everingham M., 2012, PASCAL VISUAL OBJECT
   Everingham M., 2005, P MACHINE LEARNING C, P117
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120
   Guo DS, 2009, IEEE T VIS COMPUT GR, V15, P1041, DOI 10.1109/TVCG.2009.143
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hou YJ, 2022, IEEE T VIS COMPUT GR, V28, P1030, DOI 10.1109/TVCG.2021.3114777
   Jamonnak S, 2022, IEEE T VIS COMPUT GR, V28, P1019, DOI 10.1109/TVCG.2021.3114853
   Jeung H, 2008, PROC VLDB ENDOW, V1, P1068
   Kim J, 2017, IEEE I CONF COMP VIS, P2961, DOI 10.1109/ICCV.2017.320
   Kisilevich S, 2010, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, SECOND EDITION, P855, DOI 10.1007/978-0-387-09823-4_44
   Lee J.-G., 2007, P 2007 ACM SIGMOD IN, P593
   Liu LY, 2019, J VISUAL-JAPAN, V22, P141, DOI 10.1007/s12650-018-0517-z
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mori K., 2019, IEEE INT VEH SYM, P1577, DOI DOI 10.1109/ivs.2019.8813900
   Ng MY, 2020, IEEE COMPUT SOC CONF, P4306, DOI 10.1109/CVPRW50498.2020.00508
   Ngo CW, 2003, IEEE T IMAGE PROCESS, V12, P341, DOI 10.1109/TIP.2003.809020
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   PEUQUET DJ, 1994, ANN ASSOC AM GEOGR, V84, P441, DOI 10.1111/j.1467-8306.1994.tb01869.x
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, 10.48550/arXiv.1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Sorger J., 2015, VISION MODELING VISU, P57, DOI DOI 10.2312/VMV.20151258
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Van SomerenM.W., 1994, The think aloud method: A practical guide to modeling cognitive processes
   Verbeek K, 2011, IEEE T VIS COMPUT GR, V17, P2536, DOI 10.1109/TVCG.2011.202
   Wang L, 2021, PROC CVPR IEEE, P454, DOI 10.1109/CVPR46437.2021.00052
   Worldview, ABOUT US
   Yurtsever E, 2020, IEEE ACCESS, V8, P58443, DOI 10.1109/ACCESS.2020.2983149
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng WY, 2019, PROC CVPR IEEE, P8652, DOI 10.1109/CVPR.2019.00886
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 54
TC 11
Z9 11
U1 6
U2 23
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD DEC
PY 2023
VL 29
IS 12
BP 5033
EP 5049
DI 10.1109/TVCG.2022.3201101
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z0MQ7
UT WOS:001109115200001
PM 36040948
DA 2024-11-06
ER

PT J
AU Munzner, T
   Stasko, J
   van Wijk, JJ
AF Munzner, Tamara
   Stasko, John
   van Wijk, Jarke J.
TI Preface
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Munzner, Tamara] Univ British Columbia, Vancouver, BC, Canada.
   [Stasko, John] Georgia Inst Technol, Atlanta, GA USA.
   [van Wijk, Jarke J.] Eindhoven Univ Technol, Eindhoven, Netherlands.
C3 University of British Columbia; University System of Georgia; Georgia
   Institute of Technology; Eindhoven University of Technology
RP Munzner, T (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
RI Munzner, Tamara/HKP-2536-2023
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XVII
EP XXVI
DI 10.1109/TVCG.2023.3325958
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500008
DA 2024-11-06
ER

PT J
AU Oral, E
   Chawla, R
   Wijkstra, M
   Mahyar, N
   Dimara, E
AF Oral, Emre
   Chawla, Ria
   Wijkstra, Michel
   Mahyar, Narges
   Dimara, Evanthia
TI From Information to Choice: A Critical Inquiry Into Visualization Tools
   for Decision Making
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision making; visualization; state of the art; review; survey;
   design; interaction; multi-criteria decision making; MCDM
ID VISUAL ANALYSIS; MCDM METHODS; UNCERTAINTY; COMMUNICATION; STRATEGIES;
   SUPPORT; DESIGN; MODELS
AB In the face of complex decisions, people often engage in a three-stage process that spans from (1) exploring and analyzing pertinent information (intelligence); (2) generating and exploring alternative options (design); and ultimately culminating in (3) selecting the optimal decision by evaluating discerning criteria (choice). We can fairly assume that all good visualizations aid in the "intelligence" stage by enabling data exploration and analysis. Yet, to what degree and how do visualization systems currently support the other decision making stages, namely "design" and "choice"? To further explore this question, we conducted a comprehensive review of decision-focused visualization tools by examining publications in major visualization journals and conferences, including VIS, EuroVis, and CHI, spanning all available years. We employed a deductive coding method and in-depth analysis to assess whether and how visualization tools support design and choice. Specifically, we examined each visualization tool by (i) its degree of visibility for displaying decision alternatives, criteria, and preferences, and (ii) its degree of flexibility for offering means to manipulate the decision alternatives, criteria, and preferences with interactions such as adding, modifying, changing mapping, and filtering. Our review highlights the opportunities and challenges that decision-focused visualization tools face in realizing their full potential to support all stages of the decision making process. It reveals a surprising scarcity of tools that support all stages, and while most tools excel in offering visibility for decision criteria and alternatives, the degree of flexibility to manipulate these elements is often limited, and the lack of tools that accommodate decision preferences and their elicitation is notable. Based on our findings, to better support the choice stage, future research could explore enhancing flexibility levels and variety, exploring novel visualization paradigms, increasing algorithmic support, and ensuring that this automation is user-controlled via the enhanced flexibility I evels. Our curated list of the 88 surveyed visualization tools is available in the OSF link (https://osf.io/nrasz/?view_only=b92a90a34ae241449b5f2cd33383bfcb).
C1 [Oral, Emre; Wijkstra, Michel; Dimara, Evanthia] Univ Utrecht, Utrecht, Netherlands.
   [Chawla, Ria] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
C3 Utrecht University; University of Massachusetts System; University of
   Massachusetts Amherst
RP Oral, E (corresponding author), Univ Utrecht, Utrecht, Netherlands.
EM e.oral@uu.nl; rchawla@umass.edu; m.wijkstra@uu.nl; nmahyar@cs.umass.edu;
   evanthia.dimara@gmail.com
OI Dimara, Evanthia/0000-0001-5212-7888
CR Afzal S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P191, DOI 10.1109/VAST.2011.6102457
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Alves T, 2023, COMPUT GRAPH-UK, V111, P47, DOI 10.1016/j.cag.2023.01.010
   Andrienko G, 2007, IEEE S VIS ANAL, P43, DOI 10.1109/VAST.2007.4388995
   Asahi T., 1995, P CHI, p405, DOI [DOI 10.1145/223355.223747, 10.1145/223355.223747]
   Aseniero BA, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1479, DOI 10.1145/2702123.2702426
   Azuma R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P433, DOI 10.1109/VISUAL.1999.809923
   Bajracharya S, 2018, INT J INF TECH DECIS, V17, P1839, DOI 10.1142/S0219622018500384
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Baumer EPS, 2022, COMPUT GRAPH FORUM, V41, P1, DOI 10.1111/cgf.14518
   Bautista J., 2006, Proceedings of the working conference on Advanced visual interfaces, P217
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Brans JP, 2005, INT SER OPER RES MAN, V78, P163, DOI 10.1007/b100605
   Brehmer M, 2022, IEEE T VIS COMPUT GR, V28, P1139, DOI 10.1109/TVCG.2021.3114760
   Cao AQ, 2023, IEEE T VIS COMPUT GR, V29, P5178, DOI 10.1109/TVCG.2022.3207147
   Carenini G., 2004, P WORK C ADV VIS INT, P150
   Castro SC, 2022, IEEE T VIS COMPUT GR, V28, P411, DOI 10.1109/TVCG.2021.3114803
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chermack T.J., 2011, SCENARIO PLANNING OR
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dhurkari RK, 2022, RAIRO-OPER RES, V56, P2221, DOI 10.1051/ro/2022060
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dimara E, 2019, IEEE T VIS COMPUT GR, V25, P850, DOI 10.1109/TVCG.2018.2865233
   Dimara E, 2018, IEEE T VIS COMPUT GR, V24, P749, DOI 10.1109/TVCG.2017.2745138
   Dy B, 2022, IEEE T VIS COMPUT GR, V28, P3405, DOI 10.1109/TVCG.2021.3065126
   Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Fleiss J. L., 2013, STAT METHODS RATES P, DOI [10.1002/0471445428, DOI 10.1002/0471445428]
   Gettinger J, 2013, DECIS SUPPORT SYST, V54, P976, DOI 10.1016/j.dss.2012.10.023
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Greening LA, 2004, ENERG POLICY, V32, P721, DOI 10.1016/j.enpol.2003.08.017
   Guo SN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300803, 10.1109/peds44367.2019.8998889]
   Ham C, 2009, J INTEGR CARE, V17, P3, DOI 10.1108/14769018200900040
   Han Y., 2022, PROC TREX, P16, DOI [10.1109/TREX57753.2022.00007, DOI 10.1109/TREX57753.2022.00007]
   Handler A, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3524025
   Hindalong Emily, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512896
   Huron S., 2021, ALTVIS WORKSHOP
   Jansen Y, 2013, IEEE T VIS COMPUT GR, V19, P2396, DOI 10.1109/TVCG.2013.134
   Jasim M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517649
   Jasim M, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P846, DOI 10.1145/3461778.3462132
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kandogan E, 2014, IEEE COMPUT GRAPH, V34, P42, DOI 10.1109/MCG.2014.62
   Keefe DF, 2010, IEEE COMPUT GRAPH, V30, P8, DOI 10.1109/MCG.2010.30
   KEENEY RL, 1982, OPER RES, V30, P803, DOI 10.1287/opre.30.5.803
   Keeney RL, 1993, DECISIONS MULTIPLE O
   Klein G, 2008, HUM FACTORS, V50, P456, DOI 10.1518/001872008X288385
   Kosara R, 2023, IEEE COMPUT GRAPH, V43, P91, DOI 10.1109/MCG.2022.3222024
   Kreiser J, 2018, IEEE T VIS COMPUT GR, V24, P873, DOI 10.1109/TVCG.2017.2744299
   Le Goc M, 2019, IEEE T VIS COMPUT GR, V25, P737, DOI 10.1109/TVCG.2018.2865159
   Lim NJ, 2016, INT J GEOGR INF SCI, V30, P240, DOI 10.1080/13658816.2015.1085539
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   MacQueen KM., 1998, CAM J, V10, P31, DOI [10.1177/1525822X980100020301, DOI 10.1177/1525822X980100020301]
   Mahyar N, 2020, IEEE COMPUT GRAPH, V40, P76, DOI 10.1109/MCG.2020.3017405
   Mahyar N, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1171, DOI 10.1145/3322276.3322354
   Mahyar N, 2017, CSCW'17: COMPANION OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P17, DOI 10.1145/3022198.3023269
   Marriott K, 2011, IEEE T VIS COMPUT GR, V17, P290, DOI 10.1109/TVCG.2010.45
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   Muller J., 2021, PROC EUROVISEUROGRAP, DOI [10.2312/evm.20211075, DOI 10.2312/EVM.20211075]
   Nielsen J., 2020, 10 Usability Heuristics for User Interface Design
   Norman D., 2013, The Design of Everyday Things: Revised and Expanded Edition
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Park S, 2022, INFORM HEALTH SOC CA, V47, P175, DOI 10.1080/17538157.2021.1982949
   PAYNE JW, 1988, J EXP PSYCHOL LEARN, V14, P534, DOI 10.1037/0278-7393.14.3.534
   Payne JW., 2008, Blackwell Handbook of Judgment and Decision Making, P110, DOI DOI 10.1002/9780470752937.CH6
   Pu P., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P289, DOI 10.1145/332040.332446
   Reyna VF, 2011, DEV REV, V31, P180, DOI 10.1016/j.dr.2011.07.004
   Ribicic H, 2012, IEEE T VIS COMPUT GR, V18, P2255, DOI 10.1109/TVCG.2012.261
   Rudolph Stephen, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P195, DOI 10.1109/VAST.2009.5333920
   RUSSO JE, 1983, J EXP PSYCHOL LEARN, V9, P676, DOI 10.1037/0278-7393.9.4.676
   Savikhin A., 2011, S2011 44 HAWAII INT, P1, DOI [10.1109/HICSS.2011.54, DOI 10.1109/HICSS.2011.54]
   Siirtola H., 2014, PROC BCS HCI, P240, DOI [10.14236/ewic/hci2014.30, DOI 10.14236/EWIC/HCI2014.30]
   Simon HA, 1960, NEW SCI MANAGEMENT D, DOI [DOI 10.1037/13978-000, 10.1037/13978-0002, DOI 10.1037/13978-0002]
   Sorger J, 2016, IEEE T VIS COMPUT GR, V22, P290, DOI 10.1109/TVCG.2015.2468011
   Spence R, 1998, INTERACT COMPUT, V11, P137, DOI 10.1016/S0953-5438(98)00022-8
   Sperrle F, 2021, COMPUT GRAPH FORUM, V40, P543, DOI 10.1111/cgf.14329
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Talukder AKMKA, 2020, IEEE COMPUT INTELL M, V15, P36, DOI 10.1109/MCI.2020.2976184
   Tian ZL, 2021, INFORMATION, V12, DOI 10.3390/info12060239
   Tory M, 2023, IEEE COMPUT GRAPH, V43, P22, DOI 10.1109/MCG.2021.3136545
   Tovanich N, 2021, IEEE T VIS COMPUT GR, V27, P3135, DOI 10.1109/TVCG.2019.2963018
   van Pelt R, 2014, COMPUT GRAPH FORUM, V33, P131, DOI 10.1111/cgf.12369
   Velasquez M., 2013, INT J OPERATIONS RES, V10, P56
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang Ruijie, 2023, Computers in Human Behavior, DOI 10.1016/j.chb.2022.107545
   Waser J, 2014, COMPUT GRAPH FORUM, V33, P281, DOI 10.1111/cgf.12384
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   Weistroffer H.R., 2016, MULTIPLE CRITERIA DE, P1301, DOI [10.1007/978-1-4939-3094-4_29, DOI 10.1007/978-1-4939-3094-4_29]
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wittenburg K., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P51, DOI 10.1145/502348.502357
   Xia HJ, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186471
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zavadskas EK, 2011, TECHNOL ECON DEV ECO, V17, P397, DOI 10.3846/20294913.2011.593291
   Zhang YF, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2211, DOI 10.1145/2702123.2702239
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
   Zhao Y, 2019, IEEE T VIS COMPUT GR, V25, P12, DOI 10.1109/TVCG.2018.2865020
   Ziegler H., 2007, EUROVIS 2007, P19, DOI DOI 10.2312/VISSYM/EUROVIS07/019-026
NR 106
TC 3
Z9 3
U1 6
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 359
EP 369
DI 10.1109/TVCG.2023.3326593
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500056
PM 37871054
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cui, Y
   Ge, LW
   Ding, YR
   Yang, FM
   Harrison, L
   Kay, M
AF Cui, Yuan
   Ge, Lily W.
   Ding, Yiren
   Yang, Fumeng
   Harrison, Lane
   Kay, Matthew
TI Adaptive Assessment of Visualization Literacy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization literacy; computerized adaptive testing; item response
   theory
ID TEST-RETEST RELIABILITY
AB Visualization literacy is an essential skill for accurately interpreting data to inform critical decisions. Consequently, it is vital to understand the evolution of this ability and devise targeted interventions to enhance it, requiring concise and repeatable assessments of visualization literacy for individuals. However, current assessments, such as the Visualization Literacy Assessment Test (vlat), are time-consuming due to their fixed, lengthy format. To address this limitation, we develop two streamlined computerized adaptive tests (cats) for visualization literacy, a-vlat and a-calvi, which measure the same set of skills as their original versions in half the number of questions. Specifically, we (1) employ item response theory (IRT) and non-psychometric constraints to construct adaptive versions of the assessments, (2) finalize the configurations of adaptation through simulation, (3) refine the composition of test items of a-calvi via a qualitative study, and (4) demonstrate the test-retest reliability (ICC: 0.98 and 0.98) and convergent validity (correlation: 0.81 and 0.66) of both CATS via four online studies. We discuss practical recommendations for using our CATS and opportunities for further customization to leverage the full potential of adaptive assessments. All supplemental materials are available at https://osf.io/a6258/.
C1 [Cui, Yuan; Ge, Lily W.; Yang, Fumeng; Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
   [Ding, Yiren; Harrison, Lane] Worcester Polytech Inst, Worcester, MA USA.
C3 Northwestern University; Worcester Polytechnic Institute
RP Cui, Y (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM charlescui@u.northwestern.edu; wanqian.ge@northwestern.edu;
   yding5@wpi.edu; fy@northwestern.edu; ltharrison@wpi.edu;
   mjskay@northwestern.edu
RI Kay, Matthew/AAN-2490-2021; Yang, Fumeng/HME-2828-2023
OI Kay, Matthew/0000-0001-9446-0419; Harrison, Lane/0000-0003-3029-2799;
   Ding, Yiren/0000-0001-8983-9117; Cui, Yuan/0000-0002-2681-6441; Ge,
   Lily/0000-0003-2350-8686
FU National Science Foundation
FX No Statement Available
CR Aoyama K., 2003, Mathematics Education Research Journal, V15, P207, DOI 10.1007/BF032173802
   Baker F. B., 2001, BASICS ITEM RESPONSE
   Beiser D, 2016, PSYCHIAT SERV, V67, P1039, DOI 10.1176/appi.ps.201500304
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Carlson KD, 2012, ORGAN RES METHODS, V15, P17, DOI 10.1177/1094428110392383
   Chin C.-L., 2014, Encyclopedia of Quality of Life and Well-Being Research, P1275, DOI [DOI 10.1007/978-94-007-0753-5573, 10.1007/978-94-007-0753-5_573, DOI 10.1007/978-94-007-0753-5_573]
   Cicchetti D.V., 1994, Psychol. Assess., V6, P284, DOI [10.1037/1040-3590.6.4.284, DOI 10.1037/1040-3590.6.4.284]
   Cohen RJ., 2022, Psychological Testing and Assessment, V10th
   CollegeBoard, 2022, Transitioning to a digital SAT
   DelMas R., 2005, 4 FOR STAT REAS THIN, P2
   ETS, 2023, GRE general test structure
   Foorman B., 2016, Regional Educational Laboratory Southeast (REL 2016-149), P2
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Ghio F. B., 2022, European Journal of Science and Mathematics Education, V10, P352, DOI [10.30935/scimath/119682, DOI 10.30935/SCIMATH/119682]
   Gibbons C, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.6053
   Gibbons RD, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1053-9
   Gibbons RD, 2014, AM J PSYCHIAT, V171, P187, DOI 10.1176/appi.ajp.2013.13020178
   GREEN BF, 1984, J EDUC MEAS, V21, P347, DOI 10.1111/j.1745-3984.1984.tb01039.x
   Guinart D, 2021, SCHIZOPHRENIA BULL, V47, P644, DOI 10.1093/schbul/sbaa168
   Kandula S, 2011, BMC MED INFORM DECIS, V11, DOI 10.1186/1472-6947-11-52
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Liljequist D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219854
   Matheson GJ, 2019, PEERJ, V7, DOI 10.7717/peerj.6918
   Peterman K, 2015, INT J SCI EDUC, V37, P2787, DOI 10.1080/09500693.2015.1105399
   Polit DF, 2014, QUAL LIFE RES, V23, P1713, DOI 10.1007/s11136-014-0632-9
   Rezaie M., 2015, International Journal of Educational Investigations, V2, P128
   Rudner LM, 2010, STAT SOC BEHAV SC, P151, DOI 10.1007/978-0-387-85461-8_8
   Segall D. O., 2005, Encyclopedia of social measurement, V1, P4
   Thompson N. A., 2011, Practical Assessment, Research, and Evaluation, V16, DOI [10.7275/wqzt-94271,2, DOI 10.7275/WQZT-94271,2]
   Wainer H., 2000, Computerized Adaptive Testing: A Primer, V2nd, DOI [10.4324/97814106059314, DOI 10.4324/97814106059314]
   Walter OB, 2007, QUAL LIFE RES, V16, P143, DOI 10.1007/s11136-007-9191-7
   Wilms R, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00825
NR 33
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 628
EP 637
DI 10.1109/TVCG.2023.3327165
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500038
PM 37878447
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lan, XY
   Wu, YQ
   Cao, N
AF Lan, Xingyu
   Wu, Yanqiu
   Cao, Nan
TI Affective Visualization Design: Leveraging the Emotional Impact of Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Information Visualization; Affective Design; Visual Communication; User
   Experience; Storytelling
ID STORIES
AB In recent years, more and more researchers have reflected on the undervaluation of emotion in data visualization and highlighted the importance of considering human emotion in visualization design. Meanwhile, an increasing number of studies have been conducted to explore emotion-related factors. However, so far, this research area is still in its early stages and faces a set of challenges, such as the unclear definition of key concepts, the insufficient justification of why emotion is important in visualization design, and the lack of characterization of the design space of affective visualization design. To address these challenges, first, we conducted a literature review and identified three research lines that examined both emotion and data visualization. We clarified the differences between these research lines and kept 109 papers that studied or discussed how data visualization communicates and influences emotion. Then, we coded the 109 papers in terms of how they justified the legitimacy of considering emotion in visualization design (i.e., why emotion is important) and identified five argumentative perspectives. Based on these papers, we also identified 61 projects that practiced affective visualization design. We coded these design projects in three dimensions, including design fields (where), design tasks (what), and design methods (how), to explore the design space of affective visualization design.
C1 [Lan, Xingyu] Fudan Univ, Shanghai, Peoples R China.
   [Lan, Xingyu] Res Grp Computat & AI Commun Inst Global Commun &, Shanghai, Peoples R China.
   [Wu, Yanqiu; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
C3 Fudan University; Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
EM xingyulan96@gmail.com; wuyanqiu.idvx@gmail.com; nan.cao@gmail.com
RI Cao, Nan/O-5397-2014; Lan, Xingyu/KYO-9537-2024
OI Cao, Nan/0000-0003-1316-7515; Lan, Xingyu/0000-0001-7331-2433
FU NSFC
FX No Statement Available
CR affaireclimat, US
   Aitken S., 2011, The Map Reader: Theories of Mapping Practice and Cartographic Representation, V4, P278
   Ajani K., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Alamalhodaei A., 2020, Data Visualization in Society, P5
   Anderson CL, 2022, IEEE T VIS COMPUT GR, V28, P2867, DOI 10.1109/TVCG.2021.3050118
   Aragón C, 2021, C&C'21: PROCEEDINGS OF THE 13TH CONFERENCE ON CREATIVITY AND COGNITION, DOI 10.1145/3450741.3465259
   Aseniero BA, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P105, DOI 10.1109/VISAP57411.2022.00021
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Beale R, 2008, LECT NOTES COMPUT SC, V4868, P1, DOI 10.1007/978-3-540-85099-1_1
   Bloom P., 2014, Against empathy
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Braun V., 2012, Thematic analysis, V3
   Campbell S., 2018, Feeling numbers: the rhetoric of pathos in visualization, V4, P5
   Carpendale S., 2017, Information Design Journal, V23, P3
   Cartwright W., 2008, Geospatial Vision, P4
   Chen Q., 2022, P CHI C HUMAN FACTOR, P1
   Chen Q., 2023, IEEE Transactions on Visualization and Computer Graphics, V9
   Claes S, 2017, LEONARDO, V50, P90, DOI 10.1162/LEON_a_01224
   Concannon S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376462
   Craine J., 2011, Rethinking Maps, P4
   Cummins P., 2014, Blood Swept Lands and Seas of Red
   DIgnazio C, 2020, STRONG IDEAS SERIES, P1
   Dragga S, 2001, TECH COMMUN, V48, P265
   Elli T, 2020, 2020 IEEE VIS ARTS PROGRAM (VISAP 2020), P29, DOI 10.1109/VISAP51628.2020.00010
   FloydMueller F., 2021, P CHI C HUMAN FACTOR, P1
   Gardener J., 2017, P INT CARTOGRAPHIC A, P1
   GILMARTIN P, 1991, CARTOGR J, V28, P145
   Gough P, 2014, IEEE PAC VIS SYMP, P335, DOI 10.1109/PacificVis.2014.39
   Harrison L., 2013, P CHI C HUMAN FACTOR, P2
   ieeevis, Area model for vis
   images.webofknowledge, Web of science research areas
   InfoDesignLab, 2012, The water we eat
   Iturrioz T., 2011, Mapping Different Geographies, P3
   Ivanov A, 2019, IEEE COMPUT GRAPH, V39, P19, DOI 10.1109/MCG.2019.2898941
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   Jorgenson L., 1995, IEEE VISUALIZATION C, P2
   Kauer T., 2021, P CHI C HUMAN FACTOR, P1
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kent A., 2013, Cartographic Perspectives, V73, P9
   Kosara R, 2007, IEEE INT CONF INF VI, P631
   Kostelnick C, 2016, TECH COMMUN-STC, V63, P116
   Kuznetsov S, 2011, UBICOMP'11: PROCEEDINGS OF THE 2011 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P237
   Lan X., 2022, arXiv
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Le Bon G., 1897, The crowd: A study of the popular mind, P9
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Lewis M., 2010, Handbook of emotions, P1
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Lupi G., 2016, Chronicle books, V6, P7
   Lupi Giorgia., 2017, DATA HUMANISM REVOLU
   Lupi Giorgia, 2015, Dear Data
   McCleary G., 2003, P INT CARTOGRAPHIC C, P5
   Morais L, 2022, COMPUT GRAPH FORUM, V41, P441, DOI 10.1111/cgf.14553
   Morais L., 2021, P CHI C HUMAN FACTOR, P1
   Muehlenhaus I, 2012, CARTOGR J, V49, P361, DOI 10.1179/1743277412Y.0000000032
   Nietzsche F., 2022, DigiCat, P1
   Norman D.A., 2004, EMOTIONAL DESIGN WHY
   Padilla L., 2022, IEEE transactions on visualization and computer graphics, V29, P2
   Periscopic, Revealing the overwhelming magnitude of loss from U.S. gun deaths
   Periscopic, 2013, U.S. gun deaths
   Perovich LJ, 2021, IEEE T VIS COMPUT GR, V27, P913, DOI 10.1109/TVCG.2020.3030472
   Picard R. W., 2000, Affective computing, V1, P2
   Pinilla A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.630731
   PolicyViz, 2016, Episode #31: Rees & Mushon on DataViz empathy
   Porter T. M., 1996, Trust in Numbers, P2
   Qin CY, 2020, 2020 IEEE VIS ARTS PROGRAM (VISAP 2020), P1, DOI 10.1109/VISAP51628.2020.00007
   Rebelo SM, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P70, DOI 10.1109/VISAP57411.2022.00017
   Romat H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376348
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Samsel F, 2021, 2021 IEEE VIS ARTS PROGRAM (VISAP 2021), P20, DOI 10.1109/VISAP52981.2021.00009
   Scarr S., 2011, Iraq's bloody toll
   Segal A., 2015, Grewingk glacier
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi Y., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P972
   Shi Y., 2021, P CHI C HUMAN FACTOR, P1
   Thoresen JC, 2016, NEUROBIOL LEARN MEM, V132, P1, DOI 10.1016/j.nlm.2016.04.008
   Tiles J., 2014, Interview: Paul cummins - blood swept lands & seas of red
   Tufte E. R., 2001, The visual display of quantitative information, P2
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   van Koningsbruggen Rosa, 2021, CREATIVITY COGNITION, DOI DOI 10.1145/3450741.3465257
   van Lammeren R, 2010, COMPUT ENVIRON URBAN, V34, P465, DOI 10.1016/j.compenvurbsys.2010.07.001
   Viégas FB, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P105, DOI 10.1109/INFVIS.2004.8
   Viégas FB, 2009, IEEE T VIS COMPUT GR, V15, P1137, DOI 10.1109/TVCG.2009.171
   Walter A., 2011, A Book Apart, P2
   Wang X., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Xie L., 2023, IEEE Transactions on Visualization and Computer Graphics, P9
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yu B, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P333, DOI 10.1145/3064663.3064729
   Zeller S, 2022, 2022 IEEE VIS ARTS PROGRAM (VISAP 2022), P127, DOI 10.1109/VISAP57411.2022.00025
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
NR 96
TC 7
Z9 7
U1 31
U2 45
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1
EP 11
DI 10.1109/TVCG.2023.3327385
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500048
PM 37903043
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Piochowiak, M
   Dachsbacher, C
AF Piochowiak, Max
   Dachsbacher, Carsten
TI Fast Compressed Segmentation Volumes for Scientific Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Segmentation volumes; lossless compression; volume rendering
ID OF-THE-ART; EXPLORATION; BRAIN
AB Voxel-based segmentation volumes often store a large number of labels and voxels, and the resulting amount of data can make storage, transfer, and interactive visualization difficult. We present a lossless compression technique which addresses these challenges. It processes individual small bricks of a segmentation volume and compactly encodes the labelled regions and their boundaries by an iterative refinement scheme. The result for each brick is a list of labels, and a sequence of operations to reconstruct the brick which is further compressed using rANS-entropy coding. As the relative frequencies of operations are very similar across bricks, the entropy coding can use global frequency tables for an entire data set which enables efficient and effective parallel (de)compression. Our technique achieves high throughput (up to gigabytes per second both for compression and decompression) and strong compression ratios of about 1% to 3% of the original data set size while being applicable to GPU-based rendering. We evaluate our method for various data sets from different fields and demonstrate GPU-based volume visualization with on-the-fly decompression, level-of-detail rendering (with optional on-demand streaming of detail coefficients to the GPU), and a caching strategy for decompressed bricks for further performance improvement.
C1 [Piochowiak, Max; Dachsbacher, Carsten] Karlsruhe Inst Technol, Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Piochowiak, M (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM max.piochowiak@kit.edu; dachsbacher@kit.edu
OI Piochowiak, Max/0000-0003-1980-6146
FU Helmholtz Association (HGF)
FX No Statement Available
CR Agus M, 2022, IEEE VIS CONF, P130, DOI 10.1109/VIS54862.2022.00035
   Ai-Thelaya K, 2021, IEEE T VIS COMPUT GR, V27, P645, DOI 10.1109/TVCG.2020.3030451
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Anagnostou K., 2000, P 2000 S VOLUME VISU, P129, DOI [10.1145/353888.353909, DOI 10.1145/353888.353909]
   Berger DR, 2018, FRONT NEURAL CIRCUIT, V12, DOI 10.3389/fncir.2018.00088
   Berghoff M, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03728-7
   Beyer J, 2022, COMPUT GRAPH FORUM, V41, P573, DOI 10.1111/cgf.14574
   Beyer J, 2019, IEEE T VIS COMPUT GR, V25, P1132, DOI 10.1109/TVCG.2018.2864847
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Beyer J, 2013, IEEE COMPUT GRAPH, V33, P50, DOI 10.1109/MCG.2013.55
   Careil V, 2020, COMPUT GRAPH FORUM, V39, P111, DOI 10.1111/cgf.13916
   Choi J, 2021, IEEE ACCESS, V9, P78755, DOI 10.1109/ACCESS.2021.3084066
   Dado B, 2016, COMPUT GRAPH FORUM, V35, P397, DOI 10.1111/cgf.12841
   Dolonius D, 2019, IEEE T VIS COMPUT GR, V25, P1270, DOI 10.1109/TVCG.2017.2741480
   Duda J, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P65, DOI 10.1109/PCS.2015.7170048
   Ernst M., 2004, PROC INT MESHING ROU, P6
   Fowler J. E., 1994, PROC IEEE S VOLUME V, P43, DOI DOI 10.1145/197938.197961
   Google Inc, Neuroglancer
   Guthe S., 2016, 3DTV C TRUE VISION C, P1, DOI [10.1109/3DTV.2016.75488922, DOI 10.1109/3DTV.2016.75488922]
   Hadwiger M, 2018, IEEE T VIS COMPUT GR, V24, P974, DOI 10.1109/TVCG.2017.2744238
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Hussain AJ, 2018, NEUROCOMPUTING, V300, P44, DOI 10.1016/j.neucom.2018.02.094
   Ihm I, 1999, COMPUT GRAPH FORUM, V18, P3, DOI 10.1111/1467-8659.00298
   Jönsson D, 2014, COMPUT GRAPH FORUM, V33, P27, DOI 10.1111/cgf.12252
   Kämpe V, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462024
   Kobbelt LP, 2001, COMP GRAPH, P57, DOI 10.1145/383259.383265
   Laine Samuli, 2010, P 2010 ACM SIGGRAPH, P55, DOI [DOI 10.1145/1730804.1730814, 10.1145/1730804.1730814]
   Lempitsky V, 2010, PROC CVPR IEEE, P1197, DOI 10.1109/CVPR.2010.5539832
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Mado3 B., 2021, IEEE WORLD S APPL MA, DOI [10.1109/SAMI50585.2021.93786752, DOI 10.1109/SAMI50585.2021.93786752]
   Mados B., 2020, 2020 18th International Conference on Emerging eLearning Technologies and Applications (ICETA), P424, DOI 10.1109/ICETA51985.2020.9379265
   Mados B, 2019, IEEE INT CONF INTELL, P75, DOI [10.1109/INES46365.2019.9109528, 10.1109/ines46365.2019.9109528]
   Matejek Brian, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10433, P781, DOI 10.1007/978-3-319-66182-7_89
   Maurer J, 2022, NONDESTRUCT TEST EVA, V37, P582, DOI 10.1080/10589759.2022.2075865
   Motta A, 2019, SCIENCE, V366, P1093, DOI 10.1126/science.aay3134
   Mueller JH, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275087
   Museth Ken, 2021, ACM SIGGRAPH 2021 TA, DOI DOI 10.1145/3450623.3464653
   Newman TS, 2006, COMPUT GRAPH-UK, V30, P854, DOI 10.1016/j.cag.2006.07.021
   Rahman MA, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101274
   RHODES ML, 1985, IEEE T MED IMAGING, V4, P84, DOI 10.1109/TMI.1985.4307701
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Rosenbauer J., 2020, bioRxiv, DOI [10.1101/2020.08.24.264150, DOI 10.1101/2020.08.24.264150]
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Villanueva AJ, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P7, DOI 10.1145/2856400.2856420
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Weissenberger A, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225076
   Weissenböck J, 2014, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2014.52
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
NR 50
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 12
EP 22
DI 10.1109/TVCG.2023.3326573
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500073
PM 37871064
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shen, HW
AF Shen, Han-Wei
TI Message from the Editor-in-Chief
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
AB Welcome to the January 2024 issue of the IEEE Transactions on Visualization and Computer Graphics ($TVCG$). This is my first IEEE Vis special issue as Editor-in-Chief, and I am verry excited to introduce it to you all. As in the previous two years, the papers submitted to IEEE VIS were categorized into six major research subareas: Theoretical & Empirical (123 papers), Applications (123), Systems & Rendering (57), Representations & Interaction (86), Data Transformations (68) and Analytics & Decisions (82). The conference took place in the vibrant city of Melbourne, Australia during October 22-27, 2023. Included in this special issue are the top 133 papers selected by the Program Committee from a total of 539 submissions.
C1 [Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Shen, HW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012
NR 0
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XIV
EP XIV
DI 10.1109/TVCG.2023.3326046
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500126
DA 2024-11-06
ER

PT J
AU Dwyer, T
   Goodwin, S
   Wybrow, M
AF Dwyer, Tim
   Goodwin, Sarah
   Wybrow, Michael
TI Welcome
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
AB We are thrilled this year to welcome the IEEE VIS conference for its first ever visit to Australia. It is, for that matter, the first time for this conference to come to the Southern Hemisphere, as well as its first time in an Asian time zone. We acknowledge Traditional Owners of Narrm, the Boon Wurrung and Wurundjeri Woi Wurrung people of the Kulin nation, on whose land VIS 2023 will be held. We pay our respects to their Elders past, present and emerging. We know Melbourne (Narrm) is a long way from Europe and the US, as we've been doing the reverse trip ourselves for many years. But we are grateful to all from those regions who are able to join us, and we are delighted to welcome many new participants from the Asia-Pacific region who are now able to attend in-person for the first time. This sojourn down-under marks a significant milestone for IEEE VIS towards becoming a truly global conference.
C1 [Dwyer, Tim; Goodwin, Sarah; Wybrow, Michael] Monash Univ, Clayton, Vic, Australia.
C3 Monash University
RP Dwyer, T (corresponding author), Monash Univ, Clayton, Vic, Australia.
EM tim.dwyer@monash.edu
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XV
EP XVI
DI 10.1109/TVCG.2023.3326051
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500045
DA 2024-11-06
ER

PT J
AU Yang, FM
   Cai, MD
   Mortenson, C
   Fakhari, H
   Lokmanoglu, AD
   Hullman, J
   Franconeri, S
   Diakopoulos, N
   Nisbet, EC
   Kay, M
AF Yang, Fumeng
   Cai, Mandi
   Mortenson, Chloe
   Fakhari, Hoda
   Lokmanoglu, Ayse D.
   Hullman, Jessica
   Franconeri, Steven
   Diakopoulos, Nicholas
   Nisbet, Erik C.
   Kay, Matthew
TI Swaying the Public? Impacts of Election Forecast Visualizations on
   Emotion, Trust, and Intention in the 2022 US Midterms
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; Probabilistic forecasts; Elections; Emotions;
   Trust; Political participation; Longitudinal study
ID VOTER TURNOUT; UNCERTAINTY; OPINION; POLLS
AB We conducted a longitudinal study during the 2022 U.S. midterm elections, investigating the real-world impacts of uncertainty visualizations. Using our forecast model of the governor elections in 33 states, we created a website and deployed four uncertainty visualizations for the election forecasts: single quantile dotplot (1-Dotplot), dual quantile dotplots (2-Dotplot), dual histogram intervals (2-Interval), and Plinko quantile dotplot (Plinko), an animated design with a physical and probabilistic analogy. Our online experiment ran from Oct. 18, 2022, to Nov. 23, 2022, involving 1,327 participants from 15 states. We use Bayesian multilevel modeling and post-stratification to produce demographically-representative estimates of people's emotions, trust in forecasts, and political participation intention. We find that election forecast visualizations can heighten emotions, increase trust, and slightly affect people's intentions to participate in elections. 2-Interval shows the strongest effects across all measures; 1-Dotplot increases trust the most after elections. Both visualizations create emotional and trust gaps between different partisan identities, especially when a Republican candidate is predicted to win. Our qualitative analysis uncovers the complex political and social contexts of election forecast visualizations, showcasing that visualizations may provoke polarization. This intriguing interplay between visualization types, partisanship, and trust exemplifies the fundamental challenge of disentangling visualization from its context, underscoring a need for deeper investigation into the real-world impacts of visualizations. Our preprint and supplements are available at https://doi.org/osf.io/ajq8f.
C1 [Yang, Fumeng; Cai, Mandi; Mortenson, Chloe; Fakhari, Hoda; Lokmanoglu, Ayse D.; Hullman, Jessica; Franconeri, Steven; Diakopoulos, Nicholas; Nisbet, Erik C.; Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Yang, FM (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM fy@northwestern.edu; mandicai2028@u.northwestern.edu;
   chloemortenson2026@u.northwestern.edu; hoda@u.northwestern.edu;
   ayse.lokmanoglu@northwestern.edu; jhullman@northwestern.edu;
   franconeri@northwestern.edu; nad@northwestern.edu;
   erik.nisbet@northwestern.edu; mjskay@northwestern.edu
RI Fakhari, Hoda/KZU-5810-2024; Kay, Matthew/AAN-2490-2021; Yang,
   Fumeng/HME-2828-2023; Hullman, Jessica/P-7130-2018
OI Franconeri, Steven/0000-0001-5244-9764; Hullman,
   Jessica/0000-0001-6826-3550; Fakhari, Hoda/0009-0003-0323-0880
FU NSF
FX No Statement Available
CR Agranov M, 2018, J EUR ECON ASSOC, V16, P825, DOI 10.1093/jeea/jvx023
   Anderson CJ, 2002, BRIT J POLIT SCI, V32, P335, DOI 10.1017/S0007123402000133
   [Anonymous], Party Affiliation
   ANSOLABEHERE S, 1994, POLIT COMMUN, V11, P413, DOI 10.1080/10584609.1994.9963048
   Barnfield M, 2020, POLIT STUD REV, V18, P553, DOI 10.1177/1478929919870691
   Blais A., 2000, University of Pittsburgh Pre, V2, P8
   Blankenship BT, 2019, POLIT GROUPS IDENTIT, V7, P724, DOI 10.1080/21565503.2019.1633932
   Boudreau C, 2010, J POLIT, V72, P513, DOI 10.1017/S0022381609990946
   Brown J. D., 2011, Statistics, V15, P6
   Cancela J, 2016, ELECT STUD, V42, P264, DOI 10.1016/j.electstud.2016.03.005
   Christmann A, 2006, J MULTIVARIATE ANAL, V97, P1660, DOI 10.1016/j.jmva.2005.05.012
   Christofoletti M, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18147477
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cosmides L, 1996, COGNITION, V58, P1, DOI 10.1016/0010-0277(95)00664-8
   de Visser EJ, 2020, INT J SOC ROBOT, V12, P459, DOI 10.1007/s12369-019-00596-x
   Diakopoulos N., 2022, Predictive journalism: On the role of computational prospection in news media, P2
   Duffy J, 2008, AM J POLIT SCI, V52, P603, DOI 10.1111/j.1540-5907.2008.00332.x
   economist, Forecasting the U.S. elections
   economistgroup, The Economist's German election model forecasts three possible governing coalitions
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Finn C, 2010, ANAL SOC ISS PUB POL, V10, P262, DOI 10.1111/j.1530-2415.2010.01206.x
   fivethirtyeight, How good are FiveThirtyEight forecasts?
   fivethirtyeight, Latest polls
   fivethirtyeight, 2020 Election Forecast
   fivethirtyeight, 2022 Election Forecast
   FREEMAN J, 1986, POLIT SCI QUART, V101, P327, DOI 10.2307/2151619
   Galton F., 1889
   Gelman A., 2016, Using multilevel regression and poststratification to estimate dynamic public opinion, V2, P6
   Gelman A., 2020, Judgment and Decision Making, V15, DOI [10.1017/S19302975000079812,9, DOI 10.1017/S19302975000079812,9]
   Gerber A, 2020, AM ECON J-APPL ECON, V12, P287, DOI 10.1257/app.20180574
   Gerber AS, 2008, AM POLIT SCI REV, V102, P33, DOI 10.1017/S000305540808009X
   google, Attacking discrimination with smarter machine learning
   Groenendyk EW, 2014, POLIT PSYCHOL, V35, P359, DOI 10.1111/pops.12045
   Gu YY, 2020, NEURAL PLAST, V2020, DOI 10.1155/2020/8866386
   Han PKJ, 2012, PATIENT EDUC COUNS, V86, P106, DOI 10.1016/j.pec.2011.01.033
   Harpe SE, 2015, CURR PHARM TEACH LEA, V7, P836, DOI 10.1016/j.cptl.2015.08.001
   Hart PS, 2011, SCI COMMUN, V33, P28, DOI 10.1177/1075547010366400
   Heidemanns M., 2020, Harvard Data Science Review, V2, DOI DOI 10.1162/99608F92.FC62F1-1
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Iyengar S, 2015, AM J POLIT SCI, V59, P690, DOI 10.1111/ajps.12152
   Iyengar S, 2012, PUBLIC OPIN QUART, V76, P405, DOI 10.1093/poq/nfs038
   Iyer A, 2007, PERS SOC PSYCHOL B, V33, P572, DOI 10.1177/0146167206297402
   Jordan A, 2019, J STAT SOFTW, V90, P1, DOI 10.18637/jss.v090.i12
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kastellec J. P., 2010, Estimating state public opinion with multi-level regression and poststratification using R, P6
   Kastellec JP, 2015, J POLIT, V77, P787, DOI 10.1086/681261
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kennedy L, 2021, PSYCHOL METHODS, V26, P547, DOI 10.1037/met0000362
   Khandkar S. H., 2009, University of Calgary, V23, P8
   Koval M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502010
   Kuru O, 2017, PUBLIC OPIN QUART, V81, P422, DOI 10.1093/poq/nfx018
   Lax JR, 2009, AM POLIT SCI REV, V103, P367, DOI 10.1017/S0003055409990050
   Lee TT, 2010, AM BEHAV SCI, V54, P8, DOI 10.1177/0002764210376308
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Linzer DA, 2013, J AM STAT ASSOC, V108, P124, DOI 10.1080/01621459.2012.737735
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Madsen M., 2000, 11 AUSTR C INF SYST, V53, P6
   Madson GJ, 2020, POLIT BEHAV, V42, P1055, DOI 10.1007/s11109-019-09532-1
   Manski CF, 2020, ECON PHILOS, V36, P216, DOI 10.1017/S0266267119000105
   Marinovic I, 2013, HBK ECON, P691, DOI 10.1016/B978-0-444-62731-5.00012-9
   MCALLISTER DJ, 1995, ACAD MANAGE J, V38, P24, DOI 10.5465/256727
   McCright AM, 2013, ENVIRON RES LETT, V8, DOI 10.1088/1748-9326/8/4/044029
   Merritt SM, 2013, HUM FACTORS, V55, P520, DOI 10.1177/0018720812465081
   metaculus, Metaculus track record
   Nisbet EC, 2015, ANN AM ACAD POLIT SS, V658, P36, DOI 10.1177/0002716214555474
   Oleskog Tryggvason P., 2021, Under the influence? Understanding medias coverage of opinion polls and their effects on citizens and politicians, P2
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Padilla L, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.579207
   Patterson TE, 2005, PUBLIC OPIN QUART, V69, P716, DOI 10.1093/poq/nfi065
   pewresearch, Party affiliation by state
   priceisright, The Price is Right
   researcher-help, How do I set up a longitudinal / multi-part study?
   Rushton G., 2006, AM J PREV MED, V30, P16, DOI DOI 10.1111/j.1478-9299.2006.00034.x
   Sarma Abhraneel, 2023, IEEE Trans Vis Comput Graph, V29, P602, DOI 10.1109/TVCG.2022.3209348
   Shirani-Mehr H, 2018, J AM STAT ASSOC, V113, P607, DOI 10.1080/01621459.2018.1448823
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Valentino NA, 2011, J POLIT, V73, P156, DOI 10.1017/S0022381610000939
   Van Deth J. W., 2001, JOINT SESS WORKSH EU, P5
   Walker K., 2023, Tidycensus: Load US Census Boundary and Attribute Data as "tidyverse"and sf-Ready Data Frames
   washingtonpost, Where voter turnout exceeded 2018 highs
   washingtonpost, What you need to know about the measles outbreak
   Watson D., 1994, The PANAS-X: Manual for the positive and negative affect schedule-expanded form, P4
   Weber C, 2013, POLIT RES QUART, V66, P414, DOI 10.1177/1065912912449697
   Westwood SJ, 2020, J POLIT, V82, P1530, DOI 10.1086/708682
   Witzenberger B, 2024, INFORM COMMUN SOC, V27, P951, DOI 10.1080/1369118X.2023.2230267
   Xiong C., 2022, ACM CHI, DOI [10.1145/3491102.35018742, DOI 10.1145/3491102.35018742]
   Yang FM, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580998
   Yang FM, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P189, DOI 10.1145/3377325.3377480
   Zamo M, 2018, MATH GEOSCI, V50, P209, DOI 10.1007/s11004-017-9709-7
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
NR 92
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 23
EP 33
DI 10.1109/TVCG.2023.3327356
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500024
PM 37930916
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Stasko, J
AF Stasko, John
TI 2023 VGTC Visualization Lifetime Achievement Award
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
DE Awards
AB The 2023 VGTC Visualization Lifetime Achievement Award goes to John Stasko for his seminal contributions to the value of interaction in information and visual analytics research and to the design and evaluation of software and information visualization. Stasko is a Regents Professor in the School of Interactive Computing at the Georgia Institute of Technology (GT). He earned his Ph.D. in Computer Science from Brown University in 1989 and joined the GT faculty later that year.
C1 [Stasko, John] Georgia Inst Technol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Stasko, J (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XXVIII
EP XXVIII
DI 10.1109/TVCG.2023.3326210
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500036
OA Bronze
DA 2024-11-06
ER

PT J
AU Munzner, T
AF Munzner, Tamara
TI 2023 VGTC Visualization Service Award
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
DE Awards
AB The 2023 VGTC Visualization Service Award goes to Tamara Munzner in recognition of her passionate commitment the community for over two decades including her service on the VIS Restructuring Committee (reVISe), VIS Executive Committee (VEC), VGTC Executive Committee, and Steering Committees for InfoVis and BioVis; her leadership as co-chair for EuroVis; and her unwavering dedication to teaching visualization, both at IEEE VIS and online, to foster the growth of future visualization scientists.
C1 [Munzner, Tamara] Univ British Columbia, Vancouver, BC, Canada.
C3 University of British Columbia
RP Munzner, T (corresponding author), Univ British Columbia, Vancouver, BC, Canada.
RI Munzner, Tamara/HKP-2536-2023
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XXIX
EP XXIX
DI 10.1109/TVCG.2023.3326260
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500020
DA 2024-11-06
ER

PT J
AU Kay, M
AF Kay, Matthew
TI 2023 VGTC Visualization Significant New Researcher Award
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
DE Awards
AB The 2023 VGTC Visualization Significant New Researcher Award goes to Matthew Kay in recognition of his work on uncertainty visualization, the design of human-centered tools for data analysis, and visualization literacy.
C1 [Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Kay, M (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
RI Kay, Matthew/AAN-2490-2021
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XXX
EP XXXI
DI 10.1109/TVCG.2023.3326262
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500040
DA 2024-11-06
ER

PT J
AU Miksch, S
AF Miksch, Silvia
TI 2023 VGTC Visualization Technical Achievement Award
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
DE Awards
AB The 2023 VGTC Visualization Technical Achievement Award goes to Silvia Miksch for her outstanding technical contributions to visual analytics of time-varying data.
C1 [Miksch, Silvia] TU Wien, Vienna, Austria.
C3 Technische Universitat Wien
RP Miksch, S (corresponding author), TU Wien, Vienna, Austria.
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XXXII
EP XXXII
DI 10.1109/TVCG.2023.3326263
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500140
DA 2024-11-06
ER

PT J
AU [Anonymous]
AF [Anonymous]
TI 2023 VGTC Visualization Dissertation Award
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP XXXIII
EP XXXIII
DI 10.1109/TVCG.2023.3326261
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500046
DA 2024-11-06
ER

PT J
AU Offenwanger, A
   Brehmer, M
   Chevalier, F
   Tsandilas, T
AF Offenwanger, Anna
   Brehmer, Matthew
   Chevalier, Fanny
   Tsandilas, Theophanis
TI TimeSplines: Sketch-Based Authoring of Flexible and Idiosyncratic
   Timelines
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Temporal Data; interaction design; communication / presentation;
   storytelling; sketch-based interface; lazy data binding
ID VISUALIZATION DESIGN; TIME-SERIES; IMAGES
AB Timelines are essential for visually communicating chronological narratives and reflecting on the personal and cultural significance of historical events. Existing visualization tools tend to support conventional linear representations, but fail to capture personal idiosyncratic conceptualizations of time. In response, we built TimeSplines, a visualization authoring tool that allows people to sketch multiple free-form temporal axes and populate them with heterogeneous, time-oriented data via incremental and lazy data binding. Authors can bend, compress, and expand temporal axes to emphasize or de-emphasize intervals based on their personal importance; they can also annotate the axes with text and figurative elements to convey contextual information. The results of two user studies show how people appropriate the concepts in TimeSplines to express their own conceptualization of time, while our curated gallery of images demonstrates the expressive potential of our approach.
C1 [Offenwanger, Anna; Tsandilas, Theophanis] Univ Paris Saclay, CRNS, Inria, LISN, Paris, France.
   [Brehmer, Matthew] Tableau Res, Amherst, MA USA.
   [Chevalier, Fanny] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
   [Chevalier, Fanny] Univ Toronto, Dept Stat Sci, Toronto, ON, Canada.
C3 Universite Paris Cite; Universite Paris Saclay; Inria; University of
   Toronto; University of Toronto
RP Offenwanger, A (corresponding author), Univ Paris Saclay, CRNS, Inria, LISN, Paris, France.
EM anna.offenwanger@lisn.upsaclay.fr; mbrehmer@tableau.com;
   fanny@dgp.toronto.edu; theophanis.tsandilas@lisn.upsaclay.fr
FU CNRS
FX No Statement Available
CR Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Akbar S., 2020, P IEEE INT C SMART T, DOI [10.1109/ICoSTA48221.2020.15706140562, DOI 10.1109/ICOSTA48221.2020.15706140562]
   Amini F., 2018, Data-Driven Storytelling, P6
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Beaudouin-Lafon M., 2017, Technical report, P4
   Berends L, 2011, QUAL REP, V16
   Bigelow A, 2017, IEEE T VIS COMPUT GR, V23, P481, DOI 10.1109/TVCG.2016.2598609
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Bohoj M., 2010, P ACM CHI, DOI [10.1145/1753326.17534042, DOI 10.1145/1753326.17534042]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brath R, 2017, IEEE INT CON INF VIS, P96, DOI 10.1109/iV.2017.82
   Brehmer M., 2019, P COMP JOURN C J, P2
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brown J., 2022, The Data Visualization Society State of the Industry Survey
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Byrne L, 2019, INFORM VISUAL, V18, P45, DOI 10.1177/1473871617724212
   Carpendale S., 2017, Information Design Journal, V23, DOI [10.1075/idj.23.1.07thu2, DOI 10.1075/IDJ.23.1.07THU2]
   Chalhoub G, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501833
   Chao W. O., 2010, P INFOVIS POST
   Choe EK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1143, DOI 10.1145/2556288.2557372
   Chung J. J. Y., 2022, P ACM CHI, DOI [10.1109/TVCG.2017.2743918, DOI 10.1109/TVCG.2017.2743918]
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P468, DOI 10.1109/TVCG.2009.86
   Felice MC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174022
   Fuhrman O, 2010, COGNITIVE SCI, V34, P1430, DOI 10.1111/j.1551-6709.2010.01105.x
   Goel V, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00241
   Hammond C., 2012, House of Anansi, V2, P9
   Haroz S., 2015, IEEE TVCG, V22, DOI 0.1109/TVCG.2015.25025872,6
   Hullman J., 2013, P ACM CHI, DOI [10.1145/2470654.24813744, DOI 10.1145/2470654.24813744]
   Hurter C., 2013, P ACM UIST, DOI [10.1145/2501988.25020463,6,9, DOI 10.1145/2501988.25020463,6,9]
   Icastic Consulting, ICATIME: What does time look like?
   Keefe DF, 2008, IEEE T VIS COMPUT GR, V14, P835, DOI 10.1109/TVCG.2008.31
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Kim N. W., 2017, IEEE TVCG (Proc. InfoVis), V24, DOI [10.1109/TVCG.2017.27441182,3, DOI 10.1109/TVCG.2017.27441182,3]
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300335
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Lee B, 2015, IEEE PAC VIS SYMP, P199, DOI 10.1109/PACIFICVIS.2015.7156378
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lin H., 2023, IEEE TVCG (Proc. VIS), V29, DOI 0.1109/TVCG.2022.32094513,4,9
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lupi G., 2016, Dear Data, P3
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Moore J., 2018, Proc. ACM UbiComp, V2, DOI [10.1145/32649384, DOI 10.1145/32649384]
   Otten H, 2018, PROCEEDINGS OF THE IEEE VIS ARTS PROGRAM (VISAP) 2018
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Perin C., 2017, P IEEE VIS ARTS PROG
   Perin C., 2017, IEEE TVCG (Proc. InfoVis), V24, DOI [10.1109/TVCG.2017.27439182,4, DOI 10.1109/TVCG.2017.27439182,4]
   Ren D., 2018, P IEEE EV BELIV, DOI [10.1109/BELIV.2018.86342972,6, DOI 10.1109/BELIV.2018.86342972,6]
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Resnick M., 2005, Design Principles for Tools to Support Creative Thinking, P6
   Romat H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300272
   Rosenberg D., 2013, Cartographies of Time: A History of the Timeline, P2
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Schroeder D., 2015, IEEE transactions on visualization and computer graphics, V22, P3
   Schroeder D., 2010, Proceedings of ACM SIGGRAPH/Eurographics Sketch-Based Interfaces and Modeling, P49
   Shen E., 2014, Journal of Visualization, V17, P3
   Snyder J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300363
   Sterne L., 1805, The Life and Opinions of Tristram Shandy, Gentleman: In Four Volumes, V9, P3
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Thiry E., 2013, P ACM CHI, DOI [10.1145/2470654.24662151,2,3, DOI 10.1145/2470654.24662151,2,3]
   Thudt A., 2014, P ACM DIS PVA WORKSH
   Tolmie P, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P491, DOI 10.1145/2818048.2819992
   Tornatore C, 2011, ING AUTOMOB, P9
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   Tsandilas T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3255, DOI 10.1145/2702123.2702129
   TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9
   TVERSKY B, 1991, COGNITIVE PSYCHOL, V23, P515, DOI 10.1016/0010-0285(91)90005-9
   Twain M., 1914, Harper's Monthly Magazine, V130
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Walker J, 2016, IEEE T VIS COMPUT GR, V22, P549, DOI 10.1109/TVCG.2015.2467751
   Walny J, 2015, COMPUT GRAPH FORUM, V34, P231, DOI 10.1111/cgf.12635
   Walny J., 2011, P IEEE INT WORKSH VI, DOI 0.1109/VISSOF.2011.6069462
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
NR 79
TC 2
Z9 2
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 34
EP 44
DI 10.1109/TVCG.2023.3326520
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500093
PM 37922183
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Miftari, E
   Durstewitz, D
   Sadlo, F
AF Miftari, Egzon
   Durstewitz, Daniel
   Sadlo, Filip
TI Visualization of Discontinuous Vector Field Topology
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topology; Manifolds; Eigenvalues and eigenfunctions; Dynamical systems;
   Switches; Orbits; Behavioral sciences; Discontinuous vector field
   topology; equivalence in non-unique flow; non-smooth dynamical systems
ID ATTRACTORS; SEMIFLOWS
AB This paper extends the concept and the visualization of vector field topology to vector fields with discontinuities. We address the non-uniqueness of flow in such fields by introduction of a time-reversible concept of equivalence. This concept generalizes streamlines to streamsets and thus vector field topology to discontinuous vector fields in terms of invariant streamsets. We identify respective novel critical structures as well as their manifolds, investigate their interplay with traditional vector field topology, and detail the application and interpretation of our approach using specifically designed synthetic cases and a simulated case from physics.
C1 [Miftari, Egzon; Durstewitz, Daniel; Sadlo, Filip] Heidelberg Univ, Heidelberg, Germany.
C3 Ruprecht Karls University Heidelberg
RP Miftari, E (corresponding author), Heidelberg Univ, Heidelberg, Germany.
EM egzon.miftari@iwr.uni-heidelberg.de; daniel.durstewitz@zi-mannheim.de;
   sadlo@uni-heidelberg.de
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR Andronov A. A., 1937, Dokl. Acad. Nauk SSSR, V14, P247
   Asimov D., 1993, Technical report, P2
   Ball JM, 1997, J NONLINEAR SCI, V7, P475, DOI 10.1007/s003329900037
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Fernández-García S, 2012, SIAM J APPL DYN SYST, V11, P1215, DOI 10.1137/120869134
   Glendinning P., 2019, Advanced Courses in Mathematics - CRM Barcelona, V2, P3
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   HELMAN JL, 1991, IEEE COMPUT GRAPH, V11, P36, DOI 10.1109/38.79452
   Hofmann L, 2021, COMPUT GRAPH FORUM, V40, P111, DOI 10.1111/cgf.14293
   Hofmann L, 2020, COMPUT GRAPH FORUM, V39, P303, DOI 10.1111/cgf.13982
   Hofmann L, 2018, COMPUT GRAPH FORUM, V37, P301, DOI 10.1111/cgf.13421
   HU SC, 1991, J MATH ANAL APPL, V154, P377, DOI 10.1016/0022-247X(91)90044-Z
   Jeffrey M. R., 2015, P ICOEV LJUBLJ, P10
   Jeffrey M. R., 2018, Hidden Dynamics: The Mathematics of Switches, Decisions and Other Discontinuous Behaviour, V2, P3
   Jeffrey MR, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416500875
   Jeffrey MR, 2014, PHYSICA D, V273, P34, DOI 10.1016/j.physd.2014.02.003
   Leine R., 2000, Bifurcations in discontinuous mechanical systems of Filippovtype, P8
   Melnik VS, 1998, SET-VALUED ANAL, V6, P83, DOI 10.1023/A:1008608431399
   Otto M, 2010, COMPUT GRAPH FORUM, V29, P347, DOI 10.1111/j.1467-8659.2009.01604.x
   Scheuermann G, 1997, VISUALIZATION '97 - PROCEEDINGS, P67, DOI 10.1109/VISUAL.1997.663858
   Theisel H, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P225, DOI 10.1109/VISUAL.2003.1250376
   Thieme C, 2019, Arxiv, DOI arXiv:1905.07051
   Weinkauf T., 2004, P EUROGRAPHICS IEEE, P183
NR 23
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 45
EP 54
DI 10.1109/TVCG.2023.3326519
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500075
PM 37878439
DA 2024-11-06
ER

PT J
AU Rautek, P
   Zhang, XD
   Woschizka, B
   Theussl, T
   Hadwiger, M
AF Rautek, Peter
   Zhang, Xingdi
   Woschizka, Bernhard
   Theussl, Thomas
   Hadwiger, Markus
TI Vortex Lens: Interactive Vortex Core Line Extraction using Observed Line
   Integral Convolution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Flow visualization; vortex detection; objectivity; observers; reference
   frames; Lie algebras; visual lens metaphors
ID OF-THE-ART; VECTOR-FIELDS; FLOW PATTERNS; TOPOLOGY; VISUALIZATION;
   VORTICES; MOTIONS
AB This paper describes a novel method for detecting and visualizing vortex structures in unsteady 2D fluid flows. The method is based on an interactive local reference frame estimation that minimizes the observed time derivative of the input flow field v(x,t). A locally optimal reference frame w(x,t) assists the user in the identification of physically observable vortex structures in Observed Line Integral Convolution (LIC) visualizations. The observed LIC visualizations are interactively computed and displayed in a user-steered vortex lens region, embedded in the context of a conventional LIC visualization outside the lens. The locally optimal reference frame is then used to detect observed critical points, where v = w, which are used to seed vortex core lines. Each vortex core line is computed as a solution of the ordinary differential equation (ODE) (center dot)w(t) = w(w(t),t), with an observed critical point as initial condition (w(t(0)),t(0)). During integration, we enforce a strict error bound on the difference between the extracted core line and the integration of a path line of the input vector field, i.e., a solution to the ODE (center dot)v(t) = v(v(t),t). We experimentally verify that this error depends on the step size of the core line integration. This ensures that our method extracts Lagrangian vortex core lines that are the simultaneous solution of both ODEs with a numerical error that is controllable by the integration step size. We show the usability of our method in the context of an interactive system using a lens metaphor, and evaluate the results in comparison to state-of-the-art vortex core line extraction methods.
C1 [Rautek, Peter; Zhang, Xingdi; Hadwiger, Markus] King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal, Saudi Arabia.
   [Theussl, Thomas] King Abdullah Univ Sci & Technol KAUST, Core Labs, Thuwal 239556900, Saudi Arabia.
C3 King Abdullah University of Science & Technology; King Abdullah
   University of Science & Technology
RP Rautek, P (corresponding author), King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal, Saudi Arabia.
EM peter.rautek@kaust.edu.sa; xingdi.zhang@kaust.edu.sa; w-bernhard@gmx.at;
   thomas.theussl@kaust.edu.sa; markus.hadwiger@kaust.edu.sa
OI Rautek, Peter/0000-0003-4821-7404
FU King Abdullah University of Science and Technology (KAUST)
FX No Statement Available
CR ASTARITA G, 1979, J NON-NEWTON FLUID, V6, P69, DOI 10.1016/0377-0257(79)87004-4
   BANKS DC, 1995, IEEE T VIS COMPUT GR, V1, P151, DOI 10.1109/2945.468404
   Bauer D., 2002, Proceedings of the symposium on Data Visualisation 2002, VISSYM '02, Eurographics Association, Aire-la-Ville, Switzerland, Switzerland, P233, DOI [10.2312/VisSym/VisSym02/233-240, DOI 10.2312/VISSYM/VISSYM02/233-240]
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   Bhatia H, 2014, COMPUT GRAPH FORUM, V33, P21, DOI 10.1111/cgf.12358
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Bujack R, 2016, IEEE PAC VIS SYMP, P72, DOI 10.1109/PACIFICVIS.2016.7465253
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Drouot R., 1976, Archiwum Mechaniki Stosowanej, V28, P3
   Globus A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P33, DOI 10.1109/VISUAL.1991.175773
   Günther T, 2020, IEEE T VIS COMPUT GR, V26, P1532, DOI 10.1109/TVCG.2018.2868760
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Günther T, 2016, IEEE T VIS COMPUT GR, V22, P817, DOI 10.1109/TVCG.2015.2467200
   Hadwiger M, 2019, IEEE T VIS COMPUT GR, V25, P1257, DOI 10.1109/TVCG.2018.2864839
   Haller G, 2005, J FLUID MECH, V525, P1, DOI 10.1017/S0022112004002526
   Haller G, 2016, J FLUID MECH, V795, P136, DOI 10.1017/jfm.2016.151
   Haller G, 2021, J FLUID MECH, V908, DOI 10.1017/jfm.2020.937
   Holzapfel G.A., 2010, Nonlinear Solid Mechanics: A Continuum Approach for Engineering
   Hunt J. C. R., 1988, P SUMM PROGR 1988 CT, P3
   JEONG J, 1995, J FLUID MECH, V285, P69, DOI 10.1017/S0022112095000462
   Jobard B, 2002, IEEE T VIS COMPUT GR, V8, P211, DOI 10.1109/TVCG.2002.1021575
   Jobard Bruno., 1997, VISUALIZATION SCI CO, P43
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   Laramee RS, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P131, DOI 10.1109/VISUAL.2003.1250364
   Li G.-S., 2006, Proceedings of the Eighth Joint Eurographics / IEEE VGTC Conference on Visualization, P29, DOI [10.2312/VisSym/EuroVis06/029-034, DOI 10.2312/VISSYM/EUROVIS06/029-034]
   Lugt H. J., 1979, Recent developments in theoretical and experimental fluid mechanics. Compressible and incompressible flows, P309
   Ogden R. W., 1997, Non-Linear Elastic Deformations, P3
   OKUBO A, 1970, DEEP-SEA RES, V17, P445, DOI 10.1016/0011-7471(70)90059-8
   Parikh N., 2013, Proximal Algorithms, DOI [10.1561/24000000032,6, DOI 10.1561/24000000032,6]
   Peikert R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P263, DOI 10.1109/VISUAL.1999.809896
   PERRY AE, 1994, APPL SCI RES, V53, P357, DOI 10.1007/BF00849110
   PERRY AE, 1987, ANNU REV FLUID MECH, V19, P125, DOI 10.1146/annurev.fl.19.010187.001013
   Rautek P, 2021, IEEE T VIS COMPUT GR, V27, P283, DOI 10.1109/TVCG.2020.3030454
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Roth M, 1998, VISUALIZATION '98, PROCEEDINGS, P143, DOI 10.1109/VISUAL.1998.745296
   Sadlo F, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P179, DOI 10.1109/VISUAL.2004.128
   Sahner J., 2005, Proc. EuroVis 2005, P151, DOI DOI 10.2312/VISSYM/EUROVIS05/151-160
   Shen HW, 1997, VISUALIZATION '97 - PROCEEDINGS, P317, DOI 10.1109/VISUAL.1997.663898
   Stalling D., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P249, DOI 10.1145/218380.218448
   Sujudi D., 1995, 12th Computational Fluid Dynamics Conference, P1, DOI [DOI 10.2514/6.1995-17153, 10.2514/6.1995-1715, DOI 10.2514/6.1995-1715]
   Theisel H, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P631
   Theisel H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P141
   Theisel H, 2021, PHYS FLUIDS, V33, DOI 10.1063/5.0063817
   Tricoche X, 2002, COMPUT GRAPH-UK, V26, P249, DOI 10.1016/S0097-8493(02)00056-0
   Truesdell C., 1965, The Nonlinear Field Theories of Mechanics, DOI [10.1007/978-3-662-10388-3_11,3, DOI 10.1007/978-3-662-10388-3_11,3]
   van Wijk JJ, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P123, DOI 10.1109/VISUAL.2003.1250363
   van Wijk JJ, 2002, ACM T GRAPHIC, V21, P745, DOI 10.1145/566570.566646
   Weinkauf T, 2007, IEEE T VIS COMPUT GR, V13, P1759, DOI 10.1109/TVCG.2007.70545
   WEISS J, 1991, PHYSICA D, V48, P273, DOI 10.1016/0167-2789(91)90088-Q
   Wiebel A, 2011, MATH VIS, P193
   Xie C, 2010, VISUAL INFORMATION COMMUNICATION, P173, DOI 10.1007/978-1-4419-0312-9_11
   Zhang XD, 2022, IEEE T VIS COMPUT GR, V28, P281, DOI 10.1109/TVCG.2021.3115565
NR 53
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 55
EP 65
DI 10.1109/TVCG.2023.3326915
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500121
PM 37874718
DA 2024-11-06
ER

PT J
AU Pérez-Messina, I
   Ceneda, D
   Miksch, S
AF Perez-Messina, Ignacio
   Ceneda, Davide
   Miksch, Silvia
TI Guided Visual Analytics for Image Selection in Time and Space
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Application Motivated Visualization; Geospatial Data; Mixed Initiative
   Human-Machine Analysis; Process/Workflow Design; Task Abstractions &
   Application Domains; Temporal Data
ID INTERACTIVE OPTIMIZATION; GUIDANCE; TASKS; TYPOLOGY
AB Unexploded Ordnance (UXO) detection, the identification of remnant active bombs buried underground from archival aerial images, implies a complex workflow involving decision-making at each stage. An essential phase in UXO detection is the task of image selection, where a small subset of images must be chosen from archives to reconstruct an area of interest (AOI) and identify craters. The selected image set must comply with good spatial and temporal coverage over the AOI, particularly in the temporal vicinity of recorded aerial attacks, and do so with minimal images for resource optimization. This paper presents a guidance-enhanced visual analytics prototype to select images for UXO detection. In close collaboration with domain experts, our design process involved analyzing user tasks, eliciting expert knowledge, modeling quality metrics, and choosing appropriate guidance. We report on a user study with two real-world scenarios of image selection performed with and without guidance. Our solution was well-received and deemed highly usable. Through the lens of our task-based design and developed quality measures, we observed guidance-driven changes in user behavior and improved quality of analysis results. An expert evaluation of the study allowed us to improve our guidance-enhanced prototype further and discuss new possibilities for user-adaptive guidance.
C1 [Perez-Messina, Ignacio; Ceneda, Davide; Miksch, Silvia] TU Wien, Vienna, Austria.
C3 Technische Universitat Wien
RP Pérez-Messina, I (corresponding author), TU Wien, Vienna, Austria.
EM ignacio.messina@tuwien.ac.at; davide.ceneda@tuwien.ac.at;
   silvia.miksch@tuwien.ac.at
RI Ceneda, Davide/HTT-2753-2023
FU Vienna Science and Technology Fund (WWTF)
FX No Statement Available
CR Abuzuraiq A. M., 2020, RE ANTHROPOCENE DESI, V1, P485, DOI DOI 10.52842/CONF.CAADRIA.2020.1.4852
   Amor-Amoros A., 2017, EUROVA EUROVIS, P55, DOI [10.2312/eurova.20171120, DOI 10.2312/EUROVA.20171120]
   Bao F, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461977
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cibulski L, 2022, 2022 IEEE 4TH WORKSHOP ON VISUALIZATION GUIDELINES IN RESEARCH, DESIGN, AND EDUCATION (VISGUIDES 2022), P8, DOI 10.1109/VisGuides57787.2022.00007
   Dayama NR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376553
   de Luz Palomino Valdivia F., 2023, ADV INFORM COMMUNICA, V1, P391, DOI [10.1007/978-3-031-28076-4_29, DOI 10.1007/978-3-031-28076-4_29]
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Federico P, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P104, DOI 10.1145/2993901.2993915
   Horn B, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P277
   Ip CY, 2011, IEEE T VIS COMPUT GR, V17, P1737, DOI 10.1109/TVCG.2011.231
   Khan S, 2019, OCEAN ENG, V191, DOI 10.1016/j.oceaneng.2019.106462
   Koyama Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392444
   Liu J., 2022, ACM Transactions on Computer-Human Interaction, DOI [10.1145/35034617,9, DOI 10.1145/35034617,9]
   Liu J, 2021, IEEE T VIS COMPUT GR, V27, P1764, DOI 10.1109/TVCG.2020.3030364
   Liu J, 2018, IEEE T VIS COMPUT GR, V24, P319, DOI 10.1109/TVCG.2017.2744418
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Perez-Messina I, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14555
   Perez-Messina I., 2023, A Methodology for TaskDriven Guidance Design, DOI [10.2312/eurova.202310943,4,9, DOI 10.2312/EUROVA.202310943,4,9]
   Puchinger J, 2010, INFORMS J COMPUT, V22, P250, DOI 10.1287/ijoc.1090.0344
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schulz A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201385
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shepherd EJ, 2016, MATER CULT MOD CONFL, P205
   Sperrle F., 2018, 2018 IEEE WORKSHOP M, DOI [10.1109/MLUI52768.2018.10075559, DOI 10.1109/MLUI52768.2018.10075559]
   Sperrle F., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.48550/arXiv.2208.044342, DOI 10.48550/ARXIV.2208.044342]
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/vast47406.2019.8986917, 10.1109/VAST47406.2019.8986917]
   Umentani N, 2015, COMMUN ACM, V58, P116, DOI 10.1145/2801945
   Van der Baan S., 2019, 1 C GEOPHYS INFRASTR, P1
   Wagner M, 2017, COMPUT SECUR, V67, P1, DOI 10.1016/j.cose.2017.02.003
   Walch A, 2020, IEEE T VIS COMPUT GR, V26, P569, DOI 10.1109/TVCG.2019.2934658
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
NR 37
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 66
EP 75
DI 10.1109/TVCG.2023.3326572
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500092
PM 37922176
OA hybrid
DA 2024-11-06
ER

PT J
AU Chen, CJ
   Guo, YK
   Tian, FY
   Liu, SL
   Yang, WK
   Wang, ZW
   Wu, J
   Su, H
   Pfister, H
   Liu, SX
AF Chen, Changjian
   Guo, Yukai
   Tian, Fengyuan
   Liu, Shilong
   Yang, Weikai
   Wang, Zhaowei
   Wu, Jing
   Su, Hang
   Pfister, Hanspeter
   Liu, Shixia
TI A Unified Interactive Model Evaluation for Classification, Object
   Detection, and Instance Segmentation in Computer Vision
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Model evaluation; computer vision; classification; object detection;
   instance segmentation
AB Existing model evaluation tools mainly focus on evaluating classification models, leaving a gap in evaluating more complex models, such as object detection. In this paper, we develop an open-source visual analysis tool, Uni-Evaluator, to support a unified model evaluation for classification, object detection, and instance segmentation in computer vision. The key idea behind our method is to formulate both discrete and continuous predictions in different tasks as unified probability distributions. Based on these distributions, we develop 1) a matrix-based visualization to provide an overview of model performance; 2) a table visualization to identify the problematic data subsets where the model performs poorly; 3) a grid visualization to display the samples of interest. These visualizations work together to facilitate the model evaluation from a global overview to individual samples. Two case studies demonstrate the effectiveness of Uni-Evaluator in evaluating model performance and making informed improvements.
C1 [Chen, Changjian; Guo, Yukai; Tian, Fengyuan; Yang, Weikai; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
   [Liu, Shilong; Su, Hang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff, Wales.
   [Pfister, Hanspeter] Harvard Univ, Cambridge, MA USA.
C3 Tsinghua University; Tsinghua University; Cardiff University; Harvard
   University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
EM ccj17@mails.edu.cn; gyj22@mails.edu.cn; tianfy21@mails.edu.cn;
   slongliu86@gmail.com; yangwk21@mails.edu.cn; wzw20@mails.edu.cn;
   wuj11@cardiff.ac.uk; suhangss@tsinghua.edu.cn; pfister@seas.harvard.edu;
   shixia@tsinghua.edu.cn
RI Liu, Shilong/GVS-1257-2022; Chen, Changjian/KBA-9462-2024; Liu,
   Shi-Xia/C-5574-2016
OI Guo, Yukai/0009-0000-9651-3617; Chen, Changjian/0000-0003-2715-8839
FU National Natural Science Foundation of China
FX No Statement Available
CR Abadi M., 2015, Tensorflow: Large-scale machine learning on heterogeneous distributed systems, DOI DOI 10.48550/ARXIV.1603.04467
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Bar-Joseph Z., 2001, BIOINFORMATICS S1, V17 Suppl 1, pS22, DOI [10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Biewald L., 2020, WEIGHTS BIASES
   Bolya Daniel, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P558, DOI 10.1007/978-3-030-58580-8_33
   Borji A, 2019, Arxiv, DOI arXiv:1911.12451
   Boullé M, 2006, MACH LEARN, V65, P131, DOI 10.1007/s10994-006-8364-x
   Cao JL, 2020, PROC CVPR IEEE, P11482, DOI 10.1109/CVPR42600.2020.01150
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Fang YX, 2023, PROC CVPR IEEE, P19358, DOI 10.1109/CVPR52729.2023.01855
   Ghiasi G, 2021, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR46437.2021.00294
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Görtler J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501823
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Han JW, 2007, DATA MIN KNOWL DISC, V15, P55, DOI 10.1007/s10618-006-0059-1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Heyen F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399814
   Hinterreiter A, 2022, IEEE T VIS COMPUT GR, V28, P1222, DOI 10.1109/TVCG.2020.3012063
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoiem D, 2012, LECT NOTES COMPUT SC, V7574, P340, DOI 10.1007/978-3-642-33712-3_25
   Hou LP, 2022, AAAI CONF ARTIF INTE, P923
   Jadhav D, 2009, J RISK MODEL VALIDAT, V3, P51
   Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5
   Kervadec H, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101851
   Lei N, 2020, ENGINEERING-PRC, V6, P361, DOI 10.1016/j.eng.2019.09.010
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu Y, 2024, Arxiv, DOI [arXiv:2111.11057, 10.48550/arXiv.2111.11057]
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Murtagh F, 2012, WIRES DATA MIN KNOWL, V2, P86, DOI 10.1002/widm.53
   Nakkiran P, 2021, J STAT MECH-THEORY E, V2021, DOI 10.1088/1742-5468/ac3a74
   Pastor E, 2021, INT CONF MANAGE DATA, P1400, DOI 10.1145/3448016.3457284
   Pentico DW, 2007, EUR J OPER RES, V176, P774, DOI 10.1016/j.ejor.2005.09.014
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Rottmann Peter, 2023, IEEE Trans Vis Comput Graph, V29, P875, DOI 10.1109/TVCG.2022.3209485
   Schroeder W, 2008, J USABILITY STUD, V3, P173
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   TOWNSEND JT, 1971, PERCEPT PSYCHOPHYS, V9, P40, DOI 10.3758/BF03213026
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang QW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581127
   Wang WH, 2023, PROC CVPR IEEE, P14408, DOI 10.1109/CVPR52729.2023.01385
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   WONG AKC, 1987, IEEE T PATTERN ANAL, V9, P796, DOI 10.1109/TPAMI.1987.4767986
   Xenopoulos Peter, 2023, IEEE Trans Vis Comput Graph, V29, P853, DOI 10.1109/TVCG.2022.3209489
   Yang J., 2022, ADV NEURAL INF PROCE, V35, P4203, DOI DOI 10.31525/CT1-NCT039466188
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zamir S.W., 2019, P IEEE CVF C COMP VI, P28
   Zhang H., 2023, P INT C LEARNING REP, P1
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhang Y, 2022, IEEE T KNOWL DATA EN, V34, P5586, DOI 10.1109/TKDE.2021.3070203
   Zhang Y, 2018, NATL SCI REV, V5, P30, DOI 10.1093/nsr/nwx105
NR 69
TC 5
Z9 6
U1 14
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 76
EP 86
DI 10.1109/TVCG.2023.3326588
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500088
PM 37883267
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU He, JB
   Wang, XB
   Wong, KK
   Huang, XJ
   Chen, CJ
   Chen, ZX
   Wang, FJ
   Zhu, M
   Qu, HM
AF He, Jianben
   Wang, Xingbo
   Wong, Kam Kwai
   Huang, Xijie
   Chen, Changjian
   Chen, Zixin
   Wang, Fengjie
   Zhu, Min
   Qu, Huamin
TI <i>VideoPro:</i> A Visual Analytics Approach for Interactive Video
   Programming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interactive machine learning; data programming; video exploration and
   analysis
AB Constructing supervised machine learning models for real-world video analysis require substantial labeled data, which is costly to acquire due to scarce domain expertise and laborious manual inspection. While data programming shows promise in generating labeled data at scale with user-defined labeling functions, the high dimensional and complex temporal information in videos poses additional challenges for effectively composing and evaluating labeling functions. In this paper, we propose VideoPro, a visual analytics approach to support flexible and scalable video data programming for model steering with reduced human effort. We first extract human-understandable events from videos using computer vision techniques and treat them as atomic components of labeling functions. We further propose a two-stage template mining algorithm that characterizes the sequential patterns of these events to serve as labeling function templates for efficient data labeling. The visual interface of VideoPro facilitates multifaceted exploration, examination, and application of the labeling templates, allowing for effective programming of video data at scale. Moreover, users can monitor the impact of programming on model performance and make informed adjustments during the iterative programming process. We demonstrate the efficiency and effectiveness of our approach with two case studies and expert interviews.
C1 [He, Jianben; Wang, Xingbo; Wong, Kam Kwai; Huang, Xijie; Chen, Zixin; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Chen, Changjian] Tsinghua Univ, Beijing, Peoples R China.
   [Wang, Fengjie; Zhu, Min] Sichuang Univ, Chengdu, Peoples R China.
C3 Hong Kong University of Science & Technology; Tsinghua University;
   Sichuan University
RP Wang, XB (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM jhebt@ust.hk; xwangeg@ust.hk; kkwongar@ust.hk; xhuangbs@ust.hk;
   changjianchen.me@gmail.com; zchendf@ust.hk; wangfengjie@stu.scu.edu.cn;
   zhumin@scu.edu.cn; huamin@ust.hk
RI 陈, 梓昕/GQP-6896-2022; Chen, Changjian/KBA-9462-2024; Huang,
   Xijie/KOD-4309-2024; Wang, Xingbo/JHS-6567-2023
OI WONG, Kam Kwai/0000-0002-2813-1972
FU ITF PRP
FX No Statement Available
CR Abernethy B., 2013, Human Kinetics, V8
   Afzal S, 2023, ACM T INTERACT INTEL, V13, DOI 10.1145/3576935
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bernard J, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3439333
   Bernard J, 2018, COMPUT GRAPH FORUM, V37, P121, DOI 10.1111/cgf.13406
   Blascheck T, 2016, IEEE CONF VIS ANAL, P141, DOI 10.1109/VAST.2016.7883520
   Cansik, 2022, yolo-hand-detection
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen YZ, 2018, IEEE T VIS COMPUT GR, V24, P45, DOI 10.1109/TVCG.2017.2745083
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Choi M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300460
   Contributors M., Openmmlabs next generation video understanding toolbox and benchmark
   Dasiopoulou S, 2011, LECT NOTES ARTIF INT, V6050, P196, DOI 10.1007/978-3-642-20795-2_8
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Deng D., 2021, P CHI, P1, DOI [DOI 10.1145/3411764.34454312, 10.1145/3411764.34454312]
   Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25
   Feng YCJ, 2023, Arxiv, DOI arXiv:2307.09036
   Grimmeisen B, 2023, VISUAL COMPUT, V39, P5097, DOI 10.1007/s00371-022-02648-2
   Grunwald P. D., 2007, The Minimum Description Length Principle (Adaptive Computation and Machine Learning), P4
   Halter G, 2019, COMPUT GRAPH FORUM, V38, P119, DOI 10.1111/cgf.13676
   Hamill J., 2006, Biomechanical basis of human movement, P8
   Höferlin B, 2015, INFORM VISUAL, V14, P10, DOI 10.1177/1473871613488571
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoque Md Naimul, 2023, IEEE Trans Vis Comput Graph, V29, P74, DOI 10.1109/TVCG.2022.3209466
   Hosseininasab A, 2019, AAAI CONF ARTIF INTE, P1495
   Ji JW, 2020, PROC CVPR IEEE, P10233, DOI 10.1109/CVPR42600.2020.01025
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Jiao LC, 2022, IEEE T NEUR NET LEAR, V33, P3195, DOI 10.1109/TNNLS.2021.3053249
   Khayat M, 2020, IEEE T VIS COMPUT GR, V26, P874, DOI 10.1109/TVCG.2019.2934266
   Kurby CA, 2008, TRENDS COGN SCI, V12, P72, DOI 10.1016/j.tics.2007.11.004
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lasecki W. S, 2014, P 27 ANN ACM S US IN, P551
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li JC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4568
   Li KC, 2022, Arxiv, DOI [arXiv:2201.04676, DOI 10.48550/ARXIV.2201.04676]
   Liang P. P., 2023, INT C LEARNING REPRE
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meng1994412, 2022, smile_detection
   Moehrmann J, 2011, LECT NOTES COMPUT SC, V6761, P618, DOI 10.1007/978-3-642-21602-2_67
   Morrow B, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P1, DOI [10.1109/visual.2019.8933582, 10.1109/VISUAL.2019.8933582]
   Ou Y., 2022, P CVPR, P20133
   Parry ML, 2011, IEEE T VIS COMPUT GR, V17, P1747, DOI 10.1109/TVCG.2011.208
   Price W, 2022, PROC CVPR IEEE, P13760, DOI 10.1109/CVPR52688.2022.01340
   Ratner A., 2016, PROC NEURIPS, P2
   Ratner A, 2017, PROC VLDB ENDOW, V11, P269, DOI 10.14778/3157794.3157797
   Schoning J., 2019, Advances in Information and Communication Networks, P346, DOI [10.1007/978-3-030-03402-3_232, DOI 10.1007/978-3-030-03402-3_232]
   Settles B., 1994, Machine Learning, V15, P7
   Soomro K., 2012, arXiv
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/vast47406.2019.8986917, 10.1109/VAST47406.2019.8986917]
   Sun JJ, 2021, PROC CVPR IEEE, P2875, DOI [10.1109/cvpr46437.2021.00290, 10.1109/CVPR46437.2021.00290]
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Vahdani E, 2023, IEEE T PATTERN ANAL, V45, P4302, DOI 10.1109/TPAMI.2022.3193611
   Wang JC, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3688, DOI 10.1145/3447548.3467104
   Wang M., 2021, arXiv
   Wang X, 2022, AAAI CONF ARTIF INTE, P12665
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang XB, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376726
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Wongvichayakul Kittamet, 2023, IECON 2023- 49th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON51785.2023.10311940
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang Y, 2021, Arxiv, DOI arXiv:2111.09276
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zeng HP, 2023, IEEE T VIS COMPUT GR, V29, P3685, DOI 10.1109/TVCG.2022.3169175
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang JY, 2022, Arxiv, DOI arXiv:2202.05433
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang Y, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517612
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
NR 83
TC 2
Z9 2
U1 5
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 87
EP 97
DI 10.1109/TVCG.2023.3326586
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500005
PM 37871060
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Dasu, K
   Kuo, YH
   Ma, KL
AF Dasu, Keshav
   Kuo, Yun-Hsin
   Ma, Kwan-Liu
TI Character-Oriented Design for Visual Data Storytelling
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Storytelling; Explanatory; Narrative visualization; Visual metaphor
ID NARRATIVE VISUALIZATION; TELLING STORIES; GENERATION
AB When telling a data story, an author has an intention they seek to convey to an audience. This intention can be of many forms such as to persuade, to educate, to inform, or even to entertain. In addition to expressing their intention, the story plot must balance being consumable and enjoyable while preserving scientific integrity. In data stories, numerous methods have been identified for constructing and presenting a plot. However, there is an opportunity to expand how we think and create the visual elements that present the story. Stories are brought to life by characters; often they are what make a story captivating, enjoyable, memorable, and facilitate following the plot until the end. Through the analysis of 160 existing data stories, we systematically investigate and identify distinguishable features of characters in data stories, and we illustrate how they feed into the broader concept of "character-oriented design". We identify the roles and visual representations data characters assume as well as the types of relationships these roles have with one another. We identify characteristics of antagonists as well as define conflict in data stories. We find the need for an identifiable central character that the audience latches on to in order to follow the narrative and identify their visual representations. We then illustrate "character-oriented design" by showing how to develop data characters with common data story plots. With this work, we present a framework for data characters derived from our analysis; we then offer our extension to the data storytelling process using character-oriented design. To access our supplemental materials please visit https://chaorientdesignds.github.io/.
C1 [Dasu, Keshav; Kuo, Yun-Hsin; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Dasu, K (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM kdasu@ucdavis.edu; yskuo@ucdavis.edu; klma@ucdavis.edu
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   [Anonymous], 2014, T. N. Y. Times
   [Anonymous], 2015, Systems, P1459, DOI 10.1145/
   Azad K., 2019, Colorized math equations
   B. Bach, about us
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bradbury JD, 2020, INFORM VISUAL, V19, P339, DOI 10.1177/1473871620925071
   Bran R, 2010, PROCD SOC BEHV, V2, P1790, DOI 10.1016/j.sbspro.2010.03.986
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Cai YD, 2007, LECT NOTES COMPUT SC, V4469, P260
   Cai Z, 2015, IEEE PAC VIS SYMP, P99, DOI 10.1109/PACIFICVIS.2015.7156363
   Campbell J., 2008, El heroe de las mil caras, V3rd
   Carter S., 2016, Distill, DOI DOI 10.23915/DISTILL.00004
   Cavazza M., 2001, P CAST 2001, P139
   Cavazza Marc, 2001, Virtual Storytelling Using Virtual Reality Technologies for Storytelling, P145
   Charles F, 2001, VSMM 2001: SEVENTH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA, PROCEEDINGS, P609, DOI 10.1109/VSMM.2001.969719
   Chu T., 2014, Money wins elections
   Coats E., Pixar's 22 rules of storytelling
   Cruz Pedro, 2019, Information Design Journal, V25, P6, DOI 10.1075/idj.25.1.01cru
   Dasu K, 2021, IEEE T VIS COMPUT GR, V27, P935, DOI 10.1109/TVCG.2020.3030412
   Dasu K, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P1, DOI 10.1109/SciVis.2018.8823624
   Data Visualization Society, Information Is Beautiful Awards
   Dudukovic NM, 2004, APPL COGNITIVE PSYCH, V18, P125, DOI 10.1002/acp.953
   Field S., 2005, SCREENPLAY FDN SCREE
   Fink EJ, 2014, DRAMATIC STORY STRUCTURE: A PRIMER FOR SCREENWRITERS, P1
   Forster E.M., 2010, Aspects of the Novel
   Fritz C, 2007, J ARCHAEOL METHOD TH, V14, P48, DOI 10.1007/s10816-007-9027-3
   GAPMINDER.ORG, about us
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Gove R, 2021, IEEE SYM VIS CYB SEC, P1, DOI 10.1109/VizSec53666.2021.00005
   Halloran N., 2021, How sure are climate scientists, really?
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hohman F, 2020, Distill, DOI [10.23915/distill.00028, DOI 10.23915/DISTILL.00028]
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Interactive P., Out of sight, out of mind
   Isenberg P, 2018, LECT NOTES COMPUT SC, V11190, P165, DOI 10.1007/978-3-030-01388-2_6
   Kang JA, 2020, J CONSUM BEHAV, V19, P47, DOI 10.1002/cb.1793
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Lan XY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517530
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Li YN, 2015, 8TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION (VINCI 2015), P121, DOI 10.1145/2801040.2801062
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Ojo A, 2018, DIGIT JOURNAL, V6, P693, DOI 10.1080/21670811.2017.1403291
   Petridis S, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P187, DOI 10.1145/3325480.3325503
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Reuters, 2020, How powerful was the beirut blast?
   Risch JS, 2008, Arxiv, DOI arXiv:0809.0884
   Sallaberry A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146368
   Sarica HC, 2016, COMPUT EDUC, V94, P298, DOI 10.1016/j.compedu.2015.11.016
   Scarr S., 2020, Covid-19: The pace of death
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shen D, 2008, NINETEEN CENT LIT, V63, P321, DOI 10.1525/ncl.2008.63.3.321
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stolper C., 2016, Emerging and recurring data-driven storytelling techniques: analysis of a curated collection of recent stories
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Truby J, 2008, The anatomy of story: 22 steps to becoming a master storyteller
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang SM, 2015, IEEE COMPUT GRAPH, V35, P82, DOI 10.1109/MCG.2015.74
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Woolf W., about us
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Zhao Z., 2015, DATA COMICS SEQUENTI
NR 73
TC 1
Z9 1
U1 10
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 98
EP 108
DI 10.1109/TVCG.2023.3326578
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500112
PM 37871068
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shen, LX
   Zhang, YZ
   Zhang, HD
   Wang, Y
AF Shen, Leixian
   Zhang, Yizhi
   Zhang, Haidong
   Wang, Yun
TI Data Player: Automatic Generation of Data Videos with
   Narration-Animation Interplay
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Narration-animation interplay; Data video; Human-AI
   collaboration
ID VISUALIZATION; STORIES
AB Data visualizations and narratives are often integrated to convey data stories effectively. Among various data storytelling formats, data videos have been garnering increasing attention. These videos provide an intuitive interpretation of data charts while vividly articulating the underlying data insights. However, the production of data videos demands a diverse set of professional skills and considerable manual labor, including understanding narratives, linking visual elements with narration segments, designing and crafting animations, recording audio narrations, and synchronizing audio with visual animations. To simplify this process, our paper introduces a novel method, referred to as Data Player, capable of automatically generating dynamic data videos with narration-animation interplay. This approach lowers the technical barriers associated with creating data videos rich in narration. To enable narration-animation interplay, Data Player constructs references between visualizations and text input. Specifically, it first extracts data into tables from the visualizations. Subsequently, it utilizes large language models to form semantic connections between text and visuals. Finally, Data Player encodes animation design knowledge as computational low-level constraints, allowing for the recommendation of suitable animation presets that align with the audio narration produced by text-to-speech technologies. We assessed Data Player's efficacy through an example gallery, a user study, and expert interviews. The evaluation results demonstrated that Data Player can generate high-quality data videos that are comparable to human-composed ones.
C1 [Shen, Leixian] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Zhang, Yizhi] Cornell Univ, Ithaca, NY USA.
   [Zhang, Haidong; Wang, Yun] Microsoft Res Asia MSRA, Beijing, Peoples R China.
   [Shen, Leixian; Zhang, Yizhi] MSRA, Beijing, Peoples R China.
C3 Hong Kong University of Science & Technology; Cornell University
RP Wang, Y (corresponding author), Microsoft Res Asia MSRA, Beijing, Peoples R China.
EM lshenaj@connect.ust.hk; yz2668@cornell.edu; haizhang@microsoft.com;
   wangyun@microsoft.com
RI Zhang, Haidong/J-9302-2019
CR Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Badam S. K., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P5
   Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472
   Chen Q., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1145/3491102.3517485, 10.1109/TENCON55691.2022.9978005]
   Cheng H, 2022, COMPUT GRAPH FORUM, V41, P527, DOI 10.1111/cgf.14560
   Chi Peggy, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P677, DOI 10.1145/3472749.3474778
   Chi Peggi, 2020, UIST 20, P279, DOI [10.1145/3379337.3415814, DOI 10.1145/3379337.3415814]
   Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24
   deeplearning, Chatgpt prompt engineering for developers
   ffmpeg, Ffmpeg multimedia framework
   Ge T, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14005
   Ge T., 2021, P 2021 CHI C HUM FAC, P1
   greensock, Gsap animation platform
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hohman F, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P151, DOI [10.1109/visual.2019.8933695, 10.1109/VISUAL.2019.8933695]
   Hook J, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P43, DOI 10.1145/3210825.3210826
   Huang C.-Y., 2023, arXiv
   Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617
   Kim Y., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2
   Kim Y, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P201, DOI [10.1109/VIS49827.2021.00048, 10.1109/VIS49827.2021.9623291]
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775
   Latif S., 2021, IEEE Transactions on Visualization and Computer Graphics
   Li HT, 2023, Arxiv, DOI arXiv:2304.08366
   Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048
   Li W., 2023, P 2023 CHI C HUM FAC, V1, P1
   Lin Y., 2023, IEEE Transactions on Visualization and Computer Graphics, V14, P9
   Liu V., 2022, P 2022 CHI C HUM FAC, P1
   Luo Y., 2023, Proceedings of the ACM on Management of Data, SIGMOD'23, V1, P1
   Masson D., 2023, ACM C HUM FACT COMP
   McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195
   Metoyer R, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P503, DOI 10.1145/3172944.3173007
   microsoft, Microsoft azure text-to-speech service
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Ruoff M., P 2023 CHI C HUM FAC, P1
   Russell D. M., 2014, Ways of Knowing in HCI, P3
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Shen L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Shen LX, 2022, DATA SCI ENG, V7, P354, DOI 10.1007/s41019-022-00195-3
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593
   Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974
   Thompson J., 2021, P ACM C HUM FACT COM, P2
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   Wang Y., 2023, WonderFlow: Narration-Centric Design of Animated Data Videos, P1
   Wang Y, 2023, IEEE T VIS COMPUT GR, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2021, COMPUT GRAPH FORUM, V40, P507, DOI 10.1111/cgf.14325
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Xie L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Xu P., 2014, P 27 ANN ACM S US IN, P243, DOI DOI 10.1145/2642918.2647398
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
NR 68
TC 3
Z9 3
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 109
EP 119
DI 10.1109/TVCG.2023.3327197
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500118
PM 37922173
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kim, DH
   Choi, S
   Kim, J
   Setlur, V
   Agrawala, M
AF Kim, Dae Hyun
   Choi, Seulgi
   Kim, Juho
   Setlur, Vidya
   Agrawala, Maneesh
TI EC: A Tool for Guiding Chart and Caption Emphasis&lt;sc/&gt;&lt;sc/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Chart and text takeaways; visual prominence; authoring; captions
ID VISUALIZATION
AB Recent work has shown that when both the chart and caption emphasize the same aspects of the data, readers tend to remember the doubly-emphasized features as takeaways; when there is a mismatch, readers rely on the chart to form takeaways and can miss information in the caption text. Through a survey of 280 chart-caption pairs in real-world sources (e.g., news media, poll reports, government reports, academic articles, and Tableau Public), we find that captions often do not emphasize the same information in practice, which could limit how effectively readers take away the authors' intended messages. Motivated by the survey findings, we present Emphasischecker, an interactive tool that highlights visually prominent chart features as well as the features emphasized by the caption text along with any mismatches in the emphasis. The tool implements a time-series prominent feature detector based on the Ramer-Douglas-Peucker algorithm and a text reference extractor that identifies time references and data descriptions in the caption and matches them with chart data. This information enables authors to compare features emphasized by these two modalities, quickly see mismatches, and make necessary revisions. A user study confirms that our tool is both useful and easy to use when authoring charts and captions.
C1 [Kim, Dae Hyun; Choi, Seulgi; Kim, Juho] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Kim, Dae Hyun; Agrawala, Maneesh] Stanford Univ, Stanford, CA USA.
   [Setlur, Vidya] Tableau Res, Amherst, MA USA.
   [Agrawala, Maneesh] Roblox, San Mateo, CA USA.
C3 Korea Advanced Institute of Science & Technology (KAIST); Stanford
   University
RP Kim, DH (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM dhkim16@cs.stanford.edu; igules8925@kaist.ac.kr; juhokim@kaist.ac.kr;
   vsetlur@tableau.com; maneesh@cs.stanford.edu
RI ; Kim, Juho/A-7091-2016; Kim, Dae Hyun/JJD-4264-2023
OI Choi, Seulgi/0000-0002-9334-0471; Kim, Juho/0000-0001-6348-4127; Setlur,
   Vidya/0000-0003-3722-406X; Agrawala, Maneesh/0000-0002-8996-7327; Kim,
   Dae Hyun/0000-0002-8657-9986
FU Brown Institute for Media Innovation
FX No Statement Available
CR [Anonymous], 2023, New York Times.
   [Anonymous], 2023, Vox Media
   [Anonymous], 2023, ABOUT US
   [Anonymous], 2023, About us
   Badam SK, 2019, IEEE T VIS COMPUT GR, V25, P661, DOI 10.1109/TVCG.2018.2865119
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Beck F, 2017, IEEE T VIS COMPUT GR, V23, P1576, DOI 10.1109/TVCG.2017.2674958
   Biderman A. D., 1979, Information Design Journal, V4, P232, DOI [10.1075/idj.1.4.03bid2, DOI 10.1075/IDJ.1.4.03BID2]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Carberry S., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P581, DOI 10.1145/1148170.1148270
   Chang AX, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3735
   Chen CR, 2019, Arxiv, DOI arXiv:1906.02850
   Chen C, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P482, DOI 10.1145/3341162.3345601
   Chen D, 2014, P 2014 C EMP METH NA, P740, DOI DOI 10.3115/V1/D14-1082
   Chen Z., 2022, P 2022 CHI C HUM FAC, V95, DOI [10.1145/3491102.35174852, DOI 10.1145/3491102.35174852]
   CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P289, DOI 10.2307/2288843
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Douglas D. H., 1973, Cartogr. Int. J. Geogr. Inf. Geovis, V10, P112, DOI DOI 10.3138/FM57-6770-U75U-7727
   Earnest L., The First Three Spelling Checkers
   Elzer S., 2005, P 43 ANN M ASS COMP, P223, DOI DOI 10.3115/1219840.1219868
   Elzer S, 2011, ARTIF INTELL, V175, P526, DOI 10.1016/j.artint.2010.10.003
   Fasciano M., 1996, 8 INT NAT LANG GEN W, P2
   Finkel Jenny Rose, 2005, P 43 ANN M ASS COMP, P363
   Fulda J, 2016, IEEE T VIS COMPUT GR, V22, P300, DOI 10.1109/TVCG.2015.2467531
   Goffin P., 2015, C INF VIS INFOVIS, P2
   Google, Use Smart Compose
   Google, Check Your Spelling & Grammar in Google Docs
   Google, Fix Spelling & Grammar as You Type in Gmail
   Gould J. D., 1976, Eye Movements and Psychological Processes, P2
   Grammarly, 2023, About us
   Haas P. J., 2017, arXiv
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   International Monetary Fund, 2023, About us
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Keogh E., 2001, Knowledge and Information Systems, V3, P263, DOI 10.1007/PL00011669
   Khan A, 2015, INT J HUM-COMPUT ST, V83, P94, DOI 10.1016/j.ijhcs.2015.07.001
   Kim D. H., 2021, P 2021 CHI C HUM FAC, V610, DOI [10.1145/3411764.34454431,2,3,7,9, DOI 10.1145/3411764.34454431,2,3,7,9]
   Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   LanguageTool, 2023, About us
   Latif S, 2018, EUROVIS SHORT PAPERS, P91, DOI DOI 10.5555/3290776.3290796
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   LibreOffice, 2023, Checking Spelling and Grammar
   Lin AY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P873, DOI 10.1145/3178876.3186135
   Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Merriam-Webster, 2023, About us
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Microsoft, 2023, Editor Settings in Outlook.com and Outlook on the Web
   Mitkov R., 2014, Anaphora Resolution, DOI [10.4324/97813158400869, DOI 10.4324/97813158400869]
   Obeid J., 2020, P 13 INT C NAT LANG, P2
   Ottley A., 2012, Technical Report 2012-02, P2
   Ottley A., 2019, P 2019 EUR IEEE VGTC, DOI DOI 10.2312/EVS.20191181
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Pew Research Center, 2023, About us
   Pinheiro J., 2022, arXiv
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Qian X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2792, DOI 10.1145/3442381.3449923
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Rong KX, 2017, PROC VLDB ENDOW, V10, P1358, DOI 10.14778/3137628.3137645
   Rosen P, 2021, IEEE T VIS COMPUT GR, V27, P1536, DOI 10.1109/TVCG.2020.3030421
   Springer Nature, 2023, About us
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Subbiah M., 2020, P 34 INT C NEUR INF, V159, DOI [10. 48550/arXiv.2005.14165 9, DOI 10.48550/ARXIV.2005.141659]
   Sweller J., 2011, Cognitive Load Theory, P111, DOI [10.1007/978-1-4419-8126-4_9, DOI 10.1007/978-1-4419-8126-4_9]
   Tableau Public, 2023, About us
   The British Broadcasting Corporation (BBC), 2023, About us
   Tufte E. R., 2001, The visual display of quantitative information, P2
   U.S. Department of the Treasury, 2023, About us
   un, About us
   Whitacre MP, 2016, INT J SCI MATH EDUC, V14, P1387, DOI 10.1007/s10763-015-9677-7
   Wikimedia Commons, 2023, About us
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   WolframAlpha, 2023, About us
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Zhu HZ, 2022, Arxiv, DOI [arXiv:2205.01263, 10.48550/arXiv.2205.012631,2, DOI 10.48550/ARXIV.2205.012631,2]
NR 81
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 120
EP 130
DI 10.1109/TVCG.2023.3327150
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500032
PM 37922182
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wu, GD
   Guo, SN
   Hoffswell, J
   Chan, GYY
   Rossi, RA
   Koh, E
AF Wu, Guande
   Guo, Shunan
   Hoffswell, Jane
   Chan, Gromit Yeuk-Yin
   Rossi, Ryan A.
   Koh, Eunyee
TI Socrates: Data Story Generation via Adaptive Machine-Guided Elicitation
   of User Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Narrative visualization; visual storytelling; conversational agent
ID VISUALIZATIONS; GUIDANCE; MODEL
AB Visual data stories can effectively convey insights from data, yet their creation often necessitates intricate data exploration, insight discovery, narrative organization, and customization to meet the communication objectives of the storyteller. Existing automated data storytelling techniques, however, tend to overlook the importance of user customization during the data story authoring process, limiting the system's ability to create tailored narratives that reflect the user's intentions. We present a novel data story generation workflow that leverages adaptive machine-guided elicitation of user feedback to customize the story. Our approach employs an adaptive plug-in module for existing story generation systems, which incorporates user feedback through interactive questioning based on the conversation history and dataset. This adaptability refines the system's understanding of the user's intentions, ensuring the final narrative aligns with their goals. We demonstrate the feasibility of our approach through the implementation of an interactive prototype: Socrates. Through a quantitative user study with 18 participants that compares our method to a state-of-the-art data story generation algorithm, we show that Socrates produces more relevant stories with a larger overlap of insights compared to human-generated stories. We also demonstrate the usability of Socrates via interviews with three data analysts and highlight areas of future work.
C1 [Wu, Guande] NYU, New York, NY 10012 USA.
   [Guo, Shunan; Hoffswell, Jane; Chan, Gromit Yeuk-Yin; Rossi, Ryan A.; Koh, Eunyee] Adobe Res, San Jose, CA USA.
C3 New York University; Adobe Systems Inc.
RP Wu, GD (corresponding author), NYU, New York, NY 10012 USA.
EM guandewu@nyu.edu; sguo@adobe.com; jhoffs@adobe.com; ychan@adobe.com;
   rrossi@adobe.com; eunyee@adobe.com
RI Guo, Shunan/AAE-2616-2019; Wu, Guande/JZE-5610-2024; Rossi,
   Ryan/C-7974-2013
OI Chan, Gromit Yeuk-Yin/0000-0003-1356-4406; Hoffswell,
   Jane/0000-0002-9871-4575; Guo, Shunan/0000-0001-5355-8399; Wu,
   Guande/0000-0002-9244-173X; Rossi, Ryan/0000-0001-9758-0635
CR Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Bach B., 2018, Data-driven storytelling, P2
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cao YR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517648
   Cao YR, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383057
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chen Z., 2022, P 2022 CHI C HUMAN F, DOI [10.1145/3491102.35174851,3, DOI 10.1145/3491102.35174851,3]
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chevalier F., 2018, Data-Driven Storytelling, P2
   Cohn N, 2013, COGNITIVE SCI, V37, P413, DOI 10.1111/cogs.12016
   Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Cutting JE, 2016, PSYCHON B REV, V23, P1713, DOI 10.3758/s13423-016-1051-4
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Dykes B., 2019, Effective data storytelling: how to drive change with data, narrative and visuals, P2
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Endert A, 2012, IEEE T VIS COMPUT GR, V18, P2879, DOI 10.1109/TVCG.2012.260
   Franklin A, 2017, J BIOMED INFORM, V71, P211, DOI 10.1016/j.jbi.2017.05.024
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Guo Y, 2023, Arxiv, DOI arXiv:2107.14420
   Hariri N., 2012, P ACM C REC SYST NEW, P131, DOI DOI 10.1145/2365952.2365979
   Hinne M., 2011, P DUTCH BELGIUM INFO, P20
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Jannach D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453154
   Kelly D., 2003, Acm Sigir Forum, V37, P4
   Kim N. W., 2019, P 2019 CHI C HUMAN F, P1
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Latif S., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Latif S, 2021, COMPUT GRAPH FORUM, V40, P311, DOI 10.1111/cgf.14309
   Lee B., 2015, IEEE Computer Graphics and Applications, V2
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lei WQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2073, DOI 10.1145/3394486.3403258
   Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769
   Lu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1161
   Meignan D, 2015, ACM T INTERACT INTEL, V5, DOI 10.1145/2808234
   Miettinen K., 1999, Nonlinear multiobjective optimization, V12, P4
   Mudgal S, 2018, INT CONF MANAGE DATA, P19, DOI 10.1145/3183713.3196926
   Narducci F, 2020, USER MODEL USER-ADAP, V30, P251, DOI 10.1007/s11257-019-09250-7
   Nguyen B. V., 2007, WWW2007 16 INT WORLD, P4
   Panda AK, 2012, INT J ELEC POWER, V40, P9, DOI 10.1016/j.ijepes.2011.12.012
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riche N. H., 2018, Data-driven storytelling, P2
   Rundo L, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103479
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Showkat Dilruba, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479534
   Sperrle F, 2021, COMPUT GRAPH-UK, V100, P93, DOI 10.1016/j.cag.2021.06.016
   Sun M., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P983, DOI [10.1109/TVCG.2022.32094281,2,3,4, DOI 10.1109/TVCG.2022.32094281,2,3,4]
   Swanson R, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2362394.2362398
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Whiting S, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P989
   Wojtkowski W., 2002, EUROPEAN SYSTEMS SCI, V5, P1
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Xie ZH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1400, DOI 10.1145/3404835.3462920
   Xu B, 2015, IEEE T KNOWL DATA EN, V27, P102, DOI 10.1109/TKDE.2013.70
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Zhang S, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P255, DOI 10.1145/3077136.3080796
   Zhang YM, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2153, DOI 10.1145/3485447.3512088
   Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zheng CB, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517615
   Zheng CB, 2022, IEEE PAC VIS SYMP, P141, DOI 10.1109/PacificVis53943.2022.00023
NR 79
TC 2
Z9 2
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 131
EP 141
DI 10.1109/TVCG.2023.3327363
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500049
PM 37922178
DA 2024-11-06
ER

PT J
AU Xia, JZ
   Huang, LQ
   Sun, YP
   Deng, ZW
   Zhang, XL
   Zhu, MF
AF Xia, Jiazhi
   Huang, Linquan
   Sun, Yiping
   Deng, Zhiwei
   Zhang, Xiaolong Luke
   Zhu, Minfeng
TI A Parallel Framework for Streaming Dimensionality Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE High-dimensional data visualization; dimensionality reduction; streaming
   data visualization
ID VISUALIZATION
AB The visualization of streaming high-dimensional data often needs to consider the speed in dimensionality reduction algorithms, the quality of visualized data patterns, and the stability of view graphs that usually change over time with new data. Existing methods of streaming high-dimensional data visualization primarily line up essential modules in a serial manner and often face challenges in satisfying all these design considerations. In this research, we propose a novel parallel framework for streaming high-dimensional data visualization to achieve high data processing speed, high quality in data patterns, and good stability in visual presentations. This framework arranges all essential modules in parallel to mitigate the delays caused by module waiting in serial setups. In addition, to facilitate the parallel pipeline, we redesign these modules with a parametric non-linear embedding method for new data embedding, an incremental learning method for online embedding function updating, and a hybrid strategy for optimized embedding updating. We also improve the coordination mechanism among these modules. Our experiments show that our method has advantages in embedding speed, quality, and stability over other existing methods to visualize streaming high-dimensional data.
C1 [Xia, Jiazhi; Huang, Linquan; Sun, Yiping; Deng, Zhiwei] Cent South Univ, Sch Comp Sci & Engn, Changsha, Peoples R China.
   [Zhang, Xiaolong Luke] Penn State Univ, University Pk, PA USA.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Central South University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University; Pennsylvania State
   University - University Park; Zhejiang University
RP Zhu, MF (corresponding author), Zhejiang Univ, Hangzhou, Peoples R China.
EM xiajiazhi@csu.edu.cn; lnquanhuang@csu.edu.cn; yipingsun@csu.edu.cn;
   dengzhiwei@csu.edu.cn; lzhang@ist.psu.edu; minfeng_zhu@zju.edu.cn
RI ZHANG, XIAOLONG/IZQ-4553-2023; sun, yiping/AAI-7366-2021; Zhu,
   Minfeng/R-6788-2019
OI Zhu, Minfeng/0000-0002-6711-3099
FU National Natural Science Foundation of China
FX No Statement Available
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Ali M, 2019, VISUAL COMPUT, V35, P1013, DOI 10.1007/s00371-019-01673-y
   Allaoui M., 2020, CONSIDERABLY IMPROVI, DOI [10.1007/978-3-030-51935, DOI 10.1007/978-3-030-51935]
   Alsakran J, 2011, IEEE PAC VIS SYMP, P131, DOI 10.1109/PACIFICVIS.2011.5742382
   Anguita D., 2013, P ES BRUG BELG 24 26, VVolume 3, P3
   Asuncion A., 2007, UCI machine learning repository
   Blondel M., 2020, INT C MACHINE LEARNI, P950, DOI DOI 10.5555/3524938.3525027
   Boggs P. T., 1995, ACTA NUMER, V4, P1, DOI [10.1017/S0962492900002518, DOI 10.1017/S0962492900002518]
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Cha H., 2021, ICCV, P9516
   Chen X, 2022, IEEE T VIS COMPUT GR, V28, P593, DOI 10.1109/TVCG.2021.3114880
   Cheng S., 2016, NEW YORK SCI DATA SU, P1, DOI [10.1109/NYSDS.2016.77478082, DOI 10.1109/NYSDS.2016.77478082]
   Crnovrsanin T., 2015, An incremental layout method for visualizing online dynamic graphs, V21, P1629, DOI [10.1007/978-3-319-27261-0_22,8, DOI 10.1007/978-3-319-27261-0_22,8]
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665
   Dasgupta A, 2018, COMPUT GRAPH FORUM, V37, P254, DOI 10.1111/cgf.13264
   Neves TTDT, 2022, COMPUT GRAPH-UK, V102, P233, DOI 10.1016/j.cag.2021.08.009
   Dehvari M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104336
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fort Stanislav, 2021, ADV NEUR IN, V34
   Frishman Y, 2008, IEEE T VIS COMPUT GR, V14, P727, DOI 10.1109/TVCG.2008.11
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Gansner Emden R., 2013, Journal of Graph Algorithms and Applications, V17, P515, DOI 10.7155/jgaa.00302
   Gorochowski TE, 2012, IEEE T VIS COMPUT GR, V18, P1343, DOI 10.1109/TVCG.2011.142
   Gorsuch R. L., 2013, Psychology press, V1
   Hinterreiter A., 2023, COMPUT GRAPH FORUM, DOI [10.1111/cgf.148342, DOI 10.1111/CGF.148342]
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jäckle D, 2016, IEEE T VIS COMPUT GR, V22, P141, DOI 10.1109/TVCG.2015.2467553
   Jia P, 2009, PATTERN RECOGN LETT, V30, P1457, DOI 10.1016/j.patrec.2009.08.005
   Jo J, 2020, IEEE T VIS COMPUT GR, V26, P1347, DOI 10.1109/TVCG.2018.2869149
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kaski S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-48
   Ke Z., 2021, arXiv
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Krstajic Milos, 2013, 2013 IEEE International Conference on Big Data, P41, DOI 10.1109/BigData.2013.6691713
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Lai CH, 2022, IEEE VIS CONF, P75, DOI 10.1109/VIS54862.2022.00024
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Law MHC, 2006, IEEE T PATTERN ANAL, V28, P377, DOI 10.1109/TPAMI.2006.56
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li W, 2020, IEEE T KNOWL DATA EN, V32, P1475, DOI 10.1109/TKDE.2019.2909204
   Li Y, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS AND INTELLIGENCE SYSTEM (IOTAIS), P231, DOI [10.1109/iotais47347.2019.8980418, 10.1109/IoTaIS47347.2019.8980418]
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Lin CC, 2011, INFORM SCIENCES, V181, P4253, DOI 10.1016/j.ins.2011.06.005
   Liu SX, 2016, IEEE T VIS COMPUT GR, V22, P2451, DOI 10.1109/TVCG.2015.2509990
   Mahapatra S, 2017, IEEE INT CONF BIG DA, P716, DOI 10.1109/BigData.2017.8257987
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Miglani A., Corona virus tagged data
   Palumbo F, 2016, J AMB INTEL SMART EN, V8, P87, DOI 10.3233/AIS-160372
   Paulovich FV, 2008, IEEE T VIS COMPUT GR, V14, P564, DOI 10.1109/TVCG.2007.70443
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Rauber P. E., 2016, P EUROGRAPHICS IEEE, P7377, DOI [10.2312/eurovisshort.201611642,4, DOI 10.2312/EUROVISSHORT.201611642,4]
   Ren Jie, 2019, ADV NEURAL INFORM PR, V32
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sainburg T, 2021, NEURAL COMPUT, V33, P2881, DOI 10.1162/neco_a_01434
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Steiger M, 2014, COMPUT GRAPH FORUM, V33, P401, DOI 10.1111/cgf.12396
   Tang SX, 2021, AAAI CONF ARTIF INTE, V35, P2665
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thudumu S, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00320-x
   van der Maaten L., 2009, J MACH LEARN RES, P384
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vernier EF, 2021, COMPUT GRAPH FORUM, V40, P87, DOI 10.1111/cgf.14291
   Wang YQ, 2022, IEEE T VIS COMPUT GR, V28, P623, DOI 10.1109/TVCG.2021.3114765
   Webga K, 2015, IEEE SYM VIS CYB SEC
   Wei YT, 2024, IEEE T VIS COMPUT GR, V30, P3915, DOI 10.1109/TVCG.2023.3243228
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xia J, 2013, TSINGHUA SCI TECHNOL, V18, P196, DOI 10.1109/TST.2013.6509102
   Xiaotong Liu, 2013, 2013 IEEE International Conference on Big Data, P48, DOI 10.1109/BigData.2013.6691714
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Zhang L., 2016, IEEE Transactions on Systems, Man, and Cybernetics: Systems, V47, P6
NR 77
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 142
EP 152
DI 10.1109/TVCG.2023.3326515
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500089
PM 37871057
DA 2024-11-06
ER

PT J
AU Shen, QM
   You, ZX
   Yan, X
   Zhang, CZ
   Xu, K
   Zeng, D
   Qin, JB
   Tang, B
AF Shen, Qiaomu
   You, Zhengxin
   Yan, Xiao
   Zhang, Chaozu
   Xu, Ke
   Zeng, Dan
   Qin, Jianbin
   Tang, Bo
TI QEVIS: Multi-Grained Visualization of Distributed Query Execution
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE visual analytics system; distributed query execution; performance
   analysis
AB Distributed query processing systems such as Apache Hive and Spark are widely-used in many organizations for large-scale data analytics. Analyzing and understanding the query execution process of these systems are daily routines for engineers and crucial for identifying performance problems, optimizing system configurations, and rectifying errors. However, existing visualization tools for distributed query execution are insufficient because (i) most of them (if not all) do not provide fine-grained visualization (i.e., the atomic task level), which can be crucial for understanding query performance and reasoning about the underlying execution anomalies, and (ii) they do not support proper linkages between system status and query execution, which makes it difficult to identify the causes of execution problems. To tackle these limitations, we propose QEVIS, which visualizes distributed query execution process with multiple views that focus on different granularities and complement each other. Specifically, we first devise a query logical plan layout algorithm to visualize the overall query execution progress compactly and clearly. We then propose two novel scoring methods to summarize the anomaly degrees of the jobs and machines during query execution, and visualize the anomaly scores intuitively, which allow users to easily identify the components that are worth paying attention to. Moreover, we devise a scatter plot-based task view to show a massive number of atomic tasks, where task distribution patterns are informative for execution problems. We also equip QEVIS with a suite of auxiliary views and interaction methods to support easy and effective cross-view exploration, which makes it convenient to track the causes of execution problems. QEVIS has been used in the production environment of our industry partner, and we present three use cases from real-world applications and user interview to demonstrate its effectiveness. QEVIS is open-source at https://github.com/DBGroup-SUSTech/QEVIS.
C1 [Shen, Qiaomu; Zeng, Dan; Tang, Bo] Southern Univ Sci & Technol, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.
   [You, Zhengxin] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
   [Yan, Xiao; Xu, Ke] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
   [Zhang, Chaozu; Qin, Jianbin] Shenzhen Univ, Shenzhen Inst Comp Sci, Shenzhen, Peoples R China.
C3 Southern University of Science & Technology; Southern University of
   Science & Technology; Huawei Technologies; Shenzhen Institute of
   Computing Sciences; Shenzhen University
RP Tang, B (corresponding author), Southern Univ Sci & Technol, Res Inst Trustworthy Autonomous Syst, Shenzhen, Peoples R China.
EM shenqm@sustech.edu.cn; 12250078@mail.sustech.edu.cn;
   yanx@sustech.edu.cn; 12132372@mail.sustech.edu.cn; xuke81@huawei.com;
   zengd@sustech.edu.cn; qinjianbin@szu.edu.cn; tangb3@sustech.edu.cn
OI Zeng, Dan/0000-0002-9036-7791; Shen, Qiaomu/0000-0002-6510-0964
FU National Key R&D program of China
FX No Statement Available
CR A. S. Foundation, 2023, The apache hadoop project
   Alsubaiee S., 2014, arXiv
   [Anonymous], 2023, Rug plot
   [Anonymous], 2023, dagre - graph layout for javascript
   Apache pig, 2023, About us
   Battle L, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5433, DOI 10.1145/2858036.2858408
   Begoli E, 2018, INT CONF MANAGE DATA, P221, DOI 10.1145/3183713.3190662
   Bittorf MKABV., 2015, P 7 BIENNIAL C INNOV
   Brasseur L, 2005, TECH COMMUN Q, V14, P161, DOI 10.1207/s15427625tcq1402_3
   Carbone P., 2015, Bull. IEEE Comput. Soc. Tech. Committee Data Eng., V36, P28, DOI DOI 10.1109/IC2EW.2016.56
   Cerullo C, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P109, DOI 10.1109/DEXA.2007.91
   Chaiken R, 2008, PROC VLDB ENDOW, V1, P1265, DOI 10.14778/1454159.1454166
   Chen HD, 2014, IEEE T VIS COMPUT GR, V20, P1683, DOI 10.1109/TVCG.2014.2346594
   Cloudera manager, 2022, Hadoop administration tool
   DiBartolomeo S, 2022, IEEE T VIS COMPUT GR, V28, P324, DOI 10.1109/TVCG.2021.3114756
   Dr, 2023, elephant - monitoring and tuning apache spark jobs on hadoop
   Drebes A., 2014, 7 WORKSHOP PROGRAMMA
   Fujiwara T, 2018, VIS INFORM, V2, P98, DOI 10.1016/j.visint2018.04.010
   Garcia Pinto Vinicius, 2016, 2016 Third Workshop on Visual Performance Analysis (VPA), P17, DOI 10.1109/VPA.2016.008
   Gathani S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376485
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Halperin D, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P881, DOI 10.1145/2588555.2594530
   invitae, 2023, About us
   Jaakkola H, 2003, LECT NOTES COMPUT SC, V2814, P129
   Jeyakumar V, 2019, INT CONF MANAGE DATA, P333, DOI 10.1145/3299869.3314048
   Kesavan SP, 2020, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis48177.2020.9280
   Khoussainova N, 2012, Arxiv, DOI arXiv:1203.6400
   Leventidis A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2303, DOI 10.1145/3318464.3389767
   Li JK, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P20, DOI [10.1109/VDS48975.2019.8973380, 10.1109/vds48975.2019.8973380]
   Liu HT, 2022, PROCEEDINGS OF THE 13TH SYMPOSIUM ON CLOUD COMPUTING, SOCC 2022, P158, DOI 10.1145/3542929.3563503
   Liu HT, 2022, INT CONF MANAGE DATA, P2417, DOI 10.1145/3514221.3520166
   Liu P, 2020, IEEE IPCCC, DOI 10.1109/IPCCC50635.2020.9391550
   Ma MH, 2020, PROC VLDB ENDOW, V13, P1176, DOI 10.14778/3389133.3389136
   Malik S, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2890478
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Moritz D, 2015, COMPUT GRAPH FORUM, V34, P71, DOI 10.1111/cgf.12619
   Nagel WE, 1996, SUPERCOMPUTER, V12, P69
   Prometheus, 2023, About us
   Saha B, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1357, DOI 10.1145/2723372.2742790
   Sakin SA, 2023, IEEE T VIS COMPUT GR, V29, P788, DOI 10.1109/TVCG.2022.3209375
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sigovan C, 2013, COMPUT GRAPH FORUM, V32, P141, DOI 10.1111/cgf.12101
   Simitsis A, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P701, DOI 10.1145/2588555.2594531
   Spark web ui, 2023, About us
   Tan JQ, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.63
   Teoh J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P465, DOI 10.1145/3357223.3362727
   tez.apache, 2023, Tez ui
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Thusoo A, 2010, PROC INT CONF DATA, P996, DOI 10.1109/ICDE.2010.5447738
   Vavilapalli V.K., 2013, P 4 ANN S CLOUD COMP, P1
   Wu J, 2020, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST50239.2020.00009
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Yoon DY, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1599, DOI 10.1145/2882903.2915218
   Zhao X, 2018, IEEE T VIS COMPUT GR, V24, P246, DOI 10.1109/TVCG.2017.2744738
NR 55
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 153
EP 163
DI 10.1109/TVCG.2023.3326930
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500082
PM 37883261
DA 2024-11-06
ER

PT J
AU Meng, LH
   van den Elzen, S
   Pezzotti, N
   Vilanova, A
AF Meng, Linhao
   van den Elzen, Stef
   Pezzotti, Nicola
   Vilanova, Anna
TI Class-Constrained t-SNE: Combining Data Features and Class Probabilities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data models; Visualization; Analytical models;
   Labeling; Cost function; Periodic structures; Dimensionality reduction;
   t-distributed stochastic neighbor embedding; constraint integration
AB Data features and class probabilities are two main perspectives when, e.g., evaluating model results and identifying problematic items. Class probabilities represent the likelihood that each instance belongs to a particular class, which can be produced by probabilistic classifiers or even human labeling with uncertainty. Since both perspectives are multi-dimensional data, dimensionality reduction (DR) techniques are commonly used to extract informative characteristics from them. However, existing methods either focus solely on the data feature perspective or rely on class probability estimates to guide the DR process. In contrast to previous work where separate views are linked to conduct the analysis, we propose a novel approach, class-constrained t-SNE, that combines data features and class probabilities in the same DR result. Specifically, we combine them by balancing two corresponding components in a cost function to optimize the positions of data points and iconic representation of classes - class landmarks. Furthermore, an interactive user-adjustable parameter balances these two components so that users can focus on the weighted perspectives of interest and also empowers a smooth visual transition between varying perspectives to preserve the mental map. We illustrate its application potential in model evaluation and visual-interactive labeling. A comparative analysis is performed to evaluate the DR results.
C1 [Meng, Linhao; van den Elzen, Stef; Pezzotti, Nicola; Vilanova, Anna] Eindhoven Univ Technol, Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Meng, LH (corresponding author), Eindhoven Univ Technol, Eindhoven, Netherlands.
EM l.meng1@tue.nl; s.j.v.d.elzen@tue.nl; n.pezzotti@tue.nl;
   a.vilanova@tue.nl
RI Meng, Linhao/LOR-8016-2024
OI van den Elzen, Stef/0000-0003-1245-0503
CR Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Bengio Y., 2003, P NIPS, P3
   Bernard J., 2018, EUROVIS 2018 SHORT P, DOI [10.2312/eurovisshort.20181085, DOI 10.2312/EUROVISSHORT.20181085]
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122
   Bohm J. N., 2022, Journal of Machine Learning Research, V23, P2
   Cevikalp H, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P489
   Chae J., 2017, P WORKSHOP VISUAL AN
   Chegini M, 2019, VIS INFORM, V3, P9, DOI 10.1016/j.visinf.2019.03.002
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Colange B., 2020, Advances in Neural Information Processing Systems, V33, P3
   de Bodt C., 2019, PROC ESANN
   De Silva V., 2004, Technical report, P3
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Google, 2017, Facets
   Hajderanj L, 2019, PROCEEDINGS OF 2019 8TH INTERNATIONAL CONFERENCE ON SOFTWARE AND INFORMATION ENGINEERING (ICSIE 2019), P232, DOI 10.1145/3328833.3328853
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Iwata T, 2007, NEURAL COMPUT, V19, P2536, DOI 10.1162/neco.2007.19.9.2536
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kaski S, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-48
   Kim H., 2017, P AAAI C ARTIFICIAL, V31, DOI [10.1609/aaai.v31i1.106283, DOI 10.1609/AAAI.V31I1.106283]
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kobak D, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-00809-z
   Le Q., 2014, INT C MACHINE LEARNI
   Le TMV, 2014, AAAI CONF ARTIF INTE, P1960
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meng LH, 2022, COMPUT GRAPH FORUM, V41, P97, DOI 10.1111/cgf.14525
   Paiva JGS, 2011, IEEE T VIS COMPUT GR, V17, P2459, DOI 10.1109/TVCG.2011.212
   Pérez D, 2015, NEUROCOMPUTING, V150, P611, DOI 10.1016/j.neucom.2014.09.061
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Rauber P E, 2016, P EUR IEEE VGTC C VI, P73, DOI DOI 10.2312/EUROVISSHORT.20161164
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Rheingans P, 2000, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2000.885740
   Schneider B, 2017, 2017 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P15, DOI 10.1109/VDS.2017.8573444
   Schreck T, 2007, PROC SPIE, V6495, DOI 10.1117/12.697879
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Seifert C., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining Workshops (ICDMW 2010), P418, DOI 10.1109/ICDMW.2010.181
   Seifert C, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P490, DOI 10.1109/IV.2009.45
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Tatu A., 2010, P AVI, P49, DOI DOI 10.1145/1842993.1843002
   van der Maaten L., 2009, J MACH LEARN RES, P384
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vu Viet Minh, 2022, IEEE Transactions on Artificial Intelligence, V3, P944, DOI 10.1109/TAI.2022.3204734
   Vu VM, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534470
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xiao H., 2017, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
   Yan YY, 2019, IEEE PAC VIS SYMP, P148, DOI 10.1109/PacificVis.2019.00025
   Yang Y, 2017, VIS INFORM, V1, P40, DOI 10.1016/j.visinf.2017.01.005
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
NR 60
TC 3
Z9 3
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 164
EP 174
DI 10.1109/TVCG.2023.3326600
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500052
PM 37874722
OA Green Published
DA 2024-11-06
ER

PT J
AU Vieth, A
   Kroes, T
   Thijssen, J
   van Lew, B
   Eggermont, J
   Basu, S
   Eisemann, E
   Vilanova, A
   Höllt, T
   Lelieveldt, B
AF Vieth, Alexander
   Kroes, Thomas
   Thijssen, Julian
   van Lew, Baldur
   Eggermont, Jeroen
   Basu, Soumyadeep
   Eisemann, Elmar
   Vilanova, Anna
   Hollt, Thomas
   Lelieveldt, Boudewijn
TI ManiVault: A Flexible and Extensible Visual Analytics Framework for
   High-Dimensional Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visual analytics; Software; Graphical user
   interfaces; Task analysis; Spatial databases; Python; High-dimensional
   data; Visualization framework; Progressive analytics; Prototyping system
ID INTERACTIVE VISUALIZATION; EXPLORATION; DESIGN; SYSTEM; LYRA
AB Exploration and analysis of high-dimensional data are important tasks in many fields that produce large and complex data, like the financial sector, systems biology, or cultural heritage. Tailor-made visual analytics software is developed for each specific application, limiting their applicability in other fields. However, as diverse as these fields are, their characteristics and requirements for data analysis are conceptually similar. Many applications share abstract tasks and data types and are often constructed with similar building blocks. Developing such applications, even when based mostly on existing building blocks, requires significant engineering efforts. We developed ManiVault, a flexible and extensible open-source visual analytics framework for analyzing high-dimensional data. The primary objective of ManiVault is to facilitate rapid prototyping of visual analytics workflows for visualization software developers and practitioners alike. ManiVault is built using a plugin-based architecture that offers easy extensibility. While our architecture deliberately keeps plugins self-contained, to guarantee maximum flexibility and re-usability, we have designed and implemented a messaging API for tight integration and linking of modules to support common visual analytics design patterns. We provide several visualization and analytics plugins, and ManiVault's API makes the integration of new plugins easy for developers. ManiVault facilitates the distribution of visualization and analysis pipelines and results for practitioners through saving and reproducing complete application states. As such, ManiVault can be used as a communication tool among researchers to discuss workflows and results.
C1 [Vieth, Alexander; Eisemann, Elmar; Hollt, Thomas; Lelieveldt, Boudewijn] Delft Univ Technol, Delft, Netherlands.
   [Kroes, Thomas; Thijssen, Julian; van Lew, Baldur; Eggermont, Jeroen; Basu, Soumyadeep; Lelieveldt, Boudewijn] Leiden Univ, Med Ctr, Leiden, Netherlands.
   [Vilanova, Anna] TU Eindhoven, Eindhoven, Netherlands.
C3 Delft University of Technology; Leiden University - Excl LUMC; Leiden
   University; Leiden University Medical Center (LUMC); Eindhoven
   University of Technology
RP Vieth, A (corresponding author), Delft Univ Technol, Delft, Netherlands.
EM A.Vieth@tudelft.nl; T.Kroes@lumc.nl; J.G.L.Thijssen@lumc.nl;
   B.van_Lew@lumc.nl; J.Eggermont@lumc.nl; S.Basu@lumc.nl;
   E.Eisemann@tudelft.nl; A.Vilanova@tue.nl; T.Hollt-1@tudelft.nl;
   B.P.F.Lelieveldt@lumc.nl
RI ; Lelieveldt, Boudewijn/B-6501-2008
OI van Lew, Baldur/0000-0003-0628-1264; Kroes, Thomas/0000-0002-0658-2203;
   Vilanova, Anna/0000-0002-1034-737X; /0000-0001-8125-1650; Thijssen,
   Julian/0009-0007-7585-6451; Vieth, Alexander/0000-0002-5809-4316;
   Lelieveldt, Boudewijn/0000-0001-8269-7603
FU NWO
FX No Statement Available
CR Ahlberg C., 1996, SIGMOD Record, V25, P25, DOI 10.1145/245882.245893
   AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P313, DOI 10.1145/191666.191775
   Ahrens J., 2005, Vis. Handb., P717, DOI 10.1016/B978-012387582-2/50038-1
   [Anonymous], 3D SLICER
   Badam SK, 2017, COMPUT GRAPH FORUM, V36, P491, DOI 10.1111/cgf.13205
   Bakken TE, 2021, NATURE, V598, P111, DOI 10.1038/s41586-021-03465-8
   Bavoil L, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P135, DOI 10.1109/visual.2005.1532788
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P156, DOI 10.1109/VISUAL.1991.175794
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Childs H., 2012, VisIt: An EndUser Tool for Visualizing and Analyzing Very Large Data, DOI [10.1201/b12985-29, DOI 10.1201/B12985-29]
   Cook K.A., 2005, Technical Report
   Cui QG, 2006, IEEE T VIS COMPUT GR, V12, P709, DOI 10.1109/TVCG.2006.161
   Cui WQ, 2019, IEEE ACCESS, V7, P81555, DOI 10.1109/ACCESS.2019.2923736
   Eggermont J., Cytosplore Viewer
   Fekete JD, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P167, DOI 10.1109/INFVIS.2004.64
   Fuchs R, 2009, COMPUT GRAPH FORUM, V28, P1670, DOI 10.1111/j.1467-8659.2009.01429.x
   Gahegan M, 2009, CH CRC DATA MIN KNOW, P291
   Ghosh A, 2018, VIS INFORM, V2, P235, DOI 10.1016/j.visinf.2018.12.004
   githubuser0xFFFF, Advanced docking system for Qt
   Heer J., 2005, P SIGCHI C HUM FACT, P421
   Höllt T, 2016, COMPUT GRAPH FORUM, V35, P171, DOI 10.1111/cgf.12893
   Jönsson D, 2020, IEEE T VIS COMPUT GR, V26, P3241, DOI 10.1109/TVCG.2019.2920639
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kerren A, 2014, LECT NOTES COMPUT SC, V8380, P1, DOI 10.1007/978-3-319-06793-3_1
   Kitware, Trame
   Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Lam H, 2018, IEEE T VIS COMPUT GR, V24, P435, DOI 10.1109/TVCG.2017.2744319
   Lampe OD, 2011, IEEE PAC VIS SYMP, P171, DOI 10.1109/PACIFICVIS.2011.5742387
   Landgrebe D. A., HYDICE image of washington dc mall
   Li C, 2023, bioRxiv, DOI [10.1101/2023.03.20.532934, 10.1101/2023.03.20.532934, DOI 10.1101/2023.03.20.532934]
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1075, DOI 10.1109/TVCG.2019.2934631
   Matkovic K, 2008, IEEE INT CONF INF VI, P215, DOI 10.1109/IV.2008.87
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Pezzotti Nicola, 2018, Zenodo, DOI 10.5281/ZENODO.1303855
   Pi M, 2021, IEEE T VIS COMPUT GR, V27, P2186, DOI 10.1109/TVCG.2019.2940580
   Piringer H, 2008, IEEE INT CONF INF VI, P240, DOI 10.1109/IV.2008.17
   Piringer H, 2009, IEEE T VIS COMPUT GR, V15, P1113, DOI 10.1109/TVCG.2009.110
   PLAISANT C, 1995, IEEE SOFTWARE, V12, P21, DOI 10.1109/52.368260
   Plotly Technologies Inc, About us
   Popa A., 2022, PROC GCH, DOI [10.2312/gch.20221233, DOI 10.2312/GCH.20221233]
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Ren DH, 2014, IEEE T VIS COMPUT GR, V20, P2092, DOI 10.1109/TVCG.2014.2346291
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Sakamoto N, 2015, J ADV SIMUL SCI ENG, V2, P76, DOI 10.15748/jasse.2.76
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Schroeder W., 2006, The Visualization Toolkit: An Object-Oriented Approach to 3D Graphics
   Sorger J., 2015, VISION MODELING VISU, P57, DOI DOI 10.2312/VMV.20151258
   Stalling D., 2005, Visualizat. Handbook, V38, P749, DOI DOI 10.1016/B978-012387582-2/50040-X
   Stolper CD, 2014, IEEE T VIS COMPUT GR, V20, P1653, DOI 10.1109/TVCG.2014.2346574
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Sun D, 2020, IEEE T VIS COMPUT GR, V26, P579, DOI 10.1109/TVCG.2019.2934275
   Swayne DF, 2003, COMPUT STAT DATA AN, V43, P423, DOI 10.1016/S0167-9473(02)00286-4
   Tableau Software LLC, About us
   The Qt Company, About us
   Thermo Fisher Scientific, About us
   Thijssen J., 2023, PROC EUROVA, DOI [10.2312/eurova.20231098, DOI 10.2312/EUROVA.20231098]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vieth A, 2022, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis53943.2022.00010
   Visplore GmbH, About us
   Ward M. O., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P326, DOI 10.1109/VISUAL.1994.346302
   Wolfe J. D., 2018, Technical report
   Wong P. C., 1994, SCI VISUALIZATION OV, V2, P3
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yang J, 2003, COMPUT GRAPH-UK, V27, P265, DOI 10.1016/S0097-8493(02)00283-2
   Yang J., 2003, PROC VISSYM, DOI [10.2312/VisSym/VisSym03/019-028, DOI 10.2312/VISSYM/VISSYM03/019-028]
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 73
TC 0
Z9 0
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 175
EP 185
DI 10.1109/TVCG.2023.3326582
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500070
PM 37871056
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Hoque, MN
   Elmqvist, N
AF Hoque, Md Naimul
   Elmqvist, Niklas
TI Dataopsy: Scalable and Fluid Visual Exploration using Aggregate Query
   Sculpting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multidimensional data visualization; multivariate graphs; visual
   queries; visual exploration
ID TABULAR DATA; VISUALIZATION; SEARCH
AB We present aggregate query sculpting (AQS), a faceted visual query technique for large-scale multidimensional data. As a "born scalable" query technique, AQS starts visualization with a single visual mark representing an aggregation of the entire dataset. The user can then progressively explore the dataset through a sequence of operations abbreviated as P6: pivot (facet an aggregate based on an attribute), partition (lay out a facet in space), peek (see inside a subset using an aggregate visual representation), pile (merge two or more subsets), project (extracting a subset into a new substrate), and prune (discard an aggregate not currently of interest). We validate AQS with Dataopsy, a prototype implementation of AQS that has been designed for fluid interaction on desktop and touch-based mobile devices. We demonstrate AQS and Dataopsy using two case studies and three application examples.
C1 [Hoque, Md Naimul; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 University System of Maryland; University of Maryland College Park;
   Aarhus University
RP Hoque, MN (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM nhoque@umd.edu; elm@cs.au.dk
RI Hoque, Md Naimul/JXL-7518-2024
OI Elmqvist, Niklas/0000-0001-5805-5301
FU U.S. National Science Foundation
FX No Statement Available
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   AHLBERG C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P365, DOI 10.1145/191666.191790
   Aris A., 2007, Information Visualization, V6, P281, DOI [DOI 10.1057/PALGRAVE.IVS.95001622,3, DOI 10.1057/palgrave.ivs.9500162]
   Bezerianos A, 2010, COMPUT GRAPH FORUM, V29, P863, DOI 10.1111/j.1467-8659.2009.01687.x
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI [10.1371/journal.pone.0170531, DOI 10.1371/JOURNAL.PONE.0170531]
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Choi J, 2015, IEEE T VIS COMPUT GR, V21, P1087, DOI 10.1109/TVCG.2015.2414454
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, P3
   Dachselt R, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1353
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Drucker S., 2015, Technical Report MSR-TR-2015-65, P2
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Elmqvist N, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P215
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Ghai B, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P3082, DOI 10.1145/3511808.3557155
   Ghai Bhavya, 2023, IEEE Trans Vis Comput Graph, V29, P473, DOI 10.1109/TVCG.2022.3209484
   Ghani S, 2013, IEEE T VIS COMPUT GR, V19, P2032, DOI 10.1109/TVCG.2013.223
   Google People + AI Research, Facets - visualization for ML datasets
   Harrison C, 2010, COMPUTER, V43, P86, DOI 10.1109/MC.2010.158
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Javed W, 2013, COMPUT GRAPH FORUM, V32, P441, DOI 10.1111/cgf.12131
   Kairam S, 2015, COMPUT GRAPH FORUM, V34, P301, DOI 10.1111/cgf.12642
   Kumar S, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P933, DOI 10.1145/3178876.3186141
   Lee B., 2021, AK Peters Visulization Series, P1
   Lee B, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1293
   Liu ZC, 2014, INFORM VISUAL, V13, P59, DOI 10.1177/1473871613488591
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Munzner T., 2014, AK Peters Visualization Series, P2
   New York City Taxi & Limousine Commission, 2023, TLC trip record data [WWW Document]
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Norman D. A., 1986, User Centered System Design: New Perspectives on Human-Computer Interaction, P3
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Pandey Aditeya, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209421
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Rosario G. E., 2004, Information Visualization, V3, P80, DOI 10.1057/palgrave.ivs.9500072
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Seo J, 2002, COMPUTER, V35, P80
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Shneiderman B, 2006, IEEE T VIS COMPUT GR, V12, P733, DOI 10.1109/TVCG.2006.166
   Smith G, 2006, IEEE T VIS COMPUT GR, V12, P797, DOI 10.1109/TVCG.2006.142
   Stolte C, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P5, DOI 10.1109/INFVIS.2000.885086
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wexler J., Facets: An open source visualization tool for machine learning training data
   WILLIAMSON C, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P338
   Yalçin MA, 2016, IEEE T VIS COMPUT GR, V22, P688, DOI 10.1109/TVCG.2015.2467051
   Yalçin MA, 2018, IEEE T VIS COMPUT GR, V24, P2339, DOI 10.1109/TVCG.2017.2723393
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI [DOI 10.1145/642611.642681, 10.1145/642611.642681]
   Zhang ZY, 2012, IEEE PAC VIS SYMP, P17
NR 54
TC 2
Z9 2
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 186
EP 196
DI 10.1109/TVCG.2023.3326594
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500125
PM 37871052
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Epperson, W
   Gorantla, V
   Moritz, D
   Perer, A
AF Epperson, Will
   Gorantla, Vaishnavi
   Moritz, Dominik
   Perer, Adam
TI Dead or Alive: Continuous Data Profiling for Interactive Data Science
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Codes; Data visualization; Data models; Visualization; Programming;
   Manuals; Data science; Data Profiling; Data Quality; Exploratory Data
   Analysis; Interactive Data Science
ID VISUALIZATION
AB Profiling data by plotting distributions and analyzing summary statistics is a critical step throughout data analysis. Currently, this process is manual and tedious since analysts must write extra code to examine their data after every transformation. This inefficiency may lead to data scientists profiling their data infrequently, rather than after each transformation, making it easy for them to miss important errors or insights. We propose continuous data profiling as a process that allows analysts to immediately see interactive visual summaries of their data throughout their data analysis to facilitate fast and thorough analysis. Our system, AutoProfiler, presents three ways to support continuous data profiling: (1) it automatically displays data distributions and summary statistics to facilitate data comprehension; (2) it is live, so visualizations are always accessible and update automatically as the data updates; (3) it supports follow up analysis and documentation by authoring code for the user in the notebook. In a user study with 16 participants, we evaluate two versions of our system that integrate different levels of automation: both automatically show data profiles and facilitate code authoring, however, one version updates reactively ("live") and the other updates only on demand ("dead"). We find that both tools, dead or alive, facilitate insight discovery with 91% of user-generated insights originating from the tools rather than manual profiling code written by users. Participants found live updates intuitive and felt it helped them verify their transformations while those with on-demand profiles liked the ability to look at past visualizations. We also present a longitudinal case study on how AutoProfiler helped domain scientists find serendipitous insights about their data through automatic, live data profiles. Our results have implications for the design of future tools that offer automated data analysis support.
C1 [Epperson, Will; Gorantla, Vaishnavi; Moritz, Dominik; Perer, Adam] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Epperson, W (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM willepp@cmu.edu; vaishnag@andrew.cmu.edu; domoritz@cmu.edu;
   adamperer@cmu.edu
OI Perer, Adam/0000-0002-8369-3847; Moritz, Dominik/0000-0002-3110-1053
FU Brookhaven National Laboratory
FX No Statement Available
CR 8080 Labs, 2020, bamboolib
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Anaconda Foundation, 2020, The state of data science 2020: Moving from hype toward maturity
   Apache Arrow, 2023, Pyarrow - apache arrow python bindings
   Bailis P. D., 2017, 8 BIENN C INN DAT SY, P1
   Bertrand F., sweetviz
   DeLine R, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P111, DOI 10.1109/VLHCC.2015.7357205
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   EPPerson W, 2022, COMPUT GRAPH FORUM, V41, P145, DOI 10.1111/cgf.14529
   Epperson W, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2022), P243, DOI [10.1145/3510457.3513042, 10.1109/ICSE-SEIP55303.2022.9793945]
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Forsgren Nicole, 2021, ACM Queue, V19, P20, DOI 10.1145/3454122.3454124
   Github, Github copilot - your ai pair programmer
   Head A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300500
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hellerstein J. M., 2008, Quantitative data cleaning for large databases, P2
   Hermans F, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 5, P56, DOI 10.1109/SANER.2016.86
   Hohman F, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376177
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kery MB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1265, DOI 10.1145/3025453.3025626
   Kery Mary Beth, 2020, P 33 ANN ACM S US IN, DOI DOI 10.1145/3379337.3415842
   Kiapour MH, 2014, IEEE WINT CONF APPL, P933, DOI 10.1109/WACV.2014.6836004
   Kim M, 2018, IEEE T SOFTWARE ENG, V44, P1024, DOI 10.1109/TSE.2017.2754374
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Li XJ, 2023, ACM T INTERACT INTEL, V13, DOI 10.1145/3545995
   Maloney J. H., 1995, ACM S US INT SOFTW T
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Pandas, Pandas: Python data analysis library
   Pandas-Profiling, pandas-profiling
   Peng JL, 2021, INT CONF MANAGE DATA, P2271, DOI 10.1145/3448016.3457330
   Pennington K., Bay area craigslist posts, 2000 - 2018
   Perkel J. M., 2018, Nature News, DOI DOI 10.1038/D41586-018-07196-11,2,3
   Ono JP, 2021, COMPUT SCI ENG, V23, P99, DOI 10.1109/MCSE.2021.3052619
   Pimentel Joao Felipe, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P507, DOI 10.1109/MSR.2019.00077
   Polars, Polars, lightning-fast dataframe library
   Raasveldt M., 2021, Efficient SQL on Pandas with DuckDB - duckdb.org
   Rill Data, Rill developer
   Rose A., PandasGUI
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Seltman H., 2018, Experimental design and analysis, P2
   Shankar S, 2022, Arxiv, DOI [arXiv:2209.09125, DOI 10.48550/ARXIV.2209.09125, 10.48550/arXiv.2209.09125]
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Sveltejs, 2016, Svelte: cybernetically enhanced web apps
   TUKEY JW, 1980, AM STAT, V34, P23, DOI 10.2307/2682991
   Wang AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502123
   Wongsuphasawat K, 2019, Arxiv, DOI arXiv:1911.00568
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu Y., 2020, ACM USER INTERFACE S, DOI DOI 10.1145/3379337.34158513,4
NR 51
TC 3
Z9 3
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 197
EP 207
DI 10.1109/TVCG.2023.3327367
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500006
PM 37903042
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Kale, A
   Guo, ZY
   Qiao, XL
   Heer, J
   Hullman, J
AF Kale, Alex
   Guo, Ziyang
   Qiao, Xiao Li
   Heer, Jeffrey
   Hullman, Jessica
TI EVM: Incorporating Model Checking into Exploratory Visual Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; model checks; exploratory analysis
ID INFERENCE; SELECTION; VISUALIZATION; PLOTS
AB Visual analytics (VA) tools support data exploration by helping analysts quickly and iteratively generate views of data which reveal interesting patterns. However, these tools seldom enable explicit checks of the resulting interpretations of data-e.g., whether patterns can be accounted for by a model that implies a particular structure in the relationships between variables. We present EVM, a data exploration tool that enables users to express and check provisional interpretations of data in the form of statistical models. EVM integrates support for visualization-based model checks by rendering distributions of model predictions alongside user-generated views of data. In a user study with data scientists practicing in the private and public sector, we evaluate how model checks influence analysts' thinking during data exploration. Our analysis characterizes how participants use model checks to scrutinize expectations about data generating process and surfaces further opportunities to scaffold model exploration in VA tools.
C1 [Kale, Alex] Univ Chicago, Chicago, IL 60637 USA.
   [Guo, Ziyang; Qiao, Xiao Li; Hullman, Jessica] Northwestern Univ, Evanston, IL USA.
   [Heer, Jeffrey] Univ Washington, Seattle, WA USA.
C3 University of Chicago; Northwestern University; University of
   Washington; University of Washington Seattle
RP Kale, A (corresponding author), Univ Chicago, Chicago, IL 60637 USA.
EM kalea@uchicago.edu; ziyangguo2027@u.northwestern.edu; emqiao@gmail.com;
   jheer@uw.edu; jhullman@northwestern.edu
RI Hullman, Jessica/P-7130-2018
OI Heer, Jeffrey/0000-0002-6175-1655; Hullman, Jessica/0000-0001-6826-3550;
   Guo, Ziyang/0009-0004-4200-6774
FU NSF
FX No Statement Available
CR Alvarez GA, 2011, TRENDS COGN SCI, V15, P122, DOI 10.1016/j.tics.2011.01.003
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Becker R. A., 1987, Statistical Science, V4, P355, DOI [DOI 10.1214/SS/1177013104, 10.1214/ ss/1177013104.]
   Becker Richard A, 1996, Journal of computational and Graphical Statistics, V5, P123, DOI DOI 10.1080/10618600.1996.10474701TISTICS
   Berk R, 2013, ANN STAT, V41, P802, DOI 10.1214/12-AOS1077
   Buja A., 1987, P 18 S INT, P171
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Choi IK, 2019, IEEE INT CONF INF VI, P116, DOI 10.1109/IV-2.2019.00032
   Choi IK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300298
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Cortez P, 2007, P 13 EPIA 2007 PORT
   Cortez P, 2008, 15TH EUROPEAN CONCURRENT ENGINEERING CONFERENCE/5TH FUTURE BUSINESS TECHNOLOGY CONFERENCE, P5
   Devezer B, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.200805
   Dua D, 2017, UCI MACHINE LEARNING
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   Gelman A, 2004, J COMPUT GRAPH STAT, V13, P755, DOI 10.1198/106186004X11435
   Gelman A, 2003, INT STAT REV, V71, P369
   Gelman A., 2013, The garden of forking paths: Why multiple comparisons can be a problem, even when there is no "fishing expedition"or "p-hacking"and the research hypothesis was posited ahead of time, V348, P3
   Gelman A., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2011.0180815, 10.48550/arXiv.2011.01808, DOI 10.48550/ARXIV.2011.01808]
   Green T. R. G., 1990, P 5 C BRIT COMP SOC, P9
   Guo G, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581236
   Harrell FE., 2001, Regression Modeling Strategies: With Applications to Linear Models, Logistic Regression and Survival Analysis, P53, DOI DOI 10.1007/978-1-4757-3462-1
   Hullman J., 2021, Harvard Data Science Review, DOI DOI 10.1162/99608F92.3AB8A5871,2,3,9
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Jun E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501888
   Kale A., 2022, IEEE Trans. on Visualization and Computer Graphics, V28, DOI DOI 10.1109/TVCG.2021.31148242
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kibler D., 1989, Computational Intelligence, V5, P5
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300912
   Koonchanok R., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.34457982,6,8,9
   Kraska T, 2018, PROC VLDB ENDOW, V11, P2150, DOI 10.14778/3229863.3240493
   Loy A, 2016, AM STAT, V70, P202, DOI 10.1080/00031305.2015.1077728
   Majumder M, 2013, J AM STAT ASSOC, V108, P942, DOI 10.1080/01621459.2013.808157
   McNutt A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445356
   McNutt Andrew M, 2023, IEEE Trans Vis Comput Graph, V29, P160, DOI 10.1109/TVCG.2022.3209460
   MILLER AJ, 1984, J ROY STAT SOC A STA, V147, P389, DOI 10.2307/2981576
   Nguyen F, 2020, COMPUT GRAPH FORUM, V39, P33, DOI 10.1111/cgf.13902
   Oberauer K, 2019, PSYCHON B REV, V26, P1596, DOI 10.3758/s13423-019-01645-2
   Ooms J, 2014, Arxiv, DOI arXiv:1406.4806
   Pinheiro J., 2020, Linear and Nonlinear Mixed Effects Models, V3, P5
   Pu XY, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P37
   Rigby RA, 2005, J ROY STAT SOC C, V54, P507, DOI 10.1111/j.1467-9876.2005.00510.x
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Simmons JP, 2011, PSYCHOL SCI, V22, P1359, DOI 10.1177/0956797611417632
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Talbot J., personal communication, P3
   Tibshirani RJ, 2016, J AM STAT ASSOC, V111, P600, DOI 10.1080/01621459.2015.1108848
   Tukey J. W., P NOV 7 10 1966 FALL, P695, DOI DOI 10.1145/1464291.14643662
   Tukey J. W., 1972, P 18 C DES EXP ARM R, V1010, P2
   TUKEY JW, 1972, Q APPL MATH, V30, P51, DOI 10.1090/qam/99740
   Tukey JW., 1977, EXPLORATORY DATA ANA
   Vanderplas S., 2021, Harvard Data Science Review, P1, DOI DOI 10.1162/99608F92.7D099FD02
   VanderPlas S, 2017, J COMPUT GRAPH STAT, V26, P231, DOI 10.1080/10618600.2016.1209116
   Velleman PF, 2012, WIRES COMPUT STAT, V4, P407, DOI 10.1002/wics.1208
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wickham H., 2019, J. Open Source Softw, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]
   Wickham H, 2015, STAT ANAL DATA MIN, V8, P203, DOI 10.1002/sam.11271
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Wilkinson L., 2005, The Grammar of Graphics, DOI DOI 10.1007/0-387-28695-03,4,8
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu Y., 2017, IEEE VIS WORKSH DEAL, P2
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yarkoni T, 2017, PERSPECT PSYCHOL SCI, V12, P1100, DOI 10.1177/1745691617693393
   Zgraggen E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174053
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
   Zhao ZG, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P527, DOI 10.1145/3035918.3064019
NR 70
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 208
EP 218
DI 10.1109/TVCG.2023.3326516
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500107
PM 37871070
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Teng, X
   Ahn, Y
   Lin, YR
AF Teng, Xian
   Ahn, Yongsu
   Lin, Yu-Ru
TI V: Visual Aids for Identifying and Interpreting Spurious Associations in
   Data-Driven Decisions&lt;sc/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Decision making; Training; Interviews; Cognition;
   Machine learning; Systematics; Causal Analysis; Simpson's Paradox;
   Spurious Associations; Machine Learning; Decision Making
ID PROPENSITY SCORE; CAUSAL INFERENCE; SIMPSONS PARADOX; EXPLORATION; BIAS
AB Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose Vispur, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a Confounder Dashboard, which can automatically identify possible confounding factors, and a Subgroup Viewer, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a Reasoning Storyboard, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive Decision Diagnosis panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed "de-paradox" workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.
C1 [Teng, Xian; Ahn, Yongsu; Lin, Yu-Ru] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Teng, X (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM xit22@pitt.edu; yongsu.ahn@pitt.edu; yurulin@pitt.edu
OI Lin, Yu-Ru/0000-0002-8497-3015; Ahn, Yongsu/0000-0002-5797-5445
FU AFOSR
FX No Statement Available
CR Ahn Y, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484509
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Armstrong Z, 2014, IEEE T VIS COMPUT GR, V20, P2132, DOI 10.1109/TVCG.2014.2346297
   Athey S, 2019, ANN STAT, V47, P1148, DOI 10.1214/18-AOS1709
   Athey S, 2016, P NATL ACAD SCI USA, V113, P7353, DOI 10.1073/pnas.1510489113
   Austin PC, 2019, STAT METHODS MED RES, V28, P1365, DOI 10.1177/0962280218756159
   Austin PC, 2015, STAT MED, V34, P3661, DOI 10.1002/sim.6607
   Baker SG, 2001, J WOMEN HEALTH GEN-B, V10, P867, DOI 10.1089/152460901753285769
   Battocchi K., 2019, EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation
   BICKEL PJ, 1975, SCIENCE, V187, P398, DOI 10.1126/science.187.4175.398
   Blumenschein M, 2018, IEEE CONF VIS ANAL, P36, DOI 10.1109/VAST.2018.8802486
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   Cao N, 2018, INFORM VISUAL, V17, P22, DOI 10.1177/1473871616686635
   Chen HG, 2020, Arxiv, DOI arXiv:2002.11631
   Chen M, 2011, COMPUTER, V44, P83, DOI 10.1109/MC.2011.313
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Clark WR, 2015, PS-POLIT SCI POLIT, V48, P65, DOI 10.1017/S1049096514001759
   Cole SR, 2009, EPIDEMIOLOGY, V20, P3, DOI 10.1097/EDE.0b013e31818ef366
   Cookson R, 2021, J HEALTH ORGAN MANAG, V35, P665, DOI 10.1108/JHOM-07-2020-0275
   Dang Tuan Nhon, 2015, BMC Proc, V9, pS6, DOI 10.1186/1753-6561-9-S6-S6
   DeGrave AJ, 2021, NAT MACH INTELL, V3, P610, DOI 10.1038/s42256-021-00338-7
   Dehejia RH, 1999, J AM STAT ASSOC, V94, P1053, DOI 10.2307/2669919
   Dehejia RH, 2002, REV ECON STAT, V84, P151, DOI 10.1162/003465302317331982
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Fong C, 2018, ANN APPL STAT, V12, P156, DOI 10.1214/17-AOAS1101
   Friendly M, 2013, STAT SCI, V28, P1, DOI 10.1214/12-STS402
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Gerring J, 2005, J THEOR POLIT, V17, P163, DOI 10.1177/0951629805050859
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Greenland S, 2003, EPIDEMIOLOGY, V14, P300, DOI 10.1097/00001648-200305000-00009
   Greifer N., 2023, Cobalt: Covariate balance tables and plots (4.5.1) Computer software
   Guo G., 2023, EUROPEAN CODE CONDUC, P1, DOI DOI 10.1145/3544548.35812362,3,5,7
   Guo G, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P21, DOI 10.1109/VIS49827.2021.9623285
   Heckman JJ, 1997, REV ECON STUD, V64, P605, DOI 10.2307/2971733
   Hernan MA, 2020, Causal Inference: What If
   Ho DE, 2011, J STAT SOFTW, V42
   Imai K, 2014, J R STAT SOC B, V76, P243, DOI 10.1111/rssb.12027
   Imbens G.W, 2010, Microeconometrics, P229
   Inselberg A., 2009, IEEE Trans Hum Mach Syst, P199, DOI [10.1007/978-0-387-68628-8, DOI 10.1007/978-0-387-68628-8]
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Joshi N., 2022, arXiv
   Kale A., 2021, IEEE Trans. Visual Comput. Graphics, DOI DOI 10.1109/TVCG.2021.31148242,3
   Kery Mary Beth, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383085
   Kiciman E., NEURIPS 2022 WORKSHO, V3
   Kievit RA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00513
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Künzel SR, 2019, P NATL ACAD SCI USA, V116, P4156, DOI 10.1073/pnas.1804597116
   Kwon BC, 2022, IEEE VIS CONF, P50, DOI 10.1109/VIS54862.2022.00019
   Kwon BC, 2021, IEEE T VIS COMPUT GR, V27, P3685, DOI 10.1109/TVCG.2020.2985689
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   LALONDE RJ, 1986, AM ECON REV, V76, P604
   Lerman K, 2018, J COMPUT SOC SCI, V1, P49, DOI 10.1007/s42001-017-0007-4
   Lesser L. M., 2001, Representations of reversal: An exploration of Simpson's paradox
   Microsoft Research, 2022, Introduction to ShowWhy, user interfaces for causal decision making
   Moris J., 2021, Israeli data: How can efficacy vs. severe disease be strong when 60% of hospitalized are vaccinated?
   Norton H. J., 2015, Significance, V12, P40
   Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342
   Oprescu M, 2019, PR MACH LEARN RES, V97
   Park Y, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.3909
   Pearl J, 1995, BIOMETRIKA, V82, P669, DOI 10.2307/2337329
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   ROSENBAUM PR, 1983, BIOMETRIKA, V70, P41, DOI 10.1093/biomet/70.1.41
   Rücker G, 2008, BMC MED RES METHODOL, V8, DOI 10.1186/1471-2288-8-79
   RuM F., 1980, Math. Mag., V53, P106, DOI [DOI 10.2307/26899592,3,12,13, 10.2307/26899593,12,13]
   Sharma A, 2020, Arxiv, DOI arXiv:2011.04216
   Shimoni Y, 2019, Arxiv, DOI arXiv:1906.00442
   Syrgkanis V., 2019, NeurIPS, V32, DOI DOI 10.48550/ARXIV.1905.10176
   VanderWeele TJ, 2013, J CAUSAL INFERENCE, V1, P1, DOI 10.1515/jci-2012-0002
   Wager S, 2018, J AM STAT ASSOC, V113, P1228, DOI 10.1080/01621459.2017.1319839
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wang ZJ, 2022, Arxiv, DOI arXiv:2205.03963
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Xie X, 2020, Arxiv, DOI arXiv:2008.11899
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
NR 76
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 219
EP 229
DI 10.1109/TVCG.2023.3326587
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500009
PM 37871075
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Newburger, E
   Elmqvist, N
AF Newburger, Eric
   Elmqvist, Niklas
TI Visualization According to Statisticians: An Interview Study on the Role
   of Visualization for Inferential Statistics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Interviews; Visualization; Industries; Encoding;
   Cognitive science; Codes; Inferential statistics; qualitative interview
   study; thematic coding; statistical visualization
ID INFORMATION VISUALIZATION; VISUAL REPRESENTATIONS
AB Statisticians are not only one of the earliest professional adopters of data visualization, but also some of its most prolific users. Understanding how these professionals utilize visual representations in their analytic process may shed light on best practices for visual sensemaking. We present results from an interview study involving 18 professional statisticians (19.7 years average in the profession) on three aspects: (1) their use of visualization in their daily analytic work; (2) their mental models of inferential statistical processes; and (3) their design recommendations for how to best represent statistical inferences. Interview sessions consisted of discussing inferential statistics, eliciting participant sketches of suitable visual designs, and finally, a design intervention with our proposed visual designs. We analyzed interview transcripts using thematic analysis and open coding, deriving thematic codes on statistical mindset, analytic process, and analytic toolkit. The key findings for each aspect are as follows: (1) statisticians make extensive use of visualization during all phases of their work (and not just when reporting results); (2) their mental models of inferential methods tend to be mostly visually based; and (3) many statisticians abhor dichotomous thinking. The latter suggests that a multi-faceted visual display of inferential statistics that includes a visual indicator of analytically important effect sizes may help to balance the attributed epistemic power of traditional statistical testing with an awareness of the uncertainty of sensemaking.
C1 [Newburger, Eric] US Naval Acad, Annapolis, MD 21402 USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 United States Department of Defense; United States Navy; United States
   Naval Academy; Aarhus University
RP Newburger, E (corresponding author), US Naval Acad, Annapolis, MD 21402 USA.
EM enewburg@terpmail.umd.edu; elm@cs.au.dk
OI Newburger, Eric/0000-0001-8777-0363; Elmqvist,
   Niklas/0000-0001-5805-5301
CR Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   [Anonymous], 1908, BIOMETRIKA, V6, P1
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Buja A, 2009, PHILOS T R SOC A, V367, P4361, DOI 10.1098/rsta.2009.0120
   Calin-Jageman RJ, 2019, AM STAT, V73, P271, DOI 10.1080/00031305.2018.1518266
   Casella G., 2001, Statistical Inference, V2nd, P2
   Cleveland WS., 1993, VISUALIZING DATA
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   Correll M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1387, DOI 10.1145/3025453.3025922
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Fisher R. A., 1922, Philos. Trans. R. Soc. Lond. A, Contain. Pap. Math. Phys. Character, V222, P309, DOI [10.1098/rsta.1922.0009, DOI 10.1098/RSTA.1922.0009]
   Gaver B., 1999, Interactions, V6, P21, DOI [10.1145/291224.291235, DOI 10.1145/291224.291235]
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2316, DOI 10.1109/TVCG.2013.183
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Hald A., 1998, Probability and Statistics, P2
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   JayneWallace John McCarthy, 2013, P SIGCHI C HUM FACT, P3441, DOI DOI 10.1145/2470654.2466473
   Lazar J., 2017, Research Methods in HumanComputer Interaction, V2, P3
   Lehmann E. L., 2005, Testing Statistical Hypotheses, V3rd, P2
   Mustafa R. Y., 1996, Journal of Statistics Education, V4, DOI DOI 10.1080/10691898.1996.11910504
   Newburger E., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.32107635, DOI 10.1109/TVCG.2022.32107635]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Scaife M, 1996, INT J HUM-COMPUT ST, V45, P185, DOI 10.1006/ijhc.1996.0048
   Schervish MJ., 1995, THEORY STAT, DOI DOI 10.1007/978-1-4612-4250-5
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sullivan Gail M, 2012, J Grad Med Educ, V4, P279, DOI 10.4300/JGME-D-12-00156.1
   Tukey JW., 1977, EXPLORATORY DATA ANA
   Wickham H, 2010, IEEE T VIS COMPUT GR, V16, P973, DOI 10.1109/TVCG.2010.161
NR 32
TC 0
Z9 0
U1 4
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 230
EP 239
DI 10.1109/TVCG.2023.3326521
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500098
PM 37871077
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, YX
   Yang, WK
   Chen, JS
   Chen, CJ
   Shen, ZY
   Luo, XN
   Yu, LY
   Liu, SX
AF Zhou, Yuxing
   Yang, Weikai
   Chen, Jiashu
   Chen, Changjian
   Shen, Zhiyang
   Luo, Xiaonan
   Yu, Lingyun
   Liu, Shixia
TI Cluster-Aware Grid Layout
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Grid layout; similarity; convexity; compactness; optimization
ID CONVEXITY MEASURE; VISUALIZATION
AB Grid visualizations are widely used in many applications to visually explain a set of data and their proximity relationships. However, existing layout methods face difficulties when dealing with the inherent cluster structures within the data. To address this issue, we propose a cluster-aware grid layout method that aims to better preserve cluster structures by simultaneously considering proximity, compactness, and convexity in the optimization process. Our method utilizes a hybrid optimization strategy that consists of two phases. The global phase aims to balance proximity and compactness within each cluster, while the local phase ensures the convexity of cluster shapes. We evaluate the proposed grid layout method through a series of quantitative experiments and two use cases, demonstrating its effectiveness in preserving cluster structures and facilitating analysis tasks.
C1 [Zhou, Yuxing; Yang, Weikai; Chen, Jiashu; Shen, Zhiyang; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
   [Chen, Changjian] Kuaishou Technol, Beijing, Peoples R China.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Guilin, Peoples R China.
   [Yu, Lingyun] Xian Jiaotong Liverpool Univ, Suzhou, Peoples R China.
C3 Tsinghua University; Guilin University of Electronic Technology; Xi'an
   Jiaotong-Liverpool University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing, Peoples R China.
EM yx-zhou19@mails.tsinghua.edu.cn; yangwk21@mails.tsinghua.edu.cn;
   cjs22@mails.tsinghua.edu.cn; chenchangjian@kuaishou.com;
   shenzhiy21@mails.tsinghua.edu.cn; luoxn@guet.edu.cn;
   lingyun.yu@xjtlu.edu.cn; shixia@tsinghua.edu.cn
RI Liu, Shi-Xia/C-5574-2016; Chen, Changjian/KBA-9462-2024; Zhou,
   Yuxing/AAA-3958-2020; Li, Zexi/KFA-6939-2024
OI Chen, Changjian/0000-0003-2715-8839
FU National Natural Science Foundation of China
FX No Statement Available
CR Barthel KU, 2023, COMPUT GRAPH FORUM, V42, P261, DOI 10.1111/cgf.14718
   Barthel K. U., 2019, Big Data Analytics for Large-Scale Multimedia Search, P289, DOI [10.1002/9781119376996.ch112, DOI 10.1002/9781119376996.CH112]
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Bozeman J. R., 2013, Scientiae Mathematicae Japonicae, V76, P47, DOI DOI 10.32219/ISMS.76.1_472,3
   Chan GYY, 2020, IEEE T VIS COMPUT GR, V26, P981, DOI 10.1109/TVCG.2019.2934280
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Choi J, 2023, IEEE T VIS COMPUT GR, V29, P1424, DOI 10.1109/TVCG.2021.3116656
   Corrado A., 2019, Animals-10 dataset
   Do Carmo M. P., 2016, Differential geometry of curves and surfaces: revised and updated, V2, P3
   Efrat A, 2014, LECT NOTES COMPUT SC, V8871, P452, DOI 10.1007/978-3-662-45803-7_38
   Eppstein David, 2015, International Journal of Computational Geometry & Applications, V25, P101, DOI 10.1142/S0218195915500077
   Felix C, 2017, IEEE T VIS COMPUT GR, V23, P161, DOI 10.1109/TVCG.2016.2598447
   Frey S, 2022, COMPUT GRAPH FORUM, V41, P247, DOI 10.1111/cgf.14537
   Fried O, 2015, COMPUT GRAPH FORUM, V34, P155, DOI 10.1111/cgf.12549
   Halnaut A, 2022, IEEE INT CONF INF VI, P11, DOI 10.1109/IV56949.2022.00012
   HELD A, 1994, PATTERN RECOGN LETT, V15, P611, DOI 10.1016/0167-8655(94)90022-1
   Hilasaca GM, 2021, Arxiv, DOI arXiv:1903.06262
   Hlavac V., 2014, Cengage Learning, V2, P3
   Huang Jinbin, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209384
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Itoh T, 2009, IEEE PAC VIS SYMP, P121, DOI 10.1109/PACIFICVIS.2009.4906846
   Kanizsa G., 1976, Vision and artifact, P25
   Keefe DF, 2009, IEEE T VIS COMPUT GR, V15, P1383, DOI 10.1109/TVCG.2009.152
   Kehlbeck R, 2022, IEEE T VIS COMPUT GR, V28, P433, DOI 10.1109/TVCG.2021.3114834
   Krizhevsky A., 2009, Cifar-100 dataset
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SC, 2019, AAAI CONF ARTIF INTE, P9977
   Liu XT, 2018, COMPUT GRAPH FORUM, V37, P7, DOI 10.1111/cgf.12526
   Lu M, 2020, IEEE T VIS COMPUT GR, V26, P770, DOI 10.1109/TVCG.2019.2934811
   Major T, 2019, IEEE T VIS COMPUT GR, V25, P576, DOI 10.1109/TVCG.2018.2865151
   Matejka J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173943
   Meulemans W, 2017, IEEE T VIS COMPUT GR, V23, P381, DOI 10.1109/TVCG.2016.2598542
   Muelder C, 2008, IEEE T VIS COMPUT GR, V14, P1301, DOI 10.1109/TVCG.2008.158
   Oppermann M, 2022, IEEE T VIS COMPUT GR, V28, P747, DOI 10.1109/TVCG.2021.3114841
   Pan XJ, 2021, IEEE T VIS COMPUT GR, V27, P2298, DOI 10.1109/TVCG.2019.2948611
   Peura M., 1997, Proceedings of the Third International Workshop on Visual Form. Advances in Visual Form Analysis, P443
   Quadrianto N., 2008, P ADV NEURAL INFORM, P1
   Radford A, 2021, PR MACH LEARN RES, V139
   Rahtu E, 2006, IEEE T PATTERN ANAL, V28, P1501, DOI 10.1109/TPAMI.2006.175
   Rosin PL, 2007, IET IMAGE PROCESS, V1, P182, DOI 10.1049/iet-ipr:20060185
   Rosin PL, 2006, COMPUT VIS IMAGE UND, V103, P101, DOI 10.1016/j.cviu.2006.04.002
   Rottmann Peter, 2023, IEEE Trans Vis Comput Graph, V29, P875, DOI 10.1109/TVCG.2022.3209485
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   Song H, 2017, IEEE T VIS COMPUT GR, V23, P311, DOI 10.1109/TVCG.2016.2598796
   Song Y, 2023, IEEE T VIS COMPUT GR, V29, P1330, DOI 10.1109/TVCG.2021.3113031
   Strong G, 2014, IEEE T MULTIMEDIA, V16, P1045, DOI 10.1109/TMM.2014.2306183
   Todorovic D., 2008, SCHOLARPEDIA, V3, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   Torralba A, 2009, VISUAL NEUROSCI, V26, P123, DOI 10.1017/S0952523808080930
   Tu Y., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.32251142
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Yoghourdjian V, 2016, IEEE T VIS COMPUT GR, V22, P339, DOI 10.1109/TVCG.2015.2467251
   Yuan Jun, 2023, IEEE Trans Vis Comput Graph, V29, P288, DOI 10.1109/TVCG.2022.3209404
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zunic J, 2004, IEEE T PATTERN ANAL, V26, P923, DOI 10.1109/TPAMI.2004.19
   Zunic J, 2020, IEEE T PATTERN ANAL, V42, P1394, DOI 10.1109/TPAMI.2019.2898830
NR 61
TC 2
Z9 3
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 240
EP 250
DI 10.1109/TVCG.2023.3326934
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500136
PM 37871055
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Jin, YZ
   de Jong, TJA
   Tennekes, M
   Chen, M
AF Jin, Yuanzhe
   de Jong, Tim J. A.
   Tennekes, Martijn
   Chen, Min
TI Radial Icicle Tree (RIT): Node Separation and Area Constancy
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tree visualization; icicle tree; sunburst tree; size encoding; area
   constancy; node separation; radial icicle tree; RIT
ID PLOTS
AB Icicles and sunbursts are two commonly-used visual representations of trees. While icicle trees can map data values faithfully to rectangles of different sizes, often some rectangles are too narrow to be noticed easily. When an icicle tree is transformed into a sunburst tree, the width of each rectangle becomes the length of an annular sector that is usually longer than the original width. While sunburst trees alleviate the problem of narrow rectangles in icicle trees, it no longer maintains the consistency of size encoding. At different tree depths, nodes of the same data values are displayed in annular sections of different sizes in a sunburst tree, though they are represented by rectangles of the same size in an icicle tree. Furthermore, two nodes from different subtrees could sometimes appear as a single node in both icicle trees and sunburst trees. In this paper, we propose a new visual representation, referred to as radial icicle tree (RIT), which transforms the rectangular bounding box of an icicle tree into a circle, circular sector, or annular sector while introducing gaps between nodes and maintaining area constancy for nodes of the same size. We applied the new visual design to several datasets. Both the analytical design process and user-centered evaluation have confirmed that this new design has improved the design of icicles and sunburst trees without introducing any relative demerit.
C1 [Jin, Yuanzhe; Chen, Min] Univ Oxford, Oxford, England.
   [de Jong, Tim J. A.; Tennekes, Martijn] Stat Netherlands, The Hague, Netherlands.
C3 University of Oxford
RP Jin, YZ (corresponding author), Univ Oxford, Oxford, England.
EM yuanzhe.jin@eng.ox.ac.uk; tja.dejong@cbs.nl; m.tennekes@cbs.nl;
   min.chen@eng.ox.ac.uk
RI Jin, Yuan-Zhe/P-9666-2019
FU Network of European Data Scientists (NeEDS)
FX No Statement Available
CR Abbas SS, 2013, VISION RES, V91, P84, DOI 10.1016/j.visres.2013.08.001
   Andrews K., 1998, P IEEE S INF VIS LAT, P9
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Brinton W. C., 1939, Graphic presentation, P2
   Cawthon N, 2007, IEEE INT CONF INF VI, P637
   Chen M., 2019, Computer Graphics Forum, V38, P2
   Chen M., 2020, Foundations of Data Visualization, P2
   Chen M, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020228
   Chen M, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24020282
   Chen M, 2016, IEEE T VIS COMPUT GR, V22, P2619, DOI 10.1109/TVCG.2015.2513410
   Chevalier F., 2007, P INT WORKSH PRINC S, P90
   Chi E. H., 1998, P SIGCHI C HUM FACT, P400
   Chuah MC, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P35, DOI 10.1109/INFVIS.1998.729557
   Correll M., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   Culy C, 2010, IEEE INT CONF INF VI, P98, DOI 10.1109/IV.2010.24
   Dasgupta A, 2012, COMPUT GRAPH FORUM, V31, P1015, DOI 10.1111/j.1467-8659.2012.03094.x
   Ducheyne S, 2009, J DOC, V65, P223, DOI 10.1108/00220410910937598
   Gou L, 2011, IEEE T VIS COMPUT GR, V17, P2449, DOI 10.1109/TVCG.2011.247
   Johnson B. S., 1993, Treemaps: Visualizing Hierarchical and Categorical Data, P2
   Kanjanabose R, 2015, COMPUT GRAPH FORUM, V34, P261, DOI 10.1111/cgf.12638
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   KLEINER B, 1981, J AM STAT ASSOC, V76, P260, DOI 10.2307/2287820
   Kosara R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P101, DOI [10.1109/VISUAL.2019.8933547, 10.1109/visual.2019.8933547]
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Lam H.-C., 2012, International Scholarly Research Notices, P2
   Li G., 2022, IEEE Transactions on Visualization and Computer Graphics, V2
   Luo S.-J., 2011, IEEE Transactions on Visualization and Computer Graphics, V18, P2
   Maio V., 1990, Perceptual and Motor Skills, V71, P2
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   Morgan MJ, 2005, VISION RES, V45, P2564, DOI 10.1016/j.visres.2005.04.004
   Muramalla S, 2017, IADIS-INT J COMPUT S, V12, P17
   Nachmias J, 2008, VISION RES, V48, P1290, DOI 10.1016/j.visres.2008.02.024
   Nguyen QV, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P85, DOI 10.1109/INFVIS.2002.1173152
   Qi G, 2022, DISPLAYS, V75, DOI 10.1016/j.displa.2022.102325
   Rusu A., 2011, P 15 INT C INF VIS, P2
   Sadahiro Y, 2014, COMPUT ENVIRON URBAN, V45, P24, DOI 10.1016/j.compenvurbsys.2014.02.001
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Schulz H.-J., 2010, IEEE Transactions on Visualization and Computer Graphics, V17, P2
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Skau D, 2016, COMPUT GRAPH FORUM, V35, P121, DOI 10.1111/cgf.12888
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Tan D., 2007, IEEE Transactions on Visualization and Computer Graphics, V13, P2
   Tekusová T, 2008, IEEE INT CONF INF VI, P143, DOI 10.1109/IV.2008.51
   Tennekes M, 2021, COMPUT GRAPH FORUM, V40, P323, DOI 10.1111/cgf.14310
   Tufte E., 2001, The Visual Display of Quantitative Information, V1, P2
   van de Wetering H, 2020, IEEE PAC VIS SYMP, P121, DOI 10.1109/PacificVis48177.2020.4908
   Wang Y., 2020, IEEE Transactions on Visualization and Computer Graphics, V26, P2
   Woodburn L, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P96, DOI [10.1109/visual.2019.8933545, 10.1109/VISUAL.2019.8933545]
   Yang J, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P77, DOI 10.1109/INFVIS.2002.1173151
   Yu Guangchuang, 2020, Curr Protoc Bioinformatics, V69, pe96, DOI 10.1002/cpbi.96
   Zellweger HP, 2016, IEEE INT CONF INF VI, P21, DOI 10.1109/IV.2016.75
   Zheng BY, 2021, IEEE PAC VIS SYMP, P136, DOI 10.1109/PacificVis52677.2021.00026
NR 54
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 251
EP 261
DI 10.1109/TVCG.2023.3327178
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500076
PM 37883266
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yeh, C
   Chen, Y
   Wu, A
   Chen, C
   Viégas, F
   Wattenberg, M
AF Yeh, Catherine
   Chen, Yida
   Wu, Aoyu
   Chen, Cynthia
   Viegas, Fernanda
   Wattenberg, Martin
TI AttentionViz: A Global View of Transformer Attention
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Transformer; Attention; NLP; Computer Vision; Visual Analytics
AB Transformer models are revolutionizing machine learning, but their inner workings remain mysterious. In this work, we present a new visualization technique designed to help researchers understand the self-attention mechanism in transformers that allows these models to learn rich, contextual relationships between elements of a sequence. The main idea behind our method is to visualize a joint embedding of the query and key vectors used by transformer models to compute attention. Unlike previous attention visualization techniques, our approach enables the analysis of global patterns across multiple input sequences. We create an interactive visualization tool, AttentionViz (demo: http://attentionviz.com), based on these joint query-key embeddings, and use it to study attention mechanisms in both language and vision transformers. We demonstrate the utility of our approach in improving model understanding and offering new insights about query-key interactions through several application scenarios and expert feedback.
C1 [Yeh, Catherine; Chen, Yida; Wu, Aoyu; Chen, Cynthia; Viegas, Fernanda; Wattenberg, Martin] Harvard Univ, Cambridge, MA 02138 USA.
C3 Harvard University
RP Yeh, C; Wattenberg, M (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM catherineyeh@g.harvard.edu; yidachen@g.harvard.edu;
   aoyuwu@g.harvard.edu; cynthiachen@college.harvard.edu;
   fernanda@g.harvard.edu; wattenberg@g.harvard.edu
OI Yeh, Catherine/0009-0007-0429-4770; Wu, Aoyu/0000-0001-9187-9265; Chen,
   Yida/0000-0002-4018-6095
CR Aflalo E, 2022, PROC CVPR IEEE, P21374, DOI 10.1109/CVPR52688.2022.02072
   Arendt DL, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P259, DOI 10.1145/3377325.3377514
   Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Carter S., 2019, Distill, V4, DOI [10.23915/distill.000151, DOI 10.23915/DISTILL.000151]
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Chi E. A., 2020, P 58 ANN M ASS COMP, P5564, DOI [DOI 10.18653/V1/2020.ACL-MAIN.493, 10.18653/v1/2020.acl-main.493]
   Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828
   Coenen A, 2019, ADV NEUR IN, V32
   Cordonnier J.-B., 2020, 8 INT C LEARN REPR A, DOI [10.48550/arXiv.1911.035842, DOI 10.48550/ARXIV.1911.035842]
   Dehghani M., 2023, arXiv
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A., 2021, 9 INT C LEARN REPR, DOI [10.48550/arXiv.2010.119291,2,7, DOI 10.48550/ARXIV.2010.119291,2,7]
   Elhage N., 2021, TRANSFORMER CIRCUITS
   Elhage N., 2022, arXiv, DOI 10.48550/arxiv.2209.10652
   Ghiasi A, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.06727, 10.48550/arXiv.2212.06727]
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Ji XN, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.03.003
   Jiang Chao, 2020, P 58 ACL, P7943, DOI 10.18653/v1/2020.acl-main.709
   Jolliffe I., 2022, Principal Component Analysis, P150, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1007/0-387-22440-87, 10.1007/b98835]
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Lidwell W., 2010, Universal principles of design, revised and updated: 125 ways to enhance usability, influence perception, increase appeal, make better design decisions, and teach through design, P9
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241
   Liu SS, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P36, DOI 10.13697/j.cnki.32-1449/tu.2018.01.013
   Ma J, 2023, IEEE T NEUR NET LEAR, DOI [10.1109/TNNLS.2023.3270479, 10.1109/IECON51785.2023.10312727]
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Mehrani P, 2023, Arxiv, DOI [arXiv:2303.01542, DOI 10.3389/FCOMP.2023.1178450, 10.48550/arXiv.2303.01542]
   Miaschi A., 2020, P 28 INT C COMP LING, P745
   Naseer M, 2021, ADV NEUR IN, V34
   Olah C., 2017, Distill, V2, DOI [10.23915/distill.000079, DOI 10.23915/DISTILL.000079]
   Olsson C., 2022, arXiv, DOI 10.48550/arXiv.2209.11895
   Oquab M, 2024, Arxiv, DOI arXiv:2304.07193
   Park C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P146, DOI 10.1109/visual.2019.8933677
   Park N., 2022, 10 INT C LEARN REPR, DOI [10.48550/arXiv.2202.06709 2, DOI 10.48550/ARXIV.2202.067092]
   Prokosch E, 1933, LANGUAGE, V9, P89, DOI 10.2307/409519
   Radford A., 2019, Language models are unsupervised multitask learners, V1, P9
   Radford Alec., 2018, Improving language understanding by generative pre-training
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458
   Sivaraman V, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P418, DOI 10.1145/3490099.3511137
   Smilkov D, 2016, Arxiv, DOI arXiv:1611.05469
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2018, Arxiv, DOI [arXiv:1803.07416, 10.48550/arXiv.1803.07416]
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P63
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797
   Wang A, 2019, ADV NEUR IN, V32
   Wang K, 2022, arXiv
   Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008
   Wang ZJ, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P132
   Wei JS, 2022, Arxiv, DOI arXiv:2206.07682
   Yang S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11782, DOI 10.1109/ICCV48922.2021.01159
NR 62
TC 5
Z9 5
U1 5
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 262
EP 272
DI 10.1109/TVCG.2023.3327163
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500105
PM 37883259
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, XB
   Huang, RF
   Jin, ZH
   Fang, TQ
   Qu, HM
AF Wang, Xingbo
   Huang, Renfei
   Jin, Zhihua
   Fang, Tianqing
   Qu, Huamin
TI <i>CommonsenseVIS</i>: Visualizing and Understanding Commonsense
   Reasoning Capabilities of Natural Language Models
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Commonsense reasoning; Context modeling; Analytical models; Natural
   language processing; Benchmark testing; Task analysis; Data models;
   visual analytics; XAI; natural language processing
AB Recently, large pretrained language models have achieved compelling performance on commonsense benchmarks. Nevertheless, it is unclear what commonsense knowledge the models learn and whether they solely exploit spurious patterns. Feature attributions are popular explainability techniques that identify important input concepts for model outputs. However, commonsense knowledge tends to be implicit and rarely explicitly presented in inputs. These methods cannot infer models' implicit reasoning over mentioned concepts. We present CommonsenseVIS, a visual explanatory system that utilizes external commonsense knowledge bases to contextualize model behavior for commonsense question-answering. Specifically, we extract relevant commonsense knowledge in inputs as references to align model behavior with human knowledge. Our system features multi-level visualization and interactive model probing and editing for different concepts and their underlying relations. Through a user study, we show that CommonsenseVIS helps NLP experts conduct a systematic and scalable visual analysis of models' relational reasoning over concepts in different situations.
C1 [Wang, Xingbo] Cornell Univ, Weill Cornell Med Coll, Ithaca, NY 14850 USA.
   [Wang, Xingbo; Huang, Renfei; Jin, Zhihua; Fang, Tianqing; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Cornell University; Weill Cornell Medicine; Hong Kong University of
   Science & Technology
RP Wang, XB (corresponding author), Cornell Univ, Weill Cornell Med Coll, Ithaca, NY 14850 USA.; Wang, XB (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM xingbo.wang@connect.ust.hk; rhuangan@ust.hk; zjinak@ust.hk;
   tfangaa@ust.hk; huamin@ust.hk
RI Wang, Xingbo/JHS-6567-2023; Fang, Tianqing/JJF-2802-2023
FU Hong Kong Theme-based Research Scheme
FX No Statement Available
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Ayoub J, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102569
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bertviz J. Vig., 2019, ICLR WORKSH DEB MACH
   Bhagavatula C., 2020, ICLR
   Bian N, 2024, Arxiv, DOI arXiv:2303.16421
   Bisk Y., 2020, AAAI, DOI [10.1609/aaai.v34i05.62391,2,4, DOI 10.1609/AAAI.V34I05.62391,2,4]
   Boggust A., 2022, P CHI, P1, DOI [10.1145/3491102.35019652,3,9, DOI 10.1145/3491102.35019652,3,9]
   Boratko M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1122
   Bordes A., 2013, Advances in neural information processing systems, V26, P1
   Brown T.B., 2020, Advances in neural information processing systems, V33, P1877
   Chen Hanjie., 2020, P C ASS COMP LING, P5578, DOI [DOI 10.18653/V1/2020.ACL-MAIN.494, DOI 10.18653/V1/2020.ACLMAIN]
   Coenen A, 2019, ADV NEUR IN, V32
   Cui LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P683
   Dai DM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8493
   De Cao N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6491
   Dinu G., 2015, ICLR
   Feldhus N., 2022, arXiv
   Feng Y, 2024, INT J ENVIRON HEAL R, V34, P2333, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Feng YL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1295
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2391
   Hwang JD, 2021, AAAI CONF ARTIF INTE, V35, P6384
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Jin ZH, 2024, IEEE T VIS COMPUT GR, V30, P3594, DOI 10.1109/TVCG.2023.3236380
   Kaushik Divyansh, 2020, ICLR
   Khashabi D, 2022, Arxiv, DOI arXiv:2202.12359
   Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896
   Li A., 2022, P C EMP METH NAT LAN, P11838, DOI [10.18653/v1/2022.emnlp-main.812, DOI 10.18653/V1/2022.EMNLP-MAIN.812]
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liang P. P., 2022, ICLR
   Lin BY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4611
   Lin BY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1504
   Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829
   Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154
   Lourie N, 2021, AAAI CONF ARTIF INTE, V35, P13480
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma KX, 2021, AAAI CONF ARTIF INTE, V35, P13507
   Manning C., 1999, Foundations of Statistical Natural Language Processing
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meng K., 2023, ICLR
   Meng K., 2022, ICLR
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Mitchell E., 2022, ICLR
   Mostafazadeh N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4569
   Ouyang L., NeurIPS
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Poyiadzi R, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P344, DOI 10.1145/3375627.3375850
   Raffel C, 2020, J MACH LEARN RES, V21
   Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381
   Sap M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4463
   Sap M, 2019, AAAI CONF ARTIF INTE, P3027
   Schwab P, 2019, ADV NEUR IN, V32
   Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4615
   Singh S., 2021, FINDINGS ASS COMPUTA, P883
   Slack Dylan, 2021, Advances in Neural Information Processing Systems, V34
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Talmor A., 2021, NeurIPS Datasets and Benchmarks Track, V1
   Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149
   Tandon N, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P523, DOI 10.1145/2556195.2556245
   Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Voita E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P183
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wu Tongshuang, 2021, P 59 ANN M ASS COMPU, V1, P6707, DOI DOI 10.18653/V1/2021.ACL-LONG.523
   Xu Y., 2022, P 31 INT JOINT C ART, P2762
   Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535
   Zellers R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4791
   Zhang HM, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4004
   Zhou XH, 2020, AAAI CONF ARTIF INTE, V34, P9733
NR 77
TC 3
Z9 3
U1 7
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 273
EP 283
DI 10.1109/TVCG.2023.3327153
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500135
PM 37883264
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Xiao, SS
   Huang, SZ
   Lin, Y
   Ye, YL
   Zeng, W
AF Xiao, Shishi
   Huang, Suizi
   Lin, Yue
   Ye, Yilin
   Zeng, Wei
TI Let the Chart Spark: Embedding Semantic Context into Chart with
   Text-to-Image Generative Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE pictorial visualization; generative model; authoring tool
ID VISUALIZATION; DESIGN
AB Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.
C1 [Xiao, Shishi; Huang, Suizi; Lin, Yue; Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
   [Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
EM sxiao713@connect.hkust-gz.edu.cn; shuang310@connect.hkust-gz.edu.cn;
   ylin491@connect.hkust-gz.edu.cn; yyebd@connect.hkust-gz.edu.cn;
   weizeng@hkust-gz.edu.cn
RI Ye, Yilin/GRR-8394-2022
FU National Natural Science Foundation of China
FX No Statement Available
CR Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Brooks T, 2023, PROC CVPR IEEE, P18392, DOI 10.1109/CVPR52729.2023.01764
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Byrne L, 2019, INFORM VISUAL, V18, P45, DOI 10.1177/1473871617724212
   Chefer H, 2023, Arxiv, DOI arXiv:2301.13826
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Coelho D, 2020, COMPUT GRAPH FORUM, V39, P593, DOI 10.1111/cgf.14004
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Dhariwal P, 2021, ADV NEUR IN, V34
   Ermon S, 2022, Denoising diffusion implicit models, V2, P4
   Few S., 2011, Visual Business Intelligence Newsletter, P6
   Frans Kevin., 2022, ADV NEURAL INFORM PR, V35, P5207
   Gal R., 2023, P ICML
   Gal R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530164
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   Hartmann F., 2017, European Modernism and the Information Society, P2
   Hertz A., 2023, P ICML
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Holmes N., 2022, Joyful Infographics: A Friendly, Human Approach to Data, P2
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Iluz S, 2023, Arxiv, DOI arXiv:2303.01818
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lan XY, 2021, IEEE T VIS COMPUT GR, V27, P2796, DOI 10.1109/TVCG.2021.3074582
   Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048
   Li YH, 2023, PROC CVPR IEEE, P22511, DOI 10.1109/CVPR52729.2023.02156
   Lu M., 2020, P ACM CHI, P1
   Mikolov T, 2013, Arxiv, DOI arXiv:1301.3781
   Moere AV, 2011, INFORM VISUAL, V10, P356, DOI 10.1177/1473871611415996
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Qin XB, 2022, LECT NOTES COMPUT SC, V13678, P38, DOI 10.1007/978-3-031-19797-0_3
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.06125
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Rashid MM, 2022, LECT NOTES ARTIF INT, V13281, P3, DOI 10.1007/978-3-031-05936-0_1
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ruiz N, 2023, Arxiv, DOI [arXiv:2208.12242, DOI 10.48550/ARXIV.2208.12242]
   Saharia C., 2022, NeurIPS, V35, P36479, DOI 10.1145/3528233.3530757
   Schetinger V, 2023, COMPUT GRAPH FORUM, V42, P423, DOI 10.1111/cgf.14841
   Schramowski P, 2023, PROC CVPR IEEE, P22522, DOI 10.1109/CVPR52729.2023.02157
   Shi Y., 2022, IEEE Trans. Vis. Comput. Graph., V29, P236, DOI DOI 10.1109/TVCG.2022.32094861,2,3
   Song Kaitao, 2020, Advances in Neural Information Processing Systems, V33
   Tufte E. R., 2001, The Visual Display of Quantitative Information, Vsecond, P6
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Wang Y, 2023, IEEE T VIS COMPUT GR, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wu JQ, 2023, Arxiv, DOI arXiv:2304.01919
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Xiao SS, 2023, COMPUT GRAPH FORUM, V42, P311, DOI 10.1111/cgf.14832
   Ying Lu, 2023, IEEE Trans Vis Comput Graph, V29, P331, DOI 10.1109/TVCG.2022.3209447
   Yu JH, 2022, Arxiv, DOI [arXiv:2206.10789, 10.48550/arXiv.2206.10789]
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhang L, 2023, Arxiv, DOI arXiv:2302.05543
NR 61
TC 4
Z9 4
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 284
EP 294
DI 10.1109/TVCG.2023.3326913
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500011
PM 37878451
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Feng, YCJ
   Wang, XB
   Wong, KK
   Wang, SJ
   Lu, YH
   Zhu, MF
   Wang, BC
   Chen, W
AF Feng, Yingchaojie
   Wang, Xingbo
   Wong, Kam Kwai
   Wang, Sijia
   Lu, Yuhong
   Zhu, Minfeng
   Wang, Baicheng
   Chen, Wei
TI PromptMagician: Interactive Prompt Engineering for Text-to-Image
   Creation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Semantics; Interviews; Task analysis; Electronic mail;
   Computational modeling; Natural language processing; Prompt engineering;
   text-to-image generation; image visualization
ID MODELS
AB Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiveness and usability of our system, suggesting it facilitates prompt engineering and improves the creativity support of the generative text-to-image model.
C1 [Feng, Yingchaojie] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Artand Archaeol Image, Minist Educ, Zhejiang, Peoples R China.
   [Wang, Xingbo; Wong, Kam Kwai] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wang, Sijia; Zhu, Minfeng] Zhejiang Univ, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University; Hong Kong University of
   Science & Technology; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, Lab Artand Archaeol Image, Minist Educ, Zhejiang, Peoples R China.
EM fycj@zju.edu.cn; xwangeg@connect.ust.hk; wangbaicheng@zju.edu.cn;
   sijiawang@zju.edu.cn; luyuhong@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   kkwongar@connect.ust.hk; chenvis@zju.edu.cn
RI Zhu, Minfeng/R-6788-2019; Wang, Xingbo/JHS-6567-2023; Chen,
   Wei/AAR-9817-2020; wang, sijia/IYJ-0510-2023
OI Zhu, Minfeng/0000-0002-6711-3099; WONG, Kam Kwai/0000-0002-2813-1972;
   Feng, Yingchaojie/0000-0002-1418-4635; Chen, Wei/0000-0002-8365-4741
FU National Natural Science Foundation of China
FX No Statement Available
CR Achlioptas P, 2021, PROC CVPR IEEE, P11564, DOI 10.1109/CVPR46437.2021.01140
   Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425
   Brown M., 2020, P ADV NEURAL INFORM
   Büring T, 2006, IEEE T VIS COMPUT GR, V12, P829
   Chambon P, 2022, Arxiv, DOI [arXiv:2210.04133, 10.48550/arXiv.2210.04133]
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1145/3491102.3517485, 10.1109/TENCON55691.2022.9978005]
   Cheon M, 2021, IEEE COMPUT SOC CONF, P433, DOI 10.1109/CVPRW53098.2021.00054
   Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Feng Y, 2024, INT J ENVIRON HEAL R, V34, P2333, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Feng YCJ, 2022, J VISUAL-JAPAN, V25, P671, DOI 10.1007/s12650-021-00780-0
   Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Hao Y., 2024, arXiv
   He JB, 2023, Arxiv, DOI arXiv:2308.00401
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Ho JAT, 2022, Arxiv, DOI [arXiv:2210.02303, DOI 10.48550/ARXIV.2210.02303]
   Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627
   Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045
   Liang P. P., 2022, P ICLR
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Liu V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545621
   Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825
   Longabaugh WJR, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-275
   Loper E., 2002, arXiv, DOI [DOI 10.48550/ARXIV.CS/0205028, 10.48550/arXiv.cs/0205028]
   Luca FD, 2019, Arxiv, DOI arXiv:1906.05996
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   MacQueen J., 1967, 5 BERKELEY S MATH ST, P4
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   OpenAI, 2023, arXiv, P2303
   Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988
   Ouyang L, 2022, ADV NEUR IN
   Pan XG, 2023, PROCEEDINGS OF SIGGRAPH 2023 CONFERENCE PAPERS, SIGGRAPH 2023, DOI 10.1145/3588432.3591500
   Panda R, 2018, LECT NOTES COMPUT SC, V11206, P594, DOI 10.1007/978-3-030-01216-8_36
   Perlin K., 1993, Computer Graphics Proceedings, P57, DOI 10.1145/166117.166125
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.06125
   Ramesh P, 2022, 38 INT C MACHINE LEA
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339
   Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Song J., 2021, INT C LEARN REPR, DOI [10.48550/arXiv.2010.02502, DOI 10.48550/ARXIV.2010.02502]
   Sparck-Jones K, 2004, J DOC, V60, P493, DOI [10.1108/00220410410560573, 10.1108/eb026526]
   Srinivasan A, 2020, IEEE COMPUT GRAPH, V40, P96, DOI 10.1109/MCG.2020.2986902
   Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang J., 2022, PROC AAAI, DOI [10.48550/arXiv.2207.123966, DOI 10.48550/ARXIV.2207.123966]
   Wang XB, 2022, Arxiv, DOI arXiv:2201.04868
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang XM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-023-2691-y
   Wang YL, 2023, Arxiv, DOI arXiv:2302.09466
   Wang ZJ, 2022, Arxiv, DOI [arXiv:2210.14896, DOI 10.48550/ARXIV.2210.14896]
   Weng LX, 2023, Arxiv, DOI arXiv:2304.05011
   Wong K. K., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2023.32456092, DOI 10.1109/TVCG.2023.32456092]
   Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zeng HP, 2023, IEEE T VIS COMPUT GR, V29, P3685, DOI 10.1109/TVCG.2022.3169175
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2023, Arxiv, DOI arXiv:2302.05543
   Zhang W, 2023, Arxiv, DOI arXiv:2307.14227
   Zhang W, 2024, Arxiv, DOI arXiv:2306.08834
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhou JH, 2023, IEEE T VIS COMPUT GR, V29, P809, DOI 10.1109/TVCG.2022.3209391
   Zhu HY, 2021, VIS INFORM, V5, P51, DOI 10.1016/j.visinf.2021.06.002
   Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595
NR 77
TC 9
Z9 9
U1 30
U2 41
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 295
EP 305
DI 10.1109/TVCG.2023.3327168
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500102
PM 37878445
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Moritz, D
   Padilla, LM
   Nguyen, F
   Franconeri, SL
AF Moritz, Dominik
   Padilla, Lace M.
   Nguyen, Francis
   Franconeri, Steven L.
TI Average Estimates in Line Graphs Are Biased Toward Areas of Higher
   Variability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Time series analysis; Encoding; Visualization; Task
   analysis; Ink; Market research; bias; lines graph; ensemble perception;
   average
AB We investigate variability overweighting, a previously undocumented bias in line graphs, where estimates of average value are biased toward areas of higher variability in that line. We found this effect across two preregistered experiments with 140 and 420 participants. These experiments also show that the bias is reduced when using a dot encoding of the same series. We can model the bias with the average of the data series and the average of the points drawn along the line. This bias might arise because higher variability leads to stronger weighting in the average calculation, either due to the longer line segments (even though those segments contain the same number of data values) or line segments with higher variability being otherwise more visually salient. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders, as the bias can adversely affect estimates of averages and trends.
C1 [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Padilla, Lace M.] Northeastern Univ, Boston, MA USA.
   [Nguyen, Francis] Northwestern Univ, Evanston, IL USA.
   [Franconeri, Steven L.] Univ British Columbia, Vancouver, BC, Canada.
C3 Carnegie Mellon University; Northeastern University; Northwestern
   University; University of British Columbia
RP Moritz, D (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM domoritz@cmu.edu; l.padilla@northeastern.edu;
   franconeri@northwestern.edu; frnguyen@cs.ubc.ca
OI Moritz, Dominik/0000-0002-3110-1053; Nguyen,
   Francis/0000-0003-3146-6148; Franconeri, Steven/0000-0001-5244-9764
FU NSF
FX No Statement Available
CR Adnan M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5444, DOI 10.1145/2858036.2858300
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   FOX CR, 1995, Q J ECON, V110, P585, DOI 10.2307/2946693
   Gamer Matthias, 2019, CRAN
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Hastie T. J., 2017, Statistical models in S, P9
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Heinrich J, 2009, IEEE T VIS COMPUT GR, V15, P1531, DOI 10.1109/TVCG.2009.131
   Hong MH, 2022, IEEE T VIS COMPUT GR, V28, P987, DOI 10.1109/TVCG.2021.3114783
   Huff D., 2023, How to lie with statistics, P1
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   KIMBALL MS, 1993, ECONOMETRICA, V61, P589, DOI 10.2307/2951719
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Padilla LM, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0120-9
   Playfair W., 1801, The commercial and political atlas: representing, by means of stained copper-plate charts, the progress of the commerce, revenues, expenditure and debts of england during the whole of the eighteenth century, P1
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Quinan PS, 2019, COMPUT GRAPH FORUM, V38, P363, DOI 10.1111/cgf.13695
   Raats M. M., 1992, Food Quality and Preference, V3, P89, DOI 10.1016/0950-3293(91)90028-D
   Raudenbush S. W., 2002, Hierarchical linear models: Applications and data analysis methods, DOI [10.2307/20758235, DOI 10.2307/20758235]
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Tufte E. R, 1985, J. Healthcare Qual., V7, P1
   VanRullen R, 2003, J PHYSIOL-PARIS, V97, P365, DOI 10.1016/j.jphysparis.2003.09.010
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   Wikipedia contributors, 2023, Geometric brownian motion - Wikipedia, the free encyclopedia
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
NR 34
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 306
EP 315
DI 10.1109/TVCG.2023.3326589
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500042
PM 37871088
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cabric, F
   Bjarnadóttir, MV
   Ling, M
   Rafnsdóttir, GL
   Isenberg, P
AF Cabric, Florent
   Bjarnadottir, Margret Vilborg
   Ling, Meng
   Rafnsdottir, Guobjorg Linda
   Isenberg, Petra
TI Eleven Years of Gender Data Visualization: A Step Towards More Inclusive
   Gender Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; gender; visual gender representation; ethics
ID COLOR; CATEGORIES; SEX
AB We present an analysis of the representation of gender as a data dimension in data visualizations and propose a set of considerations around visual variables and annotations for gender-related data. Gender is a common demographic dimension of data collected from study or survey participants, passengers, or customers, as well as across academic studies, especially in certain disciplines like sociology. Our work contributes to multiple ongoing discussions on the ethical implications of data visualizations. By choosing specific data, visual variables, and text labels, visualization designers may, inadvertently or not, perpetuate stereotypes and biases. Here, our goal is to start an evolving discussion on how to represent data on gender in data visualizations and raise awareness of the subtleties of choosing visual variables and words in gender visualizations. In order to ground this discussion, we collected and coded gender visualizations and their captions from five different scientific communities (Biology, Politics, Social Studies, Visualisation, and Human-Computer Interaction), in addition to images from Tableau Public and the Information Is Beautiful awards showcase. Overall we found that representation types are community-specific, color hue is the dominant visual channel for gender data, and nonconforming gender is under-represented. We end our paper with a discussion of considerations for gender visualization derived from our coding and the literature and recommendations for large data collection bodies. A free copy of this paper and all supplemental materials are available at https://osf.io/v9ams/.
C1 [Cabric, Florent; Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, LISN, Paris, France.
   [Bjarnadottir, Margret Vilborg] Univ Maryland, Robert H Smith Sch Business, College Pk, MD USA.
   [Ling, Meng] Ohio State Univ, Columbus, OH USA.
   [Rafnsdottir, Guobjorg Linda] Univ Iceland, Fac Social & Human Sci, Reykjavik, Iceland.
C3 Universite Paris Cite; Inria; Universite Paris Saclay; Centre National
   de la Recherche Scientifique (CNRS); University System of Maryland;
   University of Maryland College Park; University System of Ohio; Ohio
   State University; University of Iceland
RP Cabric, F (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Paris, France.
EM florent.cabric@inria.fr; mbjarnad@umd.edu; ling.253@osu.edu; glr@hi.is;
   petra.isenberg@inria.fr
OI Isenberg, Petra/0000-0002-2948-6417; Rafnsdottir, Gudbjorg
   LINDA/0000-0003-2662-5773; Ling, Meng/0000-0001-6597-5448
FU Inria
FX No Statement Available
CR Aikhenvald A. Y., 2016, How Gender Shapes the World, DOI DOI 10.1093/ACPROF:OSO/9780198723752.001.0001
   Ainsworth C, 2015, NATURE, V518, P288, DOI 10.1038/518288a
   [Anonymous], 2012, Sex Roles, P3
   [Anonymous], 2012, P C HUMAN FACTORS CO
   [Anonymous], 2010, The Sage Handbook of Prejudice, Stereotyping, and Discrimination, DOI [DOI 10.4135/9781446200919.N13, 10.4135/9781446200919.n132, DOI 10.4135/9781446200919.N132, 10. 4135/9781446200919.n13]
   [Anonymous], 2012, Biology of Sex Differences, P3
   [Anonymous], 2012, Politics & Gender, P3
   Bauer GR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178043
   Baumer EPS, 2022, COMPUT GRAPH FORUM, V41, P1, DOI 10.1111/cgf.14518
   Beeckman M. S., 2021, Colornamer - r package
   Beischel WJ, 2021, PSYCHOL SEX ORIENTAT, V8, P1, DOI 10.1037/sgd0000449
   Bertin J., 2011, Semiology of Graphics: Diagrams Networks Maps, P3
   Bolin A., 1999, Perspectives on Human Sexuality, P5
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2476, DOI 10.1109/TVCG.2013.155
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Bradley A., 2015, P 41 GRAPHICS INTERF, P9
   Brown T. N., Exploring international priorities and best practices for the collection of data about gender minorities a focus on south america
   Cecchini M, 2019, SOCIETIES, V9, DOI 10.3390/soc9040079
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Colaco R., 2021, A global call to action for gender-inclusive data collection and use, DOI DOI 10.3768/RTIPRESS.2021.PB.0026.2112
   Colmenarejo AB, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P107, DOI 10.1145/3514094.3534158
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Cover R., 2018, Emergent Identities: New Sexualities, Genders and Relationships in a Digital Era, DOI DOI 10.4324/9781315104348
   Cunningham SJ, 2011, BRIT J PSYCHOL, V102, P598, DOI 10.1111/j.2044-8295.2011.02023.x
   Data Visualization Society, Information Is Beautiful Awards
   Demir Ü, 2020, COLOR RES APPL, V45, P871, DOI 10.1002/col.22522
   Dhawka P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581086
   DIgnazio C., 2020, Strong Ideas Series, DOI DOI 10.7551/MITPRESS/11805.001.00011,2
   Dork Marian, 2013, CHI 13 EXTENDED ABST, P2189, DOI [10.1145/2468356.2468739, DOI 10.1145/2468356.2468739, DOI 10.1145/2468356.24687392,9]
   Dragga S, 2001, TECH COMMUN, V48, P265
   Federal Statistical Surveys of USA, 2023, Recommendations on the best practices for the collection of sexual orientation and gender identity data on federal statistical surveys
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Fortmann-Roe S, 2013, COLOR RES APPL, V38, P196, DOI 10.1002/col.20734
   Fugate JMB, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00206
   Haines EL, 2016, PSYCHOL WOMEN QUART, V40, P353, DOI 10.1177/0361684316634081
   Haslanger S., 2017, Applied Ethics, V6th, P2
   Hawkins J. K., 1970, Picture Processing and Psychopictorics, P4
   Hidalgo C., DATA USA
   Holman L, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2004956
   Hyde JS, 2019, AM PSYCHOL, V74, P171, DOI 10.1037/amp0000307
   IEEE VIS, 2012, Visualization & Visual Analytics
   Isenberg P, 2011, IEEE T VIS COMPUT GR, V17, P2469, DOI 10.1109/TVCG.2011.160
   It's Pronounced Metrosexual, 2018, The genderbread person v4
   Janosko J., 2020, 2020 gender rates and totals
   Jonauskaite D, 2019, SEX ROLES, V80, P630, DOI 10.1007/s11199-018-0955-z
   Karniol R, 2011, SEX ROLES, V65, P119, DOI 10.1007/s11199-011-9989-1
   Kliger D, 2012, J SOCIO-ECON, V41, P738, DOI 10.1016/j.socec.2012.07.003
   Lariviere Vincent, 2013, Nature, V504, P211
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   LoBue V, 2011, BRIT J DEV PSYCHOL, V29, P656, DOI 10.1111/j.2044-835X.2011.02027.x
   McElroy D., 2020, Signs & Symbols of the World: Over 1,001 Visual Signs Explained. Complete Illustrated Encyclopedia, P5
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Mochizuki M, 2023, CURR PSYCHOL, V42, P31590, DOI 10.1007/s12144-022-04179-4
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Muehlenhard CL, 2011, SEX ROLES, V64, P791, DOI 10.1007/s11199-011-9932-5
   Munzner T., 2014, A K Peters Visualization Series, V1st, DOI DOI 10.1201/B175118
   Muth L. C., 2018, An alternative to pink & blue: Colors for gender data
   Nash J, 2023, J BRAND MANAG, DOI 10.1057/s41262-023-00310-3
   Nelson R, 2023, CULT HEALTH SEX, V25, P711, DOI 10.1080/13691058.2022.2092213
   Offenwanger A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445383
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pinna B., 2011, Gestalt Theory, V33, P8
   Robards B., 2020, A Tumblr book: Platform and cultures, P281, DOI DOI 10.3998/MPUB.115370552
   Rogowitz B. E., 2019, Diversity in Visualization, Synthesis Lectures on Visualization, P63, DOI DOI 10.2200/S00894ED1V01Y201901VIS0102
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Scheuerman M. K., 2021, P C HUMAN FACTORS CO, DOI DOI 10.1145/3411764.34457428,9
   Schwabish J., 2021, Do No Harm Guide: Applyiing Equity Awareness in Data Visualization
   Semin GR, 2014, J CONSUM PSYCHOL, V24, P217, DOI 10.1016/j.jcps.2013.09.003
   Stroessner SJ, 2020, J EXP SOC PSYCHOL, V87, DOI 10.1016/j.jesp.2019.103915
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Tableau Software LLC, Tableau public
   Tate CC, 2013, J SEX RES, V50, P767, DOI 10.1080/00224499.2012.690110
   Tovanich N, 2022, IEEE T VIS COMPUT GR, V28, P497, DOI 10.1109/TVCG.2021.3114787
   Trans Student Educational Resources, 2015, The gender unicorn
   Trimm D, 2012, IEEE T VIS COMPUT GR, V18, P2809, DOI 10.1109/TVCG.2012.288
   UK, 2010, Types of discrimination ('protected characteristics')
   USA, Types of discrimination ('protected characteristics')
   van Tilburg M, 2015, PSYCHOL MARKET, V32, P422, DOI 10.1002/mar.20789
   Vivienne S, 2023, J GENDER STUD, V32, P498, DOI 10.1080/09589236.2021.2000852
   Wall E, 2022, IEEE T VIS COMPUT GR, V28, P966, DOI 10.1109/TVCG.2021.3114862
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Westbrook L, 2015, GENDER SOC, V29, P534, DOI 10.1177/0891243215584758
   Winter S, 2016, LANCET, V388, P390, DOI 10.1016/S0140-6736(16)00683-8
   Wu YC, 2012, IEEE T VIS COMPUT GR, V18, P2526, DOI 10.1109/TVCG.2012.285
NR 84
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 316
EP 326
DI 10.1109/TVCG.2023.3327369
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500108
PM 37910407
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gaba, A
   Kaufman, Z
   Cheung, J
   Shvakel, M
   Hall, KW
   Brun, Y
   Bearfield, CX
AF Gaba, Aimen
   Kaufman, Zhanna
   Cheung, Jason
   Shvakel, Marie
   Hall, Kyle Wm.
   Brun, Yuriy
   Bearfield, Cindy Xiong
TI My Model is Unfair, Do People Even Care? Visual Design Affects Trust and
   Perceived Bias in Machine Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Computational modeling; Analytical models; Data models;
   Bars; Investment; Games; machine learning; fairness; bias; trust; visual
   design; gender; human-subjects studies
ID PERCEPTION
AB Machine learning technology has become ubiquitous, but, unfortunately, often exhibits bias. As a consequence, disparate stakeholders need to interact with and make informed decisions about using machine learning models in everyday systems. Visualization technology can support stakeholders in understanding and evaluating trade-offs between, for example, accuracy and fairness of models. This paper aims to empirically answer "Can visualization design choices affect a stakeholder's perception of model bias, trust in a model, and willingness to adopt a model?" Through a series of controlled, crowd-sourced experiments with more than 1,500 participants, we identify a set of strategies people follow in deciding which models to trust. Our results show that men and women prioritize fairness and performance differently and that visual design choices significantly affect that prioritization. For example, women trust fairer models more often than men do, participants value fairness more when it is explained using text than as a bar chart, and being explicitly told a model is biased has a bigger impact than showing past biased performance. We test the generalizability of our results by comparing the effect of multiple textual and visual design choices and offer potential explanations of the cognitive mechanisms behind the difference in fairness perception and trust. Our research guides design considerations to support future work developing visualization systems for machine learning.
C1 [Gaba, Aimen; Kaufman, Zhanna; Cheung, Jason; Shvakel, Marie; Brun, Yuriy; Bearfield, Cindy Xiong] Univ Massachusetts, Amherst, MA 01003 USA.
   [Hall, Kyle Wm.] TD Bank, Global Compliance, Cherry Hill, NJ USA.
C3 University of Massachusetts System; University of Massachusetts Amherst
RP Gaba, A (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.
EM agaba@umass.edu; zhannakaufma@umass.edu; jasoncheung@umass.edu;
   mshvakel@umass.edu; kyle.hall@td.com; brun@umass.edu; yaxiong@umass.edu
OI Brun, Yuriy/0000-0003-3027-7986; Xiong Bearfield,
   Cindy/0000-0002-1451-4083
FU National Science Foundation
FX No Statement Available
CR Ahmad J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P56, DOI 10.1109/VIS49827.2021.9623314
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Angwin J., 2016, ProPublica, V23, P139
   Bell A., 2023, The possibility of fairness: Revisiting the impossibility theorem in practice, P1
   BERG J, 1995, GAME ECON BEHAV, V10, P122, DOI 10.1006/game.1995.1027
   Bird S., 2020, Microsoft Tech. Rep. MSR-TR-2020-32
   Black W. C., 2019, Cengage Learning EMEA, V4
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Braun V., 2012, Thematic analysis, P5
   Brülhart M, 2012, ECON LETT, V115, P20, DOI 10.1016/j.econlet.2011.11.039
   Buolamwini J., 2018, P 1 C FAIRN ACC TRAN, P77, DOI DOI 10.2147/OTT.S126905
   Cabrera AA, 2019, IEEE CONF VIS ANAL, P46, DOI [10.1109/VAST47406.2019.8986948, 10.1109/vast47406.2019.8986948]
   CARVER CS, 1994, J PERS SOC PSYCHOL, V67, P319, DOI 10.1037/0022-3514.67.2.319
   Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671
   Coleman J., 1990, Foundations of Social Theory. ACLS Humanities E-Book, P2
   Dang JH, 2020, TRENDS COGN SCI, V24, P267, DOI 10.1016/j.tics.2020.01.007
   Deng ZL, 2022, IEEE T COMPUT SOC SY, V9, P1768, DOI 10.1109/TCSS.2022.3162345
   Dwork C, 2012, P 3 INN THEOR COMP S, P214
   Elhamdadi H., 2022, WORKSHOP TRUST EXPER, DOI [10.48550/arXiv.2209.143401,2, DOI 10.48550/ARXIV.2209.143401,2]
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732
   Friedler S. A., 2016, CoRR, abs/1609.07236, P2
   Gaba A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1
   Galhotra S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P498, DOI 10.1145/3106237.3106277
   Ghai B., 2023, IEEE Transactions on Visualization and Computer Graphics, V29, DOI DOI 10.1109/TVCG.2022.32094842
   Giguere S., 2022, ICLR
   Glaeser EL, 2000, Q J ECON, V115, P811, DOI 10.1162/003355300554926
   Goldstein D. G., 2022, The Behavioral Economics Guide, pVI
   GOODLAND R, 1987, ECOL MODEL, V38, P19, DOI 10.1016/0304-3800(87)90043-3
   Hall KW, 2022, IEEE T VIS COMPUT GR, V28, P654, DOI 10.1109/TVCG.2021.3114805
   Harrison G, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P392, DOI 10.1145/3351095.3372831
   Hoffrage U, 2000, SCIENCE, V290, P2261, DOI 10.1126/science.290.5500.2261
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Johnson B, 2023, EURO J DECIS PROCESS, V11, DOI 10.1016/j.ejdp.2023.100031
   Jun Zheng, 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P141, DOI 10.1145/503376.503402
   Bellamy RKE, 2018, Arxiv, DOI [arXiv:1810.01943, 10.48550/arXiv.1810.01943, DOI 10.48550/ARXIV.1810.01943]
   Khan F. A., 2023, CORR
   Kim D. H., 2021, CHI
   Komorita S. S., 2019, Social dilemmas, V2, P9
   Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kreps D., 1990, Perspectives on Positive Political Economy, V2, P9
   Lai V., 2021, CoRR, abs/2112.11471, P1
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P1
   Metevier Blossom, 2019, ANN C NEURAL INFORM, P14893
   Munechika D, 2022, IEEE VIS CONF, P45, DOI 10.1109/VIS54862.2022.00018
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Ooge J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P93, DOI 10.1145/3490099.3511140
   Otto S., 2009, Jahrestagung der Deutschen Gesellschaft fur Akustik, P3
   Padilla L., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P12
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Papenmeier A, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3495013
   Paulhus D.L., 2007, Handbook of Research Methods in Personality Psychology pp, P224
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pielot Martin, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130956
   Poursabzi-Sangdeh F, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445315
   Q.ai, 2022, Forbes, P1
   Qualtrics I., 2013, Qualtrics, P3
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Ross C., 2018, STAT+, P1
   ROTTER JB, 1980, AM PSYCHOL, V35, P1, DOI 10.1037/0003-066X.35.1.1
   Roy PK, 2020, PROCEDIA COMPUT SCI, V167, P2318, DOI 10.1016/j.procs.2020.03.284
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Schloss KB, 2021, IEEE T VIS COMPUT GR, V27, P1022, DOI 10.1109/TVCG.2020.3030434
   Sears DO, 2005, ADV EXP SOC PSYCHOL, V37, P95, DOI 10.1016/S0065-2601(05)37002-X
   Sheard N., 2022, The movement to ban government use of face recognition, P1
   Singer N., 2019, New York Times, P1
   Stark TH, 2019, SOCIOL METHOD RES, P75959
   Stokes C., 2022, IEEE Transactions on Visualization and Computer Graphics, P8
   Supplementary materials for My Model is Unfair, 2023, Do People Even Care? Visual Design Affects Trust and Perceived Bias in Machine Learning
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Thomas PS, 2019, SCIENCE, V366, P999, DOI 10.1126/science.aag3311
   van Berkel N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445365
   Vereschak O., 2021, Proceedings of the ACM Human-Computer Interactions, V5, DOI DOI 10.1145/34760682
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang R., 2020, CHI, P1, DOI [10.1145/3313831.33768131,2, DOI 10.1145/3313831.33768131,2]
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Xie TK, 2022, IEEE T VIS COMPUT GR, V28, P368, DOI 10.1109/TVCG.2021.3114850
   Xiong C., 2019, EUROVIS WORKSHOP REP
   Xiong C., 2022, CHI
   Xiong C., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2023.32892926
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Yala A, 2019, RADIOLOGY, V292, P60, DOI 10.1148/radiol.2019182716
   Yin MY, 2019, IEEE CONF WIREL MOB, DOI [10.1109/wimob.2019.8923576, 10.1145/3290605.3300509]
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zürn M, 2017, J ECON PSYCHOL, V61, P74, DOI 10.1016/j.joep.2017.02.016
NR 92
TC 1
Z9 1
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 327
EP 337
DI 10.1109/TVCG.2023.3327192
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500057
PM 37878441
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wu, YF
   Guo, ZY
   Mamakos, M
   Hartline, J
   Hullman, J
AF Wu, Yifan
   Guo, Ziyang
   Mamakos, Michalis
   Hartline, Jason
   Hullman, Jessica
TI The Rational Agent Benchmark for Data Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Behavioral sciences; Visualization;
   Benchmark testing; Bayes methods; Uncertainty; Evaluation;
   decision-making; rational agent; scoring rule
ID UNCERTAINTY
AB Understanding how helpful a visualization is from experimental results is difficult because the observed performance is confounded with aspects of the study design, such as how useful the information that is visualized is for the task. We develop a rational agent framework for designing and interpreting visualization experiments. Our framework conceives two experiments with the same setup: one with behavioral agents (human subjects), and the other one with a hypothetical rational agent. A visualization is evaluated by comparing the expected performance of behavioral agents to that of a rational agent under different assumptions. Using recent visualization decision studies from the literature, we demonstrate how the framework can be used to pre-experimentally evaluate the experiment design by bounding the expected improvement in performance from having access to visualizations, and post-experimentally to deconfound errors of information extraction from errors of optimization, among other analyses.
C1 [Wu, Yifan; Guo, Ziyang; Mamakos, Michalis; Hartline, Jason; Hullman, Jessica] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Wu, YF (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM yifan.wu@u.northwestern.edu; ziyangguo2027@u.northwestern.edu;
   michailmamakos2022@u.northwestern.edu; hartline@northwestern.edu;
   jhullman@northwestern.edu
RI Hartline, Jason/B-7167-2009; Hullman, Jessica/P-7130-2018
OI Guo, Ziyang/0009-0004-4200-6774; Hullman, Jessica/0000-0001-6826-3550;
   Hartline, Jason/0000-0001-5505-6819; Wu, Yifan/0000-0002-4299-8169
CR Agrawal M, 2020, P NATL ACAD SCI USA, V117, P8825, DOI 10.1073/pnas.1915841117
   [Anonymous], 2002, BRIT ED RES ASS ANN
   Button KS, 2013, NAT REV NEUROSCI, V14, P365, DOI 10.1038/nrn3475
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P1128, DOI 10.1109/TVCG.2021.3114813
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fudenberg D, 2022, J POLIT ECON, DOI 10.1086/718371
   Gonzalez C, 2011, PSYCHOL REV, V118, P523, DOI 10.1037/a0024558
   Heine C, 2021, IEEE T VIS COMPUT GR, V27, P1000, DOI 10.1109/TVCG.2020.3030395
   Hofman JM, 2021, NATURE, V595, P181, DOI 10.1038/s41586-021-03659-0
   Hullman J., 2021, Harvard Data Science Review, DOI [10.1162/99608f92.3ab8a5872,9, DOI 10.1162/99608F92.3AB8A5872,9]
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Isenberg P., 2008, BELIV '08: Proceedings of the 2008 conference on BEyond time and errors, P1, DOI DOI 10.1145/1377966.1377974
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Kale A., 2023, IEEE Transactions on Visualization and Computer Graphics
   Kale A, 2022, IEEE T VIS COMPUT GR, V28, P1150, DOI 10.1109/TVCG.2021.3114824
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Knill D., 1996, Perception as Bayesian Inference, P2
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Li Yingkai, 2022, EC '22: Proceedings of the 23rd ACM Conference on Economics and Computation, P988, DOI 10.1145/3490486.3538338
   Mason W, 2009, P ACM SIGKDD WORKSH, P77, DOI DOI 10.1145/1600150.1600175
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Savelli S, 2013, APPL COGNITIVE PSYCH, V27, P527, DOI 10.1002/acp.2932
   Shneiderman B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168158
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Yarkoni T, 2022, BEHAV BRAIN SCI, V45, DOI 10.1017/S0140525X20001685
   Zuk T, 2006, PROC SPIE, V6060, DOI 10.1117/12.643631
NR 33
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 338
EP 347
DI 10.1109/TVCG.2023.3326513
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500063
PM 37871058
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Elhamdadi, H
   Stefkovics, A
   Beyer, J
   Moerth, E
   Pfister, H
   Bearfield, CX
   Nobre, C
AF Elhamdadi, Hamza
   Stefkovics, Adam
   Beyer, Johanna
   Moerth, Eric
   Pfister, Hanspeter
   Bearfield, Cindy Xiong
   Nobre, Carolina
TI Vistrust: a Multidimensional Framework and Empirical Study of Trust in
   Data Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trust; visualization; science; framework
ID COGNITION; UNCERTAINTY; EDUCATION; EMOTION
AB Trust is an essential aspect of data visualization, as it plays a crucial role in the interpretation and decision-making processes of users. While research in social sciences outlines the multi-dimensional factors that can play a role in trust formation, most data visualization trust researchers employ a single-item scale to measure trust. We address this gap by proposing a comprehensive, multidimensional conceptualization and operationalization of trust in visualization. We do this by applying general theories of trust from social sciences, as well as synthesizing and extending earlier work and factors identified by studies in the visualization field. We apply a two-dimensional approach to trust in visualization, to distinguish between cognitive and affective elements, as well as between visualization and data-specific trust antecedents. We use our framework to design and run a large crowd-sourced study to quantify the role of visual complexity in establishing trust in science visualizations. Our study provides empirical evidence for several aspects of our proposed theoretical framework, most notably the impact of cognition, affective responses, and individual differences when establishing trust in visualizations.
C1 [Elhamdadi, Hamza; Bearfield, Cindy Xiong] UMass Amherst, Amherst, MA USA.
   [Stefkovics, Adam] REN Ctr Social Sci, HUN, Budapest, Hungary.
   [Beyer, Johanna; Pfister, Hanspeter] Harvard Univ, Cambridge, MA USA.
   [Moerth, Eric] Harvard Med Sch, Boston, MA USA.
   [Nobre, Carolina] Univ Toronto, Toronto, ON, Canada.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   Harvard University; Harvard University; Harvard Medical School;
   University of Toronto
RP Nobre, C (corresponding author), Univ Toronto, Toronto, ON, Canada.
EM helhamdadi@umass.edu; stefkovics.adam@tk.hu; jbeyer@g.harvard.edu;
   ericmoerth@g.harvard.edu; hpfister@g.harvard.edu;
   cindy.xiong@cs.umass.edu; cnobre@cs.toronto.edu
RI Moerth, Eric/HNT-0446-2023
OI Stefkovics, Adam/0000-0003-4961-7792; Nobre,
   Carolina/0000-0002-2892-0509; Xiong Bearfield,
   Cindy/0000-0002-1451-4083; Morth, Eric/0000-0003-1625-0146; Elhamdadi,
   Hamza/0009-0006-8767-0681; Beyer, Johanna/0000-0002-3505-9171; Pfister,
   Hanspeter/0000-0002-3620-2582
FU NSF
FX No Statement Available
CR Artz D, 2007, J WEB SEMANT, V5, P58, DOI 10.1016/j.websem.2007.03.002
   Atoyan H., 2006, P 18 C INT HOMM MACH, P115, DOI DOI 10.1145/1132736.1132751
   Beauxis-Aussalet E., IEEE Computer Graphics and Applications, V41
   BERG J, 1995, GAME ECON BEHAV, V10, P122, DOI 10.1006/game.1995.1027
   Betella A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148037
   Bhandari U, 2019, INFORM MANAGE-AMSTER, V56, P85, DOI 10.1016/j.im.2018.07.003
   Borgonovi F, 2012, BRIT J SOCIOL, V63, P146, DOI 10.1111/j.1468-4446.2011.01397.x
   CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116
   Carlin RE, 2018, BRIT J POLIT SCI, V48, P115, DOI 10.1017/S0007123415000526
   Chua RYJ, 2008, ACAD MANAGE J, V51, P436
   Coelho GLD, 2020, ASSESSMENT, V27, P1870, DOI 10.1177/1073191118793208
   Costante E., 2011, 2011 Workshop on Socio-Technical Aspects in Security and Trust, P52, DOI 10.1109/STAST.2011.6059256
   Dang JH, 2020, TRENDS COGN SCI, V24, P267, DOI 10.1016/j.tics.2020.01.007
   Dasgupta A, 2017, IEEE T VIS COMPUT GR, V23, P271, DOI 10.1109/TVCG.2016.2598544
   Dimoka A, 2010, MIS QUART, V34, P373
   Duncan S, 2007, COGNITION EMOTION, V21, P1184, DOI 10.1080/02699930701437931
   Dunn JR, 2005, J PERS SOC PSYCHOL, V88, P736, DOI 10.1037/0022-3514.88.5.736
   Elhamdadi H, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P85, DOI 10.1109/BELIV57783.2022.00014
   Elhamdadi H, 2022, Arxiv, DOI arXiv:2209.14340
   Evans AM, 2008, J RES PERS, V42, P1585, DOI 10.1016/j.jrp.2008.07.011
   Gutzwiller Robert S., 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P217, DOI 10.1177/1071181319631201
   HOCH SJ, 1991, J CONSUM RES, V17, P492, DOI 10.1086/208573
   Hooghe M, 2012, INTELLIGENCE, V40, P604, DOI 10.1016/j.intell.2012.08.006
   Jahansoozi J, 2006, J MANAG DEV, V25, P942, DOI 10.1108/02621710610708577
   Jian J.-Y., 2000, Int. J. Cognitive Ergonomics, V4, P53, DOI [10.1207/s15327566ijce040104, DOI 10.1207/S15327566IJCE040104, 10.1207/S15327566IJCE0401_04, DOI 10.1207/S15327566IJCE0401_04, 10.1207/S15327566IJCE040104]
   Jun Zheng, 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P141, DOI 10.1145/503376.503402
   Kelton K, 2008, J AM SOC INF SCI TEC, V59, P363, DOI 10.1002/asi.20722
   Kiesler S., 1997, Human values and the design of computer technology, P2
   Kim Y. S., 2020, Designing Belief-driven Interactions with Data
   Kim YS, 2021, IEEE T VIS COMPUT GR, V27, P989, DOI 10.1109/TVCG.2020.3028984
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Kock N, 2012, J ASSOC INF SYST, V13, P546, DOI 10.17705/1jais.00302
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Landwehr JR, 2020, J EXP SOC PSYCHOL, V90, DOI 10.1016/j.jesp.2020.103997
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Liao M., 2022, USER TRUST RECOMMEND, P1, DOI [10.1145/3491102.35019362, DOI 10.1145/3491102.35019362]
   MAYER RC, 1995, ACAD MANAGE REV, V20, P709, DOI 10.2307/258792
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P1, DOI [10.2312/trvis.201911872,3,4, DOI 10.2312/TRVIS.201911872,3,4]
   MCALLISTER DJ, 1995, ACAD MANAGE J, V38, P24, DOI 10.5465/256727
   Myers CD, 2016, POLIT ANAL, V24, P492, DOI 10.1093/pan/mpw026
   NASS C, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P72, DOI 10.1145/191666.191703
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004
   Rieh S. Y., 1998, Journal of The American Society for Information Science and Technology - JASIS, V35, P3
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Schnackenberg AK, 2016, J MANAGE, V42, P1784, DOI 10.1177/0149206314525202
   Sohn S, 2017, J RETAIL CONSUM SERV, V36, P137, DOI 10.1016/j.jretconser.2017.01.008
   Sturgis P, 2010, INTELLIGENCE, V38, P45, DOI 10.1016/j.intell.2009.11.006
   Thorndike EL, 1920, J APPL PSYCHOL, V4, P25, DOI 10.1037/h0071663
   Tomlinson EC, 2020, J ORGAN BEHAV, V41, P535, DOI 10.1002/job.2448
   van der Bles AM, 2020, P NATL ACAD SCI USA, V117, P7672, DOI 10.1073/pnas.1913678117
   van der Bles AM, 2019, ROY SOC OPEN SCI, V6, DOI 10.1098/rsos.181870
   WETZEL CG, 1981, J EXP SOC PSYCHOL, V17, P427, DOI 10.1016/0022-1031(81)90049-4
   Xiong C., 2019, P 1 EUROVIS WORKSH T, P19
   Yin MY, 2019, IEEE CONF WIREL MOB, DOI [10.1109/wimob.2019.8923576, 10.1145/3290605.3300509]
   Yu K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P307, DOI 10.1145/3025171.3025219
   Yu Kun, 2016, P 2016 C US MOD AD P, P223
   Zehrung R, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445195
   Zhang P, 2013, MIS QUART, V37, P247
   Zhang Y., 2022, Association for Computing Machinery, DOI [10.1145/3491102.35018892,9, DOI 10.1145/3491102.35018892,9]
   Zhou JL, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312962
   Zhou M. X., 1998, CHI 98. Human Factors in Computing Systems. CHI 98 Conference Proceedings, P392, DOI 10.1145/274644.274698
NR 62
TC 2
Z9 2
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 348
EP 358
DI 10.1109/TVCG.2023.3326579
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500083
PM 37922171
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Setlur, V
   Correll, M
   Satyanarayan, A
   Tory, M
AF Setlur, Vidya
   Correll, Michael
   Satyanarayan, Arvind
   Tory, Melanie
TI Heuristics for Supporting Cooperative Dashboard Design
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Oral communication; Data visualization; Guidelines; Visualization;
   Maintenance engineering; Surveys; Grounding; Gricean maxims; interactive
   visualization; conversation initiation; grounding; turn-taking; repair
   and refinement
ID ORGANIZATION
AB Dashboards are no longer mere static displays of metrics; through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines, however, are often unable to account for this expanded scope as they largely focus on best practices for visual design. In contrast, we frame dashboard design as facilitating an analytical conversation: a cooperative, interactive experience where a user may interact with, reason about, or freely query the underlying data. By drawing on established principles of conversational flow and communication, we define the concept of a cooperative dashboard as one that enables a fruitful and productive analytical conversation, and derive a set of 39 dashboard design heuristics to support effective analytical conversations. To assess the utility of this framing, we asked 52 computer science and engineering graduate students to apply our heuristics to critique and design dashboards as part of an ungraded, opt-in homework assignment. Feedback from participants demonstrates that our heuristics surface new reasons dashboards may fail, and encourage a more fluid, supportive, and responsive style of dashboard design. Our approach suggests several compelling directions for future work, including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement and extending cooperative principles to other analytical workflows.
C1 [Setlur, Vidya; Correll, Michael] Tableau Res, Palo Alto, CA 94306 USA.
   [Satyanarayan, Arvind] MIT CSAIL, Cambridge, MA 02139 USA.
   [Tory, Melanie] Northeastern Univ, Boston, MA USA.
C3 Massachusetts Institute of Technology (MIT); Northeastern University
RP Setlur, V (corresponding author), Tableau Res, Palo Alto, CA 94306 USA.
EM vsetlur@tableau.com; m.correll@northeastern.edu; arvindsatya@mit.edu;
   m.tory@northeastern.edu
OI Satyanarayan, Arvind/0000-0001-5564-635X; Setlur,
   Vidya/0000-0003-3722-406X
FU NSF
FX No Statement Available
CR Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006
   Agarwal S, 2022, LIBR HI TECH, V40, P1013, DOI 10.1108/LHT-09-2021-0330
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   [Anonymous], 2021, Microsoft Q&A
   [Anonymous], 2021, IBM Watson Analytics
   Bach B., 2022, IEEE TVCG, P2
   Bartram L., 2021, arXiv
   Beebe S., 2004, Interpersonal Communication: Relating to Others, P2
   Bertini E., 2006, Advanced Visual Interfaces, P2
   Brehmer M., 2022, IEEE TVCG, V28, P4
   Cassell J, 2001, AI MAG, V22, P67
   Chaves AP, 2021, INT J HUM-COMPUT INT, V37, P729, DOI 10.1080/10447318.2020.1841438
   Chen X., 2020, IEEE TVCG, V27, P2
   CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006
   Coppock L., 2005, Politeness Strategies in Conversation Closings, V01, P4
   Cuttone A., 2014, INT C UN ACC HUM COM, P2
   Davis W., 2019, The Stanford Encyclopedia of Philosophy, P5
   Deng DZ, 2022, Arxiv, DOI [arXiv:2203.10476, 10.48550/arXiv.2203.10476, DOI 10.48550/ARXIV.2203.10476]
   Dhanoa V, 2022, COMPUT GRAPH FORUM, V41, P501, DOI 10.1111/cgf.14558
   Diakopoulos N., 2016, Pearson, P2
   Dimara E., 2021, IEEE TVCG, P2
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P119, DOI 10.1109/TVCG.2019.2934283
   Dowding D, 2018, APPL CLIN INFORM, V9, P511, DOI 10.1055/s-0038-1666842
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   En L. Q., 2011, 2011 6 ACM IEEE INT, P4
   Endsley T. C., 2017, P HUMAN FACTORS ERGO, V61, P2
   Epley S., 2022, Best States to Retire in the United States
   Feng M., 2017, IEEE TVCG, V23, P4
   Few S., 2006, Information Dashboard Design: The Effective Visual Communication of Data, P2
   Fiore-Gartland B., 2015, International Journal of Communication, V9, P2
   Forsell C., 2010, Proceedings of the International Conference on Advanced Visual Interfaces, DOI [10.1145/1842993.18430292, DOI 10.1145/1842993.18430292, 10.1145/1842993.1843029., DOI 10.1145/1842993.1843029]
   Fulfagar Lokesh, 2021, Design for TomorrowVolume 1. Proceedings of ICoRD 2021. Smart Innovation, Systems and Technologies (SIST 221), P375, DOI 10.1007/978-981-16-0041-8_32
   Furmanski C, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P215, DOI 10.1109/ISMAR.2002.1115091
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Grice H. P., 1967, Syntax and Semantics, P41, DOI DOI 10.1163/9789004368811
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hohn Sviatlana, 2021, Chatbot Research and Design. 4th International Workshop, CONVERSATIONS 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12604), P131, DOI 10.1007/978-3-030-68288-0_9
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Hullman J., 2021, Harvard Data Science Review, V3, P3
   Kaggle, 2023, ABOUT US
   Key A., 2012, P ACM SIGMOD INT C M, P681, DOI DOI 10.1145/2213836.2213931
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kristiansen Y. S., 2021, IEEE TVCG, V28, P2
   Lam H., 2017, IEEE TVCG, V24, P2
   Langevin R., 2021, CHI, P1
   Lee D. J.-L., 2022, IEEE TVCG, V28, P3
   Lee-Robbins E., 2022, IEEE TVCG, P2
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Lin Y., 2023, IEEE TVCG, P1
   Luo B, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1434
   Maguire M., 2019, INT C HUM COMP INT, P212
   Merriam-Webster, 2022, Heuristic, V5
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   NIELSEN J, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P152, DOI 10.1145/191666.191729
   Nielsen J., 2020, 10 Usability Heuristics for User Interface Design
   Nowacki Caroline, 2020, Design, User Experience, and Usability. Design for Contemporary Interactive Environments. 9th International Conference, DUXU 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12201), P117, DOI 10.1007/978-3-030-49760-6_8
   Pandey A, 2022, Arxiv, DOI arXiv:2208.03175
   Panfili L., 2021, P LINGUISTIC SOC AM, V6, P288
   Pirolli P, 2005, SENSEMAKING PROCESS
   Qu Z., 2017, IEEE TVCG, V24, P2
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Saygin AP, 2002, J PRAGMATICS, V34, P227, DOI 10.1016/S0378-2166(02)80001-7
   SCHEGLOFF EA, 1977, LANGUAGE, V53, P361, DOI 10.2307/413107
   Setlur Vidya, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P966, DOI 10.1145/3379337.3415813
   Setlur V., 2016, UIST, P4
   Setlur V., 2022, Functional Aesthetics for Data Visualization, P4
   Setlur V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501972
   Setlur V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P216, DOI 10.1109/VIS47514.2020.00050
   Setlur V, 2019, PROCEEDINGS OF IUI 2019, P40, DOI 10.1145/3301275.3302270
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shi Y., 2022, IEEE TVCG, P1
   Singh P., World Indicators Dashboard
   Srinivasan A., 2023, EuroVis 2023 - Short Papers, DOI DOI 10.2312/EVS.202310352
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Srinivasan A, 2018, IEEE T VIS COMPUT GR, V24, P511, DOI 10.1109/TVCG.2017.2745219
   Sugisaki K, 2020, MUC 2020: PROCEEDINGS OF MENSCH UND COMPUTER 2020, P309, DOI 10.1145/3404983.3405505
   Tarrell A., 2014, P 5 WORKSH TIM ERR N, P110
   ThoughtSpot, 2021, ABOUT US
   Tominski C., 2015, Synthesis Lectures on Visualization, P1
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Tory M., 2021, IEEE Computer Graphics and Applications, V2
   Tory M, 2019, IEEE CONF VIS ANAL, P93, DOI [10.1109/VAST47406.2019.8986918, 10.1109/vast47406.2019.8986918]
   Väätajä H, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P36, DOI 10.1145/2993901.2993918
   wa, Washington State COVID-19 Summary Dashboard
   Wall E., 2022, IEEE TVCG, V28, P4
   Wall E, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P111, DOI [10.1109/visual.2019.8933611, 10.1109/VISUAL.2019.8933611]
   Wall E, 2017, IEEE CONF VIS ANAL, P104, DOI 10.1109/VAST.2017.8585669
   Ware C, 2008, MORG KAUF SER INTER, P1
   Wei ZXN, 2018, IEEE PERVAS COMPUT, V17, P84, DOI 10.1109/MPRV.2018.022511249
   Wexler S., 2017, The Big Book of Dashboards: Visualizing your Data using Real-world Business Scenarios, V1, P2
   Whitworth B, 2005, BEHAV INFORM TECHNOL, V24, P353, DOI 10.1080/01449290512331333700
   Wu A., 2021, IEEE TVCG, V28, P2
   Yigitbasioglu O. M., 2012, International Journal of Accounting Information Systems, V13, P2
   Zhang Y., 2022, IEEE TVCG, P2
   Zuk T., 2006, P 2006 AVI WORKSH TI
NR 100
TC 2
Z9 2
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 370
EP 380
DI 10.1109/TVCG.2023.3327158
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500019
PM 37883257
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Walchshofer, C
   Dhanoa, V
   Streit, M
   Meyer, M
AF Walchshofer, Conny
   Dhanoa, Vaishal
   Streit, Marc
   Meyer, Miriah
TI Transitioning to a Commercial Dashboarding System: Socio-Technical
   Observations and Opportunities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interview study; socio-technical challenges; visual analytics
ID VISUAL ANALYTICS; VISUALIZATION; DISCOVERY; DESIGN
AB Many long-established, traditional manufacturing businesses are becoming more digital and data-driven to improve their production. These companies are embracing visual analytics in these transitions through their adoption of commercial dashboarding systems. Although a number of studies have looked at the technical challenges of adopting these systems, very few have focused on the socio-technical issues that arise. In this paper, we report on the results of an interview study with 17 participants working in a range of roles at a long-established, traditional manufacturing company as they adopted Microsoft Power BI. The results highlight a number of socio-technical challenges the employees faced, including difficulties in training, using and creating dashboards, and transitioning to a modern digital company. Based on these results, we propose a number of opportunities for both companies and visualization researchers to improve these difficult transitions, as well as opportunities for rethinking how we design dashboarding systems for real-world use.
C1 [Walchshofer, Conny; Streit, Marc] Johannes Kepler Univ Linz, Linz, Austria.
   [Dhanoa, Vaishal] Pro 2 Future GmbH, Graz, Austria.
   [Meyer, Miriah] Linkoping Univ, Linkoping, Sweden.
C3 Johannes Kepler University Linz; Linkoping University
RP Walchshofer, C (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.
EM conny.walchshofer@jku.at; vaishali.dhanoa@pro2future.at;
   marc.streit@jku.at; miriah.meyer@liu.se
OI Reis, Conny/0000-0003-3942-8445; Dhanoa, Vaishali/0000-0002-0493-8616;
   Streit, Marc/0000-0001-9186-2092
FU Wallenberg AI, Autonomous Systems and Software Program (WASP)
FX No Statement Available
CR Ahlberg C., 1996, SIGMOD Record, V25, P25, DOI 10.1145/245882.245893
   Akbaba D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581168
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bako Hannah K, 2023, IEEE Trans Vis Comput Graph, V29, P1048, DOI 10.1109/TVCG.2022.3209490
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Baskarada S, 2017, PROGRAM-ELECTRON LIB, V51, P65, DOI 10.1108/PROG-07-2016-0053
   Batch A, 2018, IEEE T VIS COMPUT GR, V24, P278, DOI 10.1109/TVCG.2017.2743990
   Behrisch M., 2018, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2018.28599732, DOI 10.1109/TVCG.2018.28599732]
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Cao Y.-R., 2020, ACM CHI C HUM FACT C, P1, DOI [10.1145/3334480.33830579, DOI 10.1145/3334480.33830579]
   Chen Q, 2022, Arxiv, DOI arXiv:2206.12118
   Crisan A., 2021, ACM CHI C HUM FACT C, P1, DOI [10.1145/3411764.34457752, DOI 10.1145/3411764.34457752]
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   Daradkeh MK, 2019, INFORM TECHNOL PEOPL, V32, P668, DOI 10.1108/ITP-10-2017-0359
   Davenport T., 2020, Harvard Data Science Review, DOI [10.1162/99608f92.55546b4a9, DOI 10.1162/99608F92.55546B4A9]
   Dhanoa V, 2022, COMPUT GRAPH FORUM, V41, P501, DOI 10.1111/cgf.14558
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Eick SG, 2000, IEEE T VIS COMPUT GR, V6, P44, DOI 10.1109/2945.841120
   Elias M, 2011, LECT NOTES COMPUT SC, V6949, P274, DOI 10.1007/978-3-642-23768-3_23
   Fisher Danyel, 2012, Interactions, V19, P50, DOI 10.1145/2168931.2168943
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kim M, 2016, PROC INT CONF SOFTW, P96, DOI 10.1145/2884781.2884783
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu J., 2019, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2019.29345932,8, DOI 10.1109/TVCG.2019.29345932,8]
   Liu Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376533
   Monforte J., 2021, Methods in Psychology, V5, P100082, DOI DOI 10.1016/J.METIP.2021.100082
   Mörth E, 2022, Arxiv, DOI [arXiv:2207.03616, 10.48550/ARXIV.2207.03616 9, DOI 10.48550/ARXIV.2207.036169]
   Muller M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300356
   ONeil C., 2013, Doing Data Science: Straight Talk from the Frontline, V8, P9
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Parsons P, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P176, DOI 10.1109/VIS47514.2020.00042
   Perkhofer LM, 2019, J APPL ACCOUNT RES, V20, P497, DOI 10.1108/JAAR-10-2017-0114
   Riche N. H., 2018, Data-Driven Storytelling, P9
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Sarikaya A, 2019, IEEE T VIS COMPUT GR, V25, P682, DOI 10.1109/TVCG.2018.2864903
   Sedlmair M., 2010, PROC WORKSHOP TIME E, P79, DOI [DOI 10.1145/2110192.2110204, 10.1145/2110192.21102042,8, DOI 10.1145/2110192.21102042,8]
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Siu A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517678
   Stoiber Christina, 2021, VINCI 2021: The 14th International Symposium on Visual Information Communication and Interaction, DOI 10.1145/3481549.3481558
   Stoiber C., 2019, IEEE WORKSH VIS COMM
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Storm M., 2020, Proceedings of the 53rd Hawaii international conference on system sciences, P5399
   Streit M, 2019, BIOINFORMATICS, V35, P3140, DOI 10.1093/bioinformatics/btz009
   Tobiasz M, 2009, IEEE T VIS COMPUT GR, V15, P1065, DOI 10.1109/TVCG.2009.162
   Tory M., 2022, IEEE Computer Graphics and Applications, P1, DOI [10.1109/MCG.2021.31365451,2,8,9, DOI 10.1109/MCG.2021.31365451,2,8,9]
   Xu X., 2022, ACM CHI C HUM FACT C, P1, DOI [10.1145/3491102.35018969, DOI 10.1145/3491102.35018969]
   Youssef MA, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102827
   Zhang LS, 2012, IEEE CONF VIS ANAL, P173, DOI 10.1109/VAST.2012.6400554
   Zhang Y., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32094932, DOI 10.1109/TVCG.2022.32094932]
NR 62
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 381
EP 391
DI 10.1109/TVCG.2023.3326525
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500030
PM 37878440
OA hybrid
DA 2024-11-06
ER

PT J
AU Schmidt, J
   Pointner, B
   Miksch, S
AF Schmidt, Johanna
   Pointner, Bernhard
   Miksch, Silvia
TI Visual Analytics for Understanding Draco's Knowledge Base
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Aggregates; Task analysis; Recommender systems;
   Costs; Bars; Visual analytics; Visual Analytics; Hypergraph
   visualization; Rule-based recommendation systems
ID OF-THE-ART; VISUALIZATION; DESIGN; COMMUNITIES
AB Draco has been developed as an automated visualization recommendation system formalizing design knowledge as logical constraints in ASP (Answer-Set Programming). With an increasing set of constraints and incorporated design knowledge, even visualization experts lose overview in Draco and struggle to retrace the automated recommendation decisions made by the system. Our paper proposes an Visual Analytics (VA) approach to visualize and analyze Draco's constraints. Our VA approach is supposed to enable visualization experts to accomplish identified tasks regarding the knowledge base and support them in better understanding Draco. We extend the existing data extraction strategy of Draco with a data processing architecture capable of extracting features of interest from the knowledge base. A revised version of the ASP grammar provides the basis for this data processing strategy. The resulting incorporated and shared features of the constraints are then visualized using a hypergraph structure inside the radial-arranged constraints of the elaborated visualization. The hierarchical categories of the constraints are indicated by arcs surrounding the constraints. Our approach is supposed to enable visualization experts to interactively explore the design rules' violations based on highlighting respective constraints or recommendations. A qualitative and quantitative evaluation of the prototype confirms the prototype's effectiveness and value in acquiring insights into Draco's recommendation process and design constraints.
C1 [Schmidt, Johanna; Pointner, Bernhard] VRVis Zentrum Virtual Real & Visualisierung Forsc, Vienna, Austria.
   [Miksch, Silvia] TU Wien, Ctr Visual Analyt Sci & Technol CVAST, Vienna, Austria.
C3 Technische Universitat Wien
RP Schmidt, J (corresponding author), VRVis Zentrum Virtual Real & Visualisierung Forsc, Vienna, Austria.
EM johanna.schmidt@vrvis.at; pointner@vrvis.at; silvia.miksch@tuwien.ac.at
OI Schmidt, Johanna/0000-0002-9638-6344; Miksch, Silvia/0000-0003-4427-5703
FU BMK
FX No Statement Available
CR Alborzi F, 2017, Arxiv, DOI [arXiv:1703.09218, 10.48550/arXiv.1703.09218, DOI 10.48550/ARXIV.1703.09218]
   Alsallakh B., 2014, EUR C VIS EUROVIS, P1, DOI [DOI 10.2312/EUROVISSTAR.20141170, 10.2312/eurovisstar.20141170]
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Burch M, 2008, COMPUT GRAPH FORUM, V27, P823, DOI 10.1111/j.1467-8659.2008.01213.x
   Burch Michael, 2012, Proceedings of the International Conference on Computer Graphics Theory and Applications (GRAPP 2012) and International Conference on Information Visualization Theory and Applications (IVAPP 2012), P603
   Cameron M., 2003, P 5 ACM SIGPLAN INT, P56, DOI [10.1145/888251.888258, DOI 10.1145/888251.888258]
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Chaturvedi S, 2014, COMPUT GRAPH FORUM, V33, P52, DOI 10.1111/cgf.12400
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Ehsan H, 2016, PROC INT CONF DATA, P731, DOI 10.1109/ICDE.2016.7498285
   Febbraro O., 2011, Logic Programming and Nonmonotonic Reasoning, P2
   Gebser M, 2012, SYNTHESIS LECT ARTIF, DOI [DOI 10.1007/978-3-031-01561-8, DOI 10.2200/S00457ED1V01Y201211AIM019]
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Hopfner M, 2003, PROG COMPREHEN, P290
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Humayoun S. R., 2016, P INT WORKING C ADV, P314, DOI [10.1145/2909132.29260725, DOI 10.1145/2909132.29260725]
   Kaur P, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P266, DOI 10.5220/0006175002660273
   Kubernatova P., 2019, Data Management Technologies and Applications, P2
   Lewis C., 1982, USING THINKING ALOUD
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Lifschitz V., 2019, Answer Set Programming, V1st, P3
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mueller C, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P141
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen Frank, 2016, Introduction to HPC with MPI for Data Science, P195, DOI [DOI 10.1007/978-3-319-21903-5, 10.1007/978-3-319-21903-5_8, DOI 10.1007/978-3-319-21903-5_8]
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Pointner B., 2022, An Interactive Visualization Approach to Tackle Design Constraints in a Rule-Based Recommendation System, DOI [10.34726/hss.2022.870631, DOI 10.34726/HSS.2022.870631]
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Saket B., 2018, CoRR, abs/1807.06641
   Santos J. M., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P24, DOI 10.1109/IV.2012.15
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schulz HJ, 2006, INFORMATION VISUALIZATION-BOOK, P166
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulzrinne Henning, 2013, Proceedings of the 2013 12th International Conference on Telecommunications (ConTEL 2013), P3
   Seo J., 2005, Information Visualization, V4, P96, DOI 10.1057/palgrave.ivs.9500091
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sinha R., 2002, Extended Abstracts on Human Factors in Computing Systems, CHI EA'02, P830, DOI DOI 10.1145/506443.506619
   Stasko J, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P57, DOI 10.1109/INFVIS.2000.885091
   Vartak M, 2016, SIGMOD REC, V45, P34, DOI 10.1145/3092931.3092937
   Vehlow C, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12512
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Viegas F., 2017, US Patent, Patent No. 201662401647
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang W., 2006, P SIGCHI C HUM FACT, P517
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Woodburn L, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P96, DOI [10.1109/visual.2019.8933545, 10.1109/VISUAL.2019.8933545]
   Zhou H, 2015, J VISUAL-JAPAN, V18, P159, DOI 10.1007/s12650-014-0271-9
   Zhou M., 1998, Second International Conference on Cooperative Multimodal Communication (CMC 1998), P43, DOI [10.1007/3-540-45520-5/_42, DOI 10.1007/3-540-45520-5/_42]
NR 53
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 392
EP 402
DI 10.1109/TVCG.2023.3326912
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500050
PM 37874727
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Snyder, LS
   Heer, J
AF Snyder, Luke S.
   Heer, Jeffrey
TI DIVI: Dynamically Interactive Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Interaction; Visualization Tools; Charts; SVG; Exploratory Data Analysis
ID TOOLKIT; LYRA
AB Dynamically Interactive Visualization (DIVI) is a novel approach for orchestrating interactions within and across static visualizations. DIVI deconstructs Scalable Vector Graphics charts at runtime to infer content and coordinate user input, decoupling interaction from specification logic. This decoupling allows interactions to extend and compose freely across different tools, chart types, and analysis goals. DIVI exploits positional relations of marks to detect chart components such as axes and legends, reconstruct scales and view encodings, and infer data fields. DIVI then enumerates candidate transformations across inferred data to perform linking between views. To support dynamic interaction without prior specification, we introduce a taxonomy that formalizes the space of standard interactions by chart element, interaction type, and input event. We demonstrate DIVI's usefulness for rapid data exploration and analysis through a usability study with 13 participants and a diverse gallery of dynamically interactive visualizations, including single chart, multi-view, and cross-tool configurations.
C1 [Snyder, Luke S.; Heer, Jeffrey] Univ Washington, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Snyder, LS (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM snyderl@cs.washington.edu; jheer@cs.washington.edu
FU Moore Foundation software
FX No Statement Available
CR Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brosz J., 2013, P 26 ANN ACM S USER, P97
   Choi J, 2015, IEEE T VIS COMPUT GR, V21, P1087, DOI 10.1109/TVCG.2015.2414454
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   Dey A. K., 2005, ACM Transactions on Computer-Human Interaction (TOCHI), V12, P4
   github, 2022, ABOUT US
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Liu C, 2024, Arxiv, DOI arXiv:2303.14476
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Lu M, 2017, IEEE PAC VIS SYMP, P61
   Lu S., 2022, D3-annotation
   Masson D., 2023, P 2023 CHI C HUMAN F, P1
   matplotlib, 2022, About Us
   McDaniel R.G., 1999, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '99, P442
   North C., 2000, Proceedings of the the working conference on Advanced visual interfaces (AVI) 2000, P128, DOI DOI 10.1145/345513.345282
   plotly, 2022, About Us
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren D., 2018, IEEE transactions on visualization and computer graphics, V25, P2
   Saket B, 2019, Arxiv, DOI arXiv:1907.08345
   Saket B, 2019, COMPUT GRAPH FORUM, V38, P663, DOI 10.1111/cgf.13718
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Sedig K., 2013, AIS Transactions on Human-Computer Interaction, V5, P2
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   tableau, 2022, About Us
   uwdata.github, 2022, About Us
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wickham H., 2016, ggplot2: Elegant graphics for data analysis
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 39
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 403
EP 413
DI 10.1109/TVCG.2023.3327172
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500100
PM 37889812
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kay, M
AF Kay, Matthew
TI ggdist: Visualizations of Distributions and Uncertainty in the Grammar
   of Graphics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty visualization; probability distributions; confidence
   distributions; grammar of graphics
ID PARAMETER; DESIGN
AB The grammar of graphics is ubiquitous, providing the foundation for a variety of popular visualization tools and toolkits. Yet support for uncertainty visualization in the grammar graphics-beyond simple variations of error bars, uncertainty bands, and density plots-remains rudimentary. Research in uncertainty visualization has developed a rich variety of improved uncertainty visualizations, most of which are difficult to create in existing grammar of graphics implementations. ggdist, an extension to the popular ggplot2 grammar of graphics toolkit, is an attempt to rectify this situation. ggdist unifies a variety of uncertainty visualization types through the lens of distributional visualization, allowing functions of distributions to be mapped to directly to visual channels (aesthetics), making it straightforward to express a variety of (sometimes weird!) uncertainty visualization types. This distributional lens also offers a way to unify Bayesian and frequentist uncertainty visualization by formalizing the latter with the help of confidence distributions. In this paper, I offer a description of this uncertainty visualization paradigm and lessons learned from its development and adoption: ggdist has existed in some form for about six years (originally as part of the tidybayes R package for post-processing Bayesian models), and it has evolved substantially over that time, with several rewrites and API re-organizations as it changed in response to user feedback and expanded to cover increasing varieties of uncertainty visualization types. Ultimately, given the huge expressive power of the grammar of graphics and the popularity of tools built on it, I hope a catalog of my experience with ggdist will provide a catalyst for further improvements to formalizations and implementations of uncertainty visualization in grammar of graphics ecosystems. A free copy of this paper is available at https://osf.io/2gsz6. All supplemental materials are available at https://github.com/mjskay/ggdist-paper and are archived on Zenodo at doi:10.5281/zenodo.7770984.
C1 [Kay, Matthew] Northwestern Univ, Evanston, IL 60208 USA.
C3 Northwestern University
RP Kay, M (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM mjskay@northwestern.edu
RI Kay, Matthew/AAN-2490-2021
OI Kay, Matthew/0000-0001-9446-0419
FU NSF
FX No Statement Available
CR Allen M., 2019, Wellcome open research, V4, DOI [10.12688/wellcomeopenres.15191.11, DOI 10.12688/WELLCOMEOPENRES.15191.11]
   Amrhein V, 2022, J INF TECHNOL-UK, V37, P316, DOI 10.1177/02683962221105904
   Ancker JS, 2006, J AM MED INFORM ASSN, V13, P608, DOI 10.1197/jamia.M2115
   [Anonymous], 2021, R LANG ENV STAT COMP
   Barrowman NJ, 2003, AM STAT, V57, P268, DOI 10.1198/0003130032369
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowman AW, 2019, J ROY STAT SOC A, V182, P403, DOI 10.1111/rssa.12379
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   BURKNER P.-C., 2022, posterior: Tools for working with posterior distributions
   Cairo A., 2018, OpenNews - Source
   Codd E. F., 1990, Relational Journal, P3
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Csardi Gabor, 2019, CRAN
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Gilbert P., 2016, numderiv: Accurate numerical derivatives
   HABER RN, 1982, IEEE COMPUT GRAPH, V2, P23
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Helske J, 2021, IEEE T VIS COMPUT GR, V27, P3397, DOI 10.1109/TVCG.2021.3073466
   HENDERSON HV, 1981, BIOMETRICS, V37, P391, DOI 10.2307/2530428
   Henry L, 2023, rlang: Functions for Base Types and Core R and 'Tidyverse' Features
   Hornik K, 2012, WIRES COMPUT STAT, V4, P394, DOI 10.1002/wics.1212
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Huron S, 2013, IEEE T VIS COMPUT GR, V19, P2446, DOI 10.1109/TVCG.2013.227
   Hyndman RJ, 1996, AM STAT, V50, P120, DOI 10.2307/2684423
   Jackson CH, 2008, AM STAT, V62, P340, DOI 10.1198/000313008X370843
   Juul JL, 2021, NAT PHYS, V17, P5, DOI 10.1038/s41567-020-01121-y
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M., 2023, tidybayes: Tidy data and geoms for Bayesian models, DOI [10.5281/zenodo.13081511, DOI 10.5281/ZENODO.13081511]
   Kay M., 2023, ggdist: Visualizations of distributions and uncertainty, DOI [10.5281/zenodo.38796201, DOI 10.5281/ZENODO.38796201]
   Kay M., 2018, The Stan Forums
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kruschke JK, 2018, ADV METH PRACT PSYCH, V1, P270, DOI 10.1177/2515245918771304
   Liu L, 2019, IEEE T VIS COMPUT GR, V25, P882, DOI 10.1109/TVCG.2018.2865193
   Liu Y, 2015, STAT COMPUT, V25, P809, DOI 10.1007/s11222-015-9563-8
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murrell P., 2022, Vectorised pattern fills in R graphics, DOI [10.17608/k6.auckland.19945787, DOI 10.17608/K6.AUCKLAND.19945787]
   Newman GE, 2012, PSYCHON B REV, V19, P601, DOI 10.3758/s13423-012-0247-5
   OHara-Wild Mitchell., 2022, distributional: Vectorised probability distributions
   Pu XY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580837
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Spiegelhalter DJ, 1999, J ROY STAT SOC A STA, V162, P45, DOI 10.1111/1467-985X.00120
   Sun Y, 2011, J COMPUT GRAPH STAT, V20, P316, DOI 10.1198/jcgs.2011.09224
   Tidyverse Team, 2020, Dot prefix. Tidyverse Design Guide
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham H, 2011, IEEE T VIS COMPUT GR, V17, P2223, DOI 10.1109/TVCG.2011.227
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wickham Hadley, 2019, Advanced R
   Wilkinson L, 1999, AM STAT, V53, P276, DOI 10.2307/2686111
   Wilkinson L., 2005, The Grammar of Graphics. Statistics and Computing, V1, P9
   Xie MG, 2013, INT STAT REV, V81, P3, DOI 10.1111/insr.12000
NR 55
TC 10
Z9 10
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 414
EP 424
DI 10.1109/TVCG.2023.3327195
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500117
PM 37883271
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Kruchten, N
   Mcnutt, AM
   Mcguffin, MJ
AF Kruchten, Nicolas
   Mcnutt, Andrew M.
   Mcguffin, Michael J.
TI Metrics-Based Evaluation and Comparison of Visualization Notations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Usability; Data visualization; Visualization; Libraries;
   Task analysis; Grammar; Notation; Evaluation; Language design; API
   design; Domain-specific languages
ID API USABILITY; GRAMMAR
AB A visualization notation is a recurring pattern of symbols used to author specifications of visualizations, from data transformation to visual mapping. Programmatic notations use symbols defined by grammars or domain-specific languages (e.g. ggplot2, dplyr, Vega-Lite) or libraries (e.g. Matplotlib, Pandas). Designers and prospective users of grammars and libraries often evaluate visualization notations by inspecting galleries of examples. While such collections demonstrate usage and expressiveness, their construction and evaluation are usually ad hoc, making comparisons of different notations difficult. More rarely, experts analyze notations via usability heuristics, such as the Cognitive Dimensions of Notations framework. These analyses, akin to structured close readings of text, can reveal design deficiencies, but place a burden on the expert to simultaneously consider many facets of often complex systems. To alleviate these issues, we introduce a metrics-based approach to usability evaluation and comparison of notations in which metrics are computed for a gallery of examples across a suite of notations. While applicable to any visualization domain, we explore the utility of our approach via a case study considering statistical graphics that explores 40 visualizations across 9 widely used notations. We facilitate the computation of appropriate metrics and analysis via a new tool called NotaScope. We gathered feedback via interviews with authors or maintainers of prominent charting libraries (n = 6). We find that this approach is a promising way to formalize, externalize, and extend evaluations and comparisons of visualization notations.
C1 [Kruchten, Nicolas; Mcguffin, Michael J.] Ecole Technol Super, Montreal, PQ, Canada.
   [Mcnutt, Andrew M.] Univ Chicago, Chicago, IL USA.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   University of Chicago
RP Kruchten, N (corresponding author), Ecole Technol Super, Montreal, PQ, Canada.
EM nicolas@kruchten.com; mcnutt@uchicago.edu; michael.mcguffin@etsmtl.ca
OI McNutt, Andrew/0000-0001-8255-4258
FU NSERC
FX No Statement Available
CR Albuquerque D, 2015, J SYST SOFTWARE, V101, P245, DOI 10.1016/j.jss.2014.11.051
   AntV, 2022, Antv-spec
   Averick M., 2019, J OPEN SOURCE SOFTW, V4, P1686, DOI DOI 10.21105/JOSS.01686
   Bares A, 2020, IEEE COMPUT GRAPH, V40, P84, DOI 10.1109/MCG.2020.2993889
   Bokeh, 2023, Bokeh
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Brandt J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1589
   Chi EH, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P69, DOI 10.1109/INFVIS.2000.885092
   Clarke S., 2004, Dr. Dobb's, P2
   de la Mora FL, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING TECHNOLOGIES RESULTS (ICSE-NIER), P37, DOI 10.1145/3183399.3183418
   Devanbu P, 2016, PROC INT CONF SOFTW, P108, DOI 10.1145/2884781.2884812
   Dolan S., jq.
   Fenton N., 2014, Software metrics: A rigorous and practical approach
   Flynn C., PyPI stats: matplotlib
   Frick V, 2018, PROC IEEE INT CONF S, P264, DOI 10.1109/ICSME.2018.00036
   Green T. R. G., 1989, People and Computers V. Proceedings of the Fifth Conference of the British Computer Society Human-Computer Interaction Specialist Group, P443
   Hopper T., 2020, Python plotting for exploratory data analysis
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   IVERSON KE, 1980, COMMUN ACM, V23, P444, DOI 10.1145/358896.358899
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Klint P, 2005, ACM T SOFTW ENG METH, V14, P331, DOI 10.1145/1072997.1073000
   Kusner MJ, 2017, PR MACH LEARN RES, V70
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Li DQ, 2018, VIS INFORM, V2, P136, DOI 10.1016/j.visinf.2018.04.011
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   McKinney W., 2010, P 9 PYTH SCI C AUST, P51, DOI [10.25080/Majora-92bf1922-00a, DOI 10.25080/MAJORA-92BF1922-00A]
   McNutt A, 2021, COMPUT GRAPH FORUM, V40, P61, DOI 10.1111/cgf.14289
   McNutt A., 2021, ACM CHI, P1
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   McNutt A, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P1, DOI 10.1109/VIS4DH51463.2020.00005
   McNutt Andrew M, 2023, IEEE Trans Vis Comput Graph, V29, P160, DOI 10.1109/TVCG.2022.3209460
   MEAD A, 1992, STATISTICIAN, V41, P27, DOI 10.2307/2348634
   Mooney P., 2022, Kaggle survey 2022: Data scientists in the USA
   Moretti F., 2013, Distant reading, P2
   Muller K., styler: Non-invasive pretty printing of R code
   Muller K., 2023, dplyr: A Grammar of Data Manipulation (1.1.2) Logiciel
   Muth L., 2016, One chart, twelve charting libraries
   Pandas team, Chart visualization - pandas 1.5.3 documentation
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pezoa F, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P263, DOI 10.1145/2872427.2883029
   Plotly, Low-code data apps
   Pu X., 2021, ACM CHI EA, P1, DOI DOI 10.1145/3411763.34504061,9
   Pu XY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580837
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Python Software Foundation, Black python code formatter
   Rakotondravony Noelle, 2023, IEEE Trans Vis Comput Graph, V29, P1189, DOI 10.1109/TVCG.2022.3209367
   Rauf I, 2019, COMPUT SCI REV, V33, P49, DOI 10.1016/j.cosrev.2019.05.001
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Rocklin M., 2022, How popular is Matplotlib?
   Russell D. M., 2016, AVI, P7, DOI [DOI 10.1145/2909132.29332876, 10.1145/2909132.29332878, DOI 10.1145/2909132.29332878]
   Saber D., 2016, A dramatic tour through Python's data visualization landscape (including ggplot and Altair)
   Sarma A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580726
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Scheller T, 2015, INFORM SOFTWARE TECH, V61, P145, DOI 10.1016/j.infsof.2015.01.009
   Schetinger V, 2023, COMPUT GRAPH FORUM, V42, P423, DOI 10.1111/cgf.14841
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Shull F., 2007, Guide to Advanced Empirical Software Engineering, DOI DOI 10.1007/978-1-84800-044-5
   Terrastruct, 2023, Text to diagram: Community list of comparisons between text to diagram tools
   Texel PP, 2015, IEEE SOUTHEASTCON
   Tidyverse team, Tidyverse design guide
   TPC, 2007, TPC-E
   Treesitter, An incremental parsing system for programming tools
   VanderPlas J, 2018, J. Open Source Softw., V3, P1057, DOI DOI 10.21105/JOSS.01057
   Vargas EL, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P245, DOI 10.1145/3368089.3409711
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Vega, 2023, Vega datasets
   Vega-Lite team, Contributing to Vega-Lite
   Vickers P, 2013, IEEE T VIS COMPUT GR, V19, P1048, DOI 10.1109/TVCG.2012.294
   Wang AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502123
   Waskom M. L., 2021, Journal of Open-Source Software, V6, P3021, DOI [DOI 10.21105/JOSS.03021, 10.21105/joss.03021]
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 2005, Statistics and Computing, DOI DOI 10.1007/0-387-28695-03,7,12
   Wongsuphasawat K., 2020, Navigating the wide world of data visualization libraries
   Wongsuphasawat K, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P131, DOI 10.1109/VIS47514.2020.00033
   Wood J., 2018, Comment on arc mark / pie chart
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Wu AY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517618
   Xie Y., formatR: Format R code automatically
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Yang S, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4846, DOI 10.1145/3534678.3542621
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
   Zuk T., 2006, P 2006 AVI WORKSH TI, P1, DOI DOI 10.1145/1168149.1168162
NR 94
TC 0
Z9 0
U1 2
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 425
EP 435
DI 10.1109/TVCG.2023.3326907
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500095
PM 37874719
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Heer, J
   Moritz, D
AF Heer, Jeffrey
   Moritz, Dominik
TI Mosaic: An Architecture for Scalable & Interoperable Data Views
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Interaction; Grammar of Graphics; Software Architecture
ID INTERACTIVE VISUALIZATION; GRAMMAR; VEGA
AB Mosaic is an architecture for greater scalability, extensibility, and interoperability of interactive data views. Mosaic decouples data processing from specification logic: clients publish their data needs as declarative queries that are then managed and automatically optimized by a coordinator that proxies access to a scalable data store. Mosaic generalizes Vegalite's selection abstraction to enable rich integration and linking across visualizations and components such as menus, text search, and tables. We demonstrate Mosaic's expressiveness, extensibility, and interoperability through examples that compose diverse visualization, interaction, and optimization techniques-many constructed using vgplot, a grammar of interactive graphics in which graphical marks act as Mosaic clients. To evaluate scalability, we present benchmark studies with order-of-magnitude performance improvements over existing web-based visualization systems-enabling flexible, real-time visual exploration of billion+ record datasets. We conclude by discussing Mosaic's potential as an open platform that bridges visualization languages, scalable visualization, and interactive data systems more broadly.
C1 [Heer, Jeffrey] Univ Washington, Seattle, WA 98195 USA.
   [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA USA.
C3 University of Washington; University of Washington Seattle; Carnegie
   Mellon University
RP Heer, J (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM jheer@uw.edu; domoritz@cmu.edu
OI Moritz, Dominik/0000-0002-3110-1053; Heer, Jeffrey/0000-0002-6175-1655
FU Moore Foundation
FX No Statement Available
CR [Anonymous], Observable Plot
   Apache Arrow, ABOUT US..
   Battle L, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1571, DOI 10.1145/3318464.3389732
   Battle L, 2021, IEEE T VIS COMPUT GR, V27, P1128, DOI 10.1109/TVCG.2020.3028891
   Battle L, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1363, DOI 10.1145/2882903.2882919
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bureau of Transportation Statistics, On-Time Performance
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen R, 2022, IEEE T VIS COMPUT GR, V28, P4127, DOI 10.1109/TVCG.2021.3076222
   Chen YR, 2022, INT CONF MANAGE DATA, P1711, DOI 10.1145/3514221.3526166
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Deriche R., 1993, Tech Report, P5
   github, Observable Inputs
   glueviz, Glue: multi-dimensional linked-data exploration
   Gray J, 1997, DATA MIN KNOWL DISC, V1, P29, DOI 10.1023/A:1009726021843
   Heer J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P11, DOI 10.1109/VIS49827.2021.9623323
   JONES MC, 1983, J STAT COMPUT SIM, V17, P133, DOI 10.1080/00949658308810650
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Kohn A, 2023, Arxiv, DOI arXiv:2306.03714
   Kohn A, 2022, PROC VLDB ENDOW, V15, P3574, DOI 10.14778/3554821.3554847
   Kruchten N, 2022, IEEE VIS CONF, P11, DOI 10.1109/VIS54862.2022.00011
   Lampe OD, 2011, COMPUT GRAPH FORUM, V30, P633, DOI 10.1111/j.1467-8659.2011.01912.x
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Livny M., 1997, PROC 1997 ACM SIGMOD, P301, DOI DOI 10.1145/253262.2533352
   Mohammed H, 2020, PROC VLDB ENDOW, V13, P2297, DOI 10.14778/3407790.3407826
   Moritz D., 2015, IEEE VIS DAT SYST IN, P9
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Moritz D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2904, DOI 10.1145/3025453.3025456
   North C., 2000, P WORK C ADV VIS INT, DOI [10.1145/345513.3452822, DOI 10.1145/345513.3452822]
   Raasveldt M., 2019, P 2019 INT C MAN DAT, DOI [10.1145/3299869.33202122,3, DOI 10.1145/3299869.33202122,3]
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tao WB, 2021, IEEE T VIS COMPUT GR, V27, P401, DOI 10.1109/TVCG.2020.3030372
   Tao WB, 2019, COMPUT GRAPH FORUM, V38, P529, DOI 10.1111/cgf.13708
   Vallenari A., 2022, arXiv
   VanderPlas J, 2018, J. Open Source Softw., V3, P1057, DOI DOI 10.21105/JOSS.01057
   WAND M. P., 1994, J. Comput. Graph. Statist., V3, P433, DOI [10.2307/1390904, DOI 10.2307/1390904]
   Weaver C, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P159, DOI 10.1109/INFVIS.2004.12
   Wickham H., 2013, Tech Report, P2
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 2011, The Grammar of Graphics, P375, DOI [10.1007/978-3-642-21551-3_132,4, DOI 10.1007/978-3-642-21551-3_132,4]
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu E, 2014, PROC VLDB ENDOW, V7, P903, DOI 10.14778/2732951.2732964
   Wu YF, 2022, IEEE T VIS COMPUT GR, V28, P737, DOI 10.1109/TVCG.2021.3114796
   Yang JR, 2022, INT CONF MANAGE DATA, P2425, DOI 10.1145/3514221.3520168
NR 49
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 436
EP 446
DI 10.1109/TVCG.2023.3327189
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500085
PM 37883269
DA 2024-11-06
ER

PT J
AU Chen, C
   Lee, BS
   Wang, YH
   Chang, YJ
   Liu, ZC
AF Chen, Chen
   Lee, Bongshin
   Wang, Yunhai
   Chang, Yunjeong
   Liu, Zhicheng
TI Mystique: Deconstructing SVG Charts for Layout Reuse
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Chart layout; Reuse; Reverse-engineering; Deconstruction
AB To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings. However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts. In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones, as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts). We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints. Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data. On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction. In a chart reproduction study, participants could easily reuse existing charts on new datasets. We discuss the current limitations of Mystique and future research directions.
C1 [Chen, Chen; Chang, Yunjeong; Liu, Zhicheng] Univ Maryland, College Pk 20742, MD USA.
   [Lee, Bongshin] Microsoft Res, Redmond, WA USA.
   [Wang, Yunhai] Shandong Univ, Qingdao, Shandong, Peoples R China.
C3 University System of Maryland; University of Maryland College Park;
   Microsoft; Shandong University
RP Chen, C (corresponding author), Univ Maryland, College Pk 20742, MD USA.
EM cchen24@umd.edu; bongshin@microsoft.com; cloudseawang@gmail.com;
   ychangs2@terpmail.umd.edu; leozcliu@umd.edu
RI Chen, Chen/IZQ-5537-2023
OI Chen, Chen/0000-0003-3171-0657; Liu, Zhicheng/0000-0002-1015-2759
FU NSF
FX No Statement Available
CR Bako Hannah K, 2023, IEEE Trans Vis Comput Graph, V29, P1048, DOI 10.1109/TVCG.2022.3209490
   Battle L, 2022, IEEE VIS CONF, P1, DOI 10.1109/VIS54862.2022.00009
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Bostock M., 2021, bl.ocks.org
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bruls M, 2000, SPRING COMP SCI, P33
   Chartmaker, 2021, The chartmaker directory
   Chen C, 2023, COMPUT GRAPH FORUM, V42, P449, DOI 10.1111/cgf.14855
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choudhury S. R., 2016, P INT WORKSH SEM BIG, V1, DOI DOI 10.1145/2928294.29283052
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Figma, 2021, Figma Charts and Infographics
   Given C., A bar chart composed of treemaps
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Harper J, 2018, IEEE T VIS COMPUT GR, V24, P1274, DOI 10.1109/TVCG.2017.2659744
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jiang WX, 2021, IEEE IMAGE PROC, P1204, DOI 10.1109/ICIP42928.2021.9506171
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Masson D., 2023, P 2023 CHI C HUM FAC, V147, DOI DOI 10.1145/3544548.35811132,3
   McNutt A. M., 2021, P 2021 CHI C HUM FAC, V17, DOI DOI 10.1145/3411764.34453562
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Nielsen Frank, 2016, Introduction to HPC with MPI for Data Science, P195, DOI [DOI 10.1007/978-3-319-21903-5, 10.1007/978-3-319-21903-5_8, DOI 10.1007/978-3-319-21903-5_8]
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Observable, 2023, Observable plot
   Po-Shen Lee, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P79
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Shi XY, 2019, INT CONF ACOUST SPEE, P1343, DOI [10.1109/ICASSP.2019.8683824, 10.1109/icassp.2019.8683824]
   Shneiderman B, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P73, DOI 10.1109/INFVIS.2001.963283
   Shukla S, 2008, INT J DOC ANAL RECOG, V11, P111, DOI 10.1007/s10032-008-0065-5
   Tableau, 2022, Tableau Prep Builder
   Tableau, 2021, Tableau Public
   Trifacta, 2022, Designer Cloud Data Wrangling Software and Tools
   Walny J, 2020, IEEE T VIS COMPUT GR, V26, P12, DOI 10.1109/TVCG.2019.2934538
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wood J, 2008, IEEE T VIS COMPUT GR, V14, P1348, DOI 10.1109/TVCG.2008.165
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
NR 48
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 447
EP 457
DI 10.1109/TVCG.2023.3327354
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500122
PM 37883270
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lin, TC
   Aouididi, A
   Chen, ZT
   Beyer, J
   Pfister, H
   Wang, JH
AF Lin, Tica
   Aouididi, Alexandre
   Chen, Zhutian
   Beyer, Johanna
   Pfister, Hanspeter
   Wang, Jui-Hsien
TI VIRD: Immersive Match Video Analysis for High-Performance Badminton
   Coaching
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sports Analytics; Immersive Analytics; Data Visualization
ID VISUALIZATION; ENVIRONMENT; NAVIGATION
AB Badminton is a fast-paced sport that requires a strategic combination of spatial, temporal, and technical tactics. To gain a competitive edge at high-level competitions, badminton professionals frequently analyze match videos to gain insights and develop game strategies. However, the current process for analyzing matches is time-consuming and relies heavily on manual note-taking, due to the lack of automatic data collection and appropriate visualization tools. As a result, there is a gap in effectively analyzing matches and communicating insights among badminton coaches and players. This work proposes an end-to-end immersive match analysis pipeline designed in close collaboration with badminton professionals, including Olympic and national coaches and players. We present VIRD, a VR Bird (i.e., shuttle) immersive analysis tool, that supports interactive badminton game analysis in an immersive environment based on 3D reconstructed game views of the match video. We propose a top-down analytic workflow that allows users to seamlessly move from a high-level match overview to a detailed game view of individual rallies and shots, using situated 3D visualizations and video. We collect 3D spatial and dynamic shot data and player poses with computer vision models and visualize them in VR. Through immersive visualizations, coaches can interactively analyze situated spatial data (player positions, poses, and shot trajectories) with flexible viewpoints while navigating between shots and rallies effectively with embodied interaction. We evaluated the usefulness of VIRD with Olympic and national-level coaches and players in real matches. Results show that immersive analytics supports effective badminton match analysis with reduced context-switching costs and enhances spatial understanding with a high sense of presence.
C1 [Lin, Tica; Aouididi, Alexandre; Chen, Zhutian; Beyer, Johanna; Pfister, Hanspeter] Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lin, Tica; Wang, Jui-Hsien] Adobe Res, San Jose, CA 95110 USA.
   [Aouididi, Alexandre] Ecole Polytech Fed Lausanne EPFL, Lausanne, Switzerland.
C3 Adobe Systems Inc.; Swiss Federal Institutes of Technology Domain; Ecole
   Polytechnique Federale de Lausanne
RP Lin, TC (corresponding author), Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.; Lin, TC (corresponding author), Adobe Res, San Jose, CA 95110 USA.
EM mlin@g.harvard.edu; alexandre.aouididi@gmail.com;
   ztchen@seas.harvard.edu; johanna.m.beyer@gmail.com;
   pfister@seas.harvard.edu; juiwang@alumni.stanford.edu
OI Lin, Tica/0000-0002-2860-0871; Pfister, Hanspeter/0000-0002-3620-2582;
   Beyer, Johanna/0000-0002-3505-9171
FU Adobe Research
FX No Statement Available
CR [Anonymous], 2023, XR Interaction Toolkit
   [Anonymous], 2023, 2021 Denmark Open - Final, Men Single, Kento Momota (JPN) vs Viktor Axelsen (DEN)
   [Anonymous], 2023, 2020 BWF World Tour Finals, Women Single, Tai Tzu Ying (TPE) vs. Carolina Marin (ESP)
   [Anonymous], 2022, Unity Technologies
   Bach B, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299019
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chang TC, 2015, IEEE GLOB COMM CONF, DOI [10.1109/GLOCOM.2015.7417476, 10.1109/ICSENS.2015.7370446]
   Chen HongHua Chen HongHua, 2011, China Condiment, P1
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Clutch, Ai-powered performance analysis for badminton
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Farin D., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5307, P80, DOI 10.1117/12.526813
   Hachet Martin., 2011, Proceedings of the 24th annual ACM symposium on User interface software and technology, P587, DOI DOI 10.1145/2047196.2047273
   Haq M. A., 2022, 2022 INT EL S IES, V8, DOI [10.1109/ies55876.2022.9888717, DOI 10.1109/IES55876.2022.9888717]
   Heaton C., 2023, MIT SLOAN SPORTS AN
   Helbig C, 2014, ENVIRON EARTH SCI, V72, P3767, DOI 10.1007/s12665-014-3136-6
   Huang YC, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909871
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   hudl, Tools to help every team, coach and athlete improve
   Kopania M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218098
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Li ZH, 2022, LECT NOTES COMPUT SC, V13665, P590, DOI 10.1007/978-3-031-20065-6_34
   Lin T., 2020, 4 WORKSH IMM AN ENV, P2020, DOI DOI 10.48550/ARXIV.2004.08010
   Lin T., 2021, P ACM C HUM FACT COM, P13, DOI [DOI 10.1145/3411764.34456492, 10.1145/3411764.34456492,9, DOI 10.1145/3411764.34456492,9, 10.1145/3411764.3445649, DOI 10.1145/3411764.3445649]
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Liu P, 2022, IEEE COMPUT SOC CONF, P3512, DOI 10.1109/CVPRW56347.2022.00395
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   López D, 2016, IEEE T VIS COMPUT GR, V22, P1616, DOI 10.1109/TVCG.2015.2440233
   Luyang Zhu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P177, DOI 10.1007/978-3-030-58558-7_11
   Lyu Y, 2021, J SENSORS, V2021, DOI 10.1155/2021/3803387
   Marin Carolina, 2023, BWF World Championship Quarter Final, Women Single, Akane Yamaguchi (JPN)
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Monet N., 2022, arXiv (Cornell University), V10, DOI [10.48550/arxiv.2210.14165, DOI 10.48550/ARXIV.2210.14165]
   Moran A., 2015, IEEE C HIGH PERF EXT, P1, DOI DOI 10.1109/HPEC.2015.7322473
   Owens N., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P182, DOI 10.1049/cp:20030517
   Patton A., 2021, MIT SLOAN SPORTS AN
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Pingali G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1433, DOI 10.1109/ICME.2000.871036
   Plumlee Matthew., 2002, In Proceedings of AVI 2002, P59, DOI DOI 10.1145/1556262.1556270
   Rahmad N.A., 2019, Indonesian Journal of Electrical Engineering and Computer Science, V14, P1330
   Ready M., 2018, WORKSH IMM AN EXPL F
   Rematas K, 2018, PROC CVPR IEEE, P4738, DOI 10.1109/CVPR.2018.00498
   Rezzil, 2020, About us
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Sumiya M, 2022, ADJUNCT PROCEEDINGS OF THE 35TH ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2022, DOI 10.1145/3526114.3558639
   Tuyls K, 2021, J ARTIF INTELL RES, V71, P41
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Zou LY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1289, DOI [10.1109/VR.2019.8798041, 10.1109/vr.2019.8798041]
   Zou SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10976, DOI 10.1109/ICCV48922.2021.01081
NR 64
TC 2
Z9 2
U1 5
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 458
EP 468
DI 10.1109/TVCG.2023.3327161
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500067
PM 37878442
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Feyer, SP
   Pinaud, B
   Kobourov, S
   Brich, N
   Krone, M
   Kerren, A
   Behrisch, M
   Schreiber, F
   Klein, K
AF Feyer, Stefan P.
   Pinaud, Bruno
   Kobourov, Stephen
   Brich, Nicolas
   Krone, Michael
   Kerren, Andreas
   Behrisch, Michael
   Schreiber, Falk
   Klein, Karsten
TI 2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network
   Visualisations in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Three-dimensional displays; Data
   visualization; Taxonomy; Nonhomogeneous media; Surveys; Network;
   Guidelines; VisDesign; HumanQuant; CompSystems
ID OF-THE-ART; GRAPHS; DETAIL
AB Relational information between different types of entities is often modelled by a multilayer network (MLN) - a network with subnetworks represented by layers. The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question. Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis. Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays. We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements. The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers. We found no clear overall winner. However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs.
C1 [Feyer, Stefan P.; Klein, Karsten] Univ Konstanz, Life Sci Informat, Constance, Germany.
   [Pinaud, Bruno] Univ Bordeaux, CNRS, Bordeaux INP, UMR 5800,LaBRI, Talence, France.
   [Kobourov, Stephen] Univ Arizona, Tucson, AZ USA.
   [Brich, Nicolas; Krone, Michael] Univ Tubingen, D-55411 Tubingen, Germany.
   [Krone, Michael] NYU, New York, NY USA.
   [Kerren, Andreas] Linkoping Univ, Linkoping, Sweden.
   [Kerren, Andreas] Linnaeus Univ, Vaxjo, Sweden.
   [Behrisch, Michael] Univ Utrecht, Utrecht, Netherlands.
   [Schreiber, Falk] Univ Konstanz, Constance, Germany.
   [Schreiber, Falk] Monash Univ, Melbourne, Australia.
C3 University of Konstanz; Universite de Bordeaux; Centre National de la
   Recherche Scientifique (CNRS); University of Arizona; Eberhard Karls
   University of Tubingen; New York University; Linkoping University;
   Linnaeus University; Utrecht University; University of Konstanz; Monash
   University
RP Feyer, SP (corresponding author), Univ Konstanz, Life Sci Informat, Constance, Germany.
EM stefan.feyer@uni-konstanz.de; bruno.pinaud@u-bordeaux.fr;
   kobourov@cs.arizona.edu; nicolas.brich@uni-tuebingen.de;
   michael.krone@uni-tuebingen.de; andreas.kerren@liu.se; m.behrisch@uu.nl;
   falk.schreiber@uni-konstanz.de; karsten.klein@uni-konstanz.de
RI Kerren, Andreas/AAV-9187-2020; Krone, Michael/HJI-9309-2023; Kobourov,
   Stephen/A-3016-2008
OI Behrisch, Michael/0000-0002-1102-103X; Kobourov,
   Stephen/0000-0002-0477-2724; Krone, Michael/0000-0002-1445-7568; Brich,
   Nicolas/0000-0003-3175-0464; Feyer, Stefan Paul/0009-0004-8574-0741
FU DFG
FX No Statement Available
CR Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Baggag A, 2018, EPJ DATA SCI, V7, DOI 10.1140/epjds/s13688-018-0139-7
   Bardoscia M, 2021, NAT REV PHYS, V3, P490, DOI 10.1038/s42254-021-00322-5
   Becker SO, 2020, AM SOCIOL REV, V85, P857, DOI 10.1177/0003122420948059
   Berger P, 2019, IEEE INT CON INF VIS, P261, DOI 10.1109/IV.2019.00051
   Bianconi G, 2018, MULTILAYER NETWORKS: STRUCTURE AND FUNCTION, DOI 10.1093/oso/9780198753919.001.0001
   Bornhofen S, 2020, APPL NETW SCI, V5, DOI 10.1007/s41109-020-00295-x
   Brandes U, 2004, LECT NOTES COMPUT SC, V2912, P111
   Brandes U., 2004, J Integr Bioinform, V1, P11
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chimani M., 2013, Handbook of Graph Drawing and Visualization, P543, DOI [10.1201/b153854, DOI 10.1201/B153854]
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Cuenca E, 2022, IEEE T VIS COMPUT GR, V28, P1634, DOI 10.1109/TVCG.2021.3067820
   De Domenico M, 2015, J COMPLEX NETW, V3, P159, DOI 10.1093/comnet/cnu038
   Dickison M. E., 2016, Visualizing Multilayer Networks, P79, DOI DOI 10.1017/CBO9781139941907.0052
   Doutreligne S, 2014, SYMP LARG DATA ANAL, P109, DOI 10.1109/LDAV.2014.7013213
   Drogemuller A, 2020, J COMPUT LANG, V56, DOI 10.1016/j.cola.2019.100937
   Estrada E, 2020, PHYS REP, V869, P1, DOI 10.1016/j.physrep.2020.07.005
   Greffard N, 2012, LECT NOTES COMPUT SC, V7034, P215
   Hammoud Zaynab, 2020, Big Data Analytics, V5, P1, DOI 10.1186/s41044-020-00046-0
   Horak T, 2021, IEEE T VIS COMPUT GR, V27, P1644, DOI 10.1109/TVCG.2020.3030371
   Interdonato R, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100246
   Joos L, 2022, IEEE T VIS COMPUT GR, V28, P3651, DOI 10.1109/TVCG.2022.3203001
   Kerren A., 2014, LNCS, V8380, DOI DOI 10.1007/978-3-319-06793-3
   Kerren A, 2014, IEEE COMPUT GRAPH, V34, P69, DOI 10.1109/MCG.2014.122
   Kivela M, 2014, J COMPLEX NETW, V2, P203, DOI 10.1093/comnet/cnu016
   Korkut EH, 2023, VIRTUAL REAL-LONDON, V27, P1447, DOI 10.1007/s10055-023-00753-8
   Kotlarek J, 2020, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis48177.2020.4722
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Kwon OH, 2016, IEEE T VIS COMPUT GR, V22, P1802, DOI 10.1109/TVCG.2016.2520921
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Liu TY, 2022, NUCLEIC ACIDS RES, V50, pW551, DOI 10.1093/nar/gkac352
   Maes A, 2018, J INTEGR BIOINFORMAT, V15, DOI 10.1515/jib-2018-0006
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   McGee F., 2021, Visual Analysis of Multilayer Networks, DOI DOI 10.2200/S01094ED1V01Y202104VIS0122,3,4,6,9
   Murray P, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1443-5
   Nicholson DN, 2020, COMPUT STRUCT BIOTEC, V18, P1414, DOI 10.1016/j.csbj.2020.05.017
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Okoe M, 2019, IEEE T VIS COMPUT GR, V25, P2940, DOI 10.1109/TVCG.2018.2865940
   Ossi L., Multilayer Network Exploration Tool in virtual reality
   Pirch S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22570-w
   Pohl M., 2019, WORKSH VIS MULT NETW
   Prouzeau A, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P241, DOI 10.1145/3343055.3359709
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase H., 2012, Experimental Human-Computer Interaction: A Practical Guide With Visual Examples, DOI DOI 10.1017/CBO97805118445225
   Rhyne TM, 2021, IEEE COMPUT GRAPH, V41, P125, DOI 10.1109/MCG.2021.3075258
   Roberts J. C., 2021, Computer Graphics and Visual Computing (CGVC), DOI DOI 10.2312/CGVC.20211309
   Roberts JC, 2014, LECT NOTES COMPUT SC, V8380, P127, DOI 10.1007/978-3-319-06793-3_7
   Santos A, 2022, NAT BIOTECHNOL, V40, P692, DOI 10.1038/s41587-021-01145-6
   Schreiber F, 2014, LECT NOTES COMPUT SC, V8380, P175, DOI 10.1007/978-3-319-06793-3_9
   Seok-Hee Hong, 2007, Journal of Graph Algorithms and Applications, V11, P371, DOI 10.7155/jgaa.00151
   SHOEMAKE K, 1992, GRAPH INTER, P151
   Sorger J, 2021, COMPUT GRAPH FORUM, V40, P241, DOI 10.1111/cgf.14417
   Sorger J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P144, DOI 10.1109/AIVR46125.2019.00030
   Unity Technologies, Unity
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Waagmeester A, 2020, ELIFE, V9, DOI 10.7554/eLife.52614
   Walsh B, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3173, DOI 10.1145/3340531.3412776
   Ware C, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279640.1279642
   Yang Y., 2006, P ACM INT C VIRT REA, P377, DOI [10.1145/1128923.1128992, DOI 10.1145/1128923.1128992]
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P1214, DOI 10.1109/TVCG.2020.3030427
   Zheng SJ, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa344
   Zhou GY, 2018, NUCLEIC ACIDS RES, V46, pW514, DOI 10.1093/nar/gky510
NR 67
TC 3
Z9 3
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 469
EP 479
DI 10.1109/TVCG.2023.3327402
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500124
PM 37883262
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, LX
   Isenberg, T
   Xie, FQ
   Liang, HN
   Yu, LY
AF Zhao, Lixiang
   Isenberg, Tobias
   Xie, Fuqi
   Liang, Hai-Ning
   Yu, Lingyun
TI MeTACAST: Target- and Context-Aware Spatial Selection in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial selection; immersive analytics; virtual reality (VR);
   target-aware and context-aware interaction for visualization
ID GALAXIES; OBJECTS
AB We propose three novel spatial data selection techniques for particle data in VR visualization environments. They are designed to be target- and context-aware and be suitable for a wide range of data features and complex scenarios. Each technique is designed to be adjusted to particular selection intents: the selection of consecutive dense regions, the selection of filament-like structures, and the selection of clusters-with all of them facilitating post-selection threshold adjustment. These techniques allow users to precisely select those regions of space for further exploration-with simple and approximate 3D pointing, brushing, or drawing input-using flexible point- or path-based input and without being limited by 3D occlusions, non-homogeneous feature density, or complex data shapes. These new techniques are evaluated in a controlled experiment and compared with the Baseline method, a region-based 3D painting selection. Our results indicate that our techniques are effective in handling a wide range of scenarios and allow users to select data based on their comprehension of crucial features. Furthermore, we analyze the attributes, requirements, and strategies of our spatial selection methods and compare them with existing state-of-the-art selection methods to handle diverse data features and situations. Based on this analysis we provide guidelines for choosing the most suitable 3D spatial selection techniques based on the interaction environment, the given data characteristics, or the need for interactive post-selection threshold adjustment.
C1 [Zhao, Lixiang; Xie, Fuqi; Liang, Hai-Ning; Yu, Lingyun] Xian Jiaotong Liverpool Univ, Xian, Peoples R China.
   [Isenberg, Tobias] Univ Paris Saclay, INRIA, LISN, CNRS, Paris, France.
C3 Xi'an Jiaotong-Liverpool University; Centre National de la Recherche
   Scientifique (CNRS); Inria; Universite Paris Saclay; Universite Paris
   Cite
RP Yu, LY (corresponding author), Xian Jiaotong Liverpool Univ, Xian, Peoples R China.
EM lixiang.zhao17@student.xjtlu.edu.cn; tobias.isenberg@inria.fr;
   fuqi.xie18@student.xjtlu.edu.cn; haining.liang@xjtlu.edu.cn;
   lingyun.yu@xjtlu.edu.cn
RI ; Isenberg, Tobias/A-7575-2008
OI Zhao, Lixiang/0000-0001-6181-1673; Liang, Hai-Ning/0000-0003-3600-8955;
   Xie, Fuqi/0009-0008-4728-9346; Isenberg, Tobias/0000-0001-7953-8644
FU NSFC
FX No Statement Available
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Baguley T, 2009, BRIT J PSYCHOL, V100, P603, DOI 10.1348/000712608X377117
   Balogun MB, 2019, AFRICON, DOI [10.1109/africon46755.2019.9133906, 10.1145/3290605.3300331]
   BECHTOLD J, 1994, ASTROPHYS J SUPPL S, V91, P1, DOI 10.1086/191937
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Besancon L, 2019, COMPUT GRAPH FORUM, V38, P553, DOI 10.1111/cgf.13710
   Bond JR, 1996, NATURE, V380, P603, DOI 10.1038/380603a0
   Brown R., Valve index
   Brunhart-Lupo N, 2016, 2016 WORKSHOP ON IMMERSIVE ANALYTICS (IA), P19, DOI 10.1109/IMMERSIVE.2016.7932377
   Chen W, 2009, IEEE T VIS COMPUT GR, V15, P1433, DOI 10.1109/TVCG.2009.112
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P195, DOI 10.1109/TVCG.2019.2934332
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, IEEE PAC VIS SYMP, P46, DOI 10.1109/PACIFICVIS.2017.8031578
   Cumming G, 2014, PSYCHOL SCI, V25, P7, DOI 10.1177/0956797613504966
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   de Haan Gerwin., 2005, Proceedings of the 11th Eurographics conference on Virtual Environments EGVE'05, P201, DOI [10.2312/EGVE/IPT_EGVE2005/201-209, DOI 10.2312/EGVE/IPT_EGVE2005/201-209]
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Dragicevic Pierre, 2014, CHI 14 HUM FACT COMP, P607, DOI DOI 10.1145/2559206.2578881
   Ferdosi BJ, 2011, ASTRON ASTROPHYS, V531, DOI 10.1051/0004-6361/201116878
   Franzluebbers A, 2022, PROCEEDINGS OF THE 2022 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2022, DOI 10.1145/3565970.3567696
   Gomez SR, 2010, LECT NOTES COMPUT SC, V6454, P373, DOI 10.1007/978-3-642-17274-8_37
   Grossman Tovi, 2006, P 19 ANN ACM S US IN, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Guest M, 2001, Arxiv, DOI arXiv:math/0104155
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hentschel B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P253, DOI 10.1109/VR.2009.4811041
   Hong Jiayi, 2021, GI 2021 GRAPHICS INT, P213, DOI [DOI 10.20380/GI2021.33, 10/kt3q, DOI 10.20380/G12021.33]
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Keefe DF, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P51
   König WA, 2009, LECT NOTES COMPUT SC, V5726, P658, DOI 10.1007/978-3-642-03655-2_73
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Lee SY, 2003, PROC SPIE, V4756, P38, DOI 10.1117/12.497665
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Lubos P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P191
   Lucas III J. F., 2005, THESIS VIRGINIA POLY
   Lucas John, 2005, Design and evaluation of 3D multiple object selection techniques
   Maletic JI, 2001, PROG COMPREHEN, P26, DOI 10.1109/WPC.2001.921711
   Malmberg F, 2006, LECT NOTES COMPUT SC, V4245, P663
   Maslych M, 2023, Symposium Virtual Re, P460, DOI 10.1109/VR55154.2023.00061
   McDonald T, 2021, IEEE T VIS COMPUT GR, V27, P744, DOI 10.1109/TVCG.2020.3030363
   Montano-Murillo RA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P53, DOI [10.1109/VR46266.2020.00-81, 10.1109/VR46266.2020.1581198507712]
   Owada S., 2005, PROC I3D, P111, DOI [10.1145/1053427.1053445, DOI 10.1145/1053427.1053445]
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Pivovar J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P907, DOI 10.1109/VRW55335.2022.00307
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Sereno M, 2022, COMPUT GRAPH FORUM, V41, P403, DOI 10.1111/cgf.14550
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Springel V, 2005, NATURE, V435, P629, DOI 10.1038/nature03597
   Springel V, 2008, MON NOT R ASTRON SOC, V391, P1685, DOI 10.1111/j.1365-2966.2008.14066.x
   Stenholt R., 2012, Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology - VRST'12, P105, DOI [DOI 10.1145/2407336.2407357, 10.1145/2407336, DOI 10.1145/2407336]
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tietjen C., 2008, Bildverarbeitung fur die Medizin (BVM), P407, DOI [10.1007/978-3-540-78640-5_82, DOI 10.1007/978-3-540-78640-5_82]
   VandenBos G.R., 2009, PUBL MAN AM PSYCH AS
   vanTeylingen R, 1997, IEEE T VIS COMPUT GR, V3, P65, DOI 10.1109/2945.582350
   Wei YS, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581042
   Wiebel A, 2012, IEEE T VIS COMPUT GR, V18, P2236, DOI 10.1109/TVCG.2012.292
   Wills GJ, 1996, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION '96, PROCEEDINGS, P54, DOI 10.1109/INFVIS.1996.559216
   Wingrave CA, 2005, P IEEE VIRT REAL ANN, P163
   Wyvill G., 1986, Visual Computer, V2, P227, DOI 10.1007/BF01900346
   Xu PF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366161
   Yu LY, 2016, IEEE T VIS COMPUT GR, V22, P886, DOI 10.1109/TVCG.2015.2467202
   Yu LY, 2012, IEEE T VIS COMPUT GR, V18, P2245, DOI 10.1109/TVCG.2012.217
   Zhao LX, 2022, IEEE INT SYMP M AU R, P118, DOI 10.1109/ISMAR-Adjunct57072.2022.00031
NR 65
TC 2
Z9 2
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 480
EP 494
DI 10.1109/TVCG.2023.3326517
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500026
PM 37871080
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Saffo, D
   Di Bartolomeo, S
   Crnovrsanin, T
   South, L
   Raynor, J
   Yildirim, C
   Dunne, C
AF Saffo, David
   Di Bartolomeo, Sara
   Crnovrsanin, Tarik
   South, Laura
   Raynor, Justin
   Yildirim, Caglar
   Dunne, Cody
TI Unraveling the Design Space of Immersive Analytics: A Systematic Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Surveys; Systematics;
   Taxonomy; Market research; Collaboration; Immersive Analytics;
   Systematic Review; Survey; Augmented Reality; Virtual Reality; Design
   Space
ID AUGMENTED REALITY; VISUALIZATION
AB Immersive analytics has emerged as a promising research area, leveraging advances in immersive display technologies and techniques, such as virtual and augmented reality, to facilitate data exploration and decision-making. This paper presents a systematic literature review of 73 studies published between 2013-2022 on immersive analytics systems and visualizations, aiming to identify and categorize the primary dimensions influencing their design. We identified five key dimensions: Academic Theory and Contribution, Immersive Technology, Data, Spatial Presentation, and Visual Presentation. Academic Theory and Contribution assess the motivations behind the works and their theoretical frameworks. Immersive Technology examines the display and input modalities, while Data dimension focuses on dataset types and generation. Spatial Presentation discusses the environment, space, embodiment, and collaboration aspects in IA, and Visual Presentation explores the visual elements, facet and position, and manipulation of views. By examining each dimension individually and cross-referencing them, this review uncovers trends and relationships that help inform the design of immersive systems visualizations. This analysis provides valuable insights for researchers and practitioners, offering guidance in designing future immersive analytics systems and shaping the trajectory of this rapidly evolving field. A free copy of this paper and all supplemental materials are available at osf.io/5ewaj.
C1 [Saffo, David; Di Bartolomeo, Sara; Crnovrsanin, Tarik; South, Laura; Raynor, Justin; Yildirim, Caglar; Dunne, Cody] Northeastern Univ, Boston, MA 02138 USA.
   [Saffo, David] JP Morgan Chase & Co, New York, NY 10017 USA.
C3 Northeastern University; JP Morgan Chase & Company
RP Saffo, D (corresponding author), Northeastern Univ, Boston, MA 02138 USA.; Saffo, D (corresponding author), JP Morgan Chase & Co, New York, NY 10017 USA.
EM david.saffo@jpmchase.com; dibartolomeo.s@northeastern.edu;
   t.crnovrsanin@northeastern.edu; south.l@northeastern.edu;
   raynor.j@northeastern.edu; c.yildirim@northeastern.edu;
   c.dunne@northeastern.edu
RI Di Bartolomeo, Sara/HNR-3613-2023; Yildirim, Caglar/AAH-5920-2021;
   Dunne, Cody/M-4444-2019; Raynor, Justin/JXL-7541-2024
OI South, Laura/0000-0003-4444-6314; Dunne, Cody/0000-0002-1609-9776; Di
   Bartolomeo, Sara/0000-0001-9517-3526; Raynor, Justin/0000-0002-7678-0846
FU Northeastern University
FX No Statement Available
CR Ard T, 2017, P IEEE VIRT REAL ANN, P465, DOI 10.1109/VR.2017.7892381
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Barreiros C, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P72, DOI [10.1109/ISMAR-Adjunct.2016.0043, 10.1109/ISMAR-Adjunct.2016.36]
   Barrios dell'Olio Giuliana, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1027, DOI 10.1145/3472749.3474803
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bhardwaj A, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489890
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Carmo MB, 2014, INT SYM MIX AUGMENT, P255, DOI 10.1109/ISMAR.2014.6948437
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Crnovrsanin T., 2023, P IEEE VIS 2023
   Danyluk K, 2022, IEEE T VIS COMPUT GR, V28, P1930, DOI 10.1109/TVCG.2020.3023336
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Gall A, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489851
   Gold L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P428, DOI 10.1109/VR50410.2021.00066
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   Hayatpur D., 2020, P 33 ANN ACM S US IN, P818, DOI DOI 10.1145/3379337.3415878
   Hu H, 2022, IEEE INT SYMP M AU R, P131, DOI 10.1109/ISMAR-Adjunct57072.2022.00033
   Huang JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1485, DOI [10.1109/VR.2019.8797996, 10.1109/vr.2019.8797996]
   Huang JB, 2022, IEEE INT SYMP M AU R, P111, DOI 10.1109/ISMAR-Adjunct57072.2022.00030
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Nguyen H, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P87, DOI 10.1109/ISMAR-Adjunct.2017.38
   Ivanov A., 2018, 2018 CHI C HUM FACT, P1, DOI [10.1145/3170427.31885443, DOI 10.1145/3170427.31885443]
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Joos L, 2022, IEEE T VIS COMPUT GR, V28, P3651, DOI 10.1109/TVCG.2022.3203001
   Kimmel S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489852
   Knierim P, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P170, DOI 10.1109/ISMAR-Adjunct.2018.00059
   Kraus M, 2020, IEEE T VIS COMPUT GR, V26, P525, DOI 10.1109/TVCG.2019.2934395
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   Laera F, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P269, DOI 10.1109/ISMAR-Adjunct51615.2020.00076
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1095, DOI 10.1109/TVCG.2020.3030435
   Leuze C, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P377, DOI 10.1109/ISMAR-Adjunct.2018.00109
   Li N., 2014, CHI 14 EXTENDED ABST, P1291
   Li RY, 2021, INT SYM MIX AUGMENT, P240, DOI 10.1109/ISMAR-Adjunct54149.2021.00056
   Li TM, 2022, IEEE INT SYMP M AU R, P124, DOI 10.1109/ISMAR-Adjunct57072.2022.00032
   Lin T., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34456495, DOI 10.1145/3411764.34456495]
   Liu JZ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580827
   Mahmood T, 2019, INT SYM MIX AUGMENT, P236, DOI 10.1109/ISMAR.2019.00021
   Marriott K., 2018, IMMERSIVE ANAL, V11190, DOI 10/kt9x
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P259, DOI 10.1007/978-3-030-01388-2_9
   Masai K, 2022, IEEE INT SYMP M AU R, P845, DOI 10.1109/ISMAR-Adjunct57072.2022.00182
   Merino L, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383017
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Munzner T., AK Peters Visualization series, P4
   Nam JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P747, DOI [10.1109/VR.2019.8797871, 10.1109/vr.2019.8797871]
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Pei YQ, 2019, I C VIRTUAL REALITY, P11, DOI 10.1109/ICVRV47840.2019.00011
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Ran LQ, 2016, I C VIRTUAL REALITY, P473, DOI 10.1109/ICVRV.2016.86
   Reichherzer C, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451839
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Romat H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376348
   Saffo David, 2021, P 2021 CHI C HUM FAC, P1, DOI 10.1145/3411764.3445426
   Saffo David., 2023, Through their eyes and in their shoes: Providing group awareness during collaboration across virtual reality and desktop platforms, DOI DOI 10.1145/3544548.3581093
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Schetinger V., 2023, Doom or deliciousness: Challenges and opportunities for visualization in the age of generative models, DOI [10.31219/osf.io/3jrcm9, DOI 10.31219/OSF.IO/3JRCM9]
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Seraji MR, 2022, IEEE INT SYMP M AU R, P146, DOI 10.1109/ISMAR-Adjunct57072.2022.00035
   Siang CV, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING (ICOCO), P347, DOI 10.1109/ICOCO53166.2021.9673569
   Ssin SY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P210, DOI [10.1109/VR.2019.8797812, 10.1109/vr.2019.8797812]
   Subramonyam H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300628
   Sun ZD, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188551
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   Tadeja SK, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313068
   Tatzgern M, 2013, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2013.6549347
   Tong W., 2023, Towards an understanding of distributed asymmetric collaborative visualization on problem-solving
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang H, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489923
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Wang Z, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489874
   Wen Zhen, 2023, IEEE Trans Vis Comput Graph, V29, P440, DOI 10.1109/TVCG.2022.3209475
   Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18
   Willett W, 2022, IEEE T VIS COMPUT GR, V28, P22, DOI 10.1109/TVCG.2021.3114844
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2021, IEEE T VIS COMPUT GR, V27, P4507, DOI 10.1109/TVCG.2020.3004137
   Zheng MY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P93, DOI 10.1109/ISMAR-Adjunct.2019.00039
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
NR 87
TC 5
Z9 5
U1 12
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 495
EP 506
DI 10.1109/TVCG.2023.3327368
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500084
PM 37878454
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Batch, A
   Butcher, PWS
   Ritsos, PD
   Elmqvist, N
AF Batch, Andrea
   Butcher, Peter W. S.
   Ritsos, Panagiotis D.
   Elmqvist, Niklas
TI Wizualization: A "Hard Magic" Visualization System for Immersive and
   Ubiquitous Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Immersive analytics; situated analytics; ubiquitous analytics; gestural
   interaction; voice interaction
ID HAND; MANIPULATION; EXPLORATION; INTERFACE; GESTURES; GRAMMAR; SPEECH;
   VEGA
AB What if magic could be used as an effective metaphor to perform data visualization and analysis using speech and gestures while mobile and on-the-go? In this paper, we introduce Wizualization, a visual analytics system for eXtended Reality (XR) that enables an analyst to author and interact with visualizations using such a magic system through gestures, speech commands, and touch interaction. Wizualization is a rendering system for current XR headsets that comprises several components: a cross-device (or Arcane Focuses) infrastructure for signalling and view control (Weave), a code notebook (Spellbook), and a grammar of graphics for XR (Optomancy). The system offers users three modes of input: gestures, spoken commands, and materials. We demonstrate Wizualization and its components using a motivating scenario on collaborative data analysis of pandemic data across time and space.
C1 [Batch, Andrea] US Bur Econ Anal, Washington, DC 20233 USA.
   [Butcher, Peter W. S.; Ritsos, Panagiotis D.] Bangor Univ, Bangor, Wales.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
   [Elmqvist, Niklas] Univ Maryland, College Pk, MD USA.
C3 Bangor University; Aarhus University; University System of Maryland;
   University of Maryland College Park
RP Batch, A (corresponding author), US Bur Econ Anal, Washington, DC 20233 USA.
EM andrea.c.batch@gmail.com; p.butcher@bangor.ac.uk; p.ritsos@bangor.ac.uk;
   elm@cs.au.dk
RI Ritsos, Panagiotis/AAE-8990-2022
OI Ritsos, Panagiotis/0000-0001-9308-3885; Elmqvist,
   Niklas/0000-0001-5805-5301; Butcher, Peter/0000-0002-3361-627X
FU U.S. National Science Foundation
FX No Statement Available
CR Ahlberg C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P619, DOI 10.1145/142750.143054
   Bach B, 2018, IEEE T VIS COMPUT GR, V24, P457, DOI 10.1109/TVCG.2017.2745941
   Badam S. K., 2017, PROC IEEE VIS WORKSH
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Batch A, 2023, COMPUT GRAPH FORUM, V42, P349, DOI 10.1111/cgf.14835
   Batch A, 2020, IEEE T VIS COMPUT GR, V26, P536, DOI 10.1109/TVCG.2019.2934803
   Berndt D.J., 1994, P 3 INT C KNOWL DISC, P359
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503
   Büschel W, 2018, LECT NOTES COMPUT SC, V11190, P95, DOI 10.1007/978-3-030-01388-2_4
   Buschel W., 2021, PROC ACM CHI, DOI [10.1145/3411764.34456512, DOI 10.1145/3411764.34456512]
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Chin-Shyurng F, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030528
   Clarke A. C., 1972, Profiles of the Future: An Inquiry Into the Limits of the Possible, P1
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/vr.2019.8797978, 10.1109/VR.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, P2
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Elmqvist N, 2013, COMPUTER, V46, P86, DOI 10.1109/MC.2013.147
   Elmqvist N, 2011, INFORM VISUAL, V10, P327, DOI 10.1177/1473871611413180
   Elmqvist N, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1769
   Fennedy K, 2021, IEEE T VIS COMPUT GR, V27, P4425, DOI 10.1109/TVCG.2021.3101854
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Hall BD, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545614
   HAUPTMANN AG, 1993, INT J MAN MACH STUD, V38, P231, DOI 10.1006/imms.1993.1011
   He SZ, 2015, IEEE INT CONF INF VI, P83, DOI 10.1109/iV.2015.25
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   Jang SJ, 2016, IEEE T VIS COMPUT GR, V22, P21, DOI 10.1109/TVCG.2015.2468292
   Kallio S., 2006, PROC ACM AVI, P480, DOI [10.1145/1133265.1133363, DOI 10.1145/1133265.1133363]
   Keefe DF, 2008, IEEE T VIS COMPUT GR, V14, P835, DOI 10.1109/TVCG.2008.31
   Kim C, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P319, DOI 10.1145/3343055.3360742
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Ledo D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173610
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee B, 2012, IEEE T VIS COMPUT GR, V18, P2689, DOI 10.1109/TVCG.2012.204
   Li HH, 2020, INFORM SCIENCES, V534, P97, DOI 10.1016/j.ins.2020.04.009
   Liao J, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545702
   Lobo Maria Jesus, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427323
   Luo YQ, 2021, CONSUM COMM NETWORK, DOI 10.1109/CCNC49032.2021.9369458
   Maguire E, 2013, IEEE T VIS COMPUT GR, V19, P2576, DOI 10.1109/TVCG.2013.225
   Marriott K, 2018, LECT NOTES COMPUT SC, V11190, P25, DOI 10.1007/978-3-030-01388-2_2
   Marriott Kim, 2018, Immersive Analytics, V11190, DOI DOI 10.1007/978-3-030-01388-2
   McCormack J, 2018, LECT NOTES COMPUT SC, V11190, P57, DOI 10.1007/978-3-030-01388-2_3
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Nebeling M., 2020, PROC ACM CHI, P1
   Nielsen M, 2016, PROCEEDINGS OF THE 28TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2016), DOI 10.1145/3010915.3010951
   Norman D. A., 1986, User Centered System Design: New Perspectives on Human-Computer Interaction, P2
   Norman Donald A., 2010, Interactions, V17, P6, DOI [DOI 10.1145/1744161.1744163, 10.1145/1744161.1744163]
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Pu XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376466
   Reipschläger P, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383138
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Sanderson B., Sanderson's first law of magics
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schroeder D, 2016, IEEE T VIS COMPUT GR, V22, P877, DOI 10.1109/TVCG.2015.2467153
   Shin S, 2024, IEEE T VIS COMPUT GR, V30, P5147, DOI 10.1109/TVCG.2023.3285546
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   Stolte C, 2002, IEEE T VIS COMPUT GR, V8, P52, DOI 10.1109/2945.981851
   Tang JR, 2018, PATTERN RECOGN, V80, P21, DOI 10.1016/j.patcog.2018.02.011
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   W3C, 2017, WebXR
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wagner J, 2021, IEEE T VIS COMPUT GR, V27, P2513, DOI 10.1109/TVCG.2021.3067759
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Wickham H, 2010, J COMPUT GRAPH STAT, V19, P3, DOI 10.1198/jcgs.2009.07098
   Wilkinson L., 1999, The Grammar of Graphics, P3
   Willett W, 2022, IEEE T VIS COMPUT GR, V28, P22, DOI 10.1109/TVCG.2021.3114844
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Zeleznik R. C., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P163, DOI 10.1145/237170.237238
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 82
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 507
EP 517
DI 10.1109/TVCG.2023.3326580
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500054
PM 37874715
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, YF
   Qian, YF
   Qi, XY
   Cao, N
   Wang, DS
AF Wang, Yifang
   Qian, Yifan
   Qi, Xiaoyu
   Cao, Nan
   Wang, Dashun
TI <i>InnovationInsights:</i> A Visual Analytics Approach for Understanding
   the Dual Frontiers of Science and Technology
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Science of Science; Innovation; Academic Profiles; Patent Data;
   Publication Data; Visual Analytics
ID VISUALIZATION; COLLECTION; DESIGN; SYSTEM
AB Science has long been viewed as a key driver of economic growth and rising standards of living. Knowledge about how scientific advances support marketplace inventions is therefore essential for understanding the role of science in propelling real-world applications and technological progress. The increasing availability of large-scale datasets tracing scientific publications and patented inventions and the complex interactions among them offers us new opportunities to explore the evolving dual frontiers of science and technology at an unprecedented level of scale and detail. However, we lack suitable visual analytics approaches to analyze such complex interactions effectively. Here we introduce InnovationInsights, an interactive visual analysis system for researchers, research institutions, and policymakers to explore the complex linkages between science and technology, and to identify critical innovations, inventors, and potential partners. The system first identifies important associations between scientific papers and patented inventions through a set of statistical measures introduced by our experts from the field of the Science of Science. A series of visualization views are then used to present these associations in the data context. In particular, we introduce the Interplay Graph to visualize patterns and insights derived from the data, helping users effectively navigate citation relationships between papers and patents. This visualization thereby helps them identify the origins of technical inventions and the impact of scientific research. We evaluate the system through two case studies with experts followed by expert interviews. We further engage a premier research institution to test-run the system, helping its institution leaders to extract new insights for innovation. Through both the case studies and the engagement project, we find that our system not only meets our original goals of design, allowing users to better identify the sources of technical inventions and to understand the broad impact of scientific research; it also goes beyond these purposes to enable an array of new applications for researchers and research institutions, ranging from identifying untapped innovation potential within an institution to forging new collaboration opportunities between science and industry.
C1 [Wang, Yifang; Qian, Yifan; Wang, Dashun] Northwestern Univ, Ctr Sci Sci & Innovat, Evanston, IL 60201 USA.
   [Qi, Xiaoyu; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
C3 Northwestern University; Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
EM yifang.wang@kellogg.northwestern.edu;
   yifan.qian1@kellogg.northwestern.edu; qixiaoyu@tongji.edu.cn;
   nan.cao@tongji.edu.cn; dashun.wang@kellogg.northwestern.edu
RI Cao, Nan/O-5397-2014; Wang, Dashun/KHE-1484-2024
OI Wang, Dashun/0000-0002-7054-2206; Wang, Yifang/0000-0001-6267-9440; Cao,
   Nan/0000-0003-1316-7515; Qian, Yifan/0000-0002-3914-1981
FU Air Force Office of Scientific Research
FX No Statement Available
CR Abdelaal Moataz, 2023, IEEE Trans Vis Comput Graph, V29, P896, DOI 10.1109/TVCG.2022.3209427
   Ahmadpoor M, 2017, SCIENCE, V357, P583, DOI 10.1126/science.aam9527
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Ankam E., 2012, P CHI C HUM FACT COM
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Borner K., 2010, Atlas of science: Visualizing what we know, DOI [10.1007/s11192-011-0409-7, DOI 10.1007/S11192-011-0409-7]
   Boyack K. W., 2000, Technical report, P2
   Burch Michael, 2013, 2013 17th International Conference on Information Visualisation, P66, DOI 10.1109/IV.2013.8
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Bush V., 1990, Science-the Endless Frontier: a Report to the President on a Program for Postwar Scientific Research, V90, P1
   Cao HC, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581108
   Chan GYY, 2019, IEEE T VIS COMPUT GR, V25, P321, DOI 10.1109/TVCG.2018.2864826
   Chen C, 2013, Mapping scientific frontiers, DOI [10.1007/978-1-4471-5128-9, DOI 10.1007/978-1-4471-5128-9]
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Cohan A., 2020, ACL, DOI [10.48550/arXiv.2004.07180 5, DOI 10.48550/ARXIV.2004.071805]
   Dattolo A, 2022, IEEE ACCESS, V10, P21631, DOI 10.1109/ACCESS.2022.3153027
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng ZW, 2022, IEEE-CAA J AUTOMATIC, DOI 10.1109/JAS.2022.105407
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Dong A, 2019, PROCEEDINGS OF THE 12TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION, VINCI 2019, DOI 10.1145/3356422.3356430
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Fattal R, 2001, IEEE VISUAL, P403, DOI 10.1109/VISUAL.2001.964539
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Fekete J.-D., 2019, Progressive data analysis and visualization, DOI [10.4230/DagRep.8.10.19, DOI 10.4230/DAGREP.8.10.19]
   Fey M., 2019, ICLR WORKSH REPR LEA, DOI [10.48550/arXiv.1903.02428 5, DOI 10.48550/ARXIV.1903.024285]
   Fortunato S, 2018, SCIENCE, V359, DOI 10.1126/science.aao0185
   Gonzalez-Marquez R., 2023, bioRxiv, P2023, DOI DOI 10.1101/2023.04.10.5362082
   Guo Z., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/VCG.2022.3163727, DOI 10.1109/VCG.2022.3163727]
   Hao H., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1016, DOI [10.1109/VCG.2022.32094222, DOI 10.1109/VCG.2022.32094222]
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jones B. F., 2021, Rebuilding the Post-Pandemic Economy
   Karimi F, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P53, DOI 10.1145/2872518.2889385
   Kim YG, 2008, EXPERT SYST APPL, V34, P1804, DOI 10.1016/j.eswa.2007.01.033
   Kipf TN, 2016, arXiv:1609.02907, P1
   Koch S, 2011, IEEE T VIS COMPUT GR, V17, P557, DOI 10.1109/TVCG.2010.85
   KRUSKAL JB, 1983, AM STAT, V37, P162, DOI 10.2307/2685881
   Kutz DO, 2004, IEEE INFOR VIS, P983, DOI 10.1109/IV.2004.1320261
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Li G., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32150702, DOI 10.1109/TVCG.2022.32150702]
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Liang WX, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100584
   Liu L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25477-8
   Marx M, 2020, STRATEGIC MANAGE J, V41, P1572, DOI 10.1002/smj.3145
   Marx M, 2022, J ECON MANAGE STRAT, V31, P369, DOI 10.1111/jems.12455
   Morris S, 2002, COMPUT IND ENG, V43, P841, DOI 10.1016/S0360-8352(02)00143-2
   Mühlbacher T, 2018, IEEE T VIS COMPUT GR, V24, P174, DOI 10.1109/TVCG.2017.2745158
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P486, DOI 10.1109/TVCG.2021.3114820
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   OpenAlex, ABOUT US
   Pandey A, 2022, IEEE T VIS COMPUT GR, V28, P3563, DOI 10.1109/TVCG.2021.3064037
   PatentsView, ABOUT US
   Phan D, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P219, DOI 10.1109/INFVIS.2005.1532150
   Qian YF, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100237
   Qian YF, 2022, IEEE T NEUR NET LEAR, V33, P1663, DOI 10.1109/TNNLS.2020.3043196
   Sarvghad A, 2023, IEEE T VIS COMPUT GR, V29, P3340, DOI 10.1109/TVCG.2022.3158236
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sun MY, 2019, IEEE T VIS COMPUT GR, V25, P2983, DOI 10.1109/TVCG.2018.2861397
   Tovanich N, 2022, IEEE T VIS COMPUT GR, V28, P497, DOI 10.1109/TVCG.2021.3114787
   USPTO, ABOUT US
   uspto, Cooperative Patent Classification (CPC)
   Uzzi B, 2013, SCIENCE, V342, P468, DOI 10.1126/science.1240474
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Verbeek K, 2011, IEEE T VIS COMPUT GR, V17, P2536, DOI 10.1109/TVCG.2011.202
   Wang D., 2021, The science of science, DOI [10.1017/97811086108341, DOI 10.1017/97811086108341]
   Wang DS, 2013, SCIENCE, V342, P127, DOI 10.1126/science.1237825
   Wang KS, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00045
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang Y, 2019, J VISUAL-JAPAN, V22, P941, DOI 10.1007/s12650-019-00585-2
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P475, DOI 10.1109/TVCG.2021.3114790
   Wang YF, 2022, IEEE T VIS COMPUT GR, V28, P3441, DOI 10.1109/TVCG.2021.3067200
   Windhager Florian, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P268
   Wu A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1026, DOI [10.1109/TVCG.2022.32093602, DOI 10.1109/TVCG.2022.32093602]
   Wu LF, 2019, NATURE, V566, P378, DOI 10.1038/s41586-019-0941-9
   Wu YH, 2016, IEEE T VIS COMPUT GR, V22, P260, DOI [10.1109/TVCG.2015.2468151, 10.1109/TVCG.2015.2465151]
   Ye YL, 2024, IEEE T VIS COMPUT GR, V30, P3224, DOI 10.1109/TVCG.2022.3229023
   Yin YA, 2022, NAT HUM BEHAV, V6, P1344, DOI 10.1038/s41562-022-01397-5
   Yin Y, 2021, SCIENCE, V371, P128, DOI 10.1126/science.abe3084
NR 78
TC 0
Z9 0
U1 10
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 518
EP 528
DI 10.1109/TVCG.2023.3327387
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500079
PM 37878444
DA 2024-11-06
ER

PT J
AU Guo, YH
   Luo, YC
   Lu, KR
   Li, LF
   Yang, HZ
   Yuan, XR
AF Guo, Yuhan
   Luo, Yuchu
   Lu, Keer
   Li, Linfang
   Yang, Haizheng
   Yuan, Xiaoru
TI LiberRoad: Probing into the Journey of Chinese Classics Through Visual
   Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; digital humanities; spatial uncertainty; trajectory
   visualization; book movement; historical data
ID TEMPORAL EVENT SEQUENCES; VISUALIZATION; UNCERTAINTY; MOVEMENT;
   GEOVISUALIZATION; FLOW
AB Books act as a crucial carrier of cultural dissemination in ancient times. This work involves joint efforts between visualization and humanities researchers, aiming at building a holistic view of the cultural exchange and integration between China and Japan brought about by the overseas circulation of Chinese classics. Book circulation data consist of uncertain spatiotemporal trajectories, with multiple dimensions, and movement across hierarchical spaces forms a compound network. LiberRoad visualizes the circulation of books collected in the Imperial Household Agency of Japan, and can be generalized to other book movement data. The LiberRoad system enables a smooth transition between three views (Location Graph, map, and timeline) according to the desired perspectives (spatial or temporal), as well as flexible filtering and selection. The Location Graph is a novel uncertainty-aware visualization method that employs improved circle packing to represent spatial hierarchy. The map view intuitively shows the overall circulation by clustering and allows zooming into single book trajectory with lenses magnifying local movements. The timeline view ranks dynamically in response to user interaction to facilitate the discovery of temporal events. The evaluation and feedback from the expert users demonstrate that LiberRoad is helpful in revealing movement patterns and comparing circulation characteristics of different times and spaces.
C1 [Guo, Yuhan; Luo, Yuchu; Lu, Keer; Yuan, Xiaoru] Peking Univ, Sch AI, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing, Peoples R China.
   [Li, Linfang; Yang, Haizheng] Peking Univ, Ctr Ancient Chinese Class & Arch, Beijing, Peoples R China.
   [Li, Linfang; Yang, Haizheng] Peking Univ, Dept Chinese Language & Literature, Beijing, Peoples R China.
C3 Peking University; Peking University; Peking University; Peking
   University
RP Yuan, XR (corresponding author), Peking Univ, Sch AI, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing, Peoples R China.
EM yuhan.guo@pku.edu.cn; luoyuchu@pku.edu.cn; keer.lu@outlook.com;
   llfang@pku.edu.cn; haizheng@pku.edu.cn; xiaoru.yuan@pku.edu.cn
RI Yuan, Xiaoru/E-1798-2013
OI Guo, Yuhan/0009-0004-3857-7486; Yuan, Xiaoru/0000-0002-7233-980X
FU NSFC
FX No Statement Available
CR Andrienko G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P161, DOI 10.1109/VAST.2011.6102454
   Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Andrienko G, 2013, IEEE T VIS COMPUT GR, V19, P1078, DOI 10.1109/TVCG.2012.311
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   Andrienko N, 2012, KUNSTL INTELL, V26, P241, DOI 10.1007/s13218-012-0177-4
   Bach B., 2015, P C INF VIS
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Burch M., 2008, P WORK C ADV VIS INT, P75
   C. CERL, 2015, Material evidence in incunabula
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Crnovrsanin Tarik, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P11, DOI 10.1109/VAST.2009.5332593
   Deitrick S., 2006, PROGR SPATIAL DATA H, P719, DOI [DOI 10.1007/3-540-35589-8_45, 10.1007/3-540-35589-8_45]
   Dodge S, 2008, INFORM VISUAL, V7, P240, DOI 10.1057/palgrave.ivs.9500182
   Eppstein D., 1998, P ANN ACM SIAM S DIS, P619
   Fischer MT, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P81, DOI 10.1109/VIS49827.2021.9623305
   Geon Cho, 1997, INFORMS Journal on Computing, V9, P431, DOI 10.1287/ijoc.9.4.431
   Görtler J, 2018, IEEE T VIS COMPUT GR, V24, P719, DOI 10.1109/TVCG.2017.2743959
   Gotz D, 2020, IEEE T VIS COMPUT GR, V26, P440, DOI 10.1109/TVCG.2019.2934661
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Guo DS, 2014, IEEE T VIS COMPUT GR, V20, P2043, DOI 10.1109/TVCG.2014.2346271
   Guo HQ, 2011, IEEE PAC VIS SYMP, P163, DOI 10.1109/PACIFICVIS.2011.5742386
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Ilagcrstrand T., 1970, Regional Science Association, V24
   Kraak Menno-Jan, P 21 INT CART C, P1988
   Krautli F., 2013, Electronic Visualisation and the Arts, P61
   Krstajic M, 2011, IEEE T VIS COMPUT GR, V17, P2432, DOI 10.1109/TVCG.2011.179
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Y., 2013, From Manuscripts to Block-prints: Research on Chinese and Japanese Edition of "Analects".
   Liu Y., 2018, The Documentation, V170, P77
   Lu J., 1990, The Circulation and Influence of Chinese Classics in Japan
   Luo Y., 2022, Big Data Research, V8, P74
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Munroe R., 2013, Movie narrative charts
   Panagiotidou Georgia, 2023, IEEE Trans Vis Comput Graph, V29, P635, DOI 10.1109/TVCG.2022.3209436
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Rosenberg D., 2010, Cartographies of Time: A History of the Timeline
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Sun X., 2017, Journal of Social Science Front, P113
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Thudt A., 2013, P EUR C VIS
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   Wang TD, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P457
   Wang W., 2006, P SIGCHI C HUM FACT, P517
   Wang Y., 2003, Research on the "Book Road"between China and Japan
   Wang Y., 1992, Studies on the History of Chinese and Japanese Classic Exchanges
   Wang ZC, 2014, INT CONF BIG DATA, P13, DOI 10.1109/BIGCOMP.2014.6741397
   Wang ZC, 2014, IEEE T VIS COMPUT GR, V20, P1813, DOI 10.1109/TVCG.2014.2346746
   Ware C, 2006, IEEE COMPUT GRAPH, V26, P14, DOI 10.1109/MCG.2006.93
   Weiskopf D, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.793819
   Windhager F, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030029
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Xing Y., 2022, EUROVIS SHORT PAPERS
   Yang H., 2020, A Compilation of Engraved Versions of "Records of the Grand Historian"in Japan
   Yang H., 2022, Library Tribune, V42, P131
   Yang H., 2017, Research on "Records of the Grand Historian
   Yang H., 2020, Peking University Center for Ancient Chinese Documentation Studies Journal, V21, P256
   Zhang WX, 2022, IEEE T VIS COMPUT GR, V28, P1982, DOI 10.1109/TVCG.2022.3150467
   Zhao J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P259, DOI 10.1145/2702123.2702419
   Zhao JF, 2008, INFORM VISUAL, V7, P198, DOI 10.1057/palgrave.ivs.9500184
NR 68
TC 1
Z9 1
U1 8
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 529
EP 539
DI 10.1109/TVCG.2023.3326944
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500002
PM 37874725
DA 2024-11-06
ER

PT J
AU Xing, YW
   Dondi, C
   Borgo, R
   Abdul-Rahman, A
AF Xing, Yiwen
   Dondi, Cristina
   Borgo, Rita
   Abdul-Rahman, Alfie
TI Visualizing Historical Book Trade Data: An Iterative Design Study with
   Close Collaboration with Domain Experts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Design study; application motivated visualization; geospatial data
ID REFLECTIONS; PATTERNS
AB The circulation of historical books has always been an area of interest for historians. However, the data used to represent the journey of a book across different places and times can be difficult for domain experts to digest due to buried geographical and chronological features within text-based presentations. This situation provides an opportunity for collaboration between visualization researchers and historians. This paper describes a design study where a variant of the Nine-Stage Framework [46] was employed to develop a Visual Analytics (VA) tool called DanteExploreVis. This tool was designed to aid domain experts in exploring, explaining, and presenting book trade data from multiple perspectives. We discuss the design choices made and how each panel in the interface meets the domain requirements. We also present the results of a qualitative evaluation conducted with domain experts. The main contributions of this paper include: 1) the development of a VA tool to support domain experts in exploring, explaining, and presenting book trade data; 2) a comprehensive documentation of the iterative design, development, and evaluation process following the variant Nine-Stage Framework; 3) a summary of the insights gained and lessons learned from this design study in the context of the humanities field; and 4) reflections on how our approach could be applied in a more generalizable way.
C1 [Xing, Yiwen; Borgo, Rita; Abdul-Rahman, Alfie] Kings Coll London, London, England.
   [Dondi, Cristina] Univ Oxford, Oxford, England.
C3 University of London; King's College London; University of Oxford
RP Xing, YW (corresponding author), Kings Coll London, London, England.
EM yiwen.xing@kcl.ac.uk; cristina.dondi@mod-langs.ox.ac.uk;
   rita.borgo@kcl.ac.uk; alfie.abdulrahman@kcl.ac.uk
RI Abdul-Rahman, Alfie/B-9992-2008
OI Dondi, Cristina/0000-0001-9478-216X; Abdul-Rahman,
   Alfie/0000-0002-6257-876X; Xing, Yiwen/0000-0003-1521-6616
FU King's-China Scholarship Council PhD Scholarship programme (K-CSC)
FX No Statement Available
CR Abdul-Rahman A., 2014, EuroVis - Short Papers, DOI [10.2312/eurovisshort.20141165, DOI 10.2312/EUROVISSHORT.20141165]
   Abras C., 2004, Encyclopedia of Human-Computer Interaction, V37, P2
   Agafonkin V., 2021, Leaflet: A JavaScript library for interactive maps
   Arnold T, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P30, DOI 10.1109/VIS4DH51463.2020.00010
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M., 2016, Why Visualization? Task Abstraction for Analysis and Design
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Brhel M, 2015, INFORM SOFTWARE TECH, V61, P163, DOI 10.1016/j.infsof.2015.01.004
   Brinck T., 2001, Usability for the web: Designing web sites that work, P3
   Buxton B., 2010, Sketching user experiences: getting the design right and the right design, P2
   C. CERL, 2021, MEI map
   C. CERL, Material Evidence in Incunabula
   Camburn B, 2017, DES SCI, V3, DOI 10.1017/dsj.2017.10
   Cavalcante R. P. G., 2021, React-leaflet-ant-path
   Chang Daniel, Visualizing the republic of letters.
   Chenjun Ling, 2016, Annals of GIS, V22, P173, DOI 10.1080/19475683.2016.1191545
   Ciula A., 2021, 2021 IEEE 6 WORKSHOP, P1, DOI [10.48550/arXiv.2110.093492, DOI 10.48550/ARXIV.2110.093492]
   Dingman B, 2021, 23RD INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2021, DOI 10.1145/3441852.3476526
   Dondi C., From the 15cBOOKTRADE Project website
   Dondi C., 2013, Gazette du livre medieval, V60, P83, DOI [10.3406/galim.2013.20352, DOI 10.3406/GALIM.2013.20352]
   Dumas B, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P65, DOI 10.1145/2598153.2598159
   Edelstein D, 2017, AM HIST REV, V122, P400, DOI 10.1093/ahr/122.2.400
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   Etikan I., 2017, BIOMETRICS BIOSTATIS, V5, P215, DOI [DOI 10.15406/BBIJ.2017.05.00149, 10.15406/bbij.2017.05.00149]
   Etikan I., 2016, AM J THEORETICAL APP, V5, P1, DOI [https://doi.org/10.11648/j.ajtas.20160501.11, 10.11648/j.ajtas.20160501.11, DOI 10.11648/J.AJTAS.20160501.11]
   Forsell C, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P608, DOI 10.1145/2254556.2254668
   Gobe S.J., 1993, QUAL HEALTH RES, V3, P430, DOI DOI 10.1177/104973239300300403
   Guo D, 2007, INT J GEOGR INF SCI, V21, P859, DOI 10.1080/13658810701349037
   He J, 2019, IEEE ACCESS, V7, P143646, DOI 10.1109/ACCESS.2019.2942844
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Huang W., 2014, Handbook of Human Centric Visualization, V1, DOI [10.1007/978-1-4614-7485-2, DOI 10.1007/978-1-4614-7485-2]
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   Mayhew D.J., 1999, CHI '99 Extended Abstracts on Human Factors in Computing Systems, P147, DOI [10.1145/632716.6328052, DOI 10.1145/632716.6328052]
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   Müller V, 2021, 2021 IEEE 6TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2021), P12, DOI 10.1109/VIS4DH53644.2021.00007
   Munzner T., 2014, AK Peters Visualization Series, V3, P5
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen J., 1994, Usability Engineering, V3, P8
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P1543, DOI 10.1109/TVCG.2018.2811488
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Prickman G. J., ATLAS EARLY PRINTING
   Qualtrics, 2005, US
   Redin D., 2017, 2017 SUSTAINABLE INT, P1, DOI [10.23919/SustainIT.2017.8379814, DOI 10.23919/SUSTAINIT.2017.8379814]
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Silva da Silva T., 2011, Proceedings of the 2011 Agile Conference, P77, DOI 10.1109/AGILE.2011.24
   Simon R., 2016, Code4Lib Journal, P3
   Skupin A, 2005, GEOINFORMATICA, V9, P159, DOI 10.1007/s10707-005-6670-2
   Sobral T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020332
   Syeda UH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376829
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Vancisin T, 2020, 2020 IEEE 5TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH 2020), P36, DOI 10.1109/VIS4DH51463.2020.00011
   Winter M, 2021, IEEE ENG MED BIO, P2215, DOI 10.1109/EMBC46164.2021.9630949
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Xing Y., 2022, EuroVis 2022 - Short Papers, DOI [10.2312/evs.202211001,2, DOI 10.2312/EVS.202211001,2]
   Ye Y, 2020, IEEE T VIS COMPUT GR, V26, P2192, DOI 10.1109/TVCG.2020.2970525
   Zhang P., 2005, Communications of the Association for Information Systems, V15, P29, DOI [10.17705/1CAIS.015292, DOI 10.17705/1CAIS.015292]
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 59
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 540
EP 550
DI 10.1109/TVCG.2023.3326923
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500110
PM 37871084
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, Y
   Jiang, RK
   Xie, LWH
   Zhao, YH
   Liu, C
   Ding, TH
   Chen, SM
   Yuan, XR
AF Zhang, Yu
   Jiang, Ruike
   Xie, Liwenhan
   Zhao, Yuheng
   Liu, Can
   Ding, Tianhong
   Chen, Siming
   Yuan, Xiaoru
TI OldVisOnline: Curating a Dataset of Historical Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Historical visualization; dataset; digital humanities; data labeling
ID ART
AB With the increasing adoption of digitization, more and more historical visualizations created hundreds of years ago are accessible in digital libraries online. It provides a unique opportunity for visualization and history research. Meanwhile, there is no large-scale digital collection dedicated to historical visualizations. The visualizations are scattered in various collections, which hinders retrieval. In this study, we curate the first large-scale dataset dedicated to historical visualizations. Our dataset comprises 13K historical visualization images with corresponding processed metadata from seven digital libraries. In curating the dataset, we propose a workflow to scrape and process heterogeneous metadata. We develop a semi-automatic labeling approach to distinguish visualizations from other artifacts. Our dataset can be accessed with OldVisOnline, a system we have built to browse and label historical visualizations. We discuss our vision of usage scenarios and research opportunities with our dataset, such as textual criticism for historical visualizations. Drawing upon our experience, we summarize recommendations for future efforts to improve our dataset.
C1 [Zhang, Yu] Univ Oxford, Dept Comp Sci, Oxford, England.
   [Jiang, Ruike; Liu, Can; Yuan, Xiaoru] Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.
   [Jiang, Ruike; Liu, Can; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Beijing, Peoples R China.
   [Zhao, Yuheng; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Xie, Liwenhan] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Ding, Tianhong] Huawei Technol, Fundamental Software Innovat Lab, Shenzhen, Peoples R China.
C3 University of Oxford; Peking University; Peking University; Fudan
   University; Hong Kong University of Science & Technology; Huawei
   Technologies
RP Yuan, XR (corresponding author), Peking Univ, Key Lab Machine Percept, Minist Educ, Beijing, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Beijing, Peoples R China.; Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
EM yuzhang94@outlook.com; jiangrk@pku.edu.cn; liwenhan.xie@connect.ust.hk;
   yuhengzhao@fudan.edu.cn; can.liu@pku.edu.cn; dingtianhong@huawei.com;
   simingchen@fudan.edu.cn; xiaoru.yuan@pku.edu.cn
RI Yuan, Xiaoru/E-1798-2013; Xie, Liwenhan/HLV-8177-2023; Chen,
   Siming/AAK-1874-2020
OI Zhang, Yu/0000-0002-9035-0463; Xie, Liwenhan/0000-0002-2601-6313; Jiang,
   Ruike/0000-0002-5001-5310; Liu, Can/0000-0002-1175-0734; Yuan,
   Xiaoru/0000-0002-7233-980X; Zhao, Yuheng/0000-0003-1573-8772
FU NSFC
FX No Statement Available
CR Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Beck F, 2016, IEEE T VIS COMPUT GR, V22, P180, DOI 10.1109/TVCG.2015.2467757
   Bederson B. B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P71, DOI 10.1145/502348.502359
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   British Library, 1973, British library
   Cartographic Research Laboratory, Alabama maps
   Chen C, 2023, COMPUT GRAPH FORUM, V42, P449, DOI 10.1111/cgf.14855
   Chen J, 2022, Arxiv, DOI arXiv:2209.07533
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen Z, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P183, DOI 10.1145/2740908.2742831
   Crissaff L, 2018, IEEE COMPUT GRAPH, V38, P91, DOI 10.1109/MCG.2017.377152546
   Deng D., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.32135652,7
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Digital Public Library of America, 2013, Digital public library of America
   Dodson R., 1994, Snow's cholera map
   Foster C., 2017, P DIG HUM C DH 17, V7, P8
   Friendly M, 2005, J HIST BEHAV SCI, V41, P103, DOI 10.1002/jhbs.20078
   Friendly M., 2001, Milestones in the history of thematic cartography, statistical graphics, and data visualization, V1, P2
   Friendly M, 2010, AM STAT, V64, P174, DOI 10.1198/tast.2010.09154
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   International Image Interoperability Framework, 2011, International image interoperability framework
   International Organization for Standardization, 2019, ISO standard no. 8601-1:2019)
   International Organization for Standardization, 2007, ISO standard no. 639-3:2007)
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Kahle B. L., 1996, Internet archive
   Kerle N, 2009, IEEE T GEOSCI REMOTE, V47, P2392, DOI 10.1109/TGRS.2008.2010853
   Khulusi R, 2019, IEEE PAC VIS SYMP, P257, DOI 10.1109/PacificVis.2019.00038
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Klein L., 2022, Harvard Data Science Review, V4, DOI [10.1162/99608f92.5dec149c2,7,8, DOI 10.1162/99608F92.5DEC149C2,7,8]
   Klokan Technologies GmbH, Old maps online
   Koch T., 2004, Cartographica, V39, P1, DOI DOI 10.3138/B123-8124-4390-5792
   Kosara R, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P162, DOI 10.1145/2993901.2993909
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kucher K, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/3132169
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Kulesza T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3075, DOI 10.1145/2556288.2557238
   Lee PS, 2018, IEEE T BIG DATA, V4, P117, DOI 10.1109/TBDATA.2017.2689038
   Library of Congress, LIB C DIG COLL
   Lima M., 2014, The Book of Trees: Visualizing Branches of Knowledge, P1
   Lin Y., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32513442, DOI 10.1109/TVCG.2023.32513442]
   Liu XX, 2023, INFORM VISUAL, V22, P3, DOI 10.1177/14738716221126992
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Marey E.-J., 1878, La Methode Graphique dans les Sciences Experimentales et Principalement en Physiologie et en Medecine, P20
   Minard C. J., 1869, Carte figurative des pertes successives en hommes de l'armee francaise dans la campagne de russie 1812-1813, P1
   Modley R., 1938, Telefact: 1938-1945 by pictograph corporation
   Munzner T., 2014, Visualization Analysis and Design, P2
   National Library of France, Gallica
   Oppermann M, 2022, IEEE T VIS COMPUT GR, V28, P747, DOI 10.1109/TVCG.2021.3114841
   Owain G., 1489, Hen Almanac Cymreig & C., P9
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Peabody E. P., 1856, Chronological History of the United States: Arranged with Plates on Bem's Principle, P15
   Pflüger H, 2020, IEEE T VIS COMPUT GR, V26, P3063, DOI 10.1109/TVCG.2019.2908166
   Playfair W., 1801, The Statistical Breviary: Shewing, on a Principle Entirely New, the Resources of Every State and Kingdom in Europe, P3
   Playfair W., 1801, The Commercial and Political Atlas: Representing, by Means of Stained Copper-Plate Charts, the Progress of the Commerce, Revenues, Expenditure, and Debts of England, during the Whole of the Eighteenth Century, Vthird, P36
   Priestley J., 1803, Lectures on History and General Policy, P262
   Priestley J., 1764, A Description of a Chart of Biography, P7
   Radford A, 2021, PR MACH LEARN RES, V139
   Rendgen S., 2019, History of Information Graphics, P1
   Robinson A.H., 1967, IMAGO MUNDI, V21, P95, DOI [10.1016/0169-328x(95)00056-x, DOI 10.1016/0169-328X(95)00056-X]
   Rumsey D., David Rumsey map collection
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Settles B., 2009, Technical report, P5
   Settles B., 2011, P C EMP METH NAT LAN, P5
   Shiode N, 2015, INT J HEALTH GEOGR, V14, DOI 10.1186/s12942-015-0011-y
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Simonyan K., 2014, arXiv
   Snow J., 1855, On the Mode of Communication of Cholera, P44
   Snow J., 1936, Snow on Cholera: Being a Reprint of Two Papers by John Snow, M.D., P44
   Stoppel S, 2017, IEEE T VIS COMPUT GR, V23, P861, DOI 10.1109/TVCG.2016.2599211
   Sutherland I. E., 1963, Sketchpad, a Man-Machine Graphical Communication System, P2
   Tufte E. R., 1983, The Visual Display of Quantitative Information, P1
   von Spaeth O., 2000, Centaurus, V42, P159
   Wikimedia Foundation, 2004, Wikimedia commons
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xu PP, 2017, IEEE T VIS COMPUT GR, V23, P291, DOI 10.1109/TVCG.2016.2598664
   Ye YL, 2024, IEEE T VIS COMPUT GR, V30, P3224, DOI 10.1109/TVCG.2022.3229023
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang Y., 2023, ACM Transactions on Interactive Intelligent Systems, DOI DOI 10.1145/35945525
   Zhang Y, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517612
   Zhang Y, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3412848
NR 91
TC 1
Z9 1
U1 5
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 551
EP 561
DI 10.1109/TVCG.2023.3326908
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500123
PM 37874726
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, Q
   Chen, N
   Shuai, W
   Wu, GD
   Xu, Z
   Tong, HH
   Cao, N
AF Chen, Qing
   Chen, Nan
   Shuai, Wei
   Wu, Guande
   Xu, Zhe
   Tong, Hanghang
   Cao, Nan
TI Calliope-Net: Automatic Generation of Graph Data Facts via Annotated
   Node-Link Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graph Data; Application Motivated Visualization; Automatic
   Visualization; Narrative Visualization; Authoring Tools
ID INFORMATION VISUALIZATION; NARRATIVE VISUALIZATION; NETWORKS; INSIGHTS
AB Graph or network data are widely studied in both data mining and visualization communities to review the relationship among different entities and groups. The data facts derived from graph visual analysis are important to help understand the social structures of complex data, especially for data journalism. However, it is challenging for data journalists to discover graph data facts and manually organize correlated facts around a meaningful topic due to the complexity of graph data and the difficulty to interpret graph narratives. Therefore, we present an automatic graph facts generation system, Calliope-Net, which consists of a fact discovery module, a fact organization module, and a visualization module. It creates annotated node-link diagrams with facts automatically discovered and organized from network data. A novel layout algorithm is designed to present meaningful and visually appealing annotated graphs. We evaluate the proposed system with two case studies and an in-lab user study. The results show that Calliope-Net can benefit users in discovering and understanding graph data facts with visually pleasing annotated visualizations.
C1 [Chen, Qing; Chen, Nan; Shuai, Wei; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
   [Wu, Guande] NYU, New York, NY USA.
   [Xu, Zhe] Univ Illinois Champaign Urbana, Champaign, IL USA.
C3 Tongji University; New York University; University of Illinois System;
   University of Illinois Urbana-Champaign
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Beijing, Peoples R China.
EM qingchen@tongji.edu.cn; christy05.chen@gmail.com;
   shuaiwei@tongji.edu.cn; guandewu@nyu.edu; zhexu3@illinois.edu;
   hanghang.tong@gmail.com; nan.cao@tongji.edu.cn
RI Cao, Nan/O-5397-2014; Wu, Guande/JZE-5610-2024
OI Cao, Nan/0000-0003-1316-7515
FU NSFC
FX No Statement Available
CR Ahn JW, 2014, IEEE T VIS COMPUT GR, V20, P365, DOI 10.1109/TVCG.2013.238
   Aisch G., 2011, Connecting the dots behind the 2016 presidential candidates
   [Anonymous], 2009, COMPARING READABILIT, DOI [DOI 10.5555/2381286.2381296, 10.2312/COMPAESTH/COMPAESTH09/049-056, DOI 10.2312/COMPAESTH/COMPAESTH09/049-056]
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bastian M, 2009, P INT AAAI C WEBL SO, V3, P361, DOI 10.13140/2.1.1341.1520
   Bennett C., 2007, P EUR C COMP AESTH G, P57, DOI [10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   BONACICH P, 1987, AM J SOCIOL, V92, P1170, DOI 10.1086/228631
   Bounegru L, 2017, DIGIT JOURNAL, V5, P699, DOI 10.1080/21670811.2016.1186497
   Brath R., 2018, IEEE VIS WORKSHOP VI
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Campbell EM, 2017, J INFECT DIS, V216, P1053, DOI 10.1093/infdis/jix307
   Chabot C., 2003, Tableau Software, V6
   Chen Q, 2024, IEEE T VIS COMPUT GR, V30, P4429, DOI 10.1109/TVCG.2023.3261320
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Cohen S., 2004, The bush money machine
   Deodhar M., 2022, arXiv
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Eiter Thomas, 1994, Computing discrete frechet distance
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   Flake G. W., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P150, DOI 10.1145/347090.347121
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Freeman L., 2004, Study Sociol. Sci, V687, P159, DOI DOI 10.4135/9781446294413.N3
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Haas P. J., 2017, arXiv
   Hart J., 2021, Storycraft: The complete guide to writing narrative nonfiction
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Huang W., 2005, Layout effects: Comparison of sociogram drawing conventions
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Ilbo J., 2012, Social network analysis of high-ranking officials in s. korean government
   Kaneider D., 2013, P ACM INT C INTERACT, P61, DOI DOI 10.1145/2512349.2512809
   Kim NW, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300335
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   KNUTH DE, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P41
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Latif S., 2019, EUROVIS SHORT PAPERS, P115
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Latif S, 2019, IEEE T VIS COMPUT GR, V25, P152, DOI 10.1109/TVCG.2018.2865022
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Lazar J., 2017, RES METHODS HUMAN CO
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Lu M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376263
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Mafrur R, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1123, DOI 10.1145/3269206.3271744
   Marsh B., 2015, Chris christie and the lane closings: A spectator's guide
   Matei S, 2011, INT J HUM-COMPUT INT, V27, P405, DOI 10.1080/10447318.2011.544971
   Nettleton DF, 2013, COMPUT SCI REV, V7, P1, DOI 10.1016/j.cosrev.2012.12.001
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   OCCRP, 2011, The proxy platform
   Pretorius AJ, 2014, LECT NOTES COMPUT SC, V8380, P77, DOI 10.1007/978-3-319-06793-3_5
   Procter R., 2011, How riot rumours spread on twitter
   Purchase HC, 2000, INTERACT COMPUT, V13, P147, DOI 10.1016/S0953-5438(00)00032-1
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Romat H, 2021, IEEE T VIS COMPUT GR, V27, P2329, DOI 10.1109/TVCG.2019.2950932
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Stack Overflow, 2021, Stack overflow tag network
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Von Daniels J., Die ttipdealer
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P489, DOI 10.1109/TVCG.2017.2745919
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wikipedia contributors, 2021, Les miserables - Wikipedia, the free encyclopedia
   Wu HY, 2016, 32ND SPRING CONFERENCE ON COMPUTER GRAPHICS (SCCG 2016), P41, DOI 10.1145/2948628.2948642
   Zhang Peng B. Z., 2022, 2022 4 INT C ADV COM, DOI DOI 10.1109/CTISC54888.2022.9849754
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
NR 78
TC 2
Z9 2
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 562
EP 572
DI 10.1109/TVCG.2023.3326925
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500051
PM 37874720
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wen, Z
   Liu, YH
   Tan, SW
   Chen, JY
   Zhu, MF
   Han, DM
   Yin, JW
   Xu, ML
   Chen, W
AF Wen, Zhen
   Liu, Yihan
   Tan, Siwei
   Chen, Jieyi
   Zhu, Minfeng
   Han, Dongming
   Yin, Jianwei
   Xu, Mingliang
   Chen, Wei
TI Quantivine: A Visualization Approach for Large-Scale Quantum Circuit
   Representation and Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Quantum circuit; semantic analysis; visual abstraction; context
   visualization
ID VISUAL ANALYTICS; GRAPH
AB Quantum computing is a rapidly evolving field that enables exponential speed-up over classical algorithms. At the heart of this revolutionary technology are quantum circuits, which serve as vital tools for implementing, analyzing, and optimizing quantum algorithms. Recent advancements in quantum computing and the increasing capability of quantum devices have led to the development of more complex quantum circuits. However, traditional quantum circuit diagrams suffer from scalability and readability issues, which limit the efficiency of analysis and optimization processes. In this research, we propose a novel visualization approach for large-scale quantum circuits by adopting semantic analysis to facilitate the comprehension of quantum circuits. We first exploit meta-data and semantic information extracted from the underlying code of quantum circuits to create component segmentations and pattern abstractions, allowing for easier wrangling of massive circuit diagrams. We then develop Quantivine, an interactive system for exploring and understanding quantum circuits. A series of novel circuit visualizations is designed to uncover contextual details such as qubit provenance, parallelism, and entanglement. The effectiveness of Quantivine is demonstrated through two usage scenarios of quantum circuits with up to 100 qubits and a formal user evaluation with quantum experts. A free copy of this paper and all supplemental materials are available at https://osf.io/2m9yh/?view_only=0aa1618c97244f5093cd7ce15f1431f9.
C1 [Wen, Zhen; Liu, Yihan; Chen, Jieyi; Han, Dongming; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Tan, Siwei; Yin, Jianwei] Zhejiang Univ, Adv Comp & Syst Lab, Hangzhou, Peoples R China.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
   [Han, Dongming] Hithink Royal Flush Informat Network Co Ltd, Hangzhou, Zhejiang, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Zhengzhou
   University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM wenzhen@zju.edu.cn; lyh1024@zju.edu.cn; siweitan@zju.edu.cn;
   chenjieyi_juraws@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   dongminghan@zju.edu.cn; zjuyjw@cs.zju.edu.cn; iexumingliang@zzu.edu.cn;
   chenvis@zju.edu.cn
RI chen, jieyi/IXM-9530-2023; Zhu, Minfeng/R-6788-2019; Chen,
   Wei/AAR-9817-2020
OI Chen, Wei/0000-0002-8365-4741; Tan, Siwei/0000-0002-0634-8089; Zhu,
   Minfeng/0000-0002-6711-3099; Wen, Zhen/0000-0002-6327-5306
FU National Natural Science Foundation of China
FX No Statement Available
CR Albertoni R., 2005, PROC GIR, P9, DOI [10.1145/1096985.1096989, DOI 10.1145/1096985.1096989]
   Bauer B, 2020, CHEM REV, V120, P12685, DOI 10.1021/acs.chemrev.9b00829
   Bhattacharjee D, 2017, Arxiv, DOI arXiv:1703.08540
   Biamonte J, 2019, COMMUN PHYS-UK, V2, DOI 10.1038/s42005-019-0152-6
   Biamonte J, 2017, NATURE, V549, P195, DOI 10.1038/nature23474
   Biedl T, 1998, COMP GEOM-THEOR APPL, V9, P159, DOI 10.1016/S0925-7721(97)00026-6
   Borner K., 2000, ACM 2000. Digital Libraries. Proceedings of the Fifth ACM Conference on Digital Libraries, P234, DOI 10.1145/336597.336672
   Brandes U., 2002, Data Visualisation (VISSYM), P159, DOI [DOI 10.2312/VISSYM/VISSYM02/159-1643, 10.2312/VisSym/VisSym02/159-1643]
   Chen W, 2019, IEEE T VIS COMPUT GR, V25, P555, DOI 10.1109/TVCG.2018.2865139
   Das P, 2021, INT SYMP MICROARCH, P950, DOI 10.1145/3466752.3480059
   Developers C., 2022, Cirq. Zenodo, DOI [10.5281/zenodo.74655771,2, DOI 10.5281/ZENODO.74655771,2]
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Egger Daniel J., 2020, IEEE Transactions on Quantum Engineering, V1, DOI 10.1109/TQE.2020.3030314
   Emani PS, 2021, NAT METHODS, V18, P701, DOI 10.1038/s41592-020-01004-3
   Feng Y, 2024, INT J ENVIRON HEAL R, V34, P2333, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Fickler R, 2013, SCI REP-UK, V3, DOI 10.1038/srep01914
   Figgatt C, 2019, NATURE, V572, P368, DOI 10.1038/s41586-019-1427-5
   Ghashami M, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P845, DOI 10.1145/2939672.2939800
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Görg C, 2004, LECT NOTES COMPUT SC, V3383, P228
   Green AS, 2013, ACM SIGPLAN NOTICES, V48, P333, DOI 10.1145/2499370.2462177
   Guo D., 2021, P ICLR, DOI [10.48550/arXiv.2009.08366 3, DOI 10.48550/ARXIV.2009.083663]
   Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hachul Stefan, 2007, Journal of Graph Algorithms and Applications, V11, P345, DOI 10.7155/jgaa.00150
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Han DM, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0013-1
   Han DM, 2021, IEEE COMPUT GRAPH, V41, P18, DOI 10.1109/MCG.2021.3097799
   Han DM, 2021, VIS INFORM, V5, P61, DOI 10.1016/j.visinf.2021.01.002
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huang YP, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P541, DOI 10.1145/3307650.3322213
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w
   Iten R, 2022, ACM T QUANTUM COMPUT, V3, DOI 10.1145/3498325
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Jozsa R, 2003, P ROY SOC A-MATH PHY, V459, P2011, DOI 10.1098/rspa.2002.1097
   Kim S., 2010, PROC APGV, P33, DOI [10.1145/1836248.1836254, DOI 10.1145/1836248.1836254, 10.1145/1836248.18362542, DOI 10.1145/1836248.18362542]
   Koutra D, 2014, P 2014 SIAM INT C DA, P91
   Kwon OH, 2020, IEEE T VIS COMPUT GR, V26, P665, DOI 10.1109/TVCG.2019.2934396
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Landauer TK, 2004, P NATL ACAD SCI USA, V101, P5214, DOI 10.1073/pnas.0400341101
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   LeFevre K., 2010, SDM, P454
   Li CH, 2017, J VISUAL-JAPAN, V20, P205, DOI 10.1007/s12650-016-0375-5
   Lin SY, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P37, DOI 10.1109/SciVis.2018.8823602
   Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727
   Liu YC, 2021, NAT PHYS, V17, P1013, DOI 10.1038/s41567-021-01287-z
   Maccioni A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1755, DOI 10.1145/2939672.2939856
   Martin A, 2021, PHYS REV RES, V3, DOI 10.1103/PhysRevResearch.3.013167
   Martonosi M., 2014, ACM C COMP FRONT, DOI [DOI 10.1145/2597917.2597939, DOI 10.1145/2597917]
   Maslov D, 2008, IEEE T COMPUT AID D, V27, P436, DOI 10.1109/TCAD.2007.911334
   Mathioudakis M., 2011, PROC SIGKDD, P529, DOI [10.1145/2020408.2020492, DOI 10.1145/2020408.2020492]
   Mehmood Yasir, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P48, DOI 10.1007/978-3-642-40991-2_4
   Miller M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON QUANTUM COMPUTING AND ENGINEERING (QCE 2021) / QUANTUM WEEK 2021, P378, DOI 10.1109/QCE52317.2021.00057
   Mueller C, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P141
   Navlakha S., 2008, P 2008 ACM SIGMOD IN, P419, DOI DOI 10.1145/1376616.1376661
   Nielsen M. A., 2010, Quantum Computation and Quantum Information, V10th, DOI [10.1017/CBO97805119766671,2,3, DOI 10.1017/CBO97805119766671,2,3]
   North SC, 2002, LECT NOTES COMPUT SC, V2265, P232
   Pan JC, 2020, FRONT INFORM TECH EL, V21, P491, DOI 10.1631/FITEE.1900310
   Preskill J, 2012, Arxiv, DOI arXiv:1203.5813
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Purchase H. C., 2006, Graph Drawing. 14th International Symposium, GD 2006. Revised Papers (Lecture Notes in Computer Science Vol. 4372), P184
   Ruan Shaolun, 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P462, DOI 10.1109/TVCG.2022.3209455
   Sen S., 2017, Proceedings of the 22nd International Conference on Intelligent User Interfaces, P179, DOI [10.1145/3025171.3025233, DOI 10.1145/3025171.3025233]
   Shen ZQ, 2006, IEEE T VIS COMPUT GR, V12, P1427, DOI 10.1109/TVCG.2006.107
   Stein SA, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON QUANTUM COMPUTING AND ENGINEERING (QCE 2021) / QUANTUM WEEK 2021, P71, DOI 10.1109/QCE52317.2021.00023
   Svore K, 2018, RWDSL2018: PROCEEDINGS OF THE REAL WORLD DOMAIN SPECIFIC LANGUAGES WORKSHOP 2018, DOI 10.1145/3183895.3183901
   tA-v A., 2021, Qiskit: An open-source framework for quantum computing
   Tan BC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415620
   Tao RZ, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P641, DOI 10.1145/3519939.3523431
   Tao ZW, 2017, I C VIRTUAL REALITY, P360, DOI 10.1109/ICVRV.2017.00082
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wang XM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-023-2691-y
   Wang YY, 2021, VIS INFORM, V5, P49, DOI 10.1016/j.visinf.2021.12.003
   Weder B, 2020, INT CONF UTIL CLOUD, P279, DOI 10.1109/UCC48980.2020.00046
   Weiden M, 2022, 2022 IEEE/ACM THIRD INTERNATIONAL WORKSHOP ON QUANTUM COMPUTING SOFTWARE (QCS), P1, DOI 10.1109/QCS56647.2022.00006
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Wu YC, 2011, COMPUT GRAPH FORUM, V30, P741, DOI 10.1111/j.1467-8659.2011.01923.x
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Xu MK, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P625, DOI 10.1145/3519939.3523433
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
   Zhou ZG, 2019, IEEE T VIS COMPUT GR, V25, P43, DOI 10.1109/TVCG.2018.2864503
   Zhu MF, 2021, IEEE T VIS COMPUT GR, V27, P1666, DOI 10.1109/TVCG.2020.3030447
NR 83
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 573
EP 583
DI 10.1109/TVCG.2023.3327148
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500007
PM 37878443
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Oliver, P
   Zhang, E
   Zhang, Y
AF Oliver, Peter
   Zhang, Eugene
   Zhang, Yue
TI Scalable Hypergraph Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Hypergraph visualization; scalable visualization; polygon layout;
   hypergraph embedding; primal-dual visualization
ID SPARSIFICATION; ALGORITHM; SET; LAYOUT
AB Hypergraph visualization has many applications in network data analysis. Recently, a polygon-based representation for hypergraphs has been proposed with demonstrated benefits. However, the polygon-based layout often suffers from excessive self-intersections when the input dataset is relatively large. In this paper, we propose a framework in which the hypergraph is iteratively simplified through a set of atomic operations. Then, the layout of the simplest hypergraph is optimized and used as the foundation for a reverse process that brings the simplest hypergraph back to the original one, but with an improved layout. At the core of our approach is the set of atomic simplification operations and an operation priority measure to guide the simplification process. In addition, we introduce necessary definitions and conditions for hypergraph planarity within the polygon representation. We extend our approach to handle simultaneous simplification and layout optimization for both the hypergraph and its dual. We demonstrate the utility of our approach with datasets from a number of real-world applications.
C1 [Oliver, Peter; Zhang, Eugene; Zhang, Yue] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
C3 Oregon State University
RP Zhang, E (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
EM oliverpe@oregonstate.edu; zhange@eecs.oregonstate.edu;
   zhangyue@oregonstate.edu
OI Oliver, Peter/0009-0002-5090-6057; Zhang, Yue/0000-0002-8467-2781;
   Zhang, Eugene/0000-0003-4752-3119
CR Alpert CJ, 1996, APCCAS '96 - IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS '96, P298, DOI 10.1109/APCAS.1996.569275
   Alsallakh B, 2016, COMPUT GRAPH FORUM, V35, P234, DOI 10.1111/cgf.12722
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   [Anonymous], 2022, World trade organization regional trade agreements database
   Arafat NA, 2017, LECT NOTES COMPUT SC, V10439, P387, DOI 10.1007/978-3-319-64471-4_31
   Benczur A. A., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P47, DOI 10.1145/237814.237827
   Berge C., 1976, North-Holland mathematical library, V6
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Bravo-Hermsdorff G, 2020, Arxiv, DOI arXiv:1902.09702
   Bretto A., 2013, Hypergraph Theory: An Introduction, P119, DOI DOI 10.1007/978-3-319-00080-0
   BUI TN, 1993, PROCEEDINGS OF THE SIXTH SIAM CONFERENCE ON PARALLEL PROCESSING FOR SCIENTIFIC COMPUTING, VOLS 1 AND 2, P445
   Chekuri C, 2018, SIAM J COMPUT, V47, P2118, DOI 10.1137/18M1163865
   Chen Y., Leibniz International Proceedings in Informatics (LIPIcs), V198
   CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500
   CONG J, 1993, ACM IEEE D, P755
   Devine Karen D., 2006, P 20 IEEE INT PARALL, DOI DOI 10.1109/IPDPS.2006.1639359
   Dörk M, 2012, IEEE T VIS COMPUT GR, V18, P2709, DOI 10.1109/TVCG.2012.252
   Frank F., SOFSEM 2021: Theory and Practice of Computer Science, P361
   Garbers J., 1990, 1990 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.90CH2924-9), P520, DOI 10.1109/ICCAD.1990.129970
   Gazepoint, 2021, Gp3 eye-tracker
   Hagen L., 1992, 1992 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.92CH03183-1), P422, DOI 10.1109/ICCAD.1992.279334
   Hagen L., 1991, 1991 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (91CH3026-2), P10, DOI 10.1109/ICCAD.1991.185177
   Hauck S, 1997, IEEE T COMPUT AID D, V16, P849, DOI 10.1109/43.644609
   Hendrickson B, 1995, SUPERCOMP PROC, P626
   Imre M, 2020, COMPUT GRAPH-UK, V87, P89, DOI 10.1016/j.cag.2020.02.004
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jacobsen B, 2021, IEEE T VIS COMPUT GR, V27, P1257, DOI 10.1109/TVCG.2020.3030475
   Kabiljo I, 2017, PROC VLDB ENDOW, V10, P1418, DOI 10.14778/3137628.3137650
   Kapralov M, 2022, ANN IEEE SYMP FOUND, P1159, DOI 10.1109/FOCS52979.2021.00114
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Karypis G, 1999, IEEE T VLSI SYST, V7, P69, DOI 10.1109/92.748202
   Kim B, 2007, INTERACT COMPUT, V19, P630, DOI 10.1016/j.intcom.2007.05.004
   Kogan D, 2015, PROCEEDINGS OF THE 6TH INNOVATIONS IN THEORETICAL COMPUTER SCIENCE (ITCS'15), P366, DOI 10.1145/2688073.2688093
   Kuratowski C., 1930, Fund. Math, V15, P271, DOI [DOI 10.4064/FM-15-1-271-283, DOI 10.1007/S10623-014-9982-0]
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Ley M., 2005, DBLP Computer Science Bibliography
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Louis A, 2015, ACM S THEORY COMPUT, P713, DOI 10.1145/2746539.2746555
   Micallef L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0101717
   Qu BT, 2022, IEEE T VIS COMPUT GR, V28, P633, DOI 10.1109/TVCG.2021.3114759
   Qu BT, 2017, SA'17: SIGGRAPH ASIA 2017 SYMPOSIUM ON VISUALIZATION, DOI 10.1145/3139295.3139314
   Riche NH, 2010, IEEE T VIS COMPUT GR, V16, P1090, DOI 10.1109/TVCG.2010.210
   Rodgers P, 2008, LECT NOTES ARTIF INT, V5223, P13, DOI 10.1007/978-3-540-87730-1_6
   Ron D, 2011, MULTISCALE MODEL SIM, V9, P407, DOI 10.1137/100791142
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Santamaría R, 2010, IEICE T INF SYST, VE93D, P1957, DOI 10.1587/transinf.E93.D.1957
   Simonetto P, 2016, IEEE T VIS COMPUT GR, V22, P678, DOI 10.1109/TVCG.2015.2467992
   Simonetto P, 2009, COMPUT GRAPH FORUM, V28, P967, DOI 10.1111/j.1467-8659.2009.01452.x
   Soma T, 2019, Disc Algorithms, P2570
   Spielman DA, 2011, SIAM J COMPUT, V40, P981, DOI 10.1137/08074489X
   Stapleton G, 2012, J VISUAL LANG COMPUT, V23, P163, DOI 10.1016/j.jvlc.2012.02.001
   Stasko J, 2007, IEEE CONF VIS ANAL, P131, DOI 10.1109/VAST.2007.4389006
   Thomassen C., 1984, Progress in graph theory
   Trifunovic A, 2008, J PARALLEL DISTR COM, V68, P563, DOI 10.1016/j.jpdc.2007.11.002
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Zykov A. A., 1974, Russian Mathematical Surveys, V29, P89, DOI DOI 10.1070/RM1974V029N06ABEH001303
NR 57
TC 2
Z9 3
U1 5
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 595
EP 605
DI 10.1109/TVCG.2023.3326599
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500047
PM 37871049
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Huang, ZY
   He, Q
   Maher, K
   Deng, XM
   Lai, YK
   Ma, CX
   Qin, SF
   Liu, YJ
   Wang, HA
AF Huang, Zeyuan
   He, Qiang
   Maher, Kevin
   Deng, Xiaoming
   Lai, Yu-Kun
   Ma, Cuixia
   Qin, Sheng-Feng
   Liu, Yong-Jin
   Wang, Hongan
TI SpeechMirror: A Multimodal Visual Analytics System for Personalized
   Reflection of Online Public Speaking Effectiveness
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Speech; Public speaking; Visual analytics; Interviews; Data
   visualization; Speech enhancement; Reflection; Visual Analytics;
   Multimodal Analysis; Public Speaking; Online Presentation
ID VISUALIZATION; PITCH
AB As communications are increasingly taking place virtually, the ability to present well online is becoming an indispensable skill. Online speakers are facing unique challenges in engaging with remote audiences. However, there has been a lack of evidence-based analytical systems for people to comprehensively evaluate online speeches and further discover possibilities for improvement. This paper introduces SpeechMirror, a visual analytics system facilitating reflection on a speech based on insights from a collection of online speeches. The system estimates the impact of different speech techniques on effectiveness and applies them to a speech to give users awareness of the performance of speech techniques. A similarity recommendation approach based on speech factors or script content supports guided exploration to expand knowledge of presentation evidence and accelerate the discovery of speech delivery possibilities. SpeechMirror provides intuitive visualizations and interactions for users to understand speech factors. Among them, SpeechTwin, a novel multimodal visual summary of speech, supports rapid understanding of critical speech factors and comparison of different speech samples, and SpeechPlayer augments the speech video by integrating visualization of the speaker's body language with interaction, for focused analysis. The system utilizes visualizations suited to the distinct nature of different speech factors for user comprehension. The proposed system and visualization techniques were evaluated with domain experts and amateurs, demonstrating usability for users with low visualization literacy and its efficacy in assisting users to develop insights for potential improvement.
C1 [Huang, Zeyuan; He, Qiang; Deng, Xiaoming; Ma, Cuixia; Wang, Hongan] Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.
   [Huang, Zeyuan; He, Qiang; Deng, Xiaoming; Ma, Cuixia; Wang, Hongan] Univ Chinese Acad Sci, Sch Comp Sci & Technol, Beijing, Peoples R China.
   [Maher, Kevin] Diatom Design LLC Co, Mckittrick, CA USA.
   [Lai, Yu-Kun] Cardiff Univ, Sch Comp Sci Informat, Cardiff, Wales.
   [Qin, Sheng-Feng] Northumbria Univ, Sch Design, Newcastle Upon Tyne, England.
   [Liu, Yong-Jin] Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy
   of Sciences; University of Chinese Academy of Sciences, CAS; Cardiff
   University; Northumbria University; Tsinghua University
RP Ma, CX; Wang, HA (corresponding author), Chinese Acad Sci, Inst Software, Beijing Key Lab Human Comp Interact, Beijing, Peoples R China.; Liu, YJ (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, MOE Key Lab Pervas Comp, Beijing, Peoples R China.
EM zeyuan2020@iscas.ac.cn; heqiang2022@iscas.ac.cn; kevintmaher@gmail.com;
   xiaoming@iscas.ac.cn; LaiY4@cardiff.ac.uk; cuixia@iscas.ac.cn;
   sheng-feng.qin@northumbria.ac.uk; liuyongjin@tsinghua.edu.cn;
   hongan@iscas.ac.cn
RI Lai, Yu-Kun/D-2343-2010
OI Qin, Shengfeng/0000-0001-8538-8136; deng, xiao ming/0000-0001-8576-1201;
   he, qiang/0009-0006-2140-1681; Maher, Kevin/0000-0002-6486-4866; ma, cui
   xia/0000-0003-3999-7429; Huang, Zeyuan/0000-0002-2639-0487; Lai,
   Yukun/0000-0002-2094-5680
FU National Key R&D Program of China
FX No Statement Available
CR Alemi O., 2014, P 2014 INT WORKSH MO, P37
   Gutiérrez PA, 2016, IEEE T KNOWL DATA EN, V28, P127, DOI 10.1109/TKDE.2015.2457911
   Arriaga O, 2017, Arxiv, DOI arXiv:1710.07557
   Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019
   Batista GEAPA, 2014, DATA MIN KNOWL DISC, V28, P634, DOI 10.1007/s10618-013-0312-3
   Bird S., 2009, Natural language processing with Python: analyzing text with the natural language toolkit, V5
   Blair-Early A, 2008, DES ISSUES, V24, P85, DOI 10.1162/desi.2008.24.3.85
   Boersma P., 2001, Glot International, V5, P341
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bttinger Michael., 2020, Foundations of Data Visualization, P297, DOI [DOI 10.1007/978-3-030-34444-3, 10.1007/978-3-030-34444-316, DOI 10.1007/978-3-030-34444-316]
   Cer D, 2018, Arxiv, DOI [arXiv:1803.11175, DOI 10.48550/ARXIV.1803.11175]
   CHERNOFF H, 1973, J AM STAT ASSOC, V68, P361, DOI 10.2307/2284077
   Contributors M., 2022, Openmmlab pose estimation toolbox and benchmark
   D'Angelo S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173923
   Deng XM, 2023, IEEE T PATTERN ANAL, V45, P932, DOI 10.1109/TPAMI.2022.3159725
   Donovan J., 2014, Speaker, Leader, Champion: Succeed at Work Through the Power of Public Speaking, featuring the prize-winning speeches of Toastmasters World Champions, P3
   Echeverria V., 2014, Proceedings of the 2014 ACM workshop on Multimodal Learning Analytics Workshop and Grand Challenge, P53, DOI [DOI 10.1145/2666633.2666641, 10.1145/2666633.26666411,2, DOI 10.1145/2666633.26666411,2]
   Ester M., 1996, P KDD, P226
   Geitgey A., 2018, face recognition
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Green E. P., 2021, Healthy Presentations, P87
   Higuch K, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P571, DOI 10.1145/3172944.3172960
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jadoul Y, 2018, J PHONETICS, V71, P1, DOI 10.1016/j.wocn.2018.07.001
   Jiang W., 2022, arXiv
   Kirchhoff K., 2018, Cmu pronouncing dictionary (cmudict)
   Kravvaris D., 2014, IFIP INT C ARTIFICIA, P60
   Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luzardo G., 2014, P 2014 ACM WORKSHOP, P37, DOI [DOI 10.1145/2666633.26666391,2, 10.1145/2666633.2666639, DOI 10.1145/2666633.2666639]
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   McLean S., 2015, Business Communication for Success. Business Communication for Success, P3
   Microsoft, Azure cognitive speech to text service
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Niewiadomski R, 2014, COVERBAL SYNCHRONY IN HUMAN-MACHINE INTERACTION, P269
   Nojavanasghari B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P284, DOI 10.1145/2993148.2993176
   Ochoa X, 2018, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'18): TOWARDS USER-CENTRED LEARNING ANALYTICS, P360, DOI 10.1145/3170358.3170406
   Pallets, Flask's documentation (1.1.x)
   PLAGENHOEF S, 1983, RES Q EXERCISE SPORT, V54, P169, DOI 10.1080/02701367.1983.10605290
   Potter R. L., 2022, Technical Writing Essentials, P1
   Quoidbach J, 2014, J EXP PSYCHOL GEN, V143, P2057, DOI 10.1037/a0038025
   Ramanarayanan V, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P23, DOI 10.1145/2818346.2820765
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Rimol M., 2021, Gartner says the majority of technology products and services will be built by professionals outside of it by 2024, P2
   Sanchez P., 2021, Presenting Virtually: Communicate and Connect with Online Audiences. Duarte Guide, V1
   Schaefer RS, 2016, PSYCHON B REV, V23, P548, DOI 10.3758/s13423-015-0934-0
   Schneider J, 2017, J COMPUT ASSIST LEAR, V33, P164, DOI 10.1111/jcal.12175
   Sharma R, 2018, IEEE WINT CONF APPL, P476, DOI 10.1109/WACV.2018.00058
   Sieyers B, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.0513
   South L, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P241, DOI 10.1109/VIS47514.2020.00055
   Spakov O, 2007, ELEKTRON ELEKTROTECH, P55
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tanveer M. I., 2018, Awe the Audience: How the Narrative Trajectories Affect Audience Perception in Public Speaking, P1
   Tanveer MI, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P863, DOI 10.1145/2733373.2806350
   Teodorescu HN, 2020, INT C ELECT COMPUT
   Tsai TJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2534
   Tu ZG, 2023, IEEE T PATTERN ANAL, V45, P9469, DOI 10.1109/TPAMI.2023.3247907
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XY, 2020, IEEE VLSI TEST SYMP, DOI 10.1109/vts48691.2020.9107600
   Wörtwein T, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P43, DOI 10.1145/2818346.2820762
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Yuan LP, 2019, INT CONF BIG DATA, P299, DOI [10.1109/bigcomp.2019.8679261, 10.1109/ICCMA46720.2019.8988728, 10.1109/iccma46720.2019.8988728]
   Zeng H., 2022, IEEE Transactions on Visualization and Computer Graphics
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang FZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13299, DOI 10.1109/ICCV48922.2021.01307
   Zhang Frederic Z, 2022, CVPR, P20104
   Zhang J. R., 2012, P 20 ACM INT C MULTI, P1389, DOI [10.1145/2393347.23964991,2, DOI 10.1145/2393347.23964991,2]
NR 71
TC 0
Z9 0
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 606
EP 616
DI 10.1109/TVCG.2023.3326932
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500027
PM 37871082
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Hull, M
   Pednekar, V
   Murray, H
   Roy, N
   Tung, E
   Routray, S
   Guerin, C
   Chen, J
   Wang, ZJ
   Lee, S
   Roozbahani, M
   Chau, DH
AF Hull, Matthew
   Pednekar, Vivian
   Murray, Hannah
   Roy, Nimisha
   Tung, Emmanuel
   Routray, Susanta
   Guerin, Connor
   Chen, Justin
   Wang, Zijie J.
   Lee, Seongmin
   Roozbahani, Mahdi
   Chau, Duen Horng
TI VISGRADER: Automatic Grading of D3 Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Automatic grading; D3 visualization; large class; Selenium; Gradescope
   grading platform
AB Manually grading D3 data visualizations is a challenging endeavor, and is especially difficult for large classes with hundreds of students. Grading an interactive visualization requires a combination of interactive, quantitative, and qualitative evaluation that are conventionally done manually and are difficult to scale up as the visualization complexity, data size, and number of students increase. We present VisGrader, a first-of-its kind automatic grading method for D3 visualizations that scalably and precisely evaluates the data bindings, visual encodings, interactions, and design specifications used in a visualization. Our method enhances students' learning experience, enabling them to submit their code frequently and receive rapid feedback to better inform iteration and improvement to their code and visualization design. We have successfully deployed our method and auto-graded D3 submissions from more than 4000 students in a visualization course at Georgia Tech, and received positive feedback for expanding its adoption.
C1 [Hull, Matthew; Pednekar, Vivian; Murray, Hannah; Roy, Nimisha; Tung, Emmanuel; Routray, Susanta; Guerin, Connor; Chen, Justin; Wang, Zijie J.; Lee, Seongmin; Roozbahani, Mahdi; Chau, Duen Horng] Georgia Inst Technol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Hull, M (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM matthewhull@gatech.edu; vpednekar3@gatech.edu; hmurray9@gatech.edu;
   nroy9@gatech.edu; tunge@gatech.edu; sroutray@gatech.edu;
   cguerin6@gatech.edu; chen3001@gatech.edu; jayw@gatech.edu;
   seongmin@gatech.edu; mahdir@gatech.edu; polo@gatech.edu
RI Murray, Hannah/JWO-5292-2024; Roy, Nimisha/GMW-7646-2022
OI Wang, Zijie Jay/0000-0003-4360-1423; Roozbahani, M.
   Mahdi/0000-0001-5462-1409; Tung, Emmanuel/0009-0005-8511-9215
CR Ahmed UZ, 2020, 2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET 2020), P139, DOI 10.1145/3377814.3381703
   [Anonymous], 2023, CS6242 Data and Visual Analytics
   [Anonymous], 2023, CS448B - Data Visualization
   [Anonymous], 2022, CS5630/CS6630 - Visualization for Data Science
   [Anonymous], 2023, Enrollment history of CS6242 Data and Visual Analytics
   [Anonymous], 2022, CS171 - Visualization
   [Anonymous], 2022, CSE512 - Data Visualization
   [Anonymous], 2019, CS444 - Data Visualization
   Battle L, 2022, IEEE VIS CONF, P1, DOI 10.1109/VIS54862.2022.00009
   Blackboard Inc, 2023, Blackboard LMS
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   D2L Corporation, 2023, Brightspace LMS
   Ed Discussion, 2023, About us
   Elavsky F., 2021, Chartability
   Gao J., 2016, PROC ACM C INNOVATIO, P53, DOI DOI 10.1145/2899415.28994402,3
   Godefroid P, 2005, ACM SIGPLAN NOTICES, V40, P213, DOI 10.1145/1064978.1065036
   Gradescope Inc, 2020, Gradescope
   Gramoli V., 2016, PROC AUSTRALASIAN CO, P1, DOI DOI 10.1145/2843043.28430703,7
   Gulwani S, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P41, DOI 10.1145/2635868.2635912
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hull M, 2021, Arxiv, DOI arXiv:2110.11227
   Instructure Inc, 2023, Canvas LMS
   Joyner D., 2022, Teaching at Scale: Improving Access, Outcomes, and Impact Through Digital Instruction, DOI DOI 10.4324/97810032748348
   Lo LYH, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P11, DOI [10.1109/VISUAL.2019.8933751, 10.1109/visual.2019.8933751]
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Maicus E, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P1145, DOI 10.1145/3328778.3366954
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Mei HH, 2018, J VISUAL LANG COMPUT, V44, P120, DOI 10.1016/j.jvlc.2017.10.001
   Moodle PTY Ltd, 2023, Moodle LMS
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Open JS Foundation, 2023, WebHint
   Parihar S, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P92, DOI 10.1145/3059009.3059026
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Segura S, 2016, IEEE T SOFTWARE ENG, V42, P805, DOI 10.1109/TSE.2016.2532875
   SGW Communications, 2023, Sakai LMS
   Sherman M., 2013, J. Comput. Sci. Coll., V28, P69, DOI DOI 10.5555/2460156.24601713,4,7
   Shin S, 2023, Arxiv, DOI arXiv:2303.06537
   Software Freedom Conservancy, 2021, Selenium Action Chain
   Software Freedom Conservancy, 2021, Selenium
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wilcox Chris, 2015, P 46 ACM TECHN S COM, P90, DOI [10.1145/2676723.2677226event-place, DOI 10.1145/2676723.2677226EVENT-PLACE]
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
NR 48
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 617
EP 627
DI 10.1109/TVCG.2023.3327181
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500013
PM 37883258
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, RZ
   Cui, WW
   Song, TQ
   Xie, X
   Ding, R
   Wang, Y
   Zhang, HD
   Zhou, H
   Wu, YC
AF Li, Renzhong
   Cui, Weiwei
   Song, Tianqi
   Xie, Xiao
   Ding, Rui
   Wang, Yun
   Zhang, Haidong
   Zhou, Hong
   Wu, Yingcai
TI Causality-Based Visual Analysis of Questionnaire Responses
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Causal analysis; Questionnaire; Design study
ID ASSOCIATION RULES; EXPLORATION
AB As the final stage of questionnaire analysis, causal reasoning is the key to turning responses into valuable insights and actionable items for decision-makers. During the questionnaire analysis, classical statistical methods (e.g., Differences-in-Differences) have been widely exploited to evaluate causality between questions. However, due to the huge search space and complex causal structure in data, causal reasoning is still extremely challenging and time-consuming, and often conducted in a trial-and-error manner. On the other hand, existing visual methods of causal reasoning face the challenge of bringing scalability and expert knowledge together and can hardly be used in the questionnaire scenario. In this work, we present a systematic solution to help analysts effectively and efficiently explore questionnaire data and derive causality. Based on the association mining algorithm, we dig question combinations with potential inner causality and help analysts interactively explore the causal sub-graph of each question combination. Furthermore, leveraging the requirements collected from the experts, we built a visualization tool and conducted a comparative study with the state-of-the-art system to show the usability and efficiency of our system.
C1 [Li, Renzhong; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Zhejiang, Peoples R China.
   [Cui, Weiwei; Ding, Rui; Wang, Yun; Zhang, Haidong] Microsoft Res Asia, Beijing, Peoples R China.
   [Song, Tianqi; Xie, Xiao] Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
   [Zhou, Hong] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Zhejiang University; Microsoft; Microsoft Research Asia; Zhejiang
   University; Shenzhen University
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
EM renzhongli@zju.edu.cn; weiweicu@microsoft.com; holly1027@zju.edu.cn;
   xxie@zju.edu.cn; juding@microsoft.com; wangyun@microsoft.com;
   haizhang@microsoft.com; hzhou@szu.edu.cn; ycwu@zju.edu.cn
RI Li, Ren-Zhong/E-6659-2012
OI Li, Renzhong/0000-0002-6577-036X
FU National Key R&D Program of China
FX No Statement Available
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   [Anonymous], 2020, Microsoft Forms
   [Anonymous], 2020, About us
   Antonakis J, 2010, LEADERSHIP QUART, V21, P1086, DOI 10.1016/j.leaqua.2010.10.010
   Bae J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P64, DOI 10.5220/0006102300640074
   Bae J, 2017, COMPUT GRAPH FORUM, V36, P411, DOI 10.1111/cgf.13198
   Bertrand M, 2004, Q J ECON, V119, P249, DOI 10.1162/003355304772839588
   Borgelt C, 2002, COMPSTAT 2002: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P395
   Burton SH, 2014, INTELL DATA ANAL, V18, P479, DOI 10.3233/IDA-140652
   Cao AQ, 2021, VIS INFORM, V5, P102, DOI 10.1016/j.visinf.2021.09.002
   Chen YL, 2009, KNOWL-BASED SYST, V22, P46, DOI 10.1016/j.knosys.2008.06.003
   Craft B, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P110, DOI 10.1109/IV.2005.28
   Craney T. A., 2002, Quality Engineering, V14, P391, DOI 10.1081/QEN-120001878
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Eick SG, 2002, J COMPUT GRAPH STAT, V11, P22, DOI 10.1198/106186002317375604
   FARRAR DE, 1967, REV ECON STAT, V49, P92, DOI 10.2307/1937887
   GAREY MR, 1977, SIAM J APPL MATH, V32, P826, DOI 10.1137/0132071
   Ghai Bhavya, 2023, IEEE Trans Vis Comput Graph, V29, P473, DOI 10.1109/TVCG.2022.3209484
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Hahn JY, 2001, ECONOMETRICA, V69, P201, DOI 10.1111/1468-0262.00183
   Hoque MN, 2022, IEEE T VIS COMPUT GR, V28, P4728, DOI 10.1109/TVCG.2021.3102051
   Jin ZC, 2021, IEEE T VIS COMPUT GR, V27, P1343, DOI 10.1109/TVCG.2020.3030465
   Kaggle, 2022, US
   Kale A, 2022, IEEE T VIS COMPUT GR, V28, P1150, DOI 10.1109/TVCG.2021.3114824
   Klaus J, 2023, VIS INFORM, V7, P72, DOI 10.1016/j.visinf.2023.05.001
   Krosnick J.A., 2018, The Palgrave Handbook of Survey Research, P439
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lonsdale C, 2011, PSYCHOL SPORT EXERC, V12, P284, DOI 10.1016/j.psychsport.2010.11.003
   Mendez J., 2023, Computer Graphics Forum, DOI [10.1111/cgf.147302, DOI 10.1111/CGF.147302]
   Müller-Sielaff J, 2023, IEEE T VIS COMPUT GR, V29, P3602, DOI 10.1109/TVCG.2022.3166071
   Pearl J., 2000, Causality: Models, Reasoning, and Inference, P5
   Pister A, 2021, IEEE T VIS COMPUT GR, V27, P1775, DOI 10.1109/TVCG.2020.3030347
   Ramsey Joseph, 2017, Int J Data Sci Anal, V3, P121, DOI 10.1007/s41060-016-0032-z
   Spirtes P., 1991, Social Science Computer Review, V9, P62, DOI 10.1177/089443939100900106
   Tianchi, 2021, About Us
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   VIRZI RA, 1992, HUM FACTORS, V34, P457, DOI 10.1177/001872089203400407
   Wang J, 2017, IEEE CONF VIS ANAL, P151, DOI 10.1109/VAST.2017.8585647
   Wang J, 2016, IEEE T VIS COMPUT GR, V22, P230, DOI 10.1109/TVCG.2015.2467931
   Wei Xiaofeng, 2016, Computer Engineering, V42, P71, DOI 10.3969/j.issn.1000-3428.2016.01.014
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1448, DOI 10.1109/TVCG.2020.3028957
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Yen CHE, 2019, COMPUT GRAPH FORUM, V38, P173, DOI 10.1111/cgf.13680
   Yeon H, 2021, J VISUAL-JAPAN, V24, P583, DOI 10.1007/s12650-020-00716-0
   Yi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P752, DOI 10.1007/978-3-030-58595-2_45
   Zhu ZH, 2023, J VISUAL-JAPAN, V26, P611, DOI 10.1007/s12650-022-00896-x
NR 48
TC 0
Z9 0
U1 6
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 638
EP 648
DI 10.1109/TVCG.2023.3327376
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500018
PM 37903040
DA 2024-11-06
ER

PT J
AU Bach, B
   Keck, M
   Rajabiyazdi, F
   Losev, T
   Meirelles, I
   Dykes, J
   Laramee, RS
   Alkadi, M
   Stoiber, C
   Huron, S
   Perin, C
   Morais, L
   Aigner, W
   Kosminsky, D
   Boucher, M
   Knudsen, S
   Manataki, A
   Aerts, J
   Hinrichs, U
   Roberts, JC
   Carpendale, S
AF Bach, Benjamin
   Keck, Mandy
   Rajabiyazdi, Fateme
   Losev, Tatiana
   Meirelles, Isabel
   Dykes, Jason
   Laramee, Robert S.
   Alkadi, Mashael
   Stoiber, Christina
   Huron, Samuel
   Perin, Charles
   Morais, Luiz
   Aigner, Wolfgang
   Kosminsky, Doris
   Boucher, Magdalena
   Knudsen, Soren
   Manataki, Areti
   Aerts, Jan
   Hinrichs, Uta
   Roberts, Jonathan C.
   Carpendale, Sheelagh
TI Challenges and Opportunities in Data Visualization Education: A Call to
   Action
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data Visualization; Education; Challenges
ID FORMAL EDUCATION; DESIGN; REFLECTIONS; LITERACY; NEED
AB This paper is a call to action for research and discussion on data visualization education. As visualization evolves and spreads through our professional and personal lives, we need to understand how to support and empower a broad and diverse community of learners in visualization. Data Visualization is a diverse and dynamic discipline that combines knowledge from different fields, is tailored to suit diverse audiences and contexts, and frequently incorporates tacit knowledge. This complex nature leads to a series of interrelated challenges for data visualization education. Driven by a lack of consolidated knowledge, overview, and orientation for visualization education, the 21 authors of this paper-educators and researchers in data visualization-identify and describe 19 challenges informed by our collective practical experience. We organize these challenges around seven themes People, Goals & Assessment, Environment, Motivation, Methods, Materials, and Change. Across these themes, we formulate 43 research questions to address these challenges. As part of our call to action, we then conclude with 5 cross-cutting opportunities and respective action items: embrace DIVERSITY+INCLUSION, build COMMUNITIES, conduct RESEARCH, act AGILE, and relish RESPONSIBILITY. We aim to inspire researchers, educators and learners to drive visualization education forward and discuss why, how, who and where we educate, as we learn to use visualization to address challenges across many scales and many domains in a rapidly changing world:
C1 [Bach, Benjamin; Alkadi, Mashael; Manataki, Areti; Hinrichs, Uta] Univ Edinburgh, Edinburgh, Scotland.
   [Keck, Mandy] Univ Appl Sci Upper Austria, Wels, Austria.
   [Rajabiyazdi, Fateme] Carleton Univ, Ottawa, ON, Canada.
   [Losev, Tatiana; Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC, Canada.
   [Meirelles, Isabel] OCAD Univ, Toronto, ON, Canada.
   [Dykes, Jason] City Univ London, London, England.
   [Morais, Luiz] Univ Fed Pernambuco, Recife, Brazil.
   [Laramee, Robert S.] Univ Nottingham, Nottingham, England.
   [Stoiber, Christina; Aigner, Wolfgang; Boucher, Magdalena] Univ Appl Sci St Polten, St Polten, Austria.
   [Huron, Samuel] Telecom Paris, Paris, France.
   [Perin, Charles] Univ Victoria, Victoria, BC, Canada.
   [Kosminsky, Doris] Univ Fed Rio De Janeiro, Rio De Janeiro, Brazil.
   [Knudsen, Soren] Univ Copenhagen, Copenhagen, Denmark.
   [Aerts, Jan] Hasselt Univ, Hasselt, Belgium.
   [Roberts, Jonathan C.] Bangor Univ, Bangor, Wales.
C3 University of Edinburgh; Carleton University; Simon Fraser University;
   City St Georges, University of London; Universidade Federal de
   Pernambuco; University of Nottingham; IMT - Institut Mines-Telecom;
   Institut Polytechnique de Paris; Telecom Paris; University of Victoria;
   Universidade Federal do Rio de Janeiro; University of Copenhagen;
   Hasselt University; Bangor University
RP Bach, B (corresponding author), Univ Edinburgh, Edinburgh, Scotland.
EM bbach@ed.ac.uk; Mandy.Keck@fh-hagenberg.at;
   fateme.rajabiyazdi@carleton.ca; tatiana_losev@sfu.ca;
   imeirelles@ocadu.ca; J.Dykes@city.ac.uk;
   robert.laramee@nottingham.ac.uk; m.alkadi@sms.ed.ac.uk;
   Christina.Stoiber@fhstp.ac.at; samuel.huron@telecom-paris.fr;
   cperin@uvic.ca; lamm@cin.ufpe.br; Wolfgang.Aigner@fhstp.ac.at;
   doriskos@eba.ufrj.br; Magdalena.Boucher@fhstp.ac.at; soekn@itu.dk;
   A.Manataki@st-andrews.ac.uk; jan.aerts@belvis.io; uhinrich@ed.ac.uk;
   j.c.roberts@bangor.ac.uk; sheelagh@sfu.ca
RI Roberts, Jonathan/U-1520-2019; Aerts, Jan/AAQ-6949-2020; Hinrichs,
   Uta/X-1644-2019; Dykes, Jason/AAD-6067-2021; Keck, Mandy/K-9750-2019
OI Aerts, Jan/0000-0002-6416-2717; Losev, Tatiana/0000-0002-0363-8072;
   Manataki, Areti/0000-0003-3698-8535; Meirelles,
   Isabel/0000-0001-8111-6002; Morais, Luiz Augusto/0000-0002-5506-9473;
   Keck, Mandy/0000-0002-5821-8016; Huron, Samuel/0000-0002-9319-8559;
   Laramee, Robert S/0000-0002-3874-6145; Stoiber,
   Christina/0000-0002-1764-1467
FU EPSRC
FX No Statement Available
CR Adar Eytan, 2023, IEEE Trans Vis Comput Graph, V29, P268, DOI 10.1109/TVCG.2022.3209402
   Adhikari A., 2021, Harvard Data Science Review, V2, DOI DOI 10.1162/99608F92.CB0FA8D24
   Aerts J., 2022, ALTVIS
   Aerts J, 2021, IEEE COMPUT GRAPH, V41, P15, DOI 10.1109/MCG.2021.3116042
   AlKadi Mashael, 2023, IEEE Trans Vis Comput Graph, V29, P907, DOI 10.1109/TVCG.2022.3209487
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   Amabili L, 2021, IEEE COMPUT GRAPH, V41, P71, DOI 10.1109/MCG.2021.3115446
   Archambault D., 2023, COMPUTER GRAPHICS forum, V42
   Bach B., 2022, 4 IEEE WORKSHOP VISU
   Bach B., 2023, Dagstuhl Reports, V12, DOI [10.4230/DagRep.12.6.832,3, DOI 10.4230/DAGREP.12.6.832,3]
   Bach B., 2018, VISBIA AVI
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Bach B, 2021, IEEE COMPUT GRAPH, V41, P13, DOI 10.1109/MCG.2021.3117412
   Bach Benjamin, 2023, DAGSTUHL REPORTS, V12
   Balchin W. G. V., 1976, The American Cartographer, V3, P33, DOI DOI 10.1559/1523040767840802212
   Ballentine Brian, 2022, Communication Design Quarterly, P24, DOI 10.1145/3507454.3507457
   Bao C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501891
   Beasley ZJ, 2021, IEEE COMPUT GRAPH, V41, P59, DOI 10.1109/MCG.2021.3115387
   Bertling J. G., 2021, Art Education, V74, P44, DOI DOI 10.1080/00043125.2020.1852381
   Beyer J, 2021, IEEE COMPUT GRAPH, V41, P37, DOI 10.1109/MCG.2021.3115413
   Biggs J., 2011, Teaching for Quality Learning at University, V4, P5
   Bishop F, 2020, IEEE T VIS COMPUT GR, V26, P451, DOI 10.1109/TVCG.2019.2934804
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P1407, DOI 10.1109/TVCG.2018.2802520
   Bloom B., 1956, Taxonomy of Educational Objectives, Handbook 1: Cognitive Domain, V2nd, P5
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowler RD, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502107
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Brandt MJ, 2014, J EXP SOC PSYCHOL, V50, P217, DOI 10.1016/j.jesp.2013.10.005
   Brooks C, 2021, INT J ARTIF INTELL E, V31, P516, DOI 10.1007/s40593-021-00262-2
   Brown A.H., 2019, The essentials of instructional design: Connecting fundamental principles with process and practice, DOI DOI 10.4324/9780429439698
   Burch M, 2020, J VISUAL-JAPAN, V23, P895, DOI 10.1007/s12650-020-00659-6
   Byrd VL, 2021, IEEE COMPUT GRAPH, V41, P25, DOI 10.1109/MCG.2021.3115396
   Cairo A., 2019, How Charts Lie, P4
   Carpendale M. S. T., 2003, Technical report, DOI DOI 10.11575/PRISM/30495
   Catherine DIgnazio R. B., 2018, Digital Humanities Quarterly, P2
   Chen CM, 2005, IEEE COMPUT GRAPH, V25, P12, DOI 10.1109/MCG.2005.91
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Cook K.A., 2005, Technical Report
   Corneli J., 2018, PROC ANN CONVENTION
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Daneshzand Foroozan, 2023, IEEE Trans Vis Comput Graph, V29, P225, DOI 10.1109/TVCG.2022.3209365
   Dewey J., 1938, Experience and education
   Diehl A., 2018, EUROVIS SHORT PAPERS, V6, P7
   DIgnazio Catherine., 2020, DATA VISUALIZATION S, P207, DOI [10.2307/j.ctvzgb8c7.194, DOI 10.2307/J.CTVZGB8C7.194]
   Domik G, 2000, IEEE COMPUT GRAPH, V20, P16, DOI 10.1109/38.851744
   Domik G, 2012, IEEE COMPUT GRAPH, V32, P87, DOI 10.1109/MCG.2012.18
   Drucker J, 2011, DIGIT HUMANITIES Q, V5
   Elmqvist N, 2012, IEEE COMPUT GRAPH, V32, P84, DOI 10.1109/MCG.2012.55
   Ens B., 2021, PROC CHI ACM, DOI [10.1145/3411764.34468662,7, DOI 10.1145/3411764.34468662,7]
   Firat E. E., 2019, Dialogue with the Creative Economy, Special Issue on Visualization, V4, P146, DOI DOI 10.22398/2525-2828.412146-1602,8
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Friedman A., 2021, PEDAGOGY DATA VIS WO
   Gaisch M, 2020, J APPL RES HIGH EDUC, V12, P137, DOI 10.1108/JARHE-03-2018-0048
   Garrison DR, 2016, THINKING COLLABORATIVELY: LEARNING IN A COMMUNITY OF INQUIRY, P1
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Goodyear P., 2015, HERDSA Review of Higher Education, V2, P27, DOI [DOI 10.1111/HEA.12037_26, DOI 10.1111/HEA.1203726]
   Goodyear P, 2021, ETR&D-EDUC TECH RES, V69, P445, DOI 10.1007/s11423-020-09926-7
   Graham E, 2017, ENGL STUD, V98, P449, DOI 10.1080/0013838X.2017.1332021
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   He SQ, 2017, IEEE T VIS COMPUT GR, V23, P561, DOI 10.1109/TVCG.2016.2599338
   Hearst M., 2015, IEEE VIS 2015 Panel: Vis, the next generation: Teaching across the researcherpractitioner gap
   Henshaw AL, 2018, J POLITICAL SCI EDUC, V14, P423, DOI 10.1080/15512169.2017.1419875
   Huron S., 2 IEEE VIS WORKSHOP
   Huron S., 1 IEEE VIS WORKSHOP
   Huron S., 2014, PROC 2014 C DESIGNIN, DOI DOI 10.1145/2598510.25985662,6,7
   Huron S, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1409, DOI 10.1145/3064663.3064798
   IPCC, 2023, Climate change 2021: the physical science basis. Contribution of working group I to the sixth assessment report of the intergovernmental panel on climate change, P81, DOI 10.59327/IPCC/AR6-9789291691647.001
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Johnson C., 2005, NIH-NSF Visualization Research Challenges Report, P2
   Johnson C. G., 2006, PROC BALTIC SEA, P120, DOI DOI 10.1145/1315803.13158255
   Johnson G., 2004, PROC IEEE VISUALIZAT, P569, DOI DOI 10.1109/VISUAL.2004.78
   Joshi A., 1 IEEE VIS WORKSHOP
   Joshi A., 2 IEEE VIS WORKSHOP
   Kahn J, 2021, LEARN MEDIA TECHNOL, V46, P128, DOI 10.1080/17439884.2020.1826962
   Kammer D., 2021, P 2 IEEE VISACTIVITI
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Keck M., 2023, EDUVIS WORKSHOP VISU
   Keck M, 2021, IEEE COMPUT GRAPH, V41, P80, DOI 10.1109/MCG.2021.3115416
   Kerren A, 2008, LECT NOTES COMPUT SC, V4950, P65, DOI 10.1007/978-3-540-70956-5_4
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Knox H, 2018, MATER DIGIT, P1
   Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Laramee R., 2014, Future Challenges and Unsolved Problems in Multi-field Visualization, P205, DOI DOI 10.1007/978-1-4471-6497-5
   Lave J., 1991, SITUATED LEARNING LE
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee V., 2018, Instructional Technology and Learning Sciences Faculty Public., P4
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Leifler E, 2020, INT J LESSON LEARN S, V9, P221, DOI 10.1108/IJLLS-01-2020-0003
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Liu X., 2023, Information Visualization, V22, DOI DOI 10.1177/147387162211269921,7
   Losev T, 2022, IEEE COMPUT GRAPH, V42, P64, DOI 10.1109/MCG.2022.3209605
   Loy A, 2019, J STAT EDUC, V27, P2, DOI 10.1080/10691898.2018.1564638
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   May R., 2010, IEEE VIS
   McGettrick A, 2005, COMPUT J, V48, P42, DOI 10.1093/comjnl/bxh064
   McNutt A., 2018, VISGUIDES 2 WORKSHOP, P1
   Melton R., 2014, Objectives, Competencies and Learning Outcomes: Developing Instructional Materials in Open and Distance Learning, P4
   Moere AV, 2007, COMPUTER-AIDED ARCHITECTURAL DESIGN FUTURES (CAAD FUTURES) 2007, P71, DOI 10.1007/978-1-4020-6528-6_6
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murtazin K., 2020, PROC FRONT EDUC CONF, P1, DOI [DOI 10.1109/fie44824.2020.9274264, 10.1109/FIE44824.2020.9274264, DOI 10.1109/FIE44824.2020.9274264]
   Owen GS, 2013, IEEE COMPUT GRAPH, V33, P14, DOI 10.1109/MCG.2013.57
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Parsons P, 2022, IEEE T VIS COMPUT GR, V28, P665, DOI 10.1109/TVCG.2021.3114959
   Pereira D, 2016, ASSESS EVAL HIGH EDU, V41, P1008, DOI 10.1080/02602938.2015.1055233
   Perin C., 2014, Theses, P6
   Perin C, 2021, IEEE COMPUT GRAPH, V41, P48, DOI 10.1109/MCG.2021.3115417
   Preves S, 2009, TEACH SOCIOL, V37, P245, DOI 10.1177/0092055X0903700303
   Riche N. H., 2018, Data-driven storytelling, DOI [10.1201/97813152815752, DOI 10.1201/97813152815752]
   Roberts JC, 2022, 2022 IEEE 4TH WORKSHOP ON VISUALIZATION GUIDELINES IN RESEARCH, DESIGN, AND EDUCATION (VISGUIDES 2022), P23, DOI 10.1109/VisGuides57787.2022.00009
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Romanelli F, 2009, AM J PHARM EDUC, V73, DOI 10.5688/aj730109
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Rushmeier H., 2006, PROC IEEE VISUALIZAT, P2
   Rushmeier H, 2007, IEEE COMPUT GRAPH, V27, P12, DOI 10.1109/MCG.2007.156
   Ryan L, 2019, IEEE COMPUT GRAPH, V39, P95, DOI 10.1109/MCG.2018.2889526
   Saket B, 2020, IEEE T VIS COMPUT GR, V26, P482, DOI 10.1109/TVCG.2019.2934534
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Schofield T, 2013, C&C'13: PROCEEDINGS OF THE 9TH ACM CONFERENCE ON CREATIVITY & COGNITION 2013, P175
   Schunk D., 2014, Motivation in Education: Theory, Research, and Applications, P5
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Setiawan E. P., 2021, J. Math. Educ., V12, P427, DOI DOI 10.22342/JME.12.3.13202.427-448
   Syeda UH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376829
   Tedre M, 2023, ACM T COMPUT EDUC, V23, DOI 10.1145/3487049
   Tsai YS, 2020, ASSESS EVAL HIGH EDU, V45, P554, DOI 10.1080/02602938.2019.1676396
   Turkay C, 2017, LECT NOTES COMPUT SC, V10410, P191, DOI 10.1007/978-3-319-66808-6_13
   Tygel A. F., 2016, J COMMUNITY INFORM, V12, P108, DOI DOI 10.15353/JOCI.V12I3.3279
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Wang ZZ, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299043
   Wenger E., 1999, Communities of practice: Learning, meaning, and identity, V4, P5
   Wileman R. E., 1993, Visual Communicating, P2
   Wood J., 2022, IEEE 2022 ALTVIS WOR, P7
   Wun T, 2016, COMPUT GRAPH FORUM, V35, P111, DOI 10.1111/cgf.12887
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 138
TC 1
Z9 1
U1 5
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 649
EP 660
DI 10.1109/TVCG.2023.3327378
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500139
PM 37934634
OA Green Published, Green Accepted
DA 2024-11-06
ER

PT J
AU Huang, YS
   Zhang, ZR
   Jiao, A
   Ma, YX
   Cheng, R
AF Huang, Yansong
   Zhang, Zherui
   Jiao, Ao
   Ma, Yuxin
   Cheng, Ran
TI A Comparative Visual Analytics Framework for Evaluating Evolutionary
   Processes in Multi-Objective Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; evolutionary multi-objective optimization
ID MODEL SELECTION; VISUALIZATION; ALGORITHM; SETS
AB Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.
C1 [Huang, Yansong; Zhang, Zherui; Jiao, Ao; Ma, Yuxin; Cheng, Ran] Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
C3 Southern University of Science & Technology
RP Ma, YX (corresponding author), Southern Univ Sci & Technol, Dept Comp Sci & Engn, Shenzhen, Peoples R China.
EM huangys2019@mail.sustech.edu.cn; zhangzr32021@mail.sustech.edu.cn;
   jiaoa2020@mail.sustech.edu.cn; mayx@sustech.edu.cn;
   chengr@sustech.edu.cn
RI Zhang, Zherui/KTI-1299-2024; Ma, Yuxin/AAJ-4486-2020; Cheng,
   Ran/V-1486-2018
OI Cheng, Ran/0000-0001-9410-8263
FU National Natural Science Foundation of China
FX No Statement Available
CR Abdolmaleki A, 2020, PR MACH LEARN RES, V119
   Andrienko N., 2021, Visual Informatics, V5, P2
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Blank J, 2020, IEEE ACCESS, V8, P89497, DOI 10.1109/ACCESS.2020.2990567
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Cawley GC, 2010, J MACH LEARN RES, V11, P2079
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Chen SH, 2013, IEEE PAC VIS SYMP, P153, DOI 10.1109/PacificVis.2013.6596140
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   Coello CAC, 2004, LECT NOTES COMPUT SC, V2972, P688
   Deb K, 2002, IEEE C EVOL COMPUTAT, P825, DOI 10.1109/CEC.2002.1007032
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Feydy Jean, 2019, PR MACH LEARN RES, V89
   Geatpy, About us
   Gleicher M., 2020, Computer Graphics Forum, V39, P2
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gong MG, 2007, IEEE C EVOL COMPUTAT, P15
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   He C, 2020, COMPLEX INTELL SYST, V6, P189, DOI 10.1007/s40747-019-00126-2
   He ZA, 2016, IEEE T EVOLUT COMPUT, V20, P386, DOI 10.1109/TEVC.2015.2472283
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Ibrahim A, 2016, IEEE C EVOL COMPUTAT, P736, DOI 10.1109/CEC.2016.7743865
   Kahng M., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kim H, 2017, AAAI CONF ARTIF INTE, P1001
   Kotthoff L, 2019, SPRING SER CHALLENGE, P81, DOI 10.1007/978-3-030-05318-5_4
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li K, 2018, IEEE ACCESS, V6, P26194, DOI 10.1109/ACCESS.2018.2832181
   Li MQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3300148
   Li MQ, 2017, IEEE COMPUT INTELL M, V12, P88, DOI 10.1109/MCI.2017.2742869
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   Lotov A., 2004, Interactive Decision Maps: Approximation and Visualization of Pareto Frontier, P2
   Lu K., 2023, P ACM CHI C HUM FACT
   Lu Y., 2017, Computer Graphics Forum, V36, P2
   Lu ZC, 2024, IEEE T EVOLUT COMPUT, V28, P323, DOI 10.1109/TEVC.2022.3233364
   Ma Y., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P3
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Mouret J.-B., 2011, NEW HORIZONS EVOLUTI, P8
   Mühlbacher T, 2014, IEEE T VIS COMPUT GR, V20, P1643, DOI 10.1109/TVCG.2014.2346578
   Murugesan S, 2019, IEEE COMPUT GRAPH, V39, P47, DOI 10.1109/MCG.2019.2919033
   Nagar D, 2023, SWARM EVOL COMPUT, V76, DOI 10.1016/j.swevo.2022.101202
   Ono JP, 2021, IEEE T VIS COMPUT GR, V27, P390, DOI 10.1109/TVCG.2020.3030361
   Pister A, 2021, IEEE T VIS COMPUT GR, V27, P1775, DOI 10.1109/TVCG.2020.3030347
   Pohlheim H, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P533
   Raschka S, 2020, Arxiv, DOI [arXiv:1811.12808, 10.48550/arXiv.1811.12808, DOI 10.48550/ARXIV.1811.12808]
   Reddy M. J., 2006, Water Resources Management, V20, P1
   Schott J. R., 1995, Fault tolerant design using single and multicriteria genetic algorithm optimization, P4
   Sener O., 2018, Advances in neural information processing systems, V31, P2
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Talukder AKMKA, 2020, IEEE COMPUT INTELL M, V15, P36, DOI 10.1109/MCI.2020.2976184
   Tian Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3470971
   Tian Y, 2017, IEEE COMPUT INTELL M, V12, P73, DOI 10.1109/MCI.2017.2742868
   Tusar T, 2015, IEEE T EVOLUT COMPUT, V19, P225, DOI 10.1109/TEVC.2014.2313407
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vincalek Jakub, 2021, GECCO '21: Proceedings of the Genetic and Evolutionary Computation Conference Companion, P231, DOI 10.1145/3449726.3459483
   Walker DJ, 2013, IEEE T EVOLUT COMPUT, V17, P165, DOI 10.1109/TEVC.2012.2225064
   Wang J., 2022, IEEE Transactions on Visualization and Computer Graphics, P1
   Wang Q., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Wang Q., 2019, P ACM CHI C HUM FACT, P1
   Wang XM, 2020, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST50239.2020.00006
   Wang Y., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P6
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Xie T., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Xuan X., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Yadav D, 2023, EUR J OPER RES, V309, P1183, DOI 10.1016/j.ejor.2023.01.062
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Ye Y., 2022, IEEE Transactions on Visualization and Computer Graphics, P1
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zeng H., 2017, P WORKSH VIS AN DEEP
   Zhang J., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P2
   Zitzler E, 1998, LECT NOTES COMPUT SC, V1498, P292, DOI 10.1007/BFb0056872
   Zitzler E., 2004, Metaheuristics for Multiobjective Optimisation, P3
   Zitzler E, 2000, EVOL COMPUT, V8, P173, DOI 10.1162/106365600568202
NR 79
TC 2
Z9 2
U1 5
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 661
EP 671
DI 10.1109/TVCG.2023.3326921
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500017
PM 37874721
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Subramonyam, H
   Hullman, J
AF Subramonyam, Hariharan
   Hullman, Jessica
TI Are We Closing the Loop Yet? Gaps in the Generalizability of VIS4ML
   Research
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Pipelines; Machine learning; Task analysis; Surveys; Human in the loop;
   Data visualization; Visual analytics; VIS4ML; Visualization;
   Human-in-the-loop; Human Knowledge; Generalizability; Survey
ID VISUAL ANALYTICS; DESIGN; SELECTION; MODEL
AB Visualization for machine learning (VIS4ML) research aims to help experts apply their prior knowledge to develop, understand, and improve the performance of machine learning models. In conceiving VIS4ML systems, researchers characterize the nature of human knowledge to support human-in-the-loop tasks, design interactive visualizations to make ML components interpretable and elicit knowledge, and evaluate the effectiveness of human-model interchange. We survey recent VIS4ML papers to assess the generalizability of research contributions and claims in enabling human-in-the-loop ML. Our results show potential gaps between the current scope of VIS4ML research and aspirations for its use in practice. We find that while papers motivate that VIS4ML systems are applicable beyond the specific conditions studied, conclusions are often overfitted to non-representative scenarios, are based on interactions with a small set of ML experts and well-understood datasets, fail to acknowledge crucial dependencies, and hinge on decisions that lack justification. We discuss approaches to close the gap between aspirations and research claims and suggest documentation practices to report generality constraints that better acknowledge the exploratory nature of VIS4ML research.
C1 [Subramonyam, Hariharan] Stanford Univ, Stanford, CA 94305 USA.
   [Hullman, Jessica] Northwestern Univ, Evanston, IL USA.
C3 Stanford University; Northwestern University
RP Subramonyam, H (corresponding author), Stanford Univ, Stanford, CA 94305 USA.
EM harihars@stanford.edu; jhullman@northwestern.edu
RI Hullman, Jessica/P-7130-2018
FU NSF
FX No Statement Available
CR Akbaba D., 2023, Troubling collaboration: Matters of care for visualization design study
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Alsallakh B, 2014, IEEE T VIS COMPUT GR, V20, P1703, DOI 10.1109/TVCG.2014.2346660
   Arora S., 2018, C LEARN THEOR, V75, P1455
   Boukhelifa N, 2020, IEEE COMPUT GRAPH, V40, P88, DOI 10.1109/MCG.2020.3017064
   Brown E. T., 2016, P CHI WORKSH HUM CTR
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Chatzimparmpas A, 2021, COMPUT GRAPH FORUM, V40, P201, DOI 10.1111/cgf.14300
   Chatzimparmpas A, 2024, Arxiv, DOI arXiv:2203.15753
   Chatzimparmpas A, 2022, IEEE T VIS COMPUT GR, V28, P1773, DOI 10.1109/TVCG.2022.3141040
   Chaudhuri S., 2006, IEEE Data Eng. Bull., V29, P5
   Chen M., 2020, Foundations of Data Visualization, P9
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Das S, 2019, IEEE COMPUT GRAPH, V39, P20, DOI 10.1109/MCG.2019.2922592
   Devezer B., 2020, The case for formal methodology in scientific reform, DOI DOI 10.1101/2020.04.26.048306
   El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654
   El-Assady M, 2019, IEEE T VIS COMPUT GR, V25, P374, DOI 10.1109/TVCG.2018.2864769
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   Endert A, 2014, J INTELL INF SYST, V43, P411, DOI 10.1007/s10844-014-0304-9
   Federico P, 2017, IEEE CONF VIS ANAL, P92, DOI 10.1109/VAST.2017.8585498
   Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972
   Gomez O, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P31, DOI 10.1109/VIS49827.2021.9623271
   Haibe-Kains B, 2020, NATURE, V586, pE14, DOI 10.1038/s41586-020-2766-y
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hong Sungsoo Ray, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392878
   Huang J., 2022, IEEE Transactions on Visualization and Computer Graphics, V1
   Huang XY, 2021, COMPUT GRAPH FORUM, V40, P227, DOI 10.1111/cgf.14302
   Hullman J., 2022, arXiv preprint arXiv:2203.06498, P8
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Jaunet T, 2020, COMPUT GRAPH FORUM, V39, P49, DOI 10.1111/cgf.13962
   Jia S., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Jin Z., 2022, IEEE Transactions on Visualization and Computer Graphics
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kerrigan D, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5120073
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Liao T., 35 C NEUR INF PROC S
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2018, IEEE T VIS COMPUT GR, V24, P163, DOI 10.1109/TVCG.2017.2744378
   McKenna S, 2014, IEEE T VIS COMPUT GR, V20, P2191, DOI 10.1109/TVCG.2014.2346331
   MEEHL PE, 1990, PSYCHOL REP, V66, P195, DOI 10.2466/PR0.66.1.195-244
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Meyer M, 2015, INFORM VISUAL, V14, P234, DOI 10.1177/1473871613510429
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116
   Neutatz F., 2021, IEEE Data Eng. Bull., V44, P2
   Nie SL, 2018, IEEE PAC VIS SYMP, P180, DOI 10.1109/PacificVis.2018.00031
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Park C., 2021, EUR C VIS EUROVIS SH
   Park H., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Rathore A, 2021, COMPUT GRAPH FORUM, V40, P382, DOI 10.1111/cgf.14195
   Sacha D., 2016, ESANN, V1, P2
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sietzen S, 2021, COMPUT GRAPH FORUM, V40, P253, DOI 10.1111/cgf.14418
   Simons DJ, 2017, PERSPECT PSYCHOL SCI, V12, P1123, DOI 10.1177/1745691617708630
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smilkov D, 2016, Arxiv, DOI arXiv:1611.05469
   Sperrle F, 2021, COMPUT GRAPH FORUM, V40, P543, DOI 10.1111/cgf.14329
   Sperrle F, 2020, Arxiv, DOI [arXiv:2009.06433, 10.48550/arXiv.2009.06433, DOI 10.48550/ARXIV.2009.06433]
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Tyagi A., 2022, IEEE Transactions on Visualization & Computer Graphics, P1
   Tyagi A., 1912, IEEE Transactions on Visualization and Computer Graphics, V4
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   von Rueden L, 2021, Arxiv, DOI [arXiv:1903.12394, DOI 10.1109/TKDE.2021.3079836]
   Wang JP, 2022, IEEE T VIS COMPUT GR, V28, P4141, DOI 10.1109/TVCG.2021.3076749
   Wang JP, 2020, IEEE PAC VIS SYMP, P51, DOI 10.1109/PacificVis48177.2020.3542
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2168, DOI 10.1109/TVCG.2019.2903943
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang X., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P4
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wattenberg M., 2016, Distill, V1, P7
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Wu TS, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P747
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yang W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P4
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI [DOI 10.1145/1377966.1377971, 10.1145/1377966.1377971]
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 93
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 672
EP 682
DI 10.1109/TVCG.2023.3326591
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500129
PM 37871059
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lai, SX
   Luan, WN
   Tao, J
AF Lai, Shaoxuan
   Luan, Wanna
   Tao, Jun
TI Explore Your Network in Minutes: A Rapid Prototyping Toolkit for
   Understanding Neural Networks with Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization model; toolkit; neural networks; visual diagnosis
ID VEGA
AB Neural networks attract significant attention in almost every field due to their widespread applications in various tasks. However, developers often struggle with debugging due to the black-box nature of neural networks. Visual analytics provides an intuitive way for developers to understand the hidden states and underlying complex transformations in neural networks. Existing visual analytics tools for neural networks have been demonstrated to be effective in providing useful hints for debugging certain network architectures. However, these approaches are often architecture-specific with strong assumptions of how the network should be understood. This limits their use when the network architecture or the exploration goal changes. In this paper, we present a general model and a programming toolkit, Neural Network Visualization Builder (NNVisBuilder), for prototyping visual analytics systems to understand neural networks. NNVisBuilder covers the common data transformation and interaction model involved in existing tools for exploring neural networks. It enables developers to customize a visual analytics interface for answering their specific questions about networks. NNVisBuilder is compatible with PyTorch so that developers can integrate the visualization code into their learning code seamlessly. We demonstrate the applicability by reproducing several existing visual analytics systems for networks with NNVisBuilder. The source code and some example cases can be found at https://github.com/sysuvis/NVB.
C1 [Lai, Shaoxuan; Luan, Wanna] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Tao, Jun] Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Tao, Jun] Southern Marine Sci & Engn Guangdong Lab Zhuhai, Zhuhai, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Southern Marine Science
   & Engineering Guangdong Laboratory (Zhuhai)
RP Tao, J (corresponding author), Sun Yat Sen Univ, Natl Supercomp Ctr Guangzhou, Sch Comp Sci & Engn, Guangzhou, Peoples R China.; Tao, J (corresponding author), Southern Marine Sci & Engn Guangdong Lab Zhuhai, Zhuhai, Peoples R China.
EM laishx3@mail2.sysu.edu.cn; luanwn@mail2.sysu.edu.cn;
   taoj23@mail.sysu.edu.cn
FU National Key R&D Program of China
FX No Statement Available
CR Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   Amershi S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1357
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chae J., 2017, WORKSHOP VISUAL ANAL, P2
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung S., 2016, P ACM SIGKDD WORKSHO, V14, P2
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Erhan D., 2009, Tech. Rep. Univ. Montr
   Gomez O, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P31, DOI 10.1109/VIS49827.2021.9623271
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Karpathy A, 2015, Arxiv, DOI [arXiv:1506.02078, DOI 10.48550/ARXIV.1506.02078]
   La Rosa B, 2023, COMPUT GRAPH FORUM, V42, P319, DOI 10.1111/cgf.14733
   Li JK, 2021, IEEE T VIS COMPUT GR, V27, P380, DOI 10.1109/TVCG.2020.3030453
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1151, DOI 10.1109/TVCG.2019.2934537
   Li JPK, 2020, IEEE T VIS COMPUT GR, V26, P1548, DOI 10.1109/TVCG.2018.2871139
   Li Y., 2023, ACM Transactions on Interactive Intelligent Systems, DOI [10.1145/35874702, DOI 10.1145/35874702]
   Liu MC, 2018, IEEE CONF VIS ANAL, P60, DOI 10.1109/VAST.2018.8802509
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   Migdal P., 2019, R. RV. torchviz: a package for neural network visualization and debugging
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ojo F, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2810, DOI 10.1145/3485447.3512001
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Park C., 2021, P EUROVIS SHORT PAPE, DOI [10.2312/evs.202110472, DOI 10.2312/EVS.202110472]
   Paszke A, 2019, ADV NEUR IN, V32
   Roeder L., Computer software
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Simonyan K., 2014, P INT C LEARNING REP, DOI [10.48550/arXiv.1312.60341,2, DOI 10.48550/ARXIV.1312.60341,2]
   Smilkov Daniel., Tensorflow playground
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sun GD, 2013, J COMPUT SCI TECH-CH, V28, P852, DOI 10.1007/s11390-013-1383-8
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   VanderPlas J, 2018, J. Open Source Softw., V3, P1057, DOI DOI 10.21105/JOSS.01057
   Vig J, 2019, Arxiv, DOI [arXiv:1906.05714, DOI 10.48550/ARXIV.1906.05714]
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wang ZJ, 2021, Arxiv, DOI arXiv:2103.14625
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wickham H, 2011, WIRES COMPUT STAT, V3, P180, DOI 10.1002/wics.147
   Xuan XW, 2022, IEEE T VIS COMPUT GR, V28, P2326, DOI 10.1109/TVCG.2022.3165347
   Yosinski J, 2015, Arxiv, DOI arXiv:1506.06579
   Zhao JH, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P286, DOI 10.1109/VIS47514.2020.00064
NR 50
TC 1
Z9 1
U1 0
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 683
EP 693
DI 10.1109/TVCG.2023.3326575
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500087
PM 37922180
DA 2024-11-06
ER

PT J
AU Jamonnak, S
   Guo, JJ
   He, WB
   Gou, L
   Ren, L
AF Jamonnak, Suphanut
   Guo, Jiajing
   He, Wenbin
   Gou, Liang
   Ren, Liu
TI OW-Adapter: Human-Assisted Open-World Object Detection with a Few
   Examples
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Detectors; Automobiles; Proposals; Object detection; Object recognition;
   Visual analytics; Training; Open world learning; object detection;
   continuous learning; human-assisted AI
ID NOVELTY DETECTION; VISUAL ANALYSIS
AB Open-world object detection (OWOD) is an emerging computer vision problem that involves not only the identification of predefined object classes, like what general object detectors do, but also detects new unknown objects simultaneously. Recently, several end-to-end deep learning models have been proposed to address the OWOD problem. However, these approaches face several challenges: a) significant changes in both network architecture and training procedure are required; b) they are trained from scratch, which can not leverage existing pre-trained general detectors; c) costly annotations for all unknown classes are needed. To overcome these challenges, we present a visual analytic framework called OW-Adapter. It acts as an adaptor to enable pre-trained general object detectors to handle the OWOD problem. Specifically, OW-Adapter is designed to identify, summarize, and annotate unknown examples with minimal human effort. Moreover, we introduce a lightweight classifier to learn newly annotated unknown classes and plug the classifier into pre-trained general detectors to detect unknown objects. We demonstrate the effectiveness of our framework through two case studies of different domains, including common object recognition and autonomous driving. The studies show that a simple yet powerful adaptor can extend the capability of pre-trained general detectors to detect unknown objects and improve the performance on known classes simultaneously.
C1 [Jamonnak, Suphanut; Guo, Jiajing; He, Wenbin; Gou, Liang; Ren, Liu] Bosch Res North Amer, Sunnyvale, CA 94085 USA.
RP Jamonnak, S (corresponding author), Bosch Res North Amer, Sunnyvale, CA 94085 USA.
EM suphanut.jamonnak@us.bosch.com; jiajing.guo@us.bosch.com;
   wenbin.he2@us.bosch.com; liang.gou@us.bosch.com; liu.ren@us.bosch.com
OI He, Wenbin/0000-0002-5376-5803
CR Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Behrisch M, 2014, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2014.7042480
   Bendale A, 2016, PROC CVPR IEEE, P1563, DOI 10.1109/CVPR.2016.173
   Bendale A, 2015, PROC CVPR IEEE, P1893, DOI 10.1109/CVPR.2015.7298799
   Bruneau Pierrick, 2013, 2013 17th International Conference on Information Visualisation, P168, DOI 10.1109/IV.2013.21
   Caesar H, 2020, PROC CVPR IEEE, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao N, 2016, IEEE T VIS COMPUT GR, V22, P280, DOI 10.1109/TVCG.2015.2467196
   Chalapathy R, 2019, Arxiv, DOI arXiv:1901.03407
   Chen C., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P3
   Chen C., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhamija AR, 2020, IEEE WINT CONF APPL, P1010, DOI 10.1109/WACV45572.2020.9093355
   Everingham M., 2012, PASCAL VISUAL OBJECT
   Faria B, 2022, LECT NOTES ARTIF INT, V13566, P464, DOI 10.1007/978-3-031-16474-3_38
   Fort S., 2021, Advances in Neural Information Processing Systems, V34, P5
   French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gupta A, 2022, PROC CVPR IEEE, P9225, DOI 10.1109/CVPR52688.2022.00902
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Heimerl F, 2012, IEEE T VIS COMPUT GR, V18, P2839, DOI 10.1109/TVCG.2012.277
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Höferlin B, 2012, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2012.6400492
   Hoque Md Naimul, 2023, IEEE Trans Vis Comput Graph, V29, P74, DOI 10.1109/TVCG.2022.3209466
   Jain L. P., 2014, COMPUTER VISION ECCV, P2
   Jaunet T., 2021, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Jia S., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Joseph KJ, 2021, PROC CVPR IEEE, P5826, DOI 10.1109/CVPR46437.2021.00577
   Kahng M., 2018, IEEE transactions on visualization and computer graphics, V25, P3
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K, 2018, ADV NEUR IN, V31
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liang S., 2018, PROC INT C LEARNING, P2
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264
   Markou M, 2003, SIGNAL PROCESS, V83, P2499, DOI 10.1016/j.sigpro.2003.07.019
   Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018
   McCloskey M., 1989, Catastrophic interference in connectionist networks: The sequential learning problem, V24, P2
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Melas-Kyriazi L, 2022, PROC CVPR IEEE, P8354, DOI 10.1109/CVPR52688.2022.00818
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Ouyang L, 2022, ADV NEUR IN
   Perera P, 2020, PROC CVPR IEEE, P11811, DOI 10.1109/CVPR42600.2020.01183
   Perez-Rua Juan-Manuel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13843, DOI 10.1109/CVPR42600.2020.01386
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren S., 2015, Advances in neural information processing systems, P6
   Ruff L, 2021, P IEEE, V109, P756, DOI 10.1109/JPROC.2021.3052449
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Shannon C. E., 1949, A mathematical theory of communication, P4
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Thom D, 2012, IEEE PAC VIS SYMP, P41, DOI 10.1109/PacificVis.2012.6183572
   Wang HZ, 2019, IEEE ACCESS, V7, P107964, DOI 10.1109/ACCESS.2019.2932769
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wilkinson L, 2018, IEEE T VIS COMPUT GR, V24, P256, DOI 10.1109/TVCG.2017.2744685
   Wu Y., 2019, Detectron2, V6
   Wu ZH, 2022, LECT NOTES COMPUT SC, V13670, P193, DOI 10.1007/978-3-031-20080-9_12
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xu H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3413, DOI 10.1145/3308558.3313644
   Yang W., 2022, IEEE Transactions on Visualization and Computer Graphics, V28, P3
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yoshihashi R, 2019, PROC CVPR IEEE, P4011, DOI 10.1109/CVPR.2019.00414
   Yue ZQ, 2021, PROC CVPR IEEE, P15399, DOI 10.1109/CVPR46437.2021.01515
   Zhang H, 2022, Arxiv, DOI arXiv:2203.03605
   Zhang J., 2018, IEEE transactions on visualization and computer graphics, V25, P3
   Zhao X., 2022, arXiv
NR 75
TC 0
Z9 0
U1 10
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 694
EP 704
DI 10.1109/TVCG.2023.3326577
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500066
PM 37871071
DA 2024-11-06
ER

PT J
AU Khan, D
   Bohak, C
   Viola, I
AF Khan, Dawar
   Bohak, Ciril
   Viola, Ivan
TI Dr. KID: Direct Remeshing and K-Set Isometric Decomposition for Scalable
   Physicalization of Organic Shapes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Physicalization; Physical visualization; 3D printing; Isometric
   decomposition; Direct remeshing; Biological structures; Intracellular
   compartments
AB Dr. KID is an algorithm that uses isometric decomposition for the physicalization of potato-shaped organic models in a puzzle fashion. The algorithm begins with creating a simple, regular triangular surface mesh of organic shapes, followed by iterative K-means clustering and remeshing. For clustering, we need similarity between triangles (segments) which is defined as a distance function. The distance function maps each triangle's shape to a single point in the virtual 3D space. Thus, the distance between the triangles indicates their degree of dissimilarity. K-means clustering uses this distance and sorts segments into k classes. After this, remeshing is applied to minimize the distance between triangles within the same cluster by making their shapes identical. Clustering and remeshing are repeated until the distance between triangles in the same cluster reaches an acceptable threshold. We adopt a curvature-aware strategy to determine the surface thickness and finalize puzzle pieces for 3D printing. Identical hinges and holes are created for assembling the puzzle components. For smoother outcomes, we use triangle subdivision along with curvature-aware clustering, generating curved triangular patches for 3D printing. Our algorithm was evaluated using various models, and the 3D-printed results were analyzed. Findings indicate that our algorithm performs reliably on target organic shapes with minimal loss of input geometry.
C1 [Khan, Dawar; Bohak, Ciril; Viola, Ivan] King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal, Saudi Arabia.
C3 King Abdullah University of Science & Technology
RP Khan, D (corresponding author), King Abdullah Univ Sci & Technol, Visual Comp Ctr, Thuwal, Saudi Arabia.
EM dawar.khan@kaust.edu.sa; ciril.bohak@kaust.edu.sa;
   ivan.viola@kaust.edu.sa
RI Khan, Dawar/Q-7730-2019; Viola, Ivan/O-8944-2014
OI Viola, Ivan/0000-0003-4248-6574; Khan, Dawar/0000-0001-5864-1888
FU King Abdullah University of Science and Technology (KAUST)
FX No Statement Available
CR Alliez P, 2008, MATH VIS, P53, DOI 10.1007/978-3-540-33265-7_2
   Bader C, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aas8652
   Bailey MJ, 1998, CURR OPIN STRUC BIOL, V8, P202, DOI 10.1016/S0959-440X(98)80039-0
   Barton M, 2010, COMPUT AIDED GEOM D, V27, P580, DOI 10.1016/j.cagd.2010.04.004
   Casas L, 2015, J CHEM EDUC, V92, P1338, DOI 10.1021/acs.jchemed.5b00147
   Chen DS, 2013, COMPUT GRAPH FORUM, V32, P305, DOI 10.1111/cgf.12050
   Chen XL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818087
   Coffin S., 2006, Geometric puzzle design, P3
   de Freitas AA, 2022, IEEE INT CONF INF VI, P73, DOI 10.1109/IV56949.2022.00021
   Djavaherpour H, 2021, COMPUT GRAPH FORUM, V40, P569, DOI 10.1111/cgf.14330
   Dragicevic P., 2020, Data Physicalization, P1, DOI DOI 10.1007/978-3-319-27648-9_94-1
   Echavarria KR, 2020, ACM J COMPUT CULT HE, V13, DOI 10.1145/3351343
   Eigensatz M., 2010, P ADV ARCH GEOM C, P3
   Elber G, 2022, COMPUT GRAPH-UK, V102, P339, DOI 10.1016/j.cag.2021.10.014
   Eslambolchilar Parisa, 2023, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2023.100565
   Fu CW, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778781
   Gavriil K, 2019, COMPUT AIDED DESIGN, V111, P29, DOI 10.1016/j.cad.2019.01.006
   Hidayat W, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON INFORMATICS AND COMPUTATIONAL SCIENCES (ICICOS 2019), DOI 10.1109/icicos48119.2019.8982471
   Huard M., 2015, Advances in Architectural Geometry 2014, P2
   Jansen Y., 2013, P SIGCHI C HUMAN FAC, DOI [10.1145/2470654, DOI 10.1145/2470654.24813591,2,3,6,11]
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jiang CG, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459839
   Khan D, 2022, IEEE T VIS COMPUT GR, V28, P1680, DOI 10.1109/TVCG.2020.3016645
   Lin ML, 2023, ACT ADAPT AGING, V47, P348, DOI 10.1080/01924788.2022.2120761
   Liu Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559758
   Liu ZY, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459843
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lo KY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618503
   Loop C.T., 1987, Smooth Subdivision Surfaces Based on Triangles
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Luo LJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366148
   Mekuc MÄ, 2022, COMPUT METH PROG BIO, V223, DOI 10.1016/j.cmpb.2022.106959
   Mekuc MZ, 2020, COMPUT BIOL MED, V119, DOI 10.1016/j.compbiomed.2020.103693
   Moere AV, 2008, IEEE INT CONF INF VI, P469, DOI 10.1109/IV.2008.84
   Nguyen N, 2023, IEEE T VIS COMPUT GR, V29, P4198, DOI 10.1109/TVCG.2022.3186146
   Nguyen N, 2021, IEEE T VIS COMPUT GR, V27, P722, DOI 10.1109/TVCG.2020.3030415
   Nicolaidou I, 2021, PROC EUR CONF GAME, P553, DOI 10.34190/GBL.21.016
   Sequin C. H., 2012, FABR SCULPT TRACK SH, P3
   Singh M., 2010, P ACM SIGGRAPH, DOI [10.1145/1833349.17787832,7, DOI 10.1145/1833349.17787832,7]
   Song P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925876
   Song P, 2015, COMPUT AIDED GEOM D, V35-36, P137, DOI 10.1016/j.cagd.2015.03.020
   Song P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366147
   Sun T, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766961
   Tang KK, 2019, COMPUT GRAPH FORUM, V38, P291, DOI 10.1111/cgf.13638
   Tosello G, 2019, INT J ADV MANUF TECH, V100, P783, DOI 10.1007/s00170-018-2762-7
   Verdine BN, 2014, TRENDS NEUROSCI EDUC, V3, P7, DOI 10.1016/j.tine.2014.02.005
   Viana MP, 2023, NATURE, V613, P345, DOI 10.1038/s41586-022-05563-7
   Vidal V, 2015, COMPUT GRAPH-UK, V47, P16, DOI 10.1016/j.cag.2014.10.004
   Xin SQ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964992
   Yao MJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818064
   Zhao Jack, 2008, P 3 ARTS INT C DIG I, P343, DOI DOI 10.1145/1413634.1413696
   Zimmer H, 2014, IEEE T VIS COMPUT GR, V20, P1461, DOI 10.1109/TVCG.2014.2307885
   Zimmer H, 2014, GRAPH MODELS, V76, P390, DOI 10.1016/j.gmod.2014.03.009
NR 53
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 705
EP 715
DI 10.1109/TVCG.2023.3326595
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500115
PM 37871062
OA hybrid, Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Zafar, A
   Yang, D
   Chen, GN
AF Zafar, Adeel
   Yang, Di
   Chen, Guoning
TI Extract and Characterize Hairpin Vortices in Turbulent Flows
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Turbulent flow; vortices; hairpin vortex extraction
ID OF-THE-ART; IDENTIFICATION; VISUALIZATION; DYNAMICS; TRACKING; FIELDS
AB Hairpin vortices are one of the most important vortical structures in turbulent flows. Extracting and characterizing hairpin vortices provides useful insight into many behaviors in turbulent flows. However, hairpin vortices have complex configurations and might be entangled with other vortices, making their extraction difficult. In this work, we introduce a framework to extract and separate hairpin vortices in shear driven turbulent flows for their study. Our method first extracts general vortical regions with a region-growing strategy based on certain vortex criteria (e.g., $\lambda_{2}$) and then separates those vortices with the help of progressive extraction of ($\lambda_{2}$) iso-surfaces in a top-down fashion. This leads to a hierarchical tree representing the spatial proximity and merging relation of vortices. After separating individual vortices, their shape and orientation information is extracted. Candidate hairpin vortices are identified based on their shape and orientation information as well as their physical characteristics. An interactive visualization system is developed to aid the exploration, classification, and analysis of hairpin vortices based on their geometric and physical attributes. We also present additional use cases of the proposed system for the analysis and study of general vortices in other types of flows.
C1 [Zafar, Adeel; Yang, Di; Chen, Guoning] Univ Houston, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Zafar, A (corresponding author), Univ Houston, Houston, TX 77004 USA.
EM azafar3@uh.edu; diyang@uh.edu; gchen16@uh.edu
RI Yang, Di/A-6858-2012
OI Chen, Guoning/0000-0003-0581-6415
FU NSF OAC
FX No Statement Available
CR Adrian RJ, 2007, PHYS FLUIDS, V19, DOI 10.1063/1.2717527
   Bai X, 2019, IEEE ACCESS, V7, P106336, DOI 10.1109/ACCESS.2019.2931781
   Banks D. C., 1994, Proceedings. Visualization '94 (Cat. No.94CH35707), P132, DOI 10.1109/VISUAL.1994.346327
   Berenjkoub M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P261, DOI 10.1109/VIS47514.2020.00059
   Berenjkoub M, 2019, IEEE T VIS COMPUT GR, V25, P1246, DOI 10.1109/TVCG.2018.2864817
   Bremer PT, 2016, COMM APP MATH COM SC, V11, P37, DOI 10.2140/camcos.2016.11.37
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Chakraborty P, 2005, J FLUID MECH, V535, P189, DOI 10.1017/S0022112005004726
   CHONG MS, 1990, PHYS FLUIDS A-FLUID, V2, P765, DOI 10.1063/1.857730
   Deng L, 2019, J VISUAL-JAPAN, V22, P65, DOI 10.1007/s12650-018-0523-1
   Ester M., 1996, P KDD, P226
   FIELD DA, 1988, COMMUN APPL NUMER M, V4, P709, DOI 10.1002/cnm.1630040603
   Franz K, 2018, INT GEOSCI REMOTE SE, P6887, DOI 10.1109/IGARSS.2018.8519261
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Hadwiger M, 2019, IEEE T VIS COMPUT GR, V25, P1257, DOI 10.1109/TVCG.2018.2864839
   Haller G, 2005, J FLUID MECH, V525, P1, DOI 10.1017/S0022112004002526
   Haller G, 2016, J FLUID MECH, V795, P136, DOI 10.1017/jfm.2016.151
   Haller G, 2015, ANNU REV FLUID MECH, V47, P137, DOI 10.1146/annurev-fluid-010313-141322
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hunt J.C., 1988, Studying Turbulence Using Numerical Simulation Databases, P2
   HUNT JCR, 1987, T CAN SOC MECH ENG, V11, P21, DOI 10.1139/tcsme-1987-0004
   JEONG J, 1995, J FLUID MECH, V285, P69, DOI 10.1017/S0022112095000462
   Kim B, 2019, COMPUT GRAPH FORUM, V38, P285, DOI 10.1111/cgf.13689
   KIM J, 1987, J FLUID MECH, V177, P133, DOI 10.1017/S0022112087000892
   Lguensat R, 2018, INT GEOSCI REMOTE SE, P1764, DOI 10.1109/IGARSS.2018.8518411
   Li M, 2019, PHYS FLUIDS, V31, DOI 10.1063/1.5099650
   Lugt H. J., 1979, Recent developments in theoretical and experimental fluid mechanics. Compressible and incompressible flows, P309
   Michalak LP, 2018, TOPOL METHOD NONL AN, V52, P749, DOI 10.12775/TMNA.2018.029
   Nguyen DB, 2023, IEEE T VIS COMPUT GR, V29, P1531, DOI 10.1109/TVCG.2021.3124729
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nguyen DB, 2021, COMPUT GRAPH FORUM, V40, P22, DOI 10.1111/cgf.14093
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P719, DOI 10.1109/TVCG.2019.2934367
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P3147, DOI 10.1109/TVCG.2019.2920157
   OKUBO A, 1970, DEEP-SEA RES, V17, P445, DOI 10.1016/0011-7471(70)90059-8
   Peikert R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P263, DOI 10.1109/VISUAL.1999.809896
   Pobitzer A, 2011, COMPUT GRAPH FORUM, V30, P1789, DOI 10.1111/j.1467-8659.2011.01901.x
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   ROBINSON SK, 1991, ANNU REV FLUID MECH, V23, P601, DOI 10.1146/annurev.fluid.23.1.601
   Rojo IB, 2020, IEEE T VIS COMPUT GR, V26, P280, DOI 10.1109/TVCG.2019.2934375
   Sadarjoen IA, 2000, COMPUT GRAPH-UK, V24, P333, DOI 10.1016/S0097-8493(00)00029-7
   Salzbrunn T, 2008, VISUAL COMPUT, V24, P1039, DOI 10.1007/s00371-007-0204-x
   Salzbrunn T, 2006, IEEE T VIS COMPUT GR, V12, P1601, DOI 10.1109/TVCG.2006.104
   Schneider D, 2008, IEEE T VIS COMPUT GR, V14, P1475, DOI 10.1109/TVCG.2008.143
   Sujudi D., 1995, 12 COMPUTATIONAL FLU, P1715, DOI [10.2514/6.1995-17151, DOI 10.2514/6.1995-17151]
   Tagliasacchi A, 2012, COMPUT GRAPH FORUM, V31, P1735, DOI 10.1111/j.1467-8659.2012.03178.x
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   Wang YQ, 2021, VISUAL COMPUT, V37, P261, DOI 10.1007/s00371-020-01797-6
   Weinkauf T, 2007, IEEE T VIS COMPUT GR, V13, P1759, DOI 10.1109/TVCG.2007.70545
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   WEISS J, 1991, PHYSICA D, V48, P273, DOI 10.1016/0167-2789(91)90088-Q
   Wiebel A, 2011, MATH VIS, P193
   Wu J.-Z., 2006, Vorticity and Vortex Dynamics, P519, DOI [10.1007/978-3-540-29028-5_10, DOI 10.1007/978-3-540-29028-5_10]
   Zafar A., IEEE VISUALIZATION 2, V5, P7
NR 55
TC 1
Z9 1
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 716
EP 726
DI 10.1109/TVCG.2023.3326603
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500128
PM 37874728
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hnatyshyn, R
   Zhao, JQ
   Perez, D
   Ahrens, J
   Maciejewski, R
AF Hnatyshyn, Rostyslav
   Zhao, Jieqiong
   Perez, Danny
   Ahrens, James
   Maciejewski, Ross
TI MolSieve: A Progressive Visual Analytics System for Molecular Dynamics
   Simulations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trajectory; Analytical models; Biological system modeling; Visual
   analytics; Three-dimensional displays; Computational modeling; Data
   models; Molecular dynamics; time-series analysis; visual analytics
ID VISUALIZATION
AB Molecular Dynamics (MD) simulations are ubiquitous in cutting-edge physio-chemical research. They provide critical insights into how a physical system evolves over time given a model of interatomic interactions. Understanding a system's evolution is key to selecting the best candidates for new drugs, materials for manufacturing, and countless other practical applications. With today's technology, these simulations can encompass millions of unit transitions between discrete molecular structures, spanning up to several milliseconds of real time. Attempting to perform a brute-force analysis with data-sets of this size is not only computationally impractical, but would not shed light on the physically-relevant features of the data. Moreover, there is a need to analyze simulation ensembles in order to compare similar processes in differing environments. These problems call for an approach that is analytically transparent, computationally efficient, and flexible enough to handle the variety found in materials-based research. In order to address these problems, we introduce MolSieve, a progressive visual analytics system that enables the comparison of multiple long-duration simulations. Using MolSieve, analysts are able to quickly identify and compare regions of interest within immense simulations through its combination of control charts, data-reduction techniques, and highly informative visual components. A simple programming interface is provided which allows experts to fit MolSieve to their needs. To demonstrate the efficacy of our approach, we present two case studies of MolSieve and report on findings from domain collaborators.
C1 [Hnatyshyn, Rostyslav; Zhao, Jieqiong; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Perez, Danny; Ahrens, James] Los Alamos Natl Lab, Los Alamos, NM USA.
C3 Arizona State University; Arizona State University-Tempe; United States
   Department of Energy (DOE); Los Alamos National Laboratory
RP Hnatyshyn, R (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM rhnatysh@asu.edu; jzhao@asu.edu; danny_perez@lanl.gov; ahrens@lanl.gov;
   rmacieje@asu.edu
RI Perez, Danny/AEQ-0157-2022; Zhao, Jieqiong/HLH-8586-2023
OI Zhao, Jieqiong/0000-0002-4303-7722
FU Exascale Computing Project
FX No Statement Available
CR Ackland GJ, 2006, PHYS REV B, V73, DOI 10.1103/PhysRevB.73.054104
   Aigner W, 2007, COMPUT GRAPH-UK, V31, P401, DOI 10.1016/j.cag.2007.01.030
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Arias-Hernandez R., 2011, PROC HAWAII INT CONF, DOI DOI 10.1109/HICSS.2011.3397
   BEKKER H, 1993, PHYSICS COMPUTING '92, P252
   Bostock M., 2011, D3
   Brehm M, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0005078
   Byska J, 2019, COMPUT GRAPH FORUM, V38, P441, DOI 10.1111/cgf.13701
   Chae J, 2019, IEEE INT CONF BIG DA, P1759, DOI 10.1109/BigData47090.2019.9006048
   Deuflhard P, 2005, LINEAR ALGEBRA APPL, V398, P161, DOI 10.1016/j.laa.2004.10.026
   Dreher M, 2014, FARADAY DISCUSS, V169, P119, DOI 10.1039/c3fd00142c
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   FastAPI, 2019, About us
   Fekete J.-D., 2019, Dagstuhl Reports, V8, DOI DOI 10.4230/DAGREP.8.10.14
   Furnas G. W., 2006, Conference on Human Factors in Computing Systems. CHI2006, P999
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e
   HONEYCUTT JD, 1987, J PHYS CHEM-US, V91, P4950, DOI 10.1021/j100303a014
   Huang R, 2018, PHYS REV MATER, V2, DOI 10.1103/PhysRevMaterials.2.126002
   Huang R, 2017, J CHEM PHYS, V147, DOI 10.1063/1.4996922
   Jnsson H., 1998, CLASS QUANTUM DYN CO, P385, DOI [10.1142/97898128396640016, DOI 10.1142/97898128396640016, DOI 10.1103/PhysRevB.75.035115]
   Jurcik A, 2018, BIOINFORMATICS, V34, P3586, DOI 10.1093/bioinformatics/bty386
   KARPLUS M, 1990, NATURE, V347, P631, DOI 10.1038/347631a0
   Kern M, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad083
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Kühne TD, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0007045
   Larsen PM, 2016, MODEL SIMUL MATER SC, V24, DOI 10.1088/0965-0393/24/5/055007
   LOWRY CA, 1995, IIE TRANS, V27, P800, DOI 10.1080/07408179508936797
   Martinez X, 2020, BIOCHEM SOC T, V48, P499, DOI 10.1042/BST20190621
   Massobrio C, 2015, SPRINGER SER MATER S, V215, P1, DOI 10.1007/978-3-319-15675-0
   Misra P. K., 2012, Physics of Condensed Matter, P567, DOI DOI 10.1016/B978-0-12-384954-0.00017-7
   Perez D, 2016, J CHEM THEORY COMPUT, V12, P18, DOI 10.1021/acs.jctc.5b00916
   Perez D, 2015, COMP MATER SCI, V100, P90, DOI 10.1016/j.commatsci.2014.12.011
   Perez D, 2009, ANN REP COMP CHEM, V5, P79, DOI 10.1016/S1574-1400(09)00504-0
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   React, 2019, About us
   Redona S., 2016, SAMSON: Software for adaptive modeling and simulation of nanosystems
   Redux, 2019, About us
   Reuter B, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5064530
   Schatz K, 2019, EUR PHYS J-SPEC TOP, V227, P1725, DOI 10.1140/epjst/e2019-800162-y
   Scheurer M, 2018, BIOPHYS J, V114, P577, DOI 10.1016/j.bpj.2017.12.003
   Shalloway D, 1996, J CHEM PHYS, V105, P9986, DOI 10.1063/1.472830
   Shewhart W. A., 1986, Statistical Method from the Viewpoint of Quality Control, P5
   Skanberg R., 2018, P EG WORKSH MOL GRAP, P19, DOI [10.2312/molva.20181102, DOI 10.2312/MOLVA.20181102]
   Stukowski A, 2010, MODEL SIMUL MATER SC, V18, DOI 10.1088/0965-0393/18/1/015012
   Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171
   Tian Z, 2023, METALS-BASEL, V13, DOI 10.3390/met13020415
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Ulbrich P, 2023, IEEE T VIS COMPUT GR, V29, P581, DOI 10.1109/TVCG.2022.3209411
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wickham H., 2011, Technical report, P5
   Wu GQ, 2022, J VISUAL-JAPAN, V25, P31, DOI 10.1007/s12650-021-00769-9
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   ZOU PF, 1994, ACTA CRYSTALLOGR A, V50, P714, DOI 10.1107/S0108767394003740
NR 54
TC 1
Z9 1
U1 4
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 727
EP 737
DI 10.1109/TVCG.2023.3326584
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500111
PM 37938968
OA Green Submitted
DA 2024-11-06
ER

PT J
AU de Souza, CVF
   Bonnet, SM
   de Oliveira, D
   Cataldi, M
   Miranda, F
   Lage, M
AF de Souza, Carolina Veiga Ferreira
   Bonnet, Suzanna Maria
   de Oliveira, Daniel
   Cataldi, Marcio
   Miranda, Fabio
   Lage, Marcos
TI PROWIS: A Visual Approach for Building, Managing, and Analyzing Weather
   Simulation Ensembles at Runtime
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Meteorology; Data visualization; Weather forecasting; Visualization;
   Atmospheric modeling; Runtime; Predictive models; Weather visualization;
   Ensemble visualization; Provenance management; WRF visual setup
ID VISUALIZATION; FLOW; TOOL
AB Weather forecasting is essential for decision-making and is usually performed using numerical modeling. Numerical weather models, in turn, are complex tools that require specialized training and laborious setup and are challenging even for weather experts. Moreover, weather simulations are data-intensive computations and may take hours to days to complete. When the simulation is finished, the experts face challenges analyzing its outputs, a large mass of spatiotemporal and multivariate data. From the simulation setup to the analysis of results, working with weather simulations involves several manual and error-prone steps. The complexity of the problem increases exponentially when the experts must deal with ensembles of simulations, a frequent task in their daily duties. To tackle these challenges, we propose ProWis: an interactive and provenance-oriented system to help weather experts build, manage, and analyze simulation ensembles at runtime. Our system follows a human-in-the-loop approach to enable the exploration of multiple atmospheric variables and weather scenarios. ProWis was built in close collaboration with weather experts, and we demonstrate its effectiveness by presenting two case studies of rainfall events in Brazil.
C1 [de Souza, Carolina Veiga Ferreira; de Oliveira, Daniel; Cataldi, Marcio; Lage, Marcos] Univ Fed Fluminense, Niteroi, Brazil.
   [de Souza, Carolina Veiga Ferreira] Univ Illinois, Champaign, IL USA.
   [Bonnet, Suzanna Maria] Univ Fed Rio De Janeiro, Rio De Janeiro, Brazil.
   [Miranda, Fabio] Univ Illinois, Chicago, IL USA.
C3 Universidade Federal Fluminense; University of Illinois System;
   University of Illinois Urbana-Champaign; Universidade Federal do Rio de
   Janeiro; University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RP de Souza, CVF (corresponding author), Univ Fed Fluminense, Niteroi, Brazil.
EM carolinavfs@id.uff.br; suzanna@lma.ufrj.br; marcio.cataldi@gmail.com;
   fabiom@uic.edu; mlage@ic.uff.br
RI de Oliveira, Daniel/HTS-4782-2023; Cataldi, Marcio/CAA-0217-2022; Lage,
   Marcos/K-4098-2012
OI Miranda, Fabio/0000-0001-8612-5805; Lage, Marcos/0000-0003-3868-8886
FU CNPq
FX No Statement Available
CR Behrens HW, 2018, PROC VLDB ENDOW, V11, P1906, DOI 10.14778/3229863.3236221
   Biswas A, 2017, IEEE T VIS COMPUT GR, V23, P841, DOI 10.1109/TVCG.2016.2598869
   Callahan S.P., 2006, INT C MAN DAT 2005 A, P745, DOI 10.1145/1142473.1142574
   Center for Ocean-Land-Atmosphere Studies, 2021, Grid analysis and display system (GrADS)
   Coen JL, 2013, J APPL METEOROL CLIM, V52, P16, DOI 10.1175/JAMC-D-12-023.1
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Davies T, 2014, Q J ROY METEOR SOC, V140, P185, DOI 10.1002/qj.2127
   de Oliveira D. C., 2019, Synthesis Lectures on Data Management, V14, P1, DOI [DOI 10.2200/S00915ED1V01Y201904DTM0601, 10.2200/S00915ED1V01Y201904DTM0601]
   de Souza CVF, 2022, COMPUT GRAPH-UK, V104, P162, DOI 10.1016/j.cag.2022.01.007
   Diehl A, 2015, COMPUT GRAPH FORUM, V34, P381, DOI 10.1111/cgf.12650
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Grell GA, 2005, ATMOS ENVIRON, V39, P6957, DOI 10.1016/j.atmosenv.2005.04.027
   Koop D., 2018, Encyclopedia of Database Systems, P2
   Li SM, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10090488
   McCreight James, 2021, Zenodo, DOI 10.5281/ZENODO.4479912
   Mizutori M., 2020, Human cost of disasters: an overview of the last 20 years (2000-2019)
   National Oceanic and Atmospheric Administration, 2013, WRF Domain Wizard
   Nikfal A, 2023, ENVIRON MODELL SOFTW, V160, DOI 10.1016/j.envsoft.2022.105591
   NOAA Pacific Marine Environmental Laboratory, 2012, Ferret
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Rautenhaus M, 2015, GEOSCI MODEL DEV, V8, P2329, DOI 10.5194/gmd-8-2329-2015
   Rautenhaus M, 2018, IEEE T VIS COMPUT GR, V24, P3268, DOI 10.1109/TVCG.2017.2779501
   Santos E, 2013, COMPUT SCI ENG, V15, P94, DOI 10.1109/MCSE.2013.15
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   School of Ocean and Earth Science and Technology of the University of Hawaii, 2019, The Generic Mapping Tools (GMT)
   Skamarock W. C., 2005, Technical report, P3
   Stitz H, 2019, IEEE T VIS COMPUT GR, V25, P120, DOI 10.1109/TVCG.2018.2865024
   University Corporation for Atmospheric, 2019, The NCAR command language
   University Corporation for Atmospheric Research, 2019, Definition of network common data form (NetCDF)
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Warner TT., 2010, NUMERICAL WEATHER CL, P1
   Waser J, 2011, IEEE T VIS COMPUT GR, V17, P1872, DOI 10.1109/TVCG.2011.225
   Watanabe K, 2022, SYMP LARG DATA ANAL, P5, DOI 10.1109/LDAV57265.2022.9966393
   Weather Meteorological Organization, 1999, Guide to public weather services practices, P1
   Williams DN, 2013, COMPUTER, V46, P68, DOI 10.1109/MC.2013.119
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
NR 36
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 738
EP 747
DI 10.1109/TVCG.2023.3326514
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500043
PM 37871065
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Troidl, J
   Warchol, S
   Choi, J
   Matelsky, J
   Dhanyasi, N
   Wang, XY
   Wester, B
   Wei, DL
   Lichtman, JW
   Pfister, H
   Beyer, J
AF Troidl, Jakob
   Warchol, Simon
   Choi, Jinhan
   Matelsky, Jordan
   Dhanyasi, Nagaraju
   Wang, Xueying
   Wester, Brock
   Wei, Donglai
   Lichtman, Jeff W.
   Pfister, Hanspeter
   Beyer, Johanna
TI VIMO - Visual Analysis of Neuronal Connectivity Motifs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Neurons; Visualization; Three-dimensional displays; Synapses;
   Morphology; Brain; Rendering (computer graphics); Visual motif analysis;
   Focus&Context; Scientific visualization; Neuroscience; Connectomics
ID EXPLORATION; TOOL
AB Recent advances in high-resolution connectomics provide researchers with access to accurate petascale reconstructions of neuronal circuits and brain networks for the first time. Neuroscientists are analyzing these networks to better understand information processing in the brain. In particular, scientists are interested in identifying specific small network motifs, i.e., repeating subgraphs of the larger brain network that are believed to be neuronal building blocks. Although such motifs are typically small (e.g., 2-6 neurons), the vast data sizes and intricate data complexity present significant challenges to the search and analysis process. To analyze these motifs, it is crucial to review instances of a motif in the brain network and then map the graph structure to detailed 3D reconstructions of the involved neurons and synapses. We present Vimo, an interactive visual approach to analyze neuronal motifs and motif chains in large brain networks. Experts can sketch network motifs intuitively in a visual interface and specify structural properties of the involved neurons and synapses to query large connectomics datasets. Motif instances (MIs) can be explored in high-resolution 3D renderings. To simplify the analysis of MIs, we designed a continuous focus&context metaphor inspired by visual abstractions. This allows users to transition from a highly-detailed rendering of the anatomical structure to views that emphasize the underlying motif structure and synaptic connectivity. Furthermore, Vimo supports the identification of motif chains where a motif is used repeatedly (e.g., 2-4 times) to form a larger network structure. We evaluate Vimo in a user study and an in-depth case study with seven domain experts on motifs in a large connectome of the fruit fly, including more than 21,000 neurons and 20 million synapses. We find that Vimo enables hypothesis generation and confirmation through fast analysis iterations and connectivity highlighting.
C1 [Troidl, Jakob; Warchol, Simon; Pfister, Hanspeter; Beyer, Johanna] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Dhanyasi, Nagaraju; Wang, Xueying; Lichtman, Jeff W.] Harvard Univ, Dept Cellular& Mol Biol, Cambridge, MA USA.
   [Matelsky, Jordan; Wester, Brock] Johns Hopkins Univ, Appl Phys Lab, Baltimore, MD USA.
   [Matelsky, Jordan] Univ Penn, Dept Bioengn, Philadelphia, PA USA.
   [Choi, Jinhan; Wei, Donglai] Boston Coll, Dept Comp Sci, Chestnut Hill, MA USA.
C3 Harvard University; Harvard University; Johns Hopkins University; Johns
   Hopkins University Applied Physics Laboratory; University of
   Pennsylvania; Boston College
RP Troidl, J (corresponding author), Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
EM jakob.troidl@gmail.com; simonwarchol@g.harvard.edu; jinhan.choi@bc.edu;
   Jordan.Matelsky@jhuapl.edu; nagarajudhanyasi@gmail.com;
   snowsd@gmail.com; brock.wester@jhuapl.edu; donglai.wei@bc.edu;
   jeff@mcb.harvard.edu; pfister@g.harvard.edu; jbeyer@g.harvard.edu
RI Wang, Xueying/J-5350-2019
OI Pfister, Hanspeter/0000-0002-3620-2582; Warchol,
   Simon/0000-0001-9067-6888
FU NSF
FX No Statement Available
CR Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   [Anonymous], 2010, P 18 ACM INT C MULT, DOI 10.1145/1873951.1874299
   Bae J. Alexander, 2021, bioRxiv, P2021
   Beyer J, 2022, COMPUT GRAPH FORUM, V41, P573, DOI 10.1111/cgf.14574
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Buhl E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80103-9
   Cakmak E., 2022, arXiv
   Choi J., 2023, Neuprint Motif Analysis Integration
   Choi J., 2023, Vimo sketches codebase, DOI VCG/vimo-sketches2,8
   Choi J, 2021, INT WOUND J, V18, P647, DOI 10.1111/iwj.13566
   Cook S. A., 1971, Proceedings of the 3rd annual ACM symposium on theory of computing, P151
   Cuenca E, 2022, IEEE T VIS COMPUT GR, V28, P1634, DOI 10.1109/TVCG.2021.3067820
   Dorkenwald S., 2023, Neuronal wiring diagram of an adult brain, DOI [10.1101/2023.06.27.5466561, DOI 10.1101/2023.06.27.5466561]
   Dorkenwald Sven, 2023, bioRxiv, DOI 10.1101/2023.07.26.550598
   Dorkenwald S, 2022, NAT METHODS, V19, P119, DOI 10.1038/s41592-021-01330-0
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Egenhofer MJ, 1997, J VISUAL LANG COMPUT, V8, P403, DOI 10.1006/jvlc.1997.0054
   Francis N, 2018, INT CONF MANAGE DATA, P1433, DOI 10.1145/3183713.3190657
   Galili DS, 2022, CURR OPIN INSECT SCI, V54, DOI 10.1016/j.cois.2022.100968
   Ganglberger F, 2022, COMPUT GRAPH-UK, V105, P12, DOI 10.1016/j.cag.2022.04.014
   Gonda F, 2021, COMPUT GRAPH FORUM, V40, P447, DOI 10.1111/cgf.14320
   Haber A., 2023, Neuroscience, DOI [10.1101/2023.03.15.5326111, DOI 10.1101/2023.03.15.5326111]
   Harth P., 2022, EUR WORKSH VIS COMP, DOI [10.2312/vcbm.202211942, DOI 10.2312/VCBM.202211942]
   Hu P, 2023, IEEE T PATTERN ANAL, V45, P3877, DOI 10.1109/TPAMI.2022.3177356
   Hulse BK, 2021, ELIFE, V10, DOI 10.7554/eLife.66039
   Itzkovitz S, 2003, PHYS REV E, V68, DOI 10.1103/PhysRevE.68.026127
   Kashani ZRM, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-318
   Li F, 2020, ELIFE, V9, DOI 10.7554/eLife.62576
   Lin A., 2023, Network Statistics of the WholeBrain Connectome of Drosophila, DOI [10.1101/2023., DOI 10.1101/2023]
   Maitin-Shepard J., 2023, FlyEM Neuroglancer Rendering
   Maitin-Shepard Jeremy, 2021, Zenodo
   Mannino M, 2018, INT CONF MANAGE DATA, P1741, DOI 10.1145/3183713.3193547
   Matejek B, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-15027-7
   Matelsky JK, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-91025-5
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Pienta R, 2018, IEEE T VIS COMPUT GR, V24, P215, DOI 10.1109/TVCG.2017.2744898
   Plaza SM, 2022, FRONT NEUROINFORM, V16, DOI 10.3389/fninf.2022.896292
   Ribeiro P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3433652
   Bolívar MPR, 2015, PUB ADMIN INF TECH, V8, P1, DOI 10.1007/978-3-319-03167-5_1
   Saalfeld S, 2009, BIOINFORMATICS, V25, P1984, DOI 10.1093/bioinformatics/btp266
   Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331
   Scheffer L. K., 2020, Available Brain regions in the hemibrain dataset
   Scheffer LK, 2020, ELIFE, V9, DOI 10.7554/eLife.57443
   Schlegel P, 2021, ELIFE, V10, DOI 10.7554/eLife.66018
   Schlegel Philipp, 2021, Zenodo, DOI 10.5281/ZENODO.5710143
   Schneider-Mizell Casey M, 2024, bioRxiv, DOI 10.1101/2023.01.23.525290
   Schreiber F, 2005, BIOINFORMATICS, V21, P3572, DOI 10.1093/bioinformatics/bti556
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shapson-Coe A, 2021, bioRxiv, DOI [10.1101/2021.05.29.446289, 10.1101/2021.05.29.446289, DOI 10.1101/2021.05.29.446289, 10.1101/2021.05.29.446289v4, DOI 10.1101/2021.05.29.446289V4]
   Sorger J, 2013, 2013 IEEE SYMPOSIUM ON BIOLOGICAL DATA VISUALIZATION (BIOVIS), P73, DOI 10.1109/BioVis.2013.6664349
   Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369
   Steinberger M, 2011, IEEE T VIS COMPUT GR, V17, P2249, DOI 10.1109/TVCG.2011.183
   Takemura S.-y., 2023, Neuroscience, DOI [10.1101/2023.06.05.543757, DOI 10.1101/2023.06.05.543757]
   Troidl J., 2023, Vimo Example Motifs Sketches, DOI jakobtroidl/neuronal-motifs/tree/main/example_motifs5,8,9
   Troidl J., 2023, Vimo Codebase
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Turner NL, 2022, CELL, V185, P1082, DOI 10.1016/j.cell.2022.01.023
   Udvary D, 2022, CELL REP, V39, DOI 10.1016/j.celrep.2022.110677
   Vohra S. K., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32436682, DOI 10.1109/TVCG.2023.32436682]
   Weaver Charlotte, 2014, Zenodo, DOI 10.5281/ZENODO.11290
   Winding M, 2023, SCIENCE, V379, P995, DOI 10.1126/science.add9330
NR 62
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 748
EP 758
DI 10.1109/TVCG.2023.3327388
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500039
PM 37883279
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Straub, A
   Karadimitriou, N
   Reina, G
   Frey, S
   Steeb, H
   Ertl, T
AF Straub, Alexander
   Karadimitriou, Nikolaos
   Reina, Guido
   Frey, Steffen
   Steeb, Holger
   Ertl, Thomas
TI Visual Analysis of Displacement Processes in Porous Media using
   Spatio-Temporal Flow Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Comparative visualization; ensemble; graph; porous media
ID 2-PHASE FLOW; VISUALIZATION; EXPLORATION; MICROMODEL; TRANSPORT;
   FRAMEWORK
AB We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.
C1 [Straub, Alexander; Karadimitriou, Nikolaos; Reina, Guido; Steeb, Holger; Ertl, Thomas] Univ Stuttgart, Stuttgart, Germany.
   [Frey, Steffen] Univ Groningen, Groningen, Netherlands.
C3 University of Stuttgart; University of Groningen
RP Straub, A (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM alexander.straub@visus.uni-stuttgart.de;
   nikos.karadimitriou@mechbau.uni-stuttgart.de;
   guido.reina@visus.uni-stuttgart.de; s.d.frey@rug.nl;
   holger.steeb@mechbau.uni-stuttgart.de; thomas.ertl@vis.uni-stuttgart.de
RI Steeb, Holger/AAE-4537-2020; Steeb, Holger/E-2572-2011
OI Reina, Guido/0000-0003-4127-1897; Steeb, Holger/0000-0001-7602-4920;
   Straub, Alexander/0000-0002-6749-9710; Frey, Steffen/0000-0002-1872-6905
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Aboulhassan A, 2015, COMPUT GRAPH FORUM, V34, P401, DOI 10.1111/cgf.12652
   Alzahid Y., 2017, SPE EUROPEC FEATURED, DOI DOI 10.2118/185832-MS1
   Andrew M, 2013, GEOPHYS RES LETT, V40, P3915, DOI 10.1002/grl.50771
   Andrews K, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P62, DOI 10.1109/IV.2009.108
   Armstrong RT, 2019, TRANSPORT POROUS MED, V130, P305, DOI 10.1007/s11242-018-1201-4
   Bartels W.-B., 2016, INT S SOC CORE ANALY
   Berg S, 2013, P NATL ACAD SCI USA, V110, P3755, DOI 10.1073/pnas.1221373110
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Chen YQ, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abj0960
   Cheng JT, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2003GL019282
   Corapcioglu MY, 1997, WATER RESOUR RES, V33, P2547, DOI 10.1029/97WR02115
   Darcy H., 1857, Impr. Imperiale, P2
   de Winter DAM, 2021, TRANSPORT POROUS MED, V136, P343, DOI 10.1007/s11242-020-01515-9
   Eulzer P, 2021, COMPUT GRAPH FORUM, V40, P435, DOI 10.1111/cgf.14319
   Favelier G., 2016, IEEE SCI VISUALIZATI, P2
   Frey S, 2022, COMPUT GRAPH FORUM, V41, P243, DOI 10.1111/cgf.14432
   Geveci B., 2016, Scientific visualization contest
   Gralka P., 2016, IEEE Computer Graphics and Applications, V38, P106
   GROSSER K, 1988, AICHE J, V34, P1850, DOI 10.1002/aic.690341111
   Grottel S., 2010, P SIGRAD 2010 CONTEN, P45
   Grottel S, 2015, IEEE T VIS COMPUT GR, V21, P201, DOI 10.1109/TVCG.2014.2350479
   Hao LH, 2016, IEEE T VIS COMPUT GR, V22, P787, DOI 10.1109/TVCG.2015.2468093
   Hasan S, 2020, P NATL ACAD SCI USA, V117, P23443, DOI 10.1073/pnas.2011716117
   HASSANIZADEH SM, 1993, WATER RESOUR RES, V29, P3389, DOI 10.1029/93WR01495
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P1716, DOI 10.1109/TVCG.2018.2879866
   Heinzl C, 2017, COMPUT GRAPH FORUM, V36, P647, DOI 10.1111/cgf.13214
   Hu Y., 2006, The Mathematica Journal, V10, P6
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Karadimitriou N., 2023, Visual characterization of displacement processes in porous media, DOI [10.18419/darus-36156, DOI 10.18419/DARUS-36156]
   Karadimitriou NK, 2014, WATER RESOUR RES, V50, P8125, DOI 10.1002/2014WR015388
   Karadimitriou NK, 2012, VADOSE ZONE J, V11, DOI 10.2136/vzj2011.0072
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kettle J, 2010, SURF COAT TECH, V204, P2103, DOI 10.1016/j.surfcoat.2009.10.035
   Khan FI, 2004, J ENVIRON MANAGE, V71, P95, DOI 10.1016/j.jenvman.2004.02.003
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Kurzeja PS, 2014, PHYS FLUIDS, V26, DOI 10.1063/1.4871489
   LENORMAND R, 1988, J FLUID MECH, V189, P165, DOI 10.1017/S0022112088000953
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Mattax C. C., 1961, Oil Gas Journal, V59, P2
   Naumov D, 2014, ENVIRON EARTH SCI, V72, P3795, DOI 10.1007/s12665-014-3445-9
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schlüter S, 2016, WATER RESOUR RES, V52, P2194, DOI 10.1002/2015WR018254
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Shaw H. S. H., 1898, Inst. N.A., P2
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   THOMPSON LF, 1983, ACS SYM SER, V219, P1
   Ushizima DM, 2012, IEEE T VIS COMPUT GR, V18, P2041, DOI 10.1109/TVCG.2012.200
   VANGENUCHTEN MT, 1980, SOIL SCI SOC AM J, V44, P892, DOI 10.2136/sssaj1980.03615995004400050002x
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Waser J, 2010, IEEE T VIS COMPUT GR, V16, P1458, DOI 10.1109/TVCG.2010.223
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
   Wills P, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228728
   Wilson RC, 2008, PATTERN RECOGN, V41, P2833, DOI 10.1016/j.patcog.2008.03.011
   Xia YN, 1998, ANNU REV MATER SCI, V28, P153, DOI 10.1146/annurev.matsci.28.1.153
   Xu JY, 2022, IEEE T VIS COMPUT GR, V28, P1514, DOI 10.1109/TVCG.2020.3017568
   Yiotis A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83065-8
   Zhang H, 2019, IEEE T VIS COMPUT GR, V25, P1060, DOI 10.1109/TVCG.2018.2864506
NR 61
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 759
EP 769
DI 10.1109/TVCG.2023.3326931
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500137
PM 37878453
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Jeon, H
   Quadri, GJ
   Lee, H
   Rosen, P
   Szafir, DA
   Seo, J
AF Jeon, Hyeon
   Quadri, Ghulam Jilani
   Lee, Hyunwook
   Rosen, Paul
   Szafir, Danielle Albers
   Seo, Jinwook
TI : A Cluster Ambiguity Measure for Estimating Perceptual Variability in
   Visual Clustering&lt;italic/&gt;
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Task analysis; Reliability; Benchmark testing; Data
   analysis; Complexity theory; Clustering algorithms; Cluster;
   scatterplot; perception; cluster analysis; cluster ambiguity; visual
   quality measure
ID INDIVIDUAL-DIFFERENCES; DIMENSIONALITY REDUCTION; QUALITY METRICS;
   VISUALIZATION; GOODNESS; FIT
AB Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates the human-judged separability of two clusters. Then, CLAMS predicts cluster ambiguity by analyzing the aggregated results of all pairwise separability between clusters that are generated by the module. CLAMS outperforms widely-used clustering techniques in predicting ground truth cluster ambiguity. Meanwhile, CLAMS exhibits performance on par with human annotators. We conclude our work by presenting two applications for optimizing and benchmarking data mining techniques using CLAMS. The interactive demo of CLAMS is available at clusterambiguity.dev.
C1 [Jeon, Hyeon; Seo, Jinwook] Seoul Natl Univ, Seoul, South Korea.
   [Quadri, Ghulam Jilani; Szafir, Danielle Albers] Univ N Carolina, Chapel Hill, NC USA.
   [Lee, Hyunwook] UNIST, Ulsan, South Korea.
   [Rosen, Paul] Univ Utah, Salt Lake City, UT USA.
C3 Seoul National University (SNU); University of North Carolina;
   University of North Carolina Chapel Hill; Ulsan National Institute of
   Science & Technology (UNIST); Utah System of Higher Education;
   University of Utah
RP Jeon, H (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM hj@hcil.snu.ac.kr; jiquad@cs.unc.edu; gusdnr0916@unist.ac.kr;
   prosen@sci.utah.edu; danielle.szafir@cs.unc.edu; jseo@snu.ac.kr
RI Rosen, Paul/GXM-8609-2022
FU NAVER Corporation (Cloud Data Box)
FX No Statement Available
CR Abbas M., 2021, Clustrank: a visual quality measure trained on perceptual data for sorting scatterplots by cluster patterns
   Abbas MM, 2019, COMPUT GRAPH FORUM, V38, P225, DOI 10.1111/cgf.13684
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Ashby FG, 1993, Advances in Psychology, V99, P369, DOI [10.1016/S0166-4115(08)62778-82, DOI 10.1016/S0166-4115(08)62778-82, DOI 10.1016/S0166-4115(08)62778-8, 10.1016/S0166-4115(08)62778-8]
   Aupetit M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P141, DOI [10.1109/visual.2019.8933620, 10.1109/VISUAL.2019.8933620]
   Aupetit M, 2016, IEEE PAC VIS SYMP, P1, DOI 10.1109/PACIFICVIS.2016.7465244
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Bertini E, 2011, IEEE T VIS COMPUT GR, V17, P2203, DOI 10.1109/TVCG.2011.229
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Calinski T., 1974, Commun. Stat. Theory Methods, V3, P1, DOI 10.1080/03610927408827101
   Cameron AC, 1997, J ECONOMETRICS, V77, P329
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Davis R., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.32264632
   Desjardins M, 2007, 2007 INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P361
   Dillon A, 1996, INT J HUM-COMPUT ST, V45, P619, DOI 10.1006/ijhc.1996.0071
   Etemadpour Ronak, 2014, 5th International Conference on Information Visualization Theory and Applications (IVAPP 2014). Proceedings, P233
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   Feurer M, 2019, SPRING SER CHALLENGE, P113, DOI 10.1007/978-3-030-05318-5_6
   Fu C, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P176, DOI 10.1145/3292500.3330834
   Fujiwara T, 2022, Arxiv, DOI arXiv:2206.13891
   GOODMAN LA, 1961, ANN MATH STAT, V32, P148, DOI 10.1214/aoms/1177705148
   Halkidi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P187, DOI 10.1109/ICDM.2001.989517
   Hartwig S, 2024, Arxiv, DOI arXiv:2304.14185
   He X, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106622
   Hoskin R, 2019, COGNITION, V182, P127, DOI 10.1016/j.cognition.2018.08.022
   Huang J, 2010, J VISION, V10, DOI 10.1167/10.2.24
   Jeon H., 2022, arXiv
   Jeon H., 2022, arXiv
   Jeon H, 2022, IEEE VIS CONF, P80, DOI 10.1109/VIS54862.2022.00025
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lee J., 2007, Nonlinear Dimensionality Reduction, DOI [10.1007/978-0-387-39351-3 7, DOI 10.1007/978-0-387-39351-37]
   Lee JA, 2007, INFORM SCI STAT, P1, DOI 10.1007/978-0-387-39351-3
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Liu R, 2018, INFORM SCIENCES, V450, P200, DOI 10.1016/j.ins.2018.03.031
   Liu Y, 2010, 2010 IEEE International Conference on Data Mining, P911, DOI [DOI 10.1109/ICDM.2010.35, 10.1109/ICDM.2010.35]
   Liu ZL, 2020, COMPUT GRAPH FORUM, V39, P693, DOI 10.1111/cgf.14033
   Lu M, 2020, IEEE T VIS COMPUT GR, V26, P770, DOI 10.1109/TVCG.2019.2934811
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   MAASSEN H, 1988, PHYS REV LETT, V60, P1103, DOI 10.1103/PhysRevLett.60.1103
   McInnes L., 2020, Umap: Uniform manifold approximation and projection for dimension reduction, V6, P7
   McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12
   Milllner D., 2011, arXiv preprint, V8, P9
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narayan A, 2021, NAT BIOTECHNOL, V39, P765, DOI 10.1038/s41587-020-00801-7
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Ons B, 2011, J EXP PSYCHOL HUMAN, V37, P422, DOI 10.1037/a0020405
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pelleg D., 2000, ICML, P727
   Pinna B., 2010, GESTALT THEORY, P11
   Prion S, 2014, CLIN SIMUL NURS, V10, P535, DOI 10.1016/j.ecns.2014.07.005
   Quadri G. J., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.31898832
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Rezaei M, 2016, IEEE T KNOWL DATA EN, V28, P2173, DOI 10.1109/TKDE.2016.2551240
   Rosenberg A., 2007, PROC PROC JOINT C EM, P410
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sadahiro Y., 1997, Cartographica: The International Journal for Geographic Information and Geovisualization, V34, P49, DOI DOI 10.3138/Y308-2422-8615-1233
   Sanchez-Rico M., 2020, EUROPEAN C METHODOLO
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Shannon W, 2003, PHARMACOGENOMICS, V4, P41, DOI 10.1517/phgs.4.1.41.22581
   Shi JL, 2010, COMPUT BIOL MED, V40, P723, DOI 10.1016/j.compbiomed.2010.06.007
   Snoek J., 2012, Advances in Neural Information Processing Systems, V25, P8
   Steinley D, 2004, PSYCHOL METHODS, V9, P386, DOI 10.1037/1082-989X.9.3.386
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Dang TN, 2014, IEEE T VIS COMPUT GR, V20, P1624, DOI 10.1109/TVCG.2014.2346572
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2006, NEURAL NETWORKS, V19, P889, DOI 10.1016/j.neunet.2006.05.014
   Vinh NX, 2010, J MACH LEARN RES, V11, P2837
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P820, DOI 10.1109/TVCG.2018.2864912
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Woolhouse LS, 2000, EUR J PERSONALITY, V14, P157, DOI 10.1002/(SICI)1099-0984(200003/04)14:2<157::AID-PER366>3.0.CO;2-L
   Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xiong H, 2014, CH CRC DATA MIN KNOW, P571
   Zaman J, 2021, PSYCHON B REV, V28, P1, DOI 10.3758/s13423-020-01780-1
   Zhang T., 1996, ACM SIGMOD RECORD, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Ziemkiewicz C, 2009, COMPUT GRAPH FORUM, V28, P911, DOI 10.1111/j.1467-8659.2009.01442.x
NR 86
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 770
EP 780
DI 10.1109/TVCG.2023.3327201
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500012
OA hybrid
DA 2024-11-06
ER

PT J
AU Jeon, H
   Kuo, YH
   Aupetit, M
   Ma, KL
   Seo, J
AF Jeon, Hyeon
   Kuo, Yun-Hsin
   Aupetit, Michael
   Ma, Kwan-Liu
   Seo, Jinwook
TI <i>Classes</i><i> are</i><i> not</i><i> Clusters:</i> Improving
   Label-based Evaluation of Dimensionality Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Distortion measurement; Reliability; Dimensionality reduction; Nonlinear
   distortion; Extraterrestrial measurements; Scalability; Degradation;
   Dimensionality Reduction; Clustering; Clustering Validation Measures;
   Dimensionality Reduction Evaluation
ID VISUALIZATION; PERCEPTION; TOPOLOGY; QUALITY
AB A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures-Label-Trustworthiness and Label-Continuity (Label-T&C)-advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative evaluation showed that Label-T&C outperform widely used DR evaluation measures (e.g., Trustworthiness and Continuity, Kullback-Leibler divergence) in terms of the accuracy in assessing how well DR embeddings preserve the cluster structure, and are also scalable. Moreover, we present case studies demonstrating that Label-T&C can be successfully used for revealing the intrinsic characteristics of DR techniques and their hyperparameters.
C1 [Jeon, Hyeon; Seo, Jinwook] Seoul Natl Univ, Seoul, South Korea.
   [Kuo, Yun-Hsin; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA USA.
   [Aupetit, Michael] Hamad Bin Khalifa Univ, Qatar Comp Res Inst, Doha, Qatar.
C3 Seoul National University (SNU); University of California System;
   University of California Davis; Qatar Foundation (QF); Hamad Bin Khalifa
   University-Qatar; Qatar Computing Research Institute
RP Jeon, H (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM hj@hcil.snu.ac.kr; yskuo@ucdavis.edu; maupetit@hbku.edu.qa;
   klma@ucdavis.edu; jseo@snu.ac.kr
OI Kuo, Yun-Hsin/0009-0000-1891-8993; Ma, Kwan-Liu/0000-0001-8086-0366
FU National Research Foundation of Korea (NRF)
FX No Statement Available
CR Angelini M, 2022, IEEE T VIS COMPUT GR, V28, P4770, DOI 10.1109/TVCG.2021.3104879
   Aupetit M, 2005, NEUROCOMPUTING, V63, P139, DOI 10.1016/j.neucom.2004.04.009
   Aupetit M., 2022, arXiv
   Aupetit M., 2014, P BELIV, P134
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Aupetit M, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P70, DOI 10.1109/TopoInVis57755.2022.00014
   Aupetit M, 2014, IEEE CONF VIS ANAL, P221, DOI 10.1109/VAST.2014.7042500
   Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314
   BELLMAN R, 1966, SCIENCE, V153, P34, DOI 10.1126/science.153.3731.34
   Ben-David S., 2008, Advances in Neural Information Processing Systems, V21, DOI [10.5555/2981780.2981796, DOI 10.5555/2981780.2981796]
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Brehmer M., 2014, P 5 WORKSH TIM ERR N, P1, DOI DOI 10.1145/2669557.2669559
   Calinski T., 1974, Commun. Stat. Theory Methods, V3, P1, DOI 10.1080/03610927408827101
   Cao YS, 2017, Arxiv, DOI arXiv:1708.03229
   Chazal F, 2018, J MACH LEARN RES, V18
   Chazal F, 2011, FOUND COMPUT MATH, V11, P733, DOI 10.1007/s10208-011-9098-0
   Colange B., 2020, Advances in Neural Information Processing Systems, V33, P13214, DOI DOI 10.5555/3495724.3496832
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Di Caro L, 2010, LECT NOTES ARTIF INT, V6119, P125
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Etemadpour Ronak, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P51
   Etemadpour R, 2015, IEEE T VIS COMPUT GR, V21, P81, DOI 10.1109/TVCG.2014.2330617
   Fadel SG, 2015, NEUROCOMPUTING, V150, P546, DOI 10.1016/j.neucom.2014.07.071
   Farber I., 2010, MULTICLUST, P1
   François D, 2007, IEEE T KNOWL DATA EN, V19, P873, DOI 10.1109/TKDE.2007.1037
   Fujiwara T, 2022, Arxiv, DOI arXiv:2206.13891
   Heulot N., 2013, EUROVIS WORKSHOP VIS, DOI [10.2312/PE.VAMP.VAMP2013.011-015, DOI 10.2312/PE.VAMP.VAMP2013.011-015]
   Jeon H., 2022, arXiv
   Jeon H, 2022, IEEE VIS CONF, P80, DOI 10.1109/VIS54862.2022.00025
   Jeon H, 2022, Arxiv, DOI arXiv:2209.10042
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Ji ZC, 2021, J AM STAT ASSOC, V116, P471, DOI 10.1080/01621459.2021.1880920
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Lai CH, 2022, IEEE VIS CONF, P75, DOI 10.1109/VIS54862.2022.00024
   Lam SK, 2015, P 2 WORKSH LLVM COMP, DOI [DOI 10.1145/2833157.2833162, 10.1145/2833157.2833162]
   Lee JA, 2007, INFORM SCI STAT, P1, DOI 10.1007/978-0-387-39351-3
   Lee JA, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P163, DOI 10.1109/CIDM.2014.7008663
   Lee JA, 2011, PROCEDIA COMPUT SCI, V4, P538, DOI 10.1016/j.procs.2011.04.056
   Lespinats S, 2007, IEEE T NEURAL NETWOR, V18, P1265, DOI 10.1109/TNN.2007.891682
   Lespinats S, 2011, COMPUT GRAPH FORUM, V30, P113, DOI 10.1111/j.1467-8659.2010.01835.x
   Liu Y, 2010, 2010 IEEE International Conference on Data Mining, P911, DOI [DOI 10.1109/ICDM.2010.35, 10.1109/ICDM.2010.35]
   Liu YC, 2013, IEEE T CYBERNETICS, V43, P982, DOI 10.1109/TSMCB.2012.2220543
   Martins RM, 2014, COMPUT GRAPH-UK, V41, P26, DOI 10.1016/j.cag.2014.01.006
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Moor M., 2020, INT C MACH LEARN, P7045
   Motta R, 2015, NEUROCOMPUTING, V150, P583, DOI 10.1016/j.neucom.2014.09.063
   Narayan A, 2021, NAT BIOTECHNOL, V39, P765, DOI 10.1038/s41587-020-00801-7
   Nene S. A., 1996, Tech. rep. CUCS-005-96
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pezzotti N, 2016, COMPUT GRAPH FORUM, V35, P21, DOI 10.1111/cgf.12878
   Quadri GJ, 2023, IEEE T VIS COMPUT GR, V29, P4312, DOI 10.1109/TVCG.2022.3189883
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2012, COMPUT GRAPH FORUM, V31, P1335, DOI 10.1111/j.1467-8659.2012.03125.x
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J, 2006, NEURAL NETWORKS, V19, P889, DOI 10.1016/j.neunet.2006.05.014
   Venna J, 2010, J MACH LEARN RES, V11, P451
   Vinh N.X., 2009, P 26 ANN INT C MACH, P1073, DOI DOI 10.1145/1553374.1553511
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wattenberg M., 2016, Distill, V1, pe2, DOI DOI 10.23915/DISTILL.00002
   Wenskovitch J, 2018, IEEE T VIS COMPUT GR, V24, P131, DOI 10.1109/TVCG.2017.2745258
   Wu JJ, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P877
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xiang RZ, 2021, FRONT GENET, V12, DOI 10.3389/fgene.2021.646936
   Xiao H, 2017, Arxiv, DOI arXiv:1708.07747
   Yang Y, 2021, CELL REP, V36, DOI 10.1016/j.celrep.2021.109442
   Zubaroglu A., 2020, P 2019 3 INT C BIG D, P142, DOI [10.1145/3372454.3372481, DOI 10.1145/3372454.3372481]
NR 74
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 781
EP 791
DI 10.1109/TVCG.2023.3327187
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500104
PM 37922177
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Giovannangeli, L
   Lalanne, F
   Giot, R
   Bourqui, R
AF Giovannangeli, Loann
   Lalanne, Frederic
   Giot, Romain
   Bourqui, Romain
TI Guaranteed Visibility in Scatterplots with Tolerance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Guaranteed visibility; Layout adjustment; Overlap removal; Scatterplots
ID LAYOUT ADJUSTMENT; OVERLAP REMOVAL; ALGORITHM
AB In 2D visualizations, visibility of every datum's representation is crucial to ease the completion of visual tasks. Such a guarantee is barely respected in complex visualizations, mainly because of overdraws between datum representations that hide parts of the information (e.g., outliers). The literature proposes various Layout Adjustment algorithms to improve the readability of visualizations that suffer from this issue. Manipulating the data in high-dimensional, geometric or visual space; they rely on different strategies with their own strengths and weaknesses. Moreover, most of these algorithms are computationally expensive as they search for an exact solution in the geometric space and do not scale well to large datasets. This article proposes GIST, a layout adjustment algorithm that aims at optimizing three criteria: (i) node visibility guarantee (at least 1 pixel), (ii) node size maximization, and (iii) the original layout preservation. This is achieved by combining a search for the maximum node size that enables to draw all the data points without overlaps, with a limited budget of movements (i.e., limiting the distortions of the original layout). The method's basis relies on the idea that it is not necessary for two data representations to be strictly not overlapping in order to guarantee their visibility in visual space. Our algorithm therefore uses a tolerance in the geometric space to determine the overlaps between pairs of data. The tolerance is optimized such that the approximation computed in the geometric space can lead to visualization without noticeable overdraw after the data rendering rasterization. In addition, such an approximation helps to ease the algorithm's convergence as it reduces the number of constraints to resolve, enabling it to handle large datasets. We demonstrate the effectiveness of our approach by comparing its results to those of state-of-the-art methods on several large datasets.
C1 [Giovannangeli, Loann; Lalanne, Frederic; Giot, Romain; Bourqui, Romain] Univ Bordeaux, LaBRI, CNRS, Bordeaux INP,UMR 5800,INRIA, Talence, France.
C3 Inria; Universite de Bordeaux; Centre National de la Recherche
   Scientifique (CNRS)
RP Giovannangeli, L (corresponding author), Univ Bordeaux, LaBRI, CNRS, Bordeaux INP,UMR 5800,INRIA, Talence, France.
EM loann.giovannangeli@u-bordeaux.fr; frederic.lalanne@u-bordeaux.fr;
   romain.giot@u-bordeaux.fr; romain.bourqui@u-bordeaux.fr
RI Giot, Romain/F-6747-2011
OI Giot, Romain/0000-0002-0638-7504; Giovannangeli,
   Loann/0000-0002-9395-6495
FU ANR
FX No Statement Available
CR Bertini E, 2004, IEEE INFOR VIS, P622, DOI 10.1109/IV.2004.1320207
   Brandes U, 2009, LECT NOTES COMPUT SC, V5417, P218, DOI 10.1007/978-3-642-00219-9_21
   Chen F., 2020, J. Graph Algorithms Appl., V24, P683, DOI [10.7155/jgaa.00532, DOI 10.7155/JGAA.00532]
   Chen FT, 2019, LECT NOTES COMPUT SC, V11904, P179, DOI 10.1007/978-3-030-35802-0_14
   Chen X, 2020, IEEE T VIS COMPUT GR, V26, P729, DOI 10.1109/TVCG.2019.2934541
   Cutura Rene, 2021, VINCI 2021: The 14th International Symposium on Visual Information Communication and Interaction, DOI 10.1145/3481549.3481569
   Dwyer T, 2006, LECT NOTES COMPUT SC, V3843, P153
   Dwyer T, 2007, LECT NOTES COMPUT SC, V4372, P446
   Gansner E., 2010, J. Graph Algorithms Appl., V14, P53
   Giovannangeli L., 2023, Guaranteed Visibility in Scatterplots with Tolerance
   Giovannangeli L, 2023, LECT NOTES COMPUT SC, V13764, P61, DOI 10.1007/978-3-031-22203-0_6
   Gomez Tristan, 2022, Pattern Recognition and Artificial Intelligence: Third International Conference, ICPRAI 2022, Proceedings, Part I. Lecture Notes in Computer Science (13363), P84, DOI 10.1007/978-3-031-09037-0_8
   Halnaut A, 2022, IEEE INT CONF INF VI, P11, DOI 10.1109/IV56949.2022.00012
   Hayashi K, 1998, LECT NOTES COMPUT SC, V1547, P183
   Hilasaca GM, 2021, Arxiv, DOI arXiv:1903.06262
   Huang XD, 2007, INFORM SCIENCES, V177, P2821, DOI 10.1016/j.ins.2007.02.016
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Kruskal JB., 1978, SAGE U PAPER SERIES, DOI DOI 10.4135/9781412985130
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Zeyu, 2023, IEEE Trans Vis Comput Graph, V29, P657, DOI 10.1109/TVCG.2022.3209459
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meulemans W, 2019, COMPUT GRAPH FORUM, V38, P713, DOI 10.1111/cgf.13722
   Micallef L, 2017, IEEE T VIS COMPUT GR, V23, P1588, DOI 10.1109/TVCG.2017.2674978
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Nachmanson L., 2007, Microsoft Automatic Graph Layout
   Nachmanson L, 2016, LECT NOTES COMPUT SC, V9801, P33, DOI 10.1007/978-3-319-50106-2_3
   Ortmann M, 2016, LECT NOTES COMPUT SC, V9801, P18, DOI 10.1007/978-3-319-50106-2_2
   Strobelt H, 2012, COMPUT GRAPH FORUM, V31, P1135, DOI 10.1111/j.1467-8659.2012.03106.x
   Strong G, 2014, IEEE T MULTIMEDIA, V16, P1045, DOI 10.1109/TMM.2014.2306183
   Van Der Maaten L., 2009, Technical report, P5
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wei LY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778816
   Xiao H, 2017, Arxiv, DOI arXiv:1708.07747
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 40
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 792
EP 802
DI 10.1109/TVCG.2023.3326596
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500080
PM 37871063
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Elavsky, F
   Nadolskis, L
   Moritz, D
AF Elavsky, Frank
   Nadolskis, Lucas
   Moritz, Dominik
TI Data Navigator: An Accessibility-Centered Data Navigation Toolkit
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE accessibility; visualization; tools; technical materials; platforms;
   data interaction
ID VISUALIZATION
AB Making data visualizations accessible for people with disabilities remains a significant challenge in current practitioner efforts. Existing visualizations often lack an underlying navigable structure, fail to engage necessary input modalities, and rely heavily on visual-only rendering practices. These limitations exclude people with disabilities, especially users of assistive technologies. To address these challenges, we present Data Navigator: a system built on a dynamic graph structure, enabling developers to construct navigable lists, trees, graphs, and flows as well as spatial, diagrammatic, and geographic relations. Data Navigator supports a wide range of input modalities: screen reader, keyboard, speech, gesture detection, and even fabricated assistive devices. We present 3 case examples with Data Navigator, demonstrating we can provide accessible navigation structures on top of raster images, integrate with existing toolkits at scale, and rapidly develop novel prototypes. Data Navigator is a step towards making accessible data visualizations easier to design and implement.
C1 [Elavsky, Frank; Nadolskis, Lucas; Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Elavsky, F (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM fje@cmu.edu; nadolskis@cmu.edu; domoritz@cmu.edu
OI Moritz, Dominik/0000-0002-3110-1053; Elavsky, Frank/0000-0002-6849-5893
FU Apple, Inc.
FX We want to take this time to express immense gratitude for Reviewer 1,
   whose generous and thorough feedback helped this project find its true
   vision. Elavsky also wants to thank the many folks who have encouraged
   this project's ideation and formation over the last few years. This work
   was supported by a grant from Apple, Inc. Any views, opinions, findings,
   and conclusions or recommendations expressed in this material are those
   of the authors and should not be interpreted as reflecting the views,
   policies or position, either expressed or implied, of Apple Inc.
CR Blanco M., 2022, IEEE VIS POSTERS
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   BOYD LH, 1990, J VISUAL IMPAIR BLIN, V84, P496
   Chundury P, 2022, IEEE T VIS COMPUT GR, V28, P1084, DOI 10.1109/TVCG.2021.3114829
   de Greef L., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34764688
   Dot Pad inc, 2020, Dot pad - the first tactile graphics display for the visually impaired
   Dourish P., 2003, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V12, P465, DOI 10.1023/A:1026149119426
   Durant E, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010622
   Elavsky F., 2021, Defensive Publication Series, V4220, P6
   Elavsky F, 2022, COMPUT GRAPH FORUM, V41, P57, DOI 10.1111/cgf.14522
   Fan DY, 2023, ACM T ACCESS COMPUT, V16, DOI 10.1145/3557899
   Gansner ER, 2000, SOFTWARE PRACT EXPER, V30, P1203, DOI 10.1002/1097-024X(200009)30:11<1203::AID-SPE338>3.0.CO;2-N
   Giraud S, 2016, LECT NOTES COMPUT SC, V9759, P61, DOI 10.1007/978-3-319-41267-2_9
   Godfrey AJR, 2018, LECT NOTES COMPUT SC, V10896, P590, DOI 10.1007/978-3-319-94277-3_92
   Highsoft, Highcharts: Render millions of chart points with the boost module
   Highsoft, 2018, Stacked column demo
   Highsoft, 2018, Highcharts accessibility module: information and demos
   Hurst A., 2013, P 12 INT C INT DES C, P635, DOI DOI 10.1145/2485760.2485883
   Jung C, 2022, IEEE T VIS COMPUT GR, V28, P1095, DOI 10.1109/TVCG.2021.3114846
   Kim JH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581532
   Kim NW, 2021, COMPUT GRAPH FORUM, V40, P173, DOI 10.1111/cgf.14298
   Lin CY, 2014, RES DEV DISABIL, V35, P1963, DOI 10.1016/j.ridd.2014.04.028
   Louridas Panagiotis, 1999, DESIGN STUDIES, V20, P517, DOI [DOI 10.1016/S0142-694X(98)00044-1, 10.1016/s0142-694x(98)00044-1]
   Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/visual.2019.8933762, 10.1109/VISUAL.2019.8933762]
   Ma'ayan D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376253
   Marriott Kim, 2021, Interactions, V28, P47, DOI [DOI 10.1145/3457875, DOI 10.1145/3457875.1]
   Reid B. E., 2022, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.4262991
   Rogers Y., 2014, P SIGCHI C HUM FACT, DOI DOI 10.1145/2556288.25571843,5
   Sarsenbayeva Z., 2022, ACM Computing Surveys, V55, P1, DOI DOI 10.1145/35435093
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Sharif A., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34712022
   Sharif A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517431
   Sharif A, 2018, CONSUM COMM NETWORK
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siean A.-I., 2021, 23 INT ACM SIGACCESS, DOI DOI 10.1145/3441852.34712123
   Sorge V, 2016, LECT NOTES COMPUT SC, V9758, P43, DOI 10.1007/978-3-319-41264-1_6
   Thompson J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581186
   Visa, 2022, Visa Chart Components
   WAI, 2016, WCAG standard
   WAI, 2017, WCAG standard
   WAI, 2017, Technical report
   WebAIM, WAVE, the web accessibility evaluation tool
   Wobbrock Jacob O, 2011, ACM Transactions on Accessible Computing (TACCESS), V3, P1, DOI [10.1145/1952383.1952384, DOI 10.1145/1952383.1952384]
   Ye K, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392375
   Zong J, 2022, COMPUT GRAPH FORUM, V41, P15, DOI 10.1111/cgf.14519
NR 46
TC 2
Z9 2
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 803
EP 813
DI 10.1109/TVCG.2023.3327393
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500004
PM 37903045
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shi, CH
   Cui, WW
   Liu, CZ
   Zheng, CB
   Zhang, HD
   Luo, Q
   Ma, XJ
AF Shi, Chuhan
   Cui, Weiwei
   Liu, Chengzhong
   Zheng, Chengbo
   Zhang, Haidong
   Luo, Qiong
   Ma, Xiaojuan
TI NL2Color: Refining Color Palettes for Charts with Natural Language
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE chart; color palette; natural language; large language model
ID VISUALIZATION
AB Choice of color is critical to creating effective charts with an engaging, enjoyable, and informative reading experience. However, designing a good color palette for a chart is a challenging task for novice users who lack related design expertise. For example, they often find it difficult to articulate their abstract intentions and translate these intentions into effective editing actions to achieve a desired outcome. In this work, we present NL2Color, a tool that allows novice users to refine chart color palettes using natural language expressions of their desired outcomes. We first collected and categorized a dataset of 131 triplets, each consisting of an original color palette of a chart, an editing intent, and a new color palette designed by human experts according to the intent. Our tool employs a large language model (LLM) to substitute the colors in original palettes and produce new color palettes by selecting some of the triplets as few-shot prompts. To evaluate our tool, we conducted a comprehensive two-stage evaluation, including a crowd-sourcing study (N=71) and a within-subjects user study (N=12). The results indicate that the quality of the color palettes revised by NL2Color has no significantly large difference from those designed by human experts. The participants who used NL2Color obtained revised color palettes to their satisfaction in a shorter period and with less effort.
C1 [Shi, Chuhan] Southeast Univ, Nanjing, Peoples R China.
   [Shi, Chuhan; Liu, Chengzhong; Zheng, Chengbo; Luo, Qiong; Ma, Xiaojuan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Cui, Weiwei; Zhang, Haidong] Microsoft Res Asia, Beijing, Peoples R China.
   [Luo, Qiong] Hong Kong Univ Sci & Technol Guangzhou, Hong Kong, Peoples R China.
C3 Southeast University - China; Hong Kong University of Science &
   Technology; Microsoft Research Asia; Microsoft
RP Shi, CH (corresponding author), Southeast Univ, Nanjing, Peoples R China.; Shi, CH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM cshiag@connect.ust.hk; weiweicu@microsoft.com;
   chengzhong.liu@connect.ust.hk; cb.zheng@connect.ust.hk;
   haizhang@microsoft.com; luo@cse.ust.hk; mxj@cse.ust.hk
RI Zhang, Haidong/J-9302-2019
OI Luo, Qiong/0000-0002-2861-9492
FU HKUST 30 for 30
FX No Statement Available
CR adobe, Adobe Illustrator
   adobe, Adobe Photoshop
   adobe, Adobe color
   Bahng H, 2018, LECT NOTES COMPUT SC, V11216, P443, DOI 10.1007/978-3-030-01258-8_27
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brewer C., 1994, Visualization in modern cartography
   Brown TB, 2020, ADV NEUR IN, V33
   coloplast, About us
   Coolors, About us
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Feng Y., 2023, IEEE Trans. Vis. Comput. Graphics
   github, Vega-Lite
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   HART S G, 1988, P139
   Hearst M, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P21, DOI [10.1109/visual.2019.8933569, 10.1109/VISUAL.2019.8933569]
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Inkscape, About us
   Kaur H., 2019, CHI 19
   Kenter T, 2015, P 24 ACM INT C INFOR, P1411, DOI 10.1145/2806416.2806475
   Kim T. S., 2022, P 2022 CHI C HUM FAC, P1
   Krause M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4627
   Kumar IP, 2020, ADV INTELL SYST COMP, V1079, P921, DOI 10.1007/978-981-15-1097-7_78
   Li Y., 2021, P 2021 CHI C HUM FAC, P1
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Lu H., 2012, CHI, P2875
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   materialise, About us
   Meier BJ, 2004, IEEE COMPUT GRAPH, V24, P64, DOI 10.1109/MCG.2004.1297012
   Mishra S, 2022, Arxiv, DOI arXiv:2109.07830
   palestinewrites, about us
   Peng YF, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P389, DOI [10.1109/icccbda.2019.8725717, 10.1109/ICCCBDA.2019.8725717]
   Qiu QR, 2022, COMPANION PROCEEDINGS OF THE 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2022 COMPANION, P26, DOI 10.1145/3490100.3516450
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Rashid MM, 2022, LECT NOTES ARTIF INT, V13281, P3, DOI 10.1007/978-3-031-05936-0_1
   Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760
   Schloss KB, 2019, IEEE T VIS COMPUT GR, V25, P810, DOI 10.1109/TVCG.2018.2865147
   Setlur V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P216, DOI 10.1109/VIS47514.2020.00050
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Shugrina M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300686
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   So David, 2021, Advances in neural information processing systems, V34, P6010
   Stern M.K., 2010, The Corsini Encyclopedia of Psychology
   Tseng C, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581416
   Tuli M., 2022, Advances in Neural Information Processing Systems, V35, P19441
   Voigt H, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P348
   vor der Brück T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1827
   Wang Y, 2023, IEEE T VIS COMPUT GR, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wijffelaars M, 2008, COMPUT GRAPH FORUM, V27, P743, DOI 10.1111/j.1467-8659.2008.01203.x
   Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582
   Yan L., 2021, P 2021 CHI C HUM FAC, P1
   Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388
   Zeileis A, 2019, Arxiv, DOI arXiv:1903.06490
NR 57
TC 3
Z9 3
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 814
EP 824
DI 10.1109/TVCG.2023.3326522
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500091
PM 37871067
DA 2024-11-06
ER

PT J
AU Xue, YM
   Paetzold, P
   Kehlbeck, R
   Chen, B
   Kwan, KC
   Wang, YH
   Deussen, O
AF Xue, Yumeng
   Paetzold, Patrick
   Kehlbeck, Rebecca
   Chen, Bin
   Kwan, Kin Chung
   Wang, Yunhai
   Deussen, Oliver
TI Reducing Ambiguities in Line-Based Density Plots by Image-Space
   Colorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Trajectory data; times series; density-based visualization; clustering;
   coloring
ID SIMILARITY MEASURES; VISUALIZATION; EDGE; COLORS; UNCERTAINTY; MAPS;
   TREE
AB Line-based density plots are used to reduce visual clutter in line charts with a multitude of individual lines. However, these traditional density plots are often perceived ambiguously, which obstructs the user's identification of underlying trends in complex datasets. Thus, we propose a novel image space coloring method for line-based density plots that enhances their interpretability. Our method employs color not only to visually communicate data density but also to highlight similar regions in the plot, allowing users to identify and distinguish trends easily. We achieve this by performing hierarchical clustering based on the lines passing through each region and mapping the identified clusters to the hue circle using circular MDS. Additionally, we propose a heuristic approach to assign each line to the most probable cluster, enabling users to analyze density and individual lines. We motivate our method by conducting a small-scale user study, demonstrating the effectiveness of our method using synthetic and real-world datasets, and providing an interactive online tool for generating colored line-based density plots.
C1 [Xue, Yumeng] Germany & Shandong Univ, Univ Konstanz, Jinan, Peoples R China.
   [Paetzold, Patrick; Kehlbeck, Rebecca; Chen, Bin; Deussen, Oliver] Univ Konstanz, Constance, Germany.
   [Kwan, Kin Chung] Calif State Univ Sacramento, Sacramento, CA USA.
   [Wang, Yunhai] Shandong Univ, Jinan, Peoples R China.
C3 University of Konstanz; California State University System; California
   State University Sacramento; Shandong University
RP Deussen, O (corresponding author), Univ Konstanz, Constance, Germany.; Wang, YH (corresponding author), Shandong Univ, Jinan, Peoples R China.
EM yumeng.xue@uni-konstanz.de; patrick.paetzold@uni-konstanz.de;
   rebecca.kehlbeck@uni-konstanz.de; bin.chen@uni-konstanz.de;
   kwan@csus.edu; cloudseawang@gmail.com; oliver.deussen@uni-konstanz.de
RI Deussen, Oliver/HKF-2004-2023; Bin, Chen/AGZ-5833-2022
OI Xue, Yumeng/0000-0002-8195-517X; Paetzold, Patrick/0000-0002-1315-4602
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR [Anonymous], 2017, Acis web services
   [Anonymous], 2023, New york stock exchange
   Artero AO, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P81, DOI 10.1109/INFVIS.2004.68
   Bergman LD, 1995, VISUALIZATION '95 - PROCEEDINGS, P118, DOI 10.1109/VISUAL.1995.480803
   Brewer C.A., 1999, P SECT STAT GRAPH, P55
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [DOI 10.1016/B978-0-08-042415-6.50014-4, 10.1016/b978-0-08-042415-6.50014-4]
   Brewer CynthiaA., 1994, Proc. SPIE, V2171, P54, DOI [DOI 10.1117/12.175328, DOI 10.1117/12.1753283]
   CARR DB, 1987, J AM STAT ASSOC, V82, P424, DOI 10.2307/2289444
   Chen CK, 2011, COMPUT GRAPH FORUM, V30, P1941, DOI 10.1111/j.1467-8659.2011.02064.x
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Chen Y, 2007, IEEE T VIS COMPUT GR, V13, P1448, DOI 10.1109/TVCG.2007.70595
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Cox M. A., 2008, Handbook of data visualization, P315, DOI DOI 10.1007/978-3-540-33037-014
   COX TF, 1991, COMMUN STAT THEORY, V20, P2943, DOI 10.1080/03610929108830679
   DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115
   Feng D, 2010, IEEE T VIS COMPUT GR, V16, P980, DOI 10.1109/TVCG.2010.176
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Frantzis A., 2018, Hellenic trench ais data, DOI [10.17882/570405,6,7, DOI 10.17882/570405,6,7]
   Frantzis A, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212016
   Fulcher BD, 2013, J R SOC INTERFACE, V10, DOI 10.1098/rsif.2013.0048
   Gaffney S., 2004, P 17 INT C NEURAL IN, P2
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Hochheiser H., 2004, Information Visualization, V3, P1, DOI 10.1057/palgrave.ivs.9500061
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hong MH, 2022, IEEE T VIS COMPUT GR, V28, P987, DOI 10.1109/TVCG.2021.3114783
   Hurter C, 2009, IEEE T VIS COMPUT GR, V15, P1017, DOI 10.1109/TVCG.2009.145
   Ihaka R., 2003, P DSC, V2
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Jerding DF, 1998, IEEE T VIS COMPUT GR, V4, P257, DOI 10.1109/2945.722299
   Kindlmann G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P299, DOI 10.1109/VISUAL.2002.1183788
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Lampe OD, 2011, COMPUT GRAPH FORUM, V30, P633, DOI 10.1111/j.1467-8659.2011.01912.x
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Lhuillier A, 2017, COMPUT GRAPH FORUM, V36, P619, DOI 10.1111/cgf.13213
   Liu T., 2021, P CHI C HUMAN FACTOR, DOI [10.1145/3411764.34457512, DOI 10.1145/3411764.34457512]
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Matejka J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2707, DOI 10.1145/2702123.2702585
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   McLoughlin T, 2013, IEEE T VIS COMPUT GR, V19, P1342, DOI 10.1109/TVCG.2012.150
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Moritz D, 2018, Arxiv, DOI arXiv:1808.06019
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Novotny M, 2006, IEEE T VIS COMPUT GR, V12, P893, DOI 10.1109/TVCG.2006.170
   OpenStreetMap contributors, 2017, Planet Dump
   Palmas G, 2014, IEEE PAC VIS SYMP, P57, DOI 10.1109/PacificVis.2014.40
   Petitjean F, 2011, PATTERN RECOGN, V44, P678, DOI 10.1016/j.patcog.2010.09.013
   PHAM B, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P202, DOI 10.1109/VISUAL.1990.146383
   Pomerenke D, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P86, DOI [10.1109/VISUAL.2019.8933706, 10.1109/visual.2019.8933706]
   Rheingans P, 2000, P SOC PHOTO-OPT INS, V3905, P35, DOI 10.1117/12.384882
   ROBERTSON PK, 1986, IEEE COMPUT GRAPH, V6, P24, DOI 10.1109/MCG.1986.276688
   Rössl C, 2012, IEEE T VIS COMPUT GR, V18, P407, DOI 10.1109/TVCG.2011.78
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Salzbrunn T, 2006, IEEE T VIS COMPUT GR, V12, P1601, DOI 10.1109/TVCG.2006.104
   Scheepens R, 2011, IEEE PAC VIS SYMP, P147, DOI 10.1109/PACIFICVIS.2011.5742384
   Scheepens R, 2011, IEEE T VIS COMPUT GR, V17, P2518, DOI 10.1109/TVCG.2011.181
   Silverman B. W., 1986, Density estimation for statistics and data analysis, V26, P2
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Thompson David, 2013, 2013 IEEE Symposium on Large-Scale Data Analysis and Visualization (LDAV), P77, DOI 10.1109/LDAV.2013.6675161
   Thony M, 2015, PROCEEDINGS OF THE 6TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON GEOSTREAMING (IWGS) 2015, P33, DOI 10.1145/2833165.2833168
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Trautner T., 2020, Computer Graphics Forum, DOI [10.1111/cgf.140012, DOI 10.1111/CGF.140012]
   TRUMBO BE, 1981, AM STAT, V35, P220, DOI 10.2307/2683294
   van der Zwan M, 2016, IEEE T VIS COMPUT GR, V22, P2550, DOI 10.1109/TVCG.2016.2515611
   Vijaymeena M., 2016, Mach. Learn. Appl.: An Int. J., V3, P19, DOI DOI 10.5121/MLAIJ2016.3103
   Wallinger M, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14789
   Wallinger M, 2022, IEEE T VIS COMPUT GR, V28, P313, DOI 10.1109/TVCG.2021.3114795
   Wang L, 2012, COMPUT GRAPH FORUM, V31, P1305, DOI 10.1111/j.1467-8659.2012.03123.x
   Wattenberg M., 2001, P 2001 CHI C HUM FAC, P381, DOI DOI 10.1145/634067.6342922
   Wertheimer M., 1938, A Source Book of Gestalt Psychology, P71, DOI [10.1037/11496-005, DOI 10.1037/11496-005]
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wickham H., 2013, Tech. Rep
   Yu HF, 2012, IEEE T VIS COMPUT GR, V18, P1353, DOI 10.1109/TVCG.2011.155
   Yuan J., 2010, P 18 SIGSPATIAL INT, P99, DOI DOI 10.1145/1869790.1869807
   Yuan Jing, 2011, P 17 ACM SIGKDD INT, P316
   Zeileis A, 2009, COMPUT STAT DATA AN, V53, P3259, DOI 10.1016/j.csda.2008.11.033
   Zeng W, 2019, COMPUT GRAPH FORUM, V38, P581, DOI 10.1111/cgf.13712
   Zhang Z, 2006, INT C PATT RECOG, P1135
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
   Zinsmaier M, 2012, IEEE T VIS COMPUT GR, V18, P2486, DOI 10.1109/TVCG.2012.238
NR 83
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 825
EP 835
DI 10.1109/TVCG.2023.3327149
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500022
PM 37883272
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Chundury, P
   Reyazuddin, Y
   Jordan, JB
   Lazar, J
   Elmqvist, N
AF Chundury, Pramod
   Reyazuddin, Yasmin
   Jordan, J. Bern
   Lazar, Jonathan
   Elmqvist, Niklas
TI TactualPlot: Spatializing Data as Sound Using Sensory Substitution for
   Touchscreen Accessibility
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Sonification; Data visualization; Smart phones; Touch sensitive screens;
   Blindness; Haptic interfaces; Electronic mail; Accessibility;
   sonification; multimodal interaction; crossmodal interaction;
   visualization
ID VISUALIZATION
AB Tactile graphics are one of the best ways for a blind person to perceive a chart using touch, but their fabrication is often costly, time-consuming, and does not lend itself to dynamic exploration. Refreshable haptic displays tend to be expensive and thus unavailable to most blind individuals. We propose TactualPlot, an approach to sensory substitution where touch interaction yields auditory (sonified) feedback. The technique relies on embodied cognition for spatial awareness-i.e., individuals can perceive 2D touch locations of their fingers with reference to other 2D locations such as the relative locations of other fingers or chart characteristics that are visualized on touchscreens. Combining touch and sound in this way yields a scalable data exploration method for scatterplots where the data density under the user's fingertips is sampled. The sample regions can optionally be scaled based on how quickly the user moves their hand. Our development of TactualPlot was informed by formative design sessions with a blind collaborator, whose practice while using tactile scatterplots caused us to expand the technique for multiple fingers. We present results from an evaluation comparing our TactualPlot interaction technique to tactile graphics printed on swell touch paper.
C1 [Chundury, Pramod; Jordan, J. Bern; Lazar, Jonathan; Elmqvist, Niklas] Univ Maryland, College Pk, MD 20742 USA.
   [Reyazuddin, Yasmin] Natl Federat Blind, Baltimore, MD USA.
   [Elmqvist, Niklas] Aarhus Univ, Aarhus, Denmark.
C3 University System of Maryland; University of Maryland College Park;
   Aarhus University
RP Chundury, P (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM pchundur@umd.edu; yasmin81065@gmail.com; jbjordan@umd.edu;
   jlazar@umd.edu; elm@cs.au.dk
RI Jordan, J Bern/JNS-6427-2023
OI Elmqvist, Niklas/0000-0001-5805-5301; Jordan, J.
   Bern/0000-0002-0386-9137
FU U.S. National Science Foundation
FX No Statement Available
CR Abraham CH, 2022, ASSIST TECHNOL, V34, P611, DOI 10.1080/10400435.2021.1907485
   Al-Zaidy RA., 2015, P ACM C KNOWL CAPT, P30, DOI [10.1145/2815833.28169562, DOI 10.1145/2815833.28169562]
   Alexander J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173873
   Bach-y-Rita P, 2003, TRENDS COGN SCI, V7, P541, DOI 10.1016/j.tics.2003.10.013
   Batch A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376733
   Baudisch P., 2003, P SIGCHI C HUM FACT, P481, DOI 10.1145/642611.642695
   Blanco M., 2022, IEEE VIS POST
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cantrell S., 2021, P INT C AUD DISPL
   Carter T., P ACM S US INT SOFTW, P505
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Chundury P, 2022, IEEE T VIS COMPUT GR, V28, P1084, DOI 10.1109/TVCG.2021.3114829
   Cook A. M., 2014, Assistive Technologies: Principles and Practice, V1
   Deroy O., 2012, Frontiers in Psychology, V3, DOI [10.3389/fpsyg.2012.004572,3, DOI 10.3389/FPSYG.2012.004572,3]
   Drogemuller A., 2021, P 2021 CHI C HUMAN F, DOI 10.1145/3411764.3445704
   Elavsky F, 2022, COMPUT GRAPH FORUM, V41, P57, DOI 10.1111/cgf.14522
   Elmqvist N., 2023, Interactions, V30, P52, DOI 10.1145/35717372,3
   Enge K., 2022, Proc. 24th Eurographics Conference on Visualization (EuroVis 2022) Short Papers, P67, DOI [10.2312/evs.202210954, DOI 10.2312/EVS.20221095]
   Fan D., 2022, P ACM C HUM FACT COM, DOI [10.1145/3491102.35177902, DOI 10.1145/3491102.35177902]
   Gaver B., 1999, Interactions, V6, P21, DOI [10.1145/291224.291235, DOI 10.1145/291224.291235]
   Gleason C, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P549, DOI 10.1145/3308558.3313605
   Gorlewicz JL, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3403933
   Guinness D, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P318, DOI 10.1145/3308561.3353804
   Hermann T., 2011, The Sonification Handbook, P2
   Holloway L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173772
   Hoque MN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581087
   Janicke S., 2020, P EUR WORKSH GAP VIS, P35, DOI DOI 10.2312/VISGAP.20201108
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   JayneWallace John McCarthy, 2013, P SIGCHI C HUM FACT, P3441, DOI DOI 10.1145/2470654.2466473
   Jung C, 2022, IEEE T VIS COMPUT GR, V28, P1095, DOI 10.1109/TVCG.2021.3114846
   Kim G, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581139
   Kim JH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581532
   Kramer G., 1994, Santa Fe Institute Studies in the Sciences of Complexity, VXVIII, P2
   Kramer G., SONIFICATION REPORT
   Lundgard A, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P16, DOI [10.1109/visual.2019.8933762, 10.1109/VISUAL.2019.8933762]
   Nakagaki K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2764, DOI 10.1145/2858036.2858104
   Nanay B, 2017, PERCEPTION, V46, P1014, DOI 10.1177/0301006617699225
   Nicolau Hugo., 2015, P 12 WEB ALL C 301 3, DOI DOI 10.1145/2745555.2746643
   Nikitenko D, 2014, PROCEDIA COMPUT SCI, V34, P360, DOI 10.1016/j.procs.2014.07.038
   Oh U, 2013, P 15 INT ACM SIGACCE, P1, DOI [10.1145/2513383.2513455, DOI 10.1145/2513383.2513455, 10.1145/2513383.2513455event-place]
   Osinski D., 2021, Sensors, V21, DOI [10.3390/s212173512, DOI 10.3390/S212173512]
   Palani HP, 2020, INT J HUM-COMPUT INT, V36, P1393, DOI 10.1080/10447318.2020.1752464
   Patnaik B, 2019, IEEE T VIS COMPUT GR, V25, P726, DOI 10.1109/TVCG.2018.2865237
   Potluri V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545700
   Salisbury K, 2004, IEEE COMPUT GRAPH, V24, P24, DOI 10.1109/MCG.2004.1274058
   Sarikaya A, 2018, IEEE T VIS COMPUT GR, V24, P402, DOI 10.1109/TVCG.2017.2744184
   Sharif A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517431
   Sharif Ather, 2022, P 24 INT ACM SIGACCE
   SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471
   Siu A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517678
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Thompson J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581186
   Tory M, 2005, IEEE COMPUT GRAPH, V25, P8, DOI 10.1109/MCG.2005.102
   Wagner J., 2012, Proc. of CHI '12, P2317
   Walker B. N., 2010, ACM Trans. Access. Comput., V2, DOI DOI 10.1145/1714458.1714459
   Walker B. N., 2005, ACM Trans. Appl. Percept, V2, P407, DOI [10.1145/1101530.1101534, DOI 10.1145/1101530.1101534]
   Wang R, 2022, COMPUT GRAPH FORUM, V41, P71, DOI 10.1111/cgf.14523
   Yau D, 2007, DIGIT CREAT, V18, P121, DOI 10.1080/14626260701401510
   Zhao H, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1352782.1352786
   Zong J, 2022, COMPUT GRAPH FORUM, V41, P15, DOI 10.1111/cgf.14519
NR 61
TC 3
Z9 3
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 836
EP 846
DI 10.1109/TVCG.2023.3326937
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500010
PM 37922170
DA 2024-11-06
ER

PT J
AU Chen, LF
   Wang, H
   Ouyang, Y
   Zhou, Y
   Wang, NY
   Li, Q
AF Chen, Longfei
   Wang, He
   Ouyang, Yang
   Zhou, Yang
   Wang, Naiyu
   Li, Quan
TI FSLens: A Visual Analytics Approach to Evaluating and Optimizing the
   Spatial Layout of Fire Stations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal Analysis; Multi-criteria Decision Making; Visualization
ID LOCATION MODEL; HIERARCHY PROCESS; SITE SELECTION; OPTIMIZATION
AB The provision of fire services plays a vital role in ensuring the safety of residents' lives and property. The spatial layout of fire stations is closely linked to the efficiency of fire rescue operations. Traditional approaches have primarily relied on mathematical planning models to generate appropriate layouts by summarizing relevant evaluation criteria. However, this optimization process presents significant challenges due to the extensive decision space, inherent conflicts among criteria, and decision-makers' preferences. To address these challenges, we propose FSLens, an interactive visual analytics system that enables in-depth evaluation and rational optimization of fire station layout. Our approach integrates fire records and correlation features to reveal fire occurrence patterns and influencing factors using spatiotemporal sequence forecasting. We design an interactive visualization method to explore areas within the city that are potentially under-resourced for fire service based on the fire distribution and existing fire station layout. Moreover, we develop a collaborative human-computer multi-criteria decision model that generates multiple candidate solutions for optimizing firefighting resources within these areas. We simulate and compare the impact of different solutions on the original layout through well-designed visualizations, providing decision-makers with the most satisfactory solution. We demonstrate the effectiveness of our approach through one case study with real-world datasets. The feedback from domain experts indicates that our system helps them to better identify and improve potential gaps in the current fire station layout.
C1 [Chen, Longfei; Wang, He; Ouyang, Yang; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Chen, Longfei; Wang, He; Ouyang, Yang; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Zhou, Yang; Wang, Naiyu] Zhejiang Univ, Coll Civil Engn & Architecture, Hangzhou, Peoples R China.
C3 ShanghaiTech University; Zhejiang University
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM chenlf@shanghaitech.edu.cn; wanghe1@shanghaitech.edu.cn;
   ouyy@shanghaitech.edu.cn; yang-zhou@zju.edu.cn; naiyuwang@zju.edu.cn;
   liquan@shanghaitech.edu.cn
RI Chen, LongFei/AAI-1277-2019; Wang, Nai-Yu/E-5303-2016
OI Wang, He/0009-0003-2550-6139; , Yang/0009-0000-5841-7659; Chen,
   Longfei/0009-0002-4596-8093
FU Research and System Development of Resilient Urban Fire Risk and Fire
   Safety Dynamic Assessment Technology Based on Multiple Data Sources
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Aruldoss M., 2013, AM J INFORM SYST, V1, P31, DOI DOI 10.12691/AJIS-1-1-5
   Badri MA, 1998, EUR J OPER RES, V110, P243, DOI 10.1016/S0377-2217(97)00247-6
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   BATTA R, 1989, TRANSPORT SCI, V23, P277, DOI 10.1287/trsc.23.4.277
   Benesty J., 2009, Noise Reduction in Speech Processing, P1, DOI DOI 10.4135/9781506326139.N510
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Booshehrian M, 2012, COMPUT GRAPH FORUM, V31, P1235, DOI 10.1111/j.1467-8659.2012.03116.x
   Borgo R., 2013, Eurographics 2013 - State of the Art Reports, DOI DOI 10.2312/CONF/EG2013/STARS/039
   Carenini G., 2004, P WORK C ADV VIS INT, P150
   Chaudhary P, 2016, SOCIO-ECON PLAN SCI, V53, P60, DOI 10.1016/j.seps.2015.10.001
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Church R., 1974, PAPERS REGIONAL SCI, V32, P101, DOI DOI 10.1007/BF01942293
   Church R. L., 1999, Geographical information systems, V1, P2
   DASKIN MS, 1983, TRANSPORT SCI, V17, P48, DOI 10.1287/trsc.17.1.48
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Doeksen G. A., 1976, Southern Journal of Agricultural Economics, V8, P121
   Düzçeker A, 2021, PROC CVPR IEEE, P15319, DOI 10.1109/CVPR46437.2021.01507
   Echeverria F, 2018, DYNA-BILBAO, V93, DOI 10.6036/8408
   Erden T, 2010, NAT HAZARD EARTH SYS, V10, P2127, DOI 10.5194/nhess-10-2127-2010
   Gratzl S, 2013, IEEE T VIS COMPUT GR, V19, P2277, DOI 10.1109/TVCG.2013.173
   Hailesilassie T, 2016, Arxiv, DOI arXiv:1610.05267
   Hilton BN, 2011, INFORM VISUAL, V10, P82, DOI 10.1057/ivs.2010.14
   HOGG JM, 1968, OPER RES QUART, V19, P275, DOI 10.2307/3008620
   Karamshuk D, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P793
   Karpathy A, 2015, Arxiv, DOI [arXiv:1506.02078, DOI 10.48550/ARXIV.1506.02078]
   Kiran KC, 2018, GEOGR RES-AUST, V56, P270, DOI 10.1111/1745-5871.12288
   Li Q, 2020, COMPUT GRAPH FORUM, V39, P483, DOI 10.1111/cgf.13996
   Liu DL, 2020, FIRE SAFETY J, V118, DOI 10.1016/j.firesaf.2020.103238
   Liu DL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196632
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Lundberg SM, 2017, ADV NEUR IN, V30
   Luo JL, 2019, CASE STUD THERM ENG, V14, DOI 10.1016/j.csite.2019.100495
   Maciejewski R, 2010, IEEE T VIS COMPUT GR, V16, P205, DOI 10.1109/TVCG.2009.100
   Mehler A, 2006, IEEE T VIS COMPUT GR, V12, P765, DOI 10.1109/TVCG.2006.179
   Miller B. L., 1995, Complex systems, V9, P5
   Monarchi D. E., 1977, Decision Sciences, V8, P211
   Murray AT, 2013, FIRE SAFETY J, V62, P64, DOI 10.1016/j.firesaf.2013.03.002
   N. NFPA, 2010, 1710 standard for the organization and deployment of fire suppression operations, emergency medical operations, and special operations to the public by career fire departments, P6
   Olah C., 2015, Understanding lstm networks, P5
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Pellegrini AFA, 2018, NATURE, V553, P194, DOI 10.1038/nature24668
   PLANE DR, 1977, OPER RES, V25, P563, DOI 10.1287/opre.25.4.563
   Reilly J.M., 1985, Fire Technology, V21, P181, DOI DOI 10.1007/BF01039973
   Robin C, 2022, Arxiv, DOI arXiv:2210.13648
   SCHILLING DA, 1980, EUR J OPER RES, V5, P1, DOI 10.1016/0377-2217(80)90067-3
   SCHREUDER JAM, 1981, EUR J OPER RES, V6, P212, DOI 10.1016/0377-2217(81)90210-1
   Sen A., 2011, The Gibbard random dictatorship theorem: A generalization and a new proof, P2
   Shi XJ, 2015, ADV NEUR IN, V28
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stein M., 2016, 12th European International Farming Systems Association (IFSA) Symposium, Social and technological transformation of farming systems: Diverging and converging pathways, 12-15 July 2016, Harper Adams University, Newport, Shropshire, UK, P1
   Tan C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Tekin SF, 2023, Arxiv, DOI arXiv:2102.00696
   TOREGAS C, 1971, OPER RES, V19, P1363, DOI 10.1287/opre.19.6.1363
   Tzeng GH, 2011, MULTIPLE ATTRIBUTE DECISION MAKING: METHODS AND APPLICATIONS, P1
   Uddin MS, 2020, NAT HAZARDS, V102, P1475, DOI 10.1007/s11069-020-03981-2
   WEAVER JR, 1985, TRANSPORT SCI, V19, P58, DOI 10.1287/trsc.19.1.58
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Xin-ming Dong, 2018, Procedia Engineering, V211, P124, DOI 10.1016/j.proeng.2017.12.129
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Xu ZS, 2021, CASE STUD THERM ENG, V25, DOI 10.1016/j.csite.2021.100957
   Yang LL, 2007, EUR J OPER RES, V181, P903, DOI 10.1016/j.ejor.2006.07.003
   Yu B, 2018, Arxiv, DOI arXiv:1709.04875
   Yu YF, 2012, PROCEEDINGS OF THE 2012 EIGHTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS 2012), P328, DOI 10.1109/CIS.2012.80
   Zhang C., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P767, DOI [10.1109/tvcg.2022.32094406, DOI 10.1109/TVCG.2022.32094403,6]
   Zhang GW, 2019, CASE STUD THERM ENG, V14, DOI 10.1016/j.csite.2019.100426
   Zhang JW, 2014, IEEE T VIS COMPUT GR, V20, P1843, DOI 10.1109/TVCG.2014.2346898
   Zhongming Z., 2009, Ministry of housing and urban-rural development of the people's republic of china, P2
NR 69
TC 1
Z9 1
U1 11
U2 18
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 847
EP 857
DI 10.1109/TVCG.2023.3327077
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500094
PM 37878448
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Fu, Y
   Stasko, J
AF Fu, Yu
   Stasko, John
TI HoopInSight: Analyzing and Comparing Basketball Shooting Performance
   Through Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE sports data visualization; sports analytics; visual comparison;
   basketball
AB Data visualization has the power to revolutionize sports. For example, the rise of shot maps has changed basketball strategy by visually illustrating where "good/bad" shots are taken from. As a result, professional basketball teams today take shots from very different positions on the court than they did 20 years ago. Although the shot map has transformed many facets of the game, there is still much room for improvement to support richer and more complex analytical tasks. More specifically, we believe that the lack of sufficient interactivity to support various analytical queries and the inability to visually compare differences across situations are significant limitations of current shot maps. To address these limitations and showcase new possibilities, we designed and developed HoopInSight, an interactive visualization system that centers around a novel spatial comparison visual technique, enhancing the capabilities of shot maps in basketball analytics. This article presents the system, with a focus on our proposed visual technique and its accompanying interactions, all designed to promote comparison of two different scenarios. Furthermore, we provide reflections on and a discussion of relevant issues, including considerations for designing spatial comparison techniques, the scalability and transferability of this approach, and the benefits and pitfalls of designing as domain experts.
C1 [Fu, Yu; Stasko, John] Georgia Inst Technol, Atlanta, GA 30332 USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Fu, Y (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM fuyu@gatech.edu; john.stasko@cc.gatech.edu
OI Fu, Yu/0000-0001-5076-6299
CR Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Basketball-Reference.com, 2022, Glossary - Effective Field Goal
   BBallytics, 2021, Is the mid-range really dead?
   Beshai P., 2014, Technical report, V2, P3
   Buchanan L., 2016, New York Times, P8
   Cervone D., 2014, P SPORTS ANALYTICS C, P2
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chung DHS, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.25
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Endert A., 2011, P GRAPHICS INTERFACE, P8
   Yu F, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502078
   Gamio L., 2016, Washington Post, P8
   Gels J., Basketball terms - terminology
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Goldsberry K., 2019, Sprawlball: A visual tour of the new era of the NBA, P1
   Goldsberry K., The death of midrange
   Goldsberry Kirk., 2012, 2012 MIT Sloan Sports Analytics Conference, V9, P12
   Hickson D., 2003, P HAWAII INT C STAT, P2
   Hu GY, 2021, STAT-US, V10, DOI 10.1002/sta4.324
   Jiao JY, 2021, J QUANT ANAL SPORTS, V17, P77, DOI 10.1515/jqas-2019-0106
   Krause J., BASKETBALL SKILLS DR
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Lin T., 2021, P 2021 CHI C HUMAN F, p461:1, DOI [10.1145/3411764.34456492, DOI 10.1145/3411764.34456492]
   Lin TC, 2023, IEEE COMPUT GRAPH, V43, P84, DOI 10.1109/MCG.2022.3222042
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   McNabb L, 2019, INFORMATION, V10, DOI 10.3390/info10100302
   Meko T., 2020, The Washington Post, P8
   Miller A, 2014, PR MACH LEARN RES, V32
   Natarajan S., 2022, Meet the data visualization king of basketball Twitter: Todd Whitehead, P2
   NBA, 2012, Advanced stats: eFG%
   Oppermann M, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P74, DOI 10.1109/BELIV51497.2020.00016
   Patel S., 2022, An API client package to access the APIs for NBA.com
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Reich BJ, 2006, AM STAT, V60, P3, DOI 10.1198/000313006X90305
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sha L, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3185596
   Strauss B., 2019, The Washington PostApr, P1
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Whitehead T., 2021, Steph Curry's record-breaking 2974 career threes
   Wickham H, 2012, ENVIRONMETRICS, V23, P382, DOI 10.1002/env.2152
   Wong YL, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P1, DOI 10.1109/BELIV.2018.8634026
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Yau N., Goodbye, mid-range shot | flowingdata
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Zhi QY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300499
NR 52
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 858
EP 868
DI 10.1109/TVCG.2023.3326910
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500130
PM 37871051
DA 2024-11-06
ER

PT J
AU Rauscher, J
   Buchmuller, R
   Keim, DA
   Miller, M
AF Rauscher, Julius
   Buchmuller, Raphael
   Keim, Daniel A.
   Miller, Matthias
TI SkiVis: Visual Exploration and Route Planning in Ski Resorts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geographic Visualization; Routing
ID MAP LAYOUT; DESIGN; PREFERENCES; NETWORKS; COLOR; RED
AB Optimal ski route selection is a challenge based on a multitude of factors, such as the steepness, compass direction, or crowdedness. The personal preferences of every skier towards these factors require individual adaptations, which aggravate this task. Current approaches within this domain do not combine automated routing capabilities with user preferences, missing out on the possibility of integrating domain knowledge in the analysis process. We introduce SkiVis, a visual analytics application to interactively explore ski slopes and provide routing recommendations based on user preferences. In collaboration with ski guides and enthusiasts, we elicited requirements and guidelines for such an application and propose different workflows depending on the skiers' familiarity with the resort. In a case study on the resort of Ski Arlberg, we illustrate how to leverage volunteered geographic information to enable a numerical comparison between slopes. We evaluated our approach through a pair-analytics study and demonstrate how it supports skiers in discovering relevant and preference-based ski routes. Besides the tasks investigated in the study, we derive additional use cases from the interviews that showcase the further potential of SkiVis, and contribute directions for further research opportunities.
C1 [Rauscher, Julius; Buchmuller, Raphael; Keim, Daniel A.; Miller, Matthias] Univ Konstanz, D-78457 Constance, Germany.
C3 University of Konstanz
RP Rauscher, J (corresponding author), Univ Konstanz, D-78457 Constance, Germany.
EM julius.rauscher@uni-konstanz.com; raphael.buchmuller@uni-konstanz.com;
   daniel.a.keim@uni-konstanz.com; matthias.miller@uni-konstanz.com
RI Miller, Matthias/JEF-6775-2023
OI Buchmuller, Raphael/0000-0002-0612-8828
FU Deutsche Forschungsgemeinschaft (DFG)
FX No Statement Available
CR Alnes PK, 2021, J OUTDOOR REC TOUR, V35, DOI 10.1016/j.jort.2021.100409
   [Anonymous], 2016, Austrian Standards Int. ONORM S 4611 - Signs for use in organised skiing areas - Requirements, design and classification
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Balzarini R, 2015, INT ARCH PHOTOGRAMM, V40-3, P495, DOI 10.5194/isprsarchives-XL-3-W3-495-2015
   Bergfex GmbH, 2022, Bergfex
   Birch J, 2012, J OPT SOC AM A, V29, P313, DOI 10.1364/JOSAA.29.000313
   Bleisch Susanne, 2009, P353
   Bortnyk S., 2020, Geoinformatics: Theor. Appl. Aspects, P1, DOI DOI 10.3997/2214-4609.2020GEO104
   Breakpoint Studio, 2023, Slopes Ski & Snowboard - Track Your Winter Adventures
   Buckley A., 2004, Geogr. Inf. Sci. Mountain Geomorphol., V01, P8
   Carden T., 2017, Adv. Human Factors Sports Outdoor Recreat, P1
   Chaze B, 2008, NEUROL CLIN, V26, P325, DOI 10.1016/j.ncl.2007.11.009
   Cloudnine Weather LLC, 2023, OpenSnow: Weather Forecasts | Snow Reports & Conditions
   Deliba3ie B., 2022, Proc. Inst. Mech. Eng., Part P: J. Sports Eng. Technol., DOI DOI 10.1177/175433712211181939
   Deng Z., 2022, J. Visualization, P1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Di Lorenzo G, 2016, IEEE T VIS COMPUT GR, V22, P1036, DOI 10.1109/TVCG.2015.2440259
   Dijkstra E. W., 1959, Numerische Mathematik, V1, P5
   Dunlop M., 2007, ACM INT C P SER, P375, DOI DOI 10.1145/1377999.13780402,5
   European Space Agency, 2021, Copernicus DEM - Global and European Digital Elevation Model (COP-DEM), DOI [10.5270/ESA-c5d3d654,9, DOI 10.5270/ESA-C5D3D654,9]
   Falk M, 2020, TOURISM ECON, V26, P1197, DOI 10.1177/1354816619868117
   Falk M, 2017, TOURISM MANAGE, V60, P92, DOI 10.1016/j.tourman.2016.11.008
   FATMAP, 2023, FATMAP 3D: Map & Guides for Skiing, Hiking and Biking
   Federal Ministry Republic of Austria, 2023, ehyd
   Fedosov A, 2016, 15TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2016), P141, DOI 10.1145/3012709.3012721
   Felicio S., 2022, Transp. Res. Procedia, V62, P189, DOI DOI 10.1016/J.TRPRO.2022.02.024
   Field K, 2010, CARTOGR J, V47, P222, DOI 10.1179/000870410X12849977317444
   Fonte C.C., 2017, MAPPING CITIZEN SENS, P137, DOI [DOI 10.5334/BBF.G8, DOI 10.5334/BBF, 10.5334/bbf.g, DOI 10.5334/BBF.G]
   Friedsam Wenzel, 2021, SIGSPATIAL '21: Proceedings of the 29th International Conference on Advances in Geographic Information Systems, P11, DOI 10.1145/3474717.3483628
   Ghaemi Z, 2022, CARTOGR GEOGR INF SC, V49, P205, DOI 10.1080/15230406.2021.2013946
   Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199
   Guo CJ, 2020, VLDB J, V29, P1149, DOI 10.1007/s00778-020-00608-7
   Han B, 2012, INT CON DISTR COMP S, P142, DOI 10.1109/ICDCS.2012.31
   HART S G, 1988, P139
   Haugom E, 2021, EMPIR ECON, V61, P469, DOI 10.1007/s00181-020-01872-w
   Haugom E, 2019, COGENT SOC SCI, V5, DOI 10.1080/23311886.2019.1681246
   Haunert JH, 2011, IEEE T VIS COMPUT GR, V17, P2555, DOI 10.1109/TVCG.2011.191
   Hendrikx J, 2016, J OUTDO RECREAT TOUR, V13, P34, DOI 10.1016/j.jort.2015.11.004
   Hrncir J, 2017, IEEE T INTELL TRANSP, V18, P493, DOI 10.1109/TITS.2016.2577047
   Int. Organisation for Standardisation, 2013, ISO19157:2013 Geographic information - Data quality
   Jackson SB, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18052506
   Jensen C. S., 2009, Encycl. Database Syst., P1692, DOI [DOI 10.1007/978-0-387-39940-9_2154, 10.1007/978-0-387-39940-9_2154]
   King MA, 2014, EXPERT SYST APPL, V41, P1176, DOI 10.1016/j.eswa.2013.08.002
   Konu H, 2011, TOURISM MANAGE, V32, P1096, DOI 10.1016/j.tourman.2010.09.010
   Korohoda N., 2021, Geoinformatics, P1, DOI DOI 10.3997/2214-4609.20215521024
   L'Yi S, 2021, IEEE T VIS COMPUT GR, V27, P1525, DOI 10.1109/TVCG.2020.3030419
   Lera I, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177712
   Leuschner W., 1971, FOR RECR S, P135
   Liu QQ, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P76, DOI 10.1109/VIS47514.2020.00022
   Malasevska I, 2020, J TRAVEL TOUR MARK, V37, P785, DOI 10.1080/10548408.2020.1835787
   McCurdy LE, 2010, CURR PROB PEDIATR AD, V40, P102, DOI 10.1016/j.cppeds.2010.02.003
   Molokác M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14116795
   Moreno-Gené J, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10093012
   Mountain News LLC, 2023, Ski And Snow Reports, Webcams, Skiing Reviews
   OpenStreetMap contributors, 2017, Planet Dump
   Owen R, 2024, J ADVENTURE EDUC OUT, V24, P474, DOI 10.1080/14729679.2022.2127113
   pgRouting Community, 2023, pgRouting
   Pickering CM, 2010, AMBIO, V39, P430, DOI 10.1007/s13280-010-0039-y
   Porter R., 2023, OpenSkiMap.org
   Pravossoudovitch K, 2014, ERGONOMICS, V57, P503, DOI 10.1080/00140139.2014.889220
   Ren XL, 2021, BIG DATA RES, V23, DOI 10.1016/j.bdr.2020.100178
   Riaz F., 2011, Proceedings of the 2011 3rd International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2011), P142, DOI 10.1109/CICSyN.2011.40
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Schmid J., 2021, EUROVIS WORKSH VIS A, DOI DOI 10.2312/EUROVA.202110955
   Schmid L., 2011, Eingebettete Systeme, P71, DOI DOI 10.1007/978-3-642-16189-6_82
   Schobesberger D., 2008, Bull. Soc. Univ. Cartogr., V42, P8
   Scott DM, 2021, J TRANSP GEOGR, V90, DOI 10.1016/j.jtrangeo.2020.102903
   Shih C, 2009, J TRAVEL RES, V47, P359, DOI 10.1177/0047287508321207
   Ski Arlberg, 2022, The Cradle of Alpine Skiing
   Ski Arlberg, 2022, Interactive Map
   Song Q, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1781, DOI 10.1109/ITSC.2014.6957951
   Steiger R, 2020, ECOL ECON, V170, DOI 10.1016/j.ecolecon.2019.106589
   Sterchi R, 2019, NAT HAZARD EARTH SYS, V19, P269, DOI 10.5194/nhess-19-269-2019
   Stigsdotter UK, 2011, URBAN FOR URBAN GREE, V10, P295, DOI 10.1016/j.ufug.2011.07.001
   Storandt S., 2012, Proc. Int. Conf. Autom. Plann. Sched., V22, P234
   Strava Inc, 2023, Strava | Run and Cycling Tracking on the Social Network for Athletes
   Su JG, 2010, TRANSPORT RES A-POL, V44, P495, DOI 10.1016/j.tra.2010.03.015
   Sykes J, 2020, APPL GEOGR, V122, DOI 10.1016/j.apgeog.2020.102261
   Tait A., 2010, Cartogr. Perspect., P5, DOI DOI 10.14714/CP67.1102,8
   Tirla L., 2014, Journal of Environmental and Tourism Analyses, V2, P48
   Vanat L., 2021, International Report on Snow & Mountain Tourism. Overview of the Key Industry Figures for Ski Resorts
   Venter ZS, 2023, LANDSCAPE URBAN PLAN, V232, DOI 10.1016/j.landurbplan.2023.104686
   Wang Y, 2018, COMPUT GRAPH FORUM, V37, P63, DOI 10.1111/cgf.13401
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu HY, 2012, COMPUT GRAPH FORUM, V31, P925, DOI 10.1111/j.1467-8659.2012.03085.x
   Zhang XY, 2023, J VISUAL-JAPAN, V26, P231, DOI 10.1007/s12650-022-00861-8
   Zhu SY, 2022, TRANSP LETT, V14, P298, DOI 10.1080/19427867.2020.1860355
NR 88
TC 0
Z9 0
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 869
EP 879
DI 10.1109/TVCG.2023.3326940
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500055
PM 37874714
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Cao, AQ
   Xie, X
   Zhou, MX
   Zhang, H
   Xu, ML
   Wu, YC
AF Cao, Anqi
   Xie, Xiao
   Zhou, Mingxu
   Zhang, Hui
   Xu, Mingliang
   Wu, Yingcai
TI Action-Evaluator: A Visualization Approach for Player Action Evaluation
   in Soccer
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Soccer Visualization; Player Evaluation; Design Study
ID VISUAL ANALYSIS; ANALYTICS
AB In soccer, player action evaluation provides a fine-grained method to analyze player performance and plays an important role in improving winning chances in future matches. However, previous studies on action evaluation only provide a score for each action, and hardly support inspecting and comparing player actions integrated with complex match context information such as team tactics and player locations. In this work, we collaborate with soccer analysts and coaches to characterize the domain problems of evaluating player performance based on action scores. We design a tailored visualization of soccer player actions that places the action choice together with the tactic it belongs to as well as the player locations in the same view. Based on the design, we introduce a visual analytics system, Action-Evaluator, to facilitate a comprehensive player action evaluation through player navigation, action investigation, and action explanation. With the system, analysts can find players to be analyzed efficiently, learn how they performed under various match situations, and obtain valuable insights to improve their action choices. The usefulness and effectiveness of this work are demonstrated by two case studies on a real-world dataset and an expert interview.
C1 [Cao, Anqi; Zhou, Mingxu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD & CG, Zhejiang, Peoples R China.
   [Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Engn Res Ctr Intelligent Swarm Syst, Minist Educ, Sch Comp & Artificial Intelligence, Zhengzhou, Peoples R China.
   [Xu, Mingliang] Natl Supercomp Ctr, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhengzhou University
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou, Peoples R China.
EM caoanqi@zju.edu.cn; xxie@zju.edu.cn; zhoumingxu@zju.edu.cn;
   zhang_hui@zju.edu.cn; iexumingliang@zzu.edu.cn; ycwu@zju.edu.cn
RI 张, 智浩/KIC-8136-2024
OI , Hui/0000-0003-0601-3905; Zhou, Mingxu/0009-0002-8479-2844
FU National Key R&D Program of China
FX No Statement Available
CR Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Beal R, 2019, KNOWL ENG REV, V34, DOI 10.1017/S0269888919000225
   Bransen L., 2019, 2019 SLOAN SPORTS AN, P2
   Bransen L, 2019, LECT NOTES ARTIF INT, V11330, P3, DOI 10.1007/978-3-030-17274-9_1
   Bransen L, 2019, J QUANT ANAL SPORTS, V15, P97, DOI 10.1515/jqas-2018-0020
   Brooks J, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P49, DOI 10.1145/2939672.2939695
   Cao A., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32071471, DOI 10.1109/TVCG.2022.32071471]
   Cervone D., 2014, P SPORTS ANALYTICS C, P2
   Decroos T., 2017, P 4 WORKSHOP MACHINE, P11
   Decroos T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1851, DOI 10.1145/3292500.3330758
   Decroos T, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P223, DOI 10.1145/3219819.3219832
   Dietrich C, 2014, IEEE CONF VIS ANAL, P23, DOI 10.1109/VAST.2014.7042478
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Fernandez J., 2019, 2019 SLOAN SPORTS AN, P2
   Fernández J, 2021, MACH LEARN, V110, P1389, DOI 10.1007/s10994-021-05989-6
   Fernandez-Navarro J, 2016, J SPORT SCI, V34, P2195, DOI 10.1080/02640414.2016.1169309
   Franks A., 2015, SLOAN SPORTS ANALYTI, P2
   Goldsberry K., 2012, P SLOAN SPORTS ANALY, P2
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gray J, 1996, PROC INT CONF DATA, P152, DOI 10.1109/ICDE.1996.492099
   Gudmundsson Joachim, 2017, ACM Computing Surveys, V50, DOI 10.1145/3054132
   Ishikawa Y, 2018, VIS INFORM, V2, P60, DOI 10.1016/j.visint2018.04.007
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Lage M, 2016, IEEE COMPUT GRAPH, V36, P28, DOI 10.1109/MCG.2016.101
   Lan J, 2022, J VISUAL-JAPAN, V25, P143, DOI 10.1007/s12650-021-00772-0
   Le H. M., 2017, 2017 SLOAN SPORTS AN
   Liu G., 2020, P 34 C NEURAL INFORM, P18704
   Liu GL, 2020, DATA MIN KNOWL DISC, V34, P1531, DOI 10.1007/s10618-020-00705-9
   Liu HY, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.10.002
   Losada AG, 2016, IEEE COMPUT GRAPH, V36, P58, DOI 10.1109/MCG.2016.124
   McHale IG, 2012, INTERFACES, V42, P339, DOI 10.1287/inte.1110.0589
   Mikolov T, 2013, Arxiv, DOI arXiv:1301.3781
   Moon B., 2013, WORKSHOP SPORTS DATA, P2
   Ono JP, 2018, COMPUT GRAPH FORUM, V37, P491, DOI 10.1111/cgf.13436
   Pappalardo L, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3343172
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Perin C, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P887, DOI 10.1145/2556288.2557379
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Power P, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1605, DOI 10.1145/3097983.3098051
   Rusu A, 2011, IEEE INT CONF INF VI, P194, DOI 10.1109/IV.2011.57
   Rusu A, 2010, IEEE INT CONF INF VI, P207, DOI 10.1109/IV.2010.39
   Ryoo M, 2018, MULTIMED TOOLS APPL, V77, P15603, DOI 10.1007/s11042-017-5137-4
   Sacha D, 2017, COMPUT GRAPH FORUM, V36, P305, DOI 10.1111/cgf.13189
   Schulte O., 2017, 2017 SLOAN SPORTS AN, P9
   Seebacher D, 2023, IEEE T VIS COMPUT GR, V29, P1920, DOI 10.1109/TVCG.2021.3134814
   Shao L., 2016, Electronic Imaging, P1
   StatsBomb, StatsBomb Open Data
   Stein M, 2019, J SPORT SCI, V37, P2774, DOI 10.1080/02640414.2019.1652541
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2016, IEEE COMPUT GRAPH, V36, P50, DOI 10.1109/MCG.2016.102
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang HX, 2021, VIS INFORM, V5, P82, DOI 10.1016/j.visinf.2021.09.001
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang WT, 2016, J VISUAL-JAPAN, V19, P515, DOI 10.1007/s12650-015-0337-3
   WhoScored, 2022, WhoScored.com: Football Statistics | Football Live Scores
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu YC, 2019, IEEE T VIS COMPUT GR, V25, P65, DOI 10.1109/TVCG.2018.2865041
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
NR 65
TC 0
Z9 0
U1 10
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 880
EP 890
DI 10.1109/TVCG.2023.3326524
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500078
PM 37878455
DA 2024-11-06
ER

PT J
AU Gao, L
   Shao, ZK
   Luo, ZQ
   Hu, HB
   Turkay, C
   Chen, SM
AF Gao, Lin
   Shao, Zekai
   Luo, Ziqin
   Hu, Haibo
   Turkay, Cagatay
   Chen, Siming
TI TransforLearn: Interactive Visual Tutorial for the Transformer Model
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deep learning; Transformer; Visual tutorial; Explorable explanations
ID NEURAL-NETWORKS
AB The widespread adoption of Transformers in deep learning, serving as the core framework for numerous large-scale language models, has sparked significant interest in understanding their underlying mechanisms. However, beginners face difficulties in comprehending and learning Transformers due to its complex structure and abstract data representation. We present TransforLearn, the first interactive visual tutorial designed for deep learning beginners and non-experts to comprehensively learn about Transformers. TransforLearn supports interactions for architecture-driven exploration and task-driven exploration, providing insight into different levels of model details and their working processes. It accommodates interactive views of each layer's operation and mathematical formula, helping users to understand the data flow of long text sequences. By altering the current decoder-based recursive prediction results and combining the downstream task abstractions, users can deeply explore model processes. Our user study revealed that the interactions of TransforLearn are positively received. We observe that TransforLearn facilitates users' accomplishment of study tasks and a grasp of key concepts in Transformer effectively.
C1 [Gao, Lin; Shao, Zekai; Luo, Ziqin; Chen, Siming] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.
   [Gao, Lin; Shao, Zekai; Luo, Ziqin; Chen, Siming] Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
   [Hu, Haibo] Chongqing Univ, Chongqing, Peoples R China.
   [Turkay, Cagatay] Univ Warwick, Warwick, England.
C3 Fudan University; Chongqing University; University of Warwick
RP Chen, SM (corresponding author), Fudan Univ, Sch Data Sci, Shanghai, Peoples R China.; Chen, SM (corresponding author), Shanghai Key Lab Data Sci, Shanghai, Peoples R China.
EM leenagao0430@gmail.com; haibo.hu@cqu.edu.cn;
   Cagatay.Turkay@warwick.ac.uk; simingchen@fudan.edu.cn
RI Turkay, Cagatay/AAA-3810-2020; Chen, Siming/AAK-1874-2020; Hu,
   Haibo/AAS-5704-2020
OI Turkay, Cagatay/0000-0001-6788-251X; Gao, Lin/0009-0004-1613-1774
FU Natural Science Foundation of China (NSFC)
FX No Statement Available
CR Abnar S., 2019, From attention in transformers to dynamic routing in capsule nets
   Alammar J., 2022, The illustrated retrieval transformer
   Alammar J., 2019, A visual guide to using bert for the first time
   Alicioglu G, 2022, COMPUT GRAPH-UK, V102, P502, DOI 10.1016/j.cag.2021.09.002
   Brown TB, 2020, Arxiv, DOI arXiv:2005.14165
   Bertviz J. Vig., 2019, ICLR WORKSHOP DEBUGG, DOI [10.18653/v1/.D17-2021, DOI 10.18653/V1/.D17-2021]
   Biggs J, 2014, Evaluating the Quality of Learning: The SOLO Taxonomy (Structure of the Observed Learning Outcome)
   Bloem Peter., 2019, Transformers from Scratch
   Brasoveanu AMP, 2020, IEEE INT CONF INF VI, P270, DOI 10.1109/IV51561.2020.00051
   Bruce G. S., 2004, Evidence-Based Educational Methods, Educational Psychology, P267, DOI [10.1016/B978-012506041-7/50016-4, DOI 10.1016/B978-012506041-7/50016-4]
   CodeEmporium, 2022, Transformer neural networks - explained! (attention is all you need)
   Coenen A, 2019, Arxiv, DOI arXiv:1906.02715
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Endert A, 2017, COMPUT GRAPH FORUM, V36, P458, DOI 10.1111/cgf.13092
   DeRose JF, 2020, Arxiv, DOI arXiv:2009.07053
   Guan Chaoyu, 2019, INT C MACH LEARN, P2454
   Gunning D., 2016, Explainable Artificial Intelligence
   H. NLP, 2018, The annotated transformer
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hundhausen CD, 2002, J VISUAL LANG COMPUT, V13, P259, DOI 10.1006/S1045-926X(02)00028-9
   Jin ZH, 2024, IEEE T VIS COMPUT GR, V30, P3594, DOI 10.1109/TVCG.2023.3236380
   Kahng M., 2019, IEEE VIS 2019 WORKSH
   Kahng M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P266, DOI 10.1109/VIS47514.2020.00060
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Li Yixuan, 2023, IEEE Trans Vis Comput Graph, V29, P95, DOI 10.1109/TVCG.2022.3209461
   Li Z, 2022, Arxiv, DOI [arXiv:2206.09355, 10.48550/ARXIV.2206.09355, DOI 10.48550/ARXIV.2206.09355]
   Lin T., 2022, AI open, DOI [DOI 10.1016/J.AIOPEN.2022.10.001, 10.1016/j.aiopen.2022.10.001, 10.1016/J.AIOPEN.2022.10.001]
   Liu DY, 2018, Arxiv, DOI [arXiv:1808.08531, 10.48550/ARXIV.1808.08531, DOI 10.48550/ARXIV.1808.08531]
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, Arxiv, DOI arXiv:1702.01226
   Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727
   McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, 10.48550/arXiv.1511.08458]
   Olah C., 2020, Olah's blogs
   Ouyang L, 2022, ADV NEUR IN
   Radford A., 2019, Language models are unsupervised multitask learners, V1, P9
   Radford Alec., 2018, Improving language understanding by generative pre-training
   Seifert C, 2017, STUD BIG DATA, V32, P123, DOI 10.1007/978-3-319-54024-5_6
   Shao ZK, 2024, IEEE T VIS COMPUT GR, V30, P3779, DOI 10.1109/TVCG.2023.3243676
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Skrlj B, 2020, Arxiv, DOI arXiv:2005.05716
   Smilkov D, 2017, Arxiv, DOI arXiv:1708.03788
   Strobelt H, 2017, Arxiv, DOI arXiv:1606.07461
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang JH, 2023, IEEE T VIS COMPUT GR, V29, P5033, DOI 10.1109/TVCG.2022.3201101
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang Z. J., 2021, CORR
   Wang ZJ, 2021, IEEE T VIS COMPUT GR, V27, P1396, DOI 10.1109/TVCG.2020.3030418
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2018, IEEE T VIS COMPUT GR, V24, P236, DOI 10.1109/TVCG.2017.2744098
   Yang ZL, 2019, ADV NEUR IN, V32
   Yosinski J, 2015, Arxiv, DOI arXiv:1506.06579
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yuan J, 2020, Arxiv, DOI [arXiv:2008.09632, 10.48550/ARXIV.2008.09632, DOI 10.48550/ARXIV.2008.09632]
   Zhao Yuheng, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579473
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
NR 62
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 891
EP 901
DI 10.1109/TVCG.2023.3327353
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500097
PM 37883278
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Atzberger, D
   Cech, T
   Trapp, M
   Richter, R
   Scheibel, W
   Döllner, J
   Schreck, T
AF Atzberger, Daniel
   Cech, Tim
   Trapp, Matthias
   Richter, Rico
   Scheibel, Willy
   Doellner, Jurgen
   Schreck, Tobias
TI Large-Scale Evaluation of Topic Models and Dimensionality Reduction
   Methods for 2D Text Spatialization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimensionality reduction; Measurement; Visualization; Analytical models;
   Computational modeling; Layout; Semantics; Text visualization;
   spatialization; dimensionality reduction algorithms; topic modeling
ID VISUALIZATION; VIEWS
AB Topic models are a class of unsupervised learning algorithms for detecting the semantic structure within a text corpus. Together with a subsequent dimensionality reduction algorithm, topic models can be used for deriving spatializations for text corpora as two-dimensional scatter plots, reflecting semantic similarity between the documents and supporting corpus analysis. Although the choice of the topic model, the dimensionality reduction, and their underlying hyperparameters significantly impact the resulting layout, it is unknown which particular combinations result in high-quality layouts with respect to accuracy and perception metrics. To investigate the effectiveness of topic models and dimensionality reduction methods for the spatialization of corpora as two-dimensional scatter plots (or basis for landscape-type visualizations), we present a large-scale, benchmark-based computational evaluation. Our evaluation consists of (1) a set of corpora, (2) a set of layout algorithms that are combinations of topic models and dimensionality reductions, and (3) quality metrics for quantifying the resulting layout. The corpora are given as document-term matrices, and each document is assigned to a thematic class. The chosen metrics quantify the preservation of local and global properties and the perceptual effectiveness of the two-dimensional scatter plots. By evaluating the benchmark on a computing cluster, we derived a multivariate dataset with over 45 000 individual layouts and corresponding quality metrics. Based on the results, we propose guidelines for the effective design of text spatializations that are based on topic models and dimensionality reductions. As a main result, we show that interpretable topic models are beneficial for capturing the structure of text corpora. We furthermore recommend the use of t-SNE as a subsequent dimensionality reduction.
C1 [Atzberger, Daniel; Trapp, Matthias; Scheibel, Willy] Univ Potsdam, Hasso Plattner Inst, Digital Engn Fac, Potsdam, Germany.
   [Cech, Tim; Richter, Rico; Doellner, Jurgen] Univ Potsdam, Digital Engn Fac, Potsdam, Germany.
   [Schreck, Tobias] Graz Univ Technol, Graz, Austria.
C3 University of Potsdam; University of Potsdam; Graz University of
   Technology
RP Atzberger, D (corresponding author), Univ Potsdam, Hasso Plattner Inst, Digital Engn Fac, Potsdam, Germany.
EM daniel.atzberger@hpi.uni-potsdam.de; tcech@uni-potsdam.de;
   matthias.trapp@hpi.uni-potsdam.de; rico.richter.1@uni-potsdam.de;
   willy.scheibel@hpi.uni-potsdam.de; doellner@uni-potsdam.de;
   tobias.schreck@cgv.tugraz.at
RI Scheibel, Willy/AAF-5883-2021; Trapp, Matthias/J-4456-2014
OI Scheibel, Willy/0000-0002-7885-9857; Schreck,
   Tobias/0000-0003-0778-8665; Dollner, Jurgen/0000-0002-8981-8583; Cech,
   Tim/0000-0001-8688-2419
FU Federal Ministry of Education and Research, Germany
FX No Statement Available
CR Adam SP, 2019, SPRINGER OPTIM APPL, V145, P57, DOI 10.1007/978-3-030-12767-1_5
   Aggarwal CC, 2012, Mining text data, DOI [10.1007/978-1-4614-3223-4, DOI 10.1007/978-1-4614-3223-4]
   Aggarwal CharuC., 2012, MINING TEXT DATA, DOI [DOI 10.1007/978-1-4614-3223-46, 10.1007/978-1-4614-3223-4_6]
   Albuquerque G., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P13, DOI 10.1109/VAST.2011.6102437
   Alexander E, 2016, IEEE T VIS COMPUT GR, V22, P320, DOI 10.1109/TVCG.2015.2467618
   Appleby G, 2022, COMPUT GRAPH FORUM, V41, P169, DOI 10.1111/cgf.14531
   Atzberger D., 2022, PROC 15 INT S VISUAL, DOI DOI 10.1145/3554944.3554961
   Atzberger D, 2022, IEEE INT WORK C SO, P143, DOI 10.1109/SCAM55253.2022.00021
   Atzberger D, 2022, VISIGRAPP, P210, DOI 10.5220/0010991100003124
   Atzberger D, 2021, IVAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 3: IVAPP, P112, DOI 10.5220/0010267601120122
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Caillou P, 2021, IEEE COMPUT GRAPH, V41, P76, DOI 10.1109/MCG.2020.3033401
   Calinski T., 1974, Commun. Stat. Theory Methods, V3, P1, DOI 10.1080/03610927408827101
   Chen TH, 2016, EMPIR SOFTW ENG, V21, P1843, DOI 10.1007/s10664-015-9402-8
   Chen YH, 2009, IEEE T VIS COMPUT GR, V15, P1161, DOI 10.1109/TVCG.2009.140
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Cox M. A., 2008, Handbook of data visualization, P315, DOI DOI 10.1007/978-3-540-33037-014
   Crain S.P., 2012, Mining Text Data, P129, DOI [10.1007/978-1-4614-3223-4_52,4, DOI 10.1007/978-1-4614-3223-4_52,4]
   Cunningham JP, 2015, J MACH LEARN RES, V16, P2859
   Dang T., 2019, PROC EUROPEAN C VISU, P103, DOI DOI 10.2312/EVS.20191178
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dou WW, 2013, IEEE T VIS COMPUT GR, V19, P2002, DOI 10.1109/TVCG.2013.162
   Engel D., 2012, VISUALIZATION LARGE, DOI [DOI 10.4230/OASICS.VLUDS.2011.135, 10.4230/OASIcs.VLUDS.2011.1352, DOI 10.4230/OASICS.VLUDS.2011.1352]
   Espadoto M., 2020, PROC WORKSHOP GAP VI, P9, DOI DOI 10.2312/VISGAP20201105
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fodor I. K., 2002, Technical Report UCRL-ID-148494, P2
   Fried D, 2014, IEEE PAC VIS SYMP, P113, DOI 10.1109/PacificVis.2014.47
   Fujiwara T, 2022, IEEE T VIS COMPUT GR, V28, P758, DOI 10.1109/TVCG.2021.3114807
   Gansner Emden R., 2013, Journal of Graph Algorithms and Applications, V17, P515, DOI 10.7155/jgaa.00302
   Garcia Fernandez F. J., 2013, PROC WORKSHOP VISUAL, DOI DOI 10.2312/PE.VAMP.VAMP2013.005-009
   Gisbrecht A, 2015, WIRES DATA MIN KNOWL, V5, P51, DOI 10.1002/widm.1147
   Hogräfer M, 2020, COMPUT GRAPH FORUM, V39, P647, DOI 10.1111/cgf.14031
   Ingram S, 2015, NEUROCOMPUTING, V150, P557, DOI 10.1016/j.neucom.2014.07.073
   Joia P, 2011, IEEE T VIS COMPUT GR, V17, P2563, DOI 10.1109/TVCG.2011.220
   Jolliffe I., 2022, Principal Component Analysis, P150, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1007/0-387-22440-87, 10.1007/b98835]
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Kohonen T, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, pPL1, DOI 10.1109/ICNN.1997.611622
   Kucher K., 2019, PROC EUROPEAN C VISU, P29, DOI DOI 10.2312/EURP.20191138
   Kucher K., 2018, PROC 11 INT S VISUAL, P97, DOI [DOI 10.1145/3231622.3231641, 10.1145/3231622.3231641.19,20, DOI 10.1145/3231622.3231641.19,20]
   Kuhn A, 2010, J SOFTW MAINT EVOL-R, V22, P191, DOI 10.1002/smr.414
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lehmann DJ, 2016, IEEE T VIS COMPUT GR, V22, P609, DOI 10.1109/TVCG.2015.2467132
   Linstead E, 2009, DATA MIN KNOWL DISC, V18, P300, DOI 10.1007/s10618-008-0118-x
   Lipton Z. C., 2018, Queue, V16, P31, DOI [10.1145/3236386.3241340, DOI 10.1145/3236386.3241340]
   Machado A., 2023, EUROVIS WORKSHOP VIS, DOI DOI 10.2312/EUROVA.202310889
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Melka J, 2019, STUD COMPUT INTELL, V829, P139, DOI 10.1007/978-3-030-16469-0_8
   Mishra S, 2020, Arxiv, DOI arXiv:2008.03964
   Morariu Cristina, 2023, IEEE Trans Vis Comput Graph, V29, P745, DOI 10.1109/TVCG.2022.3209449
   Nenkova A., 2012, Mining Text Data, P43, DOI 10.1007/978-1-4614-3223-4_3
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pandey AV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3659, DOI 10.1145/2858036.2858155
   Paulovich FV, 2006, INFORMATION VISUALIZATION-BOOK, P245
   Peter J, 2015, IEEE CONF VIS ANAL, P207, DOI 10.1109/VAST.2015.7347681
   Riehmann P, 2019, IEEE T VIS COMPUT GR, V25, P1803, DOI 10.1109/TVCG.2018.2824822
   Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sedlmair M, 2015, COMPUT GRAPH FORUM, V34, P201, DOI 10.1111/cgf.12632
   Sedlmair M, 2013, IEEE T VIS COMPUT GR, V19, P2634, DOI 10.1109/TVCG.2013.153
   Sievert C., 2014, P WORKSH INT LANG LE, P63, DOI [DOI 10.3115/V1/W14-3110, 10.3115/v1/W14-3110, DOI 10.1109/DSAA.2017.61]
   Sips M, 2009, COMPUT GRAPH FORUM, V28, P831, DOI 10.1111/j.1467-8659.2009.01467.x
   Skupin A, 2004, P NATL ACAD SCI USA, V101, P5274, DOI 10.1073/pnas.0307654100
   van der Maaten L., 2009, Technical Report 009-005, P2
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venna J., 2006, P ESANN, V6, P557
   Vernier EF, 2021, COMPUT GRAPH FORUM, V40, P87, DOI 10.1111/cgf.14291
   Vernier EF, 2020, COMPUT GRAPH FORUM, V39, P241, DOI 10.1111/cgf.13977
   Wallach H., 2009, Advances in neural information processing systems, V22, P1973
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1828, DOI 10.1109/TVCG.2017.2701829
   Wilkinson L, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P157, DOI 10.1109/INFVIS.2005.1532142
   Wilkinson L, 2006, IEEE T VIS COMPUT GR, V12, P1363, DOI 10.1109/TVCG.2006.94
   Xia Jiazhi, 2023, IEEE Trans Vis Comput Graph, V29, P734, DOI 10.1109/TVCG.2022.3209423
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xia JZ, 2021, IEEE COMPUT GRAPH, V41, P79, DOI 10.1109/MCG.2021.3098804
   Xu PP, 2013, IEEE T VIS COMPUT GR, V19, P2012, DOI 10.1109/TVCG.2013.221
   Yan YY, 2019, IEEE PAC VIS SYMP, P148, DOI 10.1109/PacificVis.2019.00025
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
NR 81
TC 3
Z9 3
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 902
EP 912
DI 10.1109/TVCG.2023.3326569
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500044
PM 37871085
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bae, SS
   Fujiwara, T
   Ynnerman, A
   Do, EYL
   Rivera, ML
   Szafir, DA
AF Bae, S. Sandra
   Fujiwara, Takanori
   Ynnerman, Anders
   Do, Ellen Yi-Luen
   Rivera, Michael L.
   Szafir, Danielle Albers
TI A Computational Design Pipeline to Fabricate Sensing Network
   Physicalizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Physicalization; tangible interfaces; 3D printing; computational
   fabrication; design automation; network data
ID INTERACTIVE VISUALIZATION; EXPLORATION; PROVENANCE; MODELS
AB Interaction is critical for data analysis and sensemaking. However, designing interactive physicalizations is challenging as it requires cross-disciplinary knowledge in visualization, fabrication, and electronics. Interactive physicalizations are typically produced in an unstructured manner, resulting in unique solutions for a specific dataset, problem, or interaction that cannot be easily extended or adapted to new scenarios or future physicalizations. To mitigate these challenges, we introduce a computational design pipeline to 3D print network physicalizations with integrated sensing capabilities. Networks are ubiquitous, yet their complex geometry also requires significant engineering considerations to provide intuitive, effective interactions for exploration. Using our pipeline, designers can readily produce network physicalizations supporting selection-the most critical atomic operation for interaction-by touch through capacitive sensing and computational inference. Our computational design pipeline introduces a new design paradigm by concurrently considering the form and interactivity of a physicalization into one cohesive fabrication workflow. We evaluate our approach using (i) computational evaluations, (ii) three usage scenarios focusing on general visualization tasks, and (iii) expert interviews. The design paradigm introduced by our pipeline can lower barriers to physicalization research, creation, and adoption.
C1 [Bae, S. Sandra; Do, Ellen Yi-Luen; Rivera, Michael L.] Univ Colorado, Boulder, CO 80309 USA.
   [Fujiwara, Takanori; Ynnerman, Anders] Linkoping Univ, Linkoping, Sweden.
   [Szafir, Danielle Albers] Univ North Carolina Chapel Hill, Chapel Hill, NC USA.
C3 University of Colorado System; University of Colorado Boulder; Linkoping
   University; University of North Carolina; University of North Carolina
   Chapel Hill; University of North Carolina School of Medicine
RP Bae, SS (corresponding author), Univ Colorado, Boulder, CO 80309 USA.
EM sandra.bae@colorado.edu; takanori.fujiwara@liu.se;
   anders.ynnerman@liu.se; ellen.do@colorado.edu; mrivera@colorado.edu;
   danielle.szafir@cs.unc.edu
RI Do, Ellen Yi-Luen/B-3621-2009
OI Ynnerman, Anders/0000-0002-9466-9826; Bae, Sandra/0000-0002-2023-6219;
   Rivera, Michael/0000-0002-5998-8039; Do, Ellen
   Yi-Luen/0000-0002-9948-6375
FU U.S. National Science Foundation
FX No Statement Available
CR Ahmed R, 2022, IEEE T VIS COMPUT GR, V28, P2388, DOI 10.1109/TVCG.2022.3155564
   Allahverdi K, 2018, COMPUT GRAPH FORUM, V37, P439, DOI 10.1111/cgf.13432
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Ang KD, 2019, COMPUT GRAPH-UK, V85, P42, DOI 10.1016/j.cag.2019.09.004
   [Anonymous], 2023, Supplemental Material
   Arduino, 2023, Arduino Documentation
   Bae SS, 2023, IEEE T VIS COMPUT GR, V29, P257, DOI 10.1109/TVCG.2022.3209442
   Bae SS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501939
   Barabasi AL, 2016, NETWORK SCIENCE, P1
   Bennett C., 2007, P EUR C COMP AESTH G, P57, DOI [10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Besançon L, 2021, COMPUT GRAPH FORUM, V40, P293, DOI 10.1111/cgf.14189
   Besancon L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4727, DOI 10.1145/3025453.3025863
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brown R., 2003, Phys Teach, V41, P483, DOI [10.1119/1.1625209, DOI 10.1119/1.1625209]
   Burstyn J, 2015, LECT NOTES COMPUT SC, V9296, P332, DOI 10.1007/978-3-319-22701-6_25
   Cohen J. S., 2003, Computer Algebra and Symbolic Computation: Mathematical Methods, DOI [10.1201/9781439863701, DOI 10.1201/9781439863701]
   Daneshzand Foroozan, 2023, IEEE Trans Vis Comput Graph, V29, P225, DOI 10.1109/TVCG.2022.3209365
   Davidson S., 2023, Grasshopper - algorithmic modeling for Rhino
   de Freitas AA, 2022, IEEE INT CONF INF VI, P73, DOI 10.1109/IV56949.2022.00021
   Dehmamy N, 2018, NATURE, V563, P676, DOI 10.1038/s41586-018-0726-6
   Dijkshoorn A, 2020, IEEE SENS J, V20, P14218, DOI 10.1109/JSEN.2020.3007249
   Djavaherpour H, 2021, COMPUT GRAPH FORUM, V40, P569, DOI 10.1111/cgf.14330
   Drogemuller A., 2021, P 2021 CHI C HUMAN F, DOI 10.1145/3411764.3445704
   ESD Association, 2020, Fundamentals of electrostatic discharge: Part fivedevice sensitivity and testing
   FOLEY JD, 1984, IEEE COMPUT GRAPH, V4, P13, DOI 10.1109/MCG.1984.6429355
   Freksa C, 2019, SPAT COGN COMPUT, V19, P46, DOI 10.1080/13875868.2018.1531415
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P418, DOI 10.1109/TVCG.2019.2934433
   Fujiwara T, 2018, VIS INFORM, V2, P213, DOI 10.1016/j.visinf.2018.12.002
   FURER M, 1992, PROCEEDINGS OF THE THIRD ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P317
   García IL, 2021, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION, TEI 2021, DOI 10.1145/3430524.3440627
   Gerber S, 2010, IEEE T VIS COMPUT GR, V16, P1271, DOI 10.1109/TVCG.2010.213
   Grabkowska D., 2023, What Made Me
   Grosse-Puppendahl T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3293, DOI 10.1145/3025453.3025808
   Hagberg A., 2008, P 7 PYTH SCI C
   Hayes M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.875
   He L, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3495000
   Herman Bridger, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488542
   Hermann T., 1999, Advances in Intelligent Computing and Multimedia Systems, P189
   Hu Guosheng, 2022, 2022 8th International Conference on Virtual Reality (ICVR), P126, DOI 10.1109/ICVR55215.2022.9847779
   Huang HH, 2023, INFORM VISUAL, V22, P169, DOI 10.1177/14738716231157082
   Huang YJ, 2017, IEEE PAC VIS SYMP, P41, DOI 10.1109/PACIFICVIS.2017.8031577
   Huron Samuel, 2014, P 2014 C DES INT SYS, P433, DOI [DOI 10.1145/2598510.2598566, DOI 10.1145/ONDESIGNINGINTERACTIVESYSTEMS(DIS'2598510.2598566]
   Hurtienne J, 2020, IEEE COMPUT GRAPH, V40, P61, DOI 10.1109/MCG.2020.3025385
   iSANMATE, 2014, Wood filament PLA+, P1733, DOI [10.1145/2556288.2557046, DOI 10.1145/2556288.2557046]
   Ishiguro Y, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1733, DOI 10.1145/2556288.2557046
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jansen Y., 2013, P SIGCHI C HUMAN FAC, DOI [10.1145/2470654, DOI 10.1145/2470654.24813591,2,3,6,11]
   Jin YH, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P701, DOI 10.1145/3332165.3347905
   Kelly JW, 2011, PSYCHON B REV, V18, P1119, DOI 10.3758/s13423-011-0162-1
   Kerren A, 2014, LECT NOTES COMPUT SC, V8380, P1, DOI 10.1007/978-3-319-06793-3_1
   Le Goc M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/2984511.2984547
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   McGuffin M. J., 2023, IEEE Trans Vis Comput Graph, P1
   Meurer A, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.103
   Newman M., 2018, Networks, V2nd ed.
   Ngo TD, 2018, COMPOS PART B-ENG, V143, P172, DOI 10.1016/j.compositesb.2018.02.012
   Noren L., 2011, Infographics inspire art | R. Justin Stewart
   Paszke A, 2019, ADV NEUR IN, V32
   Patnaik B, 2023, IEEE T VIS COMPUT GR, V29, P5282, DOI 10.1109/TVCG.2022.3209631
   Peixoto T. P., 2020, NETZSCHLEUDER NETWOR
   Peixoto Tiago P, 2017, Figshare
   ProtoPasta, 2023, Conductive PLA
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Robert McNeel & Associates, 2023, Rhinoceros
   Roberts JC, 2014, IEEE COMPUT GRAPH, V34, P26, DOI 10.1109/MCG.2014.82
   Rosling H., 2014, Global population growth, box by box
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savage V., 2014, PROC UIST, P3, DOI DOI 10.1145/2642918.2647374
   Schmitz M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300684
   Schmitz M, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P253, DOI 10.1145/2807442.2807503
   Schönborn KJ, 2016, SCI POL REP, P195, DOI 10.1007/978-3-319-31833-2_7
   Shervashidze Nino, 2009, Artificial intelligence and statistics, P488
   Soh WS, 2009, APMC: 2009 ASIA PACIFIC MICROWAVE CONFERENCE, VOLS 1-5, P1285, DOI 10.1109/APMC.2009.5384455
   Stusak S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3247, DOI 10.1145/2702123.2702248
   Stusak S, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P92, DOI 10.1145/2839462.2839476
   Stusak S, 2014, IEEE T VIS COMPUT GR, V20, P2201, DOI 10.1109/TVCG.2014.2352953
   Swaminathan S, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3845, DOI 10.1145/2556288.2557310
   Taher F, 2017, IEEE T VIS COMPUT GR, V23, P451, DOI 10.1109/TVCG.2016.2598498
   Thrun M. C., 2016, INT C CENTR EUR COMP, P7
   Tuinenga P.W., 1995, SPICE: A Guide to Circuit Simulation and Analysis Using PSpice, V3rd
   Vasquez J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376425
   Verhulsdonck G, 2007, SIGDOC'07: PROCEEDINGS OF THE 25TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P26
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Weller MichaelPhiletus., 2008, Proc. of TEI '08, P39, DOI DOI 10.1145/1347390.1347402
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Willis KDD, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P589
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Ynnerman A, 2018, IEEE COMPUT GRAPH, V38, P13, DOI 10.1109/MCG.2018.032421649
   Ynnerman A, 2016, COMMUN ACM, V59, P72, DOI 10.1145/2950040
NR 94
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 913
EP 923
DI 10.1109/TVCG.2023.3327198
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500062
PM 37906495
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Nowak, S
   Bartram, L
AF Nowak, Stan
   Bartram, Lyn
TI Designing for Ambiguity in Visual Analytics: Lessons from Risk
   Assessment and Prediction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Forecasting; Hazards; Data visualization; Risk
   management; Uncertainty; Task analysis; Complex Systems; Risk
   Assessment; Sensemaking; Visualization Design
ID VISUALIZATION; UNCERTAINTY; TYPOLOGY; ELEMENTS; MODEL
AB Ambiguity is pervasive in the complex sensemaking domains of risk assessment and prediction but there remains little research on how to design visual analytics tools to accommodate it. We report on findings from a qualitative study based on a conceptual framework of sensemaking processes to investigate how both new visual analytics designs and existing tools, primarily data tables, support the cognitive work demanded in avalanche forecasting. While both systems yielded similar analytic outcomes we observed differences in ambiguous sensemaking and the analytic actions either afforded. Our findings challenge conventional visualization design guidance in both perceptual and interaction design, highlighting the need for data interfaces that encourage reflection, provoke alternative interpretations, and support the inherently ambiguous nature of sensemaking in this critical application. We review how different visual and interactive forms support or impede analytic processes and introduce "gisting" as a significant yet unexplored analytic action for visual analytics research. We conclude with design implications for enabling ambiguity in visual analytics tools to scaffold sensemaking in risk assessment.
C1 [Nowak, Stan; Bartram, Lyn] Simon Fraser Univ, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Nowak, S (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM snowak@sfu.ca; lyn@sfu.ca
FU Mitacs
FX No Statement Available
CR Adams L., 2005, A systems approach to human factors and expert decisionmaking within the Canadian avalanche phenomena, P2
   Andrienko N, 2018, COMPUT GRAPH FORUM, V37, P275, DOI 10.1111/cgf.13324
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Beven K. J., 2018, Natural Hazards and Earth System Sciences,, DOI [10. 5194/nhess-2017-250 2, DOI 10.5194/NHESS-2017-2502]
   Borgo R., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Boukhelifa N, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3645, DOI 10.1145/3025453.3025738
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Canadian Avalanche Association, 1995, Observation guidelines and recording standards for weather, snowpack and avalanches, P2
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Crandall B., 2006, Working Minds: A Practitioner's Guide to Cognitive Task Analysis, P4
   Elfenbein A., 2018, The Gist of Reading, V2, P5
   Gamino JF, 2010, FRONT PSYCHOL, V1, DOI 10.3389/fpsyg.2010.00188
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Grabowski Franciszek, 2008, 2008 Conference on Human System Interactions, P570, DOI 10.1109/HSI.2008.4581503
   Haegeli P., 2018, Alpine Club of Canada's State of the Mountains Report, V1, P2
   Haegeli P., 2014, Proceedings of the 2014 International Snow Science Workshop, P910
   Heer J, 2007, IEEE CONF VIS ANAL, P171, DOI 10.1109/VAST.2007.4389011
   Hoffman RR, 2017, MINDING THE WEATHER: HOW EXPERT FORECASTERS THINK, P1
   Hollnagel E., 2005, Joint Cognitive Systems: Foundations of Cognitive Systems Engineering, P2
   Hoque E, 2018, IEEE T VIS COMPUT GR, V24, P309, DOI 10.1109/TVCG.2017.2744684
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Johansen IL, 2015, SAFETY SCI, V80, P243, DOI 10.1016/j.ssci.2015.07.028
   Ju Y, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00738
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kirsh D, 2010, AI SOC, V25, P441, DOI 10.1007/s00146-010-0272-8
   Klein G, 1999, HUM FAC ERG SOC P, P133
   Klein G., 2007, EXPERTISE OUT CONTEX, P118
   Klein G., 2005, COGN TECHNOL WORK, V7, P14, DOI [10.1007/s10111-004-0166-y2, DOI 10.1007/S10111-004-0166-Y2]
   Klein G., 2018, Local Applications of the Ecological Approach to Human-Machine Systems, V2, P324
   Klein G, 2006, IEEE INTELL SYST, V21, P88, DOI 10.1109/MIS.2006.100
   Klein G, 2011, INFORMED BY KNOWLEDGE: EXPERT PERFORMANCE IN COMPLEX SITUATIONS, P235
   LACHAPELLE ER, 1980, J GLACIOL, V26, P75, DOI 10.3189/S0022143000010601
   Lin HH, 2023, IEEE T VIS COMPUT GR, V29, P504, DOI 10.1109/TVCG.2022.3209451
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   MacEachren A.M., 2015, EuroVis Workshop on Visual Analytics (EuroVA), DOI DOI 10.2312/EUROVA.20151104
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   Maitlis S, 2014, ACAD MANAG ANN, V8, P57, DOI 10.1080/19416520.2014.873177
   McClung DM, 2002, NAT HAZARDS, V26, P111, DOI 10.1023/A:1015665432221
   McClung DM, 2002, NAT HAZARDS, V26, P131, DOI 10.1023/A:1015604600361
   McCurdy N, 2019, IEEE T VIS COMPUT GR, V25, P925, DOI 10.1109/TVCG.2018.2864913
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Munzner T., 2014, Visualization Analysis and Design, P3
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Nowak S., 2022, Graphics Interface, V1
   Nowak S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P81, DOI 10.1109/VIS47514.2020.00023
   Panagiotidou G, 2022, IEEE T VIS COMPUT GR, V28, P4389, DOI 10.1109/TVCG.2021.3088339
   Pirolli P, 2005, SENSEMAKING PROCESS
   Pliske R. M., 2004, Psychological investigations of competence in decision making, V40, P2
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rind A, 2016, INFORM VISUAL, V15, P288, DOI 10.1177/1473871615621602
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Saraiya P, 2006, IEEE T VIS COMPUT GR, V12, P1511, DOI 10.1109/TVCG.2006.85
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shrinivasan YB, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1237
   Smith P. J., 2017, Cognitive Systems Engineering: The Future for a Changing World, P2
   Smuc M, 2009, IEEE COMPUT GRAPH, V29, P29, DOI 10.1109/MCG.2009.53
   Statham G., 2010, INT SNOW SCI WORKSHO, P7
   Statham G., 2018, INT SNOW SCI WORKSHO, P1491
   Statham G, 2018, NAT HAZARDS, V90, P663, DOI 10.1007/s11069-017-3070-5
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Thomson J, 2005, P SOC PHOTO-OPT INS, V5669, P146, DOI 10.1117/12.587254
   Walny J, 2018, IEEE T VIS COMPUT GR, V24, P770, DOI 10.1109/TVCG.2017.2745958
   Ware C., 2022, Visual Thinking for Information Design, P2
   Weick K. E., 1995, Sensemaking in organizations, V3
   Zuk T, 2007, LECT NOTES COMPUT SC, V4569, P164
NR 66
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 924
EP 933
DI 10.1109/TVCG.2023.3326571
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500023
PM 37871061
DA 2024-11-06
ER

PT J
AU Kim, H
   Rossi, R
   Hullman, J
   Hoffswell, J
AF Kim, Hyeok
   Rossi, Ryan
   Hullman, Jessica
   Hoffswell, Jane
TI Dupo: A Mixed-Initiative Authoring Tool for Responsive Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; responsive visualization; mixed-initiative authoring
AB Designing responsive visualizations for various screen types can be tedious as authors must manage multiple chart versions across design iterations. Automated approaches for responsive visualization must take into account the user's need for agency in exploring possible design ideas and applying customizations based on their own goals. We design and implement Dupo, a mixedinitiative approach to creating responsive visualizations that combines the agency afforded by a manual interface with automation provided by a recommender system. Given an initial design, users can browse automated design suggestions for a different screen type and make edits to a chosen design, thereby supporting quick prototyping and customizability. Dupo employs a two-step recommender pipeline that first suggests significant design changes (Exploration) followed by more subtle changes (Alteration). We evaluated Dupo with six expert responsive visualization authors. While creating responsive versions of a source design in Dupo, participants could reason about different design suggestions without having to manually prototype them, and thus avoid prematurely fixating on a particular design. This process led participants to create designs that they were satisfied with but which they had previously overlooked.
C1 [Kim, Hyeok; Hullman, Jessica] Northwestern Univ, Skokie, IL 60208 USA.
   [Rossi, Ryan; Hoffswell, Jane] Adobe Res, Washington, DC USA.
C3 Northwestern University; Adobe Systems Inc.
RP Kim, H (corresponding author), Northwestern Univ, Skokie, IL 60208 USA.
EM hyeok@northwestern.edu; rrossi@adobe.com; jhullman@northwestern.edu;
   jhoffs@adobe.com
RI Hullman, Jessica/P-7130-2018; Rossi, Ryan/C-7974-2013
OI Hoffswell, Jane/0000-0002-9871-4575; Hullman,
   Jessica/0000-0001-6826-3550; Rossi, Ryan/0000-0001-9758-0635
CR Andrews K., 2018, MOBILEVIS 18 WORKSH
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Cook K, 2015, IEEE CONF VIS ANAL, P9, DOI 10.1109/VAST.2015.7347625
   Cui WW, 2022, IEEE T VIS COMPUT GR, V28, P173, DOI 10.1109/TVCG.2021.3114856
   Datawrapper GmbH, 2013, Datawrapper
   Di Giacomo E., 2015, P IISA, P1, DOI [DOI 10.1109/IISA.2015.73880951,2, 10.1109/IISA.2015.7388095, DOI 10.1109/IISA.2015.7388095]
   Ellis G, 2006, IEEE T VIS COMPUT GR, V12, P717, DOI 10.1109/TVCG.2006.138
   Elmqvist N, 2010, IEEE T VIS COMPUT GR, V16, P439, DOI 10.1109/TVCG.2009.84
   Flourish, About us
   Gebser M, 2014, Arxiv, DOI arXiv:1405.3694
   Gebser M, 2011, AI COMMUN, V24, P107, DOI 10.3233/AIC-2011-0491
   GitHub, Copilot
   Harper Jonathan, 2014, UIST 2014 P 27 ANN A, DOI [DOI 10.1145/2642918.26474117,8, 10.1145/2642918.2647411, DOI 10.1145/2642918.2647411]
   Healey CG, 2008, IEEE T VIS COMPUT GR, V14, P396, DOI 10.1109/TVCG.2007.70436
   Hinderman B., 2015, Building Responsive Data Visualization for the Web, P1
   Hoffswell J., 2020, P CHI, P1, DOI [10.1145/3313831.33767771,2,3,4,5, DOI 10.1145/3313831.33767771,2,3,4,5]
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P129, DOI 10.1109/TVCG.2021.3114782
   Kim H, 2021, COMPUT GRAPH FORUM, V40, P459, DOI 10.1111/cgf.14321
   Kolodner J. L., 1996, Design Studies, V17, P385, DOI 10.1016/S0142-694X(96)00021-X
   Kolodner J. L., 1993, Technical Report SS-93-01, P2
   Korner C., 2016, Learning Responsive Data Visualization, P1
   Leclaire J., 2015, WORKSH DAT EXPL INT, P16
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   Linsey JS, 2010, J MECH DESIGN, V132, DOI 10.1115/1.4001110
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Microsoft, 2011, Power bi
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Qu ZN, 2018, IEEE T VIS COMPUT GR, V24, P468, DOI 10.1109/TVCG.2017.2744198
   Ramirez S., FastAPI
   rollingstone, US
   Rosenbaum R, 2012, IEEE PAC VIS SYMP, P25, DOI 10.1109/PacificVis.2012.6183570
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Svelte, About us
   Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593
   Tableau Software, 2003, Tableu
   Tse A., 2011, ai2html
   Wall E, 2018, IEEE T VIS COMPUT GR, V24, P288, DOI 10.1109/TVCG.2017.2745078
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445179
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Wu YC, 2013, IEEE T VIS COMPUT GR, V19, P278, DOI 10.1109/TVCG.2012.114
   ZingSoft, 2009, Zingchart
NR 45
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 934
EP 943
DI 10.1109/TVCG.2023.3326583
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500138
PM 37871074
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lin, YN
   Li, HT
   Yang, LN
   Wu, AY
   Qu, HM
AF Lin, Yanna
   Li, Haotian
   Yang, Leni
   Wu, Aoyu
   Qu, Huamin
TI InkSight: Leveraging Sketch Interaction for Documenting Chart Findings
   in Computational Notebooks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Documentation; Data analysis; Visualization; Codes;
   Natural languages; Data models; Computational Notebook; Sketch-based
   Interaction; Exploratory Data Analysis
AB Computational notebooks have become increasingly popular for exploratory data analysis due to their ability to support data exploration and explanation within a single document. Effective documentation for explaining chart findings during the exploration process is essential as it helps recall and share data analysis. However, documenting chart findings remains a challenge due to its time-consuming and tedious nature. While existing automatic methods alleviate some of the burden on users, they often fail to cater to users' specific interests. In response to these limitations, we present InkSight, a mixed-initiative computational notebook plugin that generates finding documentation based on the user's intent. InkSight allows users to express their intent in specific data subsets through sketching atop visualizations intuitively. To facilitate this, we designed two types of sketches, i.e., open-path and closed-path sketch. Upon receiving a user's sketch, InkSight identifies the sketch type and corresponding selected data items. Subsequently, it filters data fact types based on the sketch and selected data items before employing existing automatic data fact recommendation algorithms to infer data facts. Using large language models (GPT-3.5), InkSight converts data facts into effective natural language documentation. Users can conveniently fine-tune the generated documentation within InkSight. A user study with 12 participants demonstrated the usability and effectiveness of InkSight in expressing user intent and facilitating chart finding documentation.
C1 [Lin, Yanna; Li, Haotian; Yang, Leni; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Wu, Aoyu] Harvard Univ, Cambridge, MA USA.
C3 Hong Kong University of Science & Technology; Harvard University
RP Yang, LN (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM ylindg@connect.ust.hk; haotian.li@connect.ust.hk;
   lyangbb@connect.ust.hk; aoyuwu@seas.harvard.edu; huamin@cse.ust.hk
RI wu, au/KLC-5346-2024
OI Yang, Leni/0000-0003-4527-4905; Lin, Yanna/0000-0003-3730-0827
FU HK RGC GRF
FX No Statement Available
CR Achiam J, 2023, GPT 4 TECHNICAL REPO
   Akers D., 2006, P 2006 ANN ACM S US, P33, DOI DOI 10.1145/1166253.1166260
   Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233
   [Anonymous], US
   Browne J., 2011, P 2011 ACM INT C INT, P154, DOI [DOI 10.1145/2076354.20763832,9, 10.1145/2076354.2076383]
   Chao W. O., 2010, P 2010 IEEE INF C PO
   Chattopadhyay S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376729
   Chen X, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174070
   Chen YR, 2022, INT CONF MANAGE DATA, P1711, DOI 10.1145/3514221.3526166
   Chen Z., 2022, P 2022 CHI C HUM FAC, DOI DOI 10.1145/3491102.35174853
   Choi J, 2022, IEEE VIS CONF, P40, DOI 10.1109/VIS54862.2022.00017
   Chung J. J. Y., 2022, P 2022 CHI C HUM FAC, P1, DOI [10.1145/3491102.35018192,9, DOI 10.1145/3491102.35018192,9]
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185540
   EPPerson W, 2022, COMPUT GRAPH FORUM, V41, P145, DOI 10.1111/cgf.14529
   Holz C, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P213
   jupyter, Project Jupyter Home
   Kantharaj S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4005
   Kim YS, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P255, DOI 10.1145/3343055.3359714
   Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241
   Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Lee DJL, 2019, PROCEEDINGS OF IUI 2019, P186, DOI 10.1145/3301275.3302307
   Li H., 2023, P 2023 CHI C HUM FAC, DOI DOI 10.1145/3544548.35809651,2,3,8,9
   Li HT, 2023, Arxiv, DOI arXiv:2304.08366
   Lin YN, 2024, IEEE T VIS COMPUT GR, V30, P4108, DOI 10.1109/TVCG.2023.3251344
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Mishra P, 2022, J COMPUT LANG, V69, DOI 10.1016/j.cola.2022.101107
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Obeid J., 2020, P 13 INT C NAT LANG, P2
   online.stat, Interquartile Range (IQR) method.
   Pandey Aditeya, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209421
   platform.openai, GPT-3.5
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Ryall K., 2005, P 2005 CHI C HUM FAC, P1765, DOI [10.1145/1056808.10570172, DOI 10.1145/1056808.10570172]
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Siddiqui T, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P51, DOI 10.1145/3318464.3389722
   Song S., 2023, P 2023 CHI C HUM FAC, P2
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Sutherland I. E., 1963, Sketchpad, a Man-Machine Graphical Communication System, P2
   Tohidi M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1243
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Wang AY, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3489465
   Wang FJ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580753
   Wang Y, 2023, IEEE T VIS COMPUT GR, V29, P1222, DOI 10.1109/TVCG.2022.3209357
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wattenberg M., 2001, P 2001 CHI C HUM FAC, P381, DOI DOI 10.1145/634067.6342922
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851
   Yu BW, 2020, IEEE T VIS COMPUT GR, V26, P1, DOI 10.1109/TVCG.2019.2934668
   Yu CH, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.628832
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zheng CB, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517615
NR 58
TC 3
Z9 3
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 944
EP 954
DI 10.1109/TVCG.2023.3327170
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500133
PM 37878446
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lo, LYH
   Cao, YF
   Yang, LN
   Qu, HM
AF Lo, Leo Yu-Ho
   Cao, Yifan
   Yang, Leni
   Qu, Huamin
TI Why Change My Design: Explaining Poorly Constructed Visualization
   Designs with Explorable Explanations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Best practices; Fake news; Social
   networking (online); Guidelines; Education; Information Visualization;
   Deceptive Visualization; Explorable Explanations
ID GRAPH LITERACY
AB Although visualization tools are widely available and accessible, not everyone knows the best practices and guidelines for creating accurate and honest visual representations of data. Numerous books and articles have been written to expose the misleading potential of poorly constructed charts and teach people how to avoid being deceived by them or making their own mistakes. These readings use various rhetorical devices to explain the concepts to their readers. In our analysis of a collection of books, online materials, and a design workshop, we identified six common explanation methods. To assess the effectiveness of these methods, we conducted two crowdsourced studies (each with $N=125$) to evaluate their ability to teach and persuade people to make design changes. In addition to these existing methods, we brought in the idea of Explorable Explanations, which allows readers to experiment with different chart settings and observe how the changes are reflected in the visualization. While we did not find significant differences across explanation methods, the results of our experiments indicate that, following the exposure to the explanations, the participants showed improved proficiency in identifying deceptive charts and were more receptive to proposed alterations of the visualization design. We discovered that participants were willing to accept more than 60% of the proposed adjustments in the persuasiveness assessment. Nevertheless, we found no significant differences among different explanation methods in convincing participants to accept the modifications.
C1 [Lo, Leo Yu-Ho; Cao, Yifan; Yang, Leni; Qu, Huamin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Lo, LYH (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM yhload@cse.ust.hk; ycaoaw@connect.ust.hk; lyangbb@cse.ust.hk;
   huamin@cse.ust.hk
OI Cao, Yifan/0000-0002-5892-5052; Yang, Leni/0000-0003-4527-4905; Lo, Leo
   Yu Ho/0000-0002-3660-3765
CR Bergstrom C. T., 2021, Random House Trade Paperbacks, V2
   Bergstrom C. T., 2017, Calling Bullshits. Data Reasoning in a Digital World
   Cairo A., 2019, How Charts Lie: Getting Smarter about Visual Information
   Camba JD, 2022, IEEE COMPUT GRAPH, V42, P116, DOI 10.1109/MCG.2021.3132004
   Case N., 2017, The evolution of trust
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Correll M., 2020, P 2020 CHI C HUM FAC, P1
   Correll M., 2017, WORKSH DEAL COGN BIA
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   explorabl, Explorable explanations
   Fan A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502138
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Garcia-Retamero R, 2016, MED DECIS MAKING, V36, P854, DOI 10.1177/0272989X16655334
   Ge LW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581406
   Harford T., 2022, The data detective: Ten easy rules to make sense of statistics, P3
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   Huff D., 1954, How to lie with statistics, V1
   Jones G. E., 1995, How to lie with charts, V2, P3
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Levitin D. J., 2016, A field guide to lies: Critical thinking in the information age, P3
   Lisnic M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580910
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   Lo LYH, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P11, DOI [10.1109/VISUAL.2019.8933751, 10.1109/visual.2019.8933751]
   McKinney W., 2011, Python for high performance and scientific computing, V14, P1
   McNutt A., 2018, VISGUIDES 2 WORKSH C
   McNutt A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376420
   Monmonier M. S., 1991, LIE MAPS
   Muller M., 2014, Ways of Knowing in HCI, P3
   ourworldindata, Charts - our world in data
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Ritchie J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300423
   Stephens-Davidowitz S., 2018, Everybody lies: What the internet can tell us about who we really are, P3
   Szafir D. A., 2018, Interactions, V25, P1
   VanderPlas J., 2018, Journal of Open Source Software, V3, P5
   Victor B., 2011, Explorable explanations
   Wheelan C., 2013, Naked statistics: Stripping the dread from the data, P3
   Zheng W., 2019, Course Project
NR 40
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 955
EP 964
DI 10.1109/TVCG.2023.3327155
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500109
PM 37889814
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wurster, SW
   Xiong, TY
   Shen, HW
   Guo, HQ
   Peterka, T
AF Wurster, Skylar W.
   Xiong, Tianyu
   Shen, Han-Wei
   Guo, Hanqi
   Peterka, Tom
TI Adaptively Placed Multi-Grid Scene Representation Networks for
   Large-Scale Data Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Adaptation models; Data models; Solid modeling; Computer
   architecture; Rendering (computer graphics); Encoding; Scene
   representation network; deep learning; scientific visualization; volume
   rendering
AB Scene representation networks (SRNs) have been recently proposed for compression and visualization of scientific data. However, state-of-the-art SRNs do not adapt the allocation of available network parameters to the complex features found in scientific data, leading to a loss in reconstruction quality. We address this shortcoming with an adaptively placed multi-grid SRN (APMGSRN) and propose a domain decomposition training and inference technique for accelerated parallel training on multi-GPU systems. We also release an open-source neural volume rendering application that allows plug-and-play rendering with any PyTorch-based SRN. Our proposed APMGSRN architecture uses multiple spatially adaptive feature grids that learn where to be placed within the domain to dynamically allocate more neural network resources where error is high in the volume, improving state-of-the-art reconstruction accuracy of SRNs for scientific data without requiring expensive octree refining, pruning, and traversal like previous adaptive models. In our domain decomposition approach for representing large-scale data, we train an set of APMGSRNs in parallel on separate bricks of the volume to reduce training time while avoiding overhead necessary for an out-of-core solution for volumes too large to fit in GPU memory. After training, the lightweight SRNs are used for realtime neural volume rendering in our open-source renderer, where arbitrary view angles and transfer functions can be explored.
C1 [Wurster, Skylar W.] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Wurster, SW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM wurster.18@osu.edu; xiong.336@osu.edu; hwshen@cse.ohio-state.edu;
   guo.2154@osu.edu; tpeterka@mcs.anl.gov
RI Guo, Hanqi/AAL-1929-2021; Shen, Han-wei/A-4710-2012; Guo,
   Hanqi/ADW-4234-2022
OI Guo, Hanqi/0000-0001-7776-1834; Wurster, Skylar/0000-0001-6685-615X
FU US Department of Energy SciDAC program
FX No Statement Available
CR Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Chen AP, 2022, LECT NOTES COMPUT SC, V13692, P333, DOI 10.1007/978-3-031-19824-3_20
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Gu J., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Han J, 2023, IEEE T VIS COMPUT GR, V29, P4951, DOI 10.1109/TVCG.2022.3197203
   Hohlein K., 2022, Vision, Modeling, and Visualization, DOI [10.2312/vmv.202211982, DOI 10.2312/VMV.202211982]
   Kingma D., 2015, P 3 INT C LEARN REPR, P1
   Lee M, 2015, J FLUID MECH, V774, P395, DOI 10.1017/jfm.2015.268
   Li RL, 2022, Arxiv, DOI arXiv:2210.04847
   Li Y, 2008, J TURBUL, V9, P1, DOI 10.1080/14685240802376389
   Liang X, 2023, IEEE T BIG DATA, V9, P485, DOI 10.1109/TBDATA.2022.3201176
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   Martel JNP, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459785
   Mildenhall B., 2020, PROC EUROPEAN C COMP
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Muller T., tiny-cuda-nn
   Paszke A, 2019, ADV NEUR IN, V32
   Perlman E., 2007, PROC ACMIEEE C SUPER, P1
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Sitzmann V., 2020, Proc. NeurIPS
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tancik M., 2020, Advances in Neural Information Processing Systems, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tancik M, 2022, PROC CVPR IEEE, P8238, DOI 10.1109/CVPR52688.2022.00807
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Wu Q., 2023, Hyperinr: A fast and predictive hypernetwork for implicit neural representations via knowledge distillation, V3, P9
   Wu Q, 2022, Arxiv, DOI arXiv:2207.11620
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Zhao K, 2021, PROC INT CONF DATA, P1643, DOI 10.1109/ICDE51399.2021.00145
NR 35
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 965
EP 974
DI 10.1109/TVCG.2023.3327194
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500072
PM 37883276
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bauer, D
   Wu, Q
   Ma, KL
AF Bauer, David
   Wu, Qi
   Ma, Kwan-Liu
TI Photon Field Networks for Dynamic Real-Time Volumetric Global
   Illumination
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Photonics; Rendering (computer graphics); Lighting; Data visualization;
   Real-time systems; Light sources; Visualization; Volume data; volume
   rendering; volume visualization; deep learning; global illumination;
   neural rendering; path tracing
ID OCCLUSION SHADING MODEL; AMBIENT OCCLUSION
AB Volume data is commonly found in many scientific disciplines, like medicine, physics, and biology. Experts rely on robust scientific visualization techniques to extract valuable insights from the data. Recent years have shown path tracing to be the preferred approach for volumetric rendering, given its high levels of realism. However, real-time volumetric path tracing often suffers from stochastic noise and long convergence times, limiting interactive exploration. In this paper, we present a novel method to enable real-time global illumination for volume data visualization. We develop Photon Field Networks-a phase-function-aware, multi-light neural representation of indirect volumetric global illumination. The fields are trained on multi-phase photon caches that we compute a priori. Training can be done within seconds, after which the fields can be used in various rendering tasks. To showcase their potential, we develop a custom neural path tracer, with which our photon fields achieve interactive framerates even on large datasets. We conduct in-depth evaluations of the method's performance, including visual quality, stochastic noise, inference and rendering speeds, and accuracy regarding illumination and phase function awareness. Results are compared to ray marching, path tracing and photon mapping. Our findings show that Photon Field Networks can faithfully represent indirect global illumination within the boundaries of the trained phase spectrum while exhibiting less stochastic noise and rendering at a significantly faster rate than traditional methods.
C1 [Bauer, David; Wu, Qi; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
C3 University of California System; University of California Davis
RP Bauer, D (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM davbauer@ucdavis.edu; qadwu@ucdavis.edu; klma@ucdavis.edu
RI wu, qirui/GLU-4942-2022
OI Ma, Kwan-Liu/0000-0001-8086-0366; Bauer, David/0000-0002-1327-3054
FU U.S. Department of Energy
FX No Statement Available
CR Bauer D, 2023, IEEE T VIS COMPUT GR, V29, P515, DOI 10.1109/TVCG.2022.3209498
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bi S, 2020, Arxiv, DOI [arXiv:2008.03824, 10.48550/arXiv.2008.03824]
   Bitterli B, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073698
   Boss M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12664, DOI 10.1109/ICCV48922.2021.01245
   Dachsbacher C, 2014, COMPUT GRAPH FORUM, V33, P88, DOI 10.1111/cgf.12256
   Dappa E, 2016, INSIGHTS IMAGING, V7, P849, DOI 10.1007/s13244-016-0518-1
   Díaz J, 2010, COMPUT GRAPH-UK, V34, P337, DOI 10.1016/j.cag.2010.03.005
   Dodik A, 2022, COMPUT GRAPH FORUM, V41, P172, DOI 10.1111/cgf.14428
   Engel D, 2021, IEEE T VIS COMPUT GR, V27, P1268, DOI 10.1109/TVCG.2020.3030344
   Gao D., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32099633, DOI 10.1109/TVCG.2022.32099633]
   Hachisuka T, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409083
   Hachisuka T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618487
   Han J., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.31972032
   Henyey LG, 1941, ASTROPHYS J, V93, P70, DOI 10.1086/144246
   Herholz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3230635
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Intel Corporation, 2022, OpenVKL
   Intel Corporation, 2020, oneTBB
   Jarosz W., 2008, ACM SIGGRAPH 2008 CL, p3:1, DOI DOI 10.1145/1401132.14011372,9
   Jarosz W, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899409
   Jensen H. W., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P311, DOI 10.1145/280814.280925
   Jensen H. W., 1996, Rendering Techniques '96. Proceedings of the Eurographics Workshop. Eurographics, P21
   Jönsson D, 2017, IEEE T VIS COMPUT GR, V23, P901, DOI 10.1109/TVCG.2016.2598430
   Jönsson D, 2012, IEEE T VIS COMPUT GR, V18, P2364, DOI 10.1109/TVCG.2012.232
   Kallweit S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130880
   Kaplanyan AS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451242
   Kingma D.P., 2014, P INT C LEARNING REP
   Kniss J, 2003, IEEE T VIS COMPUT GR, V9, P150, DOI 10.1109/TVCG.2003.1196003
   Kniss J, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P109, DOI 10.1109/VISUAL.2002.1183764
   Krivánek J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601219
   Kroes T., 2015, GPU Pro 6: Advanced Rendering Techniques, P475, DOI DOI 10.1201/9781351052108-172
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Liu N, 2016, COMPUT ANIMAT VIRT W, V27, P394, DOI 10.1002/cav.1706
   Lu Y, 2021, COMPUT GRAPH FORUM, V40, P135, DOI 10.1111/cgf.14295
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Muller T., 2021, Tiny CUDA Neural Network Framework
   Müller T, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459812
   Paladini G., 2015, Industrial Talk, EG/VGTC EuroVis, P2
   Ropinski T, 2008, COMPUT GRAPH FORUM, V27, P567, DOI 10.1111/j.1467-8659.2008.01154.x
   Ruiz M., 2008, IEEE EG S VOLUME POI, P113, DOI DOI 10.2312/VG/VG-PBG08/113-1202
   Schott M, 2009, COMPUT GRAPH FORUM, V28, P855, DOI 10.1111/j.1467-8659.2009.01464.x
   Shih M, 2016, SYMP LARG DATA ANAL, P47, DOI 10.1109/LDAV.2016.7874309
   Sitzmann V., 2021, Advances in Neural Information Processing Systems, V34, P9
   Soltészová V, 2010, COMPUT GRAPH FORUM, V29, P883, DOI 10.1111/j.1467-8659.2009.01695.x
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Suhail M, 2022, PROC CVPR IEEE, P8259, DOI 10.1109/CVPR52688.2022.00809
   Sundén E, 2011, IEEE T VIS COMPUT GR, V17, P2125, DOI 10.1109/TVCG.2011.211
   Veach E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P419, DOI 10.1145/218380.218498
   Veach E., 1995, Photorealistic Rendering Techniques, P2
   Vorba J., 2019, ACM SIGGRAPH 2019 Courses, DOI [DOI 10.1145/3305366.3328091, 10.1145/3305366.3328091]
   Wald I, 2022, Arxiv, DOI [arXiv:2210.12859, DOI 10.48550/ARXIV.2210.12859]
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Weber C., 2013, P INT WORKSH VIS MOD, P195, DOI [10.2312/PE.VMV.VMV13.195-202, DOI 10.2312/PE.VMV.VMV13.195-202]
   Weiss S, 2022, COMPUT GRAPH FORUM, V41, P196, DOI 10.1111/cgf.14578
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Woodcock E.R., 1965, PROC C APPL COMPUTIN, P557
   Wu Q., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32931212,3,5, DOI 10.1109/TVCG.2023.32931212,3,5]
   Zhang YB, 2013, P ACM SIGGRAPH S INT, DOI DOI 10.1145/2448196.2448205
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P1317, DOI 10.1109/TVCG.2013.17
   Zhu SL, 2020, COMPUT GRAPH FORUM, V39, P35, DOI 10.1111/cgf.14052
NR 65
TC 1
Z9 2
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 975
EP 985
DI 10.1109/TVCG.2023.3327107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500015
PM 37883277
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Shen, JY
   Shen, HW
AF Shen, Jingyi
   Shen, Han-Wei
TI PSRFlow: Probabilistic Super Resolution with Flow-Based Models for
   Scientific Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Super resolution; latent space; normalizing flow; uncertainty
   visualization
ID SUPERRESOLUTION; UNCERTAINTY
AB Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
C1 [Shen, Jingyi; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Shen, JY (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM shen.1250@osu.edu; shen.94@osu.edu
RI Shen, Han-wei/A-4710-2012
OI Shen, Han-Wei/0000-0002-1211-2320
FU US Department of Energy SciDAC
FX No Statement Available
CR Aggarwal V, 2020, INT CONF ACOUST SPEE, P6179, DOI [10.1109/icassp40776.2020.9053678, 10.1109/ICASSP40776.2020.9053678]
   An YF, 2021, IEEE COMPUT GRAPH, V41, P122, DOI 10.1109/MCG.2021.3097555
   Ardizzone L, 2019, Arxiv, DOI arXiv:1808.04730
   Arjovsky M, 2017, INT C LEARN REPR
   Athawale T. M., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P2
   Athawale T. M., 2020, IEEE Transactions on Visualization and Computer Graphics, V28, P2
   Athawale TM, 2021, IEEE T VIS COMPUT GR, V27, P1797, DOI 10.1109/TVCG.2020.3030394
   Bogachev V. I., 2005, Sbornik Mathematics, V196, P2
   Correa Carlos D., 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P51, DOI 10.1109/VAST.2009.5332611
   Dinh L., 2017, Density Estimation using Real NVP, V1, P3
   Fout N., 2012, IEEE Transactions on Visualization and Computer Graphics, V18, P2
   Grigoryan G, 2004, IEEE T VIS COMPUT GR, V10, P564, DOI 10.1109/TVCG.2004.30
   Guo L, 2020, IEEE PAC VIS SYMP, P71, DOI 10.1109/PacificVis48177.2020.8737
   Hagele David, 2023, IEEE Trans Vis Comput Graph, V29, P23, DOI 10.1109/TVCG.2022.3209420
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P2445, DOI 10.1109/TVCG.2020.3032123
   Han J, 2022, IEEE T VIS COMPUT GR, V28, P270, DOI 10.1109/TVCG.2021.3114815
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P205, DOI 10.1109/TVCG.2019.2934255
   Han M., 2022, Journal of Flow Visualization and Image Processing, V29, P2
   He K., 2015, CVPR, DOI [DOI 10.1109/MSP.2012.2205597, 10.1109/CVPR.2016.90]
   Janosh R., Random TikZ Collection
   Jo Y, 2021, PROC CVPR IEEE, P16231, DOI 10.1109/CVPR46437.2021.01597
   Jo Y, 2021, IEEE COMPUT SOC CONF, P364, DOI 10.1109/CVPRW53098.2021.00046
   Kinga D., 2015, Int. Conf. Learn. Represent., V5, P6
   Kingma D. P., 2018, Advances in neural information processing systems, V1, P5
   Liang JY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4056, DOI 10.1109/ICCV48922.2021.00404
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   Lugmayr Andreas, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P715, DOI 10.1007/978-3-030-58558-7_42
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Postels J, 2021, INT CONF 3D VISION, P1249, DOI 10.1109/3DV53792.2021.00132
   Pothkow K., 2010, IEEE Transactions on Visualization and Computer Graphics, V17, P2
   Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530
   Sakhaee E, 2017, IEEE T VIS COMPUT GR, V23, P2509, DOI 10.1109/TVCG.2016.2637333
   Schlegel S, 2012, IEEE T VIS COMPUT GR, V18, P2305, DOI 10.1109/TVCG.2012.249
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Vietinghoff D, 2022, IEEE VIS CONF, P145, DOI 10.1109/VIS54862.2022.00038
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Wurster S. W., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI DOI 10.1109/TVCG.2022.32144201
   Xie Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201304
   Yang G., 2019, P IEEECVF INT C COMP, V2, P4
NR 42
TC 0
Z9 0
U1 11
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 986
EP 996
DI 10.1109/TVCG.2023.3327171
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500101
PM 37930921
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ceneda, D
   Collins, C
   El-Assady, M
   Miksch, S
   Tominski, C
   Arleo, A
AF Ceneda, Davide
   Collins, Christopher
   El-Assady, Mennatallah
   Miksch, Silvia
   Tominski, Christian
   Arleo, Alessio
TI A Heuristic Approach for Dual Expert/End-User Evaluation of Guidance in
   Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Guidance; heuristics; evaluation; visual analytics
ID VISUALIZATION; DESIGN; TASKS
AB Guidance can support users during the exploration and analysis of complex data. Previous research focused on characterizing the theoretical aspects of guidance in visual analytics and implementing guidance in different scenarios. However, the evaluation of guidance-enhanced visual analytics solutions remains an open research question. We tackle this question by introducing and validating a practical evaluation methodology for guidance in visual analytics. We identify eight quality criteria to be fulfilled and collect expert feedback on their validity. To facilitate actual evaluation studies, we derive two sets of heuristics. The first set targets heuristic evaluations conducted by expert evaluators. The second set facilitates end-user studies where participants actually use a guidance-enhanced system. By following such a dual approach, the different quality criteria of guidance can be examined from two different perspectives, enhancing the overall value of evaluation studies. To test the practical utility of our methodology, we employ it in two studies to gain insight into the quality of two guidance-enhanced visual analytics solutions, one being a work-in-progress research prototype, and the other being a publicly available visualization recommender system. Based on these two evaluations, we derive good practices for conducting evaluations of guidance in visual analytics and identify pitfalls to be avoided during such studies.
C1 [Ceneda, Davide; Miksch, Silvia; Arleo, Alessio] TU Wien, Vienna, Austria.
   [Collins, Christopher] Ontario Tech Univ, Oshawa, ON, Canada.
   [El-Assady, Mennatallah] Swiss Fed Inst Technol, AI Ctr, Zurich, Switzerland.
   [Tominski, Christian] Univ Rostock, VAC Inst, Rostock, Germany.
C3 Technische Universitat Wien; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; University of Rostock
RP Ceneda, D (corresponding author), TU Wien, Vienna, Austria.
EM davide.ceneda@tuwien.ac.at; christopher.collins@ontariotechu.ca;
   melassady@ai.ethz.ch; miksch@ifs.tuwien.ac.at;
   christian.tominski@uni-rostock.de; alessio.arleo@tuwien.ac.at
RI Ceneda, Davide/HTT-2753-2023; Tominski, Christian/H-6388-2019; Collins,
   Christopher/AAJ-6345-2020; Arleo, Alessio/IRZ-8036-2023
OI El-Assady, Mennatallah/0000-0001-8526-2613; Ceneda,
   Davide/0000-0003-1198-567X; Miksch, Silvia/0000-0003-4427-5703;
   Tominski, Christian/0000-0001-7704-355X; Arleo,
   Alessio/0000-0003-2008-3651; Collins, Christopher/0000-0002-4520-7000
FU Vienna Science and Technology Fund (WWTF)
FX No Statement Available
CR Amar R, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P143, DOI 10.1109/INFVIS.2004.10
   [Anonymous], Templates and Protocol
   Bergeron R., 1972, Advances in Computers, V12, P175, DOI DOI 10.1016/S0065-2458(08)60510-04
   Bouali F, 2016, VISUAL COMPUT, V32, P1447, DOI 10.1007/s00371-015-1132-9
   Ceneda D., 2018, EUROVA, P19, DOI DOI 10.2312/EUROVA.20181107
   Ceneda D., 2018, Visualization in Data Science (VDS), V2, P3
   Ceneda D, 2022, IEEE T VIS COMPUT GR, V28, P4570, DOI 10.1109/TVCG.2021.3094870
   Ceneda D, 2020, COMPUT GRAPH FORUM, V39, P269, DOI 10.1111/cgf.14017
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen CM, 2000, INT J HUM-COMPUT ST, V53, P631, DOI 10.1006/ijhc.2000.0421
   Chen CM, 2000, INT J HUM-COMPUT ST, V53, P851, DOI 10.1006/ijhc.2000.0422
   Collins C, 2018, VIS INFORM, V2, P166, DOI 10.1016/j.visinf.2018.09.003
   Cook K. A., 2005, Technical report, P1
   Cronbach LJ, 1951, PSYCHOMETRIKA, V16, P297
   Forsell C., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P136, DOI 10.1109/IV.2012.33
   Forsell C., 2010, Proceedings of the International Conference on Advanced Visual Interfaces, DOI [10.1145/1842993.18430292, DOI 10.1145/1842993.18430292, 10.1145/1842993.1843029., DOI 10.1145/1842993.1843029]
   Gladisch S, 2013, LECT NOTES COMPUT SC, V8034, P36, DOI 10.1007/978-3-642-41939-3_4
   Gotz D., 2010, P INT WORKSH INT VIS, P1, DOI DOI 10.1145/2002353.2002355
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Han WK, 2023, INFORM VISUAL, V22, P140, DOI 10.1177/14738716221147289
   He T., 2022, IEEE Trans. Visual Comput. Graphics, V29, P363, DOI DOI 10.1109/TVCG.2022.32093902,3
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Hinkin T.R., 1997, J HOSP TOUR RES, V21, P100, DOI [DOI 10.1177/109634809702100108, 10.1177/1096348097021001089, DOI 10.1177/1096348097021001089]
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krishnamoorthy G., 2006, P E LEARN WORLD C E, P2122
   Luboschik M., 2012, 2012 IEEE Symposium on Biological Data Visualization (BioVis 2012), P33, DOI 10.1109/BioVis.2012.6378590
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Manka JS, 2003, PROCEEDINGS OF THE TWENTY-NINTH ANNUAL CONFERENCE ON EXPLOSIVES AND BLASTING TECHNIQUE, VOL 1, P169
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   Nielsen J., 1994, USABILITY INSPECTION, P25, DOI [DOI 10.5555/189200.189209, DOI 10.1089/TMJ.2010.0114]
   O'Donovan P, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1221, DOI 10.1145/2702123.2702149
   Perez-Messina I, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14555
   Plaisant C., 2004, P WORK C ADV VIS INT, P109, DOI [10.1145/989863.989880, DOI 10.1145/989863.989880]
   Saket B, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P133, DOI 10.1145/2993901.2993903
   Scapin DL, 1997, BEHAV INFORM TECHNOL, V16, P220, DOI 10.1080/014492997119806
   Shneiderman B., 2006, P AVI WORKSH TIM ERR, P1, DOI DOI 10.1145/1168149.1168158
   Sperotto F, 2021, EUR J PEDIATR, V180, P307, DOI 10.1007/s00431-020-03766-6
   Sperrle Fabian, 2023, IEEE Trans Vis Comput Graph, V29, P1124, DOI 10.1109/TVCG.2022.3209393
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Stasko J., 2014, P 5 WORKSH TIM ERR N, P46, DOI [DOI 10.1145/2669557.2669579, 10.1145/2669557.26695792,9, DOI 10.1145/2669557.26695792,9]
   Stoiber C, 2022, VIS INFORM, V6, P68, DOI 10.1016/j.visinf.2022.02.005
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Zuk T., 2006, P 2006 AVI WORKSH TI, P1, DOI DOI 10.1145/1168149.1168162
   Zuk T, 2006, PROC SPIE, V6060, DOI 10.1117/12.643631
NR 55
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 997
EP 1007
DI 10.1109/TVCG.2023.3327152
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500077
PM 37903044
OA Green Submitted, hybrid, Green Published
DA 2024-11-06
ER

PT J
AU Fygenson, R
   Franconeri, S
   Bertini, E
AF Fygenson, Racquel
   Franconeri, Steven
   Bertini, Enrico
TI The Arrangement of Marks Impacts Afforded Messages: Ordering,
   Partitioning, Spacing, and Coloring in Bar Charts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bars; Visualization; Data visualization; Task analysis; Affordances;
   COVID-19; Birds; Perception & cognition; Methodologies; Human-subjects
   qualitative studies; Human-subjects quantitative studies; Charts;
   diagrams and plots; General public
ID COGNITIVE FIT; SAMPLE-SIZE; SIMILARITY; INFORMATION; PROXIMITY; GRAPHS;
   PERCEPTION
AB Data visualizations present a massive number of potential messages to an observer. One might notice that one group's average is larger than another's, or that a difference in values is smaller than a difference between two others, or any of a combinatorial explosion of other possibilities. The message that a viewer tends to notice - the message that a visualization 'affords' - is strongly affected by how values are arranged in a chart, e.g., how the values are colored or positioned. Although understanding the mapping between a chart's arrangement and what viewers tend to notice is critical for creating guidelines and recommendation systems, current empirical work is insufficient to lay out clear rules. We present a set of empirical evaluations of how different messages-including ranking, grouping, and part-to-whole relationships-are afforded by variations in ordering, partitioning, spacing, and coloring of values, within the ubiquitous case study of bar graphs. In doing so, we introduce a quantitative method that is easily scalable, reviewable, and replicable, laying groundwork for further investigation of the effects of arrangement on message affordances across other visualizations and tasks. Pre-registration and all supplemental materials are available at https://osf.io/np3q7 and https://osf.io/bvy95, respectively.
C1 [Fygenson, Racquel; Franconeri, Steven; Bertini, Enrico] Northeastern Univ, Boston, MA 02138 USA.
C3 Northeastern University
RP Fygenson, R (corresponding author), Northeastern Univ, Boston, MA 02138 USA.
EM fygenson.r@northeastern.edu; franconeri@northwestern.edu;
   e.bertini@northeastern.edu
RI Fygenson, Racquel/LIC-8497-2024; Bertini, Enrico/ABG-1278-2020
OI Franconeri, Steven/0000-0001-5244-9764; Bertini,
   Enrico/0000-0002-9932-0551; Fygenson, Racquel/0000-0002-0705-9000
FU National Science Foundation
FX No Statement Available
CR Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   BENAV MB, 1995, VISION RES, V35, P853, DOI 10.1016/0042-6989(94)00173-J
   Bertini E., 2008, CHI '08 extended abstracts on Human factors in computing systems, P3913, DOI DOI 10.1145/1358628.13589552
   Bertini E, 2021, Arxiv, DOI arXiv:2008.11310
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Brooks J.L., 2015, The Oxford Handbook of Perceptual Organization
   Burns A., IEEE Transactions on Visualization amp; Computer Graphics, P1, DOI [10.1109/TVCG.2022.32317162, DOI 10.1109/TVCG.2022.32317162]
   Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227
   Cairo A, 2020, About that weird georgia chart
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dickinson CA, 2009, ATTEN PERCEPT PSYCHO, V71, P1251, DOI 10.3758/APP.71.6.1251
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Elzer S, 2006, USER MODEL USER-ADAP, V16, P1, DOI 10.1007/s11257-006-9002-9
   Feeney A., 2003, Smart Graphics, P4
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   GIBSON JJ, 1978, LEONARDO, V11, P227, DOI 10.2307/1574154
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   HOCHBERG J, 1956, AM J PSYCHOL, V69, P456, DOI 10.2307/1419052
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lidwell W., 2010, Affordance, P3
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   Munzner T., 2014, AK Peters Visualization Series
   Norman D., 2013, The Psychopathology Of Everyday Things, V1, P3
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Oyama T, 1999, PERCEPTION, V28, P739, DOI 10.1068/p2799
   Oyama T., 1961, Perceptual and Motor Skills, V13, P305, DOI DOI 10.2466/PMS.1961.13.3.305
   Padilla Lace, 2023, IEEE Trans Vis Comput Graph, V29, P12, DOI 10.1109/TVCG.2022.3209457
   Padilla L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05353-1
   Plaisant C., 2004, P WORK C ADV VIS INT, P109, DOI [10.1145/989863.989880, DOI 10.1145/989863.989880]
   Quinlan PT, 1998, PERCEPTION, V27, P417, DOI 10.1068/p270417
   Scimeca J., 2014, Wiley Interdisciplinary Reviews: Cognitive Science, V6, P12, DOI [10.1002/wcs.13286,7,8,9, DOI 10.1002/WCS.13286,7,8,9]
   Seabold S, 2010, STATSMODELS ECONOMET
   Shah P, 1999, J EDUC PSYCHOL, V91, P690, DOI 10.1037/0022-0663.91.4.690
   SIMKIN D, 1987, J AM STAT ASSOC, V82, P454, DOI 10.2307/2289447
   SISON CP, 1995, J AM STAT ASSOC, V90, P366, DOI 10.2307/2291162
   South L, 2022, COMPUT GRAPH FORUM, V41, P43, DOI 10.1111/cgf.14521
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   THOMPSON SK, 1987, AM STAT, V41, P42, DOI 10.2307/2684318
   Tufte E.R., 2001, VISUAL DISPLAY QUANT, V2nd, P1
   TVERSKY B, 1991, COGNITIVE PSYCHOL, V23, P515, DOI 10.1016/0010-0285(91)90005-9
   VESSEY I, 1991, DECISION SCI, V22, P219, DOI 10.1111/j.1540-5915.1991.tb00344.x
   Vessey I, 1991, INFORM SYST RES, V2, P63, DOI 10.1287/isre.2.1.63
   Viénot F, 1999, COLOR RES APPL, V24, P243, DOI 10.1002/(SICI)1520-6378(199908)24:4<243::AID-COL5>3.0.CO;2-3
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wall E, 2022, IEEE COMPUT GRAPH, V42, P29, DOI 10.1109/MCG.2022.3152676
   Walny J, 2015, COMPUT GRAPH FORUM, V34, P231, DOI 10.1111/cgf.12635
   Ware C, 2008, MORG KAUF SER INTER, P1
   Ware C., 2012, Morgan Kaufmann Series in Interactive Technologies, V3, P4
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Xiong C., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32329591,2, DOI 10.1109/TVCG.2022.32329591,2]
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xu YQ, 2015, PSYCHOL SCI, V26, P1241, DOI 10.1177/0956797615585002
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yu D, 2019, PSYCHOL SCI, V30, P376, DOI 10.1177/0956797618822798
   Yu D, 2019, COGNITION, V182, P8, DOI 10.1016/j.cognition.2018.08.006
   Zacks J, 1998, J EXP PSYCHOL-APPL, V4, P119
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Ziemkiewicz C, 2008, IEEE T VIS COMPUT GR, V14, P1269, DOI 10.1109/TVCG.2008.171
   Ziemkiewicz Caroline, 2010, P ADV VISUAL INTERFA, P215, DOI [10.1145/1842993.1843031, DOI 10.1145/1842993.1843031]
NR 66
TC 0
Z9 0
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1008
EP 1018
DI 10.1109/TVCG.2023.3326590
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500033
PM 37871066
OA Green Submitted
DA 2024-11-06
ER

PT J
AU He, TY
   Zhong, YY
   Isenberg, P
   Isenberg, T
AF He, Tingying
   Zhong, Yuanyang
   Isenberg, Petra
   Isenberg, Tobias
TI Design Characterization for Black-and-White Textures in Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Shape; Image color analysis; Bars;
   Encoding; Electronic mail; Aesthetics; textures; icons; black and white;
   visualization; visual representations; categorical data; design;
   perception
ID PERCEPTION; FEATURES; STATISTICS; ELEMENTS; TEXTONS
AB We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures. Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings. We specifically study how to use what we call geometric and iconic textures. Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories. We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters. 30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps. We then had 150 participants rate these designs for aesthetics. Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.
C1 [He, Tingying; Isenberg, Petra; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
   [Zhong, Yuanyang] Tencent Technol Shenzhen Co Ltd, Shenzhen, Peoples R China.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS); Inria; Universite Paris Cite; Tencent
RP He, TY (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
EM tingying.he@inria.fr; zoniaczhong@tencent.com; petra.isenberg@inria.fr;
   tobias.isenberg@inria.fr
RI He, Tingying/KHW-4844-2024; Isenberg, Tobias/A-7575-2008
OI Isenberg, Petra/0000-0002-2948-6417; He, Tingying/0000-0002-9670-5587;
   Isenberg, Tobias/0000-0001-7953-8644
CR AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 1962, IRE transactions on Information Theory, DOI [10.1109/TIT.1962.1057698.2, DOI 10.1109/TIT.1962.1057698]
   Barla P, 2006, COMPUT GRAPH FORUM, V25, P663, DOI 10.1111/j.1467-8659.2006.00986.x
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bertin J., 1998, Semiologie Graphique, V3rd
   Bertin J., 2011, SEMIOLOGY GRAPHICS D
   Besançon L, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3310432
   Blascheck T, 2023, IEEE PAC VIS SYMP, P187, DOI 10.1109/PacificVis56936.2023.00028
   Borgo R., 2013, P EUR, P39, DOI [DOI 10.2312/CONF/EG2013/STARS/039-063, 10.2312/conf/EG2013/stars/039-063]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Brinton W. C., 1939, Graphic Presentation
   Brinton W. C., 1914, The Engineering Magazine Company
   Brodatz P., 1966, Textures: A Photographic Album for Artists and Designers, V2
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Chen M, 2013, SYNTHESE, V190, P3421, DOI 10.1007/s11229-012-0183-y
   Cho RY, 2000, PERCEPT PSYCHOPHYS, V62, P735, DOI 10.3758/BF03206920
   CLEVELAND WS, 1985, SCIENCE, V229, P828, DOI 10.1126/science.229.4716.828
   Cockburn A, 2020, COMMUN ACM, V63, P70, DOI 10.1145/3360311
   Cumming G., 2013, UNDERSTANDING NEW ST, DOI DOI 10.4324/9780203807002
   Data visualization society, Global non-profit organization for data visualization practitioners and enthusiasts
   Dragicevic P, 2016, HUM-COMPUT INT-SPRIN, P291, DOI 10.1007/978-3-319-26633-6_13
   Goffin P, 2014, IEEE T VIS COMPUT GR, V20, P2291, DOI 10.1109/TVCG.2014.2346435
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Hawkins J.K., 1970, Picture processing and psychopictorics, P347
   He Tingying, 2023, IEEE Trans Vis Comput Graph, V29, P363, DOI 10.1109/TVCG.2022.3209390
   Healey CG, 1998, VISUALIZATION '98, PROCEEDINGS, P111, DOI 10.1109/VISUAL.1998.745292
   Higgins JJ., 2004, Introduction to modern nonparametric statistics
   Hutchinson Hilary, 2003, C HUM FACT COMP SYST
   Icons8, Website and icons database
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   JULESZ B, 1981, BIOL CYBERN, V41, P131, DOI 10.1007/BF00335367
   JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34
   JULESZ B, 1983, BELL SYST TECH J, V62, P1619, DOI 10.1002/j.1538-7305.1983.tb03502.x
   JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391
   Kosslyn SM., 2006, Graph design for the eye and mind, DOI DOI 10.1093/ACPROF:OSO/9780195311846.001.0001
   Lin SR, 2013, COMPUT GRAPH FORUM, V32, P401, DOI 10.1111/cgf.12127
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Martín D, 2017, COMPUT GRAPH-UK, V67, P24, DOI 10.1016/j.cag.2017.05.001
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Neurath Otto., 2010, From Hieroglyphics to Isotype: A Visual Autobiography
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   Salisbury M. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P101, DOI 10.1145/192161.192185
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Ware C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P203, DOI 10.1145/142750.142791
   Ware C., 2019, Information Visualization: Perception for Design, DOI DOI 10.1016/C2016-0-02395-1
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
   Zhong Y., 2020, POSTERS IEEE VIS
NR 53
TC 0
Z9 0
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1019
EP 1029
DI 10.1109/TVCG.2023.3326941
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500114
PM 37883265
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Arunkumar, A
   Padilla, L
   Bae, GY
   Bryan, C
AF Arunkumar, Anjana
   Padilla, Lace
   Bae, Gi-Yeul
   Bryan, Chris
TI Image or Information? Examining the Nature and Impact of Visualization
   Perceptual Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Economics; Sports;
   Meteorology; Geology; Information Visualization; Human-Centered
   Computing; Perception & Cognition; Takeaways
ID COMMUNICATION
AB How do people internalize visualizations: as images or information? In this study, we investigate the nature of internalization for visualizations (i.e., how the mind encodes visualizations in memory) and how memory encoding affects its retrieval. This exploratory work examines the influence of various design elements on a user's perception of a chart. Specifically, which design elements lead to perceptions of visualization as an image (aims to provide visual references, evoke emotions, express creativity, and inspire philosophic thought) or as information (aims to present complex data, information, or ideas concisely and promote analytical thinking)? Understanding how design elements contribute to viewers perceiving a visualization more as an image or information will help designers decide which elements to include to achieve their communication goals. For this study, we annotated 500 visualizations and analyzed the responses of 250 online participants, who rated the visualizations on a bilinear scale as 'image' or 'information.' We then conducted an in-person study (n = 101) using a free recall task to examine how the image/information ratings and design elements impacted memory. The results revealed several interesting findings: Image-rated visualizations were perceived as more aesthetically 'appealing,' 'enjoyable,' and 'pleasing.' Information-rated visualizations were perceived as less 'difficult to understand' and more aesthetically 'likable' and 'nice,' though participants expressed higher 'positive' sentiment when viewing image-rated visualizations and felt less 'guided to a conclusion.' The presence of axes and text annotations heavily influenced the likelihood of participants rating the visualization as 'information.' We also found different patterns among participants that were older. Importantly, we show that visualizations internalized as 'images' are less effective in conveying trends and messages, though they elicit a more positive emotional judgment, while 'informative' visualizations exhibit annotation focused recall and elicit a more positive design judgment. We discuss the implications of this dissociation between aesthetic pleasure and perceived ease of use in visualization design.
C1 [Arunkumar, Anjana; Bae, Gi-Yeul; Bryan, Chris] Arizona State Univ, Tempe, AZ 85281 USA.
   [Padilla, Lace] Northeastern Univ, Boston, MA USA.
C3 Arizona State University; Arizona State University-Tempe; Northeastern
   University
RP Arunkumar, A (corresponding author), Arizona State Univ, Tempe, AZ 85281 USA.
EM aarunku5@asu.edu; l.padilla@northeastern.edu; giyeulbae@asu.edu;
   cbryan16@asu.edu
FU U.S. National Science Foundation
FX No Statement Available
CR Adar E, 2021, IEEE T VIS COMPUT GR, V27, P946, DOI 10.1109/TVCG.2020.3030375
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Arnheim R., 1969, Art and visual perception: A psychology of the creative eye, P2
   Arunkumar A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P51, DOI 10.1109/VIS49827.2021.9623282
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bertini E, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P206, DOI 10.1109/VIS47514.2020.00048
   Bloom B. S., 2020, Taxonomy of educational objectives: The classification of educational goals. Book 1, Cognitive domain
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   Bradley A. J., 2021, Approaching humanities questions using slow visual search interfaces, V2, P9
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Bryan C, 2020, VIS INFORM, V4, P41, DOI 10.1016/j.visinf.2020.08.001
   Buchanan R., 1992, DESIGN ISSUES, V8, P5, DOI [DOI 10.2307/1511637, 10.2307/1511637]
   Burkhard RA, 2004, IEEE INFOR VIS, P519, DOI 10.1109/IV.2004.1320194
   Burlinson D., 2020, Journal of Vision, V20, P1
   Burns A., 2021, IEEE transactions on visualization and computer graphics, V28, P2
   Cairo A., 2016, New Riders, P2
   Card S. K., 1999, Readings in information visualization: using vision to think, V579, P1
   Chan CS, 1997, J ARCHIT PLAN RES, V14, P52
   Chen C., 2005, IEEE computer graphics and applications, V25, P3
   CLEVELAND WS, 1987, J ROY STAT SOC A STA, V150, P192, DOI 10.2307/2981473
   Cohen J., 2013, Statistical power analysis for the behavioral sciences, P5
   Conklin J., 2005, A taxonomy for learning, teaching, and assessing: A revision of bloom's taxonomy of educational objectives complete edition, P2
   Di Bartolomeo S., 2023, Doom or deliciousness: Challenges and opportunities for visualization in the age of generative models, P3
   Dick M, 2014, DIGIT JOURNAL, V2, P490, DOI 10.1080/21670811.2013.841368
   Emerson J., 2018, Practice, V171, P2
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Few S., 2009, Now you see it: simple visualization techniques for quantitative analysis, V1, P2
   Few S., 2011, The chartjunk debate-a close examination of recent findings, V2020. 2
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Garcia-Retamero R, 2013, CURR DIR PSYCHOL SCI, V22, P392, DOI 10.1177/0963721413491570
   Hair J.F., 1998, Multivariate data analysis, V5th ed.
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545
   He T., 2022, IEEE Trans. Visual Comput. Graphics, V29, P363, DOI DOI 10.1109/TVCG.2022.32093902,3
   Healey CG, 2004, ACM T GRAPHIC, V23, P64, DOI 10.1145/966131.966135
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Hogarth W., 1753, The analysis of beauty: Written with a view of fixing the fluctuating ideas of taste, P3
   Houts PS, 2006, PATIENT EDUC COUNS, V61, P173, DOI 10.1016/j.pec.2005.05.004
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2213, DOI 10.1109/TVCG.2011.175
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iliinsky N., 2011, Designing data visualizations: Representing informational Relationships, P2
   Isola P., 2011, Advances in neural information processing systems, V24, P2
   John-Steiner Vera., 1997, NOTEBOOKS MIND EXPLO
   Kefi H., 2010, Emerging Systems Approaches in Information Technologies: Concepts, Theories, and Applications, P5
   Keim D, 2013, IEEE COMPUT GRAPH, V33, P20, DOI 10.1109/MCG.2013.54
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kerpedjiev S, 1998, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION - PROCEEDINGS, P97, DOI 10.1109/INFVIS.1998.729564
   Kim NW, 2017, IEEE T VIS COMPUT GR, V23, P491, DOI 10.1109/TVCG.2016.2598620
   Kirk A., 2012, Packt publishing LTD, P2
   KOSSLYN SM, 1976, MEM COGNITION, V4, P291, DOI 10.3758/BF03213178
   KOSSLYN SM, 1977, COGNITIVE PSYCHOL, V9, P52, DOI 10.1016/0010-0285(77)90004-4
   Lambert S., 2016, And what do i do now? using data visualization for social change, P2
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Leonards U, 2002, EXP BRAIN RES, V146, P172, DOI 10.1007/s00221-002-1175-9
   Lupi G., 2017, Print Magazine, V30, P2
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mahyar N., Towards a taxonomy for evaluating user engagement in information visualization, V1, P5
   Maughan L, 2007, J BRAND MANAG, V14, P335, DOI 10.1057/palgrave.bm.2550074
   MITCHELL WJT, 1984, NEW LITERARY HIST, V15, P503, DOI 10.2307/468718
   Munzner T., 2014, Visualization Analysis and Design, P2
   Ovans A., 2014, Harvard Business Review, V2
   Padilla LMK, 2020, J EXP PSYCHOL-APPL, V26, P1, DOI 10.1037/xap0000245
   Pandey A., 1912, IEEE Transactions on Visualization and Computer Graphics, P2
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Roberts J. C., 2015, PERSONAL VISUALIZATI, P2
   Shen L., 2021, P 23 EUR C VIS SHORT, P91, DOI DOI 10.2312/EVS.20211061
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Tas AC, 2020, PSYCHOL AGING, V35, P565, DOI 10.1037/pag0000450
   Tractinsky N, 2000, INTERACT COMPUT, V13, P127, DOI 10.1016/S0953-5438(00)00031-X
   Tufte E. R., 1991, Optometry and Vision Science, V68, P322, DOI [10.1016/1045-926X(92)90022-E2, DOI 10.1016/1045-926X(92)90022-E2]
   Tufte E. R., 1985, The Journal for Healthcare Quality (JHQ), V7, P2
   TVERSKY B, 1989, J EXP PSYCHOL GEN, V118, P387, DOI 10.1037/0096-3445.118.4.387
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Wang Zezhong., 2019, Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, CHI'19, p253:1
   Wanzer DL, 2021, EVAL PROGRAM PLANN, V84, DOI 10.1016/j.evalprogplan.2020.101896
   Ware C., 2019, Information visualization: perception for design, V1, P2
   Wood J, 2012, IEEE T VIS COMPUT GR, V18, P2749, DOI 10.1109/TVCG.2012.262
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI [DOI 10.1145/1377966.1377971, 10.1145/1377966.1377971]
NR 84
TC 1
Z9 2
U1 13
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1030
EP 1040
DI 10.1109/TVCG.2023.3326919
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500064
PM 37874713
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Sterzik, A
   Lichtenberg, N
   Wilms, J
   Krone, M
   Cunningham, DW
   Lawonn, K
AF Sterzik, Anna
   Lichtenberg, Nils
   Wilms, Jana
   Krone, Michael
   Cunningham, Douglas W.
   Lawonn, Kai
TI Perception of Line Attributes for Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Data visualization; Visualization; Encoding; Task analysis;
   Shape; Image color analysis; Line Drawings; Line Stylization; Perceptual
   Evaluation; Uncertainty Visualization
ID WEBERS LAW; UNCERTAINTY; ILLUSTRATION
AB Line attributes such as width and dashing are commonly used to encode information. However, many questions on the perception of line attributes remain, such as how many levels of attribute variation can be distinguished or which line attributes are the preferred choices for which tasks. We conducted three studies to develop guidelines for using stylized lines to encode scalar data. In our first study, participants drew stylized lines to encode uncertainty information. Uncertainty is usually visualized alongside other data. Therefore, alternative visual channels are important for the visualization of uncertainty. Additionally, uncertainty-e.g., in weather forecasts-is a familiar topic to most people. Thus, we picked it for our visualization scenarios in study 1. We used the results of our study to determine the most common line attributes for drawing uncertainty: Dashing, luminance, wave amplitude, and width. While those line attributes were especially common for drawing uncertainty, they are also commonly used in other areas. In studies 2 and 3, we investigated the discriminability of the line attributes determined in study 1. Studies 2 and 3 did not require specific application areas; thus, their results apply to visualizing any scalar data in line attributes. We evaluated the just-noticeable differences (JND) and derived recommendations for perceptually distinct line levels. We found that participants could discriminate considerably more levels for the line attribute width than for wave amplitude, dashing, or luminance.
C1 [Sterzik, Anna; Wilms, Jana; Lawonn, Kai] Univ Jena, Jena, Germany.
   [Lichtenberg, Nils; Krone, Michael] Univ Tubingen, Tubingen, Germany.
   [Cunningham, Douglas W.] Brandenburg Tech Univ Cottbus, Cottbus, Germany.
C3 Friedrich Schiller University of Jena; Eberhard Karls University of
   Tubingen; Brandenburg University of Technology Cottbus
RP Sterzik, A (corresponding author), Univ Jena, Jena, Germany.
EM anna.sterzik@uni-jena.de; nils.lichtenberg@uni-tuebingen.de;
   jana.wilms@uni-jena.de; michael.krone@uni-tuebingen.de;
   douglas.cunningham@b-tu.de; kai.lawonn@uni-jena.de
RI Sterzik, Anna/LOS-8852-2024; Krone, Michael/HJI-9309-2023
OI Sterzik, Anna/0000-0002-0544-5397; Krone, Michael/0000-0002-1445-7568;
   Wilms, Jana/0009-0003-4078-5287
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Appel Arthur., 1967, Proceedings of the ACM National Conference, P387, DOI [10.1145/800196.8060072, DOI 10.1145/800196.8060072]
   Balestrucci P., 2022, bioRxiv, DOI [10.1101/2022.06.20.4968556, DOI 10.1101/2022.06.20.4968556]
   Benard P., 2012, P S NONPHOTOREALISTI, P2
   Bénard P, 2019, FOUND TRENDS COMPUT, V11, P1, DOI 10.1561/0600000075
   Bénard P, 2011, COMPUT GRAPH FORUM, V30, P2367, DOI 10.1111/j.1467-8659.2011.02075.x
   Boukhelifa N, 2012, IEEE T VIS COMPUT GR, V18, P2769, DOI 10.1109/TVCG.2012.220
   Buchholz B, 2011, P ACM SIGGRAPH EUR S, P85, DOI DOI 10.1145/2024676.2024690
   Cole F, 2008, ACM T GRAPHIC, V27, DOI [10.1145/1360612.1360657, 10.1145/1360612.1360687]
   Cole F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531334
   Cunningham D. W., 2011, Experimental Design: From User Studies to Psychophysics, V2, P7
   Deussen O, 1999, PROC GRAPH INTERF, P175
   Dooley D., 1990, Computer Graphics, V24, P77, DOI 10.1145/91394.91422
   Gillmann C, 2021, COMPUT GRAPH FORUM, V40, P665, DOI 10.1111/cgf.14333
   Görtler J, 2018, IEEE T VIS COMPUT GR, V24, P719, DOI 10.1109/TVCG.2017.2743959
   Granit AR, 1921, B J PSYCHOL-GEN SECT, V12, P223
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Kalnins RD, 2003, ACM T GRAPHIC, V22, P856, DOI 10.1145/882262.882355
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Lawonn K, 2013, COMPUT GRAPH FORUM, V32, P321, DOI 10.1111/cgf.12119
   Lawonn K., 2016, Visualization in Medicine and Life Sciences III, P93, DOI DOI 10.1007/978-3-319-24523-2_52
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lawonn K, 2017, COMPUT GRAPH-UK, V63, P37, DOI 10.1016/j.cag.2017.02.002
   Lawonn K, 2015, LECT NOTES COMPUT SC, V9350, P399, DOI 10.1007/978-3-319-24571-3_48
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P181, DOI 10.1111/cgf.12374
   Lechner VE, 2020, LECT NOTES ARTIF INT, V12169, P110, DOI 10.1007/978-3-030-54249-8_9
   Lichtenberg N, 2020, COMPUT GRAPH FORUM, V39, P497, DOI 10.1111/cgf.13888
   Lichtenberg N, 2018, COMPUT GRAPH-UK, V74, P137, DOI 10.1016/j.cag.2018.04.008
   MacEachren A. M., 1992, Cartographic Perspectives, V13, P10, DOI [10.14714/CP13.1000 10.14714/CP13.1000, DOI 10.14714/CP13.1000]
   MacEachren AM, 2012, IEEE T VIS COMPUT GR, V18, P2496, DOI 10.1109/TVCG.2012.279
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Pang A., 2001, P WORKSHOP INTERSECT, P2
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Saito T., 1990, Computer Graphics, V24, P197, DOI 10.1145/97880.97901
   Samatey F., 2001, Crystal Structure of F41 Fragment of Flagellin, DOI [10.2210/pdb1io1/pdb3, DOI 10.2210/PDB1IO1/PDB3]
   Samatey FA, 2001, NATURE, V410, P331, DOI 10.1038/35066504
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   Sterzik A., 2022, EUROGRAPHICS WORKSHO, P41, DOI [DOI 10.2312/VCBM.202211861,2,3,6,9, 10.2312/vcbm.202211862, DOI 10.2312/VCBM.202211862]
   Sterzik A., IEEE Transactions on Visualization and Computer Graphics
   Sterzik A, 2023, COMPUT GRAPH-UK, V114, P401, DOI 10.1016/j.cag.2023.06.006
   Strothotte T, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P36, DOI 10.1109/CGI.1999.777901
   Tak S, 2014, IEEE T VIS COMPUT GR, V20, P935, DOI 10.1109/TVCG.2013.247
   TREISMAN M, 1964, PSYCHOL REV, V71, P314, DOI 10.1037/h0042445
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Winkenbach G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P91, DOI 10.1145/192161.192184
   Zahan G.M. H., 2021, Graphics Interface 2021
   Zhao WX, 2019, J COMPUT LANG, V53, P1, DOI 10.1016/j.cola.2019.01.001
NR 48
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1041
EP 1051
DI 10.1109/TVCG.2023.3326523
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500059
PM 37871078
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Sterzik, A
   Meuschke, M
   Cunningham, DW
   Lawonn, K
AF Sterzik, Anna
   Meuschke, Monique
   Cunningham, Douglas W.
   Lawonn, Kai
TI Perceptually Uniform Construction of Illustrative Textures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Illustrative Visualization; Perceptual Evaluation; Hatching; Stippling
ID VISUALIZATION; PERCEPTION; GOODNESS
AB Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering. Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized. This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid. Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously. In previous work, these textures were manually generated and the choice of density was unempirically determined. Here, we first want to determine and understand the perceptual space of illustrative textures. We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles. Thus, we explore the texture types of stippling, hatching, and triangles. We create a range of textures by sampling the density space uniformly. Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type. We use multidimensional scaling (MDS) to analyze the perceptual spaces per category. The perception of stippling and triangles seems relatively similar. Both are adequately described by a 1D manifold in 2D space. The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction. However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles. Based on our findings, we construct perceptually uniform illustrative textures. Afterwards, we provide concrete application examples for the constructed textures.
C1 [Sterzik, Anna; Lawonn, Kai] Univ Jena, Jena, Germany.
   [Meuschke, Monique] Univ Magdeburg, Magdeburg, Germany.
   [Cunningham, Douglas W.] Brandenburg Tech Univ Cottbus, Cottbus, Germany.
C3 Friedrich Schiller University of Jena; Otto von Guericke University;
   Brandenburg University of Technology Cottbus
RP Sterzik, A (corresponding author), Univ Jena, Jena, Germany.
EM anna.sterzik@uni-jena.de; meuschke@isg.cs.uni-magdeburg.de;
   douglas.cunningham@b-tu.de; kai.lawonn@uni-jena.de
RI Sterzik, Anna/LOS-8852-2024
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Acevedo D, 2006, IEEE T VIS COMPUT GR, V12, P1133, DOI 10.1109/TVCG.2006.180
   CAELLI T, 1978, BIOL CYBERN, V28, P167, DOI 10.1007/BF00337138
   Coninx A., 2011, P ACM SIGGRAPH S APP, P59, DOI [10.1145/2077451.2077462, DOI 10.1145/2077451.2077462]
   Cunningham D., 2011, Experimental Design: From User Studies to Psychophysics, V1st, DOI DOI 10.1201/B113085
   Cunningham D. W., 2007, Computational Aesthetics in Graphics, Visualization, and Imaging, P89, DOI DOI 10.2312/COMPAESTH/COMPAESTH07/089-096
   Deussen O, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130819
   Eulzer P., 2021, EUROGRAPHICS WORKSHO, P79, DOI [DOI 10.2312/VCBM.20211347, 10.2312/vcbm.202113478, DOI 10.2312/VCBM.202113478]
   Eulzer Pepe, 2023, Zenodo
   Gadiraju Ujwal, 2017, Evaluation in the Crowd. Crowdsourcing and Human-Centered Experiments. Revised Contributions: LNCS 10264, P6, DOI 10.1007/978-3-319-66435-4_2
   Gerl M, 2013, COMPUT GRAPH-UK, V37, P65, DOI 10.1016/j.cag.2012.11.003
   Görtler J, 2019, IEEE T VIS COMPUT GR, V25, P2193, DOI 10.1109/TVCG.2019.2903945
   Groenen P. J. F., 2005, Modern multidimensional scaling: Theory and applications, V2nd, DOI [DOI 10.1007/0-387-28981-X, 10.1007/0-387-28981-X]
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Interrante V, 1996, IEEE VISUAL, P211, DOI 10.1109/VISUAL.1996.568110
   Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   JULESZ B, 1973, PERCEPTION, V2, P391, DOI 10.1068/p020391
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873
   Kruger Jens, 2007, IADIS International Conference. Computer Graphics and Visualization 2007, P19
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lawonn K, 2013, COMPUT GRAPH FORUM, V32, P321, DOI 10.1111/cgf.12119
   Lawonn K., 2014, Bildverarbeitung fur die Medizin (BVM), P276, DOI DOI 10.1007/978-3-642-54111-7_522
   Lawonn K., 2016, Visualization in Medicine and Life Sciences III, P93, DOI DOI 10.1007/978-3-319-24523-2_52
   Lawonn K, 2019, COMPUT GRAPH FORUM, V38, P221, DOI 10.1111/cgf.13526
   Lawonn K, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13322
   Lawonn K, 2017, COMPUT GRAPH-UK, V63, P37, DOI 10.1016/j.cag.2017.02.002
   Lawonn K, 2015, LECT NOTES COMPUT SC, V9350, P399, DOI 10.1007/978-3-319-24571-3_48
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P16, DOI 10.1111/cgf.12355
   Lawonn K, 2014, COMPUT GRAPH FORUM, V33, P181, DOI 10.1111/cgf.12374
   Lettvin J. Y., 1976, The Sciences, V16, P10, DOI DOI 10.1002/J.2326-1951.1976.TB01231.X
   Liu J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130335
   Liu LG, 2008, COMPUT GRAPH FORUM, V27, P1495, DOI 10.1111/j.1467-8659.2008.01290.x
   Liu YJ, 2011, IEEE T PATTERN ANAL, V33, P1502, DOI 10.1109/TPAMI.2010.221
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Martín D, 2019, COMPUT GRAPH-UK, V80, P1, DOI 10.1016/j.cag.2019.02.001
   Martín D, 2017, COMPUT GRAPH-UK, V67, P24, DOI 10.1016/j.cag.2017.05.001
   Meuschke M, 2017, IEEE T VIS COMPUT GR, V23, P761, DOI 10.1109/TVCG.2016.2598795
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Randen T., Brodatz Textures
   Sajadi B, 2013, IEEE T VIS COMPUT GR, V19, P118, DOI 10.1109/TVCG.2012.93
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Secord A., 2002, P 2 INT S NONPHOTORE, P37, DOI [DOI 10.1145/508530.5085372, DOI 10.1145/508535.508537]
   Spicker M., 2017, P S NONPHOTOREALISTI, DOI DOI 10.1145/3092919.3092923
   Sterzik A., IEEE Transactions on Visualization and Computer Graphics
   Sterzik A., 2022, EUROGRAPHICS WORKSHO, P41, DOI [DOI 10.2312/VCBM.202211861,2,3,6,9, 10.2312/vcbm.202211862, DOI 10.2312/VCBM.202211862]
   Sterzik A, 2023, COMPUT GRAPH-UK, V114, P401, DOI 10.1016/j.cag.2023.06.006
   Stoppel S, 2019, COMPUT GRAPH FORUM, V38, P110, DOI 10.1111/cgf.13609
   Sugathan S., 2021, EUROGRAPHICS WORKSHO, DOI DOI 10.2312/VCBM.20211346
   Sugathan S, 2022, COMPUT GRAPH-UK, V107, P208, DOI 10.1016/j.cag.2022.07.023
   Taylor R, 2002, IEEE COMPUT GRAPH, V22, P6, DOI 10.1109/MCG.2002.999781
   Timofeev V., 2010, Human Insulin, DOI DOI 10.2210/PDB3I40/PDB7
   Timofeev VI, 2010, ACTA CRYSTALLOGR F, V66, P259, DOI 10.1107/S1744309110000461
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Wills J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559760
   Xiao YY, 2022, COMPUT GRAPH FORUM, V41, P23, DOI 10.1111/cgf.14495
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1052
EP 1062
DI 10.1109/TVCG.2023.3326574
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500060
PM 37871076
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zeng, ZH
   Yang, JR
   Moritz, D
   Heer, J
   Battle, L
AF Zeng, Zehua
   Yang, Junran
   Moritz, Dominik
   Heer, Jeffrey
   Battle, Leilani
TI Too Many Cooks: Exploring How Graphical Perception Studies Influence
   Visualization Recommendations in Draco
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graphical Perception Studies; Visualization Recommendation Algorithms
AB Findings from graphical perception can guide visualization recommendation algorithms in identifying effective visualization designs. However, existing algorithms use knowledge from, at best, a few studies, limiting our understanding of how complementary (or contradictory) graphical perception results influence generated recommendations. In this paper, we present a pipeline of applying a large body of graphical perception results to develop new visualization recommendation algorithms and conduct an exploratory study to investigate how results from graphical perception can alter the behavior of downstream algorithms. Specifically, we model graphical perception results from 30 papers in Draco-a framework to model visualization knowledge-to develop new recommendation algorithms. By analyzing Draco-generated algorithms, we showcase the feasibility of our method to (1) identify gaps in existing graphical perception literature informing recommendation algorithms, (2) cluster papers by their preferred design rules and constraints, and (3) investigate why certain studies can dominate Draco's recommendations, whereas others may have little influence. Given our findings, we discuss the potential for mutually reinforcing advancements in graphical perception and visualization recommendation research.
C1 [Zeng, Zehua] Univ Maryland, College Pk, MD 20742 USA.
   [Yang, Junran; Heer, Jeffrey; Battle, Leilani] Univ Washington, Seattle, WA USA.
   [Moritz, Dominik] Carnegie Mellon Univ, Pittsburgh, PA USA.
C3 University System of Maryland; University of Maryland College Park;
   University of Washington; University of Washington Seattle; Carnegie
   Mellon University
RP Zeng, ZH (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM zhzeng@umd.edu; junran@uw.edu; domoritz@cmu.edu; jheer@uw.edu;
   leibatt@uw.edu
RI Zeng, Zehua/HME-2717-2023
OI Battle, Leilani/0000-0003-3870-636X; Zeng, Zehua/0000-0002-5153-3865;
   Moritz, Dominik/0000-0002-3110-1053; Heer, Jeffrey/0000-0002-6175-1655
FU Moore Foundation
FX No Statement Available
CR Bertin J., 1983, Semiology of Graphics, P2
   Burlinson D, 2018, IEEE T VIS COMPUT GR, V24, P574, DOI 10.1109/TVCG.2017.2745086
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Donoho D., 1982, Primdata: Data sets for use with prim-h
   Gebser M, 2014, Arxiv, DOI arXiv:1405.3694
   Gebser M, 2011, AI COMMUN, V24, P107, DOI 10.3233/AIC-2011-0491
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Herbrich R, 2000, ADV NEUR IN, P115
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Key A., 2012, P ACM SIGMOD INT C M, P681, DOI DOI 10.1145/2213836.2213931
   Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409
   Leis V, 2015, PROC VLDB ENDOW, V9, P204
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   Menne MJ, 2012, J ATMOS OCEAN TECH, V29, P897, DOI 10.1175/JTECH-D-11-00103.1
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Ondov B, 2019, IEEE T VIS COMPUT GR, V25, P861, DOI 10.1109/TVCG.2018.2864884
   Panavas L, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501893
   Peña-Araya V, 2020, IEEE T VIS COMPUT GR, V26, P375, DOI 10.1109/TVCG.2019.2934807
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Ryan G, 2019, IEEE T VIS COMPUT GR, V25, P872, DOI 10.1109/TVCG.2018.2865264
   Saket B., 2018, CoRR, abs/1807.06641
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Siddiqui T., 2017, 8 BIENN C INN DAT SY
   Sutton A. J., 2000, Methods for meta-analysis in medical research, V348, P9
   T. S. community, 2008, Scipy hierarchical clustering, P6
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Waldner M, 2020, IEEE T VIS COMPUT GR, V26, P1033, DOI 10.1109/TVCG.2019.2934784
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Ware C., 2012, Information visualization: perception for design, P2
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wongsuphasawat Kanit, 2016, P WORKSH HUM IN THE, P4, DOI [10.1145/2939502.2939506, DOI 10.1145/2939502.2939506]
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Yang J., 2023, IN PRESS
   Zeng Z., 2022, A Multi-Faceted Approach for Evaluating Visualization Recommendation Algorithms, DOI [10.13016/eyde-ceok1,2, DOI 10.13016/EYDE-CEOK1,2]
   Zeng ZH, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581349
   Zeng ZH, 2022, IEEE T VIS COMPUT GR, V28, P346, DOI 10.1109/TVCG.2021.3114814
   Zhao M., 2019, P 2019 CHI C HUM FAC, P1, DOI DOI 10.1145/3290605.33004623
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 51
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1063
EP 1073
DI 10.1109/TVCG.2023.3326527
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500041
PM 37871053
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Athawale, TM
   Triana, B
   Kotha, T
   Pugmire, D
   Rosen, P
AF Athawale, Tushar M.
   Triana, Bryan
   Kotha, Tanmay
   Pugmire, Dave
   Rosen, Paul
TI A Comparative Study of the Perceptual Sensitivity of Topological
   Visualizations to Feature Variations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Perception & cognition; computational topology-based techniques;
   comparison and similarity
ID OF-THE-ART; FIBER SURFACES; PERSISTENCE; EXTRACTION; UNAWARE
AB Color maps are a commonly used visualization technique in which data are mapped to optical properties, e.g., color or opacity. Color maps, however, do not explicitly convey structures (e.g., positions and scale of features) within data. Topology-based visualizations reveal and explicitly communicate structures underlying data. Although our understanding of what types of features are captured by topological visualizations is good, our understanding of people's perception of those features is not. This paper evaluates the sensitivity of topology-based isocontour, Reeb graph, and persistence diagram visualizations compared to a reference color map visualization for synthetically generated scalar fields on 2-manifold triangular meshes embedded in 3D. In particular, we built and ran a human-subject study that evaluated the perception of data features characterized by Gaussian signals and measured how effectively each visualization technique portrays variations of data features arising from the position and amplitude variation of a mixture of Gaussians. For positional feature variations, the results showed that only the Reeb graph visualization had high sensitivity. For amplitude feature variations, persistence diagrams and color maps demonstrated the highest sensitivity, whereas isocontours showed only weak sensitivity. These results take an important step toward understanding which topology-based tools are best for various data and task scenarios and their effectiveness in conveying topological variations as compared to conventional color mapping.
C1 [Athawale, Tushar M.; Pugmire, Dave] Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA.
   [Triana, Bryan] Univ S Florida, Tampa, FL USA.
   [Kotha, Tanmay; Rosen, Paul] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Oak Ridge National Laboratory;
   State University System of Florida; University of South Florida; Utah
   System of Higher Education; University of Utah
RP Athawale, TM (corresponding author), Oak Ridge Natl Lab, Oak Ridge, TN 37831 USA.
EM athawaletm@ornl.gov; bryantriana@usf.edu; tanmay@mail.usf.edu;
   pugmire@ornl.gov; paul.rosen@utah.edu
RI Rosen, Paul/GXM-8609-2022
OI Pugmire, David/0000-0003-0647-2634; Athawale, Tushar/0000-0003-3163-6274
FU U.S. Department of Energy
FX No Statement Available
CR Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   [Anonymous], 1977, Color Res. Appl, V2, P5, DOI [10.1002/j.1520-6378.1977.tb00102.x, DOI 10.1002/J.1520-6378.1977.TB00102.X]
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Blender Online Community, 2018, Blender - A 3D Modelling and Rendering Package
   Bollen B, 2023, IEEE T VIS COMPUT GR, V29, P1168, DOI 10.1109/TVCG.2022.3209395
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brecheisen R, 2009, IEEE T VIS COMPUT GR, V15, P1441, DOI 10.1109/TVCG.2009.170
   Bremer PT, 2007, J PHYS CONF SER, V78, DOI 10.1088/1742-6596/78/1/012007
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Cacuci D, 2003, Theory, V1, DOI DOI 10.1201/9780203498798
   Cacuci D., 2005, Applications to Large-Scale Systems, VII, P2
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H, 2015, COMPUT GRAPH FORUM, V34, P241, DOI 10.1111/cgf.12636
   Carrière M, 2017, PR MACH LEARN RES, V70
   Chan YH, 2013, IEEE T VIS COMPUT GR, V19, P1768, DOI 10.1109/TVCG.2013.20
   Chen F, 2013, COMPUT AIDED GEOM D, V30, P557, DOI 10.1016/j.cagd.2012.03.019
   cnr, Digital Shape Workbench - Shape Repository. Shape repository
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cooper PS, 2021, NEUROIMAGE, V245, DOI 10.1016/j.neuroimage.2021.118628
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   Doraiswamy H, 2012, IEEE T VIS COMPUT GR, V18, P146, DOI 10.1109/TVCG.2011.37
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   Edelsbrunner H., 2010, American Mathematical Society, V2, P3
   Edelsbrunner H, 2008, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SGG'08), P242, DOI 10.1145/1377676.1377720
   Engelke W., 2021, Topologybased feature design and tracking for multi-center cyclones, P71, DOI DOI 10.1007/978-3-030-83500-2_5
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Fechner G. T., 1948, Elements of psychophysics, DOI DOI 10.1037/11304-0265
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Forsberg AS, 2009, IEEE T VIS COMPUT GR, V15, P1219, DOI 10.1109/TVCG.2009.126
   Gasparovic E., PREPRINT
   Hajij M, 2020, ALGORITHMS, V13, DOI 10.3390/a13100258
   Hansen CJ, 2017, SPACE SCI REV, V213, P475, DOI 10.1007/s11214-014-0079-x
   Hauser H., 2007, Topological-based Methods in Visualization, DOI [10.1007/978-3-540-70823-02, DOI 10.1007/978-3-540-70823-02]
   Hilton A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P381, DOI 10.1109/ICIP.1996.560840
   Hosmer DW., 2013, APPL LOGISTIC REGRES, V398, DOI DOI 10.1002/9781118548387
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Junyi Tu, 2019, Advances in Visual Computing. 14th International Symposium on Visual Computing, ISVC 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11844), P99, DOI 10.1007/978-3-030-33720-9_8
   Kosara R, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1210860
   Kruger J, 1999, J PERS SOC PSYCHOL, V77, P1121, DOI 10.1037/0022-3514.77.6.1121
   Laidlaw DH, 2005, IEEE T VIS COMPUT GR, V11, P59, DOI 10.1109/TVCG.2005.4
   Lan FF, 2023, Arxiv, DOI arXiv:2306.01186
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liu RC, 2014, J VISUAL-JAPAN, V17, P157, DOI 10.1007/s12650-014-0207-4
   Liu Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174172
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Luo MR, 2006, COLOR RES APPL, V31, P320, DOI 10.1002/col.20227
   Makram M, 2014, Int J Image Process, V8, P17
   Masood T. B., 2021, Topological Methods in Data Analysis and Visualization VI - Theory, Applications, and Software, V9, P4
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Morozov D., 2013, TOPOINVIS TOPOLOGICA
   Morse M, 1930, P NATL ACAD SCI USA, V16, P777, DOI 10.1073/pnas.16.11.777
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Natarajan V, 2008, MATH VIS, P237, DOI 10.1007/978-3-540-72630-2_14
   Nauleau F, 2022, SYMP LARG DATA ANAL, P50, DOI 10.1109/LDAV57265.2022.9966403
   Njeru DK, 2023, COMP M BIO BIO E-IV, V11, P812, DOI 10.1080/21681163.2022.2113824
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Post FH, 2003, COMPUT GRAPH FORUM, V22, P775, DOI 10.1111/j.1467-8659.2003.00723.x
   printablemodels, Free3d
   Quadri GJ, 2022, IEEE T VIS COMPUT GR, V28, P5026, DOI 10.1109/TVCG.2021.3098240
   Quadri GJ, 2021, IEEE T VIS COMPUT GR, V27, P1829, DOI 10.1109/TVCG.2020.3030365
   Reininghaus J, 2015, PROC CVPR IEEE, P4741, DOI 10.1109/CVPR.2015.7299106
   Rogowitz E. E., 1996, Computers in Physics, V10, P268
   Rosen P., 2021, Topological Methods in Data Analysis and Visualization VI, P87, DOI [DOI 10.1007/978-3-030-83500-2_62, 10.1007/978-3-030-83500-2_6, DOI 10.1007/978-3-030-83500-2_6]
   Saltelli A., 2008, Global Sensitivity Analysis: The Primer, DOI DOI 10.1002/97804707251842,5
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/SMI.2004.1314504
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   threejs, three.js - javascript 3d library
   Tierny J, 2017, MATH VIS, P1, DOI 10.1007/978-3-319-71507-0
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2017, IEEE T VIS COMPUT GR, V23, P960, DOI 10.1109/TVCG.2016.2599017
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Tricoche X., 2002, Schriftenreihe Fachbereich Informatik, P2
   University of Michigan, 1969, Bluelink anatomy (@bluelinkanatomy) [8-86582]
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Varakin DA, 2004, HUM-COMPUT INTERACT, V19, P389, DOI 10.1207/s15327051hci1904_9
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
   Yu-Hsuan Chan, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P43, DOI 10.1109/VAST.2010.5652460
   Zhou L, 2016, IEEE T VIS COMPUT GR, V22, P2051, DOI 10.1109/TVCG.2015.2489649
NR 88
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1074
EP 1084
DI 10.1109/TVCG.2023.3326592
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500069
PM 37871073
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lukasczyk, J
   Will, M
   Wetzels, F
   Weber, GH
   Garth, C
AF Lukasczyk, Jonas
   Will, Michael
   Wetzels, Florian
   Weber, Gunther H.
   Garth, Christoph
TI ExTreeM: Scalable Augmented Merge Tree Computation via Extremum Graphs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalar field topology; merge trees; persistence pairs; high performance
   computing
ID SIMULATION; TOPOLOGY
AB Over the last decade merge trees have been proven to support a plethora of visualization and analysis tasks since they effectively abstract complex datasets. This paper describes the ExTreeM-Algorithm: a scalable algorithm for the computation of merge trees via extremum graphs. The core idea of ExTreeM is to first derive the extremum graph G of an input scalar fi eldf defined on a cell complex K, and subsequently compute the unaugmented merge tree of f on G instead of K; which are equivalent. Any merge tree algorithm can be carried out significantly faster on G , since K in general contains substantially more cells than G . To further speed up computation, ExTreeM includes a tailored procedure to derive merge trees of extremum graphs. The computation of the fully augmented merge tree, i.e., a merge tree domain segmentation of K, can then be performed in an optional post-processing step. All steps of ExTreeM consist of procedures with high parallel efficiency, and we provide a formal proof of its correctness. Our experiments, performed on publicly available datasets, report a speedup of up to one order of magnitude over the state-of-the-art algorithms included in the TTK and VTK-m software libraries, while also requiring significantly less memory and exhibiting excellent scaling behavior.
C1 [Lukasczyk, Jonas; Will, Michael; Wetzels, Florian; Garth, Christoph] RPTU Kaiserslautern Landau, Kaiserslautern, Germany.
   [Weber, Gunther H.] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
C3 United States Department of Energy (DOE); Lawrence Berkeley National
   Laboratory
RP Lukasczyk, J (corresponding author), RPTU Kaiserslautern Landau, Kaiserslautern, Germany.
EM lukasczyk@rptu.de; mswill@rptu.de; wetzels@rptu.de; ghweber@lbl.gov;
   garth@rptu.de
RI Weber, Gunther/AAA-9678-2019; Garth, Christoph/Q-5901-2018
OI Will, Michael/0009-0007-1344-3694; Wetzels, Florian/0000-0002-5526-7138;
   Weber, Gunther H./0000-0002-1794-1398; Garth,
   Christoph/0000-0003-1669-8549
FU Exascale Computing Project
FX No Statement Available
CR Ahrens J., 2005, The Visualization Handbook, P9
   Ande A, 2023, COMPUT GRAPH FORUM, V42, DOI 10.1111/cgf.14784
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Carr H. A., 2003, Computational Geometry, V24, P3
   Carr H, 2009, MATH VIS, P59, DOI 10.1007/978-3-540-88606-8_5
   Carr HA, 2022, IEEE T VIS COMPUT GR, V28, P3471, DOI 10.1109/TVCG.2021.3064385
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chiang Y.-J., 2005, Computational Geometry, V30, P3
   Cohen RH, 2002, PHYS FLUIDS, V14, P3692, DOI 10.1063/1.1504452
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2009, American Mathematical Society, V2, P3
   Edelsbrunner H, 2012, DISCRETE COMPUT GEOM, V47, P393, DOI 10.1007/s00454-011-9382-4
   Federer F., Pyramidal neurons in the marmoset primary visual cortex
   Freudenthal H, 1942, ANN MATH, V43, P580, DOI 10.2307/1968813
   Grout RW, 2012, J FLUID MECH, V706, P351, DOI 10.1017/jfm.2012.257
   Gueunet C, 2017, SYMP LARG DATA ANAL, P6, DOI 10.1109/LDAV.2017.8231846
   Guo F, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.155005
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Klacansky P., 2023, Open Scientific Visualization Datasets
   Klacansky P, 2020, IEEE T VIS COMPUT GR, V26, P173, DOI 10.1109/TVCG.2019.2934257
   Kreeger K., Ct scan of a backpack filled with items
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48, DOI [10.1090/S0002-9939-1956-0078686-7, DOI 10.1090/S0002-9939-1956-0078686-7, http://dx.doi.org/10.1090/S0002-9939-1956-0078686-7]
   Maack R. G., 2023, IEEE Transactions on Visualization and Computer Graphics, V4
   Maadasamy S, 2012, INT C HIGH PERFORM
   Masood T. B., 2019, TopoInVis 2019-Topological Methods in Data Analysis and Visualization, V1, P3
   Moreland K, 2016, IEEE COMPUT GRAPH, V36, P48, DOI 10.1109/MCG.2016.48
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Nigmetov A., 2022, 2022 TOPOLOGICAL DAT, P1
   Nigmetov A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356188
   OpenMP Architecture Review Board, 2008, OpenMP application program interface version 3.0
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Perlin K., 1985, ACM Siggraph Computer Graphics, V19, P8
   Rowe T., Digimorph - Lampropeltis getula (common kingsnake) - digimorph.org
   Schroeder W. J., 2004, The Visualization Toolkit: An Object Oriented Approach to 3D Graphics, V1, P8
   Smirnov D., 2020, Topological Methods in Data Analysis and Visualization V: Theory, Algorithms, and Applications, V7, P19
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   TTK Contributers, TTK data examples
NR 41
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1085
EP 1094
DI 10.1109/TVCG.2023.3326526
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500119
PM 37871087
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wetzels, F
   Pont, M
   Tierny, J
   Garth, C
AF Wetzels, Florian
   Pont, Mathieu
   Tierny, Julien
   Garth, Christoph
TI Merge Tree Geodesics and Barycenters with Path Mappings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topological data analysis; merge trees; scalar data; ensemble data
ID PERSISTENCE; DISTANCES; SYMMETRY; GRAPHS
AB Comparative visualization of scalar fields is often facilitated using similarity measures such as edit distances. In this paper, we describe a novel approach for similarity analysis of scalar fields that combines two recently introduced techniques: Wasserstein geodesics/barycenters as well as path mappings, a branch decomposition-independent edit distance. Effectively, we are able to leverage the reduced susceptibility of path mappings to small perturbations in the data when compared with the original Wasserstein distance. Our approach therefore exhibits superior performance and quality in typical tasks such as ensemble summarization, ensemble clustering, and temporal reduction of time series, while retaining practically feasible runtimes. Beyond studying theoretical properties of our approach and discussing implementation aspects, we describe a number of case studies that provide empirical insights into its utility for comparative visualization, and demonstrate the advantages of our method in both synthetic and real-world scenarios. We supply a C++ implementation that can be used to reproduce our results.
C1 [Wetzels, Florian; Garth, Christoph] Univ Kaiserslautern Landau, Kaiserslautern, Germany.
   [Pont, Mathieu; Tierny, Julien] Sorbonne Univ, CNRS, Paris, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Wetzels, F (corresponding author), Univ Kaiserslautern Landau, Kaiserslautern, Germany.
EM wetzels@rptu.de; mathieu.pont@sorbonne-universite.fr;
   julien.tierny@sorbonne-universite.fr; garth@rptu.de
RI Garth, Christoph/Q-5901-2018
OI Wetzels, Florian/0000-0002-5526-7138; Garth,
   Christoph/0000-0003-1669-8549; Pont, Mathieu/0000-0002-0037-0314
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Ahrens J., 2005, VISUALIZATION HDB, P717, DOI [10.1016/b978-012387582-2/50038-1, DOI 10.1016/B978-012387582-2/50038-1, 10.1016/B978-012387582-2/50038-1]
   Bauer U., 2016, 9 EUR WORKSH 3D OBJ, DOI [DOI 10.2312/3DOR.20161084, 10.2312/3dor.20161084]
   Bauer U., 2014, P 30 ANN S COMP GEOM, P464
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Bollen B, 2023, IEEE T VIS COMPUT GR, V29, P1168, DOI 10.1109/TVCG.2022.3209395
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2010, IEEE T VIS COMPUT GR, V16, P248, DOI 10.1109/TVCG.2009.69
   Bronstein A. M., 2009, Monographs in Computer Science, DOI [10.1007/978-0-387-73301-26, DOI 10.1007/978-0-387-73301-26]
   Carr H., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P49
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Chazal F, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P237, DOI 10.1145/1542362.1542407
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cohen-Steiner D, 2010, FOUND COMPUT MATH, V10, P127, DOI 10.1007/s10208-010-9060-6
   Di Fabio B, 2016, DISCRETE COMPUT GEOM, V55, P423, DOI 10.1007/s00454-016-9758-6
   Edelsbrunner H, 2000, ANN IEEE SYMP FOUND, P454
   Edelsbrunner H., 2010, American Mathematical Society, V2, P3
   Edelsbrunner H, 2008, COMP GEOM-THEOR APPL, V41, P149, DOI 10.1016/j.comgeo.2007.11.001
   Elkan C., 2003, MACH LEARN P 20 INT, P5
   Evers M., COMPUTER VISION IMAG
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Gasparovic E., PREPRINT
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kopp Wiebke, 2023, IEEE Trans Vis Comput Graph, V29, P1157, DOI 10.1109/TVCG.2022.3209387
   Kraus M, 2010, IMAGAPP & IVAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS, P132
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lohfink A. P., 2021, Source Code for Fuzzy Contour Trees: Alignment and Joint Layout of Multiple Contour Trees
   Lohfink AP, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P86, DOI [10.1109/VIS49827.2021.00025, 10.1109/VIS49827.2021.9623286]
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Lukasczyk J, 2017, COMPUT GRAPH FORUM, V36, P13, DOI 10.1111/cgf.13164
   Morozov D., 2014, Topological methods in data analysis and visualization, III: Theory, algorithms, and applications, P89, DOI DOI 10.1007/978-3-319-04099-86
   Morozov D., 2014, TopoInVis
   Morozov D, 2013, ACM SIGPLAN NOTICES, V48, P93, DOI 10.1145/2517327.2442526
   Narayanan V, 2015, IEEE PAC VIS SYMP, P263, DOI 10.1109/PACIFICVIS.2015.7156386
   Nilsson E, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P92, DOI 10.1109/TopoInVis57755.2022.00016
   Oesterling P., 2017, Topological Methods in Data Analysis and Visualization IV, P87, DOI [DOI 10.1007/978-3-319-44684-4_52, 10.1007/978-3-319-44684-4_5.2, DOI 10.1007/978-3-319-44684-4_5.2]
   Pascucci V., 2004, IASTED
   Patchett J., The IEEE SciVis Contest
   Pont M, 2023, IEEE T VIS COMPUT GR, V29, P1573, DOI 10.1109/TVCG.2022.3215001
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Popinet S., 2004, ClusterWorld, V2, P7
   Saikia H, 2017, COMPUT GRAPH FORUM, V36, P1, DOI 10.1111/cgf.13163
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Schnorr A, 2020, IEEE T VIS COMPUT GR, V26, P2219, DOI 10.1109/TVCG.2018.2883630
   Shu QY, 2016, IEEE PAC VIS SYMP, P56, DOI 10.1109/PACIFICVIS.2016.7465251
   Sridharamurthy R, 2023, IEEE T VIS COMPUT GR, V29, P1518, DOI 10.1109/TVCG.2021.3122176
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Taylor R., 2008, The IEEE SciVis Contest
   Thomas DM, 2013, IEEE T VIS COMPUT GR, V19, P2663, DOI 10.1109/TVCG.2013.148
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Turner K, 2014, DISCRETE COMPUT GEOM, V52, P44, DOI 10.1007/s00454-014-9604-7
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P1416, DOI 10.1109/TVCG.2007.70601
   Weinkauf T, 2010, IEEE T VIS COMPUT GR, V16, P1225, DOI 10.1109/TVCG.2010.198
   Wetzels F., Merge tree geodesics and barycenters with path mappings, DOI [10.5281/zenodo.8160990,2023.10, DOI 10.5281/ZENODO.8160990,2023.10]
   Wetzels F, 2022, 2022 IEEE WORKSHOP ON TOPOLOGICAL DATA ANALYSIS AND VISUALIZATION (TOPOINVIS 2022), P29, DOI 10.1109/TopoInVis57755.2022.00010
   Wetzels F, 2022, COMPUT GRAPH FORUM, V41, P367, DOI 10.1111/cgf.14547
   Widanagamaachchi W., 2012, 2012 IEEE Symposium on Large Data Analysis and Visualization (LDAV 2012), P9, DOI 10.1109/LDAV.2012.6378962
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2023, IEEE T VIS COMPUT GR, V29, P3489, DOI 10.1109/TVCG.2022.3163349
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
NR 68
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1095
EP 1105
DI 10.1109/TVCG.2023.3326601
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500090
PM 37878452
OA Green Published, hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Piccolotto, N
   Bögl, M
   Muehlmann, C
   Nordhausen, K
   Filzmoser, P
   Schmidt, J
   Miksch, S
AF Piccolotto, Nikolaus
   Boegl, Markus
   Muehlmann, Christoph
   Nordhausen, Klaus
   Filzmoser, Peter
   Schmidt, Johanna
   Miksch, Silvia
TI Data Type Agnostic Visual Sensitivity Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; parameter space analysis; sensitivity analysis;
   spatial blind source separation
ID LARGE-SCALE SYSTEMS; UNCERTAINTY ANALYSIS; SPACE; EXPLORATION;
   ANALYTICS; VISUALIZATION
AB Modern science and industry rely on computational models for simulation, prediction, and data analysis. Spatial blind source separation (SBSS) is a model used to analyze spatial data. Designed explicitly for spatial data analysis, it is superior to popular non-spatial methods, like PCA. However, a challenge to its practical use is setting two complex tuning parameters, which requires parameter space analysis. In this paper, we focus on sensitivity analysis (SA). SBSS parameters and outputs are spatial data, which makes SA difficult as few SA approaches in the literature assume such complex data on both sides of the model. Based on the requirements in our design study with statistics experts, we developed a visual analytics prototype for data type agnostic visual sensitivity analysis that fits SBSS and other contexts. The main advantage of our approach is that it requires only dissimilarity measures for parameter settings and outputs (Fig. 1). We evaluated the prototype heuristically with visualization experts and through interviews with two SBSS experts. In addition, we show the transferability of our approach by applying it to microclimate simulations. Study participants could confirm suspected and known parameter-output relations, find surprising associations, and identify parameter subspaces to examine in the future. During our design study and evaluation, we identified challenging future research opportunities.
C1 [Piccolotto, Nikolaus; Boegl, Markus; Muehlmann, Christoph; Filzmoser, Peter; Miksch, Silvia] TU Wien, Vienna, Austria.
   [Nordhausen, Klaus] Univ Jyvaskyla, Jyvaskyla, Finland.
   [Schmidt, Johanna] VRVis GmbH, Vienna, Austria.
C3 Technische Universitat Wien; University of Jyvaskyla
RP Piccolotto, N (corresponding author), TU Wien, Vienna, Austria.
EM nikolaus.piccolotto@tuwien.ac.at; markus.bogl@tuwien.ac.at;
   christoph.muehlmann@tuwien.ac.at; klaus.k.nordhausen@jyu.fi;
   peter.filzmoser@tuwien.ac.at; johanna.schmidt@vrvis.at;
   silvia.miksch@tuwien.ac.at
RI Bögl, Markus/ISS-2644-2023; Filzmoser, Peter/A-7737-2015; Nordhausen,
   Klaus/A-8644-2008
OI Muehlmann, Christoph/0000-0001-7330-8434; Schmidt,
   Johanna/0000-0002-9638-6344; Piccolotto, Nikolaus/0000-0001-6876-6502;
   Nordhausen, Klaus/0000-0002-3758-8501; Miksch,
   Silvia/0000-0003-4427-5703; Bogl, Markus/0000-0002-8337-4774
FU Austrian Science Fund (FWF)
FX No Statement Available
CR Abuzuraiq A. M., 2020, RE ANTHROPOCENE DESI, V1, P485, DOI DOI 10.52842/CONF.CAADRIA.2020.1.4852
   Bachoc F, 2020, BIOMETRIKA, V107, P627, DOI 10.1093/biomet/asz079
   Bar-Joseph Z., 2001, BIOINFORMATICS S1, V17 Suppl 1, pS22, DOI [10.1093/bioinformatics/17.suppl1.S22, 10.1093/bioinformatics/17.suppl_1.s22]
   Beham M, 2014, IEEE T VIS COMPUT GR, V20, P1693, DOI 10.1109/TVCG.2014.2346626
   Bergner S, 2013, IEEE T VIS COMPUT GR, V19, P1499, DOI 10.1109/TVCG.2013.61
   Blanch R, 2015, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2015.7156353
   Borgonovo E, 2016, EUR J OPER RES, V248, P869, DOI 10.1016/j.ejor.2015.06.032
   Bruckner S, 2010, IEEE T VIS COMPUT GR, V16, P1468, DOI 10.1109/TVCG.2010.190
   Cacuci DG, 2004, NUCL SCI ENG, V147, P204, DOI 10.13182/04-54CR
   Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Cavallo M, 2019, IEEE T VIS COMPUT GR, V25, P267, DOI 10.1109/TVCG.2018.2864477
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Cibulski L., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2022.31808992
   Cibulski L, 2020, COMPUT GRAPH FORUM, V39, P405, DOI 10.1111/cgf.13990
   de Leeuw J., 2005, Encyclopedia of Statistics in Behavioral Science, pbsa612, DOI DOI 10.1002/0470013192.BSA6125
   Desai R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300599
   Doraiswamy H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818134
   Eichner C, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.13894
   Galili T, 2015, BIOINFORMATICS, V31, P3718, DOI 10.1093/bioinformatics/btv428
   Günther T, 2016, COMPUT GRAPH FORUM, V35, P455, DOI 10.1111/cgf.12846
   Gutierrez J.M., 2021, Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report of the Intergovernmental Panel on Climate Change, P1927, DOI [10.1017/9781009157896.021, DOI 10.1017/9781009157896.021]
   HAMBY DM, 1994, ENVIRON MONIT ASSESS, V32, P135, DOI 10.1007/BF00547132
   Hazarika S, 2020, IEEE T VIS COMPUT GR, V26, P34, DOI 10.1109/TVCG.2019.2934591
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Ilmonen P, 2010, LECT NOTES COMPUT SC, V6365, P229, DOI 10.1007/978-3-642-15995-4_29
   Ionescu-Bujor M, 2004, NUCL SCI ENG, V147, P189, DOI 10.13182/NSE03-105CR
   Iooss B., 2015, Uncertainty Management in Simulation-Optimization of Complex Systems, V59, P101, DOI DOI 10.1007/978-1-4899-7547-85
   Jankun-Kelly TJ, 2000, IEEE VISUAL, P69, DOI 10.1109/VISUAL.2000.885678
   Jeon H, 2022, IEEE T VIS COMPUT GR, V28, P551, DOI 10.1109/TVCG.2021.3114833
   Knittel J, 2021, IEEE T VIS COMPUT GR, V27, P1374, DOI 10.1109/TVCG.2020.3030420
   Koyama Yuki, 2014, P 27 ANN ACM S US IN, P65, DOI [DOI 10.1145/2642918.2647386, 10.1145/2642918.2647386]
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   L'Yi S, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/1471-2105-16-S11-S5
   Ligmann-Zielinska A, 2013, INT J GEOGR INF SCI, V27, P1764, DOI 10.1080/13658816.2013.782613
   Lilburne L, 2009, INT J GEOGR INF SCI, V23, P151, DOI 10.1080/13658810802094995
   Liu Y, 2010, 2010 IEEE International Conference on Data Mining, P911, DOI [DOI 10.1109/ICDM.2010.35, 10.1109/ICDM.2010.35]
   Luboschik M, 2015, COMPUT GRAPH FORUM, V34, P421, DOI 10.1111/cgf.12654
   Luboschik M, 2014, COMPUT GRAPH-UK, V39, P37, DOI 10.1016/j.cag.2013.09.004
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   Marrel A, 2011, ENVIRONMETRICS, V22, P383, DOI 10.1002/env.1071
   Matkovic K, 2017, LECT NOTES COMPUT SC, V10410, P199, DOI 10.1007/978-3-319-66808-6_14
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Muehlmann C, 2022, SPAT STAT-NETH, V47, DOI 10.1016/j.spasta.2021.100574
   Nordhausen K, 2015, MATH GEOSCI, V47, P753, DOI 10.1007/s11004-014-9559-5
   Orban D, 2019, IEEE T VIS COMPUT GR, V25, P256, DOI 10.1109/TVCG.2018.2865051
   Pajer S, 2017, IEEE T VIS COMPUT GR, V23, P611, DOI 10.1109/TVCG.2016.2598589
   Piccolotto N, 2022, COMPUT GRAPH FORUM, V41, P157, DOI 10.1111/cgf.14530
   Piccolotto N., 2023, Computer Graphics Forum, DOI DOI 10.1111/CGF.147852,3
   Piccolotto N, 2022, VIS INFORM, V6, P51, DOI 10.1016/j.visinf.2022.10.002
   Raimbault J, 2019, JASSS-J ARTIF SOC S, V22, DOI 10.18564/jasss.4136
   Rohlf F. J., 1982, Handbook of Statistics, V2, P267, DOI [10.1016/s0169-7161(82)02015-x3, DOI 10.1016/S0169-7161(82)02015-X3]
   Rojo IB, 2018, COMPUT GRAPH FORUM, V37, P289, DOI 10.1111/cgf.13420
   Saltelli A, 2002, RISK ANAL, V22, P579, DOI 10.1111/0272-4332.00040
   Saltelli A., 2007, Global Sensitivity Analysis: The Primer, DOI DOI 10.1002/97804707251842
   Saltelli A, 2019, ENVIRON MODELL SOFTW, V114, P29, DOI 10.1016/j.envsoft.2019.01.012
   Schulz A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073688
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Seo J, 2002, COMPUTER, V35, P80
   Sobol' IM., 1990, MATEM MOD, V2, P112, DOI DOI 10.18287/0134-2452-2015-39-4-459-461
   Steed CA, 2013, COMPUT GEOSCI-UK, V61, P71, DOI 10.1016/j.cageo.2013.07.025
   Vuckovic M, 2022, INFORMATION, V13, DOI 10.3390/info13010007
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang JP, 2017, IEEE T VIS COMPUT GR, V23, P81, DOI 10.1109/TVCG.2016.2598830
   Wattenberg M., 2016, Distill, V1, pe2, DOI DOI 10.23915/DISTILL.00002
   Weissenböck J, 2016, IEEE CONF VIS ANAL, P101, DOI 10.1109/VAST.2016.7883516
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Yang HY, 2021, COMPUT GRAPH FORUM, V40, P275, DOI 10.1111/cgf.14306
   Zhenyu Guo, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P131, DOI 10.1109/VAST.2011.6102450
NR 72
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1106
EP 1116
DI 10.1109/TVCG.2023.3327203
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500029
PM 37922175
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Wu, YC
   Xu, YS
   Gao, SH
   Wang, XB
   Song, WK
   Nie, ZH
   Fan, XM
   Li, Q
AF Wu, Yuchen
   Xu, Yuansong
   Gao, Shenghan
   Wang, Xingbo
   Song, Wenkai
   Nie, Zhiheng
   Fan, Xiaomeng
   Li, Quan
TI LiveRetro: Visual Analytics for Strategic Retrospect in Livestream
   E-Commerce
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Livestream E-commerce; Visual Analytics; Multimodal Video Analysis;
   Marketing Strategy; Time-series Modeling
ID LIVE; EVOLUTION; BEHAVIOR; CURVES; TIME
AB Livestream e-commerce integrates live streaming and online shopping, allowing viewers to make purchases while watching. However, effective marketing strategies remain a challenge due to limited empirical research and subjective biases from the absence of quantitative data. Current tools fail to capture the interdependence between live performances and feedback. This study identified computational features, formulated design requirements, and developed LiveRetro, an interactive visual analytics system. It enables comprehensive retrospective analysis of livestream e-commerce for streamers, viewers, and merchandise. LiveRetro employs enhanced visualization and time-series forecasting models to align performance features and feedback, identifying influences at channel, merchandise, feature, and segment levels. Through case studies and expert interviews, the system provides deep insights into the relationship between live performance and streaming statistics, enabling efficient strategic analysis from multiple perspectives.
C1 [Wu, Yuchen; Xu, Yuansong; Gao, Shenghan; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Wu, Yuchen; Xu, Yuansong; Gao, Shenghan; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Song, Wenkai; Fan, Xiaomeng] ShanghaiTech Univ, Sch Entrepreneurship & Management, Shanghai, Peoples R China.
   [Wang, Xingbo] Cornell Univ, Weill Cornell Med Coll, Ithaca, NY USA.
   [Nie, Zhiheng] Be Friends Holding Ltd, Beijing, Peoples R China.
C3 ShanghaiTech University; ShanghaiTech University; Cornell University;
   Weill Cornell Medicine
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM wuych3@shanghaitech.edu.cn; xuys1@shanghaitech.edu.cn;
   gaoshh1@shanghaitech.edu.cn; xingbo.wang@med.cornell.edu;
   songwk@shanghaitech.edu.cn; 815194445@qq.com; fanxm@shanghaitech.edu.cn;
   liquan@shanghaitech.edu.cn
RI Wu, Yuchen/AFB-8756-2022; Wang, Xingbo/JHS-6567-2023
OI Shenghan, Gao/0009-0008-3397-0341; Wang, Xingbo/0000-0001-5693-1128;
   Fan, Xiaomeng/0000-0002-6302-8786
FU Shanghai Frontiers Science Center of Human-centered Artificial
   Intelligence (ShangHAI); Key Laboratory of Intelligent Perception and
   Human-Machine Collaboration (ShanghaiTech University), Ministry of
   Education
FX This work is partially supported by the Shanghai Frontiers Science
   Center of Human-centered Artificial Intelligence (ShangHAI) and Key
   Laboratory of Intelligent Perception and Human-Machine Collaboration
   (ShanghaiTech University), Ministry of Education.
CR Ariely D, 2003, Q J ECON, V118, P73, DOI 10.1162/00335530360535153
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Batch A., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2023.32415812,3, DOI 10.1109/TVCG.2023.32415812,3]
   Boersma P., 2001, Glot International, V5, P341
   Bonoma T. V., 1985, The marketing edge: Making strategies work, DOI [10.2307/12516052, DOI 10.2307/12516052]
   Brown T. A., 2015, Confirmatory Factor Analysis for Applied Research, P3
   Cai J, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P2548
   Cespedes FrankV., 1996, J MARKET MANAG, V12, P135, DOI DOI 10.1080/0267257X.1996.99644052
   Chen L., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1070, DOI [10.1109/TVCG.2022.32093513, DOI 10.1109/TVCG.2022.32093513]
   Chen S, 2022, COMPUT GRAPH FORUM, V41, P429, DOI 10.1111/cgf.14552
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Espadoto M, 2021, IEEE T VIS COMPUT GR, V27, P2153, DOI 10.1109/TVCG.2019.2944182
   Fei MQ, 2021, DECIS SUPPORT SYST, V142, DOI 10.1016/j.dss.2020.113466
   Gauri DK, 2021, J RETAILING, V97, P42, DOI 10.1016/j.jretai.2020.11.002
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo LY, 2021, INTERNET RES, V31, P1718, DOI 10.1108/INTR-02-2020-0078
   Guo YY, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102786
   Haenlein M, 2020, CALIF MANAGE REV, V63, P5, DOI 10.1177/0008125620958166
   Hamel G., 1990, Mckinsey quarterly, P2
   Hou FF, 2020, INTERNET RES, V30, P141, DOI 10.1108/INTR-04-2018-0177
   Hu MY, 2020, INTERNET RES, V30, P1019, DOI 10.1108/INTR-03-2019-0082
   HUTT MD, 1988, J MARKETING, V52, P4, DOI 10.2307/1251682
   Jacoby J, 2002, J CONSUM PSYCHOL, V12, P51, DOI 10.1207/S15327663JCP1201_05
   John M, 2019, IEEE INT CON INF VIS, P241, DOI 10.1109/IV.2019.00048
   Kang K, 2021, INT J INFORM MANAGE, V56, DOI 10.1016/j.ijinfomgt.2020.102251
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Lee CH, 2021, INFORMATION, V12, DOI 10.3390/info12060241
   Li HT, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445294
   Li Y, 2021, J RETAIL CONSUM SERV, V60, DOI 10.1016/j.jretconser.2021.102478
   Lin Y, 2021, J MARKETING RES, V58, P417, DOI 10.1177/00222437211002477
   Lu BJ, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103509
   Lu CYR, 2020, INT J ONLINE MARKET, V10, P1, DOI 10.4018/IJOM.2020070101
   Lu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174040
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Maher K, 2022, IEEE T VIS COMPUT GR, V28, P508, DOI 10.1109/TVCG.2021.3114789
   MARKUS ML, 1987, COMMUN RES, V14, P491, DOI 10.1177/009365087014005003
   MCGUIRE WJ, 1984, PREV MED, V13, P299, DOI 10.1016/0091-7435(84)90086-0
   Meng L, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102733
   Ming JL, 2021, INT J WEB INF SYST, V17, P300, DOI 10.1108/IJWIS-02-2021-0012
   Morgan NA, 2019, J ACAD MARKET SCI, V47, P4, DOI 10.1007/s11747-018-0598-1
   Nickerson R.S., 1998, Review of General Psychology, V2, P175, DOI [DOI 10.1037/1089-2680.2.2.175, 10.1037/1089-2680.2.2.175, 10.1037/1089-2680.2.2.17]
   NUTT PC, 1983, ACAD MANAGE REV, V8, P600, DOI 10.2307/258261
   Park HJ, 2020, J RETAIL CONSUM SERV, V52, DOI 10.1016/j.jretconser.2019.101934
   Parkhi O. M., 2015, Deep face recognition, DOI [10.5244/C.29.415, DOI 10.5244/C.29.415]
   Piercy N. F., 2016, Market-Led Strategic Change: Transforming the Process of Going to Market, P2
   Ram J., 2019, Journal Europeen Des Systemes Automatises, V52, P1, DOI DOI 10.18280/JESA.520101
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Song D., 2021, P 14 CHIN SUMM WORKS, P225
   Soure EJ, 2022, IEEE T VIS COMPUT GR, V28, P643, DOI 10.1109/TVCG.2021.3114822
   Sun Y, 2021, Arxiv, DOI arXiv:2107.02137
   Sun Y, 2019, ELECTRON COMMER R A, V37, DOI 10.1016/j.elerap.2019.100886
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P4609, DOI 10.1109/TVCG.2021.3097709
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wohn DY, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174048
   Wong K. K., 2023, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2023.32456092, DOI 10.1109/TVCG.2023.32456092]
   Wongkitrungrueng A, 2020, J MARKET MANAG-UK, V36, P488, DOI 10.1080/0267257X.2020.1748895
   Wongkitrungrueng A, 2020, J BUS RES, V117, P543, DOI 10.1016/j.jbusres.2018.08.032
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Wu C.-C., 2021, Forming the strategy for live streaming e-commerce: An Action Research, DOI [10.24251/HICSS.2021.3382, DOI 10.24251/HICSS.2021.3382]
   Wu Q., 2022, ACM Transactions on Computer-Human Interaction, DOI [10.1145/35771992, DOI 10.1145/35771992]
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Xu XY, 2020, J ELECTRON COMMER RE, V21, P144
   Yang X, 2023, J RETAIL CONSUM SERV, V70, DOI 10.1016/j.jretconser.2022.103155
   Yuan KH, 2007, HANDB STAT, V26, P297, DOI 10.1016/S0169-7161(06)26010-3
   Yuanda Ling, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873038
   Zeng H., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.31691752,3, DOI 10.1109/TVCG.2022.31691752,3]
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang C., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P767, DOI [10.1109/tvcg.2022.32094406, DOI 10.1109/TVCG.2022.32094403,6]
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
   Zhang GQ, 1998, INT J FORECASTING, V14, P35, DOI 10.1016/S0169-2070(97)00044-7
   Zhang SL, 2022, SERV IND J, V42, P1001, DOI 10.1080/02642069.2022.2068530
NR 79
TC 2
Z9 2
U1 18
U2 32
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1117
EP 1127
DI 10.1109/TVCG.2023.3326911
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500113
PM 37874716
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, CL
   Thompson, J
   Lee, B
AF Wang, Chenglong
   Thompson, John
   Lee, Bongshin
TI Data Formulator: AI-Powered Concept-Driven Visualization Authoring
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Temperature distribution; Urban areas;
   Visualization; Transforms; Histograms; Libraries; AI; visualization
   authoring; data transformation; programming by example; natural
   language; large language model
ID DESIGN; LYRA
AB With most modern visualization tools, authors need to transform their data into tidy formats to create visualizations they want. Because this requires experience with programming or separate data processing tools, data transformation remains a barrier in visualization authoring. To address this challenge, we present a new visualization paradigm, concept binding, that separates high-level visualization intents and low-level data transformation steps, leveraging an AI agent. We realize this paradigm in Data Formulator, an interactive visualization authoring tool. With Data Formulator, authors first define data concepts they plan to visualize using natural languages or examples, and then bind them to visual channels. Data Formulator then dispatches its AI-agent to automatically transform the input data to surface these concepts and generate desired visualizations. When presenting the results (transformed table and output visualizations) from the AI agent, Data Formulator provides feedback to help authors inspect and understand them. A user study with 10 participants shows that participants could learn and use Data Formulator to create visualizations that involve challenging data transformations, and presents interesting future research directions.
C1 [Wang, Chenglong; Thompson, John; Lee, Bongshin] Microsoft Res, Redmond, WA 98052 USA.
C3 Microsoft
RP Wang, CL (corresponding author), Microsoft Res, Redmond, WA 98052 USA.
EM chenglong.wang@microsoft.com; johnthompson@microsoft.com;
   bongshin@microsoft.com
OI Thompson, John/0000-0002-3102-4035
CR Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030
   Barman S, 2016, ACM SIGPLAN NOTICES, V51, P748, DOI 10.1145/3022671.2984020
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Chaudhuri S, 2021, FOUND TRENDS PROGRAM, V7, P158, DOI 10.1561/2500000049
   Chen M., CoRR
   Chen QC, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3563307
   Chowdhery A, 2022, Arxiv, DOI arXiv:2204.02311
   Fried D, 2023, Arxiv, DOI [arXiv:2204.05999, 10.48550/ARXIV.2204.05999, DOI 10.48550/ARXIV.2204.05999]
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010
   Hendrycks D., 2021, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual
   Ji RY, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P1143, DOI 10.1145/3385412.3386025
   Jin ZJ, 2020, PROC VLDB ENDOW, V13, P2368, DOI 10.14778/3407790.3407831
   Jin ZJ, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P683, DOI 10.1145/3035918.3064034
   Kandel S, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3363
   Kery Mary Beth, 2020, P 33 ANN ACM S US IN, DOI DOI 10.1145/3379337.3415842
   Kim D. H., CHI 20
   Lai Yuhang, 2022, arXiv
   Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751
   Lee DJL, 2021, PROC VLDB ENDOW, V15, P727, DOI 10.14778/3494124.3494151
   Li TJJ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P577, DOI 10.1145/3332165.3347899
   Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158
   Liu C, 2021, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis52677.2021.00010
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Ouyang L, 2022, ADV NEUR IN
   Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470
   Poesia G., 2022, 10 INT C LEARNING RE
   Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2858965.2814310, 10.1145/2814270.2814310]
   Pu K, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545691
   Raman V., 2001, VLDB 2001 P 27 INT C, P9
   Ren DH, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P86
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159
   Srinivasan A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445400
   Stolte C., 2002, KDD 02, P112, DOI [10.1145/775047.7750648, DOI 10.1145/775047.775064, 10.1145/775047.775064]
   T. pandas development team, 2023, pandas-dev/pandas: Pandas, DOI [10.5281/zenodo.77415801,9, DOI 10.5281/ZENODO.77415801,9]
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   VanderPlas J, 2018, J. Open Source Softw., V3, P1057, DOI DOI 10.21105/JOSS.01057
   Wang CL, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445249
   Wang CL, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3371117
   Wang CL, 2017, ACM SIGPLAN NOTICES, V52, P452, DOI [10.1145/3062341.3062365, 10.1145/3140587.3062365]
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Wickham H, 2014, J STAT SOFTW, V59, P1
   Wickham Hadley, 2024, CRAN
   Wilkinson L., 2005, The Grammar of Graphics, Second Edition. Statistics and computing, VSecond, P8
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xiong Kai, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209470
   Yan C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1539, DOI 10.1145/3318464.3389738
   Zhang T., 2021, CHI 21 CHI C HUMAN F, P1
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
   Zong J, 2021, IEEE T VIS COMPUT GR, V27, P304, DOI 10.1109/TVCG.2020.3030367
NR 63
TC 1
Z9 1
U1 10
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1128
EP 1138
DI 10.1109/TVCG.2023.3326585
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500081
PM 37871079
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ye, HY
   Li, CH
   Li, Y
   Wang, CB
AF Ye, Huayuan
   Li, Chenhui
   Li, Yang
   Wang, Changbo
TI InvVis: Large-Scale Data Embedding for Invertible Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Steganography; Image restoration; Visualization;
   Image reconstruction; Metadata; QR codes; Information visualization;
   information steganography; invertible visualization; invertible neural
   network
ID IMAGES; INFORMATION
AB We present InvVis, a new approach for invertible visualization, which is reconstructing or further modifying a visualization from an image. InvVis allows the embedding of a significant amount of data, such as chart data, chart information, source code, etc., into visualization images. The encoded image is perceptually indistinguishable from the original one. We propose a new method to efficiently express chart data in the form of images, enabling large-capacity data embedding. We also outline a model based on the invertible neural network to achieve high-quality data concealing and revealing. We explore and implement a variety of application scenarios of InvVis. Additionally, we conduct a series of evaluation experiments to assess our method from multiple perspectives, including data embedding quality, data restoration accuracy, data encoding capacity, etc. The result of our experiments demonstrates the great potential of InvVis in invertible visualization.
C1 [Ye, Huayuan; Li, Chenhui; Li, Yang; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
C3 East China Normal University
RP Li, CH (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai, Peoples R China.
EM huayuan221@gmail.com; chli@cs.ecnu.edu.cn; yli@cs.ecnu.edu.cn;
   cbwang@cs.ecnu.edu.cn
RI Li, Chenhui/AAR-3682-2020
OI Wang, Changbo/0000-0001-8940-6418; ye, huayuan/0009-0008-8208-2017; Li,
   Chenhui/0000-0001-9835-2650
FU NSFC
FX No Statement Available
CR Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Almohammad A., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P215, DOI 10.1109/IPTA.2010.5586786
   Almohammad A, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P544, DOI 10.1109/ARES.2008.72
   Baluja S., 2017, Adv. Neural Inf. Process. Syst. (NIPS), V30, P2
   Bose R. C., 1960, Inf. Control., V3, P3
   Callahan S.P., 2006, INT C MAN DAT 2005 A, P745, DOI 10.1145/1142473.1142574
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen Z., 2019, IEEE Trans. Visual. Comput. Graph., V26, P2
   Cheng KL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1971, DOI 10.1109/ICCV48922.2021.00200
   Choi J., 2019, COMPUT GRAPH FORUM, P2
   Delforouzi A, 2008, CIRC SYST SIGNAL PR, V27, P247, DOI 10.1007/s00034-008-9019-x
   Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]
   Flower A., 2016, Behav. Modif., V40, P2
   Fridrich J., 2001, IEEE Multimed., V8, P2
   Fu Jiayun, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P2786, DOI 10.1145/3503161.3548286
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Guan ZY, 2023, IEEE T PATTERN ANAL, V45, P372, DOI 10.1109/TPAMI.2022.3141725
   Hota A., 2019, IEEE Trans. Visual. Comput. Graph., V26, P2
   ISO, 2015, ISO/IEC18004:2015, P4
   Jing JP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4713, DOI 10.1109/ICCV48922.2021.00469
   Kawaguchi E., 1999, SPIE, V3528, P2
   Kingma D.P., 2014, P INT C LEARNING REP
   Kingma D. P., 2018, Adv. Neural Inf. Process. Syst. (NIPS), V31, P6
   Liu X., 2019, arXiv
   Lu SP, 2021, PROC CVPR IEEE, P10811, DOI 10.1109/CVPR46437.2021.01067
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Moore F., 2017, Polynomial codes over certain finite fields, P3
   N. Earth Science Data Systems, Earthdata. 3
   Paszke A, 2019, ADV NEUR IN, V32
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Por LY, 2008, ELE COM ENG, P689
   Qin J., 2020, Math., V8, P2
   Savva M., 2011, P 24 ANN ACM S US IN, P2
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh M, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P309, DOI 10.5220/0010201203090318
   Song S., 2022, IEEE Trans. Visual. Comput. Graph., V1, P2
   Swanson MD, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P558, DOI 10.1109/ICIP.1997.638832
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WAVE D., Qr code
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Wu Y., 2021, P IEEECVF INT C COMP, P14519
   Xiaoyi Yu, 2004, Proceedings. Third International Conference on Image and Graphics, P333
   Yang Y., 2016, IEEE Trans. Visual. Comput. Graph., V23, P2
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu W., 1999, IEEE Trans. Circ. Syst. Video Technol., V9, P2
NR 57
TC 3
Z9 3
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1139
EP 1149
DI 10.1109/TVCG.2023.3326597
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500106
PM 37871072
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Morrical, N
   Zellmann, S
   Sahistan, A
   Shriwise, P
   Pascucci, V
AF Morrical, Nate
   Zellmann, Stefan
   Sahistan, Alper
   Shriwise, Patrick
   Pascucci, Valerio
TI Attribute-Aware RBFs: Interactive Visualization of Time Series Particle
   Volumes Using RT Core Range Queries
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ray Tracing; Volume Rendering; Particle Volumes; Radial Basis Functions;
   Scientific Visualization
ID MODELS
AB Smoothed-particle hydrodynamics (SPH) is a mesh-free method used to simulate volumetric media in fluids, astrophysics, and solid mechanics. Visualizing these simulations is problematic because these datasets often contain millions, if not billions of particles carrying physical attributes and moving over time. Radial basis functions (RBFs) are used to model particles, and overlapping particles are interpolated to reconstruct a high-quality volumetric field; however, this interpolation process is expensive and makes interactive visualization difficult. Existing RBF interpolation schemes do not account for color-mapped attributes and are instead constrained to visualizing just the density field. To address these challenges, we exploit ray tracing cores in modern GPU architectures to accelerate scalar field reconstruction. We use a novel RBF interpolation scheme to integrate per-particle colors and densities, and leverage GPU-parallel tree construction and refitting to quickly update the tree as the simulation animates over time or when the user manipulates particle radii. We also propose a Hilbert reordering scheme to cluster particles together at the leaves of the tree to reduce tree memory consumption. Finally, we reduce the noise of volumetric shadows by adopting a spatially temporal blue noise sampling scheme. Our method can provide a more detailed and interactive view of these large, volumetric, time-series particle datasets than traditional methods, leading to new insights into these physics simulations.
C1 [Morrical, Nate; Sahistan, Alper; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Zellmann, Stefan] Univ Cologne, Cologne, Germany.
   [Shriwise, Patrick] Argonne Natl Lab, Argonne, IL USA.
C3 Utah System of Higher Education; University of Utah; University of
   Cologne; United States Department of Energy (DOE); Argonne National
   Laboratory
RP Morrical, N (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM natemorrical@gmail.com
RI Müller, Thomas/AAD-3910-2019; pascucci, Valerio/GXF-0616-2022
OI pascucci, valerio/0000-0002-8877-2042; Morrical,
   Nathan/0000-0002-2262-6974; Zellmann, Stefan/0000-0003-2880-9090;
   Sahistan, Alper/0000-0002-3480-7713; Shriwise,
   Patrick/0000-0002-3979-7665
FU UChicago Argonne, LLC
FX No Statement Available
CR AlanWolfe Nathan Morrical, 2022, P EUR S REND, P117, DOI DOI 10.2312/SR.20221161
   Berzins M, 2016, SIAM J SCI COMPUT, V38, pS101, DOI 10.1137/15M1023270
   Cha D, 2009, COMPUT GRAPH FORUM, V28, P1247, DOI 10.1111/j.1467-8659.2009.01502.x
   Evangelou I., 2021, Journal of Computer Graphics Techniques, V10, P25
   Fraedrich R, 2010, IEEE T VIS COMPUT GR, V16, P1533, DOI 10.1109/TVCG.2010.148
   Fraedrich R, 2009, IEEE T VIS COMPUT GR, V15, P1251, DOI 10.1109/TVCG.2009.142
   GINGOLD RA, 1977, MON NOT R ASTRON SOC, V181, P375, DOI 10.1093/mnras/181.3.375
   Gralka P, 2020, SYMP LARG DATA ANAL, P42, DOI 10.1109/LDAV51489.2020.00012
   Green S., 2008, Volumetric particle shadows
   Gumhold S, 2003, VISION, MODELING, AND VISUALIZATION 2003, P245
   Habib S, 2016, NEW ASTRON, V42, P49, DOI 10.1016/j.newast.2015.06.003
   Heinen M, 2019, J CHEM PHYS, V151, DOI 10.1063/1.5111759
   Jang Y., 2010, IEEE EG S VOLUME GRA, DOI [10.2312/VG/VG10/045-052, DOI 10.2312/VG/VG10/045-052]
   Karras Tero, 2012, P 4 ACM SIGGRAPH EUR, P33, DOI [10.2312/EGGH/HPG12/033-037, DOI 10.2312/EGGH/HPG12/033-037]
   Knoll A., 2021, Ray Tracing Gems II, Chapter 44: Path Tracing RBF Particle Volumes, P713, DOI [10.1007/978-1-4842-7185-8_44, DOI 10.1007/978-1-4842-7185-8_44]
   Knoll A., 2019, Ray Tracing Gems, Chapter 29: Efficient Particle Volume Splatting in a Ray Tracer, P533, DOI [10.1007/978-1-4842-4427-2_29, DOI 10.1007/978-1-4842-4427-2_29]
   Knoll A, 2014, COMPUT GRAPH FORUM, V33, P71, DOI 10.1111/cgf.12363
   Kuhnert J, 2014, Advances in PDE modeling and computation, P119
   Kutz P, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073665
   Lauterbach C, 2009, COMPUT GRAPH FORUM, V28, P375, DOI 10.1111/j.1467-8659.2009.01377.x
   Lindemann F, 2011, IEEE T VIS COMPUT GR, V17, P1922, DOI 10.1109/TVCG.2011.161
   LUCY LB, 1977, ASTRON J, V82, P1013, DOI 10.1086/112164
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Morrical N, 2023, IEEE T VIS COMPUT GR, V29, P537, DOI 10.1109/TVCG.2022.3209418
   Morrical N, 2022, IEEE T VIS COMPUT GR, V28, P2852, DOI 10.1109/TVCG.2020.3042930
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Morrical Nathan V, 2023, Zenodo, DOI 10.5281/ZENODO.8173156
   Morrical Nathan V, 2023, Zenodo, DOI 10.5281/ZENODO.8019116
   Navrátil PA, 2007, IEEE T VIS COMPUT GR, V13, P1712, DOI 10.1109/TVCG.2007.70526
   Novak J., 2018, ACM SIGGRAPH COURSES, DOI 10/c5fj
   NVIDIA Corp, 2021, Technical report
   Orthmann J., 2010, Vision, Modeling, and Visualization, P147, DOI [10.2312/PE/VMV/VMV10, DOI 10.2312/PE/VMV/VMV10]
   Piochowiak M, 2021, COMPUT GRAPH FORUM, V40, P97, DOI 10.1111/cgf.14121
   Preston A, 2016, IEEE PAC VIS SYMP, P48, DOI 10.1109/PACIFICVIS.2016.7465250
   Qingyu Meng, 2012, 2012 SC Companion: High-Performance Computing, Networking, Storage and Analysis (SCC), P2441, DOI 10.1109/SCC.2012.6674233
   Simon G., 2020, Particle simulation using CUDA
   Slattery S., 2022, Cabana: A Performance Portable Library for Particle-Based Simulations, DOI [10.5281/zenodo, DOI 10.5281/ZENODO]
   Wald I., 2019, High Performance Graphics (Short Papers), P7, DOI DOI 10.2312/HPG.20191189
   Wald I, 2022, IEEE T VIS COMPUT GR, V28, P583, DOI 10.1109/TVCG.2021.3114869
   Wald I, 2021, IEEE T VIS COMPUT GR, V27, P625, DOI 10.1109/TVCG.2020.3030470
   Winchenbach R, 2020, COMPUT GRAPH FORUM, V39, P527, DOI 10.1111/cgf.14090
   Woodcock E, 1965, P C APPL COMP METH R, V557
   Yu IS, 2009, ACM T APPL PERCEPT, V6, DOI 10.1145/1609967.1609971
   Zellmann S., 2022, EGPGV 2022 22 EUROGR, P61, DOI [10.2312/pgv.20221066, DOI 10.2312/PGV.20221066]
   Zellmann S, 2023, Arxiv, DOI arXiv:2211.09997
   Zellmann S, 2022, COMPUT SCI ENG, V24, P40, DOI 10.1109/MCSE.2022.3153677
   Zellmann S, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P96, DOI 10.1109/VIS47514.2020.00026
   Zhao SW, 2023, INT J NUMER METH ENG, V124, P696, DOI 10.1002/nme.7139
NR 48
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1150
EP 1160
DI 10.1109/TVCG.2023.3327366
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500028
PM 37878450
DA 2024-11-06
ER

PT J
AU Braun, D
   Borgo, R
   Sondag, M
   von Landesberger, T
AF Braun, Daniel
   Borgo, Rita
   Sondag, Max
   von Landesberger, Tatiana
TI Reclaiming the Horizon: Novel Visualization Designs for Time-Series Data
   with Large Value Ranges
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Image color analysis; Bars;
   Standards; Market research; Estimation; Visualization techniques;
   time-series; design study; orders of magnitude; logarithmic scale
AB introduce two novel visualization designs to support practitioners in performing identification and discrimination tasks on large value ranges (i.e., several orders of magnitude) in time-series data: (1) The order of magnitude horizon graph, which extends the classic horizon graph; and (2) the order of magnitude line chart, which adapts the log-line chart. These new visualization designs visualize large value ranges by explicitly splitting the mantissa m and exponent e of a value v = m <middle dot> 10(e). We evaluate our novel designs against the most relevant state-of-the-art visualizations in an empirical user study. It focuses on four main tasks commonly employed in the analysis of time-series and large value ranges visualization: identification, discrimination, estimation, and trend detection. For each task we analyze error, confidence, and response time. The new order of magnitude horizon graph performs better or equal to all other designs in identification, discrimination, and estimation tasks. Only for trend detection tasks, the more traditional horizon graphs reported better performance. Our results are domain-independent, only requiring time-series data with large value ranges.
C1 [Braun, Daniel; Sondag, Max; von Landesberger, Tatiana] Univ Cologne, Cologne, Germany.
   [Borgo, Rita] Kings Coll London, London, England.
C3 University of Cologne; University of London; King's College London
RP Braun, D (corresponding author), Univ Cologne, Cologne, Germany.
EM braun@cs.uni-koeln.de; rita.borgo@kcl.ac.uk; sondag@cs.uni-koeln.de;
   landesberger@cs.uni-koeln.de
RI Braun, Daniel/B-7696-2015; sondag, max/KIJ-0026-2024
OI Braun, Daniel/0000-0002-8824-7184; von Landesberger,
   Tatiana/0000-0002-5279-1444; sondag, max/0000-0003-3309-638X
FU BMBF
FX No Statement Available
CR Adnan M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5444, DOI 10.1145/2858036.2858300
   Aigner W, 2012, COMPUT GRAPH FORUM, V31, P995, DOI 10.1111/j.1467-8659.2012.03092.x
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Aigner W, 2008, IEEE T VIS COMPUT GR, V14, P47, DOI 10.1109/TVCG.2007.70415
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   [Anonymous], 2006, P 2006 AVI WORKSHOP, DOI [DOI 10.1145/1168149.1168169, 10.1145/1168149.1168169]
   Bartram L, 2011, IEEE T VIS COMPUT GR, V17, P1444, DOI 10.1109/TVCG.2010.237
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2014, IEEE T VIS COMPUT GR, V20, P2261, DOI 10.1109/TVCG.2014.2346428
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Braun D, 2022, IEEE VIS CONF, P125, DOI 10.1109/VIS54862.2022.00034
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Charness G, 2012, J ECON BEHAV ORGAN, V81, P1, DOI 10.1016/j.jebo.2011.08.009
   Clark J. H., 1924, American Journal of Physiological Optics, V5, P269
   Correll M, 2012, P SIGCHI C HUM FACT, DOI [DOI 10.1145/2207676.2208556, 10.1145/2207676.22085562, DOI 10.1145/2207676.22085562]
   Diehl A., 2018, EuroVis 2018 - Short Papers, P61, DOI DOI 10.2312/EUROVISSHORT.20181079
   Federico P, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P273, DOI 10.1145/2598153.2598172
   Few S., 2011, Visual Business Intelligence Newsletter, V3
   Few S., 2005, DM Review, V15, P3
   Few S., 2008, Visual Business Intelligence Newsletter, V1, P2
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Havre S, 2000, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2000, P115, DOI 10.1109/INFVIS.2000.885098
   Hawkins E., 2018, Show your stripes
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hlawatsch M, 2013, COMPUT GRAPH FORUM, V32, P181, DOI 10.1111/cgf.12105
   Hohn M., 2020, EUROVIS 2020 SHORT P, P103, DOI DOI 10.2312/EVS.20201056
   Jabbari A, 2018, ACTES DE LA 30 CONFERENCE FRANCOPHONE SUR L'INTERACTION HOMME-MACHINE - (IHM 2018), P73, DOI 10.1145/3286689.3286694
   Jabbari A, 2018, IEEE PAC VIS SYMP, P116, DOI 10.1109/PacificVis.2018.00023
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Kerracher N, 2015, IEEE T VIS COMPUT GR, V21, P1160, DOI 10.1109/TVCG.2015.2424889
   Kubina R, 2023, BEHAV MODIF, V47, P615, DOI 10.1177/01454455221130002
   Munzner T., 2014, Visualization Analysis and Design, P3
   Nibley B., 2022, Bitcoin price history: 2009 - 2023
   Perin C., 2013, P SIGCHI C HUMAN FAC, P3217, DOI [10.1145/2470654.24664412,3,4, DOI 10.1145/2470654.24664412,3,4, DOI 10.1145/2470654.2466441]
   Reijner H., 2008, ELECT P VIS08 WORKSH
   Romano A, 2020, HEALTH ECON, V29, P1482, DOI 10.1002/hec.4143
   Saito T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P173, DOI 10.1109/INFVIS.2005.1532144
   Schmitz Carsten, 2022, Limesurvey: An open source survey tool
   Sevi S, 2020, CAN J POLIT SCI, V53, P385, DOI 10.1017/S000842392000030X
   Shi CL, 2012, IEEE T VIS COMPUT GR, V18, P2669, DOI 10.1109/TVCG.2012.253
   Stone M., 2008, COLOR IMAGING C, V16, P3
   Vagias W. M., 2006, Likert-type scale response anchors, P4
   Ware C., 2019, Information Visualization: Perception for Design, P3
   Wertheimer M., 1938, A Source Book of Gestalt Psychology, P71, DOI [10.1037/11496-005, DOI 10.1037/11496-005]
   Yujie Fang, 2020, IOP Conference Series: Materials Science and Engineering, V782, DOI 10.1088/1757-899X/782/2/022013
   Zhao HN, 2017, IEEE T VIS COMPUT GR, V23, P1691, DOI 10.1109/TVCG.2016.2539949
NR 47
TC 0
Z9 0
U1 5
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1161
EP 1171
DI 10.1109/TVCG.2023.3326576
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500096
PM 37871083
OA Green Published, Green Submitted
DA 2024-11-06
ER

PT J
AU Shi, Y
   Chen, BC
   Chen, Y
   Jin, ZC
   Xu, K
   Jiao, XH
   Gao, T
   Cao, N
AF Shi, Yang
   Chen, Bingchang
   Chen, Ying
   Jin, Zhuochen
   Xu, Ke
   Jiao, Xiaohan
   Gao, Tian
   Cao, Nan
TI Supporting Guided Exploratory Visual Analysis on Time Series Data with
   Reinforcement Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time Series Data; Exploratory Visual Analysis; Reinforcement Learning
ID VISUALIZATION; GENERATION; GUIDANCE
AB The exploratory visual analysis (EVA) of time series data uses visualization as the main output medium and input interface for exploring new data. However, for users who lack visual analysis expertise, interpreting and manipulating EVA can be challenging. Thus, providing guidance on EVA is necessary and two relevant questions need to be answered. First, how to recommend interesting insights to provide a first glance at data and help develop an exploration goal. Second, how to provide step-by-step EVA suggestions to help identify which parts of the data to explore. In this work, we present a reinforcement learning (RL)-based system, Visail, which generates EVA sequences to guide the exploration of time series data. As a user uploads a time series dataset, Visail can generate step-by-step EVA suggestions, while each step is visualized as an annotated chart combined with textual descriptions. The RL-based algorithm uses exploratory data analysis knowledge to construct the state and action spaces for the agent to imitate human analysis behaviors in data exploration tasks. In this way, the agent learns the strategy of generating coherent EVA sequences through a well-designed network. To evaluate the effectiveness of our system, we conducted an ablation study, a user study, and two case studies. The results of our evaluation suggested that Visail can provide effective guidance on supporting EVA on time series data.
C1 [Shi, Yang; Chen, Bingchang; Chen, Ying; Jiao, Xiaohan; Gao, Tian; Cao, Nan] Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.
   [Shi, Yang; Chen, Bingchang; Chen, Ying; Jiao, Xiaohan; Gao, Tian; Cao, Nan] Huawei Cloud Comp Technol Co Ltd, Shenzhen, Peoples R China.
C3 Tongji University
RP Cao, N (corresponding author), Tongji Univ, Intelligent Big Data Visualizat Lab, Shanghai, Peoples R China.; Cao, N (corresponding author), Huawei Cloud Comp Technol Co Ltd, Shenzhen, Peoples R China.
EM yangshi.idvx@tongji.edu.cn; 2131933@tongji.edu.cn;
   2131926@tongji.edu.cn; chjzcjames@gmail.com; lukexuke@gmail.com;
   xh_xiaohan@tongji.edu.cn; gaotian@tongji.edu.cn; nan.cao@tongji.edu.cn
RI Cao, Nan/O-5397-2014
OI Cao, Nan/0000-0003-1316-7515
FU NSFC
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Assaker J., 2022, Covid-19 global dataset
   Bar El O, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1527, DOI 10.1145/3318464.3389779
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Behrisch M, 2014, IEEE CONF VIS ANAL, P43, DOI 10.1109/VAST.2014.7042480
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Bryan C, 2017, IEEE T VIS COMPUT GR, V23, P511, DOI 10.1109/TVCG.2016.2598876
   Ceneda D, 2019, COMPUT GRAPH FORUM, V38, P861, DOI 10.1111/cgf.13730
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chatfield C., 2016, Analysis of time series: An introduction, DOI [DOI 10.4324/9780203491683, https://doi.org/10.4324/9780203491683]
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Chen Y, 2009, IEEE PAC VIS SYMP, P49, DOI 10.1109/PACIFICVIS.2009.4906837
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Deng Dazhen, 2023, IEEE Trans Vis Comput Graph, V29, P690, DOI 10.1109/TVCG.2022.3209468
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Ehrenberg A. S. C., 1979, Applied Statistics, V28, P79, DOI [10.2307/23468181, DOI 10.2307/23468181]
   Franceschi JY, 2019, ADV NEUR IN, V32
   FRIEDMAN JH, 1974, IEEE T COMPUT, VC 23, P881, DOI 10.1109/T-C.1974.224051
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   GOTZ D, 2009, IUI 2009, P315, DOI DOI 10.1145/1502650.15026951
   Guo TZ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P751
   Hao M., 2011, SPIE, V7868, P194, DOI [10.1117/12.8721696, DOI 10.1117/12.8721696]
   Horvitz E, 1999, P SIGCHI C HUM FACT, P159, DOI [10.1145/302979.303030, DOI 10.1145/302979.303030]
   Huang S., 2022, INT FLAIRS C P, V35, DOI [10.32473/flairs.v35i.1305846, DOI 10.32473/FLAIRS.V35I.1305846]
   Key A., 2012, P ACM SIGMOD INT C M, P681, DOI DOI 10.1145/2213836.2213931
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Kong N, 2012, IEEE T VIS COMPUT GR, V18, P2631, DOI 10.1109/TVCG.2012.229
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Law P.-M., 2020, 2020 IEEE VIS C VIS, DOI [10.1109/vis47514.2020.000432, DOI 10.1109/VIS47514.2020.000432]
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Law PM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300409
   Law PM, 2019, IEEE T VIS COMPUT GR, V25, P427, DOI 10.1109/TVCG.2018.2864526
   Lee DJL, 2022, IEEE T VIS COMPUT GR, V28, P4225, DOI 10.1109/TVCG.2021.3085751
   Li WC, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581452
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   Lv C, 2022, J VISUAL-JAPAN, V25, P575, DOI 10.1007/s12650-021-00807-6
   Ma PC, 2021, INT CONF MANAGE DATA, P1262, DOI 10.1145/3448016.3457267
   Moshagen M, 2010, INT J HUM-COMPUT ST, V68, P689, DOI 10.1016/j.ijhcs.2010.05.006
   Ola O., 2014, Online Journal of Public Health Informatics, V5, DOI DOI 10.5210/OJPHI.V5I3.4933
   Personnaz Aurelien, 2021, aiDM '21: Fourth Workshop in Exploiting AI Techniques for Data Management, P16, DOI 10.1145/3464509.3464884
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Riedl MO, 2010, J ARTIF INTELL RES, V39, P217, DOI 10.1613/jair.2989
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Shi DQ, 2019, 2019 IEEE VISUALIZATION IN DATA SCIENCE (VDS), P58, DOI [10.1109/VDS48975.2019.8973383, 10.1109/vds48975.2019.8973383]
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P972, DOI 10.1109/TVCG.2022.3209409
   Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337
   Shumway RH., 2017, TIME SERIES ANAL ITS, DOI DOI 10.1007/978-3-319-52452-8
   Sips M, 2012, IEEE T VIS COMPUT GR, V18, P2899, DOI 10.1109/TVCG.2012.191
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Tang H, 2019, J VISUAL-JAPAN, V22, P1005, DOI 10.1007/s12650-019-00586-1
   TUDelft, 2020, Gwa-t-12 bitbrains
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Vollmer M., 2020, PHYSIONET, DOI [10.13026/CHD5-T9468, DOI 10.13026/CHD5-T9468]
   Pham V, 2020, 2020 IEEE VISUALIZATION IN DATA SCIENCE (VDS 2020), P42, DOI 10.1109/VDS51726.2020.00009
   Walker J, 2016, IEEE T VIS COMPUT GR, V22, P549, DOI 10.1109/TVCG.2015.2467751
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wongsuphasawat Krist, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P27, DOI 10.1109/VAST.2009.5332595
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P162, DOI 10.1109/TVCG.2021.3114826
   Xiao S., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.48550/ARXIV.2304.146309, DOI 10.48550/ARXIV.2304.146309]
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Yang LN, 2022, IEEE T VIS COMPUT GR, V28, P922, DOI 10.1109/TVCG.2021.3114774
   Yu L, 2010, COMPUT GRAPH FORUM, V29, P2271, DOI 10.1111/j.1467-8659.2010.01816.x
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
   Zhao J, 2011, IEEE T VIS COMPUT GR, V17, P2422, DOI 10.1109/TVCG.2011.195
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
NR 77
TC 1
Z9 1
U1 6
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1172
EP 1182
DI 10.1109/TVCG.2023.3327200
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500132
PM 37883260
DA 2024-11-06
ER

PT J
AU Hao, JN
   Shi, Q
   Ye, YL
   Zeng, W
AF Hao, Jianing
   Shi, Qing
   Ye, Yilin
   Zeng, Wei
TI <i>TimeTuner:</i> Diagnosing Time Representations for Time-Series
   Forecasting with Counterfactual Explanations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Time-series forecasting; counterfactual explanation; visual analytics
ID STATE
AB Deep learning (DL) approaches are being increasingly used for time-series forecasting, with many efforts devoted to designing complex DL models. Recent studies have shown that the DL success is often attributed to effective data representations, fostering the fields of feature engineering and representation learning. However, automated approaches for feature learning are typically limited with respect to incorporating prior knowledge, identifying interactions among variables, and choosing evaluation metrics to ensure that the models are reliable. To improve on these limitations, this paper contributes a novel visual analytics framework, namely TimeTuner, designed to help analysts understand how model behaviors are associated with localized correlations, stationarity, and granularity of time-series representations. The system mainly consists of the following two-stage technique: We first leverage counterfactual explanations to connect the relationships among time-series representations, multivariate features and model predictions. Next, we design multiple coordinated views including a partition-based correlation matrix and juxtaposed bivariate stripes, and provide a set of interactions that allow users to step into the transformation selection process, navigate through the feature space, and reason the model performance. We instantiate TimeTuner with two transformation methods of smoothing and sampling, and demonstrate its applicability on real-world time-series forecasting of univariate sunspots and multivariate air pollutants. Feedback from domain experts indicates that our system can help characterize time-series representations and guide the feature engineering processes.
C1 [Hao, Jianing; Shi, Qing; Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
   [Ye, Yilin; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Guangzhou, Peoples R China.
EM jhao768@connect.hkust-gz.edu.cn; brantqshi@hkust-gz.edu.cn;
   yyebd@connect.hkust-gz.edu.cn; weizeng@hkust-gz.edu.cn
RI Ye, Yilin/GRR-8394-2022
FU National Natural Science Foundation of China
FX No Statement Available
CR Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Aigner W, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P457, DOI 10.1109/IV.2005.97
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   [Anonymous], 2020, Interpretable Machine Learning:A Guide for Making Black Box Models Explainable
   Asuero AG, 2006, CRIT REV ANAL CHEM, V36, P41, DOI 10.1080/10408340500526766
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Binns R, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173951
   Box G. E., 1970, Time Series Analysis: Forecasting and Control, V65, P1509, DOI [10.2307/2284333, DOI 10.2307/2284333]
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Burch M, 2019, PROCEEDINGS OF THE 12TH INTERNATIONAL SYMPOSIUM ON VISUAL INFORMATION COMMUNICATION AND INTERACTION, VINCI 2019, DOI 10.1145/3356422.3356423
   Byron L, 2008, IEEE T VIS COMPUT GR, V14, P1245, DOI 10.1109/TVCG.2008.166
   Cascarino G., 2022, Bank of Italy Occasional Paper, DOI [10.32057/0.QEF.2022.0674, DOI 10.32057/0.QEF.2022.0674]
   Cheng FR, 2021, IEEE T VIS COMPUT GR, V27, P1438, DOI 10.1109/TVCG.2020.3030342
   CHEUNG YW, 1995, J BUS ECON STAT, V13, P277, DOI 10.2307/1392187
   Chimmula VKR, 2020, CHAOS SOLITON FRACT, V135, DOI 10.1016/j.chaos.2020.109864
   Correll M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174216
   d3js, The javascript library for bespoke data visualization
   Dachselt Raimund., 2006, P ANN SIGCHI C HUMAN, P682, DOI DOI 10.1145/1125451.1125590
   Elsayed S, 2021, Arxiv, DOI arXiv:2101.02118
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   GARDNER ES, 1985, J FORECASTING, V4, P1, DOI 10.1002/for.3980040103
   Hao M.C., 2007, P EUROVIS, P27, DOI 10.2312/VisSym/EuroVis07/027-034
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Javed W, 2010, IEEE T VIS COMPUT GR, V16, P927, DOI 10.1109/TVCG.2010.162
   Karimi AH, 2020, PR MACH LEARN RES, V108, P895
   Keras, About us
   Kincaid R., 2006, Proceedings of the working conference on Advanced visual interfaces, P404
   Kincaid R, 2010, IEEE T VIS COMPUT GR, V16, P900, DOI 10.1109/TVCG.2010.193
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Lammarsch T, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P44, DOI 10.1109/IV.2009.52
   Lewis D., 1973, Counterfactuals, DOI [10.2307/22737382, DOI 10.2307/22737382]
   Liang X, 2015, P ROY SOC A-MATH PHY, V471, DOI 10.1098/rspa.2015.0257
   Lim B, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206906
   Lindemann B., 2021, Procedia CIRP, V99, P650, DOI DOI 10.1016/J.PROCIR.2021.03.088
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Mishra P., 2022, Counterfactual Explanations for XAI Models, P265, DOI [10.1145/3514094.3534144, DOI 10.1145/3514094.3534144]
   Mothilal RK, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P607, DOI 10.1145/3351095.3372850
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Nocke T, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P763, DOI 10.1109/WSC.2003.1261493
   Oppermann M, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P41, DOI 10.1109/VIS49827.2021.9623320
   palletsprojects, Flask documentation (3.0.x)
   Rangapuram SS, 2018, ADV NEUR IN, V31
   readthedocs, Welcome to the shap documentation
   Sagheer A, 2019, NEUROCOMPUTING, V323, P203, DOI 10.1016/j.neucom.2018.09.082
   Saito T, 2005, INFOVIS 05: IEEE Symposium on Information Visualization, Proceedings, P173, DOI 10.1109/INFVIS.2005.1532144
   Sarkar S., 2016, PROC CEUR, V1773, P2
   Schrijver CJ, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL046658
   scipy, scipy.stats.pearsonr.
   Shen QM, 2020, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis48177.2020.2785
   Shi Y., 2023, IEEE Trans. Vis. Comput. Graphics, P1
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Siami-Namini S, 2018, Arxiv, DOI [arXiv:1803.06386, 10.48550/ARXIV.1803.06386, DOI 10.48550/ARXIV.1803.06386]
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Verma S, 2020, Arxiv, DOI [arXiv:2010.10596, 10.48550/arXiv.2010.10596, DOI 10.48550/ARXIV.2010.10596]
   Vue.js, About us
   Wang YH, 2018, IEEE T VIS COMPUT GR, V24, P1141, DOI 10.1109/TVCG.2017.2653106
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Xu K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445083
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   Yajnik M, 1999, IEEE INFOCOM SER, P345, DOI 10.1109/INFCOM.1999.749301
   Zeng W, 2021, IEEE T VIS COMPUT GR, V27, P839, DOI 10.1109/TVCG.2020.3030410
   Zhao J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1737
NR 67
TC 0
Z9 0
U1 8
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1183
EP 1193
DI 10.1109/TVCG.2023.3327389
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500034
PM 37883273
DA 2024-11-06
ER

PT J
AU Deng, ZK
   Chen, SF
   Schreck, T
   Deng, DZ
   Tang, T
   Xu, ML
   Weng, D
   Wu, YC
AF Deng, Zikun
   Chen, Shifu
   Schreck, Tobias
   Deng, Dazhen
   Tang, Tan
   Xu, Mingliang
   Weng, Di
   Wu, Yingcai
TI Visualizing Large-Scale Spatial Time Series with GeoChron
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal visualization; spatial time series; Storyline
ID SPATIOTEMPORAL PATTERNS; AIR-POLLUTION; EXPLORATION; EVOLUTION
AB In geo-related fields such as urban informatics, atmospheric science, and geography, large-scale spatial time (ST) series (i.e., geo-referred time series) are collected for monitoring and understanding important spatiotemporal phenomena. ST series visualization is an effective means of understanding the data and reviewing spatiotemporal phenomena, which is a prerequisite for in-depth data analysis. However, visualizing these series is challenging due to their large scales, inherent dynamics, and spatiotemporal nature. In this study, we introduce the notion of patterns of evolution in ST series. Each evolution pattern is characterized by 1) a set of ST series that are close in space and 2) a time period when the trends of these ST series are correlated. We then leverage Storyline techniques by considering an analogy between evolution patterns and sessions, and finally design a novel visualization called GeoChron, which is capable of visualizing large-scale ST series in an evolution pattern-aware and narrative-preserving manner. GeoChron includes a mining framework to extract evolution patterns and two-level visualizations to enhance its visual scalability. We evaluate GeoChron with two case studies, an informal user study, an ablation study, parameter analysis, and running time analysis.
C1 [Deng, Zikun; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Chen, Shifu; Deng, Dazhen; Weng, Di] Zhejiang Univ, Sch Software Technol, Hangzhou, Peoples R China.
   [Tang, Tan] Zhejiang Univ, Sch Art & Archaeol, Hangzhou, Peoples R China.
   [Schreck, Tobias] Graz Univ Technol, Graz, Austria.
   [Xu, Mingliang] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Hangzhou, Peoples R China.
   [Xu, Mingliang] Minist Educ, Engn Res Ctr Intelligent Swarm Syst, Hangzhou, Peoples R China.
   [Xu, Mingliang] Natl Supercomp Ctr, Zhengzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University; Graz
   University of Technology; Zhengzhou University
RP Weng, D (corresponding author), Zhejiang Univ, Sch Software Technol, Hangzhou, Peoples R China.
EM zikun_rain@zju.edu.cn; sfchen@zju.edu.cn; tobias.schreck@cgv.tugraz.at;
   dengdazhen@zju.edu.cn; tangtan@zju.edu.cn; iexumingliang@zzu.edu.cn;
   dweng@zju.edu.cn; ycwu@zju.edu.cn
RI Deng, Zikun/IQT-3106-2023; Weng, Di/ABG-7408-2020; Tang,
   Tan/JJD-3333-2023; Deng, Dazhen/JXW-7493-2024
OI Weng, Di/0000-0003-2712-7274; Deng, Dazhen/0000-0002-9057-8353; Tang,
   Tan/0000-0002-5260-3087; Schreck, Tobias/0000-0003-0778-8665; Deng,
   Zikun/0000-0002-4477-5292
FU National Key R&D Program of China
FX No Statement Available
CR Aghabozorgi S, 2015, INFORM SYST, V53, P16, DOI 10.1016/j.is.2015.04.007
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko G, 2008, INFORM VISUAL, V7, P173, DOI 10.1057/ivs.2008.23
   aqicn, The World Air Quality Index project. New York, USA Air Pollution: Real- time Air Quality index
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Chatzigeorgakidis G, 2019, BIG DATA RES, V15, P12, DOI 10.1016/j.bdr.2019.02.001
   Cormen T. H., 2001, Introduction to Algorithms, V4, P5
   Deng Z., 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32299539, DOI 10.1109/TVCG.2022.32299539]
   Deng ZK, 2023, J VISUAL-JAPAN, V26, P385, DOI 10.1007/s12650-022-00884-1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dong Y, 2023, J VISUAL-JAPAN, V26, P403, DOI 10.1007/s12650-022-00882-3
   Evers M, 2021, COMPUT GRAPH FORUM, V40, P519, DOI 10.1111/cgf.14326
   Garcia G, 2021, IEEE T VIS COMPUT GR, V27, P2313, DOI 10.1109/TVCG.2019.2947515
   Guo H., 2022, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/TVCG.2022.32094142, DOI 10.1109/TVCG.2022.32094142]
   Hulstein Golina, 2023, IEEE Trans Vis Comput Graph, V29, P994, DOI 10.1109/TVCG.2022.3209480
   Karnick P, 2010, IEEE T VIS COMPUT GR, V16, P235, DOI 10.1109/TVCG.2009.65
   Köthur P, 2014, INFORM VISUAL, V13, P283, DOI 10.1177/1473871613481692
   Kothur P., 2012, P EUR C VIS EUR ASS, DOI [10.2312/PE/EuroVisShort/EuroVisShort2012/115-1191,2, DOI 10.2312/PE/EUROVISSHORT/EUROVISSHORT2012/115-1191,2]
   Lekschas F, 2020, IEEE T VIS COMPUT GR, V26, P611, DOI 10.1109/TVCG.2019.2934555
   Li CH, 2022, IEEE T VIS COMPUT GR, V28, P1062, DOI 10.1109/TVCG.2021.3114762
   Li J, 2019, IEEE T VIS COMPUT GR, V25, P2554, DOI 10.1109/TVCG.2018.2851227
   Li J, 2014, IEEE CONF VIS ANAL, P133, DOI 10.1109/VAST.2014.7042489
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Li YX, 2023, VIS INFORM, V7, P41, DOI 10.1016/j.visinf.2023.02.002
   Liang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3428
   Liu DY, 2019, IEEE T VIS COMPUT GR, V25, P1, DOI 10.1109/TVCG.2018.2865018
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Shuhan, 2023, IEEE Trans Vis Comput Graph, V29, P1091, DOI 10.1109/TVCG.2022.3209430
   Liu YP, 2017, ECOL INDIC, V76, P344, DOI 10.1016/j.ecolind.2017.01.027
   Lu XY, 2023, J VISUAL-JAPAN, V26, P687, DOI 10.1007/s12650-022-00893-0
   Ma SM, 2019, J CLIMATE, V32, P1203, DOI 10.1175/JCLI-D-18-0234.1
   Magallanes J, 2022, IEEE T VIS COMPUT GR, V28, P901, DOI 10.1109/TVCG.2021.3114868
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   Meshesha TW, 2020, J HYDROL, V587, DOI 10.1016/j.jhydrol.2020.124952
   Monmonier Mark., 1990, Cartographica, V27, P30, DOI DOI 10.3138/U558-H737-6577-8U311
   Muthoni FK, 2019, THEOR APPL CLIMATOL, V137, P1869, DOI 10.1007/s00704-018-2712-1
   Ogawa M, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P35
   Patel P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P370, DOI 10.1109/ICDM.2002.1183925
   Qin Y, 2021, SCI TOTAL ENVIRON, V792, DOI 10.1016/j.scitotenv.2021.148349
   Qu H, 2007, IEEE T VIS COMPUT GR, V13, P1408, DOI 10.1109/TVCG.2007.70523
   Rodrigues N., 2017, P INT S VIS INF COMM, P37, DOI [10.1145/3105971.31059821,2, DOI 10.1145/3105971.31059821,2]
   Shi Y, 2018, IEEE T VIS COMPUT GR, V24, P1918, DOI 10.1109/TVCG.2018.2816203
   Shirato G, 2023, VIS INFORM, V7, P77, DOI 10.1016/j.visinf.2023.01.001
   Spinoni J, 2015, INT J CLIMATOL, V35, P4197, DOI 10.1002/joc.4279
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   Tanahashi Y, 2015, IEEE T VIS COMPUT GR, V21, P730, DOI 10.1109/TVCG.2015.2392771
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Thakur S, 2010, IEEE INT CONF INF VI, P336, DOI 10.1109/IV.2010.54
   Traag VA, 2015, PHYS REV E, V92, DOI 10.1103/PhysRevE.92.032801
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Wang YC, 2022, VIS INFORM, V6, P12, DOI 10.1016/j.visinf.2022.09.001
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Wu XJ, 2020, INT J GEOGR INF SCI, V34, P1822, DOI 10.1080/13658816.2020.1726922
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Yagi S, 2015, 8th International Symposium on Visual Information Communication and Interaction (VINCI 2015), P156, DOI 10.1145/2801040.2801067
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Ye WF, 2018, SCI TOTAL ENVIRON, V631-632, P524, DOI 10.1016/j.scitotenv.2018.03.057
   Yi XW, 2022, IEEE T BIG DATA, V8, P1326, DOI 10.1109/TBDATA.2020.3047078
   Ying Lu, 2023, IEEE Trans Vis Comput Graph, V29, P331, DOI 10.1109/TVCG.2022.3209447
   Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Yue XW, 2020, IEEE T VIS COMPUT GR, V26, P601, DOI 10.1109/TVCG.2019.2934660
   Zeng W, 2017, IEEE T INTELL TRANSP, V18, P2271, DOI 10.1109/TITS.2016.2639320
   Zhao WX, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2022.06.002
   Zhao Ying, 2023, IEEE Trans Vis Comput Graph, V29, P214, DOI 10.1109/TVCG.2022.3209469
   Zhao Y, 2022, IEEE T VIS COMPUT GR, V28, P890, DOI 10.1109/TVCG.2021.3114865
   Zheng Y, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2267, DOI 10.1145/2783258.2788573
   Zhu JY, 2018, IEEE T BIG DATA, V4, P571, DOI 10.1109/TBDATA.2017.2723899
NR 76
TC 1
Z9 1
U1 8
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1194
EP 1204
DI 10.1109/TVCG.2023.3327162
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500016
PM 37883274
DA 2024-11-06
ER

PT J
AU Jiang, ZH
   Chen, HD
   Zhou, R
   Deng, J
   Zhang, XC
   Zhao, RN
   Xie, C
   Wang, YF
   Ngai, ECH
AF Jiang, Zhihan
   Chen, Handi
   Zhou, Rui
   Deng, Jing
   Zhang, Xinchen
   Zhao, Running
   Xie, Cong
   Wang, Yifang
   Ngai, Edith C. H.
TI <i>HealthPrism:</i> A Visual Analytics System for Exploring Children's
   Physical and Mental Health Profiles with Multimodal Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual Analytics; Health Profiling; Multimodal Learning; Context Data;
   Motion Data
ID VISUALIZATION; RESILIENCE; DASHBOARDS
AB The correlation between children's personal and family characteristics (e.g., demographics and socioeconomic status) and their physical and mental health status has been extensively studied across various research domains, such as public health, medicine, and data science. Such studies can provide insights into the underlying factors affecting children's health and aid in the development of targeted interventions to improve their health outcomes. However, with the availability of multiple data sources, including context data (i.e., the background information of children) and motion data (i.e., sensor data measuring activities of children), new challenges have arisen due to the large-scale, heterogeneous, and multimodal nature of the data. Existing statistical hypothesis-based and learning model-based approaches have been inadequate for comprehensively analyzing the complex correlation between multimodal features and multi-dimensional health outcomes due to the limited information revealed. In this work, we first distill a set of design requirements from multiple levels through conducting a literature review and iteratively interviewing 11 experts from multiple domains (e.g., public health and medicine). Then, we propose HealthPrism, an interactive visual and analytics system for assisting researchers in exploring the importance and influence of various context and motion features on children's health status from multi-level perspectives. Within HealthPrism, a multimodal learning model with a gate mechanism is proposed for health profiling and cross-modality feature importance comparison. A set of visualization components is designed for experts to explore and understand multimodal data freely. We demonstrate the effectiveness and usability of HealthPrism through quantitative evaluation of the model performance, case studies, and expert interviews in associated domains.
C1 [Jiang, Zhihan; Chen, Handi; Zhou, Rui; Deng, Jing; Zhang, Xinchen; Zhao, Running; Ngai, Edith C. H.] Univ Hong Kong, Hong Kong, Peoples R China.
   [Xie, Cong] Tencent, Shenzhen, Peoples R China.
   [Wang, Yifang] Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
C3 University of Hong Kong; Tencent; Northwestern University
RP Wang, YF (corresponding author), Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
EM zhjiang@connect.hku.hk; hdchen@connect.hku.hk; zackery@connect.hku.hk;
   u3008395@connect.hku.hk; u3008407@connect.hku.hk; rnzhao@connect.hku.hk;
   xie.cong@outlook.com; yifang.wang@kellogg.northwestern.edu;
   chngai@eee.hku.hk
OI Zhou, Rui/0009-0002-3229-0324; Chen, Handi/0000-0002-4223-3502; Wang,
   Yifang/0000-0001-6267-9440; Deng, Jing/0009-0002-8935-4157; Zhang,
   Xinchen/0000-0003-3650-7332; Jiang, Zhihan/0000-0003-4857-7143
FU GRF
FX No Statement Available
CR Amershi S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P337, DOI 10.1145/2702123.2702509
   Arras L., 2017, P 8 WORKSH COMP APPR, P159
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Bradley RH, 2002, ANNU REV PSYCHOL, V53, P371, DOI 10.1146/annurev.psych.53.100901.135233
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   Cao L, 2022, IEEE T MULTIMEDIA, V24, P87, DOI 10.1109/TMM.2020.3046867
   Chang JX, 2023, Arxiv, DOI arXiv:2302.01115
   Charette RN, 2005, IEEE SPECTRUM, V42, P42, DOI 10.1109/MSPEC.2005.1502528
   Chen C, 2019, AAAI CONF ARTIF INTE, P865
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Choi E, 2016, ADV NEUR IN, V29
   Connor KM, 2003, DEPRESS ANXIETY, V18, P76, DOI 10.1002/da.10113
   Duangsoithong R, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P247, DOI 10.1109/ICAPR.2009.36
   Dudley JJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3185517
   Echarts.js, About us
   Eckelt K., 2022, IEEE VIS WORKSHOP VI, P2022, DOI DOI 10.1101/2022.08.16.5036222
   Elshehaly M, 2021, IEEE T VIS COMPUT GR, V27, P689, DOI 10.1109/TVCG.2020.3030424
   Garber CE, 2010, BMC GERIATR, V10, DOI 10.1186/1471-2318-10-6
   Guo SN, 2019, IEEE T VIS COMPUT GR, V25, P417, DOI 10.1109/TVCG.2018.2864885
   Hakone A, 2017, IEEE T VIS COMPUT GR, V23, P601, DOI 10.1109/TVCG.2016.2598588
   Hara S., 2018, P MACHINE LEARNING R, V84, P77, DOI [10.48550/arXiv.1606.090663, DOI 10.48550/ARXIV.1606.090663]
   HARRINGTON PD, 1993, ANAL CHEM, V65, P2167, DOI 10.1021/ac00063a042
   Herdman M, 2011, QUAL LIFE RES, V20, P1727, DOI 10.1007/s11136-011-9903-x
   Huang TW, 2020, Arxiv, DOI arXiv:2007.03519
   Huber F., 2018, A logical introduction to probability and induction, V5, P6
   Jayalakshmi T, 2011, Int. J. Comput. Theory Eng., V3, P89
   Jiang ZH, 2023, IEEE T MOBILE COMPUT, V22, P1401, DOI 10.1109/TMC.2021.3110592
   Jiang ZH, 2023, PROC ACM INTERACT MO, V7, DOI 10.1145/3580800
   Jylhä M, 2009, SOC SCI MED, V69, P307, DOI 10.1016/j.socscimed.2009.05.013
   Kaminski M., 2013, The stochastic perturbation method for computational mechanics, DOI DOI 10.1002/9781118481844.CH15
   Kaplan MS, 2001, AM J PREV MED, V21, P306, DOI 10.1016/S0749-3797(01)00364-6
   Karl M., 2017, INT C LEARNING REPRE, DOI [10.48550/arXiv.1605.06432 3, DOI 10.48550/ARXIV.1605.064323]
   Karn S. K., 2003, Economic and Political Weekly, P3575, DOI 10.2307/44139399
   Kato T, 2005, MOL PSYCHIATR, V10, P622, DOI 10.1038/sj.mp.4001662
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Kwon BC, 2016, IEEE T VIS COMPUT GR, V22, P71, DOI 10.1109/TVCG.2015.2467555
   Lee JJ, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/15403
   Loorak MH, 2016, IEEE T VIS COMPUT GR, V22, P409, DOI 10.1109/TVCG.2015.2467325
   Lundberg SM, 2017, ADV NEUR IN, V30
   Ma C, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P825, DOI 10.1145/3292500.3330984
   Ma HD, 2014, IEEE COMMUN MAG, V52, P29, DOI 10.1109/MCOM.2014.6871666
   Malarvizhi R., 2012, International Journal of Engineering Research and Development, V5, P4
   Mansoor H, 2021, IEEE COMPUT GRAPH, V41, P96, DOI 10.1109/MCG.2021.3062474
   Masten A. S., 2002, Handbook of Positive Psychology, P3
   Matkovic K, 2008, IEEE INT CONF INF VI, P215, DOI 10.1109/IV.2008.87
   Ming Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P903, DOI 10.1145/3292500.3330908
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mollyn V, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3550284
   Moon S, 2022, Arxiv, DOI [arXiv:2210.14395, DOI 10.48550/ARXIV.2210.14395, 10.48550/ARXIV.2210.14395]
   Munzner T., 2014, Visualization analysis and design, P6
   Polanin JR, 2021, PSYCHOL BULL, V147, P115, DOI 10.1037/bul0000314
   Rew L, 2001, J NURS SCHOLARSHIP, V33, P33, DOI 10.1111/j.1547-5069.2001.00033.x
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Scheer J, 2022, J MED INTERNET RES, V24, DOI 10.2196/38041
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00392-9
   Tolomei G, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P465, DOI 10.1145/3097983.3098039
   U. D. of Health and H. Services, 2000, Health disparities: Bridging the gap, P2
   Varni James W, 2005, Expert Rev Pharmacoecon Outcomes Res, V5, P705, DOI 10.1586/14737167.5.6.705
   Vue.js, About us
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Waring J, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101822
   World Health Organization, 2008, Pacific physical activity guidelines for adults: Framework for accelerating the communication of physical activity guidelines, P2
   World Health Organization, 2010, Global recommendations on physical activity for health, P3
   Xu KK, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441058
   Zhang ZY, 2013, IEEE T VIS COMPUT GR, V19, P1895, DOI 10.1109/TVCG.2013.89
   Zhou Binbin, 2023, Personal and Ubiquitous Computing, P599, DOI 10.1007/s00779-020-01456-6
   Zhuang MD, 2022, IEEE T VIS COMPUT GR, V28, P1715, DOI 10.1109/TVCG.2022.3147154
NR 69
TC 0
Z9 0
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1205
EP 1215
DI 10.1109/TVCG.2023.3326943
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500065
PM 37874717
DA 2024-11-06
ER

PT J
AU Scimone, A
   Eckelt, K
   Streit, M
   Hinterreiter, A
AF Scimone, Anna
   Eckelt, Klaus
   Streit, Marc
   Hinterreiter, Andreas
TI Marjorie: Visualizing Type 1 Diabetes Data to Support Pattern
   Exploration
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Design study; task analysis; diabetes; time series data; visual
   analytics; clustering
ID TIME-SERIES DATA
AB In this work we propose Marjorie, a visual analytics approach to address the challenge of analyzing patients' diabetes data during brief regular appointments with their diabetologists. Designed in consultation with diabetologists, Marjorie uses a combination of visual and algorithmic methods to support the exploration of patterns in the data. Patterns of interest include seasonal variations of the glucose profiles, and non-periodic patterns such as fluctuations around mealtimes or periods of hypoglycemia (i.e., glucose levels below the normal range). We introduce a unique representation of glucose data based on modified horizon graphs and hierarchical clustering of adjacent carbohydrate or insulin entries. Semantic zooming allows the exploration of patterns on different levels of temporal detail. We evaluated our solution in a case study, which demonstrated Marjorie's potential to provide valuable insights into therapy parameters and unfavorable eating habits, among others. The study results and informal feedback collected from target users suggest that Marjorie effectively supports patients and diabetologists in the joint exploration of patterns in diabetes data, potentially enabling more informed treatment decisions. A free copy of this paper and all supplemental materials are available at https://osf.io/34t8c/.
C1 [Scimone, Anna; Eckelt, Klaus; Streit, Marc; Hinterreiter, Andreas] Johannes Kepler Univ Linz, Linz, Austria.
C3 Johannes Kepler University Linz
RP Scimone, A (corresponding author), Johannes Kepler Univ Linz, Linz, Austria.
EM anna_scimone@live.de; klaus.eckelt@jku.at; marc.streit@jku.at;
   andreas.hinterreiter@jku.at
FU Austrian Research Promotion Agency
FX No Statement Available
CR Abbott Diabetes Care Inc, 2023, LibreView Portal
   Aigner Wolfgang, 2011, Foundations and Trends in Human-Computer Interaction, V5, P207, DOI 10.1561/1100000039
   Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bade R., 2004, P SIGCHI C HUM FACT, P105, DOI [10.1145/985692.985706, DOI 10.1145/985692.985706]
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Bazaev N. A., 2013, Biomedical Engineering, V47, P100, DOI [10.1007/s10527-013-9320-2, DOI 10.1007/S10527-013-9344-7, 10.1007/s10527-013-9344-7]
   Best CH, 1923, J BIOL CHEM, V57, P709
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Danne T, 2017, DIABETES CARE, V40, P1631, DOI 10.2337/dc17-1600
   Dexcom Inc, 2023, Dexcom Clarity Reports
   Eckelt K, 2023, IEEE T VIS COMPUT GR, V29, P3312, DOI 10.1109/TVCG.2022.3156760
   Federico P, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P273, DOI 10.1145/2598153.2598172
   Ferreira L, 2009, COMMUN STAT-SIMUL C, V38, P1925, DOI 10.1080/03610910903168603
   Fluck D., 2021, Coblis: Color Blindness Simulator
   Fujiwara T, 2021, IEEE T VIS COMPUT GR, V27, P1601, DOI 10.1109/TVCG.2020.3028889
   Glooko Inc, 2023, Glooko
   Green A, 2021, DIABETOLOGIA, V64, P2741, DOI 10.1007/s00125-021-05571-8
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Hall H, 2018, PLOS BIOL, V16, DOI 10.1371/journal.pbio.2005143
   Hinterreiter A, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387165
   Holt R. I., A Consensus Report by the American Diabetes Association (ADA) and the European Association for the
   Hyndman RJ., 2018, FORECASTING PRINCIPL
   Johnson ML, 2019, DIABETES TECHNOL THE, V21, pS17, DOI 10.1089/dia.2019.0034
   Karen H., 2017, Participatory design, P177
   Kovatchev BP, 2017, NAT REV ENDOCRINOL, V13, P425, DOI 10.1038/nrendo.2017.3
   Lobo B., 2021, IEEE Transactions on Biomedical Engineering, DOI [10.1109/TBME.2021.31031273, DOI 10.1109/TBME.2021.31031273]
   Medtronic Inc, 2023, Medtronic CareLink Software
   Medtronic Inc, 2018, Medtronic IPRO 2 System for CGM
   Müller W, 2003, PROCEEDINGS OF THE 2003 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P737, DOI 10.1109/WSC.2003.1261490
   Munzner T., 2014, Visualization Analysis and Design, DOI [10.1201/b175115, DOI 10.1201/B175115]
   Munzner T, 2008, LECT NOTES COMPUT SC, V4950, P134, DOI 10.1007/978-3-540-70956-5_6
   NATHAN DM, 1993, NEW ENGL J MED, V328, P1676, DOI 10.1056/NEJM199306103282306
   Plotly Technologies Inc, 2023, Plotly Dash User Guide & Documentation
   Reijner H., 2008, PROC IEEE VIS WORKSH
   Rind Alexander, 2011, Information Quality in e-Health. Proceedings 7th Conference of the Workgroup Human-Computer Interaction and Usability Engineering of the Austrian Computer Society, USAB 2011, P301, DOI 10.1007/978-3-642-25364-5_22
   Rostène W, 2021, ENDOCR REV, V42, P503, DOI 10.1210/endrev/bnab020
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Stitz H, 2016, IEEE T VIS COMPUT GR, V22, P2594, DOI 10.1109/TVCG.2015.2513389
   The Nightscout Foundation, 2023, The Nightscout Project
   The OpenAPS Community, 2017, Understanding Insulin on Board (IOB) Calculations
   Tidepool Project, Tidepool
   Tominski C., 2023, The TimeViz Browser - A Visual Survey of Visualization Techniques for Time-Oriented Data
   van den Elzen S, 2023, IEEE COMPUT GRAPH, V43, P78, DOI 10.1109/MCG.2023.3237286
   Wang Q, 2022, COMPUT GRAPH FORUM, V41, P69, DOI 10.1111/cgf.14424
   Woldaregay AZ, 2019, J MED INTERNET RES, V21, DOI 10.2196/11030
   Wong Jenise C, 2017, J Diabetes Sci Technol, V11, P800, DOI 10.1177/1932296817691305
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Zhang Y., 2021, PROC PERVASIVEHEALTH, P427, DOI [10.1145/3421937.34219572,3,5,9, DOI 10.1145/3421937.34219572,3,5,9]
   Zhang YX, 2019, IEEE T VIS COMPUT GR, V25, P512, DOI 10.1109/TVCG.2018.2865076
NR 50
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1216
EP 1226
DI 10.1109/TVCG.2023.3326936
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500053
PM 37874710
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Floricel, C
   Wentzel, A
   Mohamed, A
   Fuller, CD
   Canahuate, G
   Marai, GE
AF Floricel, Carla
   Wentzel, Andrew
   Mohamed, Abdallah
   Fuller, C. David
   Canahuate, Guadalupe
   Marai, G. Elisabeta
TI Roses Have Thorns: Understanding the Downside of Oncological Care
   Delivery Through Visual Analytics and Sequential Rule Mining
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Cancer; Computational modeling; Data visualization; Data
   mining; Analytical models; Data models; Temporal Data; Life Sciences;
   Mixed Initiative Human-Machine Analysis; Data Clustering and Aggregation
ID SYMPTOM CLUSTERS; EVENT SEQUENCES; CANCER-PATIENTS; NECK-CANCER;
   ASSOCIATION; VALIDATION; PREDICTION; COHORT; HEAD
AB Personalized head and neck cancer therapeutics have greatly improved survival rates for patients, but are often leading to understudied long-lasting symptoms which affect quality of life. Sequential rule mining (SRM) is a promising unsupervised machine learning method for predicting longitudinal patterns in temporal data which, however, can output many repetitive patterns that are difficult to interpret without the assistance of visual analytics. We present a data-driven, human-machine analysis visual system developed in collaboration with SRM model builders in cancer symptom research, which facilitates mechanistic knowledge discovery in large scale, multivariate cohort symptom data. Our system supports multivariate predictive modeling of post-treatment symptoms based on during-treatment symptoms. It supports this goal through an SRM, clustering, and aggregation back end, and a custom front end to help develop and tune the predictive models. The system also explains the resulting predictions in the context of therapeutic decisions typical in personalized care delivery. We evaluate the resulting models and system with an interdisciplinary group of modelers and head and neck oncology researchers. The results demonstrate that our system effectively supports clinical and symptom research.
C1 [Floricel, Carla; Wentzel, Andrew; Marai, G. Elisabeta] Univ Illinois, Chicago, IL 60607 USA.
   [Canahuate, Guadalupe] Univ Iowa, Iowa City, IA USA.
   [Mohamed, Abdallah; Fuller, C. David] Univ Texas MD Anderson Canc Ctr, Austin, TX USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; University of Iowa; University
   of Texas System; UTMD Anderson Cancer Center
RP Floricel, C (corresponding author), Univ Illinois, Chicago, IL 60607 USA.
EM cflori3@uic.edu; awentze2@uic.edu; asmohamed@mdanderson.org;
   cdfuller@mdanderson.org; guadalupe-canahuate@uiowa.edu; gmarai@uic.edu
RI Fuller, Clifton/AAB-4012-2019
OI Fuller, Clifton D./0000-0002-5264-3994
FU NIH
FX No Statement Available
CR Agrawal R., 1994, P 20 INT C VERY LARG, P487
   Aktas A, 2010, PALLIATIVE MED, V24, P373, DOI 10.1177/0269216310367842
   Antweiler D, 2022, IEEE VIS CONF, P55, DOI 10.1109/VIS54862.2022.00020
   Bartolomeo SD, 2021, IEEE T VIS COMPUT GR, V27, P1353, DOI 10.1109/TVCG.2020.3030442
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Bernard J., 2014, PROC IEEE VIS WORKSH, DOI DOI 10.1109/MCG.2015.492
   Biggs M., 2021, 19 INT C ARTIF INTEL, DOI DOI 10.1007/978-3-030-77211-6_582,3
   Brasseur L, 2005, TECH COMMUN Q, V14, P161, DOI 10.1207/s15427625tcq1402_3
   Bruzzese D, 2008, LECT NOTES COMPUT SC, V4404, P103, DOI 10.1007/978-3-540-71080-6_8
   Caballero HSG, 2017, 2017 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC), P39, DOI 10.1109/VAHC.2017.8387499
   Canahuate G, 2023, ORAL ONCOL, V144, DOI 10.1016/j.oraloncology.2023.106460
   Cappers BCM, 2018, IEEE T VIS COMPUT GR, V24, P532, DOI 10.1109/TVCG.2017.2745278
   Christopherson KM, 2019, CLIN TRANSL RAD ONCO, V18, P16, DOI 10.1016/j.ctro.2019.06.005
   Chui KKH, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0014683
   Cleeland CS, 2000, CANCER-AM CANCER SOC, V89, P1634, DOI 10.1002/1097-0142(20001001)89:7<1634::AID-CNCR29>3.0.CO;2-V
   Nguyen D, 2018, KNOWL-BASED SYST, V161, P313, DOI 10.1016/j.knosys.2018.07.031
   DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364
   Deogun J, 2005, LECT NOTES ARTIF INT, V3642, P98, DOI 10.1007/11548706_11
   Dong ST, 2016, J PAIN SYMPTOM MANAG, V51, P88, DOI 10.1016/j.jpainsymman.2015.07.013
   Du F, 2016, IEEE CONF VIS ANAL, P61, DOI 10.1109/VAST.2016.7883512
   Elshehaly M, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P11, DOI 10.1109/BELIV57783.2022.00006
   Eraj S. A., 2017, Rad. Onco., V12, P2
   Fan G, 2007, Curr Oncol, V14, P173, DOI 10.3747/co.2007.145
   Floricel C, 2022, Arxiv, DOI arXiv:2210.01618
   Floricel C, 2022, IEEE T VIS COMPUT GR, V28, P151, DOI 10.1109/TVCG.2021.3114810
   Fournier-Viger P, 2014, J MACH LEARN RES, V15, P3389
   Fournier-Viger P, 2012, KNOWL-BASED SYST, V25, P63, DOI 10.1016/j.knosys.2011.07.005
   Gotz D, 2014, IEEE T VIS COMPUT GR, V20, P1783, DOI 10.1109/TVCG.2014.2346682
   Guo S., 2019, PROC CHI C HUMAN FAC, P1, DOI DOI 10.1145/3290605.33008032
   Guo SN, 2018, IEEE T VIS COMPUT GR, V24, P56, DOI 10.1109/TVCG.2017.2745320
   Gwede CK, 2008, SUPPORT CARE CANCER, V16, P925, DOI 10.1007/s00520-007-0364-2
   Huang CW, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0218-7
   Huat Ong K., 2002, INT WORKSHOP ACT MIN
   Illi J, 2012, CYTOKINE, V58, P437, DOI 10.1016/j.cyto.2012.02.015
   Jaccard P., 1912, New Phytologist, V11, P37, DOI DOI 10.1111/J.1469-8137.1912.TB05611.X
   Jentner W, 2019, STUD BIG DATA, V51, P303, DOI 10.1007/978-3-030-04921-8_12
   Kim HJ, 2013, CURR OPIN SUPPORT PA, V7, P45, DOI 10.1097/SPC.0b013e32835bf28b
   Klemm P, 2014, IEEE T VIS COMPUT GR, V20, P1673, DOI 10.1109/TVCG.2014.2346591
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848
   Luciani T, 2020, J Biomed Inform, V112S, P100067, DOI 10.1016/j.yjbinx.2020.100067
   Luciani T., 2018, IEEE Trans. Vis. Comp. Graph., V25, P6
   Malik S., 2015, P 20 INT C INT US IN, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10.1145/2678025.2701407]
   Marai G. E., 2015, EUROVIS WORKSHOP VIS, P9
   Marai G. E., 2019, Ten simple rules to create biological network figures for communication, P5
   Marai GE, 2019, IEEE T VIS COMPUT GR, V25, P1732, DOI 10.1109/TVCG.2018.2817557
   Marai GE, 2018, IEEE T VIS COMPUT GR, V24, P913, DOI 10.1109/TVCG.2017.2744459
   Maries A, 2013, IEEE T VIS COMPUT GR, V19, P2916, DOI 10.1109/TVCG.2013.161
   Martens D, 2009, IEEE T KNOWL DATA EN, V21, P178, DOI 10.1109/TKDE.2008.131
   Metsalu T, 2015, NUCLEIC ACIDS RES, V43, pW566, DOI 10.1093/nar/gkv468
   Meuschke M., 2021, IEEE Trans. Vis. Comp. Graph., DOI DOI 10.1109/TVCG.2021.31340832
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Monroe M, 2013, IEEE T VIS COMPUT GR, V19, P2227, DOI 10.1109/TVCG.2013.200
   Multidisciplinary Larynx Cancer Working Group, 2017, Sci. Reports, V7, P6
   O'Sullivan B, 2016, LANCET ONCOL, V17, P440, DOI 10.1016/S1470-2045(15)00560-4
   Peake G, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2060, DOI 10.1145/3219819.3220072
   Plaisant C., 1996, PROC SIGCHI C HU FAC, P221, DOI [DOI 10.1145/257089.2573912, DOI 10.1145/238386.238493.2]
   Raidou RG, 2015, COMPUT GRAPH FORUM, V34, P11, DOI 10.1111/cgf.12613
   Rosenthal DI, 2007, HEAD NECK-J SCI SPEC, V29, P923, DOI 10.1002/hed.20602
   Skerman HM, 2009, RES NURS HEALTH, V32, P345, DOI 10.1002/nur.20323
   Tandan M, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104249
   Tardini E, 2022, J MED INTERNET RES, V24, DOI 10.2196/29455
   Tosado J., 2020, Scientific reports, V10, P2
   van Dijk L. V., 2021, Cancer, V127, P2
   van Dijk LV, 2023, EUR J CANCER, V178, P150, DOI 10.1016/j.ejca.2022.10.011
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P238, DOI 10.1109/TVCG.2021.3114840
   Wang TD, 2009, IEEE T VIS COMPUT GR, V15, P1049, DOI 10.1109/TVCG.2009.187
   Wang Y., 2021, IDEAS '21. Assoc. for Comp. Mach., DOI DOI 10.1145/3472163.34721772
   Wenskovitch JE, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-316
   Wentzel A, 2020, IEEE T VIS COMPUT GR, V26, P949, DOI 10.1109/TVCG.2019.2934546
   Wentzel A., 2023, Comp. Graph. Forum, DOI DOI 10.1111/CGF.148302
   Wentzel A, 2021, RADIOTHER ONCOL, V161, P152, DOI 10.1016/j.radonc.2021.06.016
   Wentzel A, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P281, DOI [10.1109/vis47514.2020.00063, 10.1109/VIS47514.2020.00063]
   Wentzel A, 2020, RADIOTHER ONCOL, V148, P245, DOI 10.1016/j.radonc.2020.05.023
   Wongsuphasawat K., 2011, IEEE VISWEEK WORKSHO, P6
   Wongsuphasawat K, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1747
   Yang Hongyu, 2017, INT C MACHINE LEARNI, P3921
   Yuan J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P6, DOI 10.1109/VIS49827.2021.9623303
   Zdilar L, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.18.00052
   Zhang ZY, 2015, INFORM VISUAL, V14, P289, DOI 10.1177/1473871614526077
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zhuochen Jin, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3344258
NR 82
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1227
EP 1237
DI 10.1109/TVCG.2023.3326939
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500037
PM 38015695
OA Green Submitted, Green Accepted
DA 2024-11-06
ER

PT J
AU Ouyang, Y
   Wu, YC
   Wang, H
   Zhang, CY
   Cheng, FR
   Jiang, C
   Jin, LX
   Cao, YW
   Li, Q
AF Ouyang, Yang
   Wu, Yuchen
   Wang, He
   Zhang, Chenyang
   Cheng, Furui
   Jiang, Chang
   Jin, Lixia
   Cao, Yuanwu
   Li, Quan
TI Leveraging Historical Medical Records as a Proxy via Multimodal Modeling
   and Visualization to Enrich Medical Diagnostic Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Multimodal Medical Dataset; Visual Analytics; Explainable Machine
   Learning
ID HEALTH-CARE; VISUAL ANALYTICS; SIMULATION; EDUCATION; EXPLORATION
AB Simulation-based Medical Education (SBME) has been developed as a cost-effective means of enhancing the diagnostic skills of novice physicians and interns, thereby mitigating the need for resource-intensive mentor-apprentice training. However, feedback provided in most SBME is often directed towards improving the operational proficiency of learners, rather than providing summative medical diagnoses that result from experience and time. Additionally, the multimodal nature of medical data during diagnosis poses significant challenges for interns and novice physicians, including the tendency to overlook or over-rely on data from certain modalities, and difficulties in comprehending potential associations between modalities. To address these challenges, we present DiagnosisAssistant, a visual analytics system that leverages historical medical records as a proxy for multimodal modeling and visualization to enhance the learning experience of interns and novice physicians. The system employs elaborately designed visualizations to explore different modality data, offer diagnostic interpretive hints based on the constructed model, and enable comparative analyses of specific patients. Our approach is validated through two case studies and expert interviews, demonstrating its effectiveness in enhancing medical training.
C1 [Ouyang, Yang; Wu, Yuchen; Wang, He; Li, Quan] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.
   [Ouyang, Yang; Wu, Yuchen; Wang, He; Li, Quan] Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
   [Zhang, Chenyang] Univ Illinois, Dept Comp Sci, Champaign, IL USA.
   [Cheng, Furui] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Jiang, Chang; Jin, Lixia; Cao, Yuanwu] Fudan Univ, Zhongshan Hosp, Shanghai, Peoples R China.
C3 ShanghaiTech University; University of Illinois System; University of
   Illinois Urbana-Champaign; Swiss Federal Institutes of Technology
   Domain; ETH Zurich; Fudan University
RP Li, Q (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai, Peoples R China.; Li, Q (corresponding author), Shanghai Engn Res Ctr Intelligent Vis & Imaging, Shanghai, Peoples R China.
EM ouyy@shanghaitech.edu.cn; wuych3@shanghaitech.edu.cn;
   wanghe1@shanghaitech.edu.cn; zhang414@illinois.edu;
   furui.cheng@inf.ethz.ch; cjiang_fdu@yeah.net;
   jin.lixia@zs-hospital.sh.cn; cao.yuanwu@zs-hospital.sh.cn;
   liquan@shanghaitech.edu.cn
RI Zhang, Chenyang/AAJ-1371-2020; Wu, Yuchen/AFB-8756-2022
OI Cheng, Furui/0000-0003-2329-6126; Zhang, Chenyang/0009-0003-1116-4895; ,
   Yang/0009-0000-5841-7659; Wang, He/0009-0003-2550-6139
FU National Natural Science Foundation of China
FX No Statement Available
CR Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2
   Al-Elq AH, 2010, J FAM COMMUNITY MED, V17, P35, DOI 10.4103/1319-1683.68787
   Al-Ghareeb AZ, 2016, NURS EDUC TODAY, V36, P281, DOI 10.1016/j.nedt.2015.08.005
   Alsentzer E., 2019, P 2 CLIN NAT LANG PR, P72, DOI 10.18653
   Ashuach T., 2021, bioRxiv, DOI [10.1101/2021.08.20.4570571, DOI 10.1101/2021.08.20.4570571]
   Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012
   Bastani O, 2018, Arxiv, DOI arXiv:1706.09773
   Baumgartl T, 2021, IEEE T VIS COMPUT GR, V27, P711, DOI 10.1109/TVCG.2020.3030437
   Bernard J, 2019, IEEE T VIS COMPUT GR, V25, P1615, DOI 10.1109/TVCG.2018.2803829
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burgess A, 2018, CLIN TEACH, V15, P197, DOI 10.1111/tct.12756
   Caban JJ, 2015, J AM MED INFORM ASSN, V22, P260, DOI 10.1093/jamia/ocv006
   Calisto FM, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580682
   Calisto FM, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102607
   Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TT, 2019, I S BIOMED IMAGING, P1505, DOI [10.1109/ISBI.2019.8759303, 10.1109/isbi.2019.8759303]
   Chengoden R, 2023, IEEE ACCESS, V11, P12764, DOI 10.1109/ACCESS.2023.3241628
   Choi E, 2016, ADV NEUR IN, V29
   Cui C, 2023, Arxiv, DOI arXiv:2203.15588
   Dinov ID, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157077
   Ensor K. B., 1997, Lectures in Applied Mathematics-American Mathematical Society, V33, P4
   Faris H., 2021, Inform. Med. Unlocked, V23, P100513, DOI DOI 10.1016/J.IMU.2021.100513
   Goedhart J, 2021, MOL BIOL CELL, V32, P470, DOI 10.1091/mbc.E20-09-0583
   Guo WB, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P364, DOI 10.1145/3243734.3243792
   Guo Y., 2021, IEEE Transactions on Visualization and Computer Graphics, DOI [10.1109/tvcg.2021.31004132, DOI 10.1109/TVCG.2021.31004132]
   Henelius A, 2014, DATA MIN KNOWL DISC, V28, P1503, DOI 10.1007/s10618-014-0368-8
   Holste G, 2021, IEEE INT CONF COMP V, P3287, DOI 10.1109/ICCVW54120.2021.00368
   Hoopes S, 2020, OBSTET GYNECOL, V136, P56, DOI 10.1097/AOG.0000000000003931
   Huang SC, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78888-w
   Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z
   Huff DT, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abcd17
   Issenberg SB, 2011, SIMUL HEALTHC, V6, P155, DOI 10.1097/SIH.0b013e3182207c24
   Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35
   Kawahara J, 2019, IEEE J BIOMED HEALTH, V23, P538, DOI 10.1109/JBHI.2018.2824327
   Kazan R, 2016, SIMUL HEALTHC, V11, P60, DOI 10.1097/SIH.0000000000000124
   Kolb D., 1984, Englewood Cliffs, P31
   Konig Rikard, 2008, 2008 IEEE International Conference on Data Mining Workshops, P971, DOI 10.1109/ICDMW.2008.117
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Kuiper JS, 2015, AGEING RES REV, V22, P39, DOI 10.1016/j.arr.2015.04.006
   Kwon BC, 2019, IEEE T VIS COMPUT GR, V25, P299, DOI 10.1109/TVCG.2018.2865027
   Li Q, 2018, IEEE CONF VIS ANAL, P48, DOI 10.1109/VAST.2018.8802454
   Li SQ, 2019, I S BIOMED IMAGING, P384, DOI 10.1109/ISBI.2019.8759385
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lutgendorf MA, 2017, MIL MED, V182, pE1762, DOI 10.7205/MILMED-D-16-00030
   Malik S., 2015, P 20 INT C INT US IN, P38, DOI [DOI 10.1145/2678025.27014072, DOI 10.1145/2678025.2701407, 10.1145/2678025.2701407]
   McGaghie WC, 2016, MED EDUC, V50, P986, DOI 10.1111/medu.12795
   McGaghie WC, 2010, MED EDUC, V44, P50, DOI 10.1111/j.1365-2923.2009.03547.x
   Mörth E, 2020, COMPUT GRAPH FORUM, V39, P611, DOI 10.1111/cgf.14172
   Muhammad G, 2021, INFORM FUSION, V76, P355, DOI 10.1016/j.inffus.2021.06.007
   Payrovnaziri SN, 2020, J AM MED INFORM ASSN, V27, P1173, DOI 10.1093/jamia/ocaa053
   Piccialli F, 2021, INFORM FUSION, V66, P111, DOI 10.1016/j.inffus.2020.09.006
   Raidou RG, 2018, COMPUT GRAPH FORUM, V37, P205, DOI 10.1111/cgf.13413
   Ribeiro M. T., 2018, P AAAI C ART INT, V32, DOI DOI 10.1609/AAAI.V32I1.114912
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rooney MK, 2018, INT J RADIAT ONCOL, V102, P257, DOI 10.1016/j.ijrobp.2018.05.064
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Seropian MA, 2004, J NURS EDUC, V43, P164
   Shahar Y, 2006, ARTIF INTELL MED, V38, P115, DOI 10.1016/j.artmed.2005.03.001
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Sivaraman V, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581075
   Solares JRA, 2020, J BIOMED INFORM, V101, DOI 10.1016/j.jbi.2019.103337
   Srinivasan M, 2006, ACAD PSYCHIATR, V30, P505, DOI 10.1176/appi.ap.30.6.505
   Stewart W. J., 2009, Probability, Markov chains, queues, and simulation: the mathematical basis of performance modeling, DOI [10.1515/97814008328116, DOI 10.1515/97814008328116]
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Sugathan S, 2022, COMPUT GRAPH-UK, V107, P208, DOI 10.1016/j.cag.2022.07.023
   Tanya S, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.6604
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vozenilek J, 2004, ACAD EMERG MED, V11, P1149, DOI 10.1197/j.aem.2004.08.003
   Wang HZ, 2021, I S BIOMED IMAGING, P1169, DOI 10.1109/ISBI48211.2021.9433823
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P238, DOI 10.1109/TVCG.2021.3114840
   Zigmont JJ, 2011, SEMIN PERINATOL, V35, P47, DOI 10.1053/j.semperi.2011.01.002
NR 73
TC 3
Z9 3
U1 11
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1238
EP 1248
DI 10.1109/TVCG.2023.3326929
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500127
PM 37874707
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yan, L
   Guo, HQ
   Peterka, T
   Wang, B
   Wang, JL
AF Yan, Lin
   Guo, Hanqi
   Peterka, Thomas
   Wang, Bei
   Wang, Jiali
TI TROPHY: A Topologically Robust Physics-Informed Tracking Framework for
   Tropical Cyclones
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Feature tracking; robustness; topology-based methods in visualization;
   applications; climate science; tropical cyclones
ID SIMPLIFICATION; VISUALIZATION
AB Tropical cyclones (TCs) are among the most destructive weather systems. Realistically and efficiently detecting and tracking TCs are critical for assessing their impacts and risks. In particular, the eye is a signature feature of a mature TC. Therefore, knowing the eyes' locations and movements is crucial for both operational weather forecasts and climate risk assessments. Recently, a multilevel robustness framework has been introduced to study the critical points of time-varying vector fields. The framework quantifies the robustness (i.e., structural stability) of critical points across varying neighborhoods. By relating the multilevel robustness with critical point tracking, the framework has demonstrated its potential in cyclone tracking. An advantage is that it identifies cyclonic features using only 2D wind vector fields, which is encouraging as most tracking algorithms require multiple dynamic and thermodynamic variables at different altitudes. A disadvantage is that the framework does not scale well computationally for datasets containing a large number of cyclones. This paper introduces a topologically robust physics-informed tracking framework (TROPHY) for TC tracking. The main idea is to integrate physical knowledge of TC to drastically improve the computational efficiency of multilevel robustness framework for large-scale climate datasets. First, during preprocessing, we propose a physics-informed feature selection strategy to filter 90% of critical points that are short-lived and have low stability, thus preserving good candidates for TC tracking. Second, during in-processing, we impose constraints during the multilevel robustness computation to focus only on physics-informed neighborhoods of TCs. We apply TROPHY to 30 years of 2D wind fields from reanalysis data in ERA5 and generate a number of TC tracks. In comparison with the observed tracks, we demonstrate that TROPHY can capture TC characteristics (e.g., frequency, intensity, duration, latitudes with maximum intensity, and genesis) that are comparable to and sometimes even better than a well-validated TC tracking algorithm that requires multiple dynamic and thermodynamic scalar fields.
C1 [Yan, Lin; Peterka, Thomas; Wang, Jiali] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Guo, Hanqi] Ohio State Univ, Columbus, OH USA.
   [Wang, Bei] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Argonne National Laboratory;
   University System of Ohio; Ohio State University; Utah System of Higher
   Education; University of Utah
RP Yan, L (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
EM lyan@anl.gov; guo.2154@osu.edu; tpeterka@mcs.anl.gov;
   beiwang@sci.utah.edu; jialiwang@anl.gov
RI Guo, Hanqi/AAL-1929-2021; Guo, Hanqi/ADW-4234-2022
OI Guo, Hanqi/0000-0001-7776-1834
FU Wind Energy Technologies Office of the DOE. Argonne National Laboratory
   is a US Department of Energy laboratory managed by UChicago Argonne, LLC
FX No Statement Available
CR Bell SS, 2018, J CLIMATE, V31, P2217, DOI 10.1175/JCLI-D-17-0548.1
   Biswas M., 2018, Developmental Testbed Center, P2
   Blackwell KG, 2000, MON WEATHER REV, V128, P4002, DOI 10.1175/1520-0493(2000)129<4002:TEOHDA>2.0.CO;2
   Bourdin S., 2022, EGUsphere, P1, DOI [10.5194/egusphere-2022-179, DOI 10.5194/EGUSPHERE-2022-179]
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bujack R, 2020, COMPUT GRAPH FORUM, V39, P811, DOI 10.1111/cgf.14037
   Cabral B., 1993, Computer Graphics Proceedings, P263, DOI 10.1145/166117.166151
   Camargo SJ, 2002, WEATHER FORECAST, V17, P1152, DOI 10.1175/1520-0434(2002)017<1152:ITDATO>2.0.CO;2
   Chang PL, 2009, WEATHER FORECAST, V24, P245, DOI 10.1175/2008WAF2222112.1
   Copernicus Climate Change Service, About us
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P2896, DOI 10.1109/TVCG.2013.131
   Edelsbrunner H, 2008, COMP GEOM-THEOR APPL, V41, P149, DOI 10.1016/j.comgeo.2007.11.001
   Engelke W., 2021, Topologybased feature design and tracking for multi-center cyclones, P71, DOI DOI 10.1007/978-3-030-83500-2_5
   Enz B. M., 2022, Geoscientific Model Development Discussions, P1, DOI [DOI 10.5194/GMD-2022-2792, DOI 10.5194/GMD-2022-279]
   Garth C, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P329, DOI 10.1109/VISUAL.2004.107
   Guo HQ, 2021, IEEE T VIS COMPUT GR, V27, P3463, DOI 10.1109/TVCG.2021.3073399
   HELMAN J, 1989, COMPUTER, V22, P27, DOI 10.1109/2.35197
   HELMAN JL, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P6, DOI 10.1109/VISUAL.1990.146359
   Hodges K, 2017, J CLIMATE, V30, P5243, DOI [10.1175/jcli-d-16-0557.1, 10.1175/JCLI-D-16-0557.1]
   Holland G, 2014, CLIM DYNAM, V42, P617, DOI 10.1007/s00382-013-1713-0
   Jankowai J, 2019, COMPUT GRAPH FORUM, V38, P337, DOI 10.1111/cgf.13693
   Kepert JD, 2005, MON WEATHER REV, V133, P2406, DOI 10.1175/MWR2980.1
   Kleppek S, 2008, GEOPHYS RES LETT, V35, DOI 10.1029/2008GL033880
   Knaff JA, 2014, J CLIMATE, V27, P455, DOI 10.1175/JCLI-D-13-00096.1
   Knapp KR, 2010, B AM METEOROL SOC, V91, P363, DOI 10.1175/2009BAMS2755.1
   Kossin JP, 2013, J CLIMATE, V26, P9960, DOI 10.1175/JCLI-D-13-00262.1
   Lee WC, 2000, MON WEATHER REV, V128, P1925, DOI 10.1175/1520-0493(2000)128<1925:TCKSRF>2.0.CO;2
   Marchok T, 2021, J APPL METEOROL CLIM, V60, P1265, DOI 10.1175/JAMC-D-20-0175.1
   Nilsson E., 2020, Levia, DOI [10.31219/osf.io/jqtua1, DOI 10.31219/OSF.IO/JQTUA1]
   Reininghaus J, 2012, IEEE T VIS COMPUT GR, V18, P1563, DOI 10.1109/TVCG.2011.269
   Simmerman S, 2013, COMPUT SCI ENG, V15, P46, DOI 10.1109/MCSE.2012.92
   Sivaramakrishnan M., 1966, P 12 C RAD MET NORM, P1
   Skraba P., 2014, TOPOLOGICAL METHODS, P19, DOI DOI 10.1007/978-3-319-04099-8_21,2
   Skraba P, 2016, IEEE T VIS COMPUT GR, V22, P1683, DOI 10.1109/TVCG.2016.2534538
   Skraba P, 2015, IEEE T VIS COMPUT GR, V21, P930, DOI 10.1109/TVCG.2015.2440250
   Skraba P, 2014, IEEE PAC VIS SYMP, P49, DOI 10.1109/PacificVis.2014.17
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Taylor A.A., 2008, 19 C PROB STAT
   Theisel H., 2003, P S DAT VIS 2003 GRE, P2
   Tricoche X, 2001, IEEE VISUAL, P159, DOI 10.1109/VISUAL.2001.964507
   Tricoche X, 2002, COMPUT GRAPH-UK, V26, P249, DOI 10.1016/S0097-8493(02)00056-0
   Tricoche X, 2001, SPRING EUROGRAP, P117
   Ullrich PA, 2017, GEOSCI MODEL DEV, V10, P1069, DOI 10.5194/gmd-10-1069-2017
   Walsh KJE, 2016, WIRES CLIM CHANGE, V7, P65, DOI 10.1002/wcc.371
   Wang B, 2013, COMPUT GRAPH FORUM, V32, P221, DOI 10.1111/cgf.12109
   Wang B., 2017, Topological Methods in Data Analysis and Visualization, P221, DOI [10.1007/978-3-030-43036-8_14, DOI 10.1007/978-3-030-43036-8_14]
   Wang B., 2017, Modeling, Analysis, and Visualization of Anisotropy, P3, DOI [10.1007/978-3-319-61358-1_19, DOI 10.1007/978-3-319-61358-1_19]
   Weinkauf T, 2011, IEEE T VIS COMPUT GR, V17, P770, DOI 10.1109/TVCG.2010.93
   Willoughby HE, 1998, MON WEATHER REV, V126, P3053, DOI 10.1175/1520-0493(1998)126<3053:TCET>2.0.CO;2
   Wischgoll T, 2001, IEEE T VIS COMPUT GR, V7, P165, DOI 10.1109/2945.928168
   Yan L, 2022, Arxiv, DOI arXiv:2209.11708
   Yan WK, 2008, EXPERT SYST APPL, V34, P643, DOI 10.1016/j.eswa.2006.10.013
   Yang WC, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2108397118
   Zarzycki CM, 2021, J APPL METEOROL CLIM, V60, P643, DOI 10.1175/JAMC-D-20-0149.1
   Zarzycki CM, 2017, GEOPHYS RES LETT, V44, P1141, DOI 10.1002/2016GL071606
NR 55
TC 1
Z9 1
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1249
EP 1259
DI 10.1109/TVCG.2023.3326905
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500120
PM 37930920
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Klenert, N
   Lepper, V
   Baum, D
AF Klenert, Nicolas
   Lepper, Verena
   Baum, Daniel
TI A Local Iterative Approach for the Extraction of 2D Manifolds from
   Strongly Curved and Folded Thin-Layer Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ridge surface; crease surface; 2D manifold extraction; fast marching;
   virtual unfolding; historical documents
ID VISUALIZATION; CREASES
AB Ridge surfaces represent important features for the analysis of 3-dimensional (3D) datasets in diverse applications and are often derived from varying underlying data including flow fields, geological fault data, and point data, but they can also be present in the original scalar images acquired using a plethora of imaging techniques. Our work is motivated by the analysis of image data acquired using micro-computed tomography (mu CT) of ancient, rolled and folded thin-layer structures such as papyrus, parchment, and paper as well as silver and lead sheets. From these documents we know that they are 2-dimensional (2D) in nature. Hence, we are particularly interested in reconstructing 2D manifolds that approximate the document's structure. The image data from which we want to reconstruct the 2D manifolds are often very noisy and represent folded, densely-layered structures with many artifacts, such as ruptures or layer splitting and merging. Previous ridge-surface extraction methods fail to extract the desired 2D manifold for such challenging data. We have therefore developed a novel method to extract 2D manifolds. The proposed method uses a local fast marching scheme in combination with a separation of the region covered by fast marching into two sub-regions. The 2D manifold of interest is then extracted as the surface separating the two sub-regions. The local scheme can be applied for both automatic propagation as well as interactive analysis. We demonstrate the applicability and robustness of our method on both artificial data as well as real-world data including folded silver and papyrus sheets.
C1 [Klenert, Nicolas; Baum, Daniel] Zuse Inst Berlin, Berlin, Germany.
   [Lepper, Verena] Agypt Museum & Papyrussammlung, Berlin, Germany.
C3 Zuse Institute Berlin
RP Klenert, N (corresponding author), Zuse Inst Berlin, Berlin, Germany.
EM klenert@zib.de; v.lepper@smb.spk-berlin.de; baum@zib.de
OI Baum, Daniel/0000-0003-1550-7245; Klenert, Nicolas/0009-0006-4443-8620
FU German Research Foundation (DFG)
FX No Statement Available
CR Algarni M, 2019, IEEE T PATTERN ANAL, V41, P726, DOI 10.1109/TPAMI.2018.2811810
   Ambellan F, 2021, MED IMAGE ANAL, V73, DOI 10.1016/j.media.2021.102178
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   Arnold V.I., 2006, Ordinary Differential Equations
   Axler S., 2019, Measure, Integration & Real Analysis, V1, DOI [10.1007/978-3-030-33143-6, DOI 10.1007/978-3-030-33143-6]
   Barakat S, 2011, COMPUT GRAPH FORUM, V30, P961, DOI 10.1111/j.1467-8659.2011.01945.x
   Barakat S, 2010, PROCEDIA COMPUT SCI, V1, P1703, DOI 10.1016/j.procs.2010.04.192
   Barfod GH, 2015, SCI REP-UK, V5, DOI 10.1038/srep17765
   Baum D, 2017, APPL PHYS A-MATER, V123, DOI 10.1007/s00339-017-0808-6
   Dambrogio J, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21326-w
   Deschamps T, 2001, MED IMAGE ANAL, V5, P281, DOI 10.1016/S1361-8415(01)00046-9
   Eberly D., 1994, Journal of Mathematical Imaging and Vision, V4, P353, DOI 10.1007/BF01262402
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Gibson D., 2012, SEG (Society of Exploration Geophysicists) Technical Program Expanded Abstracts, V43, P2094, DOI [10.1190/segam2012-0734.1, DOI 10.1190/SEGAM2012-0734.1]
   HARALICK RM, 1983, COMPUT VISION GRAPH, V22, P28, DOI 10.1016/0734-189X(83)90094-4
   Hege H.-C., 1997, Technical report
   Herter F, 2021, COMPUT GRAPH FORUM, V40, P147, DOI 10.1111/cgf.14296
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kindlmann G, 2018, COMPUT GRAPH FORUM, V37, P525, DOI 10.1111/cgf.13439
   Kindlmann G, 2006, LECT NOTES COMPUT SC, V4190, P126
   Kindlmann GL, 2009, IEEE T VIS COMPUT GR, V15, P1415, DOI 10.1109/TVCG.2009.177
   KOENDERINK JJ, 1993, P SOC PHOTO-OPT INS, V2031, P2, DOI 10.1117/12.146617
   Lee J, 2013, INT ADV SELF RES, P205
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Mahnke HE, 2020, J CULT HERIT, V41, P264, DOI 10.1016/j.culher.2019.07.007
   Mirebeau JM, 2014, SIAM J NUMER ANAL, V52, P1573, DOI 10.1137/120861667
   Mocella V., personal communication
   Mocella V, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms6895
   Neuber D., 2012, ZfP-Zeitung, V132, P39
   Peikert R, 2008, IEEE PACIFIC VISUALISATION SYMPOSIUM 2008, PROCEEDINGS, P119
   Sadlo F, 2007, IEEE T VIS COMPUT GR, V13, P1456, DOI 10.1109/TVCG.2007.70554
   Sahner J, 2007, IEEE T VIS COMPUT GR, V13, P980, DOI 10.1109/TVCG.2007.1053
   Samko O, 2014, PATTERN RECOGN, V47, P248, DOI 10.1016/j.patcog.2013.06.015
   Schultz T, 2010, IEEE T VIS COMPUT GR, V16, P109, DOI 10.1109/TVCG.2009.44
   Seales WB, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1601247
   Sethian JA, 1999, GEOPHYSICS, V64, P516, DOI 10.1190/1.1444558
   Sethian JA, 1999, SIAM REV, V41, P199, DOI 10.1137/S0036144598347059
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Stanford University Computer Graphics Laboratory, 2014, The Stanford 3D Scanning Repository
   Vavrík D, 2020, ARCHAEOL ANTHROP SCI, V12, DOI 10.1007/s12520-019-00976-4
   Wilster-Hansen B, 2022, ARCHAEOMETRY, V64, P969, DOI 10.1111/arcm.12734
NR 42
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1260
EP 1270
DI 10.1109/TVCG.2023.3327403
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500103
PM 37930919
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, GX
   Iuricich, F
AF Liu, Guoxi
   Iuricich, Federico
TI A Task-Parallel Approach for Localized Topological Data Structures
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data structures; Task analysis; Faces; Memory management; Instruction
   sets; Computational modeling; Graphics processing units; parallel
   computation; topological data analysis; simplicial complex
ID COMPACT REPRESENTATION; MORSE COMPLEXES; COMPUTATION
AB Unstructured meshes are characterized by data points irregularly distributed in the Euclidian space. Due to the irregular nature of these data, computing connectivity information between the mesh elements requires much more time and memory than on uniformly distributed data. To lower storage costs, dynamic data structures have been proposed. These data structures compute connectivity information on the fly and discard them when no longer needed. However, on-the-fly computation slows down algorithms and results in a negative impact on the time performance. To address this issue, we propose a new task-parallel approach to proactively compute mesh connectivity. Unlike previous approaches implementing data-parallel models, where all threads run the same type of instructions, our task-parallel approach allows threads to run different functions. Specifically, some threads run the algorithm of choice while other threads compute connectivity information before they are actually needed. The approach was implemented in the new Accelerated Clustered TOPOlogical (ACTOPO) data structure, which can support any processing algorithm requiring mesh connectivity information. Our experiments show that ACTOPO combines the benefits of state-of-the-art memory-efficient (TTK CompactTriangulation) and time-efficient (TTK ExplicitTriangulation) topological data structures. It occupies a similar amount of memory as TTK CompactTriangulation while providing up to 5x speedup. Moreover, it achieves comparable time performance as TTK ExplicitTriangulation while using only half of the memory space.
C1 [Liu, Guoxi; Iuricich, Federico] Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
C3 Clemson University
RP Liu, GX (corresponding author), Clemson Univ, Sch Comp, Clemson, SC 29634 USA.
EM guoxil@clemson.edu; fiurici@clemson.edu
RI Liu, Guoxi/J-4618-2014
OI Liu, Guoxi/0000-0002-8164-7185; Iuricich, Federico/0000-0003-1782-9715
CR Azpúrua H, 2021, IEEE INT CONF ROBOT, P2443, DOI 10.1109/ICRA48506.2021.9561099
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Bao X., 2022, EUROVIS 2022 SHORT P, DOI DOI 10.2312/EVS.202211041
   Bentley JL, 1997, PROCEEDINGS OF THE EIGHTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P360
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Boissonnat JD, 2014, ALGORITHMICA, V70, P406, DOI 10.1007/s00453-014-9887-3
   Canino D., 2014, P 22 INT MESHING ROU, P465, DOI DOI 10.1007/978-3-319-02335-9_262
   Canino D, 2011, COMPUT GRAPH-UK, V35, P747, DOI 10.1016/j.cag.2011.03.009
   Carr HA, 2022, SYMP LARG DATA ANAL, P15, DOI 10.1109/LDAV57265.2022.9966394
   Carr HA, 2021, IEEE T VIS COMPUT GR, V27, P2437, DOI 10.1109/TVCG.2019.2948616
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chandra R., 2001, Parallel Programming in OpenMP
   Codd AL, 2021, GEOPHYS J INT, V227, P2095, DOI 10.1093/gji/ggab323
   Dai A, 2019, PROC CVPR IEEE, P5559, DOI 10.1109/CVPR.2019.00572
   De Floriani L., 2010, P 19 INT MESHING ROU, P403, DOI [10.1007/978-3-642-15414-0_24, DOI 10.1007/978-3-642-15414-0_24]
   De Floriani L., 2004, P 2004 EUROGRAPHICSA, P83, DOI [10.1145/1057432.10574442, DOI 10.1145/1057432.10574442]
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Edelsbrunner H., 1987, Algorithms in combinatorial geometry, V10, DOI DOI 10.1007/978-3-642-61568-92
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Fellegara R, 2021, COMPUT GRAPH-UK, V98, P322, DOI 10.1016/j.cag.2021.05.002
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, V48, P5
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Gurung T., 2009, 2009 SIAMACM JOINT C, P79, DOI DOI 10.1145/1629255.16292662
   Gurung T, 2011, COMPUT GRAPH FORUM, V30, P355, DOI 10.1111/j.1467-8659.2011.01866.x
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy A, 2012, INT PARALL DISTRIB P, P484, DOI 10.1109/IPDPS.2012.52
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Heinecke A, 2014, INT CONF HIGH PERFOR, P3, DOI 10.1109/SC.2014.6
   Hilzer R. C.  Jr., 1992, Operating Systems Review, V26, P31, DOI 10.1145/130888.130891
   Hu H, 2021, IEEE INT C INT ROBOT, P384, DOI 10.1109/IROS51168.2021.9636067
   Huang X, 2021, PROCEEDINGS OF THE 2021 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, ICS 2021, P367, DOI 10.1145/3447818.3460358
   Kessler C., 2007, Mitteilungen - Gesellschaft far Informatik e.V., ParallelAlgorithmen und Rechnerstrukturen, V24, P1
   Klacansky P, 2020, IEEE T VIS COMPUT GR, V26, P173, DOI 10.1109/TVCG.2019.2934257
   Kremer Michael, 2013, P 21 INT MESH ROUNDT, P531, DOI [10.1007/978-3-642-33573-0_312, DOI 10.1007/978-3-642-33573-0_312]
   Lawson C.L., 1977, Mathematical software, P161, DOI [10.1016/B978-0-12-587260-7.50011-X, DOI 10.1016/B978-0-12-587260-7.50011-X]
   Liu GX, 2023, IEEE T VIS COMPUT GR, V29, P1506, DOI 10.1109/TVCG.2021.3121229
   Luffel M, 2014, IEEE T VIS COMPUT GR, V20, P84, DOI 10.1109/TVCG.2013.81
   Morrical N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P256, DOI 10.1109/visual.2019.8933539
   Nielson G. M., 1997, Scientific Visualization: overviews, Methodologies and Techniques, P2
   PAOLUZZI A, 1993, ACM T GRAPHIC, V12, P56, DOI 10.1145/169728.169719
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Sahistan A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P91, DOI [10.1109/VIS49827.2021.9623298, 10.1109/VIS49827.2021.00026]
   Samet H., 2005, The Morgan Kaufmann Series in Computer Graphics and Geometric Modeling, P2
   Sathar S, 2015, IEEE ENG MED BIO, P8062, DOI 10.1109/EMBC.2015.7320264
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Shulga D, 2017, IEEE T MED IMAGING, V36, P972, DOI 10.1109/TMI.2016.2641500
   Subhash V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P36, DOI 10.1109/VIS47514.2020.00014
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Wald I, 2022, IEEE T VIS COMPUT GR, V28, P583, DOI 10.1109/TVCG.2021.3114869
   Weiss K., 2011, P 19 ACM SIGSPATIAL, P92, DOI DOI 10.1145/2093973.20939871,2,3,4
   Xu X, 2023, INT J APPL EARTH OBS, V116, DOI 10.1016/j.jag.2022.103145
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zhao XL, 2020, COMPUT FLUIDS, V207, DOI 10.1016/j.compfluid.2020.104589
NR 59
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1271
EP 1281
DI 10.1109/TVCG.2023.3327182
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500086
PM 37906496
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hung, SH
   Zhang, Y
   Zhang, E
AF Hung, Shih-Hsuan
   Zhang, Yue
   Zhang, Eugene
TI Global Topology of 3D Symmetric Tensor Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Tensors; Structural rings; Three-dimensional displays; Topology; Stress;
   Feature extraction; Data visualization; Tensor field visualization; 3D
   symmetric tensor fields; global tensor field topology; topological
   graphs; degenerate curves; neutral surfaces; wedges and trisectors
ID SURFACES; VISUALIZATION; EXTRACTION; LINES
AB There have been recent advances in the analysis and visualization of 3D symmetric tensor fields, with a focus on the robust extraction of tensor field topology. However, topological features such as degenerate curves and neutral surfaces do not live in isolation. Instead, they intriguingly interact with each other. In this paper, we introduce the notion of topological graph for 3D symmetric tensor fields to facilitate global topological analysis of such fields. The nodes of the graph include degenerate curves and regions bounded by neutral surfaces in the domain. The edges in the graph denote the adjacency information between the regions and degenerate curves. In addition, we observe that a degenerate curve can be a loop and even a knot and that two degenerate curves (whether in the same region or not) can form a link. We provide a definition and theoretical analysis of individual degenerate curves in order to help understand why knots and links may occur. Moreover, we differentiate between wedges and trisectors, thus making the analysis more detailed about degenerate curves. We incorporate this information into the topological graph. Such a graph can not only reveal the global structure in a 3D symmetric tensor field but also allow two symmetric tensor fields to be compared. We demonstrate our approach by applying it to solid mechanics and material science data sets.
C1 [Hung, Shih-Hsuan; Zhang, Yue; Zhang, Eugene] Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
C3 Oregon State University
RP Hung, SH (corresponding author), Oregon State Univ, Sch Elect Engn & Comp Sci, Corvalis, OR 97331 USA.
EM hungsh@oregonstate.edu; zhangyue@oregonstate.edu;
   zhange@eecs.oregonstate.edu
OI Zhang, Eugene/0000-0003-4752-3119; Zhang, Yue/0000-0002-8467-2781
FU NSF
FX No Statement Available
CR BANCHOFF T, 1976, INDIANA U MATH J, V25, P1171, DOI 10.1512/iumj.1976.25.25093
   Calcaterra C, 2008, J MATH ANAL APPL, V338, P1108, DOI 10.1016/j.jmaa.2007.06.001
   Cammoun L., 2009, Advances in Pattern Recognition
   Chaimahawan P, 2021, LAT AM J SOLIDS STRU, V18
   Chen GN, 2007, IEEE T VIS COMPUT GR, V13, P769, DOI 10.1109/TVCG.2007.1021
   Crane K., 2018, Discrete differential geometry: An applied introduction, P1153
   Criscione JC, 2000, J MECH PHYS SOLIDS, V48, P2445, DOI 10.1016/S0022-5096(00)00023-5
   De Leeuw W., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P349, DOI 10.1109/VISUAL.1999.809907
   DELMARCELLE T, 1993, IEEE COMPUT GRAPH, V13, P25, DOI 10.1109/38.219447
   Dieck TT, 2008, EMS TEXTB MATH, P1
   Dudzinski N., 1952, RAE/Met-69
   Hannifin P., 2007, Parker o-ring handbook
   Hesselink L, 1997, IEEE T VIS COMPUT GR, V3, P1, DOI 10.1109/2945.582332
   Hung SH, 2022, IEEE T VIS COMPUT GR, V28, P33, DOI 10.1109/TVCG.2021.3114808
   Jankowai J, 2019, COMPUT GRAPH FORUM, V38, P337, DOI 10.1111/cgf.13693
   Kaczynski T., 2004, APPL MATH SCI, V157
   Khan F, 2020, IEEE T VIS COMPUT GR, V26, P270, DOI 10.1109/TVCG.2019.2934314
   Kratz A, 2013, COMPUT GRAPH FORUM, V32, P49, DOI 10.1111/j.1467-8659.2012.03231.x
   Lin Z., 2012, 2D Asymmetric Tensor Field Topology, P191, DOI DOI 10.1007/978-3-642-23175-913
   Livingston C., 1993, KNOT THEORY
   MARKUS L, 1955, ANN MATH, V62, P411, DOI 10.2307/1970071
   Palacios J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130844
   Palacios J, 2016, IEEE T VIS COMPUT GR, V22, P1248, DOI 10.1109/TVCG.2015.2484343
   Panagiotou E, 2020, P ROY SOC A-MATH PHY, V476, DOI 10.1098/rspa.2020.0124
   Qu BT, 2021, IEEE T VIS COMPUT GR, V27, P583, DOI 10.1109/TVCG.2020.3030431
   Rotman J. J., 2013, An introduction to algebraic topology, V119
   Roy L, 2019, IEEE T VIS COMPUT GR, V25, P1102, DOI 10.1109/TVCG.2018.2864768
   Rudin W., 1990, International series in pure and applied mathematics, V2nd
   Smith M., 2020, ABAQUSSTANDARD USERS
   Tao J, 2018, IEEE T VIS COMPUT GR, V24, P3200, DOI 10.1109/TVCG.2017.2773071
   Tricoche X, 2008, IEEE T VIS COMPUT GR, V14, P1627, DOI 10.1109/TVCG.2008.148
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
   Zhang Y., 2020, Topological Methods in Data Analysis and Visualization V, P237, DOI DOI 10.1007/978-3-030-43036-8
   Zhang Y., 2017, Topological Methods in Data Analysis and Visualization IV, P221, DOI DOI 10.1007/978-3-319-44684-413
   [Чжан Юн-Цзюнь Zhang Yongjun], 2017, [Металловедение и термическая обработка металлов, Metallovedenie i termicheskaya obrabotka metallov], P29
   Zheng XQ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P551
   Zheng XQ, 2005, IEEE T VIS COMPUT GR, V11, P395, DOI 10.1109/TVCG.2005.67
   Zheng XQ, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P313, DOI 10.1109/VISUAL.2004.105
NR 38
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1282
EP 1291
DI 10.1109/TVCG.2023.3326933
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500058
PM 37874708
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zheng, JT
   Zhang, E
   Zhang, Y
AF Zheng, Jinta
   Zhang, Eugene
   Zhang, Yue
TI Interactive Design and Optics-Based Visualization of Arbitrary
   Non-Euclidean Kaleidoscopic Orbifolds
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Kaleidoscopic Orbifolds; Orbifold Visualization; Math Visualization;
   Orbifold Construction; Spherical Geometry; Hyperbolic Geometry
ID SURFACES
AB Orbifolds are a modern mathematical concept that arises in the research of hyperbolic geometry with applications in computer graphics and visualization. In this paper, we make use of rooms with mirrors as the visual metaphor for orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon to match the orbifold. This polygon is then used to create a room for which the polygon serves as the floor and the ceiling. With our system that implements Mobius transformations, the user can interactively edit the scene and see the reflections of the edited objects. To correctly visualize non-Euclidean orbifolds, we adapt the rendering algorithms to account for the geodesics in these spaces, which light rays follow. Our interactive orbifold design system allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In addition, our mirror-based orbifold visualization approach has the potential of helping our users gain insight on the orbifold, including its orbifold notation as well as its universal cover, which can also be the spherical space and the hyperbolic space.
C1 [Zheng, Jinta; Zhang, Eugene; Zhang, Yue] Oregon State Univ, Corvallis, OR 97331 USA.
C3 Oregon State University
RP Zheng, JT (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM zhenjint@eecs.oregonstate.edu; zhange@eecs.oregonstate.edu;
   zhangyue@oregonstate.edu
OI Zhang, Eugene/0000-0003-4752-3119; Zhang, Yue/0000-0002-8467-2781
FU NSF
FX No Statement Available
CR Aigerman N, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073615
   Aigerman N, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982412
   Aigerman N, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818099
   Anderson J. W., 2006, Hyperbolic geometry, DOI DOI 10.1007/1-84628-220-9
   [Anonymous], Irrlicht_Engine
   Basmajian A, 2006, Arxiv, DOI arXiv:math/0603457
   Berger P, 2015, VISUAL COMPUT, V31, P93, DOI 10.1007/s00371-013-0913-2
   Bommes D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531383
   Conway J., 2008, Ak Peters Series, DOI DOI 10.1201/B21368
   Cooper D., 2000, MSJ Memoirs, V5, DOI DOI 10.2969/MSJMEMOIRS/00501C020
   COXETER H.S.M., 1998, Spectrum Series
   Giaccari S, 2023, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2023)173
   Greaves G, 2012, J ALGEBRA, V372, P560, DOI 10.1016/j.jalgebra.2012.09.006
   Conway JH, 2018, Arxiv, DOI arXiv:1804.03055
   Hanson A. J., 2005, ACM SIGGRAPH 2005 CO, DOI DOI 10.1145/1198555.1198701
   Hertzmann A, 2000, COMP GRAPH, P517, DOI 10.1145/344779.345074
   Hitchman M.P., 2009, Geometry with an Introduction to Cosmic Topology
   Humphreys J. F., 1996, Oxford Science Publications, V5
   Jakob Wenzel, 2010, Mitsuba Renderer
   Kälberer F, 2007, COMPUT GRAPH FORUM, V26, P375, DOI 10.1111/j.1467-8659.2007.01060.x
   Miley P., 1998, A Study of Orbifolds
   Nieser M, 2012, IEEE T VIS COMPUT GR, V18, P865, DOI 10.1109/TVCG.2011.118
   Nieser M, 2010, LECT NOTES COMPUT SC, V6130, P161, DOI 10.1007/978-3-642-13411-1_11
   Novello T, 2020, COMPUT GRAPH-UK, V93, P61, DOI 10.1016/j.cag.2020.09.014
   OShea D., 2007, The Poincare Conjecture: In Search of the Shape of the Universe, DOI DOI 10.5860/CHOICE.45-0926
   Palacios J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276446, 10.1145/1239451.1239506]
   Palacios J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130844
   Palacios J, 2016, IEEE T VIS COMPUT GR, V22, P1248, DOI 10.1109/TVCG.2015.2484343
   Qu BT, 2021, IEEE T VIS COMPUT GR, V27, P583, DOI 10.1109/TVCG.2020.3030431
   Roy L, 2019, IEEE T VIS COMPUT GR, V25, P1102, DOI 10.1109/TVCG.2018.2864768
   Roy L, 2018, IEEE T VIS COMPUT GR, V24, P843, DOI 10.1109/TVCG.2017.2744038
   Thurston W. P., 1997, Three-Dimensional Geometry and Topology, DOI DOI 10.1515/9781400865321
   van Wijk J., 2005, Visualization of the genus of knots, P01, DOI DOI 10.1109/VISUAL.2005.1532843
   Williams F., 2016, SIGGRAPH ASIA 2016 T, DOI DOI 10.1145/3005358.3005368
   Zeller R, 2021, COMPUT AIDED GEOM D, V90, DOI 10.1016/j.cagd.2021.102027
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
NR 36
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1292
EP 1301
DI 10.1109/TVCG.2023.3326927
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500074
PM 37874711
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Yan, L
   Liang, X
   Guo, HQ
   Wang, B
AF Yan, Lin
   Liang, Xin
   Guo, Hanqi
   Wang, Bei
TI TopoSZ: Preserving Topology in Error-Bounded Lossy Compression
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lossy compression; contour tree; topology preservation; topological data
   analysis; topology in visualization
ID CONTOUR TREES; SCALAR FIELDS; SIMPLIFICATION; VISUALIZATION; SYMMETRY
AB Existing error-bounded lossy compression techniques control the pointwise error during compression to guarantee the integrity of the decompressed data. However, they typically do not explicitly preserve the topological features in data. When performing post hoc analysis with decompressed data using topological methods, preserving topology in the compression process to obtain topologically consistent and correct scientific insights is desirable. In this paper, we introduce TopoSZ, an error-bounded lossy compression method that preserves the topological features in 2D and 3D scalar fields. Specifically, we aim to preserve the types and locations of local extrema as well as the level set relations among critical points captured by contour trees in the decompressed data. The main idea is to derive topological constraints from contour-tree-induced segmentation from the data domain, and incorporate such constraints with a customized error-controlled quantization strategy from the SZ compressor (version 1.4). Our method allows users to control the pointwise error and the loss of topological features during the compression process with a global error bound and a persistence threshold.
C1 [Yan, Lin] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Liang, Xin] Univ Kentucky, Lexington, KY USA.
   [Guo, Hanqi] Ohio State Univ, Columbus, OH USA.
   [Wang, Bei] Univ Utah, Salt Lake City, UT USA.
C3 United States Department of Energy (DOE); Argonne National Laboratory;
   University of Kentucky; University System of Ohio; Ohio State
   University; Utah System of Higher Education; University of Utah
RP Yan, L (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
EM lyan@anl.gov; xliang@uky.edu; guo.2154@osu.edu; beiwang@sci.utah.edu
RI Liang, Xin/LGY-5316-2024; Guo, Hanqi/AAL-1929-2021; Guo,
   Hanqi/ADW-4234-2022
OI Guo, Hanqi/0000-0001-7776-1834; Liang, Xin/0000-0002-0630-1600
FU DOE
FX No Statement Available
CR Abu-Mostafa YS, 2000, COMPUT MATH APPL, V39, P129, DOI 10.1016/S0898-1221(00)00119-X
   Almgren AS, 2013, ASTROPHYS J, V765, DOI 10.1088/0004-637X/765/1/39
   [Anonymous], Energy exascale earth system model
   [Anonymous], 2004, IEEE Scientific Visualization Contest
   [Anonymous], 2016, IEEE Scientific Visualization Contest
   Athawale TM, 2022, IEEE T VIS COMPUT GR, V28, P1955, DOI 10.1109/TVCG.2020.3022359
   Beketayev K., 2014, TopoinVis III, P151, DOI 10.1007/978-3-319-04099-8
   Biwer C., 2019, Nyx cosmological simulation dataset, DOI [10.21227/zh6w-kt7212, DOI 10.21227/ZH6W-KT7212]
   Burtscher M, 2009, IEEE T COMPUT, V58, P18, DOI 10.1109/TC.2008.131
   Burtscher M, 2007, IEEE DATA COMPR CONF, P293
   Caldwell PM, 2019, J ADV MODEL EARTH SY, V11, P4095, DOI 10.1029/2019MS001870
   Cappello F, 2019, INT J HIGH PERFORM C, V33, P1201, DOI 10.1177/1094342019853336
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Carr H, 2010, COMP GEOM-THEOR APPL, V43, P42, DOI 10.1016/j.comgeo.2006.05.009
   Chiang Y, 2003, COMPUT GRAPH FORUM, V22, P493, DOI 10.1111/1467-8659.00697
   Chow MM, 1997, VISUALIZATION '97 - PROCEEDINGS, P347, DOI 10.1109/VISUAL.1997.663902
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Computer Graphics Laboratory, ABOUT US
   Crawfis R., Tornado data set generator
   Di S, 2019, IEEE T PARALL DISTR, V30, P331, DOI 10.1109/TPDS.2018.2859932
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P2896, DOI 10.1109/TVCG.2013.131
   Edelsbrunner H, 2003, DISCRETE COMPUT GEOM, V30, P87, DOI 10.1007/s00454-003-2926-5
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Edelsbrunner H., 2010, American Mathematical Society, V3, P12
   Engelke W., 2021, Topological Methods in Data Analysis and Visualization VI. Mathematics and Visualization, DOI [10.1109/TVCG.2014.23464341, DOI 10.1109/TVCG.2014.23464341]
   Gerber S, 2012, J STAT SOFTW, V50, P1
   Golaz JC, 2019, J ADV MODEL EARTH SY, V11, P2089, DOI 10.1029/2018MS001603
   Günther T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073684
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Gzip, About us
   HOWARD PG, 1992, INFORM PROCESS MANAG, V28, P749, DOI 10.1016/0306-4573(92)90066-9
   Ibarria L, 2003, COMPUT GRAPH FORUM, V22, P343, DOI 10.1111/1467-8659.00681
   Jayasankar U, 2021, J KING SAUD UNIV-COM, V33, P119, DOI 10.1016/j.jksuci.2018.05.006
   Kai Zhao, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P89, DOI 10.1145/3369583.3392688
   Lakshminarasimhan S, 2011, LECT NOTES COMPUT SC, V6852, P366, DOI 10.1007/978-3-642-23400-2_34
   Liang XD, 2022, IEEE T IND APPL, V58, P1843, DOI 10.1109/TIA.2022.3146103
   Liang X, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356193
   Liang X, 2020, IEEE PAC VIS SYMP, P81, DOI 10.1109/PacificVis48177.2020.6431
   Liang X, 2018, IEEE INT CONF BIG DA, P438, DOI 10.1109/BigData.2018.8622520
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Lohfink AP, 2020, COMPUT GRAPH FORUM, V39, P343, DOI 10.1111/cgf.13985
   Nilsson E., 2020, Levia, DOI [10.31219/osf.io/jqtua1, DOI 10.31219/OSF.IO/JQTUA1]
   Pascucci V., 2004, PROC IASTED C VISUAL, P452
   Popinet S, 2004, J ATMOS OCEAN TECH, V21, P1575, DOI 10.1175/1520-0426(2004)021<1575:EANSOT>2.0.CO;2
   Popinet S., 2004, ClusterWorld, V2, P12
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Saikia H., 2015, TOPOLOGICAL METHODS, P121, DOI [10.1007/978-3-319-44684-4_7, DOI 10.1007/978-3-319-44684-4_7]
   Saikia H, 2014, COMPUT GRAPH FORUM, V33, P41, DOI 10.1111/cgf.12360
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Sohn BS, 2006, IEEE T VIS COMPUT GR, V12, P14, DOI 10.1109/TVCG.2006.16
   Soler M, 2018, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis.2018.00015
   Sridharamurthy R, 2020, IEEE T VIS COMPUT GR, V26, P1518, DOI 10.1109/TVCG.2018.2873612
   Takahashi S, 2004, GRAPH MODELS, V66, P24, DOI 10.1016/j.gmod.2003.08.002
   Tao DW, 2017, INT PARALL DISTRIB P, P1129, DOI 10.1109/IPDPS.2017.115
   Thomas DM, 2014, IEEE T VIS COMPUT GR, V20, P2427, DOI 10.1109/TVCG.2014.2346332
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P2035, DOI 10.1109/TVCG.2011.236
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2023, IEEE T VIS COMPUT GR, V29, P3489, DOI 10.1109/TVCG.2022.3163349
   Yan L, 2021, COMPUT GRAPH FORUM, V40, P599, DOI 10.1111/cgf.14331
   Zhang X., 2004, Technical report, P2
   Zhao K, 2021, PROC INT CONF DATA, P1643, DOI 10.1109/ICDE51399.2021.00145
   Zhenhuan Gong, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P239, DOI 10.1109/ICPP.2012.39
   ZSTD, ABOUT US
NR 68
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1302
EP 1312
DI 10.1109/TVCG.2023.3326920
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500003
PM 37930917
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Castelo, S
   Rulff, J
   McGowan, E
   Steers, B
   Wu, GD
   Chen, SY
   Roman, I
   Lopez, R
   Brewer, E
   Zhao, C
   Qian, J
   Cho, K
   He, H
   Sun, Q
   Vo, H
   Bello, J
   Krone, M
   Silva, C
AF Castelo, Sonia
   Rulff, Joao
   McGowan, Erin
   Steers, Bea
   Wu, Guande
   Chen, Shaoyu
   Roman, Iran
   Lopez, Roque
   Brewer, Ethan
   Zhao, Chen
   Qian, Jing
   Cho, Kyunghyun
   He, He
   Sun, Qi
   Vo, Huy
   Bello, Juan
   Krone, Michael
   Silva, Claudio
TI <i>ARGUS:</i> Visualization of AI-Assisted Task Guidance in AR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data Models; Image and Video Data; Temporal Data; Application Motivated
   Visualization; AR/VR/Immersive
ID VIDEO
AB The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.
C1 [Castelo, Sonia; Rulff, Joao; McGowan, Erin; Steers, Bea; Wu, Guande; Chen, Shaoyu; Roman, Iran; Lopez, Roque; Brewer, Ethan; Zhao, Chen; Qian, Jing; Cho, Kyunghyun; He, He; Sun, Qi; Vo, Huy; Bello, Juan; Krone, Michael; Silva, Claudio] NYU, New York, NY 10012 USA.
C3 New York University
RP Castelo, S (corresponding author), NYU, New York, NY 10012 USA.
EM s.castelo@nyu.edu; jlrulff@nyu.edu; erin.mcgowan@nyu.edu;
   bs3639@nyu.edu; guandewu@nyu.edu; sc6439@nyu.edu; irr2020@nyu.edu;
   rlopez@nyu.edu; ethan.brewer@nyu.edu; cz1285@nyu.edu; jq2267@nyu.edu;
   kyunghyun.cho@nyu.edu; hh2291@nyu.edu; qs2053@nyu.edu; huy.vo@nyu.edu;
   jpbello@nyu.edu; mk8949@nyu.edu; csilva@nyu.edu
RI Bello, Juan/HCH-3053-2022; Wu, Guande/JZE-5610-2024
OI Roman, Iran R./0000-0003-3781-7244; Chen, Shaoyu/0000-0002-1856-6294;
   Rulff, Joao/0000-0003-3341-7059; McGowan, Erin/0000-0002-7565-3052; Wu,
   Guande/0000-0002-9244-173X; Silva, Claudio/0000-0003-2452-2295; Bello,
   Juan Pablo/0000-0001-8561-5204; Lopez, Roque/0000-0003-3484-1783
FU DARPA
FX No Statement Available
CR Aigner W., 2011, HUMAN COMPUTER INTER, DOI DOI 10.1007/978-0-85729-079-3
   ARGUS, 2023, Augmented reality guidance and user-modeling system
   BAUM LE, 1966, ANN MATH STAT, V37, P1554, DOI 10.1214/aoms/1177699147
   Beams R, 2022, J DIGIT IMAGING, V35, P1409, DOI 10.1007/s10278-022-00622-x
   Becher M, 2022, IEEE COMPUT GRAPH, V42, P33, DOI 10.1109/MCG.2022.3157961
   Bohus D., 2021, CORR
   Bostock Michael., D3.js
   Bozkir E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255979
   Caudell T. P., 1991, Proceedings of the Twenty-Fifth Hawaii International Conference on System Sciences (Cat. No.91TH0394-7), P659, DOI 10.1109/HICSS.1992.183317
   DARPA, Perceptually-enabled task guidance (PTG)
   David-John B, 2021, IEEE T VIS COMPUT GR, V27, P2555, DOI 10.1109/TVCG.2021.3067787
   del Amo IF, 2018, PROCEDIA MANUF, V19, P148, DOI 10.1016/j.promfg.2018.01.021
   Duan Y, 2021, OPT COMMUN, V482, DOI 10.1016/j.optcom.2020.126567
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Felix C, 2018, IEEE T VIS COMPUT GR, V24, P657, DOI 10.1109/TVCG.2017.2746018
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Foxglove, Foxglove - Visualizing and debugging your robotics data, V3
   Funk M, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P185, DOI 10.1145/2700648.2809853
   Girdhar R, 2022, PROC CVPR IEEE, P16081, DOI 10.1109/CVPR52688.2022.01563
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Hsu CT, 2004, SIGNAL PROCESS-IMAGE, V19, P81, DOI 10.1016/j.image.2003.10.001
   Jiang T., 2020, Journal of Medical Internet Research, DOI [10.2196/168522, DOI 10.2196/168522]
   Kazakos E, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P855, DOI 10.1109/ICASSP39728.2021.9413376
   Kehrer J, 2013, IEEE T VIS COMPUT GR, V19, P495, DOI 10.1109/TVCG.2012.110
   Kim K, 2018, INT SYM MIX AUGMENT, P105, DOI 10.1109/ISMAR.2018.00039
   Lin A. S., 2020, P 58 ANN M ASS COMPU, P4871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.440, 10.18653/v1/2020.acl-main.440]
   Lin K. Qinghong, 2022, arXiv
   Liu C.-F., 2018, P 20 INT C HUMAN COM, P395, DOI [10.1145/3236112.3236174, DOI 10.1145/3236112.3236174]
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   M. O. Source, React
   Marriott Kim, 2018, Immersive Analytics, V11190, DOI DOI 10.1007/978-3-030-01388-2
   Microsoft, 2022, Using the windows device portal
   Microsoft, TypeScript
   Miknis M, 2015, INT CONF SYST SIGNAL, P153, DOI 10.1109/IWSSIP.2015.7314200
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   MIT Lincoln Laboratory, 2022, PTG evaluation tasks, V1
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nair V, 2023, Arxiv, DOI arXiv:2306.06459
   Nijholt A, 2022, LECT NOTES COMPUT SC, V13326, P304, DOI 10.1007/978-3-031-05431-0_21
   Pase S., 2012, P INT C E LEARNING E, P4
   Puladi B, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/34781
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramirez S., FastAPI
   Schmeil A, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P267, DOI 10.1109/VR.2007.352497
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Steedly D, 2005, IEEE I CONF COMP VIS, P1300
   Tang A., 2003, COMP EFFECTIVENESS A, P73
   three.js, about us
   Ungureanu D., CORR
   Xiao FY, 2020, Arxiv, DOI arXiv:2001.08740
   Xuetong Sun, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3365678
   Zhang JW, 2019, IEEE T VIS COMPUT GR, V25, P364, DOI 10.1109/TVCG.2018.2864499
   Zhang ZQ, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P520
   Zheng XJS, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2125, DOI 10.1145/2702123.2702305
   Zhou KY, 2022, Arxiv, DOI arXiv:2103.02503
   Zhou XY, 2022, LECT NOTES COMPUT SC, V13669, P350, DOI 10.1007/978-3-031-20077-9_21
NR 58
TC 3
Z9 3
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1313
EP 1323
DI 10.1109/TVCG.2023.3327396
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500061
PM 37917526
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lee, B
   Sedlmair, M
   Schmalstieg, D
AF Lee, Benjamin
   Sedlmair, Michael
   Schmalstieg, Dieter
TI Design Patterns for Situated Visualization in Augmented Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; immersive analytics; situated visualization; design
   patterns; design space
ID DEPTH
AB Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics. Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore. However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts. In this work, we leverage the richness of AR research and apply it to situated visualization. We derive design patterns which summarize common approaches of visualizing data in situ. The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise. We discuss design dimensions that help to describe both our patterns and previous work in the literature. This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world. We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows.
C1 [Lee, Benjamin; Sedlmair, Michael; Schmalstieg, Dieter] Univ Stuttgart, Stuttgart, Germany.
   [Schmalstieg, Dieter] Graz Univ Technol, Graz, Austria.
C3 University of Stuttgart; Graz University of Technology
RP Lee, B (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM benjamin.lee@visus.uni-stuttgart.de;
   michael.sedlmair@visus.uni-stuttgart.de; schmalstieg@tugraz.at
OI Schmalstieg, Dieter/0000-0003-2813-2235; Lee,
   Benjamin/0000-0002-1171-4741
FU German Research Foundation (DFG)
FX No Statement Available
CR Alves J, 2019, IEEE INT CONF AUTON, P168
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [10.1145/2501988.2502045, DOI 10.1145/2501988.2502045]
   Assor A., 2023, P CHI EA, P1, DOI DOI 10.1145/3544549.3583905
   Bach B., 2017, IEEE VIS WORKSH IMM
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Barakonyi I, 2005, LECT NOTES COMPUT SC, V3711, P345
   Belo J, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545651
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Bier E. A., 1993, Computer Graphics Proceedings, P73, DOI 10.1145/166117.166126
   Blattgerste J, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P133, DOI 10.1145/3197768.3197778
   Bork F, 2019, ANAT SCI EDUC, V12, P585, DOI 10.1002/ase.1864
   Bowman D. A., 2003, P ACM S VIRT REAL SO, P81, DOI [DOI 10.1145/1008653.1008669, 10.1145/1008653.1008669]
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Büttner S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376720
   Buschel Wolfgang, 2021, P 2021 CHI C HUM FAC, P1, DOI [DOI 10.1145/3411764.3445651, 10.1145/3411764.3445651]
   Cao YZ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P521, DOI 10.1145/3332165.3347902
   Card SK., 1999, READINGS INFORM VISU
   Chang Wilson M, 2005, Neurosurgery, V56, P434, DOI 10.1227/01.NEU.0000156551.66538.6A
   Chintamani K, 2010, IEEE T SYST MAN CY A, V40, P29, DOI 10.1109/TSMCA.2009.2030166
   Cook K.A., 2005, Technical Report
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Cruz E, 2019, VIRTUAL REAL-LONDON, V23, P281, DOI 10.1007/s10055-018-0338-3
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Dillman KR, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173714
   ElSayed NAM, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Ens Barrett., 2014, Proceedings of the 2nd ACM symposium on Spatial user interaction (SUI'14), P2, DOI DOI 10.1145/2659766.2659769
   Erick AO, 2020, 2020 INTERNATIONAL SAUPEC/ROBMECH/PRASA CONFERENCE, P190, DOI 10.1109/saupec/robmech/prasa48453.2020.9041002
   Feiner S. K., 1992, Visual Computer, V8, P292, DOI 10.1007/BF01897116
   Ferdous HS, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300464
   Fleck P, 2023, IEEE T VIS COMPUT GR, V29, P3281, DOI 10.1109/TVCG.2022.3157058
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grubert J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3933, DOI 10.1145/2702123.2702331
   Guarese R, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399838
   Hansen LH, 2021, IEEE T VIS COMPUT GR, V27, P4119, DOI 10.1109/TVCG.2021.3106479
   Heinrich F, 2020, IEEE T VIS COMPUT GR, V26, P3568, DOI 10.1109/TVCG.2020.3023637
   Henderson S. J., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P191, DOI 10.1109/ISMAR.2011.6092386
   Henderson S, 2011, IEEE T VIS COMPUT GR, V17, P1355, DOI 10.1109/TVCG.2010.245
   Herr D, 2018, PROC CIRP, V72, P1112, DOI 10.1016/j.procir.2018.03.200
   Hertel J, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P122, DOI 10.1109/VR50410.2021.00033
   Heyen F., 2022, P ISMIR
   Hoang T. N., 2010, P ISWC, P1, DOI [DOI 10.1109/ISWC.2010.5665865, 10.1109/ISWC.2010.5665865]
   Hou L, 2013, J COMPUT CIVIL ENG, V27, P439, DOI 10.1061/(ASCE)CP.1943-5487.0000184
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kalkofen Denis, 2007, P 6 IEEE ACM INT S M, P1, DOI [DOI 10.1109/ISMAR.2007.4538846, 10.1109/ISMAR.2007.4538846]
   Kawsar F, 2011, LECT NOTES COMPUT SC, V6696, P70, DOI 10.1007/978-3-642-21726-5_5
   Kohler Wolfgang, 1947, Gestalt psychology: An introduction to new concepts in modern psychology
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Ledermann F, 2005, P IEEE VIRT REAL ANN, P187
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lilija K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300676
   Loch F, 2016, INT CONF INTEL ENVIR, P147, DOI 10.1109/IE.2016.31
   Looser R., 2007, 6 IEEE ACM INTSYMP M, P51, DOI DOI 10.1109/ISMAR.2007.4538825
   Luo WZ, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580715
   Luo WZ, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501946
   Marriott Kim, 2018, Immersive Analytics, V11190, DOI DOI 10.1007/978-3-030-01388-2
   Mendez E., 2009, P VRST, P247, DOI [DOI 10.1145/1643928.1643988, 10.1145/1643928.1643988]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mohr P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300815
   Mohr P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6547, DOI 10.1145/3025453.3025688
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Mulloni A., 2011, P 13 INT C HUMAN COM, P211, DOI DOI 10.1145/2037373.2037406
   Munzner T., 2014, AK Peters Visualization Series
   Polys NF, 2011, INT J HUM-COMPUT ST, V69, P30, DOI 10.1016/j.ijhcs.2010.05.007
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Qian X, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517665
   Reipschläger P, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P29, DOI 10.1145/3343055.3359718
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Reitinger B, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208
   Reitmayr G., 2004, P IBS TELECARTOGRAPH
   Rekimoto J, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P63, DOI 10.1109/APCHI.1998.704151
   Ridel B, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611376
   Rigling S., 2023, P CHI EA, P1, DOI DOI 10.1145/3544549.3585912
   Roberts JC, 2007, CMV 2007: FIFTH INTERNATIONAL CONFERENCE ON COORDINATED & MULTIPLE VIEWS IN EXPLORATORY VISUALIZATION, PROCEEDINGS, P61, DOI 10.1109/CMV.2007.20
   Samset E, 2008, PROC SPIE, V6806, DOI 10.1117/12.784155
   Sandor C, 2009, INT SYM MIX AUGMENT, P211, DOI 10.1109/ISMAR.2009.5336461
   Sareika M., 2007, P ISMAR, P27, DOI DOI 10.1109/ISMAR.2007.4538821
   Satkowski M, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445330
   Satriadi KA, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580952
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Schall G, 2008, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2008.4637332
   Schall G, 2009, PERS UBIQUIT COMPUT, V13, P281, DOI 10.1007/s00779-008-0204-5
   Schmalstieg D, 1999, PRESENCE-VIRTUAL AUG, V8, P449, DOI 10.1162/105474699566332
   Schoenfelder R, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P83
   Shin S, 2024, IEEE T VIS COMPUT GR, V30, P5147, DOI 10.1109/TVCG.2023.3285546
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Skreinig LR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P386, DOI 10.1109/VRW55335.2022.00086
   Smiley Jim, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3488546
   Stanescu A, 2022, IEEE T VIS COMPUT GR, V28, P3821, DOI 10.1109/TVCG.2022.3203104
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Tainaka K, 2020, INT SYM MIX AUGMENT, P474, DOI 10.1109/ISMAR50242.2020.00077
   Tatzgern M., 2013, P JVRC EUR ASS DEC, P49, DOI DOI 10.2312/EGVE.JVRC13.049-056
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tong Wai, 2023, IEEE Trans Vis Comput Graph, V29, P418, DOI 10.1109/TVCG.2022.3209386
   Uratani K, 2005, P IEEE VIRT REAL ANN, P295
   Veas E, 2013, PERS UBIQUIT COMPUT, V17, P1515, DOI 10.1007/s00779-012-0597-z
   Veas E, 2012, IEEE T VIS COMPUT GR, V18, P565, DOI 10.1109/TVCG.2012.44
   Viega John, 1996, P 9 ANN ACM S USER I, P51, DOI DOI 10.1145/237091.237098
   Wagner D, 2005, LECT NOTES COMPUT SC, V3468, P208
   Werrlich S, 2018, INT SYM MIX AUGMENT, P134, DOI 10.1109/ISMAR.2018.00046
   White S. M., 2009, Interaction and Presentation Techniques for Situated Visualization
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Whitlock M, 2020, INT SYM MIX AUGMENT, P704, DOI 10.1109/ISMAR50242.2020.00101
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wither J, 2011, COMPUT GRAPH-UK, V35, P810, DOI 10.1016/j.cag.2011.04.010
   Wu LC, 2016, PROCEEDINGS I3D 2016: 20TH ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, P95, DOI 10.1145/2856400.2856416
   Yamaguchi Masahiro, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1010, DOI 10.1145/3379337.3415819
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
   Zheng MY, 2022, IEEE ACCESS, V10, P29543, DOI 10.1109/ACCESS.2022.3156697
   Zhu J, 2013, INT J ADV MANUF TECH, V66, P1699, DOI 10.1007/s00170-012-4451-2
   Zollmann S, 2014, IEEE T VIS COMPUT GR, V20, P560, DOI 10.1109/TVCG.2014.24
   Zollmann S, 2012, INT SYM MIX AUGMENT, P167, DOI 10.1109/ISMAR.2012.6402554
NR 124
TC 10
Z9 10
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1324
EP 1335
DI 10.1109/TVCG.2023.3327398
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500116
PM 37883275
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Assor, A
   Prouzeau, A
   Hachet, M
   Dragicevic, P
AF Assor, Ambre
   Prouzeau, Arnaud
   Hachet, Martin
   Dragicevic, Pierre
TI Handling Non-Visible Referents in Situated Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Taxonomy; Models; Frameworks; Theory; Mobile; AR/VR/Immersive;
   Specialized Input/Display Hardware
ID MIXED REALITY; TAXONOMY
AB Situated visualizations are a type of visualization where data is presented next to its physical referent (i.e., the physical object, space, or person it refers to), often using augmented-reality displays. While situated visualizations can be beneficial in various contexts and have received research attention, they are typically designed with the assumption that the physical referent is visible. However, in practice, a physical referent may be obscured by another object, such as a wall, or may be outside the user's visual field. In this paper, we propose a conceptual framework and a design space to help researchers and user interface designers handle non-visible referents in situated visualizations. We first provide an overview of techniques proposed in the past for dealing with non-visible objects in the areas of 3D user interfaces, 3D visualization, and mixed reality. From this overview, we derive a design space that applies to situated visualizations and employ it to examine various trade-offs, challenges, and opportunities for future research in this area.
C1 [Assor, Ambre; Prouzeau, Arnaud; Hachet, Martin; Dragicevic, Pierre] Univ Bordeaux, Inria, CNRS, Bordeaux, France.
C3 Inria; Universite de Bordeaux; Centre National de la Recherche
   Scientifique (CNRS)
RP Assor, A (corresponding author), Univ Bordeaux, Inria, CNRS, Bordeaux, France.
EM ambre.assor@inria.fr; arnaud.prouzeau@inria.fr; martin.hachet@inria.fr;
   pierre.dragicevic@inria.fr
RI Prouzeau, Arnaud/AAU-3378-2021; Dragicevic, Pierre/HKV-4981-2023
OI Prouzeau, Arnaud/0000-0003-3800-5870; Hachet,
   Martin/0000-0003-3889-2529; Assor, Ambre/0000-0003-3304-4459
FU Agence Nationale de la Recherche (ANR)
FX No Statement Available
CR Ajanki A, 2011, VIRTUAL REAL-LONDON, V15, P161, DOI 10.1007/s10055-010-0183-5
   Alce G, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P81, DOI 10.1109/ISMAR-Adjunct.2017.37
   Andújar C, 2004, COMPUT GRAPH FORUM, V23, P499, DOI 10.1111/j.1467-8659.2004.00781.x
   Andujar C, 2010, PRESENCE-TELEOP VIRT, V19, P499, DOI 10.1162/pres_a_00018
   Ardouin J., 2012, PROCVRST
   Arpaia P, 2021, IEEE SENS J, V21, P11176, DOI 10.1109/JSEN.2021.3059636
   Avery B., 2007, PROC ISMAR, DOI [10.1109/ISMAR.2007.4538869, DOI 10.1109/ISMAR.2007.4538869]
   Bane R, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P231, DOI 10.1109/ISMAR.2004.36
   Baudisch P., 2003, P SIGCHI C HUM FACT, P481, DOI 10.1145/642611.642695
   Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Bell B., 2002, P 15 ANN ACM S USER, P213
   Bichlmeier C, 2007, LECT NOTES COMPUT SC, V4791, P434
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Blanco R., 2019, IEEE VIS 2019
   Bluff A, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/33599973365682
   Bork F., 2019, PROC ISMAR, DOI [10.1109/ISMAR-Adjunct.2019.00-283, DOI 10.1109/ISMAR-ADJUNCT.2019.00-283]
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Boudell JA, 2019, APPL PLANT SCI, V7, DOI 10.1002/aps3.11311
   Bressa N, 2022, IEEE T VIS COMPUT GR, V28, P107, DOI 10.1109/TVCG.2021.3114835
   Caggianese Giuseppe, 2019, 2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS), P390, DOI 10.1109/SITIS.2019.00069
   Card M., 1999, Readings in information visualization: using vision to think, DOI [10.5555/3006797, DOI 10.5555/3006797]
   Chaturvedi I, 2019, PROCEEDINGS OF IUI 2019, P625, DOI 10.1145/3301275.3302263
   Chittaro L., 2003, PROC WEB 3D, DOI [10.1145/636593.636598, DOI 10.1145/636593.636598]
   Chittaro L., Proceedings of the Working Conference on Advanced Visual Interfaces, ser. AVI '04. New York, NY, USA: ACM, P267
   Coffey Dane., 2011, Symposium on Interactive 3D Graphics and Games, P191, DOI [DOI 10.1145/1944745.1944777, 10.1145/1944745, DOI 10.1145/1944745]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Danyluk K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445098
   Drey T., 2018, Data Visualisation using Augmented Reality with a Focus set on Head Mounted Displays and Collaborative Tasks
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Elvins T. T., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P21, DOI 10.1145/263407.263504
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Erat O, 2018, IEEE T VIS COMPUT GR, V24, P1437, DOI 10.1109/TVCG.2018.2794058
   Eren MT, 2018, VISUAL COMPUT, V34, P405, DOI 10.1007/s00371-016-1346-5
   Fan K., 2014, PROC AH, DOI [10.1145/2582051.2582100, DOI 10.1145/2582051.2582100]
   Fedosov A., 2014, PROC EICS
   Foyle D. C., 2005, PROC HCI INT
   Frey J., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P301, DOI [10.1145/2642918.2647368, DOI 10.1145/2642918.2647368]
   Fuchs H, 2014, COMPUTER, V47, P46, DOI 10.1109/MC.2014.185
   Ghosh S., 2015, PROC CHI
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Gruenefeld U., 2018, MobileHCI
   Gruenefeld U., 2018, PROC MOBILEHCI
   Gruenefeld U., 2018, MobileHCI, DOI [10.1145/3236112.3236115, DOI 10.1145/3236112.3236115]
   Gustafson S, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P787
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Hirose K, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P75
   Holstius D., 2004, Proceedings of the 5th conference on Designing interactive systems: processes, practices, methods, and techniques, P215, DOI DOI 10.1145/1013115.1013145
   Ilie A., 2004, Presence: Teleoperators and Virtual Environments, V13
   Ishiguro Yoshio., 2011, P 2 AUGMENTED HUMAN, P8, DOI DOI 10.1145/1959826.1959834
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Jo H, 2011, COMPUT GRAPH-UK, V35, P841, DOI 10.1016/j.cag.2011.04.005
   Johansen J.D., 2002, SIGNS USE INTRO SEMI
   Kalkofen D, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P71, DOI 10.1109/VR.2009.4811001
   Kantonen T, 2010, P IEEE VIRT REAL ANN, P179, DOI 10.1109/VR.2010.5444792
   Kristoffersson A, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/902316
   Kritzler M, 2017, IOT'17: PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS, P197, DOI 10.1145/3131542.3140274
   Kumaravel BT, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P161, DOI 10.1145/3332165.3347872
   Laaki H, 2019, IEEE ACCESS, V7, P20325, DOI 10.1109/ACCESS.2019.2897018
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   Livingston Mark A., 2013, Human Factors in Augmented Reality Environments, P67, DOI [10.1007/978-1-4614-4205-94, DOI 10.1007/978-1-4614-4205-94, DOI 10.1007/978-1-4614-4205-9_4]
   Lubos P, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927939
   Macedo L. F., 2021, IEEE TVCG
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Mercier-Ganady J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P33, DOI 10.1109/VR.2014.6802047
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Mizuno F., 2009, PROC IFMB
   Morais L, 2022, IEEE T VIS COMPUT GR, V28, P1661, DOI 10.1109/TVCG.2020.3023013
   Mori S., 2017, IPSJ Trans. Comput. Vis. Appl., V9, P1, DOI DOI 10.1186/S41074-017-0028-1
   Nam JW, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P747, DOI [10.1109/VR.2019.8797871, 10.1109/vr.2019.8797871]
   Pausch R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P399, DOI 10.1145/218380.218495
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Qiu C., 2019, Virtual Real. Intell. Hardw, V1, P597, DOI [10.1016/j.vrih.2019.10.002, DOI 10.1016/J.VRIH.2019.10.002]
   Ren D, 2016, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2016.7504692
   Satriadi K., 2023, CHI
   Satriadi KA, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517715
   Seo DW, 2016, COMPUT IND, V76, P11, DOI 10.1016/j.compind.2015.11.003
   Sherman W. R., 2003, Presence: Teleoperators & Virtual Environments, V12
   Siu T., 2013, PROC CHI
   Sousa M, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4057, DOI 10.1145/3025453.3025566
   Sukan M., 2014, PROCUIST
   Tachi S, 2003, ADV ROBOTICS, V17, P199, DOI 10.1163/156855303764018468
   Tachi S, 2011, IEEE INT C INT ROBOT, P157, DOI 10.1109/IROS.2011.6048151
   Tao F., 2019, Digital Twin Driven Smart Manufacturing
   Tatzgern M, 2015, PERVASIVE MOB COMPUT, V18, P55, DOI 10.1016/j.pmcj.2014.08.010
   Thomas BH, 2018, LECT NOTES COMPUT SC, V11190, P185, DOI 10.1007/978-3-030-01388-2_7
   Truman S., 2020, PROC FDG, V69, DOI [10.1145/3402942.34029943, DOI 10.1145/3402942.34029943]
   Vermeulen J, 2012, S VIS LANG HUM CEN C, P89, DOI 10.1109/VLHCC.2012.6344490
   Wang XY, 2014, COMPUT IND, V65, P314, DOI 10.1016/j.compind.2013.11.012
   White S, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P119, DOI 10.1109/TRIDUI.2006.1618281
   White S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1117
   Willett W., 2021, IEEE TVCG, V2021, DOI [10.1109/TVCG.2021.31148444,8,9, DOI 10.1109/TVCG.2021.31148444,8,9]
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wither J, 2009, COMPUT GRAPH-UK, V33, P679, DOI 10.1016/j.cag.2009.06.001
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
NR 97
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1336
EP 1346
DI 10.1109/TVCG.2023.3327361
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500014
PM 37878456
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, ZT
   Chiappalupi, D
   Lin, TC
   Yang, YL
   Beyer, J
   Pfister, H
AF Chen, Zhutian
   Chiappalupi, Daniele
   Lin, Tica
   Yang, Yalong
   Beyer, Johanna
   Pfister, Hanspeter
TI RL-L: A Deep Reinforcement Learning Approach Intended for AR Label
   Placement in Dynamic Scenarios
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Layout; Dynamics; Visualization;
   Optimization; Task analysis; Sports; Augmented Reality; Reinforcement
   Learning; Label Placement; Dynamic Scenarios
ID VISUALIZATIONS
AB Labels are widely used in augmented reality (AR) to display digital information. Ensuring the readability of AR labels requires placing them in an occlusion-free manner while keeping visual links legible, especially when multiple labels exist in the scene. Although existing optimization-based methods, such as force-based methods, are effective in managing AR labels in static scenarios, they often struggle in dynamic scenarios with constantly moving objects. This is due to their focus on generating layouts optimal for the current moment, neglecting future moments and leading to sub-optimal or unstable layouts over time. In this work, we present RL-Label, a deep reinforcement learning-based method intended for managing the placement of AR labels in scenarios involving moving objects. RL-Label considers both the current and predicted future states of objects and labels, such as positions and velocities, as well as the user's viewpoint, to make informed decisions about label placement. It balances the trade-offs between immediate and long-term objectives. We tested RL-Label in simulated AR scenarios on two real-world datasets, showing that it effectively learns the decision-making process for long-term optimization, outperforming two baselines (i.e., no view management and a force-based method) by minimizing label occlusions, line intersections, and label movement distance. Additionally, a user study involving 18 participants indicates that, within our simulated environment, RL-Label excels over the baselines in aiding users to identify, compare, and summarize data on labels in dynamic scenes.
C1 [Chen, Zhutian; Chiappalupi, Daniele; Lin, Tica; Beyer, Johanna; Pfister, Hanspeter] Harvard John A Paulson Sch Engn & Appl Sci, Boston, MA 02134 USA.
   [Chiappalupi, Daniele] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Yang, Yalong] Virginia Tech, Blacksburg, VA USA.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Virginia
   Polytechnic Institute & State University
RP Chen, ZT (corresponding author), Harvard John A Paulson Sch Engn & Appl Sci, Boston, MA 02134 USA.
EM ztchen@seas.harvard.edu; daniele.chiappalupi@inf.ethz.ch;
   mlin@g.harvard.edu; yalongyang@hotmail.com; johanna.m.beyer@gmail.com;
   pfister@seas.harvard.edu
OI Lin, Tica/0000-0002-2860-0871; Beyer, Johanna/0000-0002-3505-9171;
   Chiappalupi, Daniele/0000-0002-1026-4056; Yang,
   Yalong/0000-0001-9414-9911; Pfister, Hanspeter/0000-0002-3620-2582
FU NSF
FX No Statement Available
CR Ahn J., 1984, CARTOGRAPHICA, V21, P101, DOI DOI 10.1142/S0218001487000096
   Azuma R, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P66, DOI 10.1109/ISMAR.2003.1240689
   Bekos MA, 2019, COMPUT GRAPH FORUM, V38, P833, DOI 10.1111/cgf.13729
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Chen CG, 2019, IEEE INT CONF ROBOT, P6015, DOI [10.1109/ICRA.2019.8794134, 10.1109/icra.2019.8794134]
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen ZT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376436
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Dewey D., 2014, AAAI SPRING S
   Fender A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173843
   Fender A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P611, DOI 10.1145/3126594.3126621
   Gebhardt C, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P197, DOI 10.1145/3332165.3347933
   Grasset R, 2012, INT SYM MIX AUGMENT, P177, DOI 10.1109/ISMAR.2012.6402555
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Haarnoja Tuomas, 2018, P MACHINE LEARNING R, V80
   Hegde S, 2020, IEEE WINT CONF APPL, P1110, DOI 10.1109/WACV45572.2020.9093587
   Huang GP, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445283
   Jaakkola T., 1994, ADV NEURAL INF PROCE, V7, P345, DOI DOI 10.5555/2998687.2998730
   Juliani A, 2020, Arxiv, DOI [arXiv:1809.02627, 10.48550/ARXIV.1809.02627]
   Kiran BR, 2022, IEEE T INTELL TRANSP, V23, P4909, DOI 10.1109/TITS.2021.3054625
   Köppel T, 2021, IEEE PAC VIS SYMP, P91, DOI 10.1109/PacificVis52677.2021.00020
   Lerner A, 2007, COMPUT GRAPH FORUM, V26, P655, DOI 10.1111/j.1467-8659.2007.01089.x
   Lillicrap T.P., 2015, arXiv
   Lin T., 2021, P ACM C HUM FACT COM, P13, DOI [DOI 10.1145/3411764.34456492, 10.1145/3411764.34456492,9, DOI 10.1145/3411764.34456492,9, 10.1145/3411764.3445649, DOI 10.1145/3411764.3445649]
   Lin TC, 2022, Arxiv, DOI [arXiv:2209.00202, 10.48550/arXiv.2209.00202]
   Lin TC, 2023, IEEE T VIS COMPUT GR, V29, P1831, DOI 10.1109/TVCG.2021.3133511
   Lindlbauer D, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P147, DOI 10.1145/3332165.3347945
   Liu RR, 2021, ROBOTICS, V10, DOI 10.3390/robotics10010022
   Madsen JB, 2016, IEEE T VIS COMPUT GR, V22, P1415, DOI 10.1109/TVCG.2016.2518318
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   N. O. Service, What is lidar?
   Narvekar S, 2020, Arxiv, DOI arXiv:2003.04960
   Nuernberger B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1233, DOI 10.1145/2858036.2858250
   Ouyang L, 2022, ADV NEUR IN
   Paszke A, Pytorch: An imperative style, high-performance deep learning library
   Qian X, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517665
   Rakholia N, 2018, IEEE IMAGE PROC, P604, DOI 10.1109/ICIP.2018.8451052
   Esmaeeli MS, 2022, Arxiv, DOI arXiv:2209.08480
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438, DOI 10.48550/ARXIV.1506.02438]
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Shao K, 2019, Arxiv, DOI [arXiv:1912.10944, 10.48550/arXiv.1912.10944]
   SportVU, Papers with code - nba sportvu dataset
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tahara T, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P249, DOI 10.1109/ISMAR-Adjunct51615.2020.00072
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tatzgern M, 2016, P IEEE VIRT REAL ANN, P83, DOI 10.1109/VR.2016.7504691
   Tatzgern M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P27, DOI 10.1109/VR.2014.6802046
   Tong Wai, 2023, IEEE Trans Vis Comput Graph, V29, P418, DOI 10.1109/TVCG.2022.3209386
   Vemula A, 2018, IEEE INT CONF ROBOT, P4601
   Wu AY, 2021, IEEE T VIS COMPUT GR, V27, P464, DOI 10.1109/TVCG.2020.3030423
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yifei Cheng, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P282, DOI 10.1145/3472749.3474750
   Yu Fan Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P285, DOI 10.1109/ICRA.2017.7989037
   Zhou MY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2389, DOI 10.1145/3447548.3467279
   Zhu YK, 2017, INT CONF ACOUST SPEE, P5335, DOI 10.1109/ICASSP.2017.7953175
NR 58
TC 2
Z9 2
U1 2
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1347
EP 1357
DI 10.1109/TVCG.2023.3326568
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500134
PM 37871050
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Magri, VAP
   Lindstrom, P
AF Magri, Victor A. P.
   Lindstrom, Peter
TI A General Framework for Progressive Data Compression and Retrieval
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lossy to lossless compression; progressive precision; multi-component
   expansion; floating-point data
ID EFFICIENT; PRECISION; SIMULATION; REDUCTION; MODEL
AB In scientific simulations, observations, and experiments, the transfer of data to and from disk and across networks has become a major bottleneck for data analysis and visualization. Compression techniques have been employed to tackle this challenge, but traditional lossy methods often demand conservative error tolerances to meet the numerical accuracy requirements of both anticipated and unknown data analysis tasks. Progressive data compression and retrieval has emerged as a promising solution, where each analysis task dictates its own accuracy needs. However, few analysis algorithms inherently support progressive data processing, and adapting compression techniques, file formats, client/server frameworks, and APIs to support progressivity can be challenging. This paper presents a framework that enables progressive-precision data queries for any data compressor or numerical representation. Our strategy hinges on a multi-component representation that successively reduces the error between the original and compressed field, allowing each field in the progressive sequence to be expressed as a partial sum of components. We have implemented this approach with four established scientific data compressors and assessed its effectiveness using real-world data sets from the SDRBench collection. The results show that our framework competes in accuracy with the standalone compressors it is based upon. Additionally, (de)compression time is proportional to the number of components requested by the user. Finally, our framework allows for fully lossless compression using lossy compressors when a sufficient number of components are employed.
C1 [Magri, Victor A. P.; Lindstrom, Peter] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
C3 United States Department of Energy (DOE); Lawrence Livermore National
   Laboratory
RP Magri, VAP (corresponding author), Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
EM paludettomag1@llnl.gov; pl@llnl.gov
OI Lindstrom, Peter/0000-0003-3817-4199
FU U.S. Department of Energy by Lawrence Livermore National Laboratory
   under Contract
FX No Statement Available
CR Ainsworth M, 2019, SIAM J SCI COMPUT, V41, pA2146, DOI [10.1137/18M1166651, 10.1137/18M1208885]
   Antcheva I, 2009, COMPUT PHYS COMMUN, V180, P2499, DOI 10.1016/j.cpc.2009.08.005
   Ballard G, 2020, ACM T MATH SOFTWARE, V46, DOI 10.1145/3378445
   Ballester-Ripoll R, 2020, IEEE T VIS COMPUT GR, V26, P2891, DOI 10.1109/TVCG.2019.2904063
   Barbarioli Bruno, 2023, Proceedings of the ACM on Management of Data, V1, DOI 10.1145/3588953
   Bhatia H, 2022, IEEE T VIS COMPUT GR, V28, P2350, DOI 10.1109/TVCG.2022.3165392
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen JY, 2021, INT PARALL DISTRIB P, P859, DOI 10.1109/IPDPS49936.2021.00095
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Clyne J., 2012, High Performance Visualization, P145, DOI DOI 10.1201/B12985-191
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P305, DOI 10.1109/TVCG.2009.105
   DEKKER TJ, 1971, NUMER MATH, V18, P224, DOI 10.1007/BF01397083
   Diffenderfer J, 2019, SIAM J SCI COMPUT, V41, pA1867, DOI 10.1137/18M1168832
   Hoang D, 2019, IEEE T VIS COMPUT GR, V25, P1193, DOI 10.1109/TVCG.2018.2864853
   Eyring V, 2016, GEOSCI MODEL DEV, V9, P1937, DOI 10.5194/gmd-9-1937-2016
   Folk M., 2011, P EDBT ICDT 2011 WOR, P36, DOI DOI 10.1145/1966895.1966900
   Fout N, 2007, IEEE T VIS COMPUT GR, V13, P1600, DOI 10.1109/TVCG.2007.70516
   Godoy WF, 2020, SOFTWAREX, V12, DOI 10.1016/j.softx.2020.100561
   Gong Q., 2022, INT C SCI STAT DATAB, DOI DOI 10.1145/3538712.3538717
   Graham J, 2016, J TURBUL, V17, P181, DOI 10.1080/14685248.2015.1088656
   Grout RW, 2012, J FLUID MECH, V706, P351, DOI 10.1017/jfm.2012.257
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Guthe S., 2016, P C VIS MOD VIS OCT, P77, DOI DOI 10.2312/VMV.20161345
   Hida Y, 2001, P S COMP ARITHM, P155, DOI 10.1109/ARITH.2001.930115
   Hoang D, 2021, IEEE T VIS COMPUT GR, V27, P603, DOI 10.1109/TVCG.2020.3030381
   Hong ES, 2001, CONF REC ASILOMAR C, P769, DOI 10.1109/ACSSC.2001.987028
   Ivezie Zeljko, 2019, The Astrophysical Journal, V873, P1, DOI DOI 10.3847/1538-4357/AB042C1
   Kay JE, 2015, B AM METEOROL SOC, V96, P1333, DOI 10.1175/BAMS-D-13-00255.1
   Li S, 2018, COMPUT GRAPH FORUM, V37, P422, DOI 10.1111/cgf.13336
   Li SM, 2023, INT PARALL DISTRIB P, P1007, DOI 10.1109/IPDPS54959.2023.00104
   Li SM, 2019, ATMOSPHERE-BASEL, V10, DOI 10.3390/atmos10090488
   Liang X, 2023, IEEE T BIG DATA, V9, P485, DOI 10.1109/TBDATA.2022.3201176
   Liang X, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476179
   Lindstrom P, 2022, LECT NOTES COMPUT SC, V13253, P66, DOI 10.1007/978-3-031-09779-9_5
   Lindstrom P, 2006, IEEE T VIS COMPUT GR, V12, P1245, DOI 10.1109/TVCG.2006.143
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   NING P, 1992, P 1992 WORKSH VOL VI, P69, DOI [10.1145/147130.147152, DOI 10.1145/147130.147152]
   Noordsij L, 2020, EUROMICRO WORKSHOP P, P245, DOI 10.1109/PDP50117.2020.00045
   Pascucci V., 2001, ACMIEEE C SUPERCOMPU, P1, DOI DOI 10.1145/582034.5820362
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Peters AJ, 2011, J PHYS CONF SER, V331, DOI 10.1088/1742-6596/331/5/052015
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sauer T., 2018, Numerical Analysis, V8
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Shadden SC, 2005, PHYSICA D, V212, P271, DOI 10.1016/j.physd.2005.10.007
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Shewchuk JR, 1997, DISCRETE COMPUT GEOM, V18, P305, DOI 10.1007/PL00009321
   Tian JN, 2020, INT CONFER PARA, P3, DOI 10.1145/3410463.3414624
   Wilkinson J. H., 1963, Rounding Errors in Algebraic Processes, DOI DOI 10.1137/1.9781611977523
   Zhang JL, 2019, IEEE S MASS STOR SYS, P79, DOI 10.1109/MSST.2019.00-14
   Zhao K, 2020, IEEE INT CONF BIG DA, P2716, DOI 10.1109/BigData50022.2020.9378449
NR 53
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1358
EP 1368
DI 10.1109/TVCG.2023.3327186
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500031
PM 37922179
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Pan, B
   Lu, JY
   Li, HX
   Chen, WF
   Wang, YY
   Zhu, MF
   Yu, CH
   Chen, W
AF Pan, Bo
   Lu, Jiaying
   Li, Haoxuan
   Chen, Weifeng
   Wang, Yiyao
   Zhu, Minfeng
   Yu, Chenhao
   Chen, Wei
TI Differentiable Design Galleries: A Differentiable Approach to Explore
   the Design Space of Transfer Functions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Transfer function; direct volume rendering; deep learning; generative
   models; differentiable rendering
ID HISTOGRAMS
AB The transfer function is crucial for direct volume rendering (DVR) to create an informative visual representation of volumetric data. However, manually adjusting the transfer function to achieve the desired DVR result can be time-consuming and unintuitive. In this paper, we propose Differentiable Design Galleries, an image-based transfer function design approach to help users explore the design space of transfer functions by taking advantage of the recent advances in deep learning and differentiable rendering. Specifically, we leverage neural rendering to learn a latent design space, which is a continuous manifold representing various types of implicit transfer functions. We further provide a set of interactive tools to support intuitive query, navigation, and modification to obtain the target design, which is represented as a neural-rendered design exemplar. The explicit transfer function can be reconstructed from the target design with a differentiable direct volume renderer. Experimental results on real volumetric data demonstrate the effectiveness of our method.
C1 [Pan, Bo; Lu, Jiaying; Li, Haoxuan; Wang, Yiyao; Yu, Chenhao; Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Minist Educ, Lab Art & Archaeol Image, Hangzhou, Peoples R China.
   [Chen, Weifeng] Zhejiang Univ Finance & Econ, Hangzhou, Peoples R China.
   [Zhu, Minfeng] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University of Finance
   & Economics; Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.; Chen, W (corresponding author), Zhejiang Univ, Minist Educ, Lab Art & Archaeol Image, Hangzhou, Peoples R China.; Chen, WF (corresponding author), Zhejiang Univ Finance & Econ, Hangzhou, Peoples R China.
EM bopan@zju.edu.cn; jiangyinglu@zju.edu.cn; lihaoxuan@zju.edu.cn;
   cwf818@zufe.edu.cn; wangyiyao@zju.edu.cn; minfeng_zhu@zju.edu.cn;
   ych20@zju.edu.cn; chenvis@zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Zhu, Minfeng/R-6788-2019
OI Chen, Wei/0000-0002-8365-4741; Lu, Jiaying/0009-0008-3578-346X; Zhu,
   Minfeng/0000-0002-6711-3099
FU National Natural Science Foundation of China
FX No Statement Available
CR Berger M, 2019, IEEE T VIS COMPUT GR, V25, P1636, DOI 10.1109/TVCG.2018.2816059
   Correa CD, 2008, IEEE T VIS COMPUT GR, V14, P1380, DOI 10.1109/TVCG.2008.162
   Correa CD, 2011, IEEE T VIS COMPUT GR, V17, P192, DOI 10.1109/TVCG.2010.35
   Correa CD, 2009, IEEE T VIS COMPUT GR, V15, P1465, DOI 10.1109/TVCG.2009.189
   Dupont E, 2018, ADV NEUR IN, V31
   Engel K., 2006, Real-Time Volume Graphics, DOI [10.1201/b106291, DOI 10.1201/B106291]
   Glorot X., 2010, P 13 INT C ART INT S, P249
   Goodfellow L. J., 2014, Generative Adversarial Networks
   Guo HQ, 2014, IEEE PAC VIS SYMP, P262, DOI 10.1109/PacificVis.2014.24
   Guo HQ, 2011, IEEE T VIS COMPUT GR, V17, P2106, DOI 10.1109/TVCG.2011.261
   Haidacher Martin., 2008, P EUROGRAPHICS WORKS, P101, DOI [DOI 10.2312/VCBM/VCBM08/101-108, 10.2312/VCBM/VCBM08/101-108]
   He TS, 1996, IEEE VISUAL, P227, DOI 10.1109/VISUAL.1996.568113
   He WB, 2020, IEEE T VIS COMPUT GR, V26, P23, DOI 10.1109/TVCG.2019.2934312
   Hong F, 2019, IEEE PAC VIS SYMP, P282, DOI 10.1109/PacificVis.2019.00041
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jönsson D, 2016, IEEE T VIS COMPUT GR, V22, P896, DOI 10.1109/TVCG.2015.2467294
   Kato H, 2020, Arxiv, DOI arXiv:2006.12057
   Kindlmann G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P513, DOI 10.1109/VISUAL.2003.1250414
   Kindlmann G, 1998, IEEE SYMPOSIUM ON VOLUME VISUALIZATION, P79, DOI 10.1109/SVV.1998.729588
   Kingma D.P., 2014, P INT C LEARNING REP
   Kniss J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P497, DOI 10.1109/VISUAL.2003.1250412
   Kniss J, 2002, IEEE T VIS COMPUT GR, V8, P270, DOI 10.1109/TVCG.2002.1021579
   Kniss JM, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P287
   Kwan-Liu Ma, 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P81, DOI 10.1109/VISUAL.1999.809871
   Ljung P, 2016, COMPUT GRAPH FORUM, V35, P669, DOI 10.1111/cgf.12934
   Lundström C, 2006, IEEE T VIS COMPUT GR, V12, P1570, DOI 10.1109/TVCG.2006.100
   Maciejewski R, 2009, IEEE T VIS COMPUT GR, V15, P1473, DOI 10.1109/TVCG.2009.185
   Marks J., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P389, DOI 10.1145/258734.258887
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pfister H, 2001, IEEE COMPUT GRAPH, V21, P16, DOI 10.1109/38.920623
   Pinto FD, 2008, COMPUT GRAPH-UK, V32, P420, DOI 10.1016/j.cag.2008.04.004
   Pinto Franciscode Moura., 2007, Eurographics IEEE-VGTC Symposium on Visualization, P131
   Prauchner JL, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P265
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salama CR, 2006, IEEE T VIS COMPUT GR, V12, P1021, DOI 10.1109/TVCG.2006.148
   Shen YJ, 2021, PROC CVPR IEEE, P1532, DOI 10.1109/CVPR46437.2021.00158
   Tzeng F.-Y., 2004, A cluster-space visual interface for arbitrary dimensional classification of volume data, P338, DOI [10.2312/VisSym/VisSym04/017-0242, DOI 10.2312/VISSYM/VISSYM04/017-0242]
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang CL, 2023, IEEE T VIS COMPUT GR, V29, P3714, DOI 10.1109/TVCG.2022.3167896
   Wang YH, 2012, COMPUT GRAPH FORUM, V31, P1295, DOI 10.1111/j.1467-8659.2012.03122.x
   Wang YH, 2011, IEEE T VIS COMPUT GR, V17, P1560, DOI 10.1109/TVCG.2011.97
   Weiss J., 2021, arXiv, DOI 10.48550/arXiv.2106.05429
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P562, DOI 10.1109/TVCG.2021.3114769
   Weiss S, 2022, IEEE T VIS COMPUT GR, V28, P2654, DOI 10.1109/TVCG.2020.3039340
   Weiss S, 2021, IEEE T VIS COMPUT GR, V27, P3064, DOI 10.1109/TVCG.2019.2956697
   Wong H.-C., 2009, P INT C INFORM COMMU, P1, DOI [10.1109/ICICS.2009.5397587, DOI 10.1109/ICICS.2009.5397587]
   Wu YC, 2007, IEEE T VIS COMPUT GR, V13, P1027, DOI 10.1109/TVCG.2007.1051
NR 50
TC 2
Z9 2
U1 3
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1369
EP 1379
DI 10.1109/TVCG.2023.3327371
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500071
PM 37878449
DA 2024-11-06
ER

PT J
AU Herzberger, L
   Hadwiger, M
   Krüger, R
   Sorger, P
   Pfister, H
   Gröller, E
   Beyer, J
AF Herzberger, Lukas
   Hadwiger, Markus
   Krueger, Robert
   Sorger, Peter
   Pfister, Hanspeter
   Groeller, Eduard
   Beyer, Johanna
TI Residency Octree: A Hybrid Approach for Scalable Web-Based Multi-Volume
   Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volume rendering; ray-guided rendering; large-scale data; out-of-core
   rendering; multi-resolution; multi-channel; web-based visualization
ID OF-THE-ART; EXPLORATION
AB We present a hybrid multi-volume rendering approach based on a novel Residency Octree that combines the advantages of out-of-core volume rendering using page tables with those of standard octrees. Octree approaches work by performing hierarchical tree traversal. However, in octree volume rendering, tree traversal and the selection of data resolution are intrinsically coupled. This makes fine-grained empty-space skipping costly. Page tables, on the other hand, allow access to any cached brick from any resolution. However, they do not offer a clear and efficient strategy for substituting missing high-resolution data with lower-resolution data. We enable flexible mixed-resolution out-of-core multi-volume rendering by decoupling the cache residency of multi-resolution data from a resolution-independent spatial subdivision determined by the tree. Instead of one-to-one node-to-brick correspondences, each residency octree node is mapped to a set of bricks from different resolution levels. This makes it possible to efficiently and adaptively choose and mix resolutions, adapt sampling rates, and compensate for cache misses. At the same time, residency octrees support fine-grained empty-space skipping, independent of the data subdivision used for caching. Finally, to facilitate collaboration and outreach, and to eliminate local data storage, our implementation is a web-based, pure client-side renderer using WebGPU and WebAssembly. Our method is faster than prior approaches and efficient for many data channels with a flexible and adaptive choice of data resolution.
C1 [Herzberger, Lukas; Groeller, Eduard] TU Wien, Vienna, Austria.
   [Hadwiger, Markus] King Abdullah Univ Sci & Technol KAUST, Thuwal, Saudi Arabia.
   [Krueger, Robert; Pfister, Hanspeter; Beyer, Johanna] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA USA.
   [Krueger, Robert; Sorger, Peter] Harvard Med Sch, Cambridge, MA USA.
C3 Technische Universitat Wien; King Abdullah University of Science &
   Technology; Harvard University
RP Herzberger, L (corresponding author), TU Wien, Vienna, Austria.
EM herzberger@cg.tuwien.ac.at; markus.hadwiger@kaust.edu.sa;
   robert_krueger@hms.harvard.edu; peter_sorger@hms.harvard.edu;
   pfister@seas.harvard.edu; groeller@cg.tuwien.ac.at; jbeyer@g.harvard.edu
RI Sorger, Peter/IQW-7622-2023; Herzberger, Lukas/HOA-6306-2023
OI Pfister, Hanspeter/0000-0002-3620-2582; Beyer,
   Johanna/0000-0002-3505-9171; Herzberger, Lukas/0000-0002-9047-065X;
   Krueger, Robert/0000-0002-6468-8356; Sorger, Peter/0000-0002-3364-1838
FU NCI
FX No Statement Available
CR Adochiei FC, 2019, INT SYMP ADV TOP, DOI 10.1109/atee.2019.8724963
   Arbelaiz A, 2019, PROCEEDINGS WEB3D 2019: THE 24TH INTERNATIONAL ACM CONFERENCE ON 3D WEB TECHNOLOGY, DOI 10.1145/3329714.3338131
   Beyer J., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P127, DOI 10.1109/LDAV.2011.6092332
   Beyer J, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12605
   Brix T., 2014, arXiv
   Childs H., 2012, HIGH PERFORMANCE VIS, P357
   Congote J., 2011, P 16 INT C 3D WEB TE, P137, DOI DOI 10.1145/2010425.2010449
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Deakin L, 2019, SA'19: SIGGRAPH ASIA 2019 TECHNICAL BRIEFS, P25, DOI 10.1145/3355088.3365164
   Deakin LJ, 2020, COMPUT VIS MEDIA, V6, P53, DOI 10.1007/s41095-019-0155-y
   Díaz-García J, 2018, COMPUT GRAPH-UK, V73, P1, DOI 10.1016/j.cag.2018.02.007
   Drees D, 2022, Arxiv, DOI arXiv:2207.12746
   Eisemann E., 2009, P 2009 S INT 3D GRAP, P15, DOI [10.1145/1507149.1507152, DOI 10.1145/1507149.1507152]
   Faludi B., 2022, P C HIGH PERF GRAPH, P1, DOI [10.2312/hpg.20211279, DOI 10.2312/HPG.20211279]
   Fernandes IB, 2020, SIBGRAPI, P39, DOI 10.1109/SIBGRAPI51738.2020.00014
   Fogal Thomas, 2013, Proc IEEE Symp Large Scale Data Anal Vis, V2013, P43, DOI 10.1109/LDAV.2013.6675157
   Google, 2022, Neuroglancer: WebGL-Based Viewer for Volumetric Data
   Hadwiger M, 2018, IEEE T VIS COMPUT GR, V24, P974, DOI 10.1109/TVCG.2017.2744238
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Hatcher P., 2010, P C HIGH PERF GRAPH, P57, DOI DOI 10.2312/EGGH/HPG10/057-066
   Jessup J, 2022, IEEE T VIS COMPUT GR, V28, P259, DOI 10.1109/TVCG.2021.3114786
   Krueger R, 2020, IEEE T VIS COMPUT GR, V26, P227, DOI 10.1109/TVCG.2019.2934547
   Krüger J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P287, DOI 10.1109/VISUAL.2003.1250384
   Lin JR, 2023, CELL, V186, P363, DOI 10.1016/j.cell.2022.12.028
   Lin JR, 2018, ELIFE, V7, DOI 10.7554/eLife.31657
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Liu BQ, 2013, IEEE T VIS COMPUT GR, V19, P1732, DOI 10.1109/TVCG.2012.151
   Manz T, 2022, NAT METHODS, V19, P515, DOI 10.1038/s41592-022-01482-7
   Marton F, 2019, COMPUT GRAPH FORUM, V38, P53, DOI 10.1111/cgf.13671
   Maxfield M., 2023, W3C Working Draft
   Mobeen MM, 2012, IEEE I C EMBED SOFTW, P381, DOI 10.1109/HPCC.2012.58
   Moore J, 2021, NAT METHODS, V18, P1496, DOI 10.1038/s41592-021-01326-w
   Mwalongo F., 2018, P C VIS MOD VIS EG V, P147, DOI [10.2312/vmv.201812641,3, DOI 10.2312/VMV.201812641,3]
   Nirmal A. J., Cancer Discovery, V12
   Nystad Jorn, 2012, P C HIGH PERF GRAPH, P105
   Qiao L, 2017, INT J TELEMED APPL, V2017, DOI 10.1155/2017/4074137
   Raji M, 2017, SYMP LARG DATA ANAL, P45, DOI 10.1109/LDAV.2017.8231850
   Rashid R, 2022, NAT BIOMED ENG, V6, P515, DOI 10.1038/s41551-021-00789-8
   Rodríguez MB, 2014, COMPUT GRAPH FORUM, V33, P77, DOI 10.1111/cgf.12280
   Rossberg A., 2019, Technical report
   Sarton J, 2020, LECT NOTES COMPUT SC, V11887, P623, DOI 10.1007/978-3-030-34356-9_47
   Sarton J, 2020, IEEE T VIS COMPUT GR, V26, P3008, DOI 10.1109/TVCG.2019.2912752
   Schneider J, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P293, DOI 10.1109/VISUAL.2003.1250385
   Schubert N, 2011, COMPUT SCI-RES DEV, V26, P39, DOI 10.1007/s00450-010-0141-1
   Usher W, 2020, SYMP LARG DATA ANAL, P27, DOI 10.1109/LDAV51489.2020.00010
   Wang JM, 2021, J VISUAL-JAPAN, V24, P531, DOI 10.1007/s12650-020-00719-x
   Wangkaoom K., 2015, P 12 INT C ELECT ENG, P1, DOI [DOI 10.1109/ECTICON.2015.72070911,3, 10.1109/ECTICon.2015.72070911,3]
   Xue J, 2019, IEEE INT CONF MULTI, P599, DOI 10.1109/ICMEW.2019.00109
   Yang Y, 2015, WEB3D 2015, P65, DOI 10.1145/2775292.2775323
   Zellmann S., 2018, P S PAR GRAPH VIS EG, V2, P3
   Zellmann S., 2019, P IEEE C VIS 2019 OC, P1, DOI [10.1109/VISUAL.2019.89336312,3, DOI 10.1109/VISUAL.2019.89336312,3]
   Zellmann S, 2021, IEEE T VIS COMPUT GR, V27, P1904, DOI 10.1109/TVCG.2019.2938957
   Zellmann S, 2019, IEEE PAC VIS SYMP, P222, DOI 10.1109/PacificVis.2019.00033
NR 53
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1380
EP 1390
DI 10.1109/TVCG.2023.3327193
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500001
PM 37889813
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Lei, F
   Ma, YX
   Fotheringham, AS
   Mack, EA
   Li, ZQ
   Sachdeva, M
   Bardin, S
   Maciejewski, R
AF Lei, Fan
   Ma, Yuxin
   Fotheringham, A. Stewart
   Mack, Elizabeth A.
   Li, Ziqi
   Sachdeva, Mehak
   Bardin, Sarah
   Maciejewski, Ross
TI GeoExplainer: A Visual Analytics Framework for Spatial Modeling
   Contextualization and Report Generation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatial data analysis; local models; multiscale geographically weighted
   regression; model explanation; visual analytics
ID GEOGRAPHICALLY WEIGHTED REGRESSION; VISUALIZATION; EXPLORATION;
   PREDICTION; STORIES; TIME
AB Geographic regression models of various descriptions are often applied to identify patterns and anomalies in the determinants of spatially distributed observations. These types of analyses focus on answering why questions about underlying spatial phenomena, e.g., why is crime higher in this locale, why do children in one school district outperform those in another, etc.? Answers to these questions require explanations of the model structure, the choice of parameters, and contextualization of the findings with respect to their geographic context. This is particularly true for local forms of regression models which are focused on the role of locational context in determining human behavior. In this paper, we present GeoExplainer, a visual analytics framework designed to support analysts in creating explanative documentation that summarizes and contextualizes their spatial analyses. As analysts create their spatial models, our framework flags potential issues with model parameter selections, utilizes template-based text generation to summarize model outputs, and links with external knowledge repositories to provide annotations that help to explain the model results. As analysts explore the model results, all visualizations and annotations can be captured in an interactive report generation widget. We demonstrate our framework using a case study modeling the determinants of voting in the 2016 US Presidential Election.
C1 [Lei, Fan; Fotheringham, A. Stewart; Sachdeva, Mehak; Bardin, Sarah; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Ma, Yuxin] Southern Univ Sci & Technol, Shenzhen, Guangdong, Peoples R China.
   [Mack, Elizabeth A.] Michigan State Univ, E Lansing, MI USA.
   [Li, Ziqi] Florida State Univ, Tallahassee, FL 32306 USA.
C3 Arizona State University; Arizona State University-Tempe; Southern
   University of Science & Technology; Michigan State University; State
   University System of Florida; Florida State University
RP Ma, YX (corresponding author), Southern Univ Sci & Technol, Shenzhen, Guangdong, Peoples R China.
EM flei5@asu.edu; mayx@sustech.edu.cn; sfotheri@asu.edu; emack@msu.edu;
   liziqi1992@gmail.com; msachde1@asu.edu; sfbardin@asu.edu;
   rmacieje@asu.edu
RI Ma, Yuxin/AAJ-4486-2020; Fotheringham, Alexander/JOZ-4918-2023; Li,
   Ziqi/L-4326-2014; Lei, Fan/KFB-0896-2024
OI Lei, Fan/0000-0003-4244-0971
FU National Science Foundation
FX No Statement Available
CR Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   Anselin L., 1996, Regional Research Institute Working Papers, V200, P3
   Behera S, 2018, INT CONF UBIQ FUTUR, P448, DOI 10.1109/ICUFN.2018.8437001
   Bertini E., 2009, P ACM SIGKDD WORKSHO, P12, DOI DOI 10.1145/1562849.15628512
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brock AM, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P1, DOI 10.1145/3152832.3152833
   Brunsdon C, 1996, GEOGR ANAL, V28, P281, DOI 10.1111/j.1538-4632.1996.tb00936.x
   Burnham KP, 2004, SOCIOL METHOD RES, V33, P261, DOI 10.1177/0049124104268644
   Chen J., 2010, Extended Abstr. Hum. Factors Comput. Syst., P3703
   Chen SM, 2020, IEEE T VIS COMPUT GR, V26, P2499, DOI 10.1109/TVCG.2018.2889054
   Choudhry A, 2021, IEEE T VIS COMPUT GR, V27, P1332, DOI 10.1109/TVCG.2020.3030358
   Cook RD, 2000, TECHNOMETRICS, V42, P65, DOI 10.2307/1271434
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Eccles R, 2008, INFORM VISUAL, V7, P3, DOI 10.1057/palgrave.ivs.9500173
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Fotheringham A., 2008, The SAGE Handbook of Spatial Analysis, P3
   Fotheringham A. S., 2003, Geographically Weighted Regression: The Analysis of Spatially Varying Relationships, P1
   Fotheringham AS, 2017, ANN AM ASSOC GEOGR, V107, P1247, DOI 10.1080/24694452.2017.1352480
   Gao T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3005, DOI 10.1145/2556288.2557228
   Gareth J., 2013, An Introduction to Statistical Learning with Applications, P4
   Gil J., 2015, INT SPACE SYNTAX S, V10
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guo DS, 2006, IEEE T VIS COMPUT GR, V12, P1461, DOI 10.1109/TVCG.2006.84
   Hullman J., 2013, P SIGCHI C HUM FACT, P2707
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Kanevski M., 2009, Machine Learning for Spatial Environmental Data: Theory, Applications, and Software, P2
   Kastanakis B., 2016, Mapbox Cookbook, P3
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   KRAMER W, 1987, J AM STAT ASSOC, V82, P577, DOI 10.2307/2289467
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Latif S, 2021, COMPUT GRAPH FORUM, V40, P311, DOI 10.1111/cgf.14309
   Latif S, 2019, VIS INFORM, V3, P27, DOI 10.1016/j.visinf.2019.03.004
   Li J, 2011, ENVIRON MODELL SOFTW, V26, P1647, DOI 10.1016/j.envsoft.2011.07.004
   Li X, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820792
   Li ZQ, 2020, INT J GEOGR INF SCI, V34, P1378, DOI 10.1080/13658816.2020.1720692
   Liess M, 2012, GEODERMA, V170, P70, DOI 10.1016/j.geoderma.2011.10.010
   Liu C, 2020, IEEE PAC VIS SYMP, P191, DOI 10.1109/PacificVis48177.2020.1043
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Lovelace R., 2019, Geocomputation with R. Chapman and Hall/CRC, P2
   Lu JH, 2017, FRONT COMPUT SCI-CHI, V11, P192, DOI 10.1007/s11704-016-6028-y
   Lu YF, 2017, COMPUT GRAPH FORUM, V36, P539, DOI 10.1111/cgf.13210
   Lundblad Patrik, 2013, 2013 17th International Conference on Information Visualisation, P263, DOI 10.1109/IV.2013.35
   Meta Platforms Inc, 2022, React official page
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mühlbacher T, 2013, IEEE T VIS COMPUT GR, V19, P1962, DOI 10.1109/TVCG.2013.125
   Nathan Paco, 2021, Zenodo
   Nusrat S, 2018, IEEE T VIS COMPUT GR, V24, P2675, DOI 10.1109/TVCG.2017.2765330
   Oshan TM, 2019, ISPRS INT GEO-INF, V8, DOI 10.3390/ijgi8060269
   Ozturk D., 2016, AGU FALL M ABSTRACTS, pIN53A
   Pace RK, 1997, J REAL ESTATE FINANC, V14, P333, DOI 10.1023/A:1007762613901
   Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599
   Rey S. J., 2021, Geographical Analysis, DOI [10.1111/gean.122762, DOI 10.1111/GEAN.122762]
   Rey SJ, 2007, REV REG STUD, V37, P5
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Scott Lauren M., 2009, Handbook of Applied Spatial Analysis: Software Tools, Methods and Applications, P27, DOI [10.1007/978-3-642-03647-7_2, DOI 10.1007/978-3-642-03647-7_2]
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shabrina Z, 2021, GEOGR ANAL, V53, P686, DOI 10.1111/gean.12259
   Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145
   Fotheringham AS, 2021, ANN AM ASSOC GEOGR, V111, P1602, DOI 10.1080/24694452.2020.1835459
   Strode G., 2020, Cartogr Perspect, V94, P5, DOI DOI 10.14714/CP94.1538
   Takatsuka M, 2002, COMPUT GEOSCI-UK, V28, P1131, DOI 10.1016/S0098-3004(02)00031-6
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Traag VA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-41695-z
   Vittinghoff E., 2006, Regression Methods in Biostatistics: Linear, Logistic, Survival, and Repeated Measures Models, V4, P6
   Yang Chen, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P155, DOI 10.1109/VAST.2010.5652885
   Zhu AX, 2018, ANN GIS, V24, P225, DOI 10.1080/19475683.2018.1534890
NR 71
TC 1
Z9 1
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1391
EP 1401
DI 10.1109/TVCG.2023.3327359
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500068
PM 37883268
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Moreira, G
   Hosseini, M
   Nipu, MNA
   Lage, M
   Ferreira, N
   Miranda, F
AF Moreira, Gustavo
   Hosseini, Maryam
   Nipu, Md Nafiul Alam
   Lage, Marcos
   Ferreira, Nivan
   Miranda, Fabio
TI The Urban Toolkit: A Grammar-Based Framework for Urban Visual Analytics
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Urban visual analytics; Urban analytics; Urban data; Visualization
   toolkit
ID VISUALIZATION; BUILDINGS; VULNERABILITY; INFORMATION; EXPLORATION;
   MODELS; SYSTEM; FLOOD; VEGA
AB While cities around the world are looking for smart ways to use new advances in data collection, management, and analysis to address their problems, the complex nature of urban issues and the overwhelming amount of available data have posed significant challenges in translating these efforts into actionable insights. In the past few years, urban visual analytics tools have significantly helped tackle these challenges. When analyzing a feature of interest, an urban expert must transform, integrate, and visualize different thematic (e.g., sunlight access, demographic) and physical (e.g., buildings, street networks) data layers, oftentimes across multiple spatial and temporal scales. However, integrating and analyzing these layers require expertise in different fields, increasing development time and effort. This makes the entire visual data exploration and system implementation difficult for programmers and also sets a high entry barrier for urban experts outside of computer science. With this in mind, in this paper, we present the Urban Toolkit (UTK), a flexible and extensible visualization framework that enables the easy authoring of web-based visualizations through a new high-level grammar specifically built with common urban use cases in mind. In order to facilitate the integration and visualization of different urban data, we also propose the concept of knots to merge thematic and physical urban layers. We evaluate our approach through use cases and a series of interviews with experts and practitioners from different domains, including urban accessibility, urban planning, architecture, and climate science. UTK is available at urbantk.org.
C1 [Moreira, Gustavo; Miranda, Fabio] Univ Illinois, Chicago, IL 60614 USA.
   [Hosseini, Maryam] MIT, Cambridge, MA USA.
   [Nipu, Md Nafiul Alam; Lage, Marcos] Univ Fed Fluminense, Niteroi, Brazil.
   [Ferreira, Nivan] Univ Fed Pernambuco, Caruaru, Brazil.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; Massachusetts Institute of
   Technology (MIT); Universidade Federal Fluminense; Universidade Federal
   de Pernambuco
RP Moreira, G (corresponding author), Univ Illinois, Chicago, IL 60614 USA.
EM gmorei3@uic.edu; maryamh@mit.edu; mnipu2@uic.edu; mlage@ic.uff.br;
   nivan@cin.ufpe.br; fabiom@uic.edu
RI Moreira, Gustavo/V-5636-2019; Lage, Marcos/K-4098-2012
OI Ferreira, Nivan/0000-0001-6631-4609; Miranda, Fabio/0000-0001-8612-5805;
   Lage, Marcos/0000-0003-3868-8886
FU University of Illinois' Discovery Partners Institute (DPI), CNPq
FX No Statement Available
CR Andrienko Gennady, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P3, DOI 10.1109/VAST.2009.5332584
   Angelini M, 2019, COMPUT GRAPH FORUM, V38, P237, DOI 10.1111/cgf.13685
   Avini R, 2019, SUSTAIN CITIES SOC, V45, P378, DOI 10.1016/j.scs.2018.10.026
   Batty M., 2014, Urban Design, V132, P2
   Bokeh, About us
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bostock M, 2009, IEEE T VIS COMPUT GR, V15, P1121, DOI 10.1109/TVCG.2009.174
   Butcher PWS, 2021, IEEE T VIS COMPUT GR, V27, P3213, DOI 10.1109/TVCG.2020.2965109
   Chakraborty A, 2015, J AM PLANN ASSOC, V81, P18, DOI 10.1080/01944363.2015.1038576
   Chang R, 2007, IEEE T VIS COMPUT GR, V13, P1169, DOI 10.1109/TVCG.2007.70574
   Chen SM, 2016, IEEE T VIS COMPUT GR, V22, P270, DOI 10.1109/TVCG.2015.2467619
   Chen ZT, 2017, VIS INFORM, V1, P132, DOI 10.1016/j.visinf.2017.11.002
   Chippendale T, 2015, GERONTOLOGIST, V55, P575, DOI 10.1093/geront/gnu019
   Cornel D, 2019, COMPUT GRAPH FORUM, V38, P25, DOI 10.1111/cgf.13669
   Cornel D, 2015, COMPUT GRAPH FORUM, V34, P331, DOI 10.1111/cgf.12645
   Correa CD, 2006, IEEE T VIS COMPUT GR, V12, P1069, DOI 10.1109/TVCG.2006.144
   deck.gl, About us
   Delaney B, 2000, IEEE COMPUT GRAPH, V20, P10, DOI 10.1109/38.844365
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Doraiswamy H, 2018, INT CONF MANAGE DATA, P1693, DOI 10.1145/3183713.3193559
   Doraiswamy H, 2018, IEEE COMPUT GRAPH, V38, P26, DOI 10.1109/MCG.2018.053491728
   Ferreira N, 2015, IEEE CONF VIS ANAL, P97, DOI 10.1109/VAST.2015.7347636
   Ferreira N, 2013, IEEE T VIS COMPUT GR, V19, P2149, DOI 10.1109/TVCG.2013.226
   Garcia-Zanabria G, 2022, IEEE T VIS COMPUT GR, V28, P4000, DOI 10.1109/TVCG.2021.3111146
   Hemmersam P, 2015, J URBAN TECHNOL, V22, P45, DOI 10.1080/10630732.2015.1073898
   Hosseini M., 2022, CVPR 2022 AVA ACCESS, DOI [10.48550/ARXIV.2206 .13677 8, DOI 10.48550/ARXIV.2206.136778]
   Hosseini M, 2022, SUSTAIN CITIES SOC, V79, DOI 10.1016/j.scs.2021.103630
   Houle K., 2008, Winter performance assessment of permeable pavements: A comparative study of porous asphalt, pervious concrete, and conventional asphalt in a northern climate, P8
   Hu K., 2017, A usability study of ArcGIS Pro: Scaffolding an intuitive and fluid geovisualization workflow, P9
   Ichinose T, 2017, ENERG BUILDINGS, V136, P199, DOI 10.1016/j.enbuild.2016.11.064
   Jiang F, 2022, SUSTAIN CITIES SOC, V78, DOI 10.1016/j.scs.2021.103645
   Kim H, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517455
   Kindlmann G, 2016, IEEE T VIS COMPUT GR, V22, P867, DOI 10.1109/TVCG.2015.2467449
   Kraus M, 2022, COMPUT GRAPH FORUM, V41, P201, DOI 10.1111/cgf.14430
   L'Yi S, 2022, IEEE T VIS COMPUT GR, V28, P140, DOI 10.1109/TVCG.2021.3114876
   Lee B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580754
   Lee C., 2017, Building boom in Boston casts shadows on history and public space
   Liu ZC, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P171, DOI 10.1109/VIS49827.2021.9623315
   Liu ZC, 2010, IEEE T VIS COMPUT GR, V16, P999, DOI 10.1109/TVCG.2010.177
   Malik A, 2014, IEEE T VIS COMPUT GR, V20, P1863, DOI 10.1109/TVCG.2014.2346926
   Matplotlib, ABOUT US
   Miranda F, 2019, IEEE T VIS COMPUT GR, V25, P1559, DOI 10.1109/TVCG.2018.2802945
   Miranda F, 2017, IEEE T VIS COMPUT GR, V23, P791, DOI 10.1109/TVCG.2016.2598585
   Mota Roberta, 2023, IEEE Trans Vis Comput Graph, V29, P1277, DOI 10.1109/TVCG.2022.3209474
   Neuville R, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11030236
   NYC OpenData, About us
   Ortner T, 2017, IEEE T VIS COMPUT GR, V23, P1139, DOI 10.1109/TVCG.2016.2520920
   Palliwal A, 2021, COMPUT ENVIRON URBAN, V86, DOI 10.1016/j.compenvurbsys.2020.101584
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P3032, DOI 10.1109/TVCG.2017.2785807
   Rautek P, 2014, IEEE T VIS COMPUT GR, V20, P2388, DOI 10.1109/TVCG.2014.2346318
   Redweik P, 2017, INT J DISAST RISK SC, V8, P308, DOI 10.1007/s13753-017-0141-x
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Saha M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517460
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Satyanarayan A, 2016, IEEE T VIS COMPUT GR, V22, P659, DOI 10.1109/TVCG.2015.2467091
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shih M, 2019, IEEE T VIS COMPUT GR, V25, P1050, DOI 10.1109/TVCG.2018.2864841
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Speckmann B, 2010, IEEE T VIS COMPUT GR, V16, P881, DOI 10.1109/TVCG.2010.180
   Sun GD, 2017, IEEE T VIS COMPUT GR, V23, P1506, DOI 10.1109/TVCG.2016.2535234
   tableau, ABOUT US
   Tang JH, 2022, ENVIRON IMPACT ASSES, V97, DOI 10.1016/j.eiar.2022.106864
   trifolio, US
   Twardzik E, 2019, GAIT POSTURE, V68, P437, DOI 10.1016/j.gaitpost.2018.12.028
   Vuckovic M, 2022, INFORMATION, V13, DOI 10.3390/info13010007
   Wang PC, 2021, SUSTAIN CITIES SOC, V72, DOI 10.1016/j.scs.2021.103035
   Wang S., 2021, Urban Informatics, P663
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Yap W, 2022, COMPUT ENVIRON URBAN, V96, DOI 10.1016/j.compenvurbsys.2022.101825
   Yixian Zheng, 2016, IEEE Transactions on Big Data, V2, P276, DOI 10.1109/TBDATA.2016.2586447
   Zeng W, 2018, IEEE COMPUT GRAPH, V38, P38, DOI 10.1109/MCG.2018.053491730
   Ziegler P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581370
   Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369
NR 74
TC 3
Z9 3
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1402
EP 1412
DI 10.1109/TVCG.2023.3326598
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500131
PM 37871086
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Morini, F
   Eschenbacher, A
   Hartmann, J
   Dörk, M
AF Morini, Francesca
   Eschenbacher, Anna
   Hartmann, Johanna
   Dork, Marian
TI From Shock to Shift: Data Visualization for Constructive Climate
   Journalism
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Constructive Climate Journalism; Frameworks; Storytelling; Journalism
ID DESIGN; REFLECTIONS; SCIENCE
AB We present a multi-dimensional, multi-level, and multi-channel approach to data visualization for the purpose of constructive climate journalism. Data visualization has assumed a central role in environmental journalism and is often used in data stories to convey the dramatic consequences of climate change and other ecological crises. However, the emphasis on the catastrophic impacts of climate change tends to induce feelings of fear, anxiety, and apathy in readers. Climate mitigation, adaptation, and protection-all highly urgent in the face of the climate crisis-are at risk of being overlooked. These topics are more difficult to communicate as they are hard to convey on varying levels of locality, involve multiple interconnected sectors, and need to be mediated across various channels from the printed newspaper to social media platforms. So far, there has been little research on data visualization to enhance affective engagement with data about climate protection as part of solution-oriented reporting of climate change. With this research we characterize the unique challenges of constructive climate journalism for data visualization and share findings from a research and design study in collaboration with a national newspaper in Germany. Using the affordances and aesthetics of travel postcards, we present Klimakarten, a data journalism project on the progress of climate protection at multiple spatial scales (from national to local), across five key sectors (agriculture, buildings, energy, mobility, and waste), and for print and online use. The findings from quantitative and qualitative analysis of reader feedback confirm our overall approach and suggest implications for future work.
C1 [Morini, Francesca] Sodertorn Univ, Huddinge, Sweden.
   [Morini, Francesca; Dork, Marian] Univ Appl Sci Potsdam, Potsdam, Germany.
   [Eschenbacher, Anna; Hartmann, Johanna] Filmunivers Babelsberg, Potsdam, Germany.
C3 Sodertorn University
RP Morini, F (corresponding author), Sodertorn Univ, Huddinge, Sweden.
EM francesca.morini@sh.se; anna.eschenbacher@filmuniversitaet.de;
   johanna.hartmann@filmuniversitaet.de; doerk@fh-potsdam.de
OI Eschenbacher, Anna/0009-0000-3996-784X; Dork,
   Marian/0000-0002-3469-7841; Morini, Francesca/0000-0002-5677-8175
FU Bundesministerium fr Bildung und Forschung
FX No Statement Available
CR Agin S., 2022, Ph.D. dissertation
   Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552
   Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647
   [Anonymous], 2023, Climate protection (mitigation)
   [Anonymous], 2008, DIGITAL EARTH SUMMIT
   Appelgren E, 2021, DIGIT JOURNAL, V9, P755, DOI 10.1080/21670811.2020.1827965
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Attfield Simon, 2011, WSDM WORKSH US MOD W, P9
   Auer C, 2021, ONE EARTH, V4, P1074, DOI 10.1016/j.oneear.2021.07.015
   Bieh-Zimmert O, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2445, DOI 10.1109/BigData.2015.7364039
   Boy J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1449, DOI 10.1145/2702123.2702452
   COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155
   Dasgupta A, 2016, COMPUT SCI ENG, V18, P92, DOI 10.1109/MCSE.2016.7
   Dasgupta A, 2015, IEEE T VIS COMPUT GR, V21, P996, DOI 10.1109/TVCG.2015.2413774
   Eden S., 1996, PUBLIC UNDERST SCI, V5, P183, DOI [DOI 10.1088/0963-6625/5/3/001, 10.1088/0963-6625/5/3/001]
   Garretón M, 2024, IEEE T VIS COMPUT GR, V30, P4039, DOI 10.1109/TVCG.2023.3248319
   Hartmann J, 2008, ACM T COMPUT-HUM INT, V15, DOI 10.1145/1460355.1460357
   Hasebrink U, 2020, MEDIA COMMUN-LISBON, V8, P293, DOI 10.17645/mac.v8i3.3191
   Heyer J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376887
   Hickman C, 2020, J SOC WORK PRACT, V34, P411, DOI 10.1080/02650533.2020.1844166
   Hiippala T, 2020, Data Visualization in Society, P277
   Hogele M., 2019, Taz-transformation aus sicht der leser*innen und nutzer*innen
   Höhle J, 2023, ENVIRON EDUC RES, V29, P1659, DOI 10.1080/13504622.2023.2182746
   Höijer B, 2010, PUBLIC UNDERST SCI, V19, P717, DOI 10.1177/0963662509348863
   Hullman J, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1170, DOI 10.1145/2675133.2675207
   Hung Y. H., 2017, P 2017 CHI C EXTENDE, P1708, DOI [DOI 10.1145/3027063.3053113, 10.1145/3027063, 10.1145]
   Hung Y. -H., 2018, P IEEE C INFORM VISU, V5
   Kasemir B., 2003, Public participation in sustainability science: a handbook, V1, P81
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kuthe A, 2019, J ENVIRON EDUC, V50, P172, DOI 10.1080/00958964.2019.1598927
   Liem J, 2020, COMPUT GRAPH FORUM, V39, P277, DOI 10.1111/cgf.13980
   Lorenzoni I, 2007, GLOBAL ENVIRON CHANG, V17, P445, DOI 10.1016/j.gloenvcha.2007.01.004
   Lu JH, 2020, IEEE COMPUT GRAPH, V40, P18, DOI 10.1109/MCG.2020.2968249
   Lumley S, 2022, COMPUT GRAPH-UK, V103, P19, DOI 10.1016/j.cag.2021.12.007
   Lupi Giorgia, 2016, DEAR DATA
   McInerny GJ, 2014, TRENDS ECOL EVOL, V29, P148, DOI 10.1016/j.tree.2014.01.003
   Moore SA, 2019, GEOFORUM, V102, P267, DOI 10.1016/j.geoforum.2017.03.003
   Patela M, 2007, LAND USE POLICY, V24, P546, DOI 10.1016/j.landusepol.2006.02.005
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Postcard, 2023, About us
   Regattieri L. L., 2014, DATAWIZ2014 DATA VIS, V1210, P51
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Russell A, 2023, JOURNALISM, V24, P1387, DOI 10.1177/14648849221113119
   Sallam S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517727
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Sheppard S. R. J., 2008, PROCS DIGITAL DESIGN, P20
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sidiropoulos EA, 2016, 2016 11TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP), P156, DOI 10.1109/SMAP.2016.7753402
   Stoiber C, 2019, COMPUT GRAPH FORUM, V38, P699, DOI 10.1111/cgf.13721
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   von Luxburg U., 2012, INT C MACH LEARN WOR, P65
   Wiedemann G, 2018, LECT NOTES COMPUT SC, V11186, P313, DOI 10.1007/978-3-030-01159-8_30
   Windhager F., 2019, WORKSHOP VISUALISATI, DOI [10.2312/envirvis.20191098, DOI 10.2312/ENVIRVIS.20191098]
   Wolf J, 2011, WIRES CLIM CHANGE, V2, P547, DOI 10.1002/wcc.120
   Wood J, 2014, IEEE T VIS COMPUT GR, V20, P2171, DOI 10.1109/TVCG.2014.2346323
   Zimmerman J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P493
NR 57
TC 2
Z9 2
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1413
EP 1423
DI 10.1109/TVCG.2023.3327185
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500025
PM 37922181
OA hybrid
DA 2024-11-06
ER

PT J
AU Alebri, M
   Costanza, E
   Panagiotidou, G
   Brumby, DP
AF Alebri, Muna
   Costanza, Enrico
   Panagiotidou, Georgia
   Brumby, Duncan P.
TI Embellishments Revisited: Perceptions of Embellished Visualisations
   Through the Viewer's Lens
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualizations; Embellishments; Non-experts in visualisation and design
ID INFORMATION VISUALIZATION
AB Embellishments are features commonly used in everyday visualisations which are demonstrated to enhance assimilation and memorability. Despite their popularity, little is known about their impact on enticing readers to explore visualisations. To address this gap, we conducted 18 interviews with a diverse group of participants who were consumers of news media but non-experts in visualisation and design. Participants were shown ten embellished and plain visualisations collected from the news and asked to rank them based on enticement and ease of understanding. Extending prior work, our interview results suggest that visualisations with multiple embellishment types might make a visualisation perceived as more enticing. An important finding from our study is that the widespread of certain embellishments in the media might have made them part of visualisation conventions, making a visualisation appear more objective but less enticing. Based on these findings, we ran a follow-up online user study showing participants variations of the visualisations with multiple embellishments to isolate each embellishment type and investigate its effect. We found that variations with salient embellishments were perceived as more enticing. We argue that to unpack the concept of embellishments; we must consider two factors: embellishment saliency and editorial styles. Our study contributes concept and design considerations to the literature concerned with visualisation design for non-experts in visualisation and design.
C1 [Alebri, Muna; Costanza, Enrico; Panagiotidou, Georgia; Brumby, Duncan P.] UCL, London, England.
   [Alebri, Muna] United Arab Emirates Univ, Al Ain, U Arab Emirates.
C3 University of London; University College London; United Arab Emirates
   University
RP Alebri, M (corresponding author), UCL, London, England.; Alebri, M (corresponding author), United Arab Emirates Univ, Al Ain, U Arab Emirates.
EM muna.alebri.19@ucl.ac.uk; e.costanza@ucl.ac.uk;
   georgia.panagiotidou@kcl.ac.uk; d.brumpy@ucl.ac.uk
OI Panagiotidou, Georgia/0000-0003-4408-6371; Alebri,
   Muna/0000-0002-6471-6206
FU United Arab Emirates University and the Engineering and Physical
   Sciences Research Council BIP project
FX No Statement Available
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Akbaba D., 2021, ALTVIS IEEE VIS, P1, DOI [10.48550/arXiv.2109.10132, DOI 10.48550/ARXIV.2109.10132]
   Andry T., 2021, P CHI, P1, DOI [10.1145/3411764.34457391,2,3,8,9, DOI 10.1145/3411764.34457391,2,3,8,9]
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Borgo R, 2018, COMPUT GRAPH FORUM, V37, P573, DOI 10.1111/cgf.13444
   Borgo R, 2012, IEEE T VIS COMPUT GR, V18, P2759, DOI 10.1109/TVCG.2012.197
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5462, DOI 10.1145/3025453.3025512
   Braun V., 2021, Thematic Analysis A Practical Guide, Vfirst, DOI [10.1177/1035719X211058254,5, DOI 10.1177/1035719X211058254,5]
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Cleveland W. S., 1985, The Elements of Graphing Data, P2
   de Haan Y, 2018, JOURNALISM STUD, V19, P1293, DOI 10.1080/1461670X.2016.1267592
   Garreton M., 2023, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.32483191, DOI 10.1109/TVCG.2023.32483191]
   Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275
   Hill S., 2018, Journal of Information System Applied Research, V11, P2
   Hung Y. H., 2017, P 2017 CHI C EXTENDE, P1708, DOI [DOI 10.1145/3027063.3053113, 10.1145/3027063, 10.1145]
   KELLY JD, 1989, JOURNALISM QUART, V66, P632, DOI 10.1177/107769908906600315
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kennedy H, 2016, INFORM COMMUN SOC, V19, P715, DOI 10.1080/1369118X.2016.1153126
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Mahyar N., 2015, WORKSHOP PERSONAL VI, V3, P2
   Moacdieh N., 2014, PROC HUMAN FACTORS E, P1516, DOI [10.1177/1541931214581316, DOI 10.1177/1541931214581316]
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Park JH, 2018, IEEE COMPUT GRAPH, V38, P67, DOI 10.1109/MCG.2018.2879066
   Parsons P, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P211, DOI 10.1109/VIS47514.2020.00049
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Peer E, 2014, BEHAV RES METHODS, V46, P1023, DOI 10.3758/s13428-013-0434-y
   Pena A., 2020, Interdisciplinary Journal of Signage and Wayfinding, V4, P19, DOI [10.15763/issn.2470-9670.2020.v4.i1.a541,2,8, DOI 10.15763/ISSN.2470-9670.2020.V4.I1.A541,2,8]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Salminen J., 2021, P CHI, P1, DOI [10.1145/3411764.34453609, DOI 10.1145/3411764.34453609]
   Shukla P., 2022, VISCOMM IEEE VIS, P1, DOI [10.31219/osf.io/ayvq58, DOI 10.31219/OSF.IO/AYVQ58]
   Skau Drew., 2017, EuroVis Short Papers, P91, DOI DOI 10.2312/EUROVISSHORT.20171139
   Sprague D, 2012, INFORM VISUAL, V11, P106, DOI 10.1177/1473871611433710
   Su YS, 2008, COMPUT STAT DATA AN, V52, P4594, DOI 10.1016/j.csda.2008.03.007
   Tufte E., 1983, The Visual Display of Quantitative Information, DOI [10.5555/334041,2,8, DOI 10.5555/334041,2,8]
   U. Government, 2022, The National Minimum Wage in 2022, P3
   Vande Moere A, 2012, IEEE T VIS COMPUT GR, V18, P2739, DOI 10.1109/TVCG.2012.221
   Wang Y, 2019, IEEE COMPUT GRAPH, V39, P8, DOI 10.1109/MCG.2019.2923483
   Watson A., 2022, Leading News Websites in the United Kingdom (UK) 2021, by Monthly Visits, P3
   Wu K., 2021, P CHI, P1, DOI [10.1145/3411764.34457431, DOI 10.1145/3411764.34457431]
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yi C, 2015, J MANAGE INFORM SYST, V31, P213, DOI [10.1080/0742222.2014.1001270, 10.1080/07421222.2014.1001270]
   Zhang YX, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445381
NR 47
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1424
EP 1434
DI 10.1109/TVCG.2023.3326914
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500035
PM 37874724
OA Green Submitted
DA 2024-11-06
ER

PT J
AU He, HA
   Walny, J
   Thoma, S
   Carpendale, S
   Willett, W
AF He, Helen Ai
   Walny, Jagoda
   Thoma, Sonja
   Carpendale, Sheelagh
   Willett, Wesley
TI Enthusiastic and Grounded, Avoidant and Cautious: Understanding Public
   Receptivity to Data and Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Diverse audiences; Information receptivity; Information visualization;
   Open data
ID INFORMATION VISUALIZATION; TRUST; DESIGN; GRAPH
AB Despite an abundance of open data initiatives aimed to inform and empower "general" audiences, we still know little about the ways people outside of traditional data analysis communities experience and engage with public data and visualizations. To investigate this gap, we present results from an in-depth qualitative interview study with 19 participants from diverse ethnic, occupational, and demographic backgrounds. Our findings characterize a set of lived experiences with open data and visualizations in the domain of energy consumption, production, and transmission. This work exposes information receptivity - an individual's transient state of willingness or openness to receive information -as a blind spot for the data visualization community, complementary to but distinct from previous notions of data visualization literacy and engagement. We observed four clusters of receptivity responses to data- and visualization-based rhetoric: Information-Avoidant, Data-Cautious, Data-Enthusiastic, and Domain-Grounded. Based on our findings, we highlight research opportunities for the visualization community. This exploratory work identifies the existence of diverse receptivity responses, highlighting the need to consider audiences with varying levels of openness to new information. Our findings also suggest new approaches for improving the accessibility and inclusivity of open data and visualization initiatives targeted at broad audiences. A free copy of this paper and all supplemental materials are available at https://OSF.IO/MPQ32.
C1 [He, Helen Ai; Walny, Jagoda; Thoma, Sonja; Willett, Wesley] Univ Calgary, Calgary, AB, Canada.
   [Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC, Canada.
C3 University of Calgary; Simon Fraser University
RP Willett, W (corresponding author), Univ Calgary, Calgary, AB, Canada.
EM helen.he1@ucalgary.ca; jkwalny@ucalgary.ca; me@sonjathoma.ca;
   sheelagh@sfu.ca; wesley.willett@ucalgary.ca
OI Willett, Wesley/0000-0002-6793-3062; Carpendale,
   Sheelagh/0000-0002-5127-9780
FU National Energy Board (NEB) of Canada; Canada Research Chairs Program
FX This study was funded by a research grant from the National Energy Board
   (NEB) of Canada with support from the Canada Research Chairs Program.
   Thanks to our participants and to our VIS 2021 and VIS 2023 reviewers
   for their invaluable input.
CR Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   American Psychological Association, 2019, Publication Manual of the American Psychological Association, V7th, P3
   Anderson EW, 2011, COMPUT GRAPH FORUM, V30, P791, DOI 10.1111/j.1467-8659.2011.01928.x
   [Anonymous], 2011, OECD Better Life Index
   Anshari M, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P140, DOI 10.1145/3195106.3195172
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bakx K., 2019, CBC
   Barbosa L, 2014, BIG DATA-US, V2, P144, DOI 10.1089/big.2014.0020
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Card S. K., 1999, Readings in Information Visualization: Using Vision to Think, P2
   Carpendale S, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186325
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Corbin J., 2015, Basics of Qualitative Research, V4th, P3
   Correll M, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P1, DOI 10.1109/BELIV57783.2022.00005
   D'Ignazio Catherine, 2017, Information Design Journal, V23, P6, DOI 10.1075/idj.23.1.03dig
   Diakopoulos N, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1717
   Elliott J. K., 2019, Global NewsJune 21
   Emanuel AS, 2015, SOC SCI MED, V147, P113, DOI 10.1016/j.socscimed.2015.10.058
   Engebretsen M, 2020, NORD REV, V41, P33, DOI 10.2478/nor-2020-0004
   Ferretti G, 2019, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON DIGITAL GOVERNMENT RESEARCH (DGO2019): GOVERNANCE IN THE AGE OF ARTIFICIAL INTELLIGENCE, P25, DOI 10.1145/3325112.3325230
   Gapminder, 2006, Gapminder tools
   Golman R, 2017, J ECON LIT, V55, P96, DOI 10.1257/jel.20151245
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Harboe G, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P95, DOI 10.1145/2702123.2702561
   Harrison L., 2013, The role of emotion in visualization, P8
   He H. A., 2019, Open Technical Report, DOI [10.11575/PRISM/372734, DOI 10.11575/PRISM/372734]
   Heer J, 2009, COMMUN ACM, V52, P87, DOI 10.1145/1435417.1435439
   Huang DD, 2015, IEEE T VIS COMPUT GR, V21, P420, DOI 10.1109/TVCG.2014.2359887
   Huang WD, 2009, INFORM VISUAL, V8, P139, DOI 10.1057/ivs.2009.10
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Huron S., IEEE VIS PEDAGOGY DA
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Kassen M, 2013, GOV INFORM Q, V30, P508, DOI 10.1016/j.giq.2013.05.012
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kennedy H, 2018, SOCIOLOGY, V52, P830, DOI 10.1177/0038038516674675
   Kirkup K., 2019, Global NewsApril 24
   Knowles ES, 2007, FRONT SOC PSYCHOL, P83
   Knudsen S., CHI Extended Abstracts, P1
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Markant D., 2023, P CHI, DOI [10.1145/3544548.3581330, DOI 10.1145/3544548.3581330]
   Meyer M, 2020, IEEE T VIS COMPUT GR, V26, P87, DOI 10.1109/TVCG.2019.2934539
   Microsoft, 2019, Power BI, V2, P9
   Munzner T., 2014, Visualization Analysis and Design, P2
   National Energy Board of Canada, 2019, Technical Report NE2-23E-PDF, P2
   Oster E, 2013, AM ECON REV, V103, P804, DOI 10.1257/aer.103.2.804
   Pandey AV, 2014, IEEE T VIS COMPUT GR, V20, P2211, DOI 10.1109/TVCG.2014.2346419
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Plutchik R., 1980, Theories of Emotion, P3, DOI [DOI 10.1016/B978-0-12-558701-3.50007-7, DOI 10.1016/C2013-0-11313-X]
   Pousman Z, 2007, IEEE T VIS COMPUT GR, V13, P1145, DOI 10.1109/TVCG.2007.70541
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Rendgen S., 2012, TASCHEN, V2
   Rendgen S., 2018, The Minard System: The Complete Statistical Graphics of Charles-Joseph Minard, P2
   Riche NH., 2018, Data-driven storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Rowley J, 2012, INT J MARKET RES, V54, P93, DOI 10.2501/IJMR-54-1-093-110
   Sagarin BJ, 2004, RESISTANCE AND PERSUASION, P259
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Scupin R, 1997, HUM ORGAN, V56, P233, DOI 10.17730/humo.56.2.x335923511444655
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Sicherman N, 2016, REV FINANC STUD, V29, P863, DOI 10.1093/rfs/hhv073
   Siebenhaar KU, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.567905
   Siegrist M, 2000, RISK ANAL, V20, P353, DOI 10.1111/0272-4332.203034
   Snyder J., 2019, National PostJune 18
   Soroya SH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102440
   Subramonyam H, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300628
   Tableau Inc, 2019, Tableau, V2, P9
   Tasker J. P., 2019, CBCMay 23
   Treasury Board Secretariat of Canada, 2018, Canada's 2018-2020 National Action Plan on Open Government
   Tsandilas T, 2021, IEEE T VIS COMPUT GR, V27, P315, DOI 10.1109/TVCG.2020.3030476
   Twyman M, 2008, JUDGM DECIS MAK, V3, P111
   Vainio A, 2017, RISK ANAL, V37, P557, DOI 10.1111/risa.12640
   Vetrò A, 2016, GOV INFORM Q, V33, P325, DOI 10.1016/j.giq.2016.02.001
   Viegas F.B., 2008, Hawaii International Conference on System Sciences, P159, DOI DOI 10.1109/HICSS.2008.188
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Vossoughian N., 2011, Otto Neurath: The Language of the Global Polis, P2
   Walny J, 2020, IEEE COMPUT GRAPH, V40, P57, DOI 10.1109/MCG.2020.2968906
   Wieczorkowski J, 2019, 3RD INTERNATIONAL CONFERENCE ON E-COMMERCE, E-BUSINESS AND E-GOVERNMENT, ICEEG 2019, P15, DOI 10.1145/3340017.3340022
   Willett W, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3131
   Wilson J., 2019, CBCFebruary 20
NR 87
TC 2
Z9 2
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1435
EP 1445
DI 10.1109/TVCG.2023.3326917
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500099
PM 37871069
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Holder, E
   Bearfield, CX
AF Holder, Eli
   Bearfield, Cindy Xiong
TI Polarizing Political Polls: How Visualization Design Choices Can Shape
   Public Opinion and Increase Political Polarization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Political Polarization; Public Opinion; Social Categorization; Survey
   Data; Social Influence; Attitude Change
ID DECISION-MAKING; COMMUNICATION; AMERICANS; JUDGMENT; IMPACT; PARTY
AB While we typically focus on data visualization as a tool for facilitating cognitive tasks (e.g. learning facts, making decisions), we know relatively little about their second-order impacts on our opinions, attitudes, and values. For example, could design or framing choices interact with viewers' social cognitive biases in ways that promote political polarization? When reporting on U.S. attitudes toward public policies, it is popular to highlight the gap between Democrats and Republicans (e.g. with blue vs red connected dot plots). But these charts may encourage social-normative conformity, influencing viewers' attitudes to match the divided opinions shown in the visualization. We conducted three experiments examining visualization framing in the context of social conformity and polarization. Crowdworkers viewed charts showing simulated polling results for public policy proposals. We varied framing (aggregating data as non-partisan "All US Adults," or partisan "Democrat" / "Republican") and the visualized groups' support levels. Participants then reported their own support for each policy. We found that participants' attitudes biased significantly toward the group attitudes shown in the stimuli and this can increase inter-party attitude divergence. These results demonstrate that data visualizations can induce social conformity and accelerate political polarization. Choosing to visualize partisan divisions can divide us further.
C1 [Holder, Eli] 3iap, New York, NY 10065 USA.
   [Bearfield, Cindy Xiong] Georgia Tech, Atlanta, GA USA.
C3 University System of Georgia; Georgia Institute of Technology
RP Holder, E (corresponding author), 3iap, New York, NY 10065 USA.
EM eli@3iap.com; cindy.xiong@cs.umass.edu
FU NSF
FX No Statement Available
CR Abramowitz A., 2011, The Disappearing Center: Engaged Citizens, Polarization, and American Democracy
   Agley J, 2022, BEHAV RES METHODS, V54, P885, DOI 10.3758/s13428-021-01665-8
   Ahler DJ, 2018, J POLIT, V80, P964, DOI 10.1086/697253
   Allcott H, 2010, SCIENCE, V327, P1204, DOI 10.1126/science.1180775
   Atske S., 2019, Partisan antipathy: More intense, more personal
   Baekgaard M, 2019, BRIT J POLIT SCI, V49, P1117, DOI 10.1017/S0007123417000084
   Balietti S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2112552118
   BOCHNER S, 1966, J PERS SOC PSYCHOL, V4, P614, DOI 10.1037/h0021192
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Boukouras A, 2023, EUR J POLIT ECON, V78, DOI 10.1016/j.ejpoleco.2023.102383
   Burger JM, 2004, PERS SOC PSYCHOL B, V30, P35, DOI 10.1177/0146167203258838
   Cialdini R.B., 2006, Social Influence, V1, P3, DOI DOI 10.1080/15534510500181459
   Clifford S, 2021, AM POLIT SCI REV, V115, P1048, DOI 10.1017/S0003055421000241
   Cohen GL, 2003, J PERS SOC PSYCHOL, V85, P808, DOI 10.1037/0022-3514.85.5.808
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Cosmides L, 1996, COGNITION, V58, P1, DOI 10.1016/0010-0277(95)00664-8
   Cwir D, 2011, J EXP SOC PSYCHOL, V47, P661, DOI 10.1016/j.jesp.2011.01.009
   DeSilver D., 2022, The polarization in today's Congress has roots that go back decades
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   DIgnazio C, 2020, STRONG IDEAS SERIES, P1
   DiMaggio P, 1996, AM J SOCIOL, V102, P690, DOI 10.1086/230995
   Dimara E, 2020, IEEE T VIS COMPUT GR, V26, P1413, DOI 10.1109/TVCG.2018.2872577
   Druckman JN, 2021, NAT HUM BEHAV, V5, DOI 10.1038/s41562-020-01012-5
   Federico C.M., 2021, The Psychology of Political Polarization, P17
   Finkel EJ, 2020, SCIENCE, V370, P533, DOI 10.1126/science.abe1715
   Franconeri SL, 2021, PSYCHOL SCI PUBL INT, V22, P110, DOI 10.1177/15291006211051956
   Furrer RA, 2023, COGN RES, V8, DOI 10.1186/s41235-023-00465-2
   Gaba A., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P1211
   Goldstein NJ, 2008, J CONSUM RES, V35, P472, DOI 10.1086/586910
   Griffin E., 2012, A first look at communication theory, V8th ed.
   Grosser J, 2010, AM J POLIT SCI, V54, P700, DOI 10.1111/j.1540-5907.2010.00455.x
   Guilbeault D, 2018, P NATL ACAD SCI USA, V115, P9714, DOI 10.1073/pnas.1722664115
   Heyer J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376887
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Iyengar S, 2015, AM J POLIT SCI, V59, P690, DOI 10.1111/ajps.12152
   Iyengar S, 2012, PUBLIC OPIN QUART, V76, P405, DOI 10.1093/poq/nfs038
   Jacobson GC, 2016, ANN AM ACAD POLIT SS, V667, P226, DOI 10.1177/0002716216658921
   Jhangiani D. R., 2022, The many varieties of conformity
   Jhangiani D. R., 2022, Ingroup favoritism and prejudice
   Jhangiani D. R., 2022, Initial attraction
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Karduni A, 2021, IEEE T VIS COMPUT GR, V27, P978, DOI 10.1109/TVCG.2020.3029412
   Kennedy R, 2020, POLIT SCI RES METH, V8, P614, DOI 10.1017/psrm.2020.6
   Kim YS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1375, DOI 10.1145/3025453.3025592
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Klein E., 2020, WHY WERE POLARIZED
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lau IYM, 2001, SOC COGNITION, V19, P350, DOI 10.1521/soco.19.3.350.21467
   Ledgerwood A, 2007, J PERS SOC PSYCHOL, V93, P940, DOI 10.1037/0022-3514.93.6.940
   Lee-Robbins Elsie, 2023, IEEE Trans Vis Comput Graph, V29, P1, DOI 10.1109/TVCG.2022.3209500
   Lees J, 2020, NAT HUM BEHAV, V4, P279, DOI 10.1038/s41562-019-0766-4
   Leppert R., 2022, Americans continue to express mixed views about nuclear power
   Levendusky M, 2016, POLIT COMMUN, V33, P283, DOI 10.1080/10584609.2015.1038455
   Levendusky Matthew., 2009, PARTISAN SORT LIBERA
   Levendusky MS, 2018, J POLIT, V80, P59, DOI 10.1086/693987
   Luo Y, 2021, CURR OPIN BEHAV SCI, V42, P22, DOI 10.1016/j.cobeha.2021.02.010
   Madson G., 2018, All the best polls agree with me: Bias in evaluation of political polling
   Malka A, 2010, SOC JUSTICE RES, V23, P156, DOI 10.1007/s11211-010-0114-3
   Mason L, 2015, AM J POLIT SCI, V59, P128, DOI 10.1111/ajps.12089
   MILGRAM S, 1969, J PERS SOC PSYCHOL, V13, P79, DOI 10.1037/h0028070
   Milkman KL, 2021, NATURE, V600, P478, DOI 10.1038/s41586-021-04128-4
   Mueller FF, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445218
   Nadeem R., 2022, As partisan hostility grows
   Naerland T. U., 2020, Data Visualization in Society, P63
   Newburger E., 2022, IEEE Transactions on Visualization and Computer Graphics
   Padilla L, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05353-1
   Pandey AV, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1469, DOI 10.1145/2702123.2702608
   Prooijen J.-W. v., 2021, The Psychology of Political Polarization
   Reyna VF, 2008, MED DECIS MAKING, V28, P850, DOI 10.1177/0272989X08327066
   Rothschild D, 2014, RES POLITICS, V1, DOI 10.1177/2053168014547667
   Sánchez-Holgado P, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1064184
   Schaeffer K., 2021, Key facts about Americans and guns
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Sherif M., 1961, Social judgment: Assimilation and contrast effects in communication and attitude change
   Sherif M., 1936, The psychology of social norms
   Sloman SA, 2022, TOP COGN SCI, V14, P31, DOI 10.1111/tops.12580
   Smith A., 2017, Americans' attitudes toward driverless vehicles
   Sulzberger A., 2023, Columbia Journalism Review
   TAJFEL H, 1971, EUR J SOC PSYCHOL, V1, P149, DOI 10.1002/ejsp.2420010202
   Wesslen R, 2019, COMPUT GRAPH FORUM, V38, P161, DOI 10.1111/cgf.13679
   Wilmer J. B., 2022, What's really wrong with bar graphs of mean values: variable and inaccurate communication of evidence on three key dimensions
   Xiong C., 2022, CHI C HUMAN FACTORS, P1
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
NR 88
TC 2
Z9 2
U1 7
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 1446
EP 1456
DI 10.1109/TVCG.2023.3326512
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HJ3Z6
UT WOS:001159106500021
PM 37871081
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, HRY
   Appleby, G
   Brumar, CD
   Chang, RM
   Suh, A
AF Li, Harry
   Appleby, Gabriel
   Brumar, Camelia Daniela
   Chang, Remco
   Suh, Ashley
TI Knowledge Graphs in Practice: Characterizing their Users, Challenges,
   and Visualization Opportunities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Knowledge graphs; Data visualization; Interviews; Task analysis; Data
   models; Standards organizations; Semantics; visualization techniques and
   methodologies; human factors; visual communication
ID VISUAL ANALYSIS; PERFORMANCE
AB This study presents insights from interviews with nineteen Knowledge Graph (KG) practitioners who work in both enterprise and academic settings on a wide variety of use cases. Through this study, we identify critical challenges experienced by KG practitioners when creating, exploring, and analyzing KGs that could be alleviated through visualization design. Our findings reveal three major personas among KG practitioners - KG Builders, Analysts, and Consumers - each of whom have their own distinct expertise and needs. We discover that KG Builders would benefit from schema enforcers, while KG Analysts need customizable query builders that provide interim query results. For KG Consumers, we identify a lack of efficacy for node-link diagrams, and the need for tailored domain-specific visualizations to promote KG adoption and comprehension. Lastly, we find that implementing KGs effectively in practice requires both technical and social solutions that are not addressed with current tools, technologies, and collaborative workflows. From the analysis of our interviews, we distill several visualization research directions to improve KG usability, including knowledge cards that balance digestibility and discoverability, timeline views to track temporal changes, interfaces that support organic discovery, and semantic explanations for AI and machine learning predictions.
C1 [Li, Harry; Suh, Ashley] MIT Lincoln Lab, Lincoln, NE 02420 USA.
   [Li, Harry; Appleby, Gabriel; Brumar, Camelia Daniela; Chang, Remco; Suh, Ashley] Tufts Univ, Somerville, MA 02155 USA.
C3 Lincoln Laboratory; Tufts University
RP Li, HRY (corresponding author), MIT Lincoln Lab, Lincoln, NE 02420 USA.; Li, HRY (corresponding author), Tufts Univ, Somerville, MA 02155 USA.
EM harry.li@ll.mit.edu; gabriel.appleby@tufts.edu;
   camelia_daniela.brumar@tufts.edu; remco.chang@tufts.edu;
   ashley.suh@ll.mit.edu
RI Brumar, Camelia/KWT-3643-2024
OI Chang, Remco/0000-0002-6484-6430; Suh, Ashley/0000-0001-6513-8447; Li,
   Harry/0000-0002-2288-6039
FU National Science Foundation
FX No Statement Available
CR Abu-Salih B, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103076
   Ahmad S, 2021, 2021 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC 2021), P25, DOI 10.1109/VAHC53616.2021.00009
   AlKhamissi B., 2022, arXiv
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   Angelini M, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5030031
   Angles R., 2023, Proc. ACM Manag. Data, V1, DOI [10.1145/3589778 9, DOI 10.1145/35897789]
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Aurisano J., 2016, P VIS, V8
   Bastian M, 2009, P INT AAAI C WEBL SO, V3, P361, DOI 10.13140/2.1.1341.1520
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Bonatti S., 2019, Dagstuhl Rep., V8, P29, DOI DOI 10.4230/DAGREP.8.9.29
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Brown T.B., 2020, Advances in neural information processing systems, V33, P1877
   Cashman D, 2021, IEEE T VIS COMPUT GR, V27, P1731, DOI 10.1109/TVCG.2020.3030443
   Chan B, 2008, IEEE T VIS COMPUT GR, V14, P1213, DOI 10.1109/TVCG.2008.178
   Chen XJ, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112948
   DeCuir-Gunby JT, 2011, FIELD METHOD, V23, P136, DOI 10.1177/1525822X10388468
   Ehrlinger L., 2016, SEMANTiCS (Posters, Demos, SuCCESS), V48, P2
   Ell Basil, 2014, The Semantic Web: Trends and Challenges. 11th International Conference (ESWC 2014). Proceedings: LNCS 8465, P426, DOI 10.1007/978-3-319-07443-6_29
   Ferré S, 2017, SEMANT WEB, V8, P405, DOI 10.3233/SW-150208
   Francis N, 2018, INT CONF MANAGE DATA, P1433, DOI 10.1145/3183713.3190657
   Gal A, 2014, PROC VLDB ENDOW, V7, P1711, DOI 10.14778/2733004.2733068
   Gan YJ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2030
   Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478
   Gibson H, 2013, INFORM VISUAL, V12, P324, DOI 10.1177/1473871612455749
   Gómez-Romero J, 2018, FUTURE GENER COMP SY, V89, P224, DOI 10.1016/j.future.2018.06.015
   Gottschalk S, 2018, LECT NOTES COMPUT SC, V10843, P272, DOI 10.1007/978-3-319-93417-4_18
   Grafkin P., 2016, BIR WORKSH, P255
   Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705
   Hagberg A., 2008, Technical report, P4
   Helmers S. A., 2015, Microsoft Visio 2016 Step By Step: MS Visio 2016 Ste by Ste_p1, P9
   Hemberg E., 2021, arXiv
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Hogan A, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447772
   Hong S. R., 2020, Proc. CHI, V4, DOI DOI 10.1145/33928782
   Huang Jieying, 2023, IEEE Trans Vis Comput Graph, V29, P1200, DOI 10.1109/TVCG.2022.3209453
   Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956
   Husain F, 2021, 2021 IEEE WORKSHOP ON VISUAL ANALYTICS IN HEALTHCARE (VAHC 2021), P30, DOI 10.1109/VAHC53616.2021.00010
   Jing Han, 2011, Proceedings 2011 6th International Conference on Pervasive Computing and Applications (ICPCA 2011), P363, DOI 10.1109/ICPCA.2011.6106531
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kivela M., 2019, Dagstuhl Reports, V9, P1, DOI DOI 10.4230/DAGREP.9.2.12
   Klein K., 2022, Dagstuhl Rep, V12, P67, DOI [10.4230/DagRep.12.1.672,7, DOI 10.4230/DAGREP.12.1.672,7]
   Latif S, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P156, DOI 10.1109/VIS49827.2021.9623313
   Lecue F, 2020, SEMANT WEB, V11, P41, DOI 10.3233/SW-190374
   Lee B., 2006, P BELIV, P1, DOI [10.1145/1168149.11681686,9, DOI 10.1145/1168149.11681686,9]
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lissandrini M., 2022, CIDR, V22, P10
   Liu ZC, 2014, IEEE T VIS COMPUT GR, V20, P2122, DOI 10.1109/TVCG.2014.2346452
   MacQueen KM., 1998, CAM J, V10, P31, DOI [10.1177/1525822X980100020301, DOI 10.1177/1525822X980100020301]
   Miller J. J., 2013, Proc. SAIS, V2324, P2
   Mitra R, 2022, IEEE VIS CONF, P6, DOI 10.1109/VIS54862.2022.00010
   Mosca A., 2019, EuroVis 2019 - Short Papers, DOI DOI 10.2312/EVS.20191173
   Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378
   Neo4J, Neo4j Bloom
   Nobre C, 2019, IEEE T VIS COMPUT GR, V25, P544, DOI 10.1109/TVCG.2018.2865149
   Partl C, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12883
   Passi Samir, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274405
   Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218
   Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463
   Rossi A, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3424672
   Rudin C., 2019, HARVARD DATA SCI REV, V1, P1, DOI [DOI 10.1162/99608F92.5A8A3A3D, https://doi.org/10.1162/99608f92.5a8a3a3d]
   Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303
   SHNEIDERMAN B, 1984, COMPUT SURV, V16, P265, DOI 10.1145/2514.2517
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, 10.48550/arXiv.1312.6034, DOI 10.48550/ARXIV.1312.6034]
   stardog, Stardog, an enterprise Knowledge Graph platform
   Storey Margaret-Anne D., 2005, P 2005 ACM S SOFTWAR, P193, DOI DOI 10.1145/1056018.1056045
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Suresh H, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445088
   Tiddi I, 2020, STUD SEMANTIC WEB, V47, P1, DOI 10.3233/SSW47
   Toussaint E, 2022, PROC VLDB ENDOW, V15, P2613, DOI 10.14778/3551793.3551818
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Waagmeester A, 2020, ELIFE, V9, DOI 10.7554/eLife.52614
   Wikipedia, Wikidata Statistics
   Wongsuphasawat K, 2019, Arxiv, DOI arXiv:1911.00568
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Xiao GH, 2019, DATA INTELLIGENCE, V1, P201, DOI 10.1162/dint_a_00011
   Yoon Y, 2013, S VIS LANG HUM CEN C, P119, DOI 10.1109/VLHCC.2013.6645254
NR 81
TC 2
Z9 2
U1 8
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JAN
PY 2024
VL 30
IS 1
BP 584
EP 594
DI 10.1109/TVCG.2023.3326904
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DT8M9
UT WOS:001134418500001
PM 38096099
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, C
   Wei, GS
   Wei, GD
   Wang, WP
   Zhou, YF
AF Wang, Chen
   Wei, Guangshun
   Wei, Guodong
   Wang, Wenping
   Zhou, Yuanfeng
TI Tooth Alignment Network Based on Landmark Constraints and Hierarchical
   Graph Structure
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Teeth; Point cloud compression; Feature extraction; Dentistry;
   Three-dimensional displays; Shape; Solid modeling; Orthodontics; tooth
   landmark; tooth alignment; hierarchical graph neural network
ID NEURAL-NETWORK
AB Automatic tooth alignment target prediction is vital in shortening the planning time of orthodontic treatments and aligner designs. Generally, the quality of alignment targets greatly depends on the experience and ability of dentists and has enormous subjective factors. Therefore, many knowledge-driven alignment prediction methods have been proposed to help inexperienced dentists. Unfortunately, existing methods tend to directly regress tooth motion, which lacks clinical interpretability. Tooth anatomical landmarks play a critical role in orthodontics because they are effective in aiding the assessment of whether teeth are in close arrangement and normal occlusion. Thus, we consider anatomical landmark constraints to improve tooth alignment results. In this article, we present a novel tooth alignment neural network for alignment target predictions based on tooth landmark constraints and a hierarchical graph structure. We detect the landmarks of each tooth first and then construct a hierarchical graph of jaw-tooth-landmark to characterize the relationship between teeth and landmarks. Then, we define the landmark constraints to guide the network to learn the normal occlusion and predict the rigid transformation of each tooth during alignment. Our method achieves better results with the architecture built for tooth data and landmark constraints and has better explainability than previous methods with regard to clinical tooth alignments.
C1 [Wang, Chen; Wei, Guangshun; Zhou, Yuanfeng] Shandong Univ, Sch Software, Jinan 250100, Peoples R China.
   [Wei, Guodong; Wang, Wenping] Univ Hong Kong, Hong Kong, Peoples R China.
   [Wang, Wenping] Texas A&M Univ, College Stn, TX 77843 USA.
C3 Shandong University; University of Hong Kong; Texas A&M University
   System; Texas A&M University College Station
RP Zhou, YF (corresponding author), Shandong Univ, Sch Software, Jinan 250100, Peoples R China.
EM chen.wang@mail.sdu.edu.cn; guangshunwei@gmail.com; gdwei@cs.hku.hk;
   wenping@cs.hku.hk; yfzhou@sdu.edu.cn
RI Zhou, Yuanfeng/AAT-4670-2020
OI Wang, Chen/0000-0001-7162-4687; Wei, Guangshun/0000-0002-6045-4392; Wei,
   Guodong/0000-0001-6975-9865
FU National Key R#x0026;D Plan on Strategic International Scientific and
   Technological Innovation Cooperation Special Project
FX No Statement Available
CR ANDREWS LF, 1972, AMER J ORTHODONTICS, V62, P296, DOI 10.1016/S0002-9416(72)90268-0
   Atwood J, 2016, ADV NEUR IN, V29
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Chang YB, 2010, IEEE T MED IMAGING, V29, P1652, DOI 10.1109/TMI.2010.2049526
   Chen RN, 2019, LECT NOTES COMPUT SC, V11766, P873, DOI 10.1007/978-3-030-32248-9_97
   Chen W, 2020, PROC CVPR IEEE, P4232, DOI 10.1109/CVPR42600.2020.00429
   Cheng C, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0269-4
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Cui ZM, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101949
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198252
   Defferrard M, 2016, ADV NEUR IN, V29
   Du GG, 2021, ARTIF INTELL REV, V54, P1677, DOI 10.1007/s10462-020-09888-5
   Fischer K, 2021, PROC CVPR IEEE, P313, DOI 10.1109/CVPR46437.2021.00038
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Guodong Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P481, DOI 10.1007/978-3-030-58555-6_29
   He YS, 2020, PROC CVPR IEEE, P11629, DOI 10.1109/CVPR42600.2020.01165
   Hinterstoisser V., 2012, PROC ASIAN C COMPUT, P548
   Hu FY, 2019, Arxiv, DOI [arXiv:1902.06667, 10.48550/arXiv.1902.06667]
   Hwang JJ, 2019, IMAGNG SCI DENT, V49, P1, DOI 10.5624/isd.2019.49.1.1
   Kondo T, 2004, IEEE T MED IMAGING, V23, P350, DOI 10.1109/TMI.2004.824235
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li YJ, 2017, Arxiv, DOI arXiv:1511.05493
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Ma Q, 2020, COMPUT GRAPH FORUM, V39, P267, DOI 10.1111/cgf.14143
   Ma Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P723, DOI 10.1145/3292500.3330982
   Micheli A, 2009, IEEE T NEURAL NETWOR, V20, P498, DOI 10.1109/TNN.2008.2010350
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, 10.48550/arXiv.1609.02907]
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Shah S, 2006, 2006 BIOMETRICS SYMPOSIUM: SPECIAL SESSION ON RESEARCH AT THE BIOMETRIC CONSORTIUM CONFERENCE, P137
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wada K., 2020, PROC IEEECVF C COMPU, P14540
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wei GS, 2022, COMPUT AIDED GEOM D, V94, DOI 10.1016/j.cagd.2022.102077
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xiaoshuang Li, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P105, DOI 10.1007/978-3-030-59716-0_11
   Xu XJ, 2019, IEEE T VIS COMPUT GR, V25, P2336, DOI 10.1109/TVCG.2018.2839685
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yang LC, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417771
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0_37
   Zanjani FG, 2019, LECT NOTES COMPUT SC, V11768, P128, DOI 10.1007/978-3-030-32254-0_15
   Zhan G, 2020, Adv Neural Inf Process Syst, V33, P6315
   Zhang SB, 2021, PROC CVPR IEEE, P1065, DOI 10.1109/CVPR46437.2021.00112
NR 49
TC 0
Z9 0
U1 5
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1457
EP 1469
DI 10.1109/TVCG.2022.3218028
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300012
PM 36315543
DA 2024-11-06
ER

PT J
AU Yuan, J
   Barr, B
   Overton, K
   Bertini, E
AF Yuan, Jun
   Barr, Brian
   Overton, Kyle
   Bertini, Enrico
TI Visual Exploration of Machine Learning Model Behavior With Hierarchical
   Surrogate Rule Sets
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Decision trees; Data models; Behavioral sciences; Analytical models;
   Predictive models; Feature extraction; Data visualization;
   Visualization; rule set; surrogate model; model understanding
ID INTERPRETABILITY; VISUALIZATION; EXTRACTION
AB One of the potential solutions for model interpretation is to train a surrogate model: a more transparent model that approximates the behavior of the model to be explained. Typically, classification rules or decision trees are used due to their logic-based expressions. However, decision trees can grow too deep, and rule sets can become too large to approximate a complex model. Unlike paths on a decision tree that must share ancestor nodes (conditions), rules are more flexible. However, the unstructured visual representation of rules makes it hard to make inferences across rules. In this paper, we focus on tabular data and present novel algorithmic and interactive solutions to address these issues. First, we present Hierarchical Surrogate Rules (HSR), an algorithm that generates hierarchical rules based on user-defined parameters. We also contribute SuRE, a visual analytics (VA) system that integrates HSR and an interactive surrogate rule visualization, the Feature-Aligned Tree, which depicts rules as trees while aligning features for easier comparison. We evaluate the algorithm in terms of parameter sensitivity, time performance, and comparison with surrogate decision trees and find that it scales reasonably well and overcomes the shortcomings of surrogate decision trees. We evaluate the visualization and the system through a usability study and an observational study with domain experts. Our investigation shows that the participants can use feature-aligned trees to perform non-trivial tasks with very high accuracy. We also discuss many interesting findings, including a rule analysis task characterization, that can be used for visualization design and future research.
C1 [Yuan, Jun] NYU, New York 10012, NY USA.
   [Barr, Brian; Overton, Kyle] Capital One, Mclean, VA 22102 USA.
   [Bertini, Enrico] Northeastern Univ, Boston, MA 02115 USA.
C3 New York University; Northeastern University
RP Yuan, J (corresponding author), NYU, New York 10012, NY USA.
EM junyuan@nyu.edu; brian.barr@capitalone.com; kyle.overton@capitalone.com;
   e.bertini@northeastern.edu
RI Bertini, Enrico/ABG-1278-2020
OI Yuan, Jun/0000-0003-1952-5221; Bertini, Enrico/0000-0002-9932-0551;
   Barr, Brian/0000-0002-4424-3448
FU Capital One Financial Corporation
FX No Statement Available
CR Agrawal R., 1994, P 20 INT C VER LARG, V1215, P487
   Augasta MG, 2012, NEURAL PROCESS LETT, V35, P131, DOI 10.1007/s11063-011-9207-8
   Bastani O, 2019, Arxiv, DOI arXiv:1705.08504
   Bénard C, 2021, ELECTRON J STAT, V15, P427, DOI 10.1214/20-EJS1792
   Cameron AC, 1997, J ECONOMETRICS, V77, P329
   Cohen WW, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P335
   Craven MW, 1996, ADV NEUR IN, V8, P24
   Dash S., 2018, Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS'18, page, P4660
   Di Castro F., 2019, P IUI WORKSH
   Estivill-Castro V, 2020, IEEE SYS MAN CYBERN, P3852, DOI [10.1109/SMC42975.2020.9283240, 10.1109/smc42975.2020.9283240]
   FICO, 2018, Explainable machine learning challenge
   Flach PA, 2001, MACH LEARN, V42, P61, DOI 10.1023/A:1007656703224
   Frank E., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P144
   Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148
   Gobe S.J., 1993, QUAL HEALTH RES, V3, P430, DOI DOI 10.1177/104973239300300403
   Goix Nicolas, 2020, Zenodo, DOI 10.5281/ZENODO.4316671
   Guidotti R, 2018, Arxiv, DOI arXiv:1805.10820
   Hastie T.J., 1990, Statistical Science
   Hohman F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300809
   Thiagarajan JJ, 2016, Arxiv, DOI arXiv:1611.07429
   Lakkaraju H, 2017, Arxiv, DOI [arXiv:1707.01154, 10.48550/arXiv.1707.01154]
   Lakkaraju H, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P131, DOI 10.1145/3306618.3314229
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   Lundberg SM, 2017, ADV NEUR IN, V30
   Messalas A, 2019, INT CONF INFORM INTE, P220, DOI 10.1109/iisa.2019.8900669
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Molnar C., 2022, Interpretable machine learning: A Guide for Making Black Box Models Explainable, V2
   Molnar C., 2018, J Open Source Software, V3, P786, DOI [10.21105/joss.00786, DOI 10.21105/JOSS.00786]
   Narayanan M., 2018, arXiv
   Neto MP, 2020, Arxiv, DOI arXiv:2005.04289
   Pal NR, 2001, IEEE T SYST MAN CY B, V31, P745, DOI 10.1109/3477.956036
   Pei J., 2000, P 2000 ACM SIGMOD IN, V4, P21
   Poursabzi-Sangdeh F, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445315
   Quinlan J.R., 1987, P 10 INT JOINT C ART, V1, P304, DOI [10.5555/1625015.1625078, DOI 10.5555/1625015.1625078]
   Rajapaksha D, 2020, INFORM SCIENCES, V540, P221, DOI 10.1016/j.ins.2020.05.126
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Smith J. W., 1988, Proceedings. The Twelfth Annual Symposium on Computer Applications in Medical Care (IEEE Cat. No.88CH2616-1), P261
   Sza Danielle Albers, 2018, Interactions, V25, P26, DOI [DOI 10.1145/32317721, 10.1145/3231772, DOI 10.1145/3231772]
   Tam GKL, 2017, IEEE T VIS COMPUT GR, V23, P71, DOI 10.1109/TVCG.2016.2598829
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   Velmurugan Mythreyi, 2021, Intelligent Information Systems. CAiSE Forum 2021. Proceedings. Lecture Notes in Business Information Processing (LNBIP 424), P64, DOI 10.1007/978-3-030-79108-7_8
   Wang F, 2015, JMLR WORKSH CONF PRO, V38, P1013
   Wang T, 2017, J MACH LEARN RES, V18, P1
   Yang F., 2021, P ADV NEUR INF PROC
   Yuan J., 2021, An exploration and validation of visual factors in understanding classification rule sets
   Zarlenga M.E., 2021, arXiv, DOI DOI 10.48550/ARXIV.2111.12628
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
   Zilke JR, 2016, LECT NOTES ARTIF INT, V9956, P457, DOI 10.1007/978-3-319-46307-0_29
NR 51
TC 2
Z9 2
U1 2
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1470
EP 1488
DI 10.1109/TVCG.2022.3219232
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300006
PM 36327192
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Xu, X
   Wang, L
   Pérard-Gayot, A
   Membarth, R
   Li, CY
   Yang, CL
   Slusallek, P
AF Xu, Xiang
   Wang, Lu
   Perard-Gayot, Arsene
   Membarth, Richard
   Li, Cuiyu
   Yang, Chenglei
   Slusallek, Philipp
TI Temporal Coherence-Based Distributed Ray Tracing of Massive Scenes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Ray tracing; Portals; Heuristic
   algorithms; Dynamic scheduling; Task analysis; Distributed databases;
   Computer graphics; distributed graphics; ray tracing
ID CACHE
AB Distributed ray tracing algorithms are widely used when rendering massive scenes, where data utilization and load balancing are the keys to improving performance. One essential observation is that rays are temporally coherent, which indicates that temporal information can be used to improve computational efficiency. In this paper, we use temporal coherence to optimize the performance of distributed ray tracing. First, we propose a temporal coherence-based scheduling algorithm to guide the task/data assignment and scheduling. Then, we propose a virtual portal structure to predict the radiance of rays based on the previous frame, and send the rays with low radiance to a precomputed simplified model for further tracing, which can dramatically reduce the traversal complexity and the overhead of network data transmission. The approach was validated on scenes of sizes up to 355 GB. Our algorithm can achieve a speedup of up to 81% compared to previous algorithms, with a very small mean squared error.
C1 [Xu, Xiang] Shandong Univ Finance & Econ, Shandong Key Lab Blockchain Finance, Jinan 250101, Shandong, Peoples R China.
   [Wang, Lu; Yang, Chenglei] Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
   [Perard-Gayot, Arsene] Weta Digital, Wellington 6243, New Zealand.
   [Membarth, Richard] TH Ingolstadt THI, Res Inst AImot Bavaria, D-85049 Ingolstadt, Germany.
   [Membarth, Richard; Slusallek, Philipp] Saarland Informat Campus, German Res Ctr Artificial Intelligence DFKI, D-66123 Saarbrucken, Saarland, Germany.
   [Li, Cuiyu] Adv Comp East China Subctr, Suzhou 215300, Jiangsu, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University; German
   Research Center for Artificial Intelligence (DFKI)
RP Wang, L (corresponding author), Shandong Univ, Sch Software, Jinan 250101, Shandong, Peoples R China.
EM xuxiang8420@outlook.com; luwang_hcivr@sdu.edu.cn;
   aperardgayot@wetafx.co.nz; Richard.Membarth@thi.de; lxyystn@126.com;
   chl_yang@sdu.edu.cn; philipp.slusallek@dfki.de
RI 徐, 翔/KOC-9548-2024
OI xu, xiang/0000-0002-9570-0784; Slusallek, Philipp/0000-0002-2189-2429
FU National Key R#x0026;D Program of China
FX No Statement Available
CR Abram G, 2018, SYMP LARG DATA ANAL, P72, DOI 10.1109/LDAV.2018.8739241
   [Anonymous], 2017, ACM SIGGRAPH 2017 TA
   BADOUEL D, 1994, IEEE COMPUT GRAPH, V14, P69, DOI 10.1109/38.291533
   Budge B, 2009, COMPUT GRAPH FORUM, V28, P385, DOI 10.1111/j.1467-8659.2009.01378.x
   DeMarle DavidE., 2004, EGPGV, P93
   DeMarle DE, 2005, PARALLEL COMPUT, V31, P221, DOI 10.1016/j.parco.2005.02.007
   DeMarle DE, 2003, PVG 2003 PROCEEDINGS, P87, DOI 10.1109/PVGS.2003.1249046
   Djeu P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2019627.2019634
   Eisenacher C, 2013, COMPUT GRAPH FORUM, V32, P125, DOI 10.1111/cgf.12158
   Fussell C., 2012, EUR S PAR GRAPH VIS, P61
   Gassenbauer V, 2009, COMPUT GRAPH FORUM, V28, P1189, DOI 10.1111/j.1467-8659.2009.01496.x
   Green S. A., 1990, Visual Computer, V6, P62, DOI 10.1007/BF01901067
   Gropp W., 1994, Using MPI: Portable Parallel Programming with the Message-Passing Interface
   Howison M., 2010, P EUR S PAR GRAPH VI, P1
   Howison M, 2012, IEEE T VIS COMPUT GR, V18, P17, DOI 10.1109/TVCG.2011.24
   Kato T., 2002, Fourth Eurographics Workshop on Parallel Graphics and Visualization, P7
   Kobayashi H., 1988, Visual Computer, V4, P197, DOI 10.1007/BF01887592
   Larsen M, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P276, DOI 10.1109/SC.2016.23
   Matt J., 2016, Physically Based Rendering, V3rd
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Moon B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805972
   Müller T, 2017, COMPUT GRAPH FORUM, V36, P91, DOI 10.1111/cgf.13227
   Navrátil PA, 2014, IEEE T VIS COMPUT GR, V20, P893, DOI 10.1109/TVCG.2013.261
   Park H, 2018, SYMP LARG DATA ANAL, P77, DOI 10.1109/LDAV.2018.8739224
   Pérard-Gayot A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322955
   Pharr M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P101, DOI 10.1145/258734.258791
   Plachetka T, 2003, Event -driven message passing and parallel simulation of global illumination
   Plachetka T, 2004, P 5 EUR C PAR GRAPH, P101
   Reinhard E., 1999, Proceedings 1999 IEEE Parallel Visualization and Graphics Symposium (Cat. No.99EX381), P21, DOI 10.1109/PVGS.1999.810135
   Son M, 2017, HPG '17: PROCEEDINGS OF HIGH PERFORMANCE GRAPHICS, DOI 10.1145/3105762.3105784
   Studio B, 2020, Agent 327-blender cloud
   Wald I, 2001, SPRING EUROGRAP, P277
   Wald I, 2022, Arxiv, DOI arXiv:2204.10170
   Ward G, 1999, ACM T GRAPHIC, V18, P361, DOI 10.1145/337680.337722
   Yoon SE, 2006, VISUAL COMPUT, V22, P772, DOI 10.1007/s00371-006-0062-y
   Zellmann S., 2020, P EUR S PAR GRAPH VI, P1
   Zhu JQ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459798
NR 37
TC 0
Z9 0
U1 3
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1489
EP 1501
DI 10.1109/TVCG.2022.3219982
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300010
PM 36342995
DA 2024-11-06
ER

PT J
AU Prasad, V
   van Sloun, RJG
   Elzen, SV
   Vilanova, A
   Pezzotti, N
AF Prasad, Vidya
   van Sloun, Ruud J. G.
   Elzen, Stef van den
   Vilanova, Anna
   Pezzotti, Nicola
TI The <i>Transform-and-Perform</i> Framework: Explainable Deep Learning
   Beyond Classification
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; explainable AI; framework; deep learning;
   high-dimensional-to-high-dimensional translation; XAI
ID VISUAL ANALYTICS; INTERACTIVE ANALYSIS
AB In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&P with a real-world image-to-image translation application. We illustrate how T&P effectively supports the understanding and identification of potential gaps in existing VA systems.
C1 [Prasad, Vidya; Elzen, Stef van den; Vilanova, Anna; Pezzotti, Nicola] Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 AZ Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.] Eindhoven Univ Technol, Dept Elect Engn, NL-5612 AZ Eindhoven, Netherlands.
   [van Sloun, Ruud J. G.; Pezzotti, Nicola] Philips Res, NL-5656 AE Eindhoven, Netherlands.
C3 Eindhoven University of Technology; Eindhoven University of Technology;
   Philips; Philips Research
RP Prasad, V (corresponding author), Eindhoven Univ Technol, Dept Math & Comp Sci, NL-5600 AZ Eindhoven, Netherlands.
EM v.prasad@tue.nl; r.j.g.v.sloun@tue.nl; s.j.v.d.elzen@tue.nl;
   a.vilanova@tue.nl; n.pezzotti@tue.nl
RI van Sloun, Ruud/AGX-0436-2022
OI van Sloun, Ruud JG/0000-0003-2845-0495; van den Elzen,
   Stef/0000-0003-1245-0503; Vilanova, Anna/0000-0002-1034-737X; Prasad,
   Vidya/0000-0002-9296-3693
CR [Anonymous], 2017, Facets-know your data
   Barbu A, 2019, ADV NEUR IN, V32
   Buongiorno D, 2021, NEUROCOMPUTING, V452, P549, DOI 10.1016/j.neucom.2020.06.139
   Caballero HSG, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13667
   Cashman D, 2020, IEEE T VIS COMPUT GR, V26, P863, DOI 10.1109/TVCG.2019.2934261
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Cohen TS, 2016, PR MACH LEARN RES, V48
   D'Amour A, 2020, Arxiv, DOI [arXiv:2011.03395, DOI 10.48550/ARXIV.2011.03395]
   Darestani MZ, 2021, PR MACH LEARN RES, V139
   Das N, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P271, DOI 10.1109/VIS47514.2020.00061
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L., 2012, IEEE Signal Process. Mag, V29, P141, DOI [10.1109/MSP.2012.2211477, DOI 10.1109/MSP.2012.2211477]
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Ghorbani A, 2020, ADV NEUR IN, V33
   Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095
   Hamid S., 2019, P OF 2 WORKSHOP MACH, P19
   Han X, 2017, MED PHYS, V44, P1408, DOI 10.1002/mp.12155
   Harfiya LN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21092952
   Haskins G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01060-x
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hendrycks D., 2019, P INT C LEARN REPR
   Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Huang XY, 2021, COMPUT GRAPH FORUM, V40, P227, DOI 10.1111/cgf.14302
   Hund Michael, 2016, Brain Inform, V3, P233, DOI 10.1007/s40708-016-0043-5
   Iwana BK, 2019, IEEE INT CONF COMP V, P4176, DOI 10.1109/ICCVW.2019.00513
   Jacobsen J., 2019, P INT C LEARN REPR
   Jaderberg M, 2015, ADV NEUR IN, V28
   Janik A., 2019, P C MACH LEARN METH
   Jeong S, 2022, COMPUT GRAPH FORUM, V41, P85, DOI 10.1111/cgf.14524
   Jia Y, 2019, INTERSPEECH, P1123, DOI 10.21437/Interspeech.2019-1951
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kaji S, 2019, RADIOL PHYS TECHNOL, V12, P235, DOI 10.1007/s12194-019-00520-y
   Kastryulin S, 2022, Arxiv, DOI [arXiv:2203.07809, 10.1109/ACCESS.2023.3243466]
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kindlmann G, 2014, IEEE T VIS COMPUT GR, V20, P2181, DOI 10.1109/TVCG.2014.2346325
   Krause J, 2017, IEEE CONF VIS ANAL, P162, DOI 10.1109/VAST.2017.8585720
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Li G, 2021, IEEE T VIS COMPUT GR, V27, P1364, DOI 10.1109/TVCG.2020.3030461
   Li H., 2018, PROC 32 ADV NEURAL I
   Lin DJ, 2021, J MAGN RESON IMAGING, V53, P1015, DOI 10.1002/jmri.27078
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Bronstein MMM, 2021, Arxiv, DOI arXiv:2104.13478
   Ma YX, 2021, IEEE T VIS COMPUT GR, V27, P1385, DOI 10.1109/TVCG.2020.3028888
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   McNutt A, 2021, COMPUT GRAPH FORUM, V40, P61, DOI 10.1111/cgf.14289
   Montavon G, 2018, DIGIT SIGNAL PROCESS, V73, P1, DOI 10.1016/j.dsp.2017.10.011
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nikolov Stanislav, 2021, J Med Internet Res, V23, pe26151, DOI 10.2196/26151
   Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670
   Park C., 2021, P EUR C VIS
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Pezzotti N, 2017, IEEE T VIS COMPUT GR, V23, P1739, DOI 10.1109/TVCG.2016.2570755
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, 10.48550/ARXIV.1511.06434]
   Raidou R. G., 2016, P EG VIS COMP BIOL M, P193
   Rauber PE, 2017, IEEE T VIS COMPUT GR, V23, P101, DOI 10.1109/TVCG.2016.2598838
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Sacha D, 2017, NEUROCOMPUTING, V268, P164, DOI 10.1016/j.neucom.2017.01.105
   Schlegel U., 2020, P INT WORKSH MACH LE, P7
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sietzen S, 2021, COMPUT GRAPH FORUM, V40, P253, DOI 10.1111/cgf.14418
   Smilkov D., 2016, P NEUR INF PROC SYST
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   van Sloun RJG, 2020, P IEEE, V108, P11, DOI 10.1109/JPROC.2019.2932116
   van Wijk JJ, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P79
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wexler J, 2020, IEEE T VIS COMPUT GR, V26, P56, DOI 10.1109/TVCG.2019.2934619
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Zbontar J, 2019, Arxiv, DOI [arXiv:1811.08839, 10.48550/arXiv.1811.08839]
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JP, 2017, Arxiv, DOI arXiv:1706.09092
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 79
TC 3
Z9 3
U1 3
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1502
EP 1515
DI 10.1109/TVCG.2022.3219248
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300001
PM 36327191
OA Green Published
DA 2024-11-06
ER

PT J
AU Giovannangeli, L
   Lalanne, F
   Auber, D
   Giot, R
   Bourqui, R
AF Giovannangeli, Loann
   Lalanne, Frederic
   Auber, David
   Giot, Romain
   Bourqui, Romain
TI Toward Efficient Deep Learning for Graph Drawing (DL4GD)
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Graph drawing; Deep learning; Task analysis; Training;
   Measurement; Computational modeling; deep learning; graph neural
   network; graph convolution
ID LAYOUTS
AB Due to their great performance in many challenges, Deep Learning (DL) techniques keep gaining popularity in many fields. They have been adapted to process graph data structures to solve various complicated tasks such as graph classification and edge prediction. Eventually, they reached the Graph Drawing (GD) task. This article is an extended version of the previously published (DNN)(2) and presents a framework to leverage DL techniques for graph drawing (DL4GD). We demonstrate how it is possible to train a Deep Learning model to extract features from a graph and project them into a graph layout. The method proposes to leverage efficient Convolutional Neural Networks, adapting them to graphs using Graph Convolutions. The graph layout projection is learned by optimizing a cost function that does not require any ground truth layout, as opposed to prior work. This paper also proposes an implementation and benchmark of the framework to study its sensitivity to certain deep learning-related conditions. As the field is novel, and many questions remain to be answered, we do not focus on finding the most optimal implementation of the method, but rather contribute toward a better understanding of the approach potential. More precisely, we study different learning strategies relative to the models training datasets. Finally, we discuss the main advantages and limitations of DL4GD.
C1 [Giovannangeli, Loann; Lalanne, Frederic; Auber, David; Giot, Romain; Bourqui, Romain] Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
C3 Inria; Universite de Bordeaux; Centre National de la Recherche
   Scientifique (CNRS)
RP Bourqui, R (corresponding author), Univ Bordeaux, CNRS, Bordeaux INP, INRIA,LaBRI,UMR 5800, F-33400 Talence, France.
EM Loann.Giovannangeli@u-bordeaux.fr; Frederic.Lalanne@u-bordeaux.fr;
   David.Auber@u-bordeaux.fr; Romain.Giot@u-bordeaux.fr;
   Romain.Bourqui@u-bordeaux.fr
RI Giot, Romain/F-6747-2011
OI Giovannangeli, Loann/0000-0002-9395-6495; Giot,
   Romain/0000-0002-0638-7504; Auber, David/0000-0002-1114-8612
FU Nouvelle-Aquitaine Region Project
FX No Statement Available
CR Abu-El-Haija S, 2020, PR MACH LEARN RES, V115, P841
   Ahmed R, 2020, Arxiv, DOI arXiv:2008.05584
   [Anonymous], 2000, GRAPH CLUSTERING FLO
   Auber David, 2018, Encyclopedia of Social Network Analysis and Mining, P3185, DOI [10.1007/978-1-4939-7131-2315, DOI 10.1007/978-1-4939-7131-2315]
   Bourqui, 2021, LNCS, P375, DOI [10.1007/978303092931227, DOI 10.1007/978303092931227]
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Bruna J, 2014, Arxiv, DOI arXiv:1312.6203
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467
   Defferrard M, 2017, Arxiv, DOI [arXiv:1606.09375, 10.48550/arXiv.1606.09375]
   Espadoto M, 2020, INFORM VISUAL, V19, P247, DOI 10.1177/1473871620909485
   Frick A., 1994, INT S GRAPH DRAW, P388, DOI [10.1007/3-540-58950-3_393, DOI 10.1007/3-540-58950-3_393]
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gutwenger C, 1998, LECT NOTES COMPUT SC, V1547, P167
   Haleem H, 2019, IEEE COMPUT GRAPH, V39, P40, DOI 10.1109/MCG.2018.2881501
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YF, 2012, IEEE PAC VIS SYMP, P33, DOI 10.1109/PacificVis.2012.6183571
   Jankun-Kelly TJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P59, DOI 10.1109/INFVIS.2003.1249009
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Kingma DP, 2014, ADV NEUR IN, V27
   Klimenta M., 2012, P INT S GRAPH DRAW, P55
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Kwon OH, 2018, IEEE T VIS COMPUT GR, V24, P478, DOI 10.1109/TVCG.2017.2743858
   Meidiana A, 2021, IEEE PAC VIS SYMP, P146, DOI 10.1109/PacificVis52677.2021.00027
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, 10.48550/arXiv.1609.02907]
   NEMENYI P, 1962, BIOMETRICS, V18, P263
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Purchase HC, 1996, LECT NOTES COMPUT SC, V1027, P435, DOI 10.1007/BFb0021827
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tiezzi M, 2024, IEEE T NEUR NET LEAR, V35, P4668, DOI 10.1109/TNNLS.2022.3184967
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P., 2017, ARXIV
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang XQ, 2021, IEEE COMPUT GRAPH, V41, P32, DOI 10.1109/MCG.2021.3093908
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P676, DOI 10.1109/TVCG.2019.2934798
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Ware C., 2002, Information Visualization, V1, P103, DOI 10.1057/palgrave.ivs.95000/3
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xie Y, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105578
   Xu K., 2019, 7 INT C LEARN REPR I
   Leow YY, 2019, Arxiv, DOI arXiv:1904.06915
   You JX, 2019, PR MACH LEARN RES, V97
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 53
TC 2
Z9 2
U1 1
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1516
EP 1532
DI 10.1109/TVCG.2022.3222186
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300008
PM 36378788
OA Green Published
DA 2024-11-06
ER

PT J
AU Qiu, R
   Tu, YM
   Wang, YS
   Yen, PY
   Shen, HW
AF Qiu, Rui
   Tu, Yamei
   Wang, Yu-Shuen
   Yen, Po-Yin
   Shen, Han-Wei
TI DocFlow: A Visual Analytics System for Question-Based Document Retrieval
   and Categorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Systematics; Visual analytics; Task analysis; Semantics; Human in the
   loop; Natural languages; Bit error rate; Biomedical systematic review;
   evidence-based-practice; human-in-the-loop information retrieval;
   question-based document categorization; question-based document
   retrieval
ID SCIENTIFIC LITERATURE; VISUALIZATION; METAANALYSES; GUIDELINES; REVIEWS
AB A systematic review (SR) is essential with up-to-date research evidence to support clinical decisions and practices. However, the growing literature volume makes it challenging for SR reviewers and clinicians to discover useful information efficiently. Many human-in-the-loop information retrieval approaches (HIR) have been proposed to rank documents semantically similar to users' queries and provide interactive visualizations to facilitate document retrieval. Given that the queries are mainly composed of keywords and keyphrases retrieving documents that are semantically similar to a query does not necessarily respond to the clinician's need. Clinicians still have to review many documents to find the solution. The problem motivates us to develop a visual analytics system, DocFlow, to facilitate information-seeking. One of the features of our DocFlow is accepting natural language questions. The detailed description enables retrieving documents that can answer users' questions. Additionally, clinicians often categorize documents based on their backgrounds and with different purposes (e.g., populations, treatments). Since the criteria are unknown and cannot be pre-defined in advance, existing methods can only achieve categorization by considering the entire information in documents. In contrast, by locating answers in each document, our DocFlow can intelligently categorize documents based on users' questions. The second feature of our DocFlow is a flexible interface where users can arrange a sequence of questions to customize their rules for document retrieval and categorization. The two features of this visual analytics system support a flexible information-seeking process. The case studies and the feedback from domain experts demonstrate the usefulness and effectiveness of our DocFlow.
C1 [Qiu, Rui; Tu, Yamei; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Wang, Yu-Shuen] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Yen, Po-Yin] Washington Univ, Inst Informat, Sch Med, St Louis, MO 63110 USA.
C3 University System of Ohio; Ohio State University; National Yang Ming
   Chiao Tung University; Washington University (WUSTL)
RP Qiu, R (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM qiu.580@buckeyemail.osu.edu; tu.253@osu.edu; yushuen@cs.nctu.edu.tw;
   yenp@wustl.edu; shen.94@osu.edu
RI Tu, Yamei/KSL-7529-2024; Shen, Han-wei/A-4710-2012; wang,
   yiting/GYU-5306-2022
OI Qiu, Rui/0000-0002-3905-8926; Wang, Yu-Shuen/0000-0003-2550-2990; Tu,
   Yamei/0000-0002-0722-837X; Shen, Han-Wei/0000-0002-1211-2320
CR Amati G., 2009, BM25, P257, DOI 10.1007/978- 0-387- 39940-9 921
   Barbosa O., 2017, EvidenceSET: A tool for supporting analysis of evidence and synthesis of primary and secondary studies
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Borlund P., 2013, J. Inf. Sci. Theory Pract., V1
   Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154
   Choe K, 2021, IEEE PAC VIS SYMP, P176, DOI 10.1109/PacificVis52677.2021.00037
   Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929
   Dai ZY, 2019, Arxiv, DOI arXiv:1910.10687
   Dattolo A, 2022, IEEE ACCESS, V10, P21631, DOI 10.1109/ACCESS.2022.3153027
   Dehghani M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/3077136.3080832
   Despins LA, 2018, CIN-COMPUT INFORM NU, V36, P323, DOI 10.1097/CIN.0000000000000430
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dias AG, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345401
   Dreisbach C, 2019, INT J MED INFORM, V125, P37, DOI 10.1016/j.ijmedinf.2019.02.008
   Federico P, 2017, IEEE T VIS COMPUT GR, V23, P2179, DOI 10.1109/TVCG.2016.2610422
   Haddaway NR, 2018, ENVIRON INT, V114, P357, DOI 10.1016/j.envint.2018.02.018
   Hassan H.A.M., 2019, P ACM RECSYS 2019 LA, V2431, P6
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Heimerl F, 2016, IEEE T VIS COMPUT GR, V22, P190, DOI 10.1109/TVCG.2015.2467621
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Humaira H., 2018, P 2 WORKSH MULT APPL, DOI [10.4108/eai.24-1-2018.2292388, DOI 10.4108/EAI.24-1-2018.2292388]
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P771, DOI 10.1109/TVCG.2016.2598827
   Ji XN, 2017, J BIOMED INFORM, V69, P33, DOI 10.1016/j.jbi.2017.03.007
   Ji Xiaonan, 2015, AMIA Annu Symp Proc, V2015, P1927
   Johnson J, 2017, Arxiv, DOI [arXiv:1702.08734, 10.48550/arXiv.1702.08734]
   Joshi M, 2017, Arxiv, DOI arXiv:1705.03551
   Kim M, 2017, IEEE T VIS COMPUT GR, V23, P151, DOI 10.1109/TVCG.2016.2598445
   Martinic MK, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0855-0
   Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288
   Lee EK, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01330-8
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lee Y, 2018, HEALTHC INFORM RES, V24, P157, DOI 10.4258/hir.2018.24.3.157
   Wang LL, 2020, Arxiv, DOI [arXiv:2004.10706, 10.48550/arXiv.2004.10706]
   Dai AM, 2015, Arxiv, DOI arXiv:1507.07998
   Manchikanti L, 2009, PAIN PHYSICIAN, V12, P929
   McClellan E. N. M. B., 2008, Evidence-Based Medicine and the Changing Nature of Health Care: Meeting Summary IOM Roundtable on Evidence-Based Medicine
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Mitra B, 2016, Arxiv, DOI arXiv:1602.01137
   Munshi NC, 2011, CLIN CANCER RES, V17, P1234, DOI 10.1158/1078-0432.CCR-10-1843
   Narechania A, 2022, IEEE T VIS COMPUT GR, V28, P486, DOI 10.1109/TVCG.2021.3114820
   Pai M, 2004, NATL MED J INDIA, V17, P86
   Palpacuer C, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1409-3
   Pampari A, 2018, Arxiv, DOI arXiv:1809.00732
   Pocco X, 2021, SIBGRAPI, P136, DOI 10.1109/SIBGRAPI54419.2021.00027
   Ponsard Antoine, 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, CHI EA 16, P2264, DOI 10.1145/2851581
   Portenoy J, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501905
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Rachamallu V, 2019, AM J THER, V26, pE406, DOI 10.1097/MJT.0000000000000894
   Radford A., 2019, Language models are unsupervised multitask learners, V1, P9
   Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250
   Riehmann P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P233, DOI 10.1109/INFVIS.2005.1532152
   Rossanez A, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01341-5
   Schardt C, 2007, BMC MED INFORM DECIS, V7, DOI 10.1186/1472-6947-7-16
   Shen Y., 2014, P 23 ACM INT C CONFE, V2014, P101
   Tendal B, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b3128
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   van Eck NJ, 2017, SCIENTOMETRICS, V111, P1053, DOI 10.1007/s11192-017-2300-7
   WANOUS JP, 1989, J APPL PSYCHOL, V74, P259, DOI 10.1037/0021-9010.74.2.259
   Wu Y, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000007349
   Yang Jianji J, 2008, AMIA Annu Symp Proc, P825
   Zheng GQ, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P575, DOI 10.1145/2766462.2767700
NR 62
TC 1
Z9 1
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1533
EP 1548
DI 10.1109/TVCG.2022.3219762
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300005
PM 36331645
DA 2024-11-06
ER

PT J
AU Neto, MP
   Paulovich, FV
AF Neto, Mario Popolin
   Paulovich, Fernando V.
TI Multivariate Data Explanation by Jumping Emerging Patterns Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data explanation; jumping emerging patterns; random decision trees;
   exploratory analysis
ID INTERACTIVE VISUAL ANALYSIS; GENERATION; DISCOVERY; SPACE
AB Multivariate or multidimensional visualization plays an essential role in exploratory data analysis by allowing users to derive insights and formulate hypotheses. Despite their popularity, it is usually users' responsibility to (visually) discover the data patterns, which can be cumbersome and time-consuming. Visual Analytics (VA) and machine learning techniques can be instrumental in mitigating this problem by automatically discovering and representing such patterns. One example is the integration of classification models with (visual) interpretability strategies, where models are used as surrogates for data patterns so that understanding a model enables understanding the phenomenon represented by the data. Although useful and inspiring, the few proposed solutions are based on visual representations of so-called black-box models, so the interpretation of the patterns captured by the models is not straightforward, requiring mechanisms to transform them into human-understandable pieces of information. This paper presents multiVariate dAta eXplanation (VAX), a new VA method to support identifying and visual interpreting patterns in multivariate datasets. Unlike the existing similar approaches, VAX uses the concept of Jumping Emerging Patterns, inherent interpretable logic statements representing class-variable relationships (patterns) derived from random Decision Trees. The potential of VAX is shown through use cases employing two real-world datasets covering different scenarios where intricate patterns are discovered and represented, something challenging to be done using usual exploratory approaches.
C1 [Neto, Mario Popolin] Univ Sao Paulo, Fed Inst Sao Paulo IFSP, BR-05508060 Sao Paulo, Brazil.
   [Paulovich, Fernando V.] Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
C3 Universidade de Sao Paulo; Instituto Federal de Sao Paulo (IFSP);
   Eindhoven University of Technology
RP Paulovich, FV (corresponding author), Eindhoven Univ Technol, NL-5600 MB Eindhoven, Netherlands.
EM mariopopolin@ifsp.edu.br; f.paulovich@tue.nl
RI Popolin Neto, Mário/AFI-8722-2022; Paulovich, Fernando/G-1329-2010
OI Paulovich, Fernando/0000-0002-2316-760X; Popolin Neto,
   Mario/0000-0002-8379-2458
FU Qualification Program of the Federal Institute of Sao Paulo (IFSP)
FX The authors wish to thank the valuable comments and suggestions obtained
   from the reviewers, as well as the supportreceived from the
   Qualification Program of the Federal Institute of Sao Paulo (IFSP).
CR Anwar N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND COMPUTATIONAL INTELLIGENCE (CYBERNETICSCOM), P11, DOI 10.1109/CYBERNETICSCOM.2017.8311714
   Bernard J, 2014, COMPUT GRAPH FORUM, V33, P291, DOI 10.1111/cgf.12385
   Biau G, 2016, TEST-SPAIN, V25, P197, DOI 10.1007/s11749-016-0481-7
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boulesteix AL, 2003, BIOINFORMATICS, V19, P2465, DOI 10.1093/bioinformatics/btg361
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cao F, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P256, DOI 10.1109/VIS47514.2020.00058
   Cao N, 2011, IEEE T VIS COMPUT GR, V17, P2581, DOI 10.1109/TVCG.2011.188
   Chan G. Y.-Y., 2020, MELODY GENERATING VI
   Chen CH, 2004, COMPSTAT 2004: PROCEEDINGS IN COMPUTATIONAL STATISTICS, P85
   Correll M, 2019, IEEE T VIS COMPUT GR, V25, P830, DOI 10.1109/TVCG.2018.2864907
   de Silva V., 2004, Sparse multidimensional scaling using landmark points
   Di Castro F., 2019, P IUI WORKSH
   Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI [DOI 10.1145/312129.312191, 10.1145/312129., DOI 10.1145/312129, 10.1145/312129.312191]
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   FREEDMAN D, 1981, Z WAHRSCHEINLICHKEIT, V57, P453, DOI 10.1007/BF01025868
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Furnkranz J., 2012, Foundations of rule learning
   Gamberger D., 2002, P INT WORKSH INT DAT, P31
   García-Borroto M, 2015, EXPERT SYST APPL, V42, P4859, DOI 10.1016/j.eswa.2015.02.028
   García-Vico AM, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1231
   Gleicher M, 2013, IEEE T VIS COMPUT GR, V19, P2042, DOI 10.1109/TVCG.2013.157
   Goodwin S, 2016, IEEE T VIS COMPUT GR, V22, P599, DOI 10.1109/TVCG.2015.2467199
   Guidotti R, 2018, Arxiv, DOI arXiv:1805.10820
   Helliwell J. F., 2019, World Happiness Report 2019
   Huysmans J, 2011, DECIS SUPPORT SYST, V51, P141, DOI 10.1016/j.dss.2010.12.003
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jeong DH, 2009, COMPUT GRAPH FORUM, V28, P767, DOI 10.1111/j.1467-8659.2009.01475.x
   Kane B, 2015, LECT NOTES ARTIF INT, V9077, P722, DOI 10.1007/978-3-319-18038-0_56
   Keim D., 2010, Mastering the Information Age Solving Problems with Visual Analytics, DOI DOI 10.2312/14803
   Knittel J, 2021, IEEE T VIS COMPUT GR, V27, P1374, DOI 10.1109/TVCG.2020.3030420
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Lakkaraju H, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1675, DOI 10.1145/2939672.2939874
   Law PM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P171, DOI 10.1109/VIS47514.2020.00041
   Li Jie, 2023, IEEE Trans Vis Comput Graph, V29, P723, DOI 10.1109/TVCG.2022.3209382
   Li JY, 2004, DATA MIN KNOWL DISC, V9, P89, DOI 10.1023/B:DAMI.0000026901.85057.58
   Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590
   Liu Qiangqiang, 2023, IEEE Trans Vis Comput Graph, V29, P701, DOI 10.1109/TVCG.2022.3209463
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Loekito E, 2009, LECT NOTES ARTIF INT, V5476, P483, DOI 10.1007/978-3-642-01307-2_44
   Loyola-González O, 2020, J GRID COMPUT, V18, P797, DOI 10.1007/s10723-020-09526-y
   Loyola-González O, 2019, INFORM FUSION, V46, P91, DOI 10.1016/j.inffus.2018.05.004
   Lundberg SM, 2017, ADV NEUR IN, V30
   Malik A, 2012, IEEE CONF VIS ANAL, P33, DOI 10.1109/VAST.2012.6400491
   May T., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P111, DOI 10.1109/VAST.2011.6102448
   Mazumdar D, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222862
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Michalski R., 1982, Machine Learning, V10
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Miranda TZ, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113811
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Novak PK, 2009, J MACH LEARN RES, V10, P377
   Paja W, 2018, LECT NOTES ARTIF INT, V10933, P230, DOI 10.1007/978-3-319-95786-9_17
   Paulovich FV, 2010, IEEE T VIS COMPUT GR, V16, P1281, DOI 10.1109/TVCG.2010.207
   Pérez D, 2015, NEUROCOMPUTING, V150, P611, DOI 10.1016/j.neucom.2014.09.061
   Piringer H, 2008, IEEE INT CONF INF VI, P240, DOI 10.1109/IV.2008.17
   Popolin Neto M, 2021, IEEE T VIS COMPUT GR, V27, P1427, DOI 10.1109/TVCG.2020.3030354
   Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sacha D, 2014, IEEE T VIS COMPUT GR, V20, P1604, DOI 10.1109/TVCG.2014.2346481
   Salman R, 2012, IEEE SOUTHEASTCON
   Talbot J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1283
   Tan PN., 2005, Introduction to Data Mining
   Teoh S.T., 2003, 9 ACM SIGKDD INT C K, P667
   Tompson T., 2018, AP votecast 2018
   Dang TN, 2014, IEEE PAC VIS SYMP, P73, DOI 10.1109/PacificVis.2014.42
   Turkay C, 2012, IEEE T VIS COMPUT GR, V18, P2621, DOI 10.1109/TVCG.2012.256
   van den Elzen S., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P151, DOI 10.1109/VAST.2011.6102453
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang JP, 2023, IEEE T VIS COMPUT GR, V29, P3809, DOI 10.1109/TVCG.2022.3172107
   Wang LS, 2005, THEOR COMPUT SCI, V335, P15, DOI 10.1016/j.tcs.2004.12.014
   Wu H.M., 2008, Handbook of Data Visualization, P681
   Yamamoto CH, 2007, ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P87, DOI 10.1109/ICMLA.2007.45
   Yamamoto CH, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1212
   Yuan XR, 2013, IEEE T VIS COMPUT GR, V19, P2625, DOI 10.1109/TVCG.2013.150
   Zhang ZY, 2015, IEEE T VIS COMPUT GR, V21, P289, DOI 10.1109/TVCG.2014.2350494
   Zhao X, 2019, IEEE T VIS COMPUT GR, V25, P407, DOI 10.1109/TVCG.2018.2864475
NR 80
TC 6
Z9 6
U1 1
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1549
EP 1563
DI 10.1109/TVCG.2022.3223529
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300003
PM 36409810
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gray, K
   Li, MW
   Ahmed, R
   Rahman, MK
   Azad, A
   Kobourov, S
   Borner, K
AF Gray, Kathryn
   Li, Mingwei
   Ahmed, Reyan
   Rahman, Md. Khaledur
   Azad, Ariful
   Kobourov, Stephen
   Borner, Katy
TI A Scalable Method for Readable Tree Layouts
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Force-directed; readability; tree layouts
ID VISUALIZATION; GRAPHS
AB Large tree structures are ubiquitous and real-world relational datasets often have information associated with nodes (e.g., labels or other attributes) and edges (e.g., weights or distances) that need to be communicated to the viewers. Yet, scalable, easy to read tree layouts are difficult to achieve. We consider tree layouts to be readable if they meet some basic requirements: node labels should not overlap, edges should not cross, edge lengths should be preserved, and the output should be compact. There are many algorithms for drawing trees, although very few take node labels or edge lengths into account, and none optimizes all requirements above. With this in mind, we propose a new scalable method for readable tree layouts. The algorithm guarantees that the layout has no edge crossings and no label overlaps, and optimizes one of the remaining aspects: desired edge lengths and compactness. We evaluate the performance of the new algorithm by comparison with related earlier approaches using several real-world datasets, ranging from a few thousand nodes to hundreds of thousands of nodes. Tree layout algorithms can be used to visualize large general graphs, by extracting a hierarchy of progressively larger trees. We illustrate this functionality by presenting several map-like visualizations generated by the new tree layout algorithm.
C1 [Gray, Kathryn; Li, Mingwei; Ahmed, Reyan; Kobourov, Stephen] Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
   [Rahman, Md. Khaledur; Azad, Ariful] Indiana Univ, Dept Comp Sci, Bloomington, IN 47405 USA.
   [Borner, Katy] Indiana Univ, SLIS, Bloomington, IN 47408 USA.
C3 University of Arizona; Indiana University System; Indiana University
   Bloomington; Indiana University System; Indiana University Bloomington
RP Ahmed, R (corresponding author), Univ Arizona, Dept Comp Sci, Tucson, AZ 85721 USA.
EM ryngray@email.arizona.edu; mwli@email.arizona.edu;
   abureyanahmed@email.arizona.edu; morahma@iu.edu; azad@iu.edu;
   kobourov@cs.arizona.edu; katy@indiana.edu
RI Rahman, Khaledur/N-9843-2019; Kobourov, Stephen/A-3016-2008
OI Kobourov, Stephen/0000-0002-0477-2724; Borner, Katy/0000-0002-3321-6137;
   Ahmed, Reyan/0000-0001-6830-9053
FU NSF
FX No Statement Available
CR Ahmed R., 2019, ACM J. Exp. Algorithmics, V24
   [Anonymous], 2020, OpenLayers
   Arleo A, 2019, IEEE T PARALL DISTR, V30, P754, DOI 10.1109/TPDS.2018.2869805
   Bachmaier C, 2005, LECT NOTES COMPUT SC, V3827, P1110, DOI 10.1007/11602613_110
   Ballen CJ, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001630
   Bastian M, 2009, P INT AAAI C WEBL SO, V3, P361, DOI 10.13140/2.1.1341.1520
   BAVELAS A, 1950, J ACOUST SOC AM, V22, P723
   Blanch R, 2015, IEEE PAC VIS SYMP, P31, DOI 10.1109/PACIFICVIS.2015.7156353
   Bonacich P, 2007, SOC NETWORKS, V29, P555, DOI 10.1016/j.socnet.2007.04.002
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyack KW, 2005, SCIENTOMETRICS, V64, P351, DOI 10.1007/s11192-005-0255-6
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Burd K., 2018, P C ADV VIS INT, p31:1
   Chandra L., 2001, Parallel Programming in OpenMP
   Chimani Markus., 2011, Handbook of graph drawing and visualization, P543
   Choi JH, 2000, BIOINFORMATICS, V16, P1056, DOI 10.1093/bioinformatics/16.11.1056
   EADES P, 1990, DISCRETE APPL MATH, V28, P111, DOI 10.1016/0166-218X(90)90110-X
   Eades Peter, 1984, Congr Numer, V42, P149
   Efrat A, 2010, ACM T SENSOR NETWORK, V7, DOI 10.1145/1807048.1807057
   Ellson J, 2002, LECT NOTES COMPUT SC, V2265, P483
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gajer P., 2004, Computational Geometry: Theory and Applications, V29, P3
   Gansner E., 2009, Proceedings of the ACM Conference on Recommender Systems, P345, DOI [10.1145/1639714.1639784, DOI 10.1145/1639714.1639784]
   Gansner ER, 2010, IEEE PAC VIS SYMP, P201, DOI 10.1109/PACIFICVIS.2010.5429590
   Gansner ER, 2009, LECT NOTES COMPUT SC, V5417, P206, DOI 10.1007/978-3-642-00219-9_20
   Gansner ER, 1998, LECT NOTES COMPUT SC, V1547, P364
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Hadany R, 2001, DISCRETE APPL MATH, V113, P3, DOI 10.1016/S0166-218X(00)00389-9
   Nguyen QH, 2018, Arxiv, DOI arXiv:1801.07008
   Hu Yifan, 2005, Mathematica J., V10, P37
   Hug LA, 2016, NAT MICROBIOL, V1, DOI [10.1038/NMICROBIOL.2016.48, 10.1038/nmicrobiol.2016.48]
   Kittivorawong C, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P101, DOI 10.1109/VIS47514.2020.00027
   Kobak D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13056-x
   Kobourov S.G., 2014, EUROVIS SHORT PAPERS
   Koren Y, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P137, DOI 10.1109/INFVIS.2002.1173159
   Leow T., 2019, P WORKSH REPRESENTAT, P1
   Letunic I, 2021, NUCLEIC ACIDS RES, V49, pW293, DOI 10.1093/nar/gkab301
   Luboschik M, 2008, IEEE T VIS COMPUT GR, V14, P1237, DOI 10.1109/TVCG.2008.152
   Marriott K, 2003, CONSTRAINTS, V8, P143, DOI 10.1023/A:1022371615202
   McGuffin MJ, 2010, INFORM VISUAL, V9, P115, DOI 10.1057/ivs.2009.4
   Mote K., 2007, Information Visualization, V6, P249, DOI DOI 10.1057/PALGRAVE.IVS.9500163
   Nachmanson L, 2016, LECT NOTES COMPUT SC, V9801, P33, DOI 10.1007/978-3-319-50106-2_3
   Nguyen QV, 2002, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2002, P85, DOI 10.1109/INFVIS.2002.1173152
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Purchase H. C., 2002, Empirical Software Engineering, V7, P233, DOI 10.1023/A:1016344215610
   Rahman MK, 2020, IEEE DATA MINING, P442, DOI 10.1109/ICDM50108.2020.00053
   Rahman MK, 2020, IEEE PAC VIS SYMP, P16, DOI 10.1109/PacificVis48177.2020.3756
   REINGOLD EM, 1981, IEEE T SOFTWARE ENG, V7, P223, DOI 10.1109/TSE.1981.234519
   Schulz H. -J., 2015, P 17 EUR C VIS, P1
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Sun D, 2005, PROG COMPREHEN, P317
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wiese R, 2004, MATH VIS, P173
   Zager LA, 2008, APPL MATH LETT, V21, P86, DOI 10.1016/j.aml.2007.01.006
NR 55
TC 2
Z9 3
U1 1
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1564
EP 1578
DI 10.1109/TVCG.2023.3274572
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300011
PM 37159326
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gan, WS
   Xu, HB
   Huang, Y
   Chen, SF
   Yokoya, N
AF Gan, Wanshui
   Xu, Hongbin
   Huang, Yi
   Chen, Shifeng
   Yokoya, Naoto
TI V4D: Voxel for 4D Novel View Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Rendering (computer graphics); Table lookup;
   Task analysis; Solid modeling; Geometry; Computational efficiency;
   Neural radiance field; novel view synthesis; neural rendering; 4D
   representation; look-up tables
AB Neural radiance fields have made a remarkable breakthrough in the novel view synthesis task at the 3D static scene. However, for the 4D circumstance (e.g., dynamic scene), the performance of the existing method is still limited by the capacity of the neural network, typically in a multilayer perceptron network (MLP). In this article, we utilize 3D Voxel to model the 4D neural radiance field, short as V4D, where the 3D voxel has two formats. The first one is to regularly model the 3D space and then use the sampled local 3D feature with the time index to model the density field and the texture field by a tiny MLP. The second one is in look-up tables (LUTs) format that is for the pixel-level refinement, where the pseudo-surface produced by the volume rendering is utilized as the guidance information to learn a 2D pixel-level refinement mapping. The proposed LUTs-based refinement module achieves the performance gain with little computational cost and could serve as the plug-and-play module in the novel view synthesis task. Moreover, we propose a more effective conditional positional encoding toward the 4D data that achieves performance gain with negligible computational burdens. Extensive experiments demonstrate that the proposed method achieves state-of-the-art performance at a low computational cost.
C1 [Gan, Wanshui; Yokoya, Naoto] Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.
   [Gan, Wanshui; Yokoya, Naoto] RIKEN Ctr Adv Intelligence Project AIP, Geoinformat Team, Tokyo 1030027, Japan.
   [Xu, Hongbin] South China Univ Technol, Guangzhou 510641, Guangdong, Peoples R China.
   [Xu, Hongbin] Alibaba Grp, Hangzhou 311121, Zhejiang, Peoples R China.
   [Huang, Yi; Chen, Shifeng] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab Comp Vis & Pattern Recognit, Shenzhen 518055, Guangdong, Peoples R China.
   [Huang, Yi; Chen, Shifeng] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
C3 University of Tokyo; RIKEN; South China University of Technology;
   Alibaba Group; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Yokoya, N (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, Chiba 2778561, Japan.; Yokoya, N (corresponding author), RIKEN Ctr Adv Intelligence Project AIP, Geoinformat Team, Tokyo 1030027, Japan.
EM 1850255222@edu.k.u-tokyo.ac.jp; hongbinxu1013@gmail.com;
   yi.huang@siat.ac.cn; shifeng.chen@siat.ac.cn; yokoya@k.u-tokyo.ac.jp
RI Yokoya, Naoto/AAC-1530-2022; Xu, Hongbin/I-6309-2019
OI Huang, Yi/0000-0002-8443-6877; Xu, Hongbin/0000-0002-3455-1527; Gan,
   Wanshui/0000-0002-6720-6500
FU JST, FOREST
FX No Statement Available
CR Andersson P, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406183
   Barron JT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5835, DOI 10.1109/ICCV48922.2021.00580
   Cai HR, 2022, Arxiv, DOI arXiv:2206.15258
   CHABRA ROHAN, 2020, COMPUTER VISION ECCV, P608
   Chen AP, 2022, Arxiv, DOI arXiv:2203.09517
   Chen AP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14104, DOI 10.1109/ICCV48922.2021.01386
   Chibane J, 2021, PROC CVPR IEEE, P7907, DOI 10.1109/CVPR46437.2021.00782
   Fang J., 2022, arXiv
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gao C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5692, DOI 10.1109/ICCV48922.2021.00566
   Garbin Stephan J, 2021, P IEEE CVF INT C COM
   Gu J., 2020, Advances in Neural Information Processing Systems, V33, P15651
   Guo X, 2022, Arxiv, DOI arXiv:2206.07698
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Kingma DP, 2014, ADV NEUR IN, V27
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Lassner Christoph, 2021, arXiv
   Li JX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12558, DOI 10.1109/ICCV48922.2021.01235
   Li Shuhang, 2022, P IEEE CVF C COMP VI
   Li TY, 2022, Arxiv, DOI arXiv:2103.02597
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Lindell DB, 2021, PROC CVPR IEEE, P14551, DOI 10.1109/CVPR46437.2021.01432
   Liu Y., 2021, arXiv
   Lombardi S, 2019, Arxiv, DOI arXiv:1906.07751
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Neff T., 2021, COMPUT GRAPH FORUM, V40, P45, DOI [10.1111/cgf.14340, DOI 10.1111/CGF.14340]
   Niemeyer M, 2019, IEEE I CONF COMP VIS, P5378, DOI 10.1109/ICCV.2019.00548
   Oechsle M, 2021, Arxiv, DOI arXiv:2104.10078
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Peng S., 2020, ECCV, P523
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Rematas K, 2022, PROC CVPR IEEE, P12922, DOI 10.1109/CVPR52688.2022.01259
   Shao R., 2021, arXiv
   Shechtman Y, 2015, IEEE SIGNAL PROC MAG, V32, P87, DOI 10.1109/MSP.2014.2352673
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tancik M, 2022, PROC CVPR IEEE, P8238, DOI 10.1109/CVPR52688.2022.00807
   Tretschk E, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12939, DOI 10.1109/ICCV48922.2021.01272
   Trevithick A., 2021, P IEEE CVF INT C COM, p15 182
   Wang P, 2021, 35 C NEURAL INFORM P, V34
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wang T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2451, DOI 10.1109/ICCV48922.2021.00247
   Wei Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5590, DOI 10.1109/ICCV48922.2021.00556
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Xian WQ, 2021, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR46437.2021.00930
   Xiangli Y., 2021, arXiv
   Yao G., 2021, arXiv
   Yariv L, 2021, ADV NEUR IN
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5732, DOI 10.1109/ICCV48922.2021.00570
   Yuille A, 2006, TRENDS COGN SCI, V10, P301, DOI 10.1016/j.tics.2006.05.002
   Zeng H, 2022, IEEE T PATTERN ANAL, V44, P2058, DOI 10.1109/TPAMI.2020.3026740
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhi SF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15818, DOI 10.1109/ICCV48922.2021.01554
NR 60
TC 2
Z9 2
U1 3
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1579
EP 1591
DI 10.1109/TVCG.2023.3312127
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300007
PM 37669213
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lei, F
   Fan, AR
   Maceachren, AM
   Maciejewski, R
AF Lei, Fan
   Fan, Arlen
   Maceachren, Alan M.
   Maciejewski, Ross
TI GeoLinter: A Linting Framework for Choropleth Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Image color analysis; Geology; Recommender systems;
   Guidelines; Bars; Visualization; Choropleth maps; visualization linting;
   automated visualization design; visualization recommendation
ID COLOR SCHEMES; SELECTION
AB Visualization linting is a proven effective tool in assisting users to follow established visualization guidelines. Despite its success, visualization linting for choropleth maps, one of the most popular visualizations on the internet, has yet to be investigated. In this paper, we present GeoLinter, a linting framework for choropleth maps that assists in creating accurate and robust maps. Based on a set of design guidelines and metrics drawing upon a collection of best practices from the cartographic literature, GeoLinter detects potentially suboptimal design decisions and provides further recommendations on design improvement with explanations at each step of the design process. We perform a validation study to evaluate the proposed framework's functionality with respect to identifying and fixing errors and apply its results to improve the robustness of GeoLinter. Finally, we demonstrate the effectiveness of the GeoLinter - validated through empirical studies - by applying it to a series of case studies using real-world datasets.
C1 [Lei, Fan; Fan, Arlen; Maciejewski, Ross] Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
   [Maceachren, Alan M.] Penn State Univ, State Coll, PA 16801 USA.
C3 Arizona State University; Arizona State University-Tempe; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); Pennsylvania State
   University
RP Maciejewski, R (corresponding author), Arizona State Univ, Sch Comp Informat & Decis Syst Engn, Tempe, AZ 85281 USA.
EM flei5@asu.edu; afan5@asu.edu; maceachren@psu.edu; rmacieje@asu.edu
RI Lei, Fan/KFB-0896-2024
OI Fan, Arlen/0000-0002-8376-2881; Lei, Fan/0000-0003-4244-0971
FU National Science Foundation
FX No Statement Available
CR A. of American Geographers U. C. for Geographic Information Science M. C. T. Force and B. of Knowledge Advisory Board, 2006, Geographic information science and technology body of knowledge
   [Anonymous], 1995, Cartographica, DOI DOI 10.3138/J610-13NU-5537-0483
   [Anonymous], 2015, Int. J. Cartography
   Anselin L., 2010, HDB APPL SPATIAL ANA, P73, DOI [10.1007/978-3-642-03647-7_5, DOI 10.1007/978-3-642-03647-7_5]
   Anselin L., 2020, Contiguity -based spatial weights
   ArcGIS Pro 3.1 Esri, 2023, ArcGIS Pro geoprocessing tool reference, spatial autocorrelation (global Moran's I)(spatial statistics)
   Barowy DW, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276518
   Barowy DW, 2014, ACM SIGPLAN NOTICES, V49, P507, DOI [10.1145/2714064.2660207, 10.1145/2660193.2660207]
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brewer CA, 1997, ANN ASSOC AM GEOGR, V87, P411, DOI 10.1111/1467-8306.00061
   Brewer CA, 2002, ANN ASSOC AM GEOGR, V92, P662, DOI 10.1111/1467-8306.00310
   Brychtová A, 2017, CARTOGR GEOGR INF SC, V44, P229, DOI 10.1080/15230406.2016.1140074
   Brychtova A, 2016, CARTOGR J, V53, P202, DOI 10.1179/1743277414Y.0000000103
   Chang KT, 2008, Introduction to Geographic Information Systems, V4
   Chen Q, 2022, IEEE T VIS COMPUT GR, V28, P206, DOI 10.1109/TVCG.2021.3114804
   CLEVELAND WS, 1983, AM STAT, V37, P101, DOI 10.2307/2685868
   Declerq F, 1995, P 17 C 10 GEN ASS IN, P918
   Dent B. D., 1999, Cartography: Thematic Map Design
   Duke D, 2001, P ACM INT C P SER, P11
   Duque JC, 2012, J REGIONAL SCI, V52, P397, DOI 10.1111/j.1467-9787.2011.00743.x
   EVANS IS, 1977, T I BRIT GEOGR, V2, P98, DOI 10.2307/622195
   Golebiowska IM, 2022, IEEE T VIS COMPUT GR, V28, P2722, DOI 10.1109/TVCG.2020.3035823
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Hegarty M., 2009, CARTOGRAPHICA, V44, P171, DOI DOI 10.3138/CARTO.44.3.171
   Hopkins AK, 2020, COMPUT GRAPH FORUM, V39, P219, DOI 10.1111/cgf.13975
   JENKS GF, 1971, ANN ASSOC AM GEOGR, V61, P217, DOI 10.1111/j.1467-8306.1971.tb00779.x
   Jiang B, 2013, PROF GEOGR, V65, P482, DOI 10.1080/00330124.2012.700499
   Kang C., 2003, P ANN NAT C DIG GOV, P1
   Kessler FC, 2017, LECT NOTES GEOINF CA, P117, DOI 10.1007/978-3-319-51835-0_4
   Kraak F., 2020, Cartography: Visualization of GeospatialData
   LASKOWSKI PH, 1989, AM CARTOGRAPHER, V16, P123, DOI 10.1559/152304089783875497
   León GM, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P91, DOI 10.1109/VIS47514.2020.00025
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Lin H, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376880
   MCGRANAGHAN M, 1989, AM CARTOGRAPHER, V16, P279, DOI 10.1559/152304089783813918
   McNutt G., 2018, P 2 WORKSH CREAT CUR, P1
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/0033-295X.101.2.343
   MORAN PAP, 1950, BIOMETRIKA, V37, P17, DOI 10.1093/biomet/37.1-2.17
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Muslu Kivanc, 2015, INT S SOFTWARE TESTI, P373, DOI [10.1145/27717 83.2771792, DOI 10.1145/2771783.2771792, 10.1145/2771783.2771792]
   Perry D. B., 2013, P ISCHOOL C
   Qian X, 2020, Arxiv, DOI arXiv:2009.12316
   Rey SJ, 2022, GEOGR ANAL, V54, P467, DOI 10.1111/gean.12276
   Satopaa V., 2011, Proceedings of the 2011 31st International Conference on Distributed Computing Systems Workshops (ICDCS Workshops), P166, DOI 10.1109/ICDCSW.2011.20
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savric B, 2019, INT J GEOGR INF SCI, V33, P454, DOI 10.1080/13658816.2018.1504949
   Savric B, 2016, CARTOGR J, V53, P177, DOI 10.1080/00087041.2015.1131938
   Savric B, 2011, CARTOGR GEOGR INF SC, V38, P363, DOI 10.1559/15230406384363
   Schiewe J., 2019, KN-Journal of Cartography and Geographic Information, V69, P217, DOI [DOI 10.1007/S42489-019-00026-Y, DOI 10.1007/S42489-019-00026-Y4]
   Slocum T.A., 2014, Thematic Cartography and Geovisualisation
   SMITH RM, 1986, PROF GEOGR, V38, P62, DOI 10.1111/j.0033-0124.1986.00062.x
   Snyder J. P, 1982, Tech. Rep. 1354
   SNYDER JP, 1978, ANN ASSOC AM GEOGR, V68, P373, DOI 10.1111/j.1467-8306.1978.tb01201.x
   Stern B., 2011, Geographic Inf. Technol. Training Alliance
   Stone Maureen, 2014, FIN PROGR P IS T SID, P253, DOI [10.2352/CIC.2014.22.1.ART000453,9, DOI 10.2352/CIC.2014.22.1.ART000453,9]
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Usery LE., 2001, Cartography and Geographic Information Science, V28(3), P183
   Wills G, 2010, INFORM VISUAL, V9, P47, DOI 10.1057/ivs.2008.27
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Xiao NC, 2006, GEOGR ANAL, V38, P102, DOI 10.1111/j.0016-7363.2005.00678.x
   Zhang YF, 2017, IEEE T VIS COMPUT GR, V23, P371, DOI 10.1109/TVCG.2016.2598541
NR 62
TC 1
Z9 1
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1592
EP 1607
DI 10.1109/TVCG.2023.3322372
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300009
PM 37801373
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Neuhauser, C
   Stumpfegger, J
   Westermann, R
AF Neuhauser, Christoph
   Stumpfegger, Josef
   Westermann, Ruediger
TI Adaptive Sampling of 3D Spatial Correlations for Focus plus Context
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Correlation; Three-dimensional displays; Meteorology; Visualization;
   Graphics processing units; Layout; Weather forecasting; Chord diagrams;
   correlation sampling; ensemble analysis
ID VISUAL ANALYSIS; ENSEMBLE; UNCERTAINTY; SENSITIVITY; TOOL
AB Visualizing spatial correlations in 3D ensembles is challenging due to the vast amounts of information that need to be conveyed. Memory and time constraints make it unfeasible to pre-compute and store the correlations between all pairs of domain points. We propose the embedding of adaptive correlation sampling into chord diagrams with hierarchical edge bundling to alleviate these constraints. Entities representing spatial regions are arranged along the circular chord layout via a space-filling curve, and Bayesian optimal sampling is used to efficiently estimate the maximum occurring correlation between any two points from different regions. Hierarchical edge bundling reduces visual clutter and emphasizes the major correlation structures. By selecting an edge, the user triggers a focus diagram in which only the two regions connected via this edge are refined and arranged in a specific way in a second chord layout. For visualizing correlations between two different variables, which are not symmetric anymore, we switch to showing a full correlation matrix. This avoids drawing the same edges twice with different correlation values. We introduce GPU implementations of both linear and non-linear correlation measures to further reduce the time that is required to generate the context and focus views, and to even enable the analysis of correlations in a 1000-member ensemble.
C1 [Neuhauser, Christoph; Stumpfegger, Josef; Westermann, Ruediger] Tech Univ Munich, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Neuhauser, C (corresponding author), Tech Univ Munich, D-80333 Munich, Germany.
EM christoph.neuhauser@tum.de; ga87tux@mytum.de; westermann@tum.de
OI Neuhauser, Christoph/0000-0002-0290-1991; Westermann,
   Rudiger/0000-0002-3394-0731
CR Ancell B, 2007, MON WEATHER REV, V135, P4117, DOI 10.1175/2007MWR1904.1
   Chen CK, 2011, IEEE PAC VIS SYMP, P27, DOI 10.1109/PACIFICVIS.2011.5742369
   Dalelane C, 2023, EARTH SYST DYNAM, V14, P17, DOI 10.5194/esd-14-17-2023
   Demir I., 2016, P S VIS NEW YORK NY, P1, DOI DOI 10.1145/3002151.3002165
   Farokhmanesh F., 2023, Modeling Vision, and Visualization
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Hazarika S, 2018, IEEE T VIS COMPUT GR, V24, P934, DOI 10.1109/TVCG.2017.2744099
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Kumpf A, 2019, IEEE T VIS COMPUT GR, V25, P98, DOI 10.1109/TVCG.2018.2864901
   Necker T, 2020, Q J ROY METEOR SOC, V146, P1423, DOI 10.1002/qj.3744
   Nocke T, 2015, NONLINEAR PROC GEOPH, V22, P545, DOI 10.5194/npg-22-545-2015
   Obermaier H, 2014, IEEE COMPUT GRAPH, V34, P8, DOI 10.1109/MCG.2014.52
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Rautenhaus M, 2015, GEOSCI MODEL DEV, V8, P2329, DOI 10.5194/gmd-8-2329-2015
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Torn RD, 2008, MON WEATHER REV, V136, P663, DOI 10.1175/2007MWR2132.1
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P2853, DOI 10.1109/TVCG.2018.2853721
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Wilks DS, 2016, B AM METEOROL SOC, V97, P2263, DOI 10.1175/BAMS-D-15-00267.1
NR 20
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1608
EP 1623
DI 10.1109/TVCG.2023.3326855
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300004
PM 37874723
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Leon, GM
   Isenberg, P
   Breiter, A
AF Leon, Gabriela Molina
   Isenberg, Petra
   Breiter, Andreas
TI Eliciting Multimodal and Collaborative Interactions for Data Exploration
   on Large Vertical Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Collaborative work; elicitation study; large vertical
   displays; multimodal interaction; spatio-temporal data
ID INFORMATION VISUALIZATION; AUGMENTED REALITY; TOUCH; WALL; MANIPULATION;
   SPEECH; MOBILE; PEN
AB We examined user preferences to combine multiple interaction modalities for collaborative interaction with data shown on large vertical displays. Large vertical displays facilitate visual data exploration and allow the use of diverse interaction modalities by multiple users at different distances from the screen. Yet, how to offer multiple interaction modalities is a non-trivial problem. We conducted an elicitation study with 20 participants that generated 1015 interaction proposals combining touch, speech, pen, and mid-air gestures. Given the opportunity to interact using these four modalities, participants preferred speech interaction in 10 of 15 low-level tasks and direct manipulation for straightforward tasks such as showing a tooltip or selecting. In contrast to previous work, participants most favored unimodal and personal interactions. We identified what we call collaborative synonyms among their interaction proposals and found that pairs of users collaborated either unimodally and simultaneously or multimodally and sequentially. We provide insights into how end-users associate visual exploration tasks with certain modalities and how they collaborate at different interaction distances using specific interaction modalities.(1)
C1 [Leon, Gabriela Molina; Breiter, Andreas] Univ Bremen, D-28359 Bremen, Germany.
   [Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, LISN, F-91405 Orsay, France.
C3 University of Bremen; Universite Paris Saclay; Inria; Centre National de
   la Recherche Scientifique (CNRS); Universite Paris Cite; Microsoft
RP Leon, GM (corresponding author), Univ Bremen, D-28359 Bremen, Germany.
EM molina@uni-bremen.de; petra.isenberg@inria.fr; abreiter@uni-bremen.de
RI Breiter, Andreas/P-4859-2016
OI Isenberg, Petra/0000-0002-2948-6417; Molina Leon, Gabriela
   C./0000-0002-9223-2022
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
FX No Statement Available
CR Abras D., 2004, Encyclope-dia of Human-Computer Interaction, V37, P445
   Ali Abdullah, 2021, P 2021 CHI C HUMAN F, DOI 10.1145/3411764.3445758
   Andrews C, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P55
   Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6
   Andrienko N., 2006, Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach
   [Anonymous], 2014, Proceedings of The International Symposium on Pervasive Displays - PerDis'14, DOI [DOI 10.1145/2611009.2611028, 10.1145/2611009.2611028]
   Badam S. K., 2017, P 2 WORKSH IMM AN
   Badam SK, 2016, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST.2016.7883506
   Ball R, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P191
   Baudisch P., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P31, DOI 10.1145/502348.502354
   Bezerianos A, 2012, IEEE T VIS COMPUT GR, V18, P2516, DOI 10.1109/TVCG.2012.251
   Bongshin Lee, 2021, Foundations and Trends in Human-Computer Interaction, V14, P1, DOI 10.1561/1100000081
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Buxton W., 1995, Readings in Human-Computer Interaction, P494
   Dostal J., 2014, Proceedings of the International Conference on Intelligent User Interfaces, P143, DOI DOI 10.1145/2557500.2557541
   Drucker S.M., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '13, P2301
   G. Foundation, 2022, Free data via gapminder.org, cc -by license
   Guimbretiere F., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P21, DOI 10.1145/502348.502353
   Herholz L. L., 2008, 13 INT FALL WORKSH V, P101
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Hinckley Ken, 2010, P 23 ANN ACM S US IN, P27, DOI [DOI 10.1145/1866029.1866036, DOI 10.1145/1866029.18660362]
   Hinrichs U, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3023
   Horak T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173593
   Isenberg P., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P179, DOI 10.1109/VAST.2010.5652880
   Isenberg P, 2011, INFORM VISUAL, V10, P310, DOI 10.1177/1473871611412817
   Isenberg P, 2009, IEEE COMPUT GRAPH, V29, P44, DOI 10.1109/MCG.2009.78
   Isenberg P, 2009, COMPUT GRAPH FORUM, V28, P1031, DOI 10.1111/j.1467-8659.2009.01444.x
   Jakobsen MR, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2576099
   Jakobsen MR, 2013, IEEE T VIS COMPUT GR, V19, P2386, DOI 10.1109/TVCG.2013.166
   Kister U, 2017, COMPUT GRAPH FORUM, V36, P503, DOI 10.1111/cgf.13206
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Langner R, 2019, IEEE T VIS COMPUT GR, V25, P608, DOI 10.1109/TVCG.2018.2865235
   Lee B, 2015, IEEE PAC VIS SYMP, P199, DOI 10.1109/PACIFICVIS.2015.7156378
   León GM, 2022, COMPUT GRAPH FORUM, V41, P417, DOI 10.1111/cgf.14551
   Liu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6730, DOI 10.1145/3025453.3025594
   Mignot Christophe., 1993, INTERACT 93 CHI 93 C, P67, DOI DOI 10.1145/259964.260075
   Morris M. R., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1201
   Morris Meredith Ringel, 2012, P 2012 ACM INT C INT, P95, DOI DOI 10.1145/2396636.2396651
   Morris Meredith Ringel, 2014, Interactions, V21, P40, DOI DOI 10.1145/2591689
   Nacenta Miguel A, 2013, P SIGCHI C HUM FACT, P1099, DOI DOI 10.1145/2470654.2466142
   Nancel M, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P177
   Nebeling Michael, 2014, P 9 ACM INT C INT TA, P15, DOI [DOI 10.1145/2669485.2669497, 10.1145/2669485.2669497]
   Oviatt A., 1997, Referring Phenomena Multimedia Context Their Comput. Treat., P1
   Oviatt S, 1999, COMMUN ACM, V42, P74, DOI 10.1145/319382.319398
   Perera M, 2021, IEEE SYS MAN CYBERN, P2576, DOI 10.1109/SMC52423.2021.9658673
   Plotly, 2022, Plotly express in python
   Prouzeau A, 2017, IEEE T VIS COMPUT GR, V23, P1936, DOI 10.1109/TVCG.2016.2592906
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Riehmann P, 2020, COMPUT GRAPH FORUM, V39, P265, DOI 10.1111/cgf.13979
   Rogers Y, 2004, INTERACT COMPUT, V16, P1133, DOI 10.1016/j.intcom.2004.07.008
   Sadana R, 2016, COMPUT GRAPH FORUM, V35, P261, DOI 10.1111/cgf.12902
   Sadana R, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P265, DOI 10.1145/2598153.2598163
   Saktheeswaran A, 2020, IEEE T VIS COMPUT GR, V26, P2168, DOI 10.1109/TVCG.2020.2970512
   Sassenberg K, 2005, J EXP SOC PSYCHOL, V41, P506, DOI 10.1016/j.jesp.2004.10.002
   Srinivasan A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376782
   Srinivasan A, 2021, IEEE T VIS COMPUT GR, V27, P3519, DOI 10.1109/TVCG.2020.2978050
   T. Y. Channel, 2018, Tableau
   Tsandilas T., 2016, Research Report 1584
   Tsandilas T, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3182168
   Vatavu RD, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3476101
   Vatavu RD, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300454
   Vatavu RD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1325, DOI 10.1145/2702123.2702223
   Villarreal-Narvaez S, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P855, DOI 10.1145/3357236.3395511
   Walny J, 2012, IEEE T VIS COMPUT GR, V18, P2779, DOI 10.1109/TVCG.2012.275
   Willett W., 2014, P EUR C VIS, DOI [10.2312/eurovisshort.20141161, DOI 10.2312/EUROVISSHORT.20141161]
   Williams AS, 2020, MULTIMODAL TECHNOLOG, V4, DOI 10.3390/mti4040088
   Williams AS, 2020, IEEE T VIS COMPUT GR, V26, P3479, DOI 10.1109/TVCG.2020.3023566
   Williams Adam S., CONCISE GUIDE ELICIT
   Wobbrock J.O., 2005, CHI 05 EXTENDED ABST, DOI [DOI 10.1145/1056808.1057043, 10.1145/1056808.1057043]
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
NR 71
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1624
EP 1637
DI 10.1109/TVCG.2023.3323150
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300002
PM 37930918
OA hybrid
DA 2024-11-06
ER

PT J
AU Sisouk, K
   Delon, J
   Tierny, J
AF Sisouk, Keanu
   Delon, Julie
   Tierny, Julien
TI Wasserstein Dictionaries of Persistence Diagrams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ensemble data; persistence diagrams; topological data analysis
ID NONPARAMETRIC MODELS; MORSE COMPLEXES; VISUAL ANALYSIS; CRITICAL-POINTS;
   REEB GRAPHS; UNCERTAINTY; VISUALIZATION; TOPOLOGY; VARIABILITY;
   INTERPOLATION
AB This article presents a computational framework for the concise encoding of an ensemble of persistence diagrams, in the form of weighted Wasserstein barycenters Turner et al. (2014), Vidal et al. (2020) of a dictionary of atom diagrams. We introduce a multi-scale gradient descent approach for the efficient resolution of the corresponding minimization problem, which interleaves the optimization of the barycenter weights with the optimization of the atom diagrams. Our approach leverages the analytic expressions for the gradient of both sub-problems to ensure fast iterations and it additionally exploits shared-memory parallelism. Extensive experiments on public ensembles demonstrate the efficiency of our approach, with Wasserstein dictionary computations in the orders of minutes for the largest examples. We show the utility of our contributions in two applications. First, we apply Wassserstein dictionaries to data reduction and reliably compress persistence diagrams by concisely representing them with their weights in the dictionary. Second, we present a dimensionality reduction framework based on a Wasserstein dictionary defined with a small number of atoms (typically three) and encode the dictionary as a low dimensional simplex embedded in a visual space (typically in 2D). In both applications, quantitative experiments assess the relevance of our framework. Finally, we provide a C++ implementation that can be used to reproduce our results.
C1 [Sisouk, Keanu; Tierny, Julien] Sorbonne Univ, F-75005 Paris, France.
   [Delon, Julie] Univ Paris Cite, F-75006 Paris, France.
C3 Sorbonne Universite; Universite Paris Cite
RP Sisouk, K (corresponding author), Sorbonne Univ, F-75005 Paris, France.
EM Keanu.Sisouk@lip6.fr; julie.delon@u-paris.fr;
   julien.tierny@sorbonneuniversite.fr
RI Delon, Julie/U-5964-2017
OI Delon, Julie/0000-0002-7182-7537
FU European Commission
FX No Statement Available
CR Acharya A, 2015, IEEE PAC VIS SYMP, P271, DOI 10.1109/PACIFICVIS.2015.7156387
   Anderson KL, 2018, LECT NOTES COMPUT SC, V11083, P67, DOI 10.1007/978-3-030-00755-3_8
   Athawale T. M., 2019, arXiv
   Athawale T, 2016, IEEE T VIS COMPUT GR, V22, P777, DOI 10.1109/TVCG.2015.2467958
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Ayachit U., 2015, P 1 WORKSH IN SIT IN, P25, DOI [10.1145/2828612. 2828624, DOI 10.1145/2828612.2828624, 10.1145/2828612.2828624]
   BERTSEKAS DP, 1981, MATH PROGRAM, V21, P152, DOI 10.1007/BF01584237
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bhatia H, 2012, IEEE T VIS COMPUT GR, V18, P1383, DOI 10.1109/TVCG.2011.265
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bin Masood T., 2019, P TOP METH DAT AN VI, VVI, P327
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P139, DOI 10.1109/VISUAL.2003.1250365
   Brown N, 2021, PROCEEDINGS OF URGENTHPC 2021: THE THIRD INTERNATIONAL WORKSHOP ON HPC FOR URGENT DECISION MAKING, P36, DOI 10.1109/UrgentHPC54802.2021.00010
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Cohen-Steiner D, 2010, FOUND COMPUT MATH, V10, P127, DOI 10.1007/s10208-010-9060-6
   Cuturi M., 2013, Advances in Neural Information Processing Systems, V2, P2292
   Cuturi M, 2014, PR MACH LEARN RES, V32, P685
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   Diggle P., 2002, Analysis of longitudinal data
   Doraiswamy H, 2013, IEEE T VIS COMPUT GR, V19, P249, DOI 10.1109/TVCG.2012.115
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H, 2009, Computational Topology An Introduction
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Favelier G., 2016, P IEEE SCIVIS CONT
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Ferstl F, 2016, COMPUT GRAPH FORUM, V35, P221, DOI 10.1111/cgf.12898
   Ferstl F, 2016, IEEE T VIS COMPUT GR, V22, P767, DOI 10.1109/TVCG.2015.2467204
   Forman R., 1998, Advances in mathematics
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Günther D, 2014, COMPUT GRAPH FORUM, V33, P31, DOI 10.1111/cgf.12359
   Gueunet C., 2019, P EUR S PAR GRAPH VI
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Guillou P., 2023, IEEE Trans. Vis. Comput. Graph.
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Hummel M, 2013, IEEE T VIS COMPUT GR, V19, P2743, DOI 10.1109/TVCG.2013.141
   ISO/IEC, 2008, 983200 ISOIEC
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kantorovitch L, 1942, CR ACAD SCI URSS, V37, P199
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Kerber M., 2017, ACM Journal of Experimental Algorithmics, V22
   Kraus M, 2010, IMAGAPP & IVAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING THEORY AND APPLICATIONS AND INTERNATIONAL CONFERENCE ON INFORMATION VISUALIZATION THEORY AND APPLICATIONS, P132
   Kruskal J. B., 1978, SUPS
   Lacombe T, 2018, ADV NEUR IN, V31
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Liebmann T, 2016, COMPUT GRAPH FORUM, V35, P361, DOI 10.1111/cgf.12912
   Maadasamy S, 2012, INT C HIGH PERFORM
   MacEachren A.M., 2005, CARTOGR GOEGR INFOR, V32, P139, DOI [DOI 10.1559/1523040054738936, 10.1559/1523040054738936 10.1559/1523040054738936]
   Maljovec D, 2016, IEEE PAC VIS SYMP, P64, DOI 10.1109/PACIFICVIS.2016.7465252
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Monge G., 1781, Academie Royale des Sci. de Paris
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nauleau F., 2022, P IEEE S LARG DAT AN, P1
   Olejniczak M, 2023, PHYS CHEM CHEM PHYS, V25, P5942, DOI 10.1039/d2cp05893f
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Organizers, 2004, The IEEE SciVis Contest
   Otto M., 2010, CGF, V31, P1045
   Otto M, 2011, IEEE PAC VIS SYMP, P67, DOI 10.1109/PACIFICVIS.2011.5742374
   Pang AT, 1997, VISUAL COMPUT, V13, P370, DOI 10.1007/s003710050111
   Parsa S., 2012, P 28 ANN S COMP GEOM, P269
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   Petz C, 2012, COMPUT GRAPH FORUM, V31, P1045, DOI 10.1111/j.1467-8659.2012.03097.x
   Pfaffelmoser T, 2013, IEEE T VIS COMPUT GR, V19, P1948, DOI 10.1109/TVCG.2013.92
   Pfaffelmoser T, 2012, COMPUT GRAPH FORUM, V31, P1025, DOI 10.1111/j.1467-8659.2012.03095.x
   Pfaffelmoser T, 2011, COMPUT GRAPH FORUM, V30, P951, DOI 10.1111/j.1467-8659.2011.01944.x
   Pöthkow K, 2013, COMPUT GRAPH FORUM, V32, P131, DOI 10.1111/cgf.12100
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Pöthkow K, 2011, IEEE T VIS COMPUT GR, V17, P1393, DOI 10.1109/TVCG.2010.247
   Pont M, 2023, IEEE T VIS COMPUT GR, V29, P1573, DOI 10.1109/TVCG.2022.3215001
   Pont M, 2022, IEEE T VIS COMPUT GR, V28, P291, DOI 10.1109/TVCG.2021.3114839
   Potter Kristin, 2012, IFIP Adv Inf Commun Technol, V377, P226
   Potter K, 2013, IEEE COMPUT GRAPH, V33, P75, DOI 10.1109/MCG.2013.14
   Potter K, 2009, INT CONF DAT MIN WOR, P233, DOI 10.1109/ICDMW.2009.55
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Sanyal J, 2010, IEEE T VIS COMPUT GR, V16, P1421, DOI 10.1109/TVCG.2010.181
   Schlegel S, 2012, IEEE T VIS COMPUT GR, V18, P2305, DOI 10.1109/TVCG.2012.249
   Schmitz MA, 2018, SIAM J IMAGING SCI, V11, P643, DOI 10.1137/17M1140431
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   SINKHORN R, 1967, AM MATH MON, V74, P402, DOI 10.2307/2314570
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Szymczak A, 2013, IEEE T VIS COMPUT GR, V19, P799, DOI 10.1109/TVCG.2012.147
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   Turner Y., 2014, DCG
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Wang B, 2023, IEEE TOPOINVIS
   Whitaker RT, 2013, IEEE T VIS COMPUT GR, V19, P2713, DOI 10.1109/TVCG.2013.143
   Woodruff DP, 2014, FOUND TRENDS THEOR C, V10, P1, DOI 10.1561/0400000060
   Wu KQ, 2013, INT J UNCERTAIN QUAN, V3, P203, DOI 10.1615/Int.J.UncertaintyQuantification.2012003956
   Yan L, 2020, IEEE T VIS COMPUT GR, V26, P832, DOI 10.1109/TVCG.2019.2934242
NR 105
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD FEB
PY 2024
VL 30
IS 2
BP 1638
EP 1651
DI 10.1109/TVCG.2023.3330262
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EC6D7
UT WOS:001136746300013
PM 37930922
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Tian, XZ
   Günther, T
AF Tian, Xingze
   Guenther, Tobias
TI A Survey of Smooth Vector Graphics: Recent Advances in Repr esentation,
   Creation, Rasterization, and Image Vectorization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Graphics; Image color analysis; Shape; Mathematical models; Rendering
   (computer graphics); Splines (mathematics); Solids; Vector graphics;
   diffusion curves; gradient meshes; survey
ID COLOR TRANSFER; DIFFUSION CURVES; INTERPOLATION; SUBDIVISION;
   REPRESENTATION; COLORIZATION; OPTIMIZATION; COMPRESSION; PATCH; SHAPE
AB The field of smooth vector graphics explores the representation, creation, rasterization, and automatic generation of light-weight image representations, frequently used for scalable image content. Over the past decades, several conceptual approaches on the representation of images with smooth gradients have emerged that each led to separate research threads, including the popular gradient meshes and diffusion curves. As the computational models matured, the mathematical descriptions diverged and article started to focus more narrowly on subproblems, such as on the representation and creation of vector graphics, or the automatic vectorization from raster images. Most of the work concentrated on a specific mathematical model only. With this survey, we describe the established computational models in a consistent notation to spur further knowledge transfer, leveraging the recent advances in each field. We therefore categorize vector graphics article from the last decades based on their underlying mathematical representations as well as on their contribution to the vector graphics content creation pipeline, comprising representation, creation, rasterization, and automatic image vectorization. This survey is meant as an entry point for both artists and researchers. We conclude this survey with an outlook on promising research directions and challenges to overcome in the future.
C1 [Tian, Xingze; Guenther, Tobias] Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Günther, T (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
EM xingze.tian@fau.de; tobias.guenther@fau.de
OI Gunther, Tobias/0000-0002-3020-0930
CR Abadpour A, 2007, J VIS COMMUN IMAGE R, V18, P15, DOI 10.1016/j.jvcir.2006.08.001
   Dominici EA, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392401
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Baksteen S. D., 2021, P SMART TOOLS APPS G, P91
   Bao B, 2019, COMPUT GRAPH-UK, V81, P73, DOI 10.1016/j.cag.2019.04.003
   Barendrecht PJ, 2018, VISUAL COMPUT, V34, P949, DOI 10.1007/s00371-018-1547-1
   Barla P., 2013, Image and Video-Based Artistic Stylisation, P149
   Battiato S, 2005, PROC SPIE, V5670, P1, DOI 10.1117/12.586802
   Battiato S., 2005, P 4 ANN C SCAL VECT, P1
   Battiato S., 2004, P 20 SPRING C COMP G, P185
   Beatson R, 2018, COMPUT AIDED GEOM D, V60, P18, DOI 10.1016/j.cagd.2018.01.002
   Bezerra H., 2010, P 8 INT S NONPH AN R, P35
   Bhunia AK, 2021, PROC CVPR IEEE, P5668, DOI 10.1109/CVPR46437.2021.00562
   Botsch M., 2005, Mathematics of Surfaces XI 11th IMA International Conference. Proceedings (Lecture Notes in Computer Science Vol. 3604), P62, DOI 10.1007/11537908_5
   Bowers JC, 2011, COMPUT GRAPH FORUM, V30, P1345, DOI 10.1111/j.1467-8659.2011.01994.x
   Boyé S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366192
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Briggs W.L., 2000, MULTIGRID TUTORIAL
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao J, 2019, COMPUT METHOD APPL M, V357, DOI 10.1016/j.cma.2019.112598
   Carlier A., 2020, P INT C NEUR INF PRO, p16 351
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Charrot P., 1984, Computer-Aided Geometric Design, V1, P87, DOI 10.1016/0167-8396(84)90006-2
   Chen KW, 2020, IEEE T MULTIMEDIA, V22, P15, DOI 10.1109/TMM.2019.2922126
   Chiyokura H., 1983, Computer Graphics, V17, P289, DOI 10.1145/964967.801160
   Dai W, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P922, DOI 10.1109/CISP.2013.6745296
   Davoine F, 1996, IEEE T IMAGE PROCESS, V5, P338, DOI 10.1109/83.480769
   Demaret L, 2006, SIGNAL PROCESS, V86, P1604, DOI 10.1016/j.sigpro.2005.09.003
   Douglas D. H., 1973, Cartogr. Int. J. Geogr. Inf. Geovis, V10, P112, DOI DOI 10.3138/FM57-6770-U75U-7727
   DYN N, 1990, IMA J NUMER ANAL, V10, P137, DOI 10.1093/imanum/10.1.137
   Egiazarian V., 2020, COMPUTER VISION ECCV, P582
   Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117
   Ellis K, 2018, ADV NEUR IN, V31
   Farin G.E., 2002, Curves and surfaces for CAGD, a practical guide
   Favreau JD, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130888
   Favreau JD, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925946
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FERGUSON J, 1964, J ACM, V11, P221, DOI 10.1145/321217.321225
   Finch M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024200
   Floater MS, 2003, COMPUT AIDED GEOM D, V20, P19, DOI 10.1016/S0167-8396(03)00002-5
   Fraeijs de Veubeke B., 1974, International Journal for Numerical Methods in Engineering, V8, P783, DOI 10.1002/nme.1620080408
   Froumentin M, 2000, COMPUT GRAPH FORUM, V19, pC419, DOI 10.1111/1467-8659.00434
   Fu Q, 2021, IEEE COMPUT GRAPH, V41, P152, DOI 10.1109/MCG.2020.3024870
   Fu Q, 2019, COMPUT AIDED DESIGN, V115, P111, DOI 10.1016/j.cad.2019.05.005
   Fu Q, 2018, COMPUT AIDED DESIGN, V102, P1, DOI 10.1016/j.cad.2018.04.019
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Goodnight N., 2005, ACM SIGGRAPH 2005 Courses, P193
   Guo Y, 2019, COMPUT GRAPH FORUM, V38, P81, DOI 10.1111/cgf.13818
   He Y., 2022, PREPRINT, DOI [10.21203/rs.3.rs-1817017/v1, DOI 10.21203/RS.3.RS-1817017/V1]
   Hettinga G., 2021, P IT CHAPT C SMART T, P139
   Hettinga G. J., 2018, P 39 ANN EUR ASS COM, P45
   Hettinga GJ, 2022, COMPUT GRAPH-UK, V105, P119, DOI 10.1016/j.cag.2022.05.004
   Hettinga GJ, 2019, COMPUT AIDED GEOM D, V74, DOI 10.1016/j.cagd.2019.101769
   Hettinga GJ, 2019, GRAPH MODELS, V103, DOI 10.1016/j.gmod.2019.101024
   Hnaidi H, 2010, COMPUT GRAPH FORUM, V29, P2179, DOI 10.1111/j.1467-8659.2010.01806.x
   Hoff KE, 1999, COMP GRAPH, P277, DOI 10.1145/311535.311567
   Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233
   Hoshyari S, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201312
   Hou F., 2017, arXiv
   Hou F, 2020, IEEE T VIS COMPUT GR, V26, P1361, DOI 10.1109/TVCG.2018.2867478
   Hu ZY, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1889
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Ilbery P, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508426
   Iu M.-Y., 2019, P 45 GRAPH INT C, P1
   Jacobson A, 2012, COMPUT GRAPH FORUM, V31, P1577, DOI 10.1111/j.1467-8659.2012.03163.x
   Jarvis John F, 1976, Comput. Graph. Image Process, V5, P13, DOI [10.1016/S0146-664X(76)80003-2, DOI 10.1016/S0146-664X(76)80003-2]
   Jeschke S, 2011, COMPUT GRAPH FORUM, V30, P523, DOI 10.1111/j.1467-8659.2011.01877.x
   Jeschke S, 2016, COMPUT GRAPH FORUM, V35, P71, DOI 10.1111/cgf.12812
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618462
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618463
   Ju T, 2005, ACM T GRAPHIC, V24, P561, DOI 10.1145/1073204.1073229
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   Lai YK, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531391
   LASCAUX P, 1975, REV FR AUTOMAT INFOR, V9, P9
   Lawonn K, 2019, COMPUT GRAPH FORUM, V38, P221, DOI 10.1111/cgf.13526
   Lecot G., 2006, P 17 EUR C REND TECH, P349
   Lee S-M., 2002, PhD dissertation
   Levenberg K., 1944, Q. Appl. Math, V2, P164, DOI [10.1090/QAM/10666, 10.1090/qam/10666, DOI 10.1090/QAM/10666]
   Li TM, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417871
   Li XY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461917
   Li YJ, 2021, IEEE T VIS COMPUT GR, V27, P228, DOI 10.1109/TVCG.2019.2929808
   Li YQ, 2022, IEEE T VIS COMPUT GR, V28, P3265, DOI 10.1109/TVCG.2021.3061131
   Liao ZC, 2012, IEEE T VIS COMPUT GR, V18, P1858, DOI 10.1109/TVCG.2012.76
   Lieng H, 2016, P ACM SIG GRAPH POST, P1
   Lieng H, 2017, COMPUT GRAPH FORUM, V36, P112, DOI 10.1111/cgf.12862
   Lieng H, 2015, COMPUT GRAPH FORUM, V34, P228, DOI 10.1111/cgf.12532
   Lin H., 2018, Comput. Vis. Media, V4
   Lin JC, 2015, 2015 NINTH INTERNATIONAL CONFERENCE ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY FCST 2015, P153, DOI 10.1109/FCST.2015.12
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Liu C, 2017, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2017.241
   Lopes RG, 2019, IEEE I CONF COMP VIS, P7929, DOI 10.1109/ICCV.2019.00802
   Lu SF, 2020, IEEE ACCESS, V8, P57158, DOI 10.1109/ACCESS.2020.2982457
   Lu SF, 2019, VISUAL COMPUT, V35, P1027, DOI 10.1007/s00371-019-01671-0
   Ma Xu, 2022, P IEEE CVF C COMP VI, P16314
   Maire M, 2008, PROC CVPR IEEE, P611
   Mao CY, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 4, PROCEEDINGS, P13, DOI 10.1109/WCSE.2009.182
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Niessner M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077347
   Nocedal J., 1999, Numerical optimization
   Noris G, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421640
   Orzan A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360691
   Pang WM, 2012, IEEE COMPUT GRAPH, V32, P68, DOI 10.1109/MCG.2011.86
   Powell MJD., 1996, Computational_Techniques_and_Applications:_CTAC95,_RL_May_and_, P43
   Prévost R, 2015, COMPUT GRAPH FORUM, V34, P253, DOI 10.1111/cgf.12510
   Price B, 2006, VISUAL COMPUT, V22, P661, DOI 10.1007/s00371-006-0051-1
   Qi Y, 2022, COMPUT GRAPH FORUM, V41, P51, DOI 10.1111/cgf.14586
   Reddy P, 2021, PROC CVPR IEEE, P7338, DOI 10.1109/CVPR46437.2021.00726
   Ribeiro L.S.F., 2020, P IEEE CVF C COMP VI
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sawhney R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392374
   Schmidt TW, 2016, COMPUT GRAPH FORUM, V35, P216, DOI 10.1111/cgf.12721
   Schmitt D, 2019, LECT NOTES COMPUT SC, V11651, P335, DOI 10.1007/978-3-030-25027-0_23
   Schneider P. J., 1990, Graph. Gems, V1, P612
   Shen IC, 2022, IEEE T VIS COMPUT GR, V28, P4211, DOI 10.1109/TVCG.2021.3084944
   Shewchuk J.R., 1996, WORKSH APPL COMP GEO, P203
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   Su H, 2023, Arxiv, DOI arXiv:2110.04830
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Sun Q, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1611
   Sun T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601187
   Sun X, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185570
   Svergja J. K., 2017, P ACM SIGGRAPH POST, P1
   Swaminarayan Sriram, 2006, AIPR 06, P28, DOI DOI 10.1109/AIPR.2006.30
   Takayama K., 2010, P ACM SIGGRAPH AS, P1
   Várady T, 2016, COMPUT GRAPH FORUM, V35, P307, DOI 10.1111/cgf.12833
   Verstraaten TW, 2018, COMPUT GRAPH FORUM, V37, P373, DOI 10.1111/cgf.13575
   Wan L, 2018, MULTIMED TOOLS APPL, V77, P13753, DOI 10.1007/s11042-017-4987-0
   Wang CA, 2017, IEEE T IMAGE PROCESS, V26, P1833, DOI 10.1109/TIP.2017.2666742
   Weber O, 2012, COMPUT GRAPH FORUM, V31, P2409, DOI 10.1111/j.1467-8659.2012.03130.x
   Wei GS, 2019, COMPUT GRAPH FORUM, V38, P171, DOI 10.1111/cgf.13826
   Wolberg G, 1999, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P188, DOI 10.1109/CGI.1999.777953
   Xia T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618461
   Xiao CF, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480502
   Xiao X.Z., 2006, P 2006 ACM INT C VIR, P305
   Xiao YY, 2022, COMPUT GRAPH FORUM, V41, P23, DOI 10.1111/cgf.14495
   Xiao Y, 2015, COMPUT GRAPH FORUM, V34, P123, DOI 10.1111/cgf.12524
   Xiao Y, 2013, IEEE T MULTIMEDIA, V15, P549, DOI 10.1109/TMM.2012.2233725
   Xie GF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661275
   Yang M, 2016, IEEE T VIS COMPUT GR, V22, P1063, DOI 10.1109/TVCG.2015.2440273
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yu XH, 2001, IEEE COMPUT GRAPH, V21, P62, DOI 10.1109/38.920628
   Yuksel C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731053
   Zhao S, 2018, IEEE T VIS COMPUT GR, V24, P2153, DOI 10.1109/TVCG.2017.2721400
   Zhou HL, 2014, IEEE T IMAGE PROCESS, V23, P3268, DOI 10.1109/TIP.2014.2327807
   Zhou J, 2022, COMPUT GRAPH FORUM, V41, P389, DOI 10.1111/cgf.14442
   Zhu HK, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3513132
   Zorin D., 2006, ACM SIGGRAPH 2006 CO, P30
NR 147
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1652
EP 1671
DI 10.1109/TVCG.2022.3220575
PG 20
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500009
PM 36346866
OA hybrid
DA 2024-11-06
ER

PT J
AU Xia, MH
   Echevarria, J
   Xie, MS
   Wong, TT
AF Xia, Menghan
   Echevarria, Jose
   Xie, Minshan
   Wong, Tien-Tsin
TI LF2MV: Learning an Editable Meta-View Towards Light Field Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Compact representation; editing propagation; light field; representation
   learning
ID RECONSTRUCTION
AB Light fields are 4D scene representations that are typically structured as arrays of views or several directional samples per pixel in a single view. However, this highly correlated structure is not very efficient to transmit and manipulate, especially for editing. To tackle this issue, we propose a novel representation learning framework that can encode the light field into a single meta-view that is both compact and editable. Specifically, the meta-view composes of three visual channels and a complementary meta channel that is embedded with geometric and residual appearance information. The visual channels can be edited using existing 2D image editing tools, before reconstructing the whole edited light field. To facilitate edit propagation against occlusion, we design a special editing-aware decoding network that consistently propagates the visual edits to the whole light field upon reconstruction. Extensive experiments show that our proposed method achieves competitive representation accuracy and meanwhile enables consistent edit propagation.
C1 [Xia, Menghan; Xie, Minshan; Wong, Tien-Tsin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Echevarria, Jose] Adobe Syst Inc, San Jose, CA 95110 USA.
C3 Chinese University of Hong Kong; Adobe Systems Inc.
RP Xia, MH (corresponding author), Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
EM menghanxyz@gmail.com; echevarr@adobe.com; msxie@cse.cuhk.edu.hk;
   ttwong@cse.cuhk.edu.hk
OI Echevarria, Jose/0000-0001-6802-0911; Wong,
   Tien-Tsin/0000-0002-7792-9307
FU Research Grants Council of the Hong Kong Special Administrative Region
FX No Statement Available
CR Alperovich A, 2018, PROC CVPR IEEE, P9145, DOI 10.1109/CVPR.2018.00953
   Beigpour S., 2018, J. Perceptual imag., V1
   Birklbauer C, 2012, COMPUT GRAPH FORUM, V31, P295, DOI 10.1111/j.1467-8659.2012.03008.x
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen KW, 2015, IEEE INT CON MULTI
   Conti C, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574667
   Conti C, 2011, IEEE IMAGE PROC, P961, DOI 10.1109/ICIP.2011.6116721
   Cun XD, 2020, AAAI CONF ARTIF INTE, V34, P10680
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Guo M., 2018, AS C COMP VIS, P50
   Hart D, 2020, IEEE WINT CONF APPL, P99, DOI [10.1109/wacv45572.2020.9093478, 10.1109/WACV45572.2020.9093478]
   Heber S, 2016, PROC CVPR IEEE, P3746, DOI 10.1109/CVPR.2016.407
   Hériard-Dubreuil B, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954495
   Hu WB, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417764
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Inagaki Y, 2018, LECT NOTES COMPUT SC, V11211, P431, DOI 10.1007/978-3-030-01234-2_26
   Jarabo A., 2011, P IBERO AM S COMP GR
   Jarabo A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601125
   Jin X, 2018, IEEE T IMAGE PROCESS, V27, P3954, DOI 10.1109/TIP.2018.2832449
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Kingma D.P., 2014, P INT C LEARNING REP
   Le Pendu M, 2018, IEEE T IMAGE PROCESS, V27, P1981, DOI 10.1109/TIP.2018.2791864
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Liu D., 2016, P IEEE INT C MULT EX, P1, DOI [10.1109/ICMEW.2016.7574674, DOI 10.1109/ICMEW.2016.7574674]
   Marwah K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461914
   Miandji E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269980
   Ng R., 2005, Ph.D. Thesis
   Ni LX, 2019, COMPUT GRAPH FORUM, V38, P425, DOI 10.1111/cgf.13849
   Perra C, 2016, IEEE INT CONF MULTI
   Raj A.S., 2016, Light-Field Database Creation and Depth Estimation
   Ruder M, 2016, LECT NOTES COMPUT SC, V9796, P26, DOI 10.1007/978-3-319-45886-1_3
   Seitz SM, 2002, INT J COMPUT VISION, V48, P115, DOI 10.1023/A:1016046923611
   Shi LX, 2014, ACM T GRAPHIC, V34, DOI [10.1145/2682631, 10.1145/2816795.2818070]
   Srinivasan PP, 2019, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2019.00026
   Srinivasan PP, 2017, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2017.246
   Vadathya AK, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P328, DOI 10.1109/ACPR.2017.142
   Vagharshakyan S, 2015, IEEE IMAGE PROC, P1379, DOI 10.1109/ICIP.2015.7351026
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LF, 2005, IEEE T VIS COMPUT GR, V11, P25
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wang XR, 2020, PROC CVPR IEEE, P8087, DOI 10.1109/CVPR42600.2020.00811
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanner S, 2014, IEEE T PATTERN ANAL, V36, P606, DOI 10.1109/TPAMI.2013.147
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9
   Yoo J, 2019, IEEE I CONF COMP VIS, P9035, DOI 10.1109/ICCV.2019.00913
   Yoon Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P57, DOI 10.1109/ICCVW.2015.17
   Zhang FL, 2017, IEEE T VIS COMPUT GR, V23, P1561, DOI 10.1109/TVCG.2016.2532329
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 58
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1672
EP 1684
DI 10.1109/TVCG.2022.3220773
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500012
PM 36350869
DA 2024-11-06
ER

PT J
AU Feng, BY
   Varshney, A
AF Feng, Brandon Yushan
   Varshney, Amitabh
TI Neural Subspaces for Light Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Light fields; Neural networks; Videos; Image color analysis; Image
   coding; Encoding; Dictionaries; Implicit neural representations; light
   field compression; neural fields; volumetric videos
ID COMPRESSION; ALGORITHM
AB We introduce a framework for compactly representing light field content with the novel concept of neural subspaces. While the recently proposed neural light field representation achieves great compression results by encoding a light field into a single neural network, the unified design is not optimized for the composite structures exhibited in light fields. Moreover, encoding every part of the light field into one network is not ideal for applications that require rapid transmission and decoding. We recognize this problem's connection to subspace learning. We present a method that uses several small neural networks, specializing in learning the neural subspace for a particular light field segment. Moreover, we propose an adaptive weight sharing strategy among those small networks, improving parameter efficiency. In effect, this strategy enables a concerted way to track the similarity among nearby neural subspaces by leveraging the layered structure of neural networks. Furthermore, we develop a soft-classification technique to enhance the color prediction accuracy of neural representations. Our experimental results show that our method better reconstructs the light field than previous methods on various light field scenes. We further demonstrate its successful deployment on encoding light fields with irregular viewpoint layout and dynamic scene content.
C1 [Feng, Brandon Yushan; Varshney, Amitabh] Univ Maryland, Dept Comp Sci, College Pk, MD 20770 USA.
C3 University System of Maryland; University of Maryland College Park
RP Feng, BY (corresponding author), Univ Maryland, Dept Comp Sci, College Pk, MD 20770 USA.
EM yfeng97@umd.edu; varshney@umd.edu
RI Feng, Brandon Yushan/ABH-3517-2021
OI Feng, Brandon Yushan/0000-0001-7003-9128; Varshney,
   Amitabh/0000-0002-9873-2212
FU NSF
FX No Statement Available
CR Abdi A, 2017, INT CONF ACOUST SPEE, P3689, DOI 10.1109/ICASSP.2017.7952845
   Adams A., 2008, The stanford light field archive
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bemana M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417827
   Bergman P., 2021, NIPS, P172
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Chang CL, 2006, IEEE T IMAGE PROCESS, V15, P793, DOI 10.1109/TIP.2005.863954
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Dib E, 2019, IEEE IMAGE PROC, P3751, DOI [10.1109/ICIP.2019.8803756, 10.1109/icip.2019.8803756]
   Feng BY, 2022, LECT NOTES COMPUT SC, V13663, P138, DOI 10.1007/978-3-031-20062-5_9
   Feng BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14204, DOI 10.1109/ICCV48922.2021.01396
   Feng S., 2022, P ACM SIGGRAPH AS C, P1
   Flynn J, 2019, PROC CVPR IEEE, P2362, DOI 10.1109/CVPR.2019.00247
   Hajisharif S, 2019, COMPUT GRAPH FORUM, V38, P265, DOI 10.1111/cgf.13835
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jagmohan A, 2003, CONF REC ASILOMAR C, P830
   Jiang XR, 2017, IEEE J-STSP, V11, P1132, DOI 10.1109/JSTSP.2017.2747078
   Kalantari NK, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980251
   Koniaris C, 2019, IEEE T VIS COMPUT GR, V25, P1666, DOI 10.1109/TVCG.2018.2818156
   Le Pendu M, 2020, IEEE IMAGE PROC, P2606, DOI [10.1109/ICIP40778.2020.9190719, 10.1109/icip40778.2020.9190719]
   Le Pendu M, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922099
   Li D, 2021, IEEE T VIS COMPUT GR, V27, P2638, DOI 10.1109/TVCG.2021.3067762
   Magnor M, 2000, IEEE T CIRC SYST VID, V10, P338, DOI 10.1109/76.836278
   Mairal J., 2009, P 26 ANN INT C MACH, DOI 10.1145/1553374.1553463
   Meng XX, 2021, IEEE T VIS COMPUT GR, V27, P3350, DOI 10.1109/TVCG.2020.2975801
   Miandji E, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3269980
   Miandji J., 2013, P SIGGRAPH AS TECH B, P1
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Nystad Jorn, 2012, P C HIGH PERF GRAPH, P105
   Pendu A., 2020, P IEEE INT C COMP PH, P1
   Pratapa S, 2019, COMPUT GRAPH FORUM, V38, P1, DOI 10.1111/cgf.13755
   Pratapa S, 2019, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2019), DOI 10.1145/3306131.3317018
   Sitzmann V., 2020, Advances in Neural Information Processing Systems, V33, P7462
   Sitzmann V, 2021, ADV NEUR IN, V34
   STEWART GW, 1992, IEEE T SIGNAL PROCES, V40, P1535, DOI 10.1109/78.139256
   Sulam J, 2018, IEEE T SIGNAL PROCES, V66, P4090, DOI 10.1109/TSP.2018.2846226
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tancik M., 2020, Advances in Neural Information Processing Systems, V33, P7537, DOI DOI 10.48550/ARXIV.2006.10739
   Tancik M, 2021, PROC CVPR IEEE, P2845, DOI 10.1109/CVPR46437.2021.00287
   Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566
   Wang B, 2013, PROC CVPR IEEE, P468, DOI 10.1109/CVPR.2013.67
   Winkler S, 2003, PROC SPIE, V5203, P371, DOI 10.1117/12.512550
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Zhang Y., 2021, Implicit neural video compression
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhu XQ, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P30
NR 47
TC 1
Z9 1
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1685
EP 1695
DI 10.1109/TVCG.2022.3224674
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500011
PM 36455094
OA hybrid
DA 2024-11-06
ER

PT J
AU Wang, M
   Chen, ZY
   Cai, WC
   Steinicke, F
AF Wang, Miao
   Chen, Ze-Yin
   Cai, Wen-Chuan
   Steinicke, Frank
TI Transferable Virtual-Physical Environmental Alignment With Redirected
   Walking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Redirected walking; virtual-physical environmental alignment;
   reinforcement learning
AB Several advanced redirected walking techniques have been proposed in recent years to improve natural walking in virtual environments. One active and important research challenge of redirected walking focuses on the alignment of virtual and physical environments by redirection gains. If both environments are aligned, physical objects appear at the same positions as their virtual counterparts. When a user arrives at such a virtual object, she can touch the corresponding physical object providing passive haptic feedback. When multiple transferable virtual or physical target positions exist, the alignment can exploit multiple options, but the process requires more complicated solutions. In this paper, we study the problem of virtual-physical environmental alignment at multiple transferable target positions, and introduce a novel reinforcement learning-based redirected walking method. We design a novel comprehensive reward function that dynamically determines virtual-physical target matching and updates virtual target weights for reward computation. We evaluate our method through various simulated experiments as well as real user tests. The results show that our method obtains less physical distance error for environmental alignment and requires fewer resets than state-of-the-art techniques.
C1 [Wang, Miao; Chen, Ze-Yin; Cai, Wen-Chuan] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Wang, Miao] Zhongguancun Lab, Beijing 100094, Peoples R China.
   [Steinicke, Frank] Univ Hamburg, Dept Informat, D-22605 Hamburg, Germany.
C3 Beihang University; Zhongguancun Laboratory; University of Hamburg
RP Wang, M (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM miaow@buaa.edu.cn; chenzeyin9867@buaa.edu.cn; wenchuancai@buaa.edu.cn;
   frank.steinicke@uni-hamburg.de
RI Steinicke, Frank/AAC-2976-2020
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], 2022, 2sync house scale vr: Connect virtual and real worlds
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2277, DOI 10.1109/TVCG.2022.3150500
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen H., 2017, P 21 ACM SIGGRAPH S, P1
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Dynkin E.B., 1965, Markov processes, Markov Processes, P77
   Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P2, DOI 10.1037/a0024338
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Kim D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P653, DOI 10.1109/VR50410.2021.00091
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253
   Konda VR, 2000, ADV NEUR IN, V12, P1008
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Li YJ, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P95, DOI [10.1109/VR50410.2021.00030, 10.1109/ISHC54333.2021.00026]
   Lindeman RW, 1999, P IEEE VIRT REAL ANN, P205, DOI 10.1109/VR.1999.756952
   Min DH, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P164, DOI [10.1109/VR46266.2020.00-69, 10.1109/VR46266.2020.1581308731108]
   Multon F., 2013, Human Walking in Virtual Environments: Perception, Technology, and Applications
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Razzaque S., 2001, P 22 ANN C EUR ASS C, P289, DOI DOI 10.2312/EGS.20011036
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Schulman J, 2018, Arxiv, DOI [arXiv:1506.02438, 10.48550/arXiv.1506.02438, DOI 10.48550/ARXIV.1506.02438]
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Silver D, 2014, PR MACH LEARN RES, V32
   Steinicke F, 2010, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2010.5444790
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma E.A, 2015, P ACM SIGGRAPH EM TE, P1
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   TESAURO G, 1995, COMMUN ACM, V38, P58, DOI 10.1145/203330.203343
   Thomas J., 2020, P 26 ACM S VIRT REAL, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Wang LL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P651, DOI [10.1109/VRW50115.2020.00-99, 10.1109/VRW50115.2020.00176]
   Wang LL, 2019, IEEE T VIS COMPUT GR, V25, P2083, DOI 10.1109/TVCG.2019.2898782
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Ye ZM, 2021, INT SYM MIX AUGMENT, P239, DOI 10.1109/ISMAR52148.2021.00039
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 52
TC 0
Z9 0
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1696
EP 1709
DI 10.1109/TVCG.2022.3224073
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500007
PM 36417720
DA 2024-11-06
ER

PT J
AU Zang, ZL
   Cheng, SH
   Xia, HC
   Li, LY
   Sun, YT
   Xu, YJ
   Shang, L
   Sun, BG
   Li, SZ
AF Zang, Zelin
   Cheng, Shenghui
   Xia, Hanchen
   Li, Liangyu
   Sun, Yaoting
   Xu, Yongjie
   Shang, Lei
   Sun, Baigui
   Li, Stan Z.
TI DMT-EV: An Explainable Deep Network for Dimension Reduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dimension reduction; explainability of DR models; deep learning;
   parametric model
AB Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the poor generalisation performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called DMT-EV, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. DMT-EV starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained DMT-EV parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust DMT-EV to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that DMT-EV consistently outperforms the state-of-the-art methods in both performance measures and explainability.
C1 [Zang, Zelin; Cheng, Shenghui; Xia, Hanchen; Li, Liangyu; Sun, Yaoting; Xu, Yongjie; Li, Stan Z.] Westlake Univ, Sch Engn, AI Div, Hangzhou 310024, Zhejiang, Peoples R China.
   [Shang, Lei; Sun, Baigui] Alibaba Grp, Hangzhou 311121, Peoples R China.
C3 Westlake University; Alibaba Group
RP Li, SZ (corresponding author), Westlake Univ, Sch Engn, AI Div, Hangzhou 310024, Zhejiang, Peoples R China.
EM zangzelin@westlake.edu.cn; chengshenghui@westlake.edu.cn;
   573375794@qq.com; liliangyu@westlake.edu.cn; sunyaoting@westlake.edu.cn;
   xuyongjie@westlake.edu.cn; sl172005@alibaba-inc.com;
   baigui.sbg@alibaba-inc.com; stan.zq.li@westlake.edu.cn
RI cheng, shenghui/KIJ-8262-2024; Shang, Lei/W-2984-2019
OI Zang, Zelin/0000-0003-2831-5437; Cheng, Shenghui/0000-0002-3767-8371;
   Xu, Yongjie/0000-0002-6045-1626
FU National Natural Science Foundation of China
FX No Statement Available
CR Adler P, 2018, KNOWL INF SYST, V54, P95, DOI 10.1007/s10115-017-1116-3
   Andrews TS, 2021, NAT PROTOC, V16, P1, DOI 10.1038/s41596-020-00409-w
   Aupetit M, 2007, NEUROCOMPUTING, V70, P1304, DOI 10.1016/j.neucom.2006.11.018
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkina AC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13055-y
   Björklund A, 2022, Arxiv, DOI [arXiv:2201.04455, 10.48550/ARXIV.2201.04455, DOI 10.48550/ARXIV.2201.04455]
   Chatzimparmpas A, 2020, IEEE T VIS COMPUT GR, V26, P2696, DOI 10.1109/TVCG.2020.2986996
   Chen C, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21082873
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, 10.48550/ARXIV.2002.05709, DOI 10.48550/ARXIV.2002.05709, 10.48550/arXiv.2002.05709]
   Cheng SH, 2016, IEEE T VIS COMPUT GR, V22, P121, DOI 10.1109/TVCG.2015.2467552
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Duque AF, 2020, IEEE INT CONF BIG DA, P5027, DOI 10.1109/BigData50022.2020.9378049
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Fujiwara T, 2020, IEEE T VIS COMPUT GR, V26, P45, DOI 10.1109/TVCG.2019.2934251
   Ghosh A, 2022, IEEE T KNOWL DATA EN, V34, P2227, DOI 10.1109/TKDE.2020.3005878
   Ghosh A, 2022, IEEE T VIS COMPUT GR, V28, P2791, DOI 10.1109/TVCG.2020.3039106
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   HARDLE W, 1993, ANN STAT, V21, P1926, DOI 10.1214/aos/1176349403
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/ARXIV.1512.03385]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G. E., 2002, ADV NEURAL INFORM PR, V15, P857, DOI DOI 10.5555/2968618.2968725
   Kobak D., 2019, BIORXIV, DOI DOI 10.1101/2019.12.19.877522
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P115, DOI 10.1007/BF02289694
   Kumar A, 2020, ETRA 2020 SHORT PAPERS: ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3379156.3391361
   Lähnemann D, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-1926-6
   Lee JA, 2009, NEUROCOMPUTING, V72, P1431, DOI 10.1016/j.neucom.2008.12.017
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Liu SS, 2017, IEEE T VIS COMPUT GR, V23, P1249, DOI 10.1109/TVCG.2016.2640960
   Loshchilov I, 2019, Arxiv, DOI [arXiv:1711.05101, DOI 10.48550/ARXIV.1711.05101, 10.48550/arXiv.1711.05101]
   Lundberg SM, 2017, ADV NEUR IN, V30
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28
   Moon KR, 2019, NAT BIOTECHNOL, V37, P1482, DOI 10.1038/s41587-019-0336-3
   Moor M., 2020, INT C MACH LEARN, P7045
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Pagliosa L, 2016, SIBGRAPI, P297, DOI [10.1109/SIBGRAPI.2016.048, 10.1109/SIBGRAPI.2016.45]
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sainburg T, 2021, Arxiv, DOI [arXiv:2009.12981, 10.48550/arXiv.2009.12981, DOI 10.48550/ARXIV.2009.12981]
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, 10.48550/arXiv.1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Sohns J.-T., 2021, arXiv
   Stahnke J, 2016, IEEE T VIS COMPUT GR, V22, P629, DOI 10.1109/TVCG.2015.2467717
   Suhre K, 2021, NAT REV GENET, V22, P19, DOI 10.1038/s41576-020-0268-2
   Szubert B, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45301-0
   Tang J, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P287, DOI 10.1145/2872427.2883041
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1602.04938, DOI 10.48550/ARXIV.1602.04938, 10.48550/arXiv.1602.04938]
   van der Maaten L., 2009, J MACH LEARN RES, P384
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Unen V, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01689-9
   Verma S, 2020, Arxiv, DOI [arXiv:2010.10596, 10.48550/arXiv.2010.10596, DOI 10.48550/ARXIV.2010.10596]
   [王瑛 Wang Ying], 2021, [空军工程大学学报. 自然科学版, Journal of Air Force Engineering University. Natural Science Edition], V22, P1
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zang ZL, 2022, LECT NOTES COMPUT SC, V13681, P576, DOI 10.1007/978-3-031-19803-8_34
NR 55
TC 3
Z9 3
U1 9
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1710
EP 1727
DI 10.1109/TVCG.2022.3223399
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500013
PM 36409811
OA hybrid
DA 2024-11-06
ER

PT J
AU Zhang, WH
   Yue, YT
   Pan, H
   Chen, ZG
   Wang, C
   Pfister, H
   Wang, WP
AF Zhang, Wenhua
   Yue, Yating
   Pan, Hao
   Chen, Zhonggui
   Wang, Chuan
   Pfister, Hanspeter
   Wang, Wenping
TI Marching Windows: Scalable Mesh Generation for Volumetric Data With
   Multiple Materials
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Topology; Mesh generation; Three-dimensional displays; Imaging; Data
   visualization; Memory management; Measurement; Large volumetric data;
   multiple material; marching windows; mesh simplification; topology
   guarantee
ID TETRAHEDRAL MESHES; SIMPLIFICATION; ALGORITHM; SURFACES
AB Volumetric data abounds in medical imaging and other fields. With the improved imaging quality and the increased resolution, volumetric datasets are getting so large that the existing tools have become inadequate for processing and analyzing the data. Here we consider the problem of computing tetrahedral meshes to represent large volumetric datasets with labeled multiple materials, which are often encountered in medical imaging or microscopy optical slice tomography. Such tetrahedral meshes are a more compact and expressive geometric representation so are in demand for efficient visualization and simulation of the data, which are impossible if the original large volumetric data are used directly due to the large memory requirement. Existing methods for meshing volumetric data are not scalable for handling large datasets due to their sheer demand on excessively large run-time memory or failure to produce a tet-mesh that preserves the multi-material structure of the original volumetric data. In this article we propose a novel approach, called Marching Windows, that uses a moving window and a disk-swap strategy to reduce the run-time memory footprint, devise a new scheme that guarantees to preserve the topological structure of the original dataset, and adopt an error-guided optimization technique to improve both geometric approximation error and mesh quality. Extensive experiments show that our method is capable of processing very large volumetric datasets beyond the capability of the existing methods and producing tetrahedral meshes of high quality.
C1 [Zhang, Wenhua; Yue, Yating; Wang, Chuan] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
   [Pan, Hao] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Chen, Zhonggui] Xiamen Univ, Sch Informat, Xiamen 361005, Peoples R China.
   [Pfister, Hanspeter] Harvard Univ, John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Wang, Wenping] Texas A&M Univ, Dept Visualizat, College Stn, TX 77843 USA.
C3 University of Hong Kong; Microsoft; Microsoft Research Asia; Xiamen
   University; Harvard University; Texas A&M University System; Texas A&M
   University College Station
RP Zhang, WH (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
EM winniezhangcoding@gmail.com; ytyue@cs.hku.hk; haopan@microsoft.com;
   chenzhonggui@xmu.edu.cn; cwang.hku@gmail.com; pfister@g.harvard.edu;
   wenping@tamu.edu
RI Zhang, Wenhua/HOC-9630-2023
OI Pfister, Hanspeter/0000-0002-3620-2582; PAN, Hao/0000-0003-3628-9777;
   Zhang, Wenhua/0000-0001-5411-0684; Chen, Zhonggui/0000-0002-9960-4896
FU National Natural Science Foundation of China
FX No Statement Available
CR Alliez C., 2015, inCGAL User Reference Manual
   Alliez P, 2005, ACM T GRAPHIC, V24, P617, DOI 10.1145/1073204.1073238
   Amenta N., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P39, DOI 10.1145/276884.276889
   [Anonymous], 2020, The CGAL Project CGAL User and Reference Manual 5.1.0
   Au OKC, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360643
   Boltcheva D, 2009, LECT NOTES COMPUT SC, V5762, P283, DOI 10.1007/978-3-642-04271-3_35
   Bronson J, 2014, IEEE T VIS COMPUT GR, V20, P223, DOI 10.1109/TVCG.2013.115
   Cabiddu D, 2015, COMPUT GRAPH-UK, V51, P81, DOI 10.1016/j.cag.2015.05.015
   Chen L, 2004, J COMPUT MATH, V22, P299
   Chen ZG, 2014, SIAM J SCI COMPUT, V36, pA930, DOI 10.1137/120875132
   Cheng SW, 2010, DISCRETE COMPUT GEOM, V43, P121, DOI 10.1007/s00454-008-9109-3
   Choi HK, 2010, INT J ADV MANUF TECH, V50, P235, DOI 10.1007/s00170-009-2484-y
   Chopra P, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P133, DOI 10.1109/VISUAL.2002.1183767
   Cignoni P, 2000, IEEE VISUAL, P85, DOI 10.1109/VISUAL.2000.885680
   Cohen-Steiner David., 2002, P 18 ANN S COMPUTATI, P199, DOI [10.1145/513400.513425, DOI 10.1145/513400.513425]
   Cui ZM, 2019, PROC CVPR IEEE, P6361, DOI 10.1109/CVPR.2019.00653
   CUTLER B., 2004, SGP 04, P93
   Date H, 2009, IEEE T MAGN, V45, P1352, DOI 10.1109/TMAG.2009.2012623
   Desbrun M., 2008, Discrete Differ. Geom. Oberwolfach Semin., V38, P287
   Dey TK, 2009, ALGORITHMS, V2, P1327, DOI 10.3390/a2041327
   Dey Tamal K., 1998, Publ. l'Inst. Math., V66, P23
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   Eppstein D, 2001, TUTORIAL 10 INT MESH, V10
   Faraj N, 2016, COMPUT GRAPH-UK, V58, P150, DOI 10.1016/j.cag.2016.05.019
   Frey PJ., 2007, MESH GENERATION APPL
   Fu XM, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661235
   Garland M, 2005, ACM T GRAPHIC, V24, P209, DOI 10.1145/1061347.1061350
   Garland M., 1997, P 24 ANN C COMP GRAP, P209, DOI DOI 10.1145/258734.258849
   Guanlong Li, 2012, 2012 IEEE/ACIS 11th International Conference on Computer and Information Science (ICIS), P356, DOI 10.1109/ICIS.2012.107
   Harer H Edelsbrunner J., 2010, Computational Topology: An Introduction (no. Book, Whole)
   Heckbert PS, 1999, COMP GEOM-THEOR APPL, V14, P49, DOI 10.1016/S0925-7721(99)00030-9
   Heller N, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101821
   Ito Y, 2007, MATH COMPUT SIMULAT, V75, P200, DOI 10.1016/j.matcom.2006.12.008
   Lévy B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778856
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Loseille A, 2015, PROCEDIA ENGINEER, V124, P57, DOI 10.1016/j.proeng.2015.10.122
   Ma WY, 2004, COMPUT AIDED DESIGN, V36, P525, DOI 10.1016/S0010-4485(03)00160-X
   Meyer M, 2008, IEEE T VIS COMPUT GR, V14, P1539, DOI 10.1109/TVCG.2008.154
   Moore RH, 2009, ENG COMPUT-GERMANY, V25, P221, DOI 10.1007/s00366-008-0114-1
   Murphy M, 2001, INT J COMPUT GEOM AP, V11, P669, DOI 10.1142/S0218195901000699
   Pons JP, 2007, LECT NOTES COMPUT SC, V4584, P198
   Renze KJ, 1996, IEEE COMPUT GRAPH, V16, P24, DOI 10.1109/38.544069
   Rossignac P., 1993, Multi-Resolution 3D Approximations forRendering Complex Scenes
   RUPPERT J, 1995, J ALGORITHM, V18, P548, DOI 10.1006/jagm.1995.1021
   Said R, 1999, COMPUT METHOD APPL M, V177, P109, DOI 10.1016/S0045-7825(98)00374-0
   Shewchuk J., 2014, Proceedings of the 30th Annual Symposium on Computational Geometry, P290
   Shewchuk J. R., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P86, DOI 10.1145/276884.276894
   Shewchuk JonathanRichard., 2002, 11 INT MESHING ROUND, P193
   Si H, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2629697
   Si H, 2010, FINITE ELEM ANAL DES, V46, P33, DOI 10.1016/j.finel.2009.06.017
   Soler L, 2010, Tech. Rep
   Soucy M, 1996, COMPUT VIS IMAGE UND, V63, P1, DOI 10.1006/cviu.1996.0001
   Thomas DM, 2011, IEEE T VIS COMPUT GR, V17, P1007, DOI 10.1109/TVCG.2010.90
   Trotts IJ, 1999, IEEE T VIS COMPUT GR, V5, P224, DOI 10.1109/2945.795214
   Vivodtzev F, 2011, MATH VIS, P55
   Wei Donglai, 2020, Med Image Comput Comput Assist Interv, V12265, P66, DOI 10.1007/978-3-030-59722-1_7
   Wu Y., 2004, Proceedings of the 2Nd International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, P50
   Yao JH, 2016, COMPUT MED IMAG GRAP, V49, P16, DOI 10.1016/j.compmedimag.2015.12.006
NR 59
TC 0
Z9 0
U1 0
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1728
EP 1742
DI 10.1109/TVCG.2022.3225526
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500006
PM 36455093
DA 2024-11-06
ER

PT J
AU Li, H
   Yang, XR
   Zhai, HJ
   Liu, YQ
   Bao, HJ
   Zhang, GF
AF Li, Hai
   Yang, Xingrui
   Zhai, Hongjia
   Liu, Yuqian
   Bao, Hujun
   Zhang, Guofeng
TI Vox-Surf: Voxel-Based Implicit Surface Representation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surface reconstruction; Image reconstruction; Geometry; Rendering
   (computer graphics); Three-dimensional displays; Feature extraction;
   Surface treatment; Implicit representation; surface reconstruction;
   scene editing
AB Virtual content creation and interaction play an important role in modern 3D applications. Recovering detailed 3D models from real scenes can significantly expand the scope of its applications and has been studied for decades in the computer vision and computer graphics community. In this work, we propose Vox-Surf, a voxel-based implicit surface representation. Our Vox-Surf divides the space into finite sparse voxels, where each voxel is a basic geometry unit that stores geometry and appearance information on its corner vertices. Due to the sparsity inherited from the voxel representation, Vox-Surf is suitable for almost any scene and can be easily trained end-to-end from multiple view images. We utilize a progressive training process to gradually cull out empty voxels and keep only valid voxels for further optimization, which greatly reduces the number of sample points and improves inference speed. Experiments show that our Vox-Surf representation can learn fine surface details and accurate colors with less memory and faster rendering than previous methods. The resulting fine voxels can also be considered as the bounding volumes for collision detection, which is useful in 3D interactions. We also show the potential application of Vox-Surf in scene editing and augmented reality. The source code is publicly available at https://github.com/zju3dv/Vox-Surf.
C1 [Li, Hai; Zhai, Hongjia; Bao, Hujun; Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yang, Xingrui] Univ Bristol, Visual Informat Lab, Bristol BS8 1TL, England.
   [Liu, Yuqian] SenseTime, Autonomous Driving Grp, Shanghai 200233, Peoples R China.
C3 Zhejiang University; University of Bristol
RP Zhang, GF (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
EM garyli@zju.edu.cn; x.yang@bristol.ac.uk; zhj1999@zju.edu.cn;
   liuyuqian@senseauto.com; baohujun@zju.edu.cn; zhangguofeng@zju.edu.cn
RI Zhang, Ge/K-9118-2019; liu, yuqian/ITV-9412-2023
OI Zhang, Guofeng/0000-0001-5661-8430; Zhai, Hongjia/0000-0002-7729-8787;
   Yang, Xingrui/0000-0001-6812-3072; Li, Hai/0000-0002-5114-6566; Bao,
   Hujun/0000-0002-2662-0334
FU National Natural Science Foundation of China
FX No Statement Available
CR Azinovic D, 2022, Arxiv, DOI arXiv:2104.04532
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739
   Darmon F, 2022, PROC CVPR IEEE, P6250, DOI 10.1109/CVPR52688.2022.00616
   Deng KL, 2022, Arxiv, DOI arXiv:2107.02791
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gropp A., 2020, INT C MACH LEARN, V119, P3789
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Laine S, 2011, IEEE T VIS COMPUT GR, V17, P1048, DOI 10.1109/TVCG.2010.240
   Li H, 2020, INT CONF 3D VISION, P1098, DOI 10.1109/3DV50981.2020.00120
   Liao YY, 2022, Arxiv, DOI arXiv:2109.13410
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu J. Gu, 2020, ADV NEURAL INF PROCE
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Munkberg J, 2022, PROC CVPR IEEE, P8270, DOI 10.1109/CVPR52688.2022.00810
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374
   Oechsle M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5569, DOI 10.1109/ICCV48922.2021.00554
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Rematas K., 2021, arXiv
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S. M., 2006, 2006 IEEE COMPUTER S, V1, P519, DOI [DOI 10.1109/CVPR.2006.19(VER, https://doi.org/10.1109/CVPR.2006.19, DOI 10.1109/CVPR.2006.19]
   Sitzmann V, 2019, ADV NEUR IN, V32
   Sun J., 2022, PROC SPECIALINT GROU
   Takikawa T, 2021, PROC CVPR IEEE, P11353, DOI 10.1109/CVPR46437.2021.01120
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Wang L., 2021, Adv. Neural Inf. Process. Syst., p27 171
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Yang BB, 2022, LECT NOTES COMPUT SC, V13676, P597, DOI 10.1007/978-3-031-19787-1_34
   Yariv L, 2021, ADV NEUR IN
   Yariv Lior, 2020, P ADV NEURAL INFORM
   Yu Alex, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P4576, DOI 10.1109/CVPR46437.2021.00455
NR 43
TC 5
Z9 5
U1 9
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1743
EP 1755
DI 10.1109/TVCG.2022.3225844
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500002
PM 36459607
DA 2024-11-06
ER

PT J
AU Davis, R
   Pu, XY
   Ding, YR
   Hall, BD
   Bonilla, K
   Feng, M
   Kay, M
   Harrison, L
AF Davis, Russell
   Pu, Xiaoying
   Ding, Yiren
   Hall, Brian D.
   Bonilla, Karen
   Feng, Mi
   Kay, Matthew
   Harrison, Lane
TI The Risks of Ranking: Revisiting Graphical Perception to Model
   Individual Differences in Visualization Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Visualization; Correlation;
   Observers; Bars; Sociology; graphical perception; individual differences
ID REGRESSION; LITERACY; DESIGN
AB Graphical perception studies typically measure visualization encoding effectiveness using the error of an "average observer", leading to canonical rankings of encodings for numerical attributes: e.g., position > area > angle > volume. Yet different people may vary in their ability to read different visualization types, leading to variance in this ranking across individuals not captured by population-level metrics using "average observer" models. One way we can bridge this gap is by recasting classic visual perception tasks as tools for assessing individual performance, in addition to overall visualization performance. In this article we replicate and extend Cleveland and McGill's graphical comparison experiment using Bayesian multilevel regression, using these models to explore individual differences in visualization skill from multiple perspectives. The results from experiments and modeling indicate that some people show patterns of accuracy that credibly deviate from the canonical rankings of visualization effectiveness. We discuss implications of these findings, such as a need for new ways to communicate visualization effectiveness to designers, how patterns in individuals' responses may show systematic biases and strategies in visualization judgment, and how recasting classic visual perception tasks as tools for assessing individual performance may offer new ways to quantify aspects of visualization literacy. Experiment data, source code, and analysis scripts are available at the following repository: https://osf.io/8ub7t/?view_only=9be4798797404a4397be3c6fc2a68cc0 .
C1 [Davis, Russell; Ding, Yiren; Feng, Mi; Harrison, Lane] Worcester Polytech Inst, Worcester, MA 01609 USA.
   [Bonilla, Karen] Worcester Polytech Inst, Dept Comp Sci, VIEW Grp, Worcester, MA 01609 USA.
   [Pu, Xiaoying] Univ Calif Merced, Merced, CA 95343 USA.
   [Hall, Brian D.] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Kay, Matthew] Northwestern Univ, Comp Sci & Commun Studies, Evanston, IL 60208 USA.
C3 Worcester Polytechnic Institute; Worcester Polytechnic Institute;
   University of California System; University of California Merced;
   University of Michigan System; University of Michigan; Northwestern
   University
RP Ding, YR (corresponding author), Worcester Polytech Inst, Worcester, MA 01609 USA.
EM rdavis@wpi.edu; xpu@ucmerced.edu; yding5@wpi.edu; briandh@umich.edu;
   kbonilla@wpi.edu; mfeng2@wpi.edu; mjskay@northwestern.edu;
   ltharrison@wpi.edu
RI Kay, Matthew/AAN-2490-2021
OI Harrison, Lane/0000-0003-3029-2799; Kay, Matthew/0000-0001-9446-0419;
   Bonilla, Karen/0000-0002-9383-5693; Ding, Yiren/0000-0001-8983-9117
FU National Science Foundation
FX No Statement Available
CR Adler D., 1966, Elements of Psychophysics
   Alper B, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5485, DOI 10.1145/3025453.3025877
   [Anonymous], 2010, 28 ACM INT C COMMUN
   BAIRD JC, 1970, PERCEPT PSYCHOPHYS, V8, P358, DOI 10.3758/BF03212608
   Beecham R, 2017, IEEE T VIS COMPUT GR, V23, P391, DOI 10.1109/TVCG.2016.2598862
   Berinato S., 2016, Good charts: The HBR guide to making smarter, more persuasive data visualizations
   Börner K, 2019, P NATL ACAD SCI USA, V116, P1857, DOI 10.1073/pnas.1807180116
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Burkner PC, 2017, Arxiv, DOI arXiv:1705.11123
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chevalier F, 2018, IEEE COMPUT GRAPH, V38, P21, DOI 10.1109/MCG.2018.032421650
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Dillon A, 1996, INT J HUM-COMPUT ST, V45, P619, DOI 10.1006/ijhc.1996.0071
   EKMAN G, 1968, PERCEPT MOTOR SKILL, V26, P815, DOI 10.2466/pms.1968.26.3.815
   EKMAN G, 1958, J PSYCHOL, V45, P287, DOI 10.1080/00223980.1958.9916259
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Firat EE, 2022, INFORM VISUAL, V21, P285, DOI 10.1177/14738716221081831
   Gabry J, 2019, J ROY STAT SOC A, V182, P389, DOI 10.1111/rssa.12378
   Gajos D. S., 2005, UIST 2005, P173, DOI DOI 10.1145/1095034.1095063
   Gajos KZ, 2010, ARTIF INTELL, V174, P910, DOI 10.1016/j.artint.2010.05.005
   Galesic M, 2011, MED DECIS MAKING, V31, P444, DOI 10.1177/0272989X10373805
   Gelman A., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2011.0180815, 10.48550/arXiv.2011.01808, DOI 10.48550/ARXIV.2011.01808]
   Gelman A, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19100555
   Green T. M., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P203, DOI 10.1109/VAST.2010.5653587
   Harrison L., 2013, P SIGCHI C HUMAN FAC, P2949, DOI DOI 10.1145/2470654.24814109
   Harrison L, 2014, IEEE T VIS COMPUT GR, V20, P1943, DOI 10.1109/TVCG.2014.2346979
   Hedeker D, 2008, BIOMETRICS, V64, P627, DOI 10.1111/j.1541-0420.2007.00924.x
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Heer J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1303
   Hollands JG, 2001, APPL COGNITIVE PSYCH, V15, P413, DOI 10.1002/acp.714
   Hullman J, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1461
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   HURLBERT SH, 1984, ECOL MONOGR, V54, P187, DOI 10.2307/1942661
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M, 2016, IEEE T VIS COMPUT GR, V22, P469, DOI 10.1109/TVCG.2015.2467671
   Knoblauch K, 2008, J STAT SOFTW, V25, P1
   Kong N, 2010, IEEE T VIS COMPUT GR, V16, P990, DOI 10.1109/TVCG.2010.186
   Kosara R, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P101, DOI [10.1109/VISUAL.2019.8933547, 10.1109/visual.2019.8933547]
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lewandowski D, 2009, J MULTIVARIATE ANAL, V100, P1989, DOI 10.1016/j.jmva.2009.04.008
   Liu F, 2018, STAT METHODS MED RES, V27, P1024, DOI 10.1177/0962280216650699
   Liu ZL, 2020, COMPUT GRAPH FORUM, V39, P693, DOI 10.1111/cgf.14033
   Lu M, 2022, IEEE T VIS COMPUT GR, V28, P718, DOI 10.1109/TVCG.2021.3114874
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McElreath R., 2016, Rethinking: An R package for fitting and manipulating Bayesian models
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Peissner Matthias, 2012, P 4 ACM SIGCHI S ENG, DOI [10.1145/2305484.2305500, DOI 10.1145/2305484.2305500]
   Pinheiro J, 2020, R package version 3.1-151
   R Core Team, 2017, R: A language and environment for statistical computing
   Reinecke K, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P11, DOI 10.1145/2556288.2557052
   Reinecke P., 2011, 16 INT C INTELL USER, P453
   Rensink RA, 2010, COMPUT GRAPH FORUM, V29, P1203, DOI 10.1111/j.1467-8659.2009.01694.x
   Smithson M, 2006, PSYCHOL METHODS, V11, P54, DOI 10.1037/1082-989X.11.1.54
   Srinivasan M., 2018, CHI C HUM FACTORS CO, P1
   STEVENS SS, 1958, PSYCHOL BULL, V55, P177, DOI 10.1037/h0044251
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   WILKINSON GN, 1973, ROY STAT SOC C-APP, V22, P392
   Yuan L, 2019, PSYCHON B REV, V26, P669, DOI 10.3758/s13423-018-1525-7
   Ziemkiewicz C, 2013, IEEE T VIS COMPUT GR, V19, P1109, DOI 10.1109/TVCG.2012.180
   Ziemkiewicz C, 2009, COMPUT GRAPH FORUM, V28, P911, DOI 10.1111/j.1467-8659.2009.01442.x
NR 70
TC 1
Z9 1
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1756
EP 1771
DI 10.1109/TVCG.2022.3226463
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500010
PM 37015487
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ye, SQ
   Chen, DD
   Han, SF
   Liao, J
AF Ye, Shuquan
   Chen, Dongdong
   Han, Songfang
   Liao, Jing
TI 3D Question Answering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud; scene understanding
ID LANGUAGE; VISION
AB Visual question answering (VQA) has experienced tremendous progress in recent years. However, most efforts have only focused on 2D image question-answering tasks. In this article, we extend VQA to its 3D counterpart, 3D question answering (3DQA), which can facilitate a machine's perception of 3D real-world scenarios. Unlike 2D image VQA, 3DQA takes the color point cloud as input and requires both appearance and 3D geometrical comprehension to answer the 3D-related questions. To this end, we propose a novel transformer-based 3DQA framework "3DQA-TR", which consists of two encoders to exploit the appearance and geometry information, respectively. Finally, the multi-modal information about the appearance, geometry, and linguistic question can attend to each other via a 3D-linguistic Bert to predict the target answers. To verify the effectiveness of our proposed 3DQA framework, we further develop the first 3DQA dataset "ScanQA", which builds on the ScanNet dataset and contains over 10 K question-answer pairs for 806 scenes. To the best of our knowledge, ScanQA is the first large-scale dataset with natural-language questions and free-form answers in 3D environments that is fully human-annotated. We also use several visualizations and experiments to investigate the astonishing diversity of the collected questions and the significant differences between this task from 2D VQA and 3D captioning. Extensive experiments on this dataset demonstrate the obvious superiority of our proposed 3DQA framework over state-of-the-art VQA frameworks and the effectiveness of our major designs. Our code and dataset will be made publicly available to facilitate research in this direction. The code and data are available at http://shuquanye.com/3DQA_website/.
C1 [Ye, Shuquan; Liao, Jing] City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
   [Chen, Dongdong] Microsoft Cloud AI, Redmond, WA 98052 USA.
   [Han, Songfang] Univ Calif San Diego, La Jolla, CA 92093 USA.
C3 City University of Hong Kong; University of California System;
   University of California San Diego
RP Liao, J (corresponding author), City Univ Hong Kong, Kowloon Tong, Hong Kong, Peoples R China.
EM shuquanye2-c@my.cityu.edu.hk; cddlyf@gmail.com; hansongfang@gmail.com;
   jingliao@cityu.edu.hk
RI Han, Songfang/AAA-5781-2020; Chen, Dongdong/AAR-4481-2020
OI Han, Songfang/0000-0002-6432-8764; Chen, Dongdong/0000-0002-4642-4373;
   LIAO, Jing/0000-0001-7014-5377
FU Hong Kong Research Grants Council
FX No Statement Available
CR Achlioptas Panos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P422, DOI 10.1007/978-3-030-58452-8_25
   Agrawal A, 2016, Arxiv, DOI arXiv:1606.07356
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Banerjee P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1888, DOI 10.1109/ICCV48922.2021.00192
   Bansal Ankan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P51, DOI 10.1007/978-3-030-58589-1_4
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Chaudhry R, 2020, IEEE WINT CONF APPL, P3501, DOI 10.1109/WACV45572.2020.9093269
   Chen D.Z., 2020, COMP VIS ECCV 202 20, P202
   Chen DZ, 2021, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR46437.2021.00321
   Chen HH, 2020, IEEE T VIS COMPUT GR, V26, P3255, DOI 10.1109/TVCG.2019.2920817
   Chen WH, 2021, IEEE WINT CONF APPL, P655, DOI 10.1109/WACV48630.2021.00070
   Chen XL, 2015, Arxiv, DOI [arXiv:1504.00325, 10.48550/arXiv.1504.00325, DOI 10.48550/ARXIV.1504.00325]
   Chou SH, 2020, IEEE WINT CONF APPL, P1596, DOI 10.1109/WACV45572.2020.9093452
   Chou W.-L., 2020, P IEEE CVF WINT C AP, P1607
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Das A, 2018, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2018.00008
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   David HA, 1997, AM STAT, V51, P9, DOI 10.2307/2684684
   Denkowski M., 2014, P EACL 2014 WORKSHOP, P376
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Feng M., 2021, arXiv
   Gao HY, 2015, ADV NEUR IN, V28
   Garcia M., 2020, AAAI C ARTIF INTELL, p10 826
   Goyal A., 2020, Advances in Neural Information Processing Systems, V33
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Hu SM, 2020, IEEE T VIS COMPUT GR, V26, P2485, DOI 10.1109/TVCG.2018.2889944
   Huang PH, 2021, AAAI CONF ARTIF INTE, V35, P1610
   Huang Yichen, 2020, INT C MACHINE LEARNI, P279
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kahou Samira Ebrahimi, 2018, arXiv, DOI DOI 10.48550/ARXIV.1710.07300
   Kervadec C, 2021, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR46437.2021.00280
   Kim J., 2017, 5 INT C LEARN REPR I, P1
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lan Zhenzhong, 2020, ICLR
   Lei J, 2020, Arxiv, DOI arXiv:1904.11574
   Lei J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1369
   Li L, 2023, IEEE T VIS COMPUT GR, V29, P3368, DOI 10.1109/TVCG.2022.3160005
   Li Xianzhi, 2021, IEEE T VISUALIZATION
   Liu Z, 2021, Arxiv, DOI arXiv:2104.00678
   Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782
   Loshchilov I., 2019, P 7 INT C LEARN REPR
   Lu JS, 2019, ADV NEUR IN, V32
   Lu J, 2020, PROC CVPR IEEE, P10434, DOI 10.1109/CVPR42600.2020.01045
   Lu JS, 2016, ADV NEUR IN, V29
   Malinowski M, 2014, ADV NEUR IN, V27
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Mathew M, 2021, IEEE WINT CONF APPL, P2199, DOI 10.1109/WACV48630.2021.00225
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qiu Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082281
   Qiu Y, 2019, INT CONF 3D VISION, P756, DOI 10.1109/3DV.2019.00088
   Ren MY, 2015, ADV NEUR IN, V28
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Singh A., 2018, SYSML WORKSH NEURIPS, V2018
   STEPHENS MA, 1974, J AM STAT ASSOC, V69, P730, DOI 10.2307/2286009
   Su W., 2020, ICLR
   Su Y.-C., 2021, arXiv
   Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100
   Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wijmans E, 2019, PROC CVPR IEEE, P6652, DOI 10.1109/CVPR.2019.00682
   Yang JW, 2020, Arxiv, DOI arXiv:2012.11587
   Yang ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1836, DOI 10.1109/ICCV48922.2021.00187
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Ye SQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6423, DOI 10.1109/ICCV48922.2021.00638
   Ye SQ, 2022, IEEE T VIS COMPUT GR, V28, P3206, DOI 10.1109/TVCG.2021.3058311
   Yu LC, 2015, Arxiv, DOI arXiv:1506.00278
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yuan ZH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1771, DOI 10.1109/ICCV48922.2021.00181
   Yun H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2011, DOI 10.1109/ICCV48922.2021.00204
   Zadeh A, 2019, PROC CVPR IEEE, P8799, DOI 10.1109/CVPR.2019.00901
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 84
TC 2
Z9 2
U1 4
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1772
EP 1786
DI 10.1109/TVCG.2022.3225327
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500008
PM 36446015
DA 2024-11-06
ER

PT J
AU Tu, YM
   Qiu, R
   Wang, YS
   Yen, PY
   Shen, HW
AF Tu, Yamei
   Qiu, Rui
   Wang, Yu-Shuen
   Yen, Po-Yin
   Shen, Han-Wei
TI PhraseMap: Attention-Based Keyphrases Recommendation for Information
   Seeking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Navigation; Bit error rate; Semantics; Computational
   modeling; Visual analytics; Task analysis; Textual data; machine
   learning; visual analytics; natural language processing;
   user-in-the-loop
ID VISUALIZATION
AB Many Information Retrieval (IR) approaches have been proposed to extract relevant information from a large corpus. Among these methods, phrase-based retrieval methods have been proven to capture more concrete and concise information than word-based and paragraph-based methods. However, due to the complex relationship among phrases and a lack of proper visual guidance, achieving user-driven interactive information-seeking and retrieval remains challenging. In this study, we present a visual analytic approach for users to seek information from an extensive collection of documents efficiently. The main component of our approach is a PhraseMap, where nodes and edges represent the extracted keyphrases and their relationships, respectively, from a large corpus. To build the PhraseMap, we extract keyphrases from each document and link the phrases according to word attention determined using modern language models, i.e., BERT. As can be imagined, the graph is complex due to the extensive volume of information and the massive amount of relationships. Therefore, we develop a navigation algorithm to facilitate information seeking. It includes (1) a question-answering (QA) model to identify phrases related to users' queries and (2) updating relevant phrases based on users' feedback. To better present the PhraseMap, we introduce a resource-controlled self-organizing map (RC-SOM) to evenly and regularly display phrases on grid cells while expecting phrases with similar semantics to stay close in the visualization. To evaluate our approach, we conducted case studies with three domain experts in diverse literature. The results and feedback demonstrate its effectiveness, usability, and intelligence.
C1 [Tu, Yamei; Qiu, Rui; Shen, Han-Wei] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Wang, Yu-Shuen] Natl Chiao Tung Univ, Hsinchu 30010, Taiwan.
   [Yen, Po-Yin] Washington Univ, Sch Med, St Louis, MO 63110 USA.
C3 University System of Ohio; Ohio State University; National Yang Ming
   Chiao Tung University; Washington University (WUSTL)
RP Tu, YM (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM tu.253@osu.edu; qiu.580@osu.edu; yushuen@cs.nctu.edu.tw; yenp@wustl.edu;
   shen.94@osu.edu
RI Tu, Yamei/KSL-7529-2024; Qiu, Rui/LLM-4177-2024; Shen,
   Han-wei/A-4710-2012; wang, yiting/GYU-5306-2022
OI Tu, Yamei/0000-0002-0722-837X; Qiu, Rui/0000-0002-3905-8926; Wang,
   Yu-Shuen/0000-0003-2550-2990; Shen, Han-Wei/0000-0002-1211-2320
FU NSF
FX No Statement Available
CR Andrews K, 2002, Inf. Visualization, V1, P3
   Barratt A, 2008, PATIENT EDUC COUNS, V73, P407, DOI 10.1016/j.pec.2008.07.054
   Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Berglund E, 2006, IEEE T NEURAL NETWOR, V17, P305, DOI 10.1109/TNN.2006.871720
   Bier EA, 2010, IEEE T VIS COMPUT GR, V16, P178, DOI 10.1109/TVCG.2009.104
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Borner K., 2010, Atlas of science: Visualizing what we know
   Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431
   Burd R, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206531
   Cao W., 2016, Introduction to text visualization
   Chen SX, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814017740710
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P1204, DOI 10.1109/TVCG.2019.2934263
   Chen SM, 2016, IEEE CONF VIS ANAL, P41, DOI 10.1109/VAST.2016.7883510
   Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212
   Coenen A, 2019, ADV NEUR IN, V32
   Couclelis H., 1998, CARTOGR GEOGR INF SC, V25, P209
   Cui L., 2020, Does bert solve commonsense task via commonsense knowledge, V4
   Cui YM, 2017, Arxiv, DOI arXiv:1607.04423
   Debiasi A, 2016, Study of visual clutter in geographic node-link diagrams
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Ding X., 2021, ACM Trans. Comput. Healthcare, V3, P1
   Dou WW, 2012, IEEE CONF VIS ANAL, P93, DOI 10.1109/VAST.2012.6400485
   Eftimov T, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179488
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fried D, 2014, IEEE PAC VIS SYMP, P113, DOI 10.1109/PacificVis.2014.47
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Galassi A, 2021, IEEE T NEUR NET LEAR, V32, P4291, DOI 10.1109/TNNLS.2020.3019893
   Gansner ER, 2010, LECT NOTES COMPUT SC, V5849, P405, DOI 10.1007/978-3-642-11805-0_38
   Heimerl F, 2016, IEEE CONF VIS ANAL, P11, DOI 10.1109/VAST.2016.7883507
   Hoffmann M, 2022, CELL, V185, P447, DOI 10.1016/j.cell.2021.12.032
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kim M., 2013, P 6 INT JOINT C NATU, P864
   Kim T, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13042276
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Kohonen T., 2007, Scholarpedia, V2, DOI [DOI 10.4249/SCHOLARPEDIA.1568, 10.4249/scholarpedia.1568]
   Kohonen T., 2012, Self-Organizing Maps, V30
   Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365
   Lan Zhenzhong, 2020, ICLR
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lee J, 2021, P 59 ANN M ASS COMP, V1, P6634, DOI DOI 10.18653/V1/2021.ACL-LONG.518
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Lewis DD, 1996, COMMUN ACM, V39, P92, DOI 10.1145/234173.234210
   Li ZY, 2020, IEEE T VIS COMPUT GR, V26, P1182, DOI 10.1109/TVCG.2019.2934667
   Liu MC, 2016, IEEE T VIS COMPUT GR, V22, P250, DOI 10.1109/TVCG.2015.2467554
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P2482, DOI 10.1109/TVCG.2018.2834341
   Liu SX, 2014, IEEE CONF VIS ANAL, P183, DOI 10.1109/VAST.2014.7042494
   Liu Y., 2021, bioRxiv, DOI [10.1101/2021.12.22.473615, DOI 10.1101/2021.12.22.473615]
   Liu Y., 2019, ROBERTA ROBUSTLY OPT
   Blei DM, 2009, Arxiv, DOI arXiv:0907.1013
   Ma DH, 2017, Arxiv, DOI [arXiv:1709.00893, DOI 10.48550/ARXIV.1709.00893]
   Marecek D, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P263
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nemet I, 2022, NEW ENGL J MED, V386, P492, DOI 10.1056/NEJMc2119358
   Nishida K, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P647, DOI 10.1145/3269206.3271702
   Nocaj A, 2012, IEEE T VIS COMPUT GR, V18, P2546, DOI 10.1109/TVCG.2012.250
   Park D, 2018, IEEE T VIS COMPUT GR, V24, P361, DOI 10.1109/TVCG.2017.2744478
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Perera N, 2020, FRONT CELL DEV BIOL, V8, DOI 10.3389/fcell.2020.00673
   Vu PM, 2016, IEEE INT CONF AUTOM, P726, DOI 10.1145/2970276.2970365
   Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341
   Radford Alec., 2018, Improving language understanding by generative pre-training
   Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019
   Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349
   Santorini B., 1990, PART OF SPEECH TAGGI
   Sarracen Gretel Liz De La Pena, 2023, Personal and Ubiquitous Computing, P45, DOI 10.1007/s00779-021-01605-5
   Shahriar Hossain M., 2012, PROC 18 ACM SIGKDD I, P1375, DOI [10.1145/2339530 .2339742, DOI 10.1145/2339530.2339742]
   SKUPIN ANDRE., 2003, CARTOGR GEOGR INF SC, V30, P95, DOI DOI 10.1559/152304003100011081
   Tang DY, 2016, Arxiv, DOI arXiv:1605.08900
   Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593
   Tu YM, 2021, IEEE PAC VIS SYMP, P206, DOI 10.1109/PacificVis52677.2021.00034
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Waltl G., 2018, C IRIS 2018
   Wang L., 2021, Phrase-bert: Improved phrase embeddings from bert with an application to corpus exploration
   Wang XT, 2016, IEEE CONF VIS ANAL, P51, DOI 10.1109/VAST.2016.7883511
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   Xu QN, 2020, NEUROCOMPUTING, V388, P135, DOI 10.1016/j.neucom.2020.01.024
   Leow YY, 2019, Arxiv, DOI arXiv:1904.06915
   Yang W., 2022, Influenza Other Respir. Viruses, V16
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Zhang DC, 2021, LECT NOTES ARTIF INT, V12977, P762, DOI 10.1007/978-3-030-86523-8_46
   Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029
   Zuo Y., 2022, Proceedings of the Design Society, V2, P821, DOI DOI 10.1017/PDS.2022.84
NR 88
TC 1
Z9 1
U1 5
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1787
EP 1802
DI 10.1109/TVCG.2022.3225114
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500001
PM 36441879
DA 2024-11-06
ER

PT J
AU Chai, YJ
   Shao, TJ
   Weng, YL
   Zhou, K
AF Chai, Yujin
   Shao, Tianjia
   Weng, Yanlin
   Zhou, Kun
TI Personalized Audio-Driven 3D Facial Animation via Style-Content
   Disentanglement
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Audio-driven animation; facial animation; style learning; style-content
   disentanglement; facial motion decomposition
ID PLUS PLUS
AB We present a learning-based approach for generating 3D facial animations with the motion style of a specific subject from arbitrary audio inputs. The subject style is learned from a video clip (1-2 minutes) either downloaded from the Internet or captured through an ordinary camera. Traditional methods often require many hours of the subject's video to learn a robust audio-driven model and are thus unsuitable for this task. Recent research efforts aim to train a model from video collections of a few subjects but ignore the discrimination between the subject style and underlying speech content within facial motions, leading to inaccurate style or articulation. To solve the problem, we propose a novel framework that disentangles subject-specific style and speech content from facial motions. The disentanglement is enabled by two novel training mechanisms. One is two-pass style swapping between two random subjects, and the other is joint training of the decomposition network and audio-to-motion network with a shared decoder. After training, the disentangled style is combined with arbitrary audio inputs to generate stylized audio-driven 3D facial animations. Compared with start-of-the-art methods, our approach achieves better results qualitatively and quantitatively, especially in difficult cases like bilabial plosive and bilabial nasal phonemes.
C1 [Chai, Yujin; Shao, Tianjia; Weng, Yanlin; Zhou, Kun] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Weng, YL (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM 11821001@zju.edu.cn; tjshao@zju.edu.cn; weng@cad.zju.edu.cn;
   kunzhou@acm.org
RI zhou, kun/KRP-1631-2024
OI Chai, Yujin/0000-0002-5525-6527
FU National Key Research and Development Program of China
FX No Statement Available
CR Cao Y, 2005, ACM T GRAPHIC, V24, P1283, DOI 10.1145/1095878.1095881
   Chai YJ, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-0133-7
   Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034
   Deng Z., 2004, PROC IEEE COMPUT ANI, P267
   Deng ZG, 2006, IEEE T VIS COMPUT GR, V12, P1523, DOI 10.1109/TVCG.2006.90
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Fan YR, 2022, PROC CVPR IEEE, P18749, DOI 10.1109/CVPR52688.2022.01821
   Feng Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459936
   github, Mozilla
   Gong SW, 2019, IEEE INT CONF COMP V, P4141, DOI 10.1109/ICCVW.2019.00509
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Hannun A, 2014, Arxiv, DOI arXiv:1412.5567
   Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Kim H, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356500
   Kingma D. P., 2017, P INT C LEARNING REP, P1
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liu MY, 2017, ADV NEUR IN, V30
   Mittal G, 2020, IEEE WINT CONF APPL, P3279, DOI [10.1109/wacv45572.2020.9093527, 10.1109/WACV45572.2020.9093527]
   Pham HX, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361, DOI 10.1145/3242969.3243017
   Pham HX, 2017, IEEE COMPUT SOC CONF, P2328, DOI 10.1109/CVPRW.2017.287
   Richard A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1153, DOI 10.1109/ICCV48922.2021.00121
   Schwartz JL, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003743
   Senin P., 2008, Information and Computer Science, V855, P1
   Shimba T, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P100, DOI 10.1109/SII.2015.7404961
   Song LS, 2022, IEEE T INF FOREN SEC, V17, P585, DOI 10.1109/TIFS.2022.3146783
   Suwajanakorn S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073640
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Unterthiner T., 2019, PROC INT C LEARN REP, P1
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Websdale D, 2018, INTERSPEECH, P2479, DOI 10.21437/Interspeech.2018-2066
   Wen X, 2020, IEEE T VIS COMPUT GR, V26, P3457, DOI 10.1109/TVCG.2020.3023573
   Wu HZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1478, DOI 10.1145/3474085.3475280
   Yao S., 2022, arXiv
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Zhang CX, 2023, IEEE T VIS COMPUT GR, V29, P1438, DOI 10.1109/TVCG.2021.3117484
   Zhang ZM, 2021, PROC CVPR IEEE, P3660, DOI 10.1109/CVPR46437.2021.00366
   Zheng RB, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4255, DOI 10.1109/ICASSP39728.2021.9413472
   Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416
   Zhou H, 2019, AAAI CONF ARTIF INTE, P9299
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
   Zhu H, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2362
NR 48
TC 0
Z9 0
U1 2
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1803
EP 1820
DI 10.1109/TVCG.2022.3230541
PG 18
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500003
PM 37015450
DA 2024-11-06
ER

PT J
AU Yao, LJ
   Vuillemot, R
   Bezerianos, A
   Isenberg, P
AF Yao, Lijie
   Vuillemot, Romain
   Bezerianos, Anastasia
   Isenberg, Petra
TI Designing for Visualization in Motion: Embedding Visualizations in
   Swimming Videos
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Embedded visualization; sports analytics; design framework;
   visualization in motion
AB We report on challenges and considerations for supporting design processes for visualizations in motion embedded in sports videos. We derive our insights from analyzing swimming race visualizations and motion-related data, building a technology probe, as well as a study with designers. Understanding how to design situated visualizations in motion is important for a variety of contexts. Competitive sports coverage, in particular, increasingly includes information on athlete or team statistics and records. Although moving visual representations attached to athletes or other targets are starting to appear, systematic investigations on how to best support their design process in the context of sports videos are still missing. Our work makes several contributions in identifying opportunities for visualizations to be added to swimming competition coverage but, most importantly, in identifying requirements and challenges for designing situated visualizations in motion. Our investigations include the analysis of a survey with swimming enthusiasts on their motion-related information needs, an ideation workshop to collect designs and elicit design challenges, the design of a technology probe that allows to create embedded visualizations in motion based on real data (Fig. 1), and an evaluation with visualization designers that aimed to understand the benefits of designing directly on videos.
C1 [Yao, Lijie; Isenberg, Petra] Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
   [Bezerianos, Anastasia] Univ Paris Saclay, CNRS, Inria, LISN, F-91190 Gif Sur Yvette, France.
   [Vuillemot, Romain] Univ Lyon, Ecole Cent Lyon, CNRS, UMR5205,LIRIS, F-69134 Lyon, France.
C3 Centre National de la Recherche Scientifique (CNRS); Inria; Universite
   Paris Saclay; Universite Paris Cite; Universite Paris Saclay; Centre
   National de la Recherche Scientifique (CNRS); Inria; Universite Paris
   Cite; Ecole Centrale de Lyon; Institut National des Sciences Appliquees
   de Lyon - INSA Lyon; Centre National de la Recherche Scientifique (CNRS)
RP Yao, LJ (corresponding author), Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
EM yaolijie0219@gmail.com; romain.vuillemot@ec-lyon.fr;
   anastasiab@gmail.com; petra.isenberg@inria.fr
RI Yao, Lijie/ISS-7925-2023; Vuillemot, Romain/ABE-5719-2020
OI Vuillemot, Romain/0000-0003-1447-6926; Isenberg,
   Petra/0000-0002-2948-6417; Yao, Lijie/0000-0002-4208-5140
FU Agence Nationale de la Recherche
FX No Statement Available
CR Bai L., 2016, PROC C PERVASIVE COM, P1
   Bressa N, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P173, DOI 10.1145/3322276.3322326
   Bucchieri F., 2022, Master's thesis
   Buxton Bill., 2011, Sketching User Experiences: Getting the Design Right and the Right Design
   Chen SW, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P217, DOI 10.1109/ISMAR-Adjunct51615.2020.00064
   Chen ZT, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581266
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P2645, DOI 10.1109/TVCG.2019.2892415
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   Dix A, 2003, HUM FAC ER
   FFN, French national swimming federation
   FootoVision, About us
   Holtz Y., From data to vis
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hutchinson Hilary, 2003, C HUM FACT COMP SYST
   labellmg, Welcome to labellmg
   Lin T., 2020, PROC IMMERSIVE ANALY
   Lin T., 2021, P ACM C HUM FACT COM, P13, DOI [DOI 10.1145/3411764.34456492, 10.1145/3411764.34456492,9, DOI 10.1145/3411764.34456492,9, 10.1145/3411764.3445649, DOI 10.1145/3411764.3445649]
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Liu ZC, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173697
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Oagaz H, 2022, IEEE T VIS COMPUT GR, V28, P4332, DOI 10.1109/TVCG.2021.3086403
   Olympics Aquatics, Welcome to the women's 200 m butterfly final at the Olympics Tokyo 2020
   Park H, 2018, LECT NOTES COMPUT SC, V10918, P725, DOI 10.1007/978-3-319-91797-9_50
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C., 2013, PROC SPORTS DATA VIS
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Ren DH, 2019, IEEE T VIS COMPUT GR, V25, P789, DOI 10.1109/TVCG.2018.2865158
   Ribecca S., The data visualisation catalogue
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Rogers Y., 2023, Interaction Design: Beyond Human-Computer Interact Ion
   Satyanarayan A, 2020, IEEE T VIS COMPUT GR, V26, P461, DOI 10.1109/TVCG.2019.2934281
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P351, DOI 10.1111/cgf.12391
   Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   sondages, LimeSurvey
   Sports Dynamics, About us
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   SwimFlow, The example design made and shared by swimflow
   Tang T, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484506
   Tang T, 2020, J VISUAL-JAPAN, V23, P707, DOI 10.1007/s12650-020-00644-z
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Willett W, 2017, IEEE T VIS COMPUT GR, V23, P461, DOI 10.1109/TVCG.2016.2598608
   Wu E, 2021, IEEE T VIS COMPUT GR, V27, P2566, DOI 10.1109/TVCG.2021.3067761
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Yao A., 2022, JOURNEE VISU 2022
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   youtube, Tokyo 2020 men's 100 m butterfly final
   youtube, SportBuzzBusiness
   youtube, Tokyo 2020 women's 100 m freestyle final
   youtube, Tokyo 2020 mixed-gender 4100 m medley final
   Zhang JE, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376172
NR 56
TC 0
Z9 0
U1 7
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1821
EP 1836
DI 10.1109/TVCG.2023.3341990
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500005
PM 38090861
OA Green Published
DA 2024-11-06
ER

PT J
AU Yang, WK
   Guo, YK
   Wu, J
   Wang, Z
   Guo, LZ
   Li, YF
   Liu, SX
AF Yang, Weikai
   Guo, Yukai
   Wu, Jing
   Wang, Zheng
   Guo, Lan-Zhe
   Li, Yu-Feng
   Liu, Shixia
TI Interactive Reweighting for Mitigating Label Quality Issues
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Training; Training data; Noise measurement; Annotations; Bipartite
   graph; Visualization; Data visualization; Bipartite graph visualization;
   sample reweighting; training data quality
ID VISUAL ANALYTICS; SYSTEM
AB Label quality issues, such as noisy labels and imbalanced class distributions, have negative effects on model performance. Automatic reweighting methods identify problematic samples with label quality issues by recognizing their negative effects on validation samples and assigning lower weights to them. However, these methods fail to achieve satisfactory performance when the validation samples are of low quality. To tackle this, we develop Reweighter, a visual analysis tool for sample reweighting. The reweighting relationships between validation samples and training samples are modeled as a bipartite graph. Based on this graph, a validation sample improvement method is developed to improve the quality of validation samples. Since the automatic improvement may not always be perfect, a co-cluster-based bipartite graph visualization is developed to illustrate the reweighting relationships and support the interactive adjustments to validation samples and reweighting results. The adjustments are converted into the constraints of the validation sample improvement method to further improve validation samples. We demonstrate the effectiveness of Reweighter in improving reweighting results through quantitative evaluation and two case studies.
C1 [Yang, Weikai; Guo, Yukai; Wang, Zheng; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
   [Wu, Jing] Cardiff Univ, Cardiff, Wales.
   [Guo, Lan-Zhe; Li, Yu-Feng] Nanjing Univ, Nanjing, Jiangsu, Peoples R China.
C3 Tsinghua University; Cardiff University; Nanjing University
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100084, Peoples R China.
EM yangwk21@mails.tsinghua.edu.cn; gyj22@mails.tsinghua.edu.cn;
   wuj11@cardiff.ac.uk; zheng-wa19@mails.tsinghua.edu.cn;
   guolz@lamda.nju.edu.cn; liyf@nju.edu.cn; shixia@tsinghua.edu.cn
RI li, yufeng/AAA-8596-2019; Liu, Shi-Xia/C-5574-2016
OI Guo, Yukai/0009-0000-9651-3617; Wang, Zheng/0009-0004-0575-5936; Wu,
   Jing/0000-0001-5123-9861; Guo, Lan-Zhe/0000-0001-8965-1288
FU National Natural Science Foundation of China
FX No Statement Available
CR [Anonymous], 2004, KDD Conference
   Bäuerle A, 2020, COMPUT GRAPH FORUM, V39, P195, DOI 10.1111/cgf.13973
   Boyd S., 2004, Convex Optimization, DOI 10.1017/CBO9780511804441
   Chakrabarti D., 2012, Graph Mining: Laws Tools and Case studies
   Chatterjee S, 2020, P INT C LEARN REPR
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Choi J, 2023, IEEE T VIS COMPUT GR, V29, P1424, DOI 10.1109/TVCG.2021.3116656
   Dennig FL, 2019, IEEE CONF VIS ANAL, P69, DOI [10.1109/vast47406.2019.8986940, 10.1109/VAST47406.2019.8986940]
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Eirich J, 2022, IEEE T VIS COMPUT GR, V28, P11, DOI 10.1109/TVCG.2021.3114797
   GANSNER ER, 1993, IEEE T SOFTWARE ENG, V19, P214, DOI 10.1109/32.221135
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Gray RM, 2011, ENTROPY AND INFORMATION THEORY , SECOND EDITION, P395, DOI 10.1007/978-1-4419-7970-4
   Gu KR, 2023, MACH LEARN, V112, P1871, DOI 10.1007/s10994-022-06207-7
   Halter G, 2019, COMPUT GRAPH FORUM, V38, P119, DOI 10.1111/cgf.13676
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He WB, 2022, IEEE T VIS COMPUT GR, V28, P1040, DOI 10.1109/TVCG.2021.3114855
   Hlawatsch M, 2014, IEEE T VIS COMPUT GR, V20, P1590, DOI 10.1109/TVCG.2014.2322594
   Hoang DA, 2022, Arxiv, DOI arXiv:2208.08132
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Khayat M, 2020, IEEE T VIS COMPUT GR, V26, P874, DOI 10.1109/TVCG.2019.2934266
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Li Z, 2022, IEEE T VIS COMPUT GR, V28, P4980, DOI 10.1109/TVCG.2022.3184186
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu YP, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2568
   Moehrmann J, 2011, LECT NOTES COMPUT SC, V6761, P618, DOI 10.1007/978-3-642-21602-2_67
   Paiva JGS, 2015, IEEE T VIS COMPUT GR, V21, P4, DOI 10.1109/TVCG.2014.2331979
   Park JH, 2021, IEEE T VIS COMPUT GR, V27, P2869, DOI 10.1109/TVCG.2019.2953026
   Park JH, 2016, IEEE CONF VIS ANAL, P21, DOI 10.1109/VAST.2016.7883508
   Ren MY, 2018, PR MACH LEARN RES, V80
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Robertson S., 2023, P CHI C HUM FACT COM, P1
   Robinson I, 2020, Arxiv, DOI arXiv:2002.05687
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Shu J, 2019, ADV NEUR IN, V32
   Snyder LS, 2020, IEEE T VIS COMPUT GR, V26, P558, DOI 10.1109/TVCG.2019.2934614
   Soares A, 2017, IEEE COMPUT GRAPH, V37, P28, DOI 10.1109/MCG.2017.3621221
   Song C. Li, 2022, IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3225554.[9]X, DOI 10.1109/TVCG.2022.3225554.[9]X]
   Sperrle F, 2019, IEEE CONF VIS ANAL, P11, DOI [10.1109/vast47406.2019.8986917, 10.1109/VAST47406.2019.8986917]
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Wang RX, 2018, IEEE T NEUR NET LEAR, V29, P2568, DOI 10.1109/TNNLS.2017.2699783
   Wang XM, 2020, IEEE CONF VIS ANAL, P1, DOI 10.1109/VAST50239.2020.00006
   Wang YX, 2017, PR MACH LEARN RES, V70
   Whang SE, 2020, PROC VLDB ENDOW, V13, P3429, DOI 10.14778/3415478.3415562
   Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Xu YJ, 2021, PROC CVPR IEEE, P144, DOI 10.1109/CVPR46437.2021.00021
   Yang M., 2023, Comput. Vis. Media
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2020, IEEE CONF VIS ANAL, P12, DOI 10.1109/VAST50239.2020.00007
   Yeshchenko A, 2022, IEEE T VIS COMPUT GR, V28, P3050, DOI 10.1109/TVCG.2021.3050071
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan J, 2021, IEEE T VIS COMPUT GR, V27, P1720, DOI 10.1109/TVCG.2020.3030432
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang Bowen, 2021, Advances in Neural Information Processing Systems, V34
   Zhang XY, 2023, IEEE PAC VIS SYMP, P167, DOI [10.1109/PacificVis56936.2023.00026, 10.1145/3608164.3608188]
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhang Z., 2021, P IEEE CVF INT C COM, P725
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 69
TC 1
Z9 1
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAR
PY 2024
VL 30
IS 3
BP 1837
EP 1852
DI 10.1109/TVCG.2023.3345340
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IN0A9
UT WOS:001166876500004
PM 38127601
OA Green Accepted, Green Submitted
DA 2024-11-06
ER

PT J
AU Nam, JW
   Isenberg, T
   Keefe, DF
AF Nam, Jung Who
   Isenberg, Tobias
   Keefe, Daniel F.
TI V-Mail: 3D-Enabled Correspondence About Spatial Data on (Almost) All
   Your Devices
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Three-dimensional displays; Annotations; Spatial
   databases; Collaboration; Software; Task analysis; Communication;
   human-computer interaction; immersive analytics; storytelling;
   visualization of scientific 3D data
ID VISUALIZATION; STORIES
AB We present V-Mail, a framework of cross-platform applications, interactive techniques, and communication protocols for improved multi-person correspondence about spatial 3D datasets. Inspired by the daily use of e-mail, V-Mail seeks to enable a similar style of rapid, multi-person communication accessible on any device; however, it aims to do this in the new context of spatial 3D communication, where limited access to 3D graphics hardware typically prevents such communication. The approach integrates visual data storytelling with data exploration, spatial annotations, and animated transitions. V-Mail "data stories" are exported in a standard video file format to establish a common baseline level of access on (almost) any device. The V-Mail framework also includes a series of complementary client applications and plugins that enable different degrees of story co-authoring and data exploration, adjusted automatically to match the capabilities of various devices. A lightweight, phone-based V-Mail app makes it possible to annotate data by adding captions to the video. These spatial annotations are then immediately accessible to team members running high-end 3D graphics visualization systems that also include a V-Mail client, implemented as a plugin. Results and evaluation from applying V-Mail to assist communication within an interdisciplinary science team studying Antarctic ice sheets confirm the utility of the asynchronous, cross-platform collaborative framework while also highlighting some current limitations and opportunities for future work.
C1 [Nam, Jung Who; Keefe, Daniel F.] Univ Minnesota, Minneapolis, MN 55455 USA.
   [Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, LISN, F-91190 Gif Sur Yvette, France.
C3 University of Minnesota System; University of Minnesota Twin Cities;
   Universite Paris Cite; Universite Paris Saclay; Inria; Centre National
   de la Recherche Scientifique (CNRS)
RP Nam, JW (corresponding author), Univ Minnesota, Minneapolis, MN 55455 USA.
EM namxx054@umn.edu; tobias.isenberg@inria.fr; dfk@umn.edu
RI ; Isenberg, Tobias/A-7575-2008
OI Nam, Jung Who/0000-0003-0295-6906; Keefe, Daniel/0000-0002-7039-2340;
   Isenberg, Tobias/0000-0001-7953-8644
FU National Science Foundation
FX No Statement Available
CR Acevedo D, 2001, IEEE VISUAL, P493, DOI 10.1109/VISUAL.2001.964560
   Ahrens B., inThe Visualization Handbook
   Akiba H, 2010, IEEE COMPUT GRAPH, V30, P61, DOI 10.1109/MCG.2009.107
   [Anonymous], 2016, Tech. rep. MSR-TR-2016-14
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Bach B, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3670, DOI 10.1145/2858036.2858387
   Bladin K, 2018, IEEE T VIS COMPUT GR, V24, P802, DOI 10.1109/TVCG.2017.2743958
   de Lange P, 2018, LECT NOTES COMPUT SC, V11007, P88, DOI 10.1007/978-3-319-96565-9_9
   Dong Hyun Jeong, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P231, DOI 10.1109/VAST.2010.5652958
   Duarte N., 2019, Data Story. Explain Data and Inspire Action through Story
   Eccles R, 2008, INFORM VISUAL, V7, P3, DOI 10.1057/palgrave.ivs.9500173
   Farooq H, 2016, SCI REP-UK, V6, DOI 10.1038/srep38927
   Gershon N, 2001, COMMUN ACM, V44, P31, DOI 10.1145/381641.381653
   Heer J, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1029
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Heer J, 2008, INFORM VISUAL, V7, P49, DOI 10.1057/palgrave.ivs.9500167
   Iserhardt-Bauer S, 2001, IEEE VISUAL, P425, DOI 10.1109/VISUAL.2001.964542
   Jeong DH, 2015, HUM-CENT COMPUT INFO, V5, DOI 10.1186/s13673-015-0023-4
   Johnson S, 2020, IEEE T VIS COMPUT GR, V26, P492, DOI 10.1109/TVCG.2019.2934260
   Klein T, 2018, IEEE T VIS COMPUT GR, V24, P862, DOI 10.1109/TVCG.2017.2744258
   Knaflic CN, 2015, STORYTELLING WITH DATA: A DATA VISUALIZATION GUIDE FOR BUSINESS PROFESSIONALS, P1, DOI 10.1002/9781119055259
   Kosara R, 2013, COMPUTER, V46, P44, DOI 10.1109/MC.2013.36
   Kouril D, 2023, IEEE T VIS COMPUT GR, V29, P1733, DOI 10.1109/TVCG.2021.3130670
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee B, 2013, IEEE T VIS COMPUT GR, V19, P2416, DOI 10.1109/TVCG.2013.191
   Liao Isaac, 2014, Smart Graphics. 12th International Symposium (SG 2014). Proceedings: LNCS 8698, P1, DOI 10.1007/978-3-319-11650-1_1
   Lidal EM, 2013, COMPUT GRAPH-UK, V37, P445, DOI 10.1016/j.cag.2013.01.010
   Luke EJ, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P61, DOI 10.1109/VISUAL.2002.1183758
   Lundblad Patrik, 2013, 2013 17th International Conference on Information Visualisation, P263, DOI 10.1109/IV.2013.35
   Ma KL, 2012, IEEE COMPUT GRAPH, V32, P12, DOI 10.1109/MCG.2012.24
   Meuschke M, 2021, Arxiv, DOI arXiv:2108.05462
   Riche C., 2018, Data-Driven Storytelling, DOI [10.1201/9781315281575, DOI 10.1201/9781315281575]
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Stolper B., 2016, Microsoft Research, Washing-ton, Tech. Rep. MSR-TR-2016-14
   Thöny M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030123
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Tsang, 2002, P 15 ANN ACM S US IN, P111, DOI [10.1145/571985.572001, DOI 10.1145/571985.572001]
   Usher W, 2020, SYMP LARG DATA ANAL, P27, DOI 10.1109/LDAV51489.2020.00010
   Viégas FB, 2007, IEEE T VIS COMPUT GR, V13, P1121, DOI 10.1109/TVCG.2007.70577
   Wohlfart Michael., 2007, EuroVis, P91, DOI [10.2312/VisSym/EuroVis07/091-098, DOI 10.2312/VISSYM/EUROVIS07/091-098]
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Ynnerman A, 2018, IEEE COMPUT GRAPH, V38, P13, DOI 10.1109/MCG.2018.032421649
NR 43
TC 0
Z9 0
U1 2
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1853
EP 1867
DI 10.1109/TVCG.2022.3229017
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500010
PM 37015540
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhao, HN
   Bryant, GW
   Griffin, W
   Terrill, JE
   Chen, J
AF Zhao, Henan
   Bryant, Garnett W.
   Griffin, Wesley
   Terrill, Judith E.
   Chen, Jian
TI Evaluating Glyph Design for Showing Large-Magnitude-Range Quantum Spins
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Image color analysis; Visualization; Three-dimensional
   displays; Data visualization; Behavioral sciences; Shape; Bivariate
   glyph; 3D glyph; large-magnitude-range; quantitative visualization;
   separable and integral dimension pairs
ID VISUALIZATION; PERCEPTION; SEARCH
AB We present experimental results to explore a form of bivariate glyphs for representing large-magnitude-range vectors. The glyphs meet two conditions: (1) two visual dimensions are separable; and (2) one of the two visual dimensions uses a categorical representation (e.g., a categorical colormap). We evaluate how much these two conditions determine the bivariate glyphs' effectiveness. The first experiment asks participants to perform three local tasks requiring reading no more than two glyphs. The second experiment scales up the search space in global tasks when participants must look at the entire scene of hundreds of vector glyphs to get an answer. Our results support that the first condition is necessary for local tasks when a few items are compared. But it is not enough for understanding a large amount of data. The second condition is necessary for perceiving global structures of examining very complex datasets. Participants' comments reveal that the categorical features in the bivariate glyphs trigger emergent optimal viewers' behaviors. This work contributes to perceptually accurate glyph representations for revealing patterns from large scientific results. We release source code, quantum physics data, training documents, participants' answers, and statistical analyses for reproducible science at https://osf.io/4xcf5/?view_only=94123139df9c4ac984a1e0df811cd580.
C1 [Zhao, Henan] Univ Maryland, Baltimore, MD 21250 USA.
   [Bryant, Garnett W.; Terrill, Judith E.] NIST, Gaithersburg, MD 20899 USA.
   [Griffin, Wesley] Stellar Sci, Albuquerque, NM 87110 USA.
   [Chen, Jian] Ohio State Univ, Columbus, OH 43210 USA.
C3 University System of Maryland; University of Maryland Baltimore;
   National Institute of Standards & Technology (NIST) - USA; University
   System of Ohio; Ohio State University
RP Chen, J (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM henan1@umbc.edu; garnett.bryant@nist.gov; griffin5@umbc.edu;
   judith.terrill@nist.gov; chen.8028@osu.edu
FU NSF
FX No Statement Available
CR Acevedo D., 2007, PROC IEEE VIS POSTER
   Albers D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P551, DOI 10.1145/2556288.2557200
   [Anonymous], 1967, Semiology of Graphics: Diagrams, Networks
   Ariely D, 2001, PSYCHOL SCI, V12, P157, DOI 10.1111/1467-9280.00327
   Biederman I., 1977, PROC ACM SIGGRAPH WO, P75, DOI DOI 10.1145/1024273.1024283
   Borgo R., 2013, EUROGRAPHICS 2013 ST, DOI DOI 10.2312/CONF/EG2013/STARS/039-063
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Buetti S, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56238-9
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   CALLAGHAN TC, 1989, PERCEPT PSYCHOPHYS, V46, P299, DOI 10.3758/BF03204984
   CASNER SM, 1991, ACM T GRAPHIC, V10, P111, DOI 10.1145/108360.108361
   Chen ZM, 2021, ATTEN PERCEPT PSYCHO, V83, P1240, DOI 10.3758/s13414-020-02067-2
   Chung DHS, 2016, COMPUT GRAPH FORUM, V35, P131, DOI 10.1111/cgf.12889
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Drew T, 2013, PSYCHOL SCI, V24, P1848, DOI 10.1177/0956797613479386
   DUNCAN J, 1989, PSYCHOL REV, V96, P433, DOI 10.1037/0033-295X.96.3.433
   Eckstein MP, 2017, CURR BIOL, V27, P2827, DOI 10.1016/j.cub.2017.07.068
   Forsberg AS, 2009, IEEE T VIS COMPUT GR, V15, P1219, DOI 10.1109/TVCG.2009.126
   Fuchs J, 2017, IEEE T VIS COMPUT GR, V23, P1863, DOI 10.1109/TVCG.2016.2549018
   GARNER WR, 1970, COGNITIVE PSYCHOL, V1, P225, DOI 10.1016/0010-0285(70)90016-2
   Gerrits T, 2017, IEEE T VIS COMPUT GR, V23, P980, DOI 10.1109/TVCG.2016.2598998
   Harrower M, 2003, CARTOGR J, V40, P27, DOI 10.1179/000870403235002042
   Healey C. G., 1995, ACM Transactions on Modeling and Computer Simulation, V5, P190, DOI 10.1145/217853.217855
   Healey C. G., 1996, ACM T COMPUT-HUM INT, V3, P107, DOI [DOI 10.1145/230562.230563, 10.1145/230562.230563]
   Healey CG, 1999, IEEE T VIS COMPUT GR, V5, P145, DOI 10.1109/2945.773807
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Kindmann G, 2006, IEEE T VIS COMPUT GR, V12, P1329, DOI 10.1109/TVCG.2006.134
   Kundel HL, 2007, RADIOLOGY, V242, P396, DOI 10.1148/radiol.2422051997
   Li R, 2018, 2018 IEEE SCIENTIFIC VISUALIZATION CONFERENCE (SCIVIS), P26, DOI 10.1109/SciVis.2018.8823764
   Lie A. E., 2009, P 25 SPRING C COMP G, P19, DOI DOI 10.1145/1980462.1980470
   Lleras A, 2020, ATTEN PERCEPT PSYCHO, V82, P394, DOI 10.3758/s13414-019-01928-9
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Maule J, 2014, J OPT SOC AM A, V31, pA93, DOI 10.1364/JOSAA.31.000A93
   McColeman CM, 2022, IEEE T VIS COMPUT GR, V28, P707, DOI 10.1109/TVCG.2021.3114684
   McNabb L, 2017, COMPUT GRAPH FORUM, V36, P589, DOI 10.1111/cgf.13212
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nothelfer C, 2017, J EXP PSYCHOL HUMAN, V43, P1667, DOI 10.1037/xhp0000314
   O'Shea JP, 2010, J VISION, V10, DOI 10.1167/10.12.21
   Oliva Aude, 2005, P251, DOI 10.1016/B978-012375731-9/50045-8
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Ropinski T, 2011, COMPUT GRAPH-UK, V35, P392, DOI 10.1016/j.cag.2011.01.011
   Ryan G, 2019, IEEE T VIS COMPUT GR, V25, P872, DOI 10.1109/TVCG.2018.2865264
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Sekimoto T., 2022, Sci. Rep., V12, P1
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P489, DOI 10.1109/TVCG.2015.2467759
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Urness T, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P115, DOI 10.1109/VISUAL.2003.1250362
   Ware C., 2012, Information Visualization: Perception for Design, V3rd
   Ware C, 2009, IEEE T VIS COMPUT GR, V15, P1523, DOI 10.1109/TVCG.2009.175
   Whitney D, 2018, ANNU REV PSYCHOL, V69, P105, DOI 10.1146/annurev-psych-010416-044232
   Wineland DJ, 2013, REV MOD PHYS, V85, P1103, DOI 10.1103/RevModPhys.85.1103
   Wolfe JM, 2021, PSYCHON B REV, V28, P1060, DOI 10.3758/s13423-020-01859-9
   Wolfe JM, 2019, CURR OPIN PSYCHOL, V29, P19, DOI 10.1016/j.copsyc.2018.11.005
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Zhang CG, 2016, IEEE T VIS COMPUT GR, V22, P797, DOI 10.1109/TVCG.2015.2467435
   Zhao HN, 2017, IEEE T VIS COMPUT GR, V23, P1691, DOI 10.1109/TVCG.2016.2539949
NR 59
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1868
EP 1884
DI 10.1109/TVCG.2022.3232591
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500007
PM 37015635
DA 2024-11-06
ER

PT J
AU Tetzlaff, M
AF Tetzlaff, Michael
TI High-Fidelity Specular SVBRDF Acquisition From Flash Photographs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Reflectivity; Rendering (computer graphics); Three-dimensional displays;
   Optimization; Geometry; Image color analysis; Lighting; Computational
   photography; flash photography; image-based relighting; non-linear
   optimization; normal map refinement; photogrammetry; real-time
   rendering; SVBRDF acquisition
ID APPEARANCE
AB Obtaining accurate SVBRDFs from 2D photographs of shiny, heterogeneous 3D objects is a highly sought-after goal for domains like cultural heritage archiving, where it is critical to document color appearance in high fidelity. In prior work such as the promising framework by Nam et al., the problem is simplified by assuming that specular highlights exhibit symmetry and isotropy about an estimated surface normal. The present work builds on this foundation with several significant modifications. Recognizing the importance of the surface normal as an axis of symmetry, we compare nonlinear optimization for normals with a linear approximation proposed by Nam et al. and find that nonlinear optimization is superior to the linear approximation, while noting that the surface normal estimates generally have a very significant impact on the reconstructed color appearance of the object. We also examine the use of a monotonicity constraint for reflectance and develop a generalization that also enforces continuity and smoothness when optimizing continuous monotonic functions like a microfacet distribution. Finally, we explore the impact of simplifying from an arbitrary 1D basis function to a traditional parametric microfacet distribution (GGX), and we find this to be a reasonable approximation that trades some fidelity for practicality in certain applications. Both representations can be used in existing rendering architectures like game engines or online 3D viewers, while retaining accurate color appearance for fidelity-critical applications like cultural heritage or online sales.
C1 [Tetzlaff, Michael] Univ Wisconsin Stout, Dept Math Stat & Comp Sci, Menomonie, WI 54751 USA.
C3 University of Wisconsin System; University of Wisconsin Stout
RP Tetzlaff, M (corresponding author), Univ Wisconsin Stout, Dept Math Stat & Comp Sci, Menomonie, WI 54751 USA.
EM tetzlaffm@uwstout.edu
RI Tetzlaff, Michael/AAC-6055-2019
OI Tetzlaff, Michael/0000-0002-5163-069X
CR Aittala M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925917
   Aittala M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766967
   Aittala M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461978
   Ashikhmin M., 2002, J GRAPHICS TOOLS, V7, P3
   Bagher MM, 2012, COMPUT GRAPH FORUM, V31, P1509, DOI 10.1111/j.1467-8659.2012.03147.x
   Bi S., 2020, ECCV
   Bi S., 2020, ACM Trans. Graph., V38
   Boss M, 2020, PROC CVPR IEEE, P3981, DOI 10.1109/CVPR42600.2020.00404
   Cook RL., 1982, ACM T GRAPHIC, V1, P7, DOI [DOI 10.1145/357290.357293, 10.1145/357290.357293]
   Debevec P., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P105
   Deschaintre V, 2021, PROC CVPR IEEE, P15562, DOI 10.1109/CVPR46437.2021.01531
   Deschaintre V, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201378
   Dong Y., 2014, ACM Trans. Graph., V33
   Dupuy J, 2015, COMPUT GRAPH FORUM, V34, P21, DOI 10.1111/cgf.12675
   Everitt Cass, 2001, White Paper
   Filip J, 2013, COMPUT GRAPH-UK, V37, P376, DOI 10.1016/j.cag.2013.02.010
   Fyffe G, 2016, COMPUT GRAPH FORUM, V35, P353, DOI 10.1111/cgf.12837
   Gao D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417767
   Gao D, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323042
   Garbin SJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14326, DOI 10.1109/ICCV48922.2021.01408
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Ghosh A, 2009, COMPUT GRAPH FORUM, V28, P1161, DOI 10.1111/j.1467-8659.2009.01493.x
   Guo J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459854
   Guo KW, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356571
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Heitz E., 2014, J COMP GRAPH TECH, V3, P32
   Henzler P, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480507
   Hui Z, 2017, IEEE I CONF COMP VIS, P5372, DOI 10.1109/ICCV.2017.573
   Kang KZ, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356492
   Kang KZ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201279
   Khronos Group, 2014, smoothstep
   Laine S, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417861
   Lensch HPA, 2003, ACM T GRAPHIC, V22, P234, DOI 10.1145/636886.636891
   Levenberg K., 1944, Q. Appl. Math, V2, P164, DOI [10.1090/QAM/10666, 10.1090/qam/10666, DOI 10.1090/QAM/10666]
   Li ZQ, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275055
   Ma XH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459679
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   McCamy C. S., 1976, Journal of Applied Photographic Engineering, V2, P95
   Meka A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323027
   Nam G, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275017
   Nam G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980220
   Nishino K. Ikeuchi, 2005, Tech.Rep. DU-CS-05-12, P39
   Palma M., Comput. Graph. Forum, V31
   Paterson JA, 2005, COMPUT GRAPH FORUM, V24, P383, DOI 10.1111/j.1467-8659.2005.00863.x
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Riviere J, 2016, COMPUT GRAPH FORUM, V35, P191, DOI 10.1111/cgf.12719
   Riviere J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130894
   Sen P, 2009, COMPUT GRAPH FORUM, V28, P609, DOI 10.1111/j.1467-8659.2009.01401.x
   Srinivasan PP, 2021, PROC CVPR IEEE, P7491, DOI 10.1109/CVPR46437.2021.00741
   Tetzlaff Michael., 2016, Eurographics Workshop on Graphics and Cultural Heritage, P137
   TROWBRIDGE TS, 1975, J OPT SOC AM, V65, P531, DOI 10.1364/JOSA.65.000531
   Tunwattanapong B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461944
   Walter B., 2007, RENDERING TECHNIQUES
   Wang Y., 2009, ACM Trans. Graph., V28, p29:1
   Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925
   Xia R, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980248
   Xu ZX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323007
   Xu ZX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201313
   Zhang XM, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480496
   Zhou ZM, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980247
   Zickler T, 2006, IEEE T PATTERN ANAL, V28, P1287, DOI 10.1109/TPAMI.2006.170
NR 61
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1885
EP 1896
DI 10.1109/TVCG.2023.3235277
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500012
PM 37018562
DA 2024-11-06
ER

PT J
AU Guillou, P
   Vidal, J
   Tierny, J
AF Guillou, Pierre
   Vidal, Jules
   Tierny, Julien
TI Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for
   Scalar Data - An Algorithm and a Benchmark
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE discrete Morse theory; persistence diagrams; scalar data; Topological
   data analysis
ID TOPOLOGICAL SIMPLIFICATION; EFFICIENT COMPUTATION; COMPLEXES
AB This paper introduces an efficient algorithm for persistence diagram computation, given an input piecewise linear scalar field f defined on a d-dimensional simplicial complex K, with d <= 3. Our work revisits the seminal algorithm "PairSimplices" (Edelsbrunner et al. 2002), (Zomorodian, 2010) with discrete Morse theory (DMT) (Forman, 1998), (Robins et al. 2011), which greatly reduces the number of input simplices to consider. Further, we also extend to DMT and accelerate the stratification strategy described in "PairSimplices" (Edelsbrunner et al. 2002), (Zomorodian, 2010) for the fast computation of the 0th and (d - 1)th diagrams, noted D-0(f) and Dd-1(f ). Minima-saddle persistence pairs (D-0(f )) and saddle-maximum persistence pairs (Dd-1(f )) are efficiently computed by processing, with a Union-Find, the unstable sets of 1-saddles and the stable sets of (d - 1)-saddles. This fast precomputation for the dimensions 0 and (d - 1) enables an aggressive specialization of (Bauer et al. 2014) to the 3D case, which results in a drastic reduction of the number of input simplices for the computation of D-1(f ), the intermediate layer of the sandwich. Finally, we document several performance improvements via shared-memory parallelism. We provide an open-source implementation of our algorithm for reproducibility purposes. Extensive experiments indicate that our algorithm improves by two orders of magnitude the time performance of the seminal "PairSimplices" algorithm it extends. Moreover, it also improves memory footprint and time performance over a selection of 14 competing approaches, with a substantial gain over the fastest available approaches, while producing a strictly identical output.
C1 [Guillou, Pierre; Vidal, Jules; Tierny, Julien] CNRS, F-75005 Paris, France.
   [Guillou, Pierre; Vidal, Jules; Tierny, Julien] Sorbonne Univ, F-75005 Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne Universite
RP Tierny, J (corresponding author), CNRS, F-75005 Paris, France.
EM pierre.guillou@lip6.fr; jules.vidal@lip6.fr;
   julien.tierny@sorbonne-universite.fr
OI Vidal, Jules/0000-0002-1154-4391
FU European Commission
FX No Statement Available
CR Adams Henry, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P129, DOI 10.1007/978-3-662-44199-2_23
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Barannikov S., 1994, Advances in Soviet Mathematics, V21, P93
   Bauer U., 2014, P TOP METH DAT AN VI, P103
   Bauer U., 2014, P 16 WORKSH ALG ENG, P31, DOI [10.1137/1.9781611973198.4, DOI 10.1137/1.9781611973198.4]
   Bauer U., 2019, Ripser: efficient computation of Vietoris-Rips persistence barcodes, DOI DOI 10.1186/s13059-016-0980-6
   Bauer U, 2017, J SYMB COMPUT, V78, P76, DOI 10.1016/j.jsc.2016.03.008
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Bin Masood T., 2019, P TOP METH DAT AN VI, VVI, P327
   Bock A, 2018, IEEE T VIS COMPUT GR, V24, P812, DOI 10.1109/TVCG.2017.2743980
   Boissonnat J., 2020, P INT S COMP GEOM, P1
   Boissonnat JD, 2015, ALGORITHMICA, V73, P607, DOI 10.1007/s00453-015-9999-4
   Boissonnat JD, 2014, ALGORITHMICA, V70, P406, DOI 10.1007/s00453-014-9887-3
   Bremer PT, 2011, IEEE T VIS COMPUT GR, V17, P1307, DOI 10.1109/TVCG.2010.253
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   Carr H, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P918
   Carr HA, 2016, SYMP LARG DATA ANAL, P75, DOI 10.1109/LDAV.2016.7874312
   Chen C., 2011, P 27 EUR WORKSH COMP, V11, P197
   Chen F, 2013, COMPUT AIDED GEOM D, V30, P557, DOI 10.1016/j.cagd.2012.03.019
   Chiang YJ, 2005, COMP GEOM-THEOR APPL, V30, P165, DOI 10.1016/j.comgeo.2004.05.002
   Cormen TH., 2009, INTRO ALGORITHMS
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   de Silva V, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/12/124003
   de Silva V, 2011, DISCRETE COMPUT GEOM, V45, P737, DOI 10.1007/s00454-011-9344-x
   Delgado-Friedrichs O., 2020, Digital image analysis using discrete Morse theory and persistent homology
   Dey T.K., 2014, P 30 ANN S COMP GEOM, P345, DOI DOI 10.1145/2582112.2582165
   Dey TK, 2019, LECT NOTES COMPUT SC, V11382, P123, DOI 10.1007/978-3-030-10828-1_10
   Doraiswamy H, 2021, IEEE T VIS COMPUT GR, V27, P561, DOI 10.1109/TVCG.2020.3030441
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H, 2009, Computational Topology An Introduction
   Favelier G, 2019, IEEE T VIS COMPUT GR, V25, P1152, DOI 10.1109/TVCG.2018.2864432
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, VB48c, P1
   Freudenthal H, 1942, ANN MATH, V43, P580, DOI 10.2307/1968813
   Frosini P., 1999, Pattern Recognition and Image Analysis, V9, P596
   Garin A., 2020, P INT S COMP GEOM, P1
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gueunet C., 2019, P EUR S PAR GRAPH VI, P27
   Gueunet C, 2019, IEEE T PARALL DISTR, V30, P1889, DOI 10.1109/TPDS.2019.2898436
   Gueunet C, 2016, SYMP LARG DATA ANAL, P85, DOI 10.1109/LDAV.2016.7874333
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A, 2014, COMPUT GRAPH FORUM, V33, P51, DOI 10.1111/cgf.12361
   Gyulassy A., 2011, P TOP METH DAT AN VI, P31
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Hebrail G, 2012, UCI Machine Learning Repository
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Henselman G, 2017, Arxiv, DOI arXiv:1606.00199
   Henselman-Petrusek G., 2018, Eirene.jl package for homological Algebra
   Iuricich F, 2022, IEEE T VIS COMPUT GR, V28, P4966, DOI 10.1109/TVCG.2021.3110663
   Kaji S., 2020, Cubical Ripser: Software for computing persistent homology of image and volume data
   Kasten J, 2011, IEEE T VIS COMPUT GR, V17, P2080, DOI 10.1109/TVCG.2011.249
   Klacansky P., 2020, Open scientific visualization data sets
   Kontak M, 2019, PROCEEDINGS OF URGENTHPC: 2019 FIRST IEEE/ACM INTERNATIONAL WORKSHOP ON HPC FOR URGENT DECISION MAKING (URGENTHPC), P7, DOI 10.1109/UrgentHPC49580.2019.00007
   Kruskal J. B., 1978, Multidimensional Scaling
   KUHN HW, 1960, IBM J RES DEV, V4, P518, DOI 10.1147/rd.45.0518
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Lukasczyk J, 2020, IEEE T VIS COMPUT GR, V26, P249, DOI 10.1109/TVCG.2019.2934368
   Maadasamy S, 2012, INT C HIGH PERFORM
   Maria Clement, 2014, Mathematical Software - ICMS 2014. 4th International Congress. Proceedings. LNCS: 8592, P167, DOI 10.1007/978-3-662-44199-2_28
   Milnor J., 1963, Annals of Math. Studies
   Mischaikow K, 2013, DISCRETE COMPUT GEOM, V50, P330, DOI 10.1007/s00454-013-9529-6
   Morozov D., 2017, Dionysus2
   Morozov D, 2020, PROCEEDINGS OF THE 32ND ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES (SPAA '20), P555, DOI 10.1145/3350755.3400244
   Morse M., 1934, The Calculus of Variations in the Large, DOI [10.1090/coll/018, DOI 10.1090/COLL/018]
   Nanda V., 2021, Perseus, the persistent homology software
   Nigmetov A., 2021, Oineus
   Oesterling P, 2011, IEEE T VIS COMPUT GR, V17, P1547, DOI 10.1109/TVCG.2011.27
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Parsa S., 2012, P 28 ANN S COMP GEOM, P269
   Pascucci V, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276449, 10.1145/1239451.1239509]
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Robins V, 1999, Topology Proc., V24, P503
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Saul Nathaniel, 2021, Zenodo
   Shivashankar N, 2016, IEEE T VIS COMPUT GR, V22, P1745, DOI 10.1109/TVCG.2015.2452919
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Smirnov D., 2017, PROC TOPOLOGICAL MET, P19
   Soler M, 2019, SYMP LARG DATA ANAL, P62, DOI [10.1109/ldav48142.2019.8944365, 10.1109/LDAV48142.2019.8944365]
   Soler M, 2018, SYMP LARG DATA ANAL, P23, DOI 10.1109/LDAV.2018.8739196
   Soler M, 2018, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis.2018.00015
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Suh A, 2020, IEEE T VIS COMPUT GR, V26, P697, DOI 10.1109/TVCG.2019.2934802
   Tarasov S. P., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P68, DOI 10.1145/276884.276892
   Tauzin G, 2021, J MACH LEARN RES, V22
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tierny J, 2012, IEEE T VIS COMPUT GR, V18, P2005, DOI 10.1109/TVCG.2012.228
   Tralie C., 2018, J. Open Source Soft, V3, P925, DOI DOI 10.21105/JOSS.00925
   Van Kreveld M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P212, DOI 10.1145/262839.269238
   Vidal J., 2021, P IEEE 11 S LARG DAT, P1
   Vidal J, 2021, IEEE T VIS COMPUT GR, V27, P2833, DOI 10.1109/TVCG.2021.3060500
   Vidal J, 2020, IEEE T VIS COMPUT GR, V26, P151, DOI 10.1109/TVCG.2019.2934256
   Wagner H., 2012, Topological Methods in Data Analysis and Visualization II: Theory, Algorithms, and Applications, P91, DOI DOI 10.1007/978-3-642-23175-97
   Weber GH, 2007, IEEE T VIS COMPUT GR, V13, P330, DOI 10.1109/TVCG.2007.47
   Zomorodian A. J, 2010, Algorithms and Theory of Computation Handbook, P82
NR 103
TC 4
Z9 4
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1897
EP 1915
DI 10.1109/TVCG.2023.3238008
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500001
PM 37021884
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Xu, SZ
   Liu, JH
   Wang, M
   Zhang, FL
   Zhang, SH
AF Xu, Sen-Zhe
   Liu, Jia-Hong
   Wang, Miao
   Zhang, Fang-Lue
   Zhang, Song-Hai
TI Multi-User Redirected Walking in Separate Physical Spaces for Online VR
   Scenarios
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Redirected walking; multi-user; online VR; fairness
AB With the recent rise of Metaverse, online multiplayer VR applications are becoming increasingly prevalent worldwide. However, as multiple users are located in different physical environments, different reset frequencies and timings can lead to serious fairness issues for online collaborative/competitive VR applications. For the fairness of online VR apps/games, an ideal online RDW strategy must make the locomotion opportunities of different users equal, regardless of different physical environment layouts. The existing RDW methods lack the scheme to coordinate multiple users in different PEs, and thus have the issue of triggering too many resets for all the users under the locomotion fairness constraint. We propose a novel multi-user RDW method that is able to significantly reduce the overall reset number and give users a better immersive experience by providing a fair exploration. Our key idea is to first find out the "bottleneck" user that may cause all users to be reset and estimate the time to reset given the users' next targets, and then redirect all the users to favorable poses during that maximized bottleneck time to ensure the subsequent resets can be postponed as much as possible. More particularly, we develop methods to estimate the time of possibly encountering obstacles and the reachable area for a specific pose to enable the prediction of the next reset caused by any user. Our experiments and user study found that our method outperforms existing RDW methods in online VR applications.
C1 [Xu, Sen-Zhe] Tsinghua Univ, YMSC, Beijing 100190, Peoples R China.
   [Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.
   [Liu, Jia-Hong; Zhang, Song-Hai] Tsinghua Univ, BNRist, Beijing 100190, Peoples R China.
   [Wang, Miao] Beihang Univ, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Sch Engn & Comp Sci, Wellington 6012, New Zealand.
C3 Tsinghua University; Tsinghua University; Tsinghua University; Beihang
   University; Victoria University Wellington
RP Zhang, SH (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100190, Peoples R China.; Zhang, SH (corresponding author), Tsinghua Univ, BNRist, Beijing 100190, Peoples R China.
EM xsz15@tsinghua.org.cn; liujiaho19@mails.tsinghua.edu.cn;
   miaowang.me@gmail.com; z.fanglue@gmail.com; shz@tsinghua.edu.cn
RI liu, jiahong/GXH-6188-2022
OI Xu, Sen-Zhe/0000-0003-2669-7814; Liu, JiaHong/0000-0001-9166-9364
FU National Natural Science Foundation of China
FX No Statement Available
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Chang Y., 2019, arXiv
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Dong ZC, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3345554
   Fan LW, 2023, IEEE T VIS COMPUT GR, V29, P4104, DOI 10.1109/TVCG.2022.3179269
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kennedy R., 1992, INT J AVIAT PSYCHOL, V2, P23, DOI [DOI 10.1207/S15327108IJAP02012, 10.1207/s15327108ijap02012]
   Williams NL, 2021, Arxiv, DOI arXiv:2106.06807
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Ondrejka C., 2004, NEW YORK LAW SCH LAW, V49, P81
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque S., 2005, Redirected Walking
   Razzaque Sharif, 2001, Redirected Walking, DOI [10.2312/egs.20011036, DOI 10.2312/EGS.20011036]
   Rewkowski N, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P395, DOI [10.1109/vr.2019.8798286, 10.1109/VR.2019.8798286]
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Steinicke G., 2009, JVRB-J. Virtual Reality Broadcast., V6
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Thomas C. Hutton, 2020, P 26 ACM S VIRT REAL, P1
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams A., IEEETrans.Vis.Comput.Graph., V27, P2535
   Williams B., 2006, Proceedings of the 3rd Symposium on applied Perception in Graphics and visualization (ACM), P21, DOI [10.1145/1140491.1140495, DOI 10.1145/1140491.1140495]
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
NR 36
TC 10
Z9 10
U1 12
U2 19
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1916
EP 1926
DI 10.1109/TVCG.2023.3251648
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500008
PM 37028008
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Valdrighi, G
   Ferreira, N
   Poco, J
AF Valdrighi, Giovani
   Ferreira, Nivan
   Poco, Jorge
TI MoReVis: A Visual Summary for Spatiotemporal Moving Regions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Spatiotemporal visualization; spatial interactions; spatial abstraction
ID TRACKING; SYSTEMS; LINES; FIT
AB Spatial and temporal interactions are central and fundamental in many activities in our world. A common problem faced when visualizing this type of data is how to provide an overview that helps users navigate efficiently. Traditional approaches use coordinated views or 3D metaphors like the Space-time cube to tackle this problem. However, they suffer from overplotting and often lack spatial context, hindering data exploration. More recent techniques, such as MotionRugs, propose compact temporal summaries based on 1D projection. While powerful, these techniques do not support the situation for which the spatial extent of the objects and their intersections is relevant, such as the analysis of surveillance videos or tracking weather storms. In this article, we propose MoReVis, a visual overview of spatiotemporal data that considers the objects' spatial extent and strives to show spatial interactions among these objects by displaying spatial intersections. Like previous techniques, our method involves projecting the spatial coordinates to 1D to produce compact summaries. However, our solution's core consists of performing a layout optimization step that sets the size and positions of the visual marks on the summary to resemble the actual values on the original space. We also provide multiple interactive mechanisms to make interpreting the results more straightforward for the user. We perform an extensive experimental evaluation and usage scenarios. Moreover, we evaluated the usefulness of MoReVis in a study with 9 participants. The results point out the effectiveness and suitability of our method in representing different datasets compared to traditional techniques.
C1 [Valdrighi, Giovani; Ferreira, Nivan] Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
   [Ferreira, Nivan] Univ Fed Pernambuco, BR-50670901 Recife, Brazil.
C3 Escola de Pos-Graduacao em Economia (EPGE); Getulio Vargas Foundation;
   Universidade Federal de Pernambuco
RP Valdrighi, G (corresponding author), Fundacao Getulio Vargas, BR-22250900 Rio De Janeiro, Brazil.
EM giovani.valdrighi@fgv.br; nivan@cin.ufpe.br; jpocom@gmail.com
RI Valdrighi, Giovani/LJK-6592-2024; Poco, Jorge/F-3344-2016
OI Valdrighi, Giovani/0000-0003-0106-4789; Poco, Jorge/0000-0001-9096-6287;
   Ferreira, Nivan/0000-0001-6631-4609
FU CNPq-Brazil
FX No Statement Available
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Andrienko N, 2013, IEEE T VIS COMPUT GR, V19, P2169, DOI 10.1109/TVCG.2013.193
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   [Anonymous], 2007, Cartogr Int J Geogr Inf Geovisualization, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   Arendt D, 2017, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2017.8585487
   Ayesha S, 2020, INFORM FUSION, V59, P44, DOI 10.1016/j.inffus.2020.01.005
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Bäuerle A, 2022, COMPUT GRAPH FORUM, V41, P235, DOI 10.1111/cgf.14536
   Bonchi F, 2009, LECT NOTES COMPUT SC, V5599, P190, DOI 10.1007/978-3-642-03511-1_9
   Buchmüller J, 2019, IEEE T VIS COMPUT GR, V25, P76, DOI 10.1109/TVCG.2018.2865049
   Buchmüller JF, 2021, COMPUT GRAPH-UK, V101, P23, DOI 10.1016/j.cag.2021.08.003
   Camargo SJ, 2007, J CLIMATE, V20, P3635, DOI 10.1175/JCLI4188.1
   Chavdarova T, 2018, PROC CVPR IEEE, P5030, DOI 10.1109/CVPR.2018.00528
   Chen W, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2436897
   Cox J, 2013, INT J UNCERTAIN QUAN, V3, P143, DOI 10.1615/Int.J.UncertaintyQuantification.2012003966
   Diehl A, 2021, COMPUT GRAPH FORUM, V40, P299, DOI 10.1111/cgf.14308
   DIXON M, 1993, J ATMOS OCEAN TECH, V10, P785, DOI 10.1175/1520-0426(1993)010<0785:TTITAA>2.0.CO;2
   Domingo-Ferrer J, 2012, INFORM SCIENCES, V208, P55, DOI 10.1016/j.ins.2012.04.015
   Ferreira N, 2013, COMPUT GRAPH FORUM, V32, P201, DOI 10.1111/cgf.12107
   Fonseca CM, 2021, SIBGRAPI, P176, DOI 10.1109/SIBGRAPI54419.2021.00032
   Franke M, 2021, COMPUT GRAPH FORUM, V40, P335, DOI 10.1111/cgf.14311
   Guo DS, 2006, J INTELL INF SYST, V27, P243, DOI 10.1007/s10844-006-9952-8
   Höferlin M, 2013, IEEE T MULTIMEDIA, V15, P908, DOI 10.1109/TMM.2013.2238521
   INSELBERG A, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P361, DOI 10.1109/VISUAL.1990.146402
   Joshi K. A., 2012, International Journal of Soft Computing and Engineering, V2, P44
   Kraak Menno-Jan, P 21 INT CART C, P1988
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Landsea C., 2021, The revised atlantic hurricane database (HURDAT2)
   Lee J, 2012, IMA VOL MATH APPL, V154, P1, DOI 10.1007/978-1-4614-1927-3
   Lee TY, 2019, IEEE PAC VIS SYMP, P318, DOI 10.1109/PacificVis.2019.00045
   Li H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134419
   Li ZH, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1989734.1989741
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Lu H., 1993, IEEE Data Eng. Bull., V16, P16
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Mirzargar M, 2014, IEEE T VIS COMPUT GR, V20, P2654, DOI 10.1109/TVCG.2014.2346455
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Peña-Araya V, 2022, INFORM VISUAL, V21, P38, DOI 10.1177/14738716211045007
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Tejada E., 2003, Information Visualization, V2, P218, DOI 10.1057/palgrave.ivs.9500054
   Thudt A., 2013, Proc. Eurographics Conference on Visualization (EuroVis), P79
   Tripathi P. K., 2016, P 9 ACM INT C PERV T
   Valdivia P, 2021, IEEE T VIS COMPUT GR, V27, P1, DOI 10.1109/TVCG.2019.2933196
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Dijk TC, 2016, LECT NOTES COMPUT SC, V9801, P382, DOI 10.1007/978-3-319-50106-2_30
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang ZJ, 2011, 2011 AASRI CONFERENCE ON ARTIFICIAL INTELLIGENCE AND INDUSTRY APPLICATION (AASRI-AIIA 2011), VOL 2, P37, DOI 10.1109/WiMOB.2011.6085392
   Wang ZC, 2014, INT CONF BIG DATA, P13, DOI 10.1109/BIGCOMP.2014.6741397
   Ware C., 2013, Information visualization, V2
   Wulms J, 2021, IEEE PAC VIS SYMP, P61, DOI 10.1109/PacificVis52677.2021.00016
NR 56
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1927
EP 1941
DI 10.1109/TVCG.2023.3250166
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500006
PM 37028073
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Maack, RGC
   Lukasczyk, J
   Tierny, J
   Hagen, H
   Maciejewski, R
   Garth, C
AF Maack, Robin G. C.
   Lukasczyk, Jonas
   Tierny, Julien
   Hagen, Hans
   Maciejewski, Ross
   Garth, Christoph
TI Parallel Computation of Piecewise Linear Morse-Smale Segmentations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Morse-smale complex; segmentation; topology; visualization; watershed
   transformation
ID EFFICIENT COMPUTATION; COMPLEXES; SIMPLIFICATION; SIMULATION; SURFACES;
   DISTANCE
AB This article presents a well-scaling parallel algorithm for the computation of Morse-Smale (MS) segmentations, including the region separators and region boundaries. The segmentation of the domain into ascending and descending manifolds, solely defined on the vertices, improves the computational time using path compression and fully segments the border region. Region boundaries and region separators are generated using a multi-label marching tetrahedra algorithm. This enables a fast and simple solution to find optimal parameter settings in preliminary exploration steps by generating an MS complex preview. It also poses a rapid option to generate a fast visual representation of the region geometries for immediate utilization. Two experiments demonstrate the performance of our approach with speedups of over an order of magnitude in comparison to two publicly available implementations. The example section shows the similarity to the MS complex, the useability of the approach, and the benefits of this method with respect to the presented datasets. We provide our implementation with the paper.
C1 [Maack, Robin G. C.; Lukasczyk, Jonas; Hagen, Hans; Garth, Christoph] RPTU Kaiserslautern Landau, D-67663 Kaiserslautern, Germany.
   [Tierny, Julien] Sorbonne Univ, CNRS, F-75006 Paris, France.
   [Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85281 USA.
C3 Centre National de la Recherche Scientifique (CNRS); Sorbonne
   Universite; Arizona State University; Arizona State University-Tempe
RP Maack, RGC (corresponding author), RPTU Kaiserslautern Landau, D-67663 Kaiserslautern, Germany.
EM maack@rhrk.uni-kl.de; jl@jluk.de; julien.tierny@sorbonne-universite.fr;
   hagen@cs.uni-kl.de; rmacieje@asu.edu; garth@cs.uni-kl.de
RI Garth, Christoph/Q-5901-2018
OI Garth, Christoph/0000-0003-1669-8549; Maack, Robin Georg
   Claus/0000-0002-2414-3351; Lukasczyk, Jonas/0000-0001-6650-770X; Hagen,
   Hans/0000-0001-5626-963X
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Banchoff T. F., 1967, The American Mathematical Monthly, V1, P245, DOI DOI 10.1080/00029890.1970.119925231
   BANCHOFF TF, 1970, AM MATH MON, V77, P475, DOI 10.2307/2317380
   Beucher S., 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P1928
   Beucher S., 1979, Use of watersheds in contour detection
   Bhatia H, 2018, J COMPUT CHEM, V39, P936, DOI 10.1002/jcc.25181
   Bremer PT, 2004, IEEE T VIS COMPUT GR, V10, P385, DOI 10.1109/TVCG.2004.3
   Carr H, 2006, IEEE T VIS COMPUT GR, V12, P231, DOI 10.1109/TVCG.2006.22
   Chouchane M, 2019, ACS OMEGA, V4, P11141, DOI 10.1021/acsomega.9b01279
   Cook AW, 2004, J FLUID MECH, V511, P333, DOI 10.1017/S0022112004009681
   Danovaro E, 2003, LECT NOTES COMPUT SC, V2616, P386
   Danovaro E., 2003, Proceedings ACM GIS 2003 - The 11th International Symposium on Advances in Geographic Information Systems, P63, DOI [10.1145/956676.956685, DOI 10.1145/956676.956685]
   De Floriani L, 2015, COMPUT GRAPH FORUM, V34, P761, DOI 10.1111/cgf.12596
   DOI A, 1991, IEICE TRANS COMMUN, V74, P214
   Dong S, 2006, ACM T GRAPHIC, V25, P1057, DOI 10.1145/1141911.1141993
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Edelsbrunner H., 2001, PROC 17 ANN ACM SYMP, P70, DOI DOI 10.1145/378583.378626
   Edelsbrunner H, 2009, Computational Topology An Introduction
   Edelsbrunner H., 2003, P 19 ANN S COMPUTATI, P361, DOI [DOI 10.1145/777792.7778464, 10.1145/777792.777846, DOI 10.1145/777792.777846, 10.1145/777792.7778462, DOI 10.1145/777792.7778462]
   Fellegara R., 2014, PROC 22 ACM SIGSPATI, P223
   Forman R, 1998, ADV MATH, V134, P90, DOI 10.1006/aima.1997.1650
   Forman R., 2002, Seminaire Lotharingien de Combinatoire, V48, pB48c
   Gabrielyan Y, 2022, IEEE IMAGE PROC, P1501, DOI 10.1109/ICIP46576.2022.9897372
   Günther D, 2014, IEEE T VIS COMPUT GR, V20, P2476, DOI 10.1109/TVCG.2014.2346403
   Guenther D, 2012, VISUAL COMPUT, V28, P959, DOI 10.1007/s00371-012-0726-8
   Gyulassy A, 2006, IEEE T VIS COMPUT GR, V12, P474, DOI 10.1109/TVCG.2006.57
   Gyulassy A, 2008, IEEE T VIS COMPUT GR, V14, P1619, DOI 10.1109/TVCG.2008.110
   Gyulassy A, 2007, IEEE T VIS COMPUT GR, V13, P1440, DOI 10.1109/TVCG.2007.70552
   Gyulassy A, 2019, IEEE T VIS COMPUT GR, V25, P1183, DOI 10.1109/TVCG.2018.2864848
   Gyulassy A, 2016, IEEE T VIS COMPUT GR, V22, P916, DOI 10.1109/TVCG.2015.2467432
   Gyulassy A, 2014, IEEE T VIS COMPUT GR, V20, P2595, DOI 10.1109/TVCG.2014.2346434
   Gyulassy A, 2012, IEEE T VIS COMPUT GR, V18, P2014, DOI 10.1109/TVCG.2012.209
   Gyulassy A, 2012, INT PARALL DISTRIB P, P484, DOI 10.1109/IPDPS.2012.52
   Gyulassy AG, 2007, IEEE T VIS COMPUT GR, V13, P1432, DOI 10.1109/TVCG.2007.70603
   Heine C, 2016, COMPUT GRAPH FORUM, V35, P643, DOI 10.1111/cgf.12933
   Homberg U., 2014, Topological Methods in Data Analysis and Visualization, VIII, P235
   King H, 2005, EXP MATH, V14, P435, DOI 10.1080/10586458.2005.10128941
   Laney D, 2006, IEEE T VIS COMPUT GR, V12, P1053, DOI 10.1109/TVCG.2006.186
   Lewiner T, 2013, COMPUT AIDED GEOM D, V30, P609, DOI 10.1016/j.cagd.2012.03.012
   Lorensen WE., 1998, Seminal graphics: pioneering efforts that shaped the field; SIGGRAPH 98; celebrating 25 years of discovery; a publication of ACM SIGGRAPH, P347, DOI [10.1145/37401.37422, DOI 10.1145/37401.37422, 10.1145/280811.281026, DOI 10.1145/280811.281026]
   Lukasczyk Jonas, 2017, Applied Mechanics and Materials, V869, P9, DOI 10.4028/www.scientific.net/AMM.869.9
   Lukasczyk J, 2021, IEEE T VIS COMPUT GR, V27, P572, DOI 10.1109/TVCG.2020.3030353
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Masood T. B, 2021, Topological Methods in Data Analysis and Visualization VI: Theory, Applications, and Software
   MEYER F, 1994, SIGNAL PROCESS, V38, P113, DOI 10.1016/0165-1684(94)90060-4
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Meyer F., 1993, Mathematical morphology and its applications to signal processing, P70
   Milnor J., 1963, Annals of Math. Studies
   Müller TM, 2014, COMP MATER SCI, V81, P205, DOI 10.1016/j.commatsci.2013.08.013
   Najman L, 1993, PROC MATH MORPHOL AP, P76
   Nielson GM, 1997, VISUALIZATION '97 - PROCEEDINGS, P229, DOI 10.1109/VISUAL.1997.663887
   NIELSON GM, 1991, VISUALIZATION 91, P83
   Olejniczak M, 2020, INT J QUANTUM CHEM, V120, DOI 10.1002/qua.26133
   Peterka T., 2011, Proceedings of the IEEE Symposium on Large Data Analysis and Visualization (LDAV 2011), P105, DOI 10.1109/LDAV.2011.6092324
   Pierre G, 2023, IEEE Trans. Vis. Comput. Graph.
   Robins V, 2011, IEEE T PATTERN ANAL, V33, P1646, DOI 10.1109/TPAMI.2011.95
   Seidel R, 2005, SIAM J COMPUT, V34, P515, DOI 10.1137/S0097539703439088
   Shivashankar N, 2012, IEEE T VIS COMPUT GR, V18, P1757, DOI 10.1109/TVCG.2011.284
   Shivashankar N, 2012, COMPUT GRAPH FORUM, V31, P965, DOI 10.1111/j.1467-8659.2012.03089.x
   Soille P., 2004, MORPHOLOGICAL IMAGE, DOI [DOI 10.1007/978-3-662-03939-7, DOI 10.1007/978-3-662-05088-0]
   Sousbie T, 2011, MON NOT R ASTRON SOC, V414, P350, DOI 10.1111/j.1365-2966.2011.18394.x
   Stoev SL, 2000, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2000.885672
   Subhash V, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P36, DOI 10.1109/VIS47514.2020.00014
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   TTK Contributers, 2021, TTK Tutorial Data
   TTK Contributers, 2020, TTK Data Repository
   Venkat A, 2022, IEEE T VIS COMPUT GR, V28, P76, DOI 10.1109/TVCG.2021.3114819
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Weinkauf T, 2010, COMPUT GRAPH FORUM, V29, P1221, DOI 10.1111/j.1467-8659.2009.01702.x
   Weinstein D, 2000, IEEE VISUAL, P283, DOI 10.1109/VISUAL.2000.885706
   Yeghiazaryan V, 2018, IEEE WINT CONF APPL, P577, DOI 10.1109/WACV.2018.00069
   ZHANG N., 2006, Proceedings of Eurographics Symposium on Point-Based Graphics 2006, P145
   Zomorodian A. J, 2010, Algorithms and Theory of Computation Handbook, P82
NR 72
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1942
EP 1955
DI 10.1109/TVCG.2023.3261981
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500009
PM 37030777
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Hong, JY
   Maciejewski, R
   Trubuil, A
   Isenberg, T
AF Hong, Jiayi
   Maciejewski, Ross
   Trubuil, Alain
   Isenberg, Tobias
TI Visualizing and Comparing Machine Learning Predictions to Improve
   Human-AI Teaming on the Example of Cell Lineage
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cell lineage; comparing ML predictions; human -AI teaming; machine
   learning; plant biology; visual analytics; visualization
ID DIVISION; ANALYTICS; PLATFORM
AB We visualize the predictions of multiple machine learning models to help biologists as they interactively make decisions about cell lineage-the development of a (plant) embryo from a single ovum cell. Based on a confocal microscopy dataset, traditionally biologists manually constructed the cell lineage, starting from this observation and reasoning backward in time to establish their inheritance. To speed up this tedious process, we make use of machine learning (ML) models trained on a database of manually established cell lineages to assist the biologist in cell assignment. Most biologists, however, are not familiar with ML, nor is it clear to them which model best predicts the embryo's development. We thus have developed a visualization system that is designed to support biologists in exploring and comparing ML models, checking the model predictions, detecting possible ML model mistakes, and deciding on the most likely embryo development. To evaluate our proposed system, we deployed our interface with six biologists in an observational study. Our results show that the visual representations of machine learning are easily understandable, and our tool, LineageD+, could potentially increase biologists' working efficiency and enhance the understanding of embryos.
C1 [Hong, Jiayi; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85281 USA.
   [Trubuil, Alain] Univ Paris Saclay, INRAE, F-69100 Villeurbanne, France.
   [Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, F-91120 Palaiseau, France.
C3 Arizona State University; Arizona State University-Tempe; Universite
   Paris Saclay; Universite Paris Cite; INRAE; Inria; Universite Paris
   Cite; Universite Paris Saclay; Institut Polytechnique de Paris; Ecole
   Polytechnique; Centre National de la Recherche Scientifique (CNRS)
RP Isenberg, T (corresponding author), Univ Paris Saclay, CNRS, Inria, F-91120 Palaiseau, France.
EM jiayi.hong@hotmail.com; rmacieje@asu.edu; alain.trubuil@inra.fr;
   tobias.isenberg@inria.fr
RI Isenberg, Tobias/A-7575-2008
OI Isenberg, Tobias/0000-0001-7953-8644; Hong, Jiayi/0000-0002-1332-5045
FU Inria#x0027;s Naviscope Project
FX No Statement Available
CR Bajusz D, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/s13321-015-0069-3
   Besson S, 2011, P NATL ACAD SCI USA, V108, P6294, DOI 10.1073/pnas.1011866108
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burkart N, 2021, J ARTIF INTELL RES, V70, P245
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Dietvorst BJ, 2018, MANAGE SCI, V64, P1155, DOI 10.1287/mnsc.2016.2643
   Eisen MB, 1998, P NATL ACAD SCI USA, V95, P14863, DOI 10.1073/pnas.95.25.14863
   Endsley MR, 2022, J COGN ENG DECIS MAK, V16, P179, DOI 10.1177/15553434221133288
   Gil Y, 2019, PROCEEDINGS OF IUI 2019, P614, DOI 10.1145/3301275.3302324
   Harper B., 1993, P 1 ANN MIDATLANTIC, P224
   Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115
   Hong JY, 2022, COMPUT GRAPH FORUM, V41, P195, DOI 10.1111/cgf.14533
   Jaegul Choo, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P27, DOI 10.1109/VAST.2010.5652443
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kwon BC, 2018, IEEE T VIS COMPUT GR, V24, P142, DOI 10.1109/TVCG.2017.2745085
   Leggio B, 2019, bioRxiv, DOI [10.1101/785337, 10.1101/785337, DOI 10.1101/785337]
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Martinez P, 2018, PLANT CELL, V30, P2255, DOI 10.1105/tpc.18.00401
   Minc N, 2012, TRENDS CELL BIOL, V22, P193, DOI 10.1016/j.tcb.2012.01.003
   Mohammed R, 2020, INT CONF INFORM COMM, P243, DOI 10.1109/ICICS49469.2020.239556
   National academies of sciences engineering and medicine, 2022, Human-AI teaming: State-Of-The-Art and research needs, DOI [10.17226/26355, DOI 10.17226/26355]
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Pagendarm H.-G., 1994, PROC EUROGRAPHICS WO, P95
   Patton M. Q., 2015, Qualitative Research & Evaluation Methods: Integrating Theory and Practice
   Pavlopoulos GA, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-104
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Pierre A, 2016, DEV CELL, V39, P667, DOI 10.1016/j.devcel.2016.11.018
   Rosset A, 2004, J DIGIT IMAGING, V17, P205, DOI 10.1007/s10278-004-1014-6
   Sacha D, 2019, IEEE T VIS COMPUT GR, V25, P385, DOI 10.1109/TVCG.2018.2864838
   Salvador-Martinez I., 2021, NUCLEIC ACIDS RES, V49, pW80, DOI DOI 10.1093/nar/gkab325
   Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/NMETH.2019, 10.1038/nmeth.2019]
   Schroeder WJ, 1996, IEEE VISUAL, P93, DOI 10.1109/VISUAL.1996.567752
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Seo J, 2002, COMPUTER, V35, P80
   Siau Keng, 2018, Cutter Business Technology Journal, V31, P47
   Speckmann B, 2010, IEEE T VIS COMPUT GR, V16, P881, DOI 10.1109/TVCG.2010.180
   Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   Sugawara K, 2022, ELIFE, V11, DOI [10.7554/eLife.69380, 10.7554/eLife.69380.sa1, 10.7554/eLife.69380.sa2]
   Tam GKL, 2017, IEEE T VIS COMPUT GR, V23, P71, DOI 10.1109/TVCG.2016.2598829
   Tinevez JY, 2017, METHODS, V115, P80, DOI 10.1016/j.ymeth.2016.09.016
   Woodring J, 2006, IEEE T VIS COMPUT GR, V12, P909, DOI 10.1109/TVCG.2006.164
NR 47
TC 1
Z9 1
U1 4
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1956
EP 1969
DI 10.1109/TVCG.2023.3302308
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500003
PM 37665712
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wang, SY
   Yan, H
   Isaacs, KE
   Sun, YF
AF Wang, Shaoyu
   Yan, Hang
   Isaacs, Katherine E.
   Sun, Yifan
TI Visual Exploratory Analysis for Designing Large-Scale Network-on-Chip
   Architectures: A Domain Expert-Led Design Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Computer architecture;
   Network-on-chip; Behavioral sciences; Synchronization; Collaboration;
   design study; network-on-chip; performance analysis
ID NOC; BYPASS; ATTACK
AB Visualization design studies bring together visualization researchers and domain experts to address yet unsolved data analysis challenges stemming from the needs of the domain experts. Typically, the visualization researchers lead the design study process and implementation of any visualization solutions. This setup leverages the visualization researchers' knowledge of methodology, design, and programming, but the availability to synchronize with the domain experts can hamper the design process. We consider an alternative setup where the domain experts take the lead in the design study, supported by the visualization experts. In this study, the domain experts are computer architecture experts who simulate and analyze novel computer chip designs. These chips rely on a Network-on-Chip (NOC) to connect components. The experts want to understand how the chip designs perform and what in the design led to their performance. To aid this analysis, we develop Vis4Mesh, a visualization system that provides spatial, temporal, and architectural context to simulated NOC behavior. Integration with an existing computer architecture visualization tool enables architects to perform deep-dives into specific architecture component behavior. We validate Vis4Mesh through a case study and a user study with computer architecture researchers. We reflect on our design and process, discussing advantages, disadvantages, and guidance for engaging in a domain expert-led design studies.
C1 [Wang, Shaoyu; Yan, Hang] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
   [Isaacs, Katherine E.] Univ Utah, Salt Lake City, UT 84112 USA.
   [Sun, Yifan] William & Mary, Williamsburg, VA 23185 USA.
C3 Huazhong University of Science & Technology; Utah System of Higher
   Education; University of Utah
RP Sun, YF (corresponding author), William & Mary, Williamsburg, VA 23185 USA.
EM wsyy0619@gmail.com; iyanhang@gmail.com; kisaacs@sci.utah.edu;
   ysun25@wm.edu
RI Shaoyu, Wang/HSH-3251-2023
OI Wang, Shaoyu/0009-0005-7741-1953; Sun, Yifan/0000-0003-3532-6521; Yan,
   Hang/0000-0002-3386-8784; Isaacs, Katherine/0000-0002-9947-928X
FU National Science Foundation
FX No Statement Available
CR Akbaba D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581168
   Ariel A, 2010, INT SYM PERFORM ANAL, P164, DOI 10.1109/ISPASS.2010.5452029
   Ascia G, 2020, INT SYMP NETW CHIP
   Bashir J, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241713
   Bharadwaj S, 2021, INT SYMP NETW CHIP, P49, DOI 10.1145/3479876.3481590
   Bhatele A, 2016, INT PARALL DISTRIB P, P93, DOI 10.1109/IPDPS.2016.123
   Bisht B, 2022, IEEE DES TEST, V39, P39, DOI 10.1109/MDAT.2022.3202998
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brown K.A., 2014, PROC 21 EUR MPI USER, DOI DOI 10.1145/2642769.2642789
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chen C, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241585
   Chen ZQ, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2022.3204201
   Cheng SH, 2014, 2014 FIRST WORKSHOP ON VISUAL PERFORMANCE ANALYSIS (VPA), P9, DOI 10.1109/VPA.2014.7
   Devkota S, 2021, IEEE T VIS COMPUT GR, V27, P667, DOI 10.1109/TVCG.2020.3030357
   Fujiwara T, 2017, IEEE CONF VIS ANAL, P59, DOI 10.1109/VAST.2017.8585646
   Gogte V., 2015, PROC 8 INT WORKSHOP, P21, DOI [10.1145/2835512.2835518, DOI 10.1145/2835512.2835518]
   González JA, 2021, INT SYMP NETW CHIP, P61
   Grammatikakis MD, 2021, INT SYMP NETW CHIP, P75, DOI 10.1145/3479876.3481598
   Hall KW, 2020, IEEE T VIS COMPUT GR, V26, P109, DOI 10.1109/TVCG.2019.2934790
   Haynes R., 2001, Proceedings 2001 IEEE International Conference on Cluster Computing, P295, DOI 10.1109/CLUSTR.2001.959990
   Isaacs KE, 2012, 2012 SC COMPANION: HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SCC), P1380
   Joseph JM, 2021, INT SYMP NETW CHIP, P15, DOI 10.1145/3479876.3481591
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung DC, 2020, INT SYMP NETW CHIP
   Kaeli D., 2015, PROC WORKSHOP COMPUT, P1, DOI [10.1145/2795122.2795125, DOI 10.1145/2795122.2795125]
   Kerzner E, 2019, IEEE T VIS COMPUT GR, V25, P748, DOI 10.1109/TVCG.2018.2865241
   Koh LC, 2011, IEEE INT CONF INF VI, P90, DOI 10.1109/IV.2011.32
   Krichene H, 2021, INT SYMP NETW CHIP, P9, DOI 10.1145/3479876.3481588
   Kulkarni VJ, 2021, INT SYMP NETW CHIP, P21, DOI 10.1145/3479876.3481597
   Landge AG, 2012, IEEE T VIS COMPUT GR, V18, P2467, DOI 10.1109/TVCG.2012.286
   Landstorfer J, 2014, IEEE CONF VIS ANAL, P73, DOI 10.1109/VAST.2014.7042483
   Lang I, 2021, INT SYMP NETW CHIP, P55, DOI 10.1145/3479876.3481593
   León GM, 2020, COMPUT GRAPH FORUM, V39, P291, DOI 10.1111/cgf.13981
   Leyva N, 2022, IEEE DES TEST, V39, P58, DOI 10.1109/MDAT.2022.3202996
   Li Y, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241709
   Li ZM, 2022, IEEE DES TEST, V39, P79, DOI 10.1109/MDAT.2022.3202993
   Luan H, 2022, IEEE DES TEST, V39, P5, DOI 10.1109/MDAT.2022.3202997
   Luan H, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241708
   Mallappa U, 2022, IEEE DES TEST, V39, P16, DOI 10.1109/MDAT.2022.3202994
   Manju R, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241711
   McCarthy CM, 2014, 2014 First Workshop on Visual Performance Analysis (VPA), P24, DOI 10.1109/VPA.2014.10
   McKenna S, 2016, COMPUT GRAPH FORUM, V35, P281, DOI 10.1111/cgf.12904
   Moller L., 2009, PROC 4 INT TEST WORK, P1, DOI [10.1109/IDT.2009.5404105, DOI 10.1109/IDT.2009.5404105]
   Monemi A, 2021, INT SYMP NETW CHIP, P41, DOI 10.1145/3479876.3481601
   Muñoz-Martínez F, 2021, INT SYMP NETW CHIP, P1, DOI 10.1145/3479876.3481602
   Ou YH, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241710
   Petrisko D, 2020, INT SYMP NETW CHIP
   Psistakis A, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241587
   Sarihi A, 2021, INT SYMP NETW CHIP, P29, DOI 10.1145/3479876.3481592
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shalaby A, 2021, INT SYMP NETW CHIP, P67, DOI 10.1145/3479876.3481595
   Simon SA., 2015, Ecological Modeling and Fire, P1, DOI DOI 10.2312/EUROVISSHORT.20151137
   Sobhani V, 2022, IEEE DES TEST, V39, P70, DOI 10.1109/MDAT.2022.3204199
   Sudusinghe C, 2022, IEEE DES TEST, V39, P28, DOI 10.1109/MDAT.2022.3202995
   Sudusinghe C, 2021, INT SYMP NETW CHIP, P35, DOI 10.1145/3479876.3481589
   Summers K. L., 2004, Information Visualization, V3, P209, DOI 10.1057/palgrave.ivs.9500079
   Sun YF, 2021, COMPUT GRAPH FORUM, V40, P239, DOI 10.1111/cgf.14303
   Sun YF, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P197, DOI 10.1145/3307650.3322230
   Sun YF, 2016, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2016.7581262
   Theisen L, 2014, 2014 FIRST WORKSHOP ON VISUAL PERFORMANCE ANALYSIS (VPA), P17, DOI 10.1109/VPA.2014.6
   Vatsavai SS, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241712
   Wang JS, 2016, THIRD ACM INTERNATIONAL WORKSHOP ON MANY-CORE EMBEDDED SYSTEMS (MES 2016), P18, DOI 10.1145/2934495.2949544
   Williams K, 2020, IEEE T VIS COMPUT GR, V26, P1118, DOI 10.1109/TVCG.2019.2934285
   Yin JM, 2020, INT SYMP NETW CHIP, DOI 10.1109/nocs50636.2020.9241583
   Zhang Yixuan, 2023, IEEE Trans Vis Comput Graph, V29, P1037, DOI 10.1109/TVCG.2022.3209493
NR 65
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1970
EP 1983
DI 10.1109/TVCG.2023.3337173
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500004
PM 38015697
DA 2024-11-06
ER

PT J
AU Schäfer, M
   Brich, N
   Byska, J
   Marques, SM
   Bednár, D
   Thiel, P
   Kozliková, B
   Krone, M
AF Schaefer, Marco
   Brich, Nicolas
   Byska, Jan
   Marques, Sergio M.
   Bednar, David
   Thiel, Philipp
   Kozlikova, Barbora
   Krone, Michael
TI InVADo: Interactive Visual Analysis of Molecular Docking Data
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Proteins; Drugs; Visualization; Data visualization; Three-dimensional
   displays; Receptor (biochemistry); Carbon; Molecular docking; AutoDock;
   virtual screening; visual analysis; visualization; clustering;
   protein-ligand interaction
ID PROTOTYPING FRAMEWORK; VISUALIZATION; DISCOVERY; MEGAMOL
AB Molecular docking is a key technique in various fields like structural biology, medicinal chemistry, and biotechnology. It is widely used for virtual screening during drug discovery, computer-assisted drug design, and protein engineering. A general molecular docking process consists of the target and ligand selection, their preparation, and the docking process itself, followed by the evaluation of the results. However, the most commonly used docking software provides no or very basic evaluation possibilities. Scripting and external molecular viewers are often used, which are not designed for an efficient analysis of docking results. Therefore, we developed InVADo, a comprehensive interactive visual analysis tool for large docking data. It consists of multiple linked 2D and 3D views. It filters and spatially clusters the data, and enriches it with post-docking analysis results of protein-ligand interactions and functional groups, to enable well-founded decision-making. In an exemplary case study, domain experts confirmed that InVADo facilitates and accelerates the analysis workflow. They rated it as a convenient, comprehensive, and feature-rich tool, especially useful for virtual screening.
C1 [Schaefer, Marco; Brich, Nicolas; Thiel, Philipp; Krone, Michael] Univ Tubingen, Inst Bioinformat & Med Informat IBMI, D-72074 Tubingen, Germany.
   [Byska, Jan] Univ Bergen, N-5007 Bergen, Norway.
   [Marques, Sergio M.] Masaryk Univ, Loschmidt Labs, Brno 60177, Czech Republic.
   [Marques, Sergio M.] St Annes Univ Hosp Brno, Int Ctr Clin Res, Brno 60200, Czech Republic.
   [Bednar, David; Kozlikova, Barbora] Masaryk Univ, Brno 60177, Czech Republic.
C3 Eberhard Karls University of Tubingen; University of Bergen; Masaryk
   University Brno; St Anne's University Hospital Brno (FNUSA); Masaryk
   University Brno
RP Krone, M (corresponding author), Univ Tubingen, Inst Bioinformat & Med Informat IBMI, D-72074 Tubingen, Germany.
EM marco.schaefer@uni-tuebingen.de; nicolas.brich@uni-tuebingen.de;
   jan.byska@gmail.com; smar96@gmail.com; 222755@mail.muni.cz;
   philipp.thiel@uni-tuebingen.de; kozlikova@fi.muni.cz;
   michael.krone@uni-tuebingen.de
RI Bednar, David/ABF-5943-2020; Krone, Michael/HJI-9309-2023; Marques,
   Sergio/H-8685-2012
OI Marques, Sergio/0000-0002-6281-7505; Brich, Nicolas/0000-0003-3175-0464;
   Krone, Michael/0000-0002-1445-7568; Bednar, David/0000-0002-6803-0340;
   Schafer, Marco/0000-0003-3854-6415; Byska, Jan/0000-0001-9483-7562
FU German Research Foundation
FX No Statement Available
CR Alberts B., 2008, MOL BIOL CELL
   Bai B, 2021, MOLECULES, V26, DOI 10.3390/molecules26154625
   Banaganapalli B., 2019, Essentials of Bioinformatics: Understanding Bioinformatics: Genes to Proteins, V1, P335, DOI [10.1007/978-3-030-02634-9, DOI 10.1007/978-3-030-02634-9_15]
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Byska J, 2019, COMPUT GRAPH FORUM, V38, P441, DOI 10.1111/cgf.13701
   Coleman RG, 2010, J CHEM INF MODEL, V50, P589, DOI 10.1021/ci900397t
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   Eberhardt J, 2021, J CHEM INF MODEL, V61, P3891, DOI 10.1021/acs.jcim.1c00203
   Ester M., 1996, P KDD, P226
   Fährrolfes R, 2017, NUCLEIC ACIDS RES, V45, pW337, DOI 10.1093/nar/gkx333
   Ferreira LG, 2015, MOLECULES, V20, P13384, DOI 10.3390/molecules200713384
   Furmanová K, 2020, COMPUT GRAPH FORUM, V39, P452, DOI 10.1111/cgf.14048
   Furmanova K, 2020, INFORM VISUAL, V19, P114, DOI 10.1177/1473871619878085
   Furmanová K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1448-0
   Goodsell DS, 2021, PROTEIN SCI, V30, P31, DOI 10.1002/pro.3934
   Gralka P, 2019, EUR PHYS J-SPEC TOP, V227, P1817, DOI 10.1140/epjst/e2019-800167-5
   Grottel S, 2015, IEEE T VIS COMPUT GR, V21, P201, DOI 10.1109/TVCG.2014.2350479
   Grottel S, 2012, IEEE PAC VIS SYMP, P209, DOI 10.1109/PacificVis.2012.6183593
   Gütlein M, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/s13321-014-0041-7
   Haider N, 2010, MOLECULES, V15, P5079, DOI 10.3390/molecules15085079
   Hermosilla P, 2017, IEEE T VIS COMPUT GR, V23, P731, DOI 10.1109/TVCG.2016.2598825
   Hoetzlein R. C., 2014, PROC GPU TECHNOL C
   Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5
   Janssen APA, 2019, J CHEM INF MODEL, V59, P1221, DOI 10.1021/acs.jcim.8b00640
   Jurcík A, 2019, IEEE PAC VIS SYMP, P212, DOI 10.1109/PacificVis.2019.00032
   Jurcik A, 2018, BIOINFORMATICS, V34, P3586, DOI 10.1093/bioinformatics/bty386
   Keim DA, 2008, LECT NOTES COMPUT SC, V4404, P76, DOI 10.1007/978-3-540-71080-6_6
   Kozlíková B, 2017, COMPUT GRAPH FORUM, V36, P178, DOI 10.1111/cgf.13072
   Krone M, 2016, COMPUT GRAPH FORUM, V35, P527, DOI 10.1111/cgf.12928
   Laskowski RA, 2011, J CHEM INF MODEL, V51, P2778, DOI 10.1021/ci200227u
   Lipinski CA, 1997, ADV DRUG DELIVER REV, V23, P3, DOI 10.1016/S0169-409X(96)00423-1
   Lodish H., 2007, MOL CELL BIOL, V6
   Marques SM, 2021, BIOMEDICINES, V9, DOI 10.3390/biomedicines9040357
   Morris GM, 2009, J COMPUT CHEM, V30, P2785, DOI 10.1002/jcc.21256
   Morris Garrett M., 2008, V443, P365, DOI 10.1007/978-1-59745-177-2_19
   MULLER P, 1994, PURE APPL CHEM, V66, P1077, DOI 10.1351/pac199466051077
   O'Boyle NM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-33
   OneAngstrom, SAMSON
   Osolodkin DI, 2015, EXPERT OPIN DRUG DIS, V10, P959, DOI 10.1517/17460441.2015.1060216
   Pande M, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07803
   Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084
   Reina G., 2005, P EUROGRAPHICS IEEE, P177
   Sabando MV, 2020, Arxiv, DOI arXiv:2008.13150
   Salentin S, 2015, NUCLEIC ACIDS RES, V43, pW443, DOI 10.1093/nar/gkv315
   Salmaso V, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00923
   Sander T, 2015, J CHEM INF MODEL, V55, P460, DOI 10.1021/ci500588j
   Sangster J. M., 1997, WILEY S SOL CHEM
   Schafer M., 2019, PROC 2 WORKSHOP MOL, P1
   Schatz K, 2021, COMPUT GRAPH FORUM, V40, P394, DOI 10.1111/cgf.14386
   Shoichet BK, 2002, CURR OPIN CHEM BIOL, V6, P439, DOI 10.1016/S1367-5931(02)00339-3
   Skanberg R., 2018, PROC WORKSHOP MOL GR
   Sterling T, 2015, J CHEM INF MODEL, V55, P2324, DOI 10.1021/acs.jcim.5b00559
   Torres PHM, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20184574
   Trott O, 2010, J COMPUT CHEM, V31, P455, DOI 10.1002/jcc.21334
   Vázquez P, 2018, COMPUT GRAPH FORUM, V37, P391, DOI 10.1111/cgf.13428
   vuetifyjs.com, Vuetify - A material design framework for Vue.js
   Wang GM, 2016, FUTURE MED CHEM, V8, DOI 10.4155/fmc-2016-0143
   Wei WX, 2020, DRUG DISCOV TODAY, V25, P1839, DOI 10.1016/j.drudis.2020.07.017
   Yuan SG, 2017, WIRES COMPUT MOL SCI, V7, DOI 10.1002/wcms.1298
   Zhang BH, 2022, CCF T HIGH PERFORM C, V4, P63, DOI 10.1007/s42514-021-00086-5
NR 61
TC 2
Z9 2
U1 12
U2 16
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1984
EP 1997
DI 10.1109/TVCG.2023.3337642
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500011
PM 38019636
DA 2024-11-06
ER

PT J
AU Li, CL
   Gao, Y
   He, JY
   Cheng, TW
   Li, S
   Hao, AM
   Qin, H
AF Li, Chunlei
   Gao, Yang
   He, Jiayi
   Cheng, Tianwei
   Li, Shuai
   Hao, Aimin
   Qin, Hong
TI A Unified Particle-Based Solver for Non-Newtonian Behaviors Simulation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Deformable solid; non-newtonian material; physically based animation;
   SPH; viscous fluid
ID SPH; FLUIDS; MODEL
AB In this article, we present a unified framework to simulate non-Newtonian behaviors. We combine viscous and elasto-plastic stress into a unified particle solver to achieve various non-Newtonian behaviors ranging from fluid-like to solid-like. Our constitutive model is based on a Generalized Maxwell model, which incorporates viscosity, elasticity and plasticity in one non-linear framework by a unified way. On the one hand, taking advantage of the viscous term, we construct a series of strain-rate dependent models for classical non-Newtonian behaviors such as shear-thickening, shear-thinning, Bingham plastic, etc. On the other hand, benefiting from the elasto-plastic model, we empower our framework with the ability to simulate solid-like non-Newtonian behaviors, i.e., visco-elasticity/plasticity. In addition, we enrich our method with a heat diffusion model to make our method flexible in simulating phase change. Through sufficient experiments, we demonstrate a wide range of non-Newtonian behaviors ranging from viscous fluid to deformable objects. We believe this non-Newtonian model will enhance the realism of physically-based animation, which has great potential for computer graphics.
C1 [Li, Chunlei; Gao, Yang; He, Jiayi; Cheng, Tianwei; Li, Shuai; Hao, Aimin] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Li, Chunlei; Gao, Yang; He, Jiayi; Cheng, Tianwei] Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg, 2019RU004, Beijing 100050, Peoples R China.
   [Li, Shuai; Hao, Aimin] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Li, Shuai] Zhongguancun Lab, Beijing 100094, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Dept Comp Sci, 2424 USA, New York, NY 11794 USA.
C3 Beihang University; Chinese Academy of Medical Sciences - Peking Union
   Medical College; Peng Cheng Laboratory; Zhongguancun Laboratory; State
   University of New York (SUNY) System; Stony Brook University
RP Gao, Y (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.; Gao, Y (corresponding author), Chinese Acad Med Sci, Res Unit Virtual Body & Virtual Surg, 2019RU004, Beijing 100050, Peoples R China.; Qin, H (corresponding author), SUNY Stony Brook, Dept Comp Sci, 2424 USA, New York, NY 11794 USA.
EM li_cl@foxmail.com; gaoyangvr@buaa.edu.cn; jiayihe1104@gmail.com;
   ctw@buaa.edu.cn; lishuaiouc@126.com; ham@buaa.edu.cn;
   qin@cs.stonybrook.edu
RI Gao, Yang/JQV-9627-2023; Zhao, Mingyu/HHS-0141-2022
OI He, Jiayi/0009-0000-8202-0520; QIN, HONG/0000-0001-7699-1355; Gao,
   Yang/0000-0002-9149-3554
FU National Key R#x0026;D Program of China
FX No Statement Available
CR Bargteil Adam W., 2007, ACM Transactions on Graphics, V26, P1, DOI 10.1145/1276377.1276397
   Batty Christopher, 2008, P 2008 ACM SIGGRAPH, P219
   Becker M, 2007, SYMPOSIUM ON COMPUTER ANIMATION 2007: ACM SIGGRAPH/ EUROGRAPHICS SYMPOSIUM PROCEEDINGS, P209
   Bender J, 2017, IEEE T VIS COMPUT GR, V23, P1193, DOI 10.1109/TVCG.2016.2578335
   BOTTIGLIERI P, 1991, J FOOD QUALITY, V14, P497, DOI 10.1111/j.1745-4557.1991.tb00089.x
   Carlson M., 2002, ACM SIGGRAPH/Eurographics Symp. Comp. Anim, P167
   Chhabra RP, 2010, RHEOLOGY OF COMPLEX FLUIDS, P3, DOI 10.1007/978-1-4419-6494-6_1
   Cleary PW, 1999, J COMPUT PHYS, V148, P227, DOI 10.1006/jcph.1998.6118
   CROSS MM, 1965, J COLL SCI IMP U TOK, V20, P417, DOI 10.1016/0095-8522(65)90022-X
   Andrade LFD, 2015, COMPUT GRAPH-UK, V52, P106, DOI 10.1016/j.cag.2015.07.021
   Fang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322968
   Fujisawa M, 2007, GRAPHITE 2007: 5TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES IN AUSTRALASIA AND SOUTHERN ASIA, PROCEEDINGS, P249
   Gao M, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201309
   Gao Y, 2021, IEEE T VIS COMPUT GR, V27, P4483, DOI 10.1109/TVCG.2021.3107597
   Gao Y, 2019, VISUAL COMPUT, V35, P1741, DOI 10.1007/s00371-018-1569-8
   Gao Y, 2017, GRAPH MODELS, V94, P14, DOI 10.1016/j.gmod.2017.09.001
   Gissler C, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392431
   Goktekin TG, 2004, ACM T GRAPHIC, V23, P463, DOI 10.1145/1015706.1015746
   Goldade R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322939
   Ihmsen M, 2014, IEEE T VIS COMPUT GR, V20, P426, DOI 10.1109/TVCG.2013.105
   Koschier D., 2019, PROC EUROGRAPHICS, P1
   Koschier D, 2022, COMPUT GRAPH FORUM, V41, P737, DOI 10.1111/cgf.14508
   Larionov E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073628
   Losasso F, 2006, ACM T GRAPHIC, V25, P812, DOI 10.1145/1141911.1141960
   Markus Becker, 2009, NPH, V9, P27, DOI [10.2312/EG/DL/conf/EG2009/nph/027-034, DOI 10.2312/EG/DL/CONF/EG2009/NPH/027-034]
   MONAGHAN JJ, 1992, ANNU REV ASTRON ASTR, V30, P543, DOI 10.1146/annurev.aa.30.090192.002551
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Muller M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P154
   MULLER MATTHIAS, 2004, P 2004 ACM SIGGRAPH, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542]
   O'Brien JF, 2002, ACM T GRAPHIC, V21, P291, DOI 10.1145/566570.566579
   Orthmann J, 2012, COMPUT GRAPH FORUM, V31, P2436, DOI 10.1111/j.1467-8659.2012.03186.x
   Ozgen O, 2019, COMPUT ANIMAT VIRT W, V30, DOI 10.1002/cav.1870
   Peer A, 2017, IEEE T VIS COMPUT GR, V23, P2656, DOI 10.1109/TVCG.2016.2636144
   Peer A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766925
   Phan Thien N., 2017, Understanding Viscoelasticity: An Introduction to Rheology, P95
   Schechter H, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185557
   Shao H, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530109
   Solenthaler B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531346
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Stomakhin A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461948
   Stomakhin A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601176
   Stora D, 1999, PROC GRAPH INTERF, P203
   Su HZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459820
   Takahashi T, 2015, COMPUT GRAPH FORUM, V34, P493, DOI 10.1111/cgf.12578
   Terzopoulos D., 1991, Journal of Visualization and Computer Animation, V2, P68, DOI 10.1002/vis.4340020208
   Weiler M, 2018, COMPUT GRAPH FORUM, V37, P145, DOI 10.1111/cgf.13349
   Wojtan C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360646
   Yue YH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2751541
   Zhu B, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766981
NR 49
TC 0
Z9 0
U1 8
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 1998
EP 2010
DI 10.1109/TVCG.2023.3341453
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500002
PM 38090860
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zabel, S
   Hennig, P
   Nieselt, K
AF Zabel, Susanne
   Hennig, Philipp
   Nieselt, Kay
TI VIPurPCA: Visualizing and Propagating Uncertainty in Principal Component
   Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Dimensionality reduction; visualization
AB Variables obtained by experimental measurements or statistical inference typically carry uncertainties. When an algorithm uses such quantities as input variables, this uncertainty should propagate to the algorithm's output. Concretely, we consider the classic notion of principal component analysis (PCA): If it is applied to a finite data matrix containing imperfect (i.e., uncertain) multidimensional measurements, its output-a lower-dimensional representation-is itself subject to uncertainty. We demonstrate that this uncertainty can be approximated by appropriate linearization of the algorithm's nonlinear functionality, using automatic differentiation. By itself, however, this structured, uncertain output is difficult to interpret for users. We provide an animation method that effectively visualizes the uncertainty of the lower dimensional map. Implemented as an open-source software package, it allows researchers to assess the reliability of PCA embeddings.
C1 [Zabel, Susanne] Univ Tubingen, Fac Sci, D-72076 Tubingen, Germany.
   [Hennig, Philipp] Univ Tubingen, Fac Sci, MPI Intelligent Syst, D-72076 Tubingen, Germany.
   [Hennig, Philipp; Nieselt, Kay] Max Planck Inst MPI Intelligent Syst, D-72076 Tubingen, Germany.
C3 Eberhard Karls University of Tubingen; Eberhard Karls University of
   Tubingen; Max Planck Society
RP Zabel, S (corresponding author), Univ Tubingen, Fac Sci, D-72076 Tubingen, Germany.
EM susanne.zabel@uni-tuebingen.de; philipp.hennig@uni-tuebingen.de;
   kay.nieselt@uni-tuebingen.de
RI Hennig, Philipp/KVY-3344-2024
OI Hennig, Philipp/0000-0001-7293-6092; Zabel, Susanne/0000-0003-3374-149X
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Abadi M., 2015, TensorFlow. Large-Scale Machine Learning on Heterogeneous Systems, V1
   [Anonymous], 2006, Semi-Supervised Learn., DOI [DOI 10.7551/MITPRESS/9780262033589.003.0016, 10.1234/12345678]
   Athawale T, 2013, IEEE T VIS COMPUT GR, V19, P2723, DOI 10.1109/TVCG.2013.208
   Athawale TM, 2021, IEEE T VIS COMPUT GR, V27, P1797, DOI 10.1109/TVCG.2020.3030394
   Barratt S, 2018, Arxiv, DOI [arXiv:1804.11010, DOI arXiv:1804.11010.v3]
   Baydin AG, 2018, J MACH LEARN RES, V18
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Chan YH, 2013, IEEE T VIS COMPUT GR, V19, P1768, DOI 10.1109/TVCG.2013.20
   Deitrick S., 2012, PROC AUTOCARTO
   Denoeux T, 2004, IEEE T FUZZY SYST, V12, P336, DOI 10.1109/TFUZZ.2004.825990
   Dua D., 2017, UCI MACHINE LEARNING
   Faust R, 2019, IEEE T VIS COMPUT GR, V25, P481, DOI 10.1109/TVCG.2018.2865194
   Görtler J, 2020, IEEE T VIS COMPUT GR, V26, P822, DOI 10.1109/TVCG.2019.2934812
   Gupta A.K., 2018, MATRIX VARIATE DISTR
   Hasin Y, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1215-1
   Hennig P., 2013, Tec. Rep. 8
   Hennig P., 2022, PROBABILISTIC NUMERI
   Higuera C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129126
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   IMAN RL, 1988, RISK ANAL, V8, P71, DOI 10.1111/j.1539-6924.1988.tb01155.x
   Janssen H, 2013, RELIAB ENG SYST SAFE, V109, P123, DOI 10.1016/j.ress.2012.08.003
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Lee JA, 2007, INFORM SCI STAT, P1
   Lee SH, 2009, STRUCT MULTIDISCIP O, V37, P239, DOI 10.1007/s00158-008-0234-7
   Levontin P., 2020, Visualising Uncertainty: A Short Introduction
   Li XH, 2020, NAT GENET, V52, P969, DOI 10.1038/s41588-020-0676-4
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu XJ, 2005, BIOINFORMATICS, V21, P3637, DOI 10.1093/bioinformatics/bti583
   Maclaurin D., 2016, Modeling, inference and optimization with composable differentiable procedures
   Matthews M., 2008, DRDC Atlantic CR, V177
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Nonato LG, 2019, IEEE T VIS COMPUT GR, V25, P2650, DOI 10.1109/TVCG.2018.2846735
   Ochoa B., 2006, PROC WORKSHOP STAT M
   Paszke A, Automatic differentiation in pytorch
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pearson R., 2020, Pumadata: Various data sets for use with the puma package
   Pearson RD, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-211
   Perez D. A., 2020, PROC IEEE INT INSTRU, P1
   Pöthkow K, 2011, COMPUT GRAPH FORUM, V30, P931, DOI 10.1111/j.1467-8659.2011.01942.x
   Posth C, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abi7673
   Schenkendorf R., 2014, PROC PHM SOC EUR C, V2
   Schulz C, 2017, IEEE T VIS COMPUT GR, V23, P531, DOI 10.1109/TVCG.2016.2598919
   Seeger M., 2017, arXiv
   Skeels M, 2010, INFORM VISUAL, V9, P70, DOI 10.1057/ivs.2009.1
   Spearman C, 1904, AM J PSYCHOL, V15, P201, DOI 10.2307/1412107
   Spiegelhalter D, 2011, SCIENCE, V333, P1393, DOI 10.1126/science.1191181
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401
   Van Der Maaten L., 2009, Technical report, V10, P1, DOI 10.1080/13506280444000102
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Dorp JR, 2003, METRIKA, V58, P85, DOI 10.1007/s001840200230
   Weiskopf D, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.793819
   Yu-Hsuan Chan, 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P43, DOI 10.1109/VAST.2010.5652460
   Zhang DP, 2022, IEEE T VIS COMPUT GR, V28, P443, DOI 10.1109/TVCG.2021.3114679
NR 56
TC 0
Z9 0
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD APR
PY 2024
VL 30
IS 4
BP 2011
EP 2022
DI 10.1109/TVCG.2023.3345532
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JN9X1
UT WOS:001173975500005
PM 38127602
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Cauquis, J
   Peillard, E
   Dominjon, L
   Duval, T
   Moreau, G
AF Cauquis, Julien
   Peillard, Etienne
   Dominjon, Lionel
   Duval, Thierry
   Moreau, Guillaume
TI Investigating Whether the Mass of a Tool Replica Influences Virtual
   Training Learning Outcomes
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Virtual Training; Prop Design; Weight Perception; User
   Study
ID COGNITIVE LOAD; ENVIRONMENT; REALITY
AB Virtual Reality (VR) has emerged as a promising solution to address the pressing concern of transferring know-how in the manufacturing industry. Making an immersive training experience often involves designing an instrumented replica of a tool whose use is to be learned through virtual training. The process of making a replica can alter its mass, making it different from that of the original tool. As far as we know, the influence of this difference on learning outcomes has never been evaluated. To investigate this subject, an immersive training experience was designed with pre and post-training phases under real conditions, dedicated to learning the use of a rotary tool. 80 participants took part in this study, split into three groups: a control group performing the virtual training using a replica with the same mass as the original tool (m = 100%), a second group that used a replica with a lighter mass than the original tool (m= 50%) and a third group using a replica heavier than the original tool (m = 150%). Despite variations in the mass of the replica used for training, this study revealed that the learning outcomes remained comparable across all groups, while also demonstrating significant enhancements in certain performance measures, including task completion time. Overall, these findings provide useful insights regarding the design of tool replicas for immersive training.
C1 [Cauquis, Julien; Dominjon, Lionel] CLARTE, Nice, France.
   [Cauquis, Julien; Peillard, Etienne; Duval, Thierry; Moreau, Guillaume] IMT Atlantique, UMR CNRS 6285, Lab STICC, Brest, France.
C3 Universite de Bretagne Occidentale; IMT - Institut Mines-Telecom; IMT
   Atlantique
RP Cauquis, J (corresponding author), CLARTE, Nice, France.; Cauquis, J (corresponding author), IMT Atlantique, UMR CNRS 6285, Lab STICC, Brest, France.
EM julien.cauquis@clarte-lab.fr; etienne.peillard@imt-atlantique.fr;
   lionel.dominjon@clarte-lab.fr; thierry.duval@imt-atlantique.fr;
   guillaume.moreau@imt-atlantique.fr
RI Duval, Thierry/AAH-4372-2020
OI Peillard, Etienne/0000-0002-4429-670X
FU National Research Agency
FX No Statement Available
CR Bloom B.S., 1956, Taxonomy of Educational Objectives. HANDBOOK I: Cognitive Domain, P4
   Borba E. Z., 2016, ACM SIGGRAPH 2016 VR, P1, DOI [10.1145/2929490.29294972, DOI 10.1145/2929490.29294972]
   Botella C, 2000, BEHAV THER, V31, P583, DOI 10.1016/S0005-7894(00)80032-5
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Byers J. C., 1989, Advances inIndustrial Erfonomics and Safety l, P3
   Choi HH, 2014, EDUC PSYCHOL REV, V26, P225, DOI 10.1007/s10648-014-9262-6
   Congès A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P87, DOI [10.1109/VRW50115.2020.00022, 10.1109/VRW50115.2020.0-254]
   Cooper N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248225
   Cooper N, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P194, DOI [10.1109/ISMAR-Adjunct.2016.66, 10.1109/ISMAR-Adjunct.2016.0075]
   Dalgarno B, 2010, BRIT J EDUC TECHNOL, V41, P10, DOI 10.1111/j.1467-8535.2009.01038.x
   Doolani S, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8040077
   Duchowski AT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376394
   Duchowski AT, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173856
   East J., 2005, Ergonomic Guidelines for Selecting Hand and Power Tools
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Feick M, 2020, INT SYM MIX AUGMENT, P195, DOI 10.1109/ISMAR50242.2020.00042
   Franzluebbers A, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P16, DOI 10.1145/3267782.3267790
   Gonçalves G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533377
   Government of Canada Canadian Centre for Occupational Healthand Safety, 2023, CCOHS: Hand Tool Ergonomics - Tool Design.
   Haapalainen E, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P301
   HINCKLEY K, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P452, DOI 10.1145/191666.191821
   Husson F., 2017, Exploratory Multivariate Analysis byExample Using R. Chapman and Hall/CRC, Vsecond, DOI [10.1201/b218745, DOI 10.1201/B218745]
   Ipsita A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517696
   Kaplan AD, 2021, HUM FACTORS, V63, P706, DOI 10.1177/0018720820904229
   Kim G, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.797993
   Lecuyer A., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P83, DOI 10.1109/VR.2000.840369
   Lee EAL, 2008, LECT NOTES COMPUT SC, V5080, P231
   Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307
   Lim WN, 2021, IEEE ACCESS, V9, P163253, DOI 10.1109/ACCESS.2021.3131525
   Lu J, 2023, COMPUT ASSIST SURG, V28, DOI 10.1080/24699322.2023.2189047
   Lyu K, 2023, AUTOMAT CONSTR, V150, DOI 10.1016/j.autcon.2023.104836
   Maehigashi A, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451842
   Makransky G., Educational Psychology Review
   Meiselwitz G., 2008, MERLOT Journal of Online Learning and Teaching, V4, P3
   Miguel-Alonso I, 2022, LECT NOTES COMPUT SC, V13446, P63, DOI 10.1007/978-3-031-15553-6_5
   Mulders M, 2024, TECHNOL KNOWL LEARN, V29, P697, DOI 10.1007/s10758-022-09630-w
   Mulders M, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6070049
   Naskrent B, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19095241
   National Aeronautics and Space Administration, TLX @ NASA AmesHome
   Nianlong Li, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1261, DOI 10.1145/3379337.3415812
   Nilsson N. C., 2021, CHI 2021 WORKSH EV P
   Noguchi K, 2012, J STAT SOFTW, V50, P1, DOI 10.18637/jss.v050.i12
   Omori K, 2023, AM J INFECT CONTROL, V51, P129, DOI 10.1016/j.ajic.2022.05.023
   Patle DS, 2019, VIRTUAL REAL-LONDON, V23, P293, DOI 10.1007/s10055-018-0354-3
   Ricca A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI 10.1109/VR50410.2021.00031
   Richmond V.P., 1987, COMMUNICATION YB, V10, P574
   Rovai AP, 2009, INTERNET HIGH EDUC, V12, P7, DOI 10.1016/j.iheduc.2008.10.002
   Saghafian M., 2020, Frontiers inPsychology, V11, P2
   Salisbury JK, 1997, IEEE COMPUT GRAPH, V17, P6, DOI 10.1109/MCG.1997.1626171
   Sauro J, 2016, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, 2ND EDITION, P9, DOI 10.1016/B978-0-12-802308-2.00002-3
   Sauter L., 2023, ECIS 2023 RES PAPERS, P2
   Schnotz W, 2007, EDUC PSYCHOL REV, V19, P469, DOI 10.1007/s10648-007-9053-4
   Shen SJ, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.597487
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Skulmowski A, 2018, COGN RES, V3, DOI 10.1186/s41235-018-0092-9
   Strandholt P. L., 2020, P 2020 CHI C HUM FAC, P2
   Stylianos Mystakidis S. Lympouridis., 2023, Encyclopedia, V3, P396, DOI DOI 10.3390/ENCYCLOPEDIA3020026
   Sweller J, 2011, PSYCHOL LEARN MOTIV, V55, P37
   Takano T, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489933
   TICHAUER ER, 1977, AM IND HYG ASSOC J, V38, P622, DOI 10.1080/00028897708984406
   Vasarainen M., 2021, International Journal of Virtual Reality, V21, P1
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
   Ye Xupeng, 2021, J COMPUTER COMMUNICA, V9, P1, DOI [10.4236/jcc.2021.99001, DOI 10.4236/JCC.2021.99001]
   Zenner A, 2019, P 2019 CHI C HUM FAC, P1, DOI [10.1145/3290605.33004412, DOI 10.1145/3290605.33004412]
NR 66
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2411
EP 2421
DI 10.1109/TVCG.2024.3372041
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400010
PM 38437074
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ren, YL
   Zhang, Y
   Liu, ZT
   Xie, N
AF Ren, Yunlei
   Zhang, Yan
   Liu, Zhitao
   Xie, Ning
TI Eye-Hand Typing: Eye Gaze Assisted Finger Typing via Bayesian Processes
   in AR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Keyboards; Production facilities; Bayes methods; Task analysis;
   Performance evaluation; Prediction algorithms; Visualization; Augmented
   reality; text entry; multi-modal interaction; eye-hand coordination;
   bayesian process; fitts' law; primacy effect
ID TEXT ENTRY; COORDINATION; INPUT
AB Nowadays, AR HMDs are widely used in scenarios such as intelligent manufacturing and digital factories. In a factory environment, fast and accurate text input is crucial for operators' efficiency and task completion quality. However, the traditional AR keyboard may not meet this requirement, and the noisy environment is unsuitable for voice input. In this article, we introduce Eye-Hand Typing, an intelligent AR keyboard. We leverage the speed advantage of eye gaze and use a Bayesian process based on the information of gaze points to infer users' text input intentions. We improve the underlying keyboard algorithm without changing user input habits, thereby improving factory users' text input speed and accuracy. In real-time applications, when the user's gaze point is on the keyboard, the Bayesian process can predict the most likely characters, vocabulary, or commands that the user will input based on the position and duration of the gaze point and input history. The system can enlarge and highlight recommended text input options based on the predicted results, thereby improving user input efficiency. A user study showed that compared with the current HoloLens 2 system keyboard, Eye-Hand Typing could reduce input error rates by 28.31 % and improve text input speed by 14.5%. It also outperformed a gaze-only technique, being 43.05% more accurate and 39.55% faster. And it was no significant compromise in eye fatigue. Users also showed positive preferences.
C1 [Ren, Yunlei; Zhang, Yan; Liu, Zhitao; Xie, Ning] Univ Elect Sci & Technol China, Ctr Future Media, Sch Comp Sci & Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xie, N (corresponding author), Univ Elect Sci & Technol China, Ctr Future Media, Sch Comp Sci & Engn, Chengdu, Peoples R China.
EM allenrens@qq.com; 1278425816@qq.com; zl425uestc@gmail.com;
   seanxiening@gmail.com
FU National Key R&D Program of China
FX No Statement Available
CR ABRAMS RA, 1990, J EXP PSYCHOL HUMAN, V16, P248, DOI 10.1037/0096-1523.16.2.248
   Alsharif O, 2015, INT CONF ACOUST SPEE, P2076, DOI 10.1109/ICASSP.2015.7178336
   [Anonymous], 2022, Hololens 2 system keyboard
   ASCH SE, 1946, J ABNORM SOC PSYCH, V41, P258, DOI 10.1037/h0055756
   Azenkot Shiri, 2012, P 14 INT C HUM COMP, P251
   Baldwin T., 2012, Proceedings of the 2012 ACM international conference on Intelligent User Interfaces, IUI '12, P11, DOI DOI 10.1145/2166966.2166969
   Bellman T, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P168
   Bernardos AM, 2016, INT J HUM-COMPUT INT, V32, P325, DOI 10.1080/10447318.2016.1142054
   Borg G., 1998, Borgs Perceived Exertion and Pain Scales, DOI DOI 10.1249/00005768-199809000-00018
   Bowman D. A., 2001, Technical report, P2
   Diaz-Tula A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3533, DOI 10.1145/2858036.2858517
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Dudley JJ, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3232163
   Fang FY, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569461
   Feng WX, 2021, PROCEEDINGS ETRA 2021: ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, DOI 10.1145/3448017.3457379
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Goel Mayank, 2012, P SIGCHI C HUM FACT, P2687, DOI [10.1145/2207676.2208662, 10.1145/2207676, DOI 10.1145/2207676]
   Goodman J., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P194
   Gunawardana A, 2010, IUI 2010, P111
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Huckauf A, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P141
   Ide N., 2001, LREC, V2, P1276
   Isomoto T, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3550301
   Jacob R. J. K., 1990, SIGCHI Bulletin, P11
   Johansson RS, 2001, J NEUROSCI, V21, P6917, DOI 10.1523/JNEUROSCI.21-17-06917.2001
   Kurauchi A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1952, DOI 10.1145/2858036.2858335
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935
   Lee L. H., 2019, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., V3, DOI [10.1145/33512522, DOI 10.1145/33512522]
   Lee LH, 2019, INT CONF PERVAS COMP, DOI 10.1109/percom.2019.8767420
   Lu XS, 2020, INT SYM MIX AUGMENT, P344, DOI 10.1109/ISMAR50242.2020.00061
   Lu YG, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P536, DOI 10.1109/VRW52623.2021.00150
   Lystbaek Mathias N., 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3530882
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   Majaranta P, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P357
   Markussen A, 2013, LECT NOTES COMPUT SC, V8117, P401
   McCall R, 2015, C HUM SYST INTERACT, P195, DOI 10.1109/HSI.2015.7170665
   Menges R, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3338844
   Miniotas D., 2006, Proceedings o f ETRA: Eye Tracking Research Applications Symposium, P67, DOI [DOI 10.1145/1117309.1117345, 10.1145/1117309.1117345]
   Morimoto C.H., 2010, P 2010 S EYE TRACKIN, P271, DOI DOI 10.1145/1743666.1743730
   Mott ME, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2558, DOI 10.1145/3025453.3025517
   Murre JMJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0120644
   Mutasim Aunnoy K., 2021, ACM Symposium on Eye Tracking Research and Applications, P1, DOI DOI 10.1145/3448018.3457998
   Ni T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2473
   Paivi Majaranta K. R., 2007, text entry systems, V2
   Pedrosa Diogo, 2015, ACM Transactions on Accessible Computing, V6, DOI 10.1145/2724728
   Pfeuffer K., 2020, P 26 ACM S VIRTUAL R, P1
   Pfeuffer K, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P99, DOI 10.1145/3131277.3132180
   Plopski A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491207
   Raynal M, 2007, LECT NOTES COMPUT SC, V4551, P452
   Reiter K, 2022, 2022 ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, ETRA 2022, DOI 10.1145/3517031.3529233
   Rough D, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P169, DOI 10.1145/2598153.2598157
   Sarcar S., 2013, P 11 ASIA PACIFIC C, P215, DOI DOI 10.1145/2525194.2525288
   Schick A, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P217
   Schmitz M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501981
   Sengupta K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI [10.1145/3317956.3318152, 10.23919/iwjt.2019.8802901]
   Sengupta Korok., 2017, P 22 INT C INTELLIGE, P121, DOI DOI 10.1145/3030024.3038259
   Shen XY, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3550327
   Shi WN, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300747
   Sibert L. E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P281, DOI 10.1145/332040.332445
   Sidenmark L, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319815
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Stellmach S., 2012, Proc. CHI, P2981, DOI DOI 10.1145/2207676.2208709
   Tuisku O, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P19, DOI 10.1145/1344471.1344476
   Velichkovsky B, 1997, HUMAN-COMPUTER INTERACTION - INTERACT '97, P509
   VERCHER JL, 1994, EXP BRAIN RES, V99, P507
   Weill-Tessier P, 2018, SMART INNOV SYST TEC, V73, P287, DOI 10.1007/978-3-319-59424-8_27
   Weir D, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2307
   Wobbrock J. O., 2006, ACM Transactions on Computer-Human Interaction, V13, P458, DOI 10.1145/1188816.1188819
   Wobbrock JO, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P11, DOI 10.1145/1344471.1344475
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yan Y., 2018, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., V2, DOI [10.1145/32870762, DOI 10.1145/32870762]
   Yi X, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P705, DOI 10.1145/3025453.3025454
   Yu C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4479, DOI 10.1145/3025453.3025964
   Zhai S., 1999, P SIGCHI C HUM FACT, P246, DOI [10.1145/302979.303053, DOI 10.1145/302979.303053, DOI 10.1145/302979.3030532]
NR 75
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2496
EP 2506
DI 10.1109/TVCG.2024.3372106
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400049
PM 38498759
DA 2024-11-06
ER

PT J
AU He, H
   Xu, XH
   Li, SM
   Wang, F
   Schroeder, I
   Aldrich, EM
   Murrell, SD
   Xue, LX
   Gu, YY
AF He, Hao
   Xu, Xinhao
   Li, Shangman
   Wang, Fang
   Schroeder, Isaac
   Aldrich, Eric M.
   Murrell, Scottie D.
   Xue, Lanxin
   Gu, Yuanyuan
TI Learning Middle-Latitude Cyclone Formation up in the Air: Student
   Learning Experience, Outcomes, and Perceptions in a CAVE-Enabled
   Meteorology Class
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Meteorology; Three-dimensional displays; Education; Federated learning;
   Virtual reality; Glass; Resists; CAVE; meteorology; learning expereince;
   learning outcomes; student perceptions
ID IMMERSIVE VIRTUAL-REALITY; ENVIRONMENT; DESIGN
AB Cave Automatic Virtual Environment (CAVE) is a virtual reality (VR) environment that has not been fully studied due to its high cost and complexity in system integration. Previous CAVE-related studies mainly focused on comparing its effectiveness with other learning media, such as textbooks, desktop VR, or head-mounted display (HMD) VR. In this study, through the utilization of CAVE in a meteorology class, we concentrated on CAVE itself, measured how CAVE impacted learners' learning outcomes before and after using CAVE in an actual ongoing undergraduate-level class, and investigated how learners perceived their learning experiences. Quantitative data were collected to examine the students' knowledge acquisition and learning experience. We also triangulated the quantitative results with qualitative data from the interviews regarding learners' perceptions of the CAVE-enabled class and their knowledge mastery. The results indicated that their learning outcomes increased through learning with CAVE and that their perceptions of immersion, presence, and engagement significantly correlated with each other. The interview results showed a great fondness of and satisfaction with the learning experience, group collaboration, and effectiveness of the CAVE-enabled class from the learners. We also learned that the learners' learning experiences in CAVE could be further improved if we provided them with more learner-environment interaction, offered them a better sense of immersion, and reduced cybersickness. Implications of these findings are discussed.
C1 [He, Hao] Emporia State Univ, Emporia, KS 66801 USA.
   [Xu, Xinhao; Li, Shangman; Wang, Fang; Schroeder, Isaac; Aldrich, Eric M.; Murrell, Scottie D.; Xue, Lanxin; Gu, Yuanyuan] Univ Missouri Columbia, Columbia, MO USA.
C3 University of Missouri System; University of Missouri Columbia
RP He, H (corresponding author), Emporia State Univ, Emporia, KS 66801 USA.
EM hhe1@emporia.edu; xuxinhao@missouri.edu; sli@missouri.edu;
   wangfan@missouri.edu; isaacschrdr@gmail.com; AldrichE@mail.missouri.edu;
   sdm6f8@mail.missouri.edu; lxbzy@mail.missouri.edu;
   yggcc@mail.missouri.edu
RI He, Hao/GQB-1369-2022; XUE, LANXIN/JAO-1460-2023; Xu, Xinhao/L-2992-2019
OI Murrell, Scott/0009-0007-8727-8468; Wang, Fang/0000-0003-3669-3948; He,
   Hao/0000-0002-5385-8022; Xu, Xinhao/0000-0002-4981-4641
FU NSF
FX No Statement Available
CR Anderson LW., 2001, TAXONOMY LEARNING TE
   [Anonymous], 2021, R LANG ENV STAT COMP
   [Anonymous], 2013, P 29 ANN ARCOM C
   Bailey B, 2022, REV J AUTISM DEV DIS, V9, P160, DOI 10.1007/s40489-020-00230-x
   Braun K., 2006, Qualitative. Psychol. Res., V3, P77, DOI DOI 10.1191/1478088706QP063OA
   Creswell J.W., 2014, RES DESIGN QUALITATI
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Cutrim E.M., 2006, Adv. Geosci, V8, P11, DOI DOI 10.5194/ADGEO-8-11-2006
   De Back TT, 2023, INTERACT LEARN ENVIR, V31, P5364, DOI 10.1080/10494820.2021.2006238
   de Back TT, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00288-5
   de Back TT, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00228-9
   Dickey M.D., 2003, Distance Education, V24, P105
   Dickey MD, 2005, INTERACT LEARN ENVIR, V13, P121, DOI 10.1080/10494820500173714
   El-Mounayri H A., 2016, AM SOC ENG ED 123 AS, DOI DOI 10.18260/P.26336
   Elor Aviv, 2020, ACM Transactions on Computing and Healthcare, V1, DOI 10.1145/3396249
   Fogarty J, 2018, J PROF ISS ENG ED PR, V144, DOI 10.1061/(ASCE)EI.1943-5541.0000349
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gallus WA, 2003, B AM METEOROL SOC, V84, P18, DOI 10.1175/BAMS-84-1-18
   Gerry LJ, 2017, IEEE T VIS COMPUT GR, V23, P1398, DOI 10.1109/TVCG.2017.2657239
   Halarnkar P., 2012, International Journal of Computer Science Issues, V9, P325
   Hart Sandra G, 1986, NASA task load index (TTX)
   Hedberg J.G., 1994, Educational Media International, V31, P214, DOI DOI 10.1080/0952398940310402
   Helbig C, 2014, ENVIRON EARTH SCI, V72, P3767, DOI 10.1007/s12665-014-3136-6
   Ho LH, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11061605
   Hu XQ, 2019, 2019 4TH IEEE INTERNATIONAL CONFERENCE ON BIG DATA ANALYTICS (ICBDA 2019), P144, DOI [10.1109/icbda.2019.8713235, 10.1109/ICBDA.2019.8713235]
   Huang LL, 2021, LECT NOTES COMPUT SC, V12771, P340, DOI 10.1007/978-3-030-77074-7_27
   Huang XX, 2023, COMPUT EDUC OPEN, V4, DOI 10.1016/j.caeo.2023.100124
   Jacobson D, 2001, CYBERPSYCHOL BEHAV, V4, P653, DOI 10.1089/109493101753376605
   Jantjies M, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY MANAGEMENT (ICETM 2018), P42, DOI 10.1145/3300942.3300956
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jeong H, 2016, EDUC PSYCHOL-US, V51, P247, DOI 10.1080/00461520.2016.1158654
   Jin Q, 1997, IEEE SYS MAN CYBERN, P1418, DOI 10.1109/ICSMC.1997.638175
   Kasapakis V, 2024, INTERACT LEARN ENVIR, V32, P2357, DOI 10.1080/10494820.2022.2146140
   Kemeny A., 2017, IS T INT S EL IM SCI, P48, DOI [DOI 10.2352/ISSN.2470-1173.2017.3.ERVR-097, 10.2352/issn.2470-1173.2017.3.ervr-097]
   Kiesler S., 1997, CULTURE INTERNET
   Kim K, 2014, COMPUT METH PROG BIO, V113, P882, DOI 10.1016/j.cmpb.2013.12.024
   Kirschner F, 2009, EDUC PSYCHOL REV, V21, P31, DOI 10.1007/s10648-008-9095-2
   Lave Jean, 1991, SITUATED LEARNING LE, P138, DOI [10.1017/CBO9780511815355, DOI 10.1017/CBO9780511815355]
   Leder J, 2019, SAFETY SCI, V111, P271, DOI 10.1016/j.ssci.2018.07.021
   Lee EAL, 2008, LECT NOTES COMPUT SC, V5080, P231
   Limniou M, 2008, COMPUT EDUC, V51, P584, DOI 10.1016/j.compedu.2007.06.014
   Lin James J. W., 2004, P SIGCHI C HUM FACT, P719, DOI DOI 10.1145/985692.985783
   Loeffler C., 1994, The virtual reality casebook
   Ma CW, 2023, ADV PHYSIOL EDUC, V47, P594, DOI 10.1152/advan.00172.2022
   Maftei L, 2021, ARCHNET-IJAR, V15, P887, DOI 10.1108/ARCH-03-2021-0067
   Mayer RE., 2014, CAMBRIDGE HDB MULTIM, P43, DOI [10.1017/CBO9781139547369.005, DOI 10.1017/CBO9780511816819.004, DOI 10.1017/CBO9781139547369.005, 10.1017/cbo9780511816819.004]
   McGovern A, 2015, B AM METEOROL SOC, V96, P397, DOI 10.1175/BAMS-D-13-00202.1
   MiddleVR, 2022, Middle VR
   Mikropoulos TA, 2011, COMPUT EDUC, V56, P769, DOI 10.1016/j.compedu.2010.10.020
   Moore P., 1995, Australian Journal of Educational Technology, V11, P91, DOI [10.14742/ajet.2078, DOI 10.14742/AJET.2078]
   Mount N.J., 2009, ITALICS, V8, P40, DOI [10.11120/ital.2009.08030040, DOI 10.11120/ITAL.2009.08030040]
   Muhanna MA, 2015, J KING SAUD UNIV-COM, V27, P344, DOI 10.1016/j.jksuci.2014.03.023
   Muñoz-Saavedra L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010322
   Mystakidis S, 2022, EDUC SCI, V12, DOI 10.3390/educsci12040281
   Ojajuni O., 2023, SOC INFORM TECHNOLOG, P75
   Parong J, 2018, J EDUC PSYCHOL, V110, P785, DOI 10.1037/edu0000241
   Pervolarakis Z, 2022, HERITAGE-BASEL, V5, P956, DOI 10.3390/heritage5020052
   Petterssen S., 2007, Introduction to Meteorology
   Porcino TM, 2017, IEEE INT CONF SERIOU
   Qiu XY, 2023, INTERACT LEARN ENVIR, V31, P2090, DOI 10.1080/10494820.2021.1874999
   Radianti J, 2020, COMPUT EDUC, V147, DOI 10.1016/j.compedu.2019.103778
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Reisoglu I, 2017, ASIA PAC EDUC REV, V18, P81, DOI 10.1007/s12564-016-9467-0
   Ritz LT, 2016, TECHTRENDS, V60, P549, DOI 10.1007/s11528-016-0085-9
   Robinson WR, 2004, J CHEM EDUC, V81, P10, DOI 10.1021/ed081p10
   RStudio Team, 2023, RStudio: Integrated Development for R
   Rutherford S. M., 2014, Nova
   Salzman MC, 1999, PRESENCE-TELEOP VIRT, V8, P293, DOI 10.1162/105474699566242
   Sattar MU, 2019, PAK J MED SCI, V35, P852, DOI 10.12669/pjms.35.3.44
   Schwienhorst K., 2002, Computer Assisted Language Learning, V15, P221, DOI 10.1076/call.15.3.221.8186
   Smith TK, 2014, EDUC SCI, V4, P122, DOI 10.3390/educsci4010122
   Spaeth AB, 2018, ARCHIT ENG DES MANAG, V14, P470, DOI 10.1080/17452007.2018.1502654
   Stein D., 1998, ERIC Digest No. 195
   Tcha-Tokey K., 2017, ACM International Conference Proceeding Series, Part, VF1311, P1, DOI DOI 10.1145/3121283.3121284
   Tepe T., 2018, World Journal on Educational Technology, V10, P72, DOI DOI 10.18844/WJET.V10I4.3786
   Unity Technologies, 2022, Unity
   Vergara D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214625
   Vesga JB, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P645, DOI 10.1109/VR50410.2021.00090
   Visbox, VisCube™ M4, M5: CAVE Immersive 3D Display
   Watanabe H, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P210, DOI 10.1109/ISUC.2008.11
   Yeh YL, 2018, ETR&D-EDUC TECH RES, V66, P693, DOI 10.1007/s11423-017-9566-6
   Zheng L, 2018, 2018 INTERNATIONAL JOINT CONFERENCE ON INFORMATION, MEDIA AND ENGINEERING (ICIME), P6, DOI 10.1109/ICIME.2018.00011
NR 83
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2807
EP 2817
DI 10.1109/TVCG.2024.3372072
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400036
PM 38437089
DA 2024-11-06
ER

PT J
AU Shen, HW
   Kiyokawa, K
AF Shen, Han-Wei
   Kiyokawa, Kiyoshi
TI Message from the Editor-in-Chief and from the Associate Editor-in-Chief
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
AB Welcome to the <italic>13th IEEE Transactions on Visualization and Computer Graphics (TVCG)</italic> special issue on IEEE Virtual Reality and 3D User Interfaces. This volume contains a total of 80 full papers selected for and presented at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR 2024), held in Orlando, Florida, USA, from March 16 to 21, 2024.
C1 [Shen, Han-Wei] Ohio State Univ, Columbus, OH 43210 USA.
   [Kiyokawa, Kiyoshi] Nara Inst Sci & Technol, Ikoma, Japan.
C3 University System of Ohio; Ohio State University; Nara Institute of
   Science & Technology
RP Shen, HW (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM shen.94@osu.edu; kiyo@is.naist.jp
RI Shen, Han-wei/A-4710-2012
NR 0
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 0viii
EP 0viii
DI 10.1109/TVCG.2024.3369809
PG 1
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400004
OA Bronze
DA 2024-11-06
ER

PT J
AU Wang, JL
   Shi, RK
   Li, XD
   Wei, YS
   Liang, HN
AF Wang, Jialin
   Shi, Rongkai
   Li, Xiaodong
   Wei, Yushi
   Liang, Hai-Ning
TI Omnidirectional Virtual Visual Acuity: A User-Centric Visual Clarity
   Metric for Virtual Reality Head-Mounted Displays and Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Measurement; Resists; Rendering (computer graphics);
   Optical imaging; Image resolution; Optical sensors; Virtual reality;
   Head-mounted displays; Measurements; Visual clarity; Passthrough; Render
   resolution; Frame rate
ID PERFORMANCE; LOGMAR
AB Users' perceived image quality of virtual reality head-mounted displays (VR HMDs) is determined by multiple factors, including the HMD's structure, optical system, display and render resolution, and users' visual acuity (VA). Existing metrics such as pixels per degree (PPD) have limitations that prevent accurate comparison of different VR HMDs. One of the main limitations is that not all VR HMD manufacturers released the official PPD or details of their HMDs' optical systems. Without these details, developers and users cannot know the precise PPD or calculate it for a given HMD. The other issue is that the visual clarity varies with the VR environment. Our work has identified a gap in having a feasible metric that can measure the visual clarity of VR HMDs. To address this gap, we present an end-to-end and user-centric visual clarity metric, omnidirectional virtual visual acuity (OVVA), for VR HMDs. OVVA extends the physical visual acuity chart into a virtual format to measure the virtual visual acuity of an HMD's central focal area and its degradation in its noncentral area. OVVA provides a new perspective to measure visual clarity and can serve as an intuitive and accurate reference for VR applications sensitive to visual accuracy. Our results show that OVVA is a simple yet effective metric for comparing VR HMDs and environments.
C1 [Wang, Jialin; Shi, Rongkai; Li, Xiaodong; Wei, Yushi] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou, Peoples R China.
   [Wang, Jialin; Shi, Rongkai; Wei, Yushi] Univ Liverpool, Dept Comp Sci, Liverpool, England.
   [Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Dept Comp, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; University of Liverpool; Xi'an
   Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Sch Adv Technol, Dept Comp, Suzhou, Peoples R China.
EM Jialin.Wang16@student.xjtlu.edu.cn; rongkai.shi19@student.xjtlu.edu.cn;
   Xiaodong.Li22@student.xjtlu.edu.cn; Yushi.Wei21@student.xjtlu.edu.cn;
   haining.liang@xjtlu.edu.cn
RI ; Wang, Jialin/KFS-9745-2024
OI Shi, Rongkai/0000-0001-8845-6034; Liang, Hai-Ning/0000-0003-3600-8955;
   Wei, Yushi/0000-0002-6003-0557; Wang, Jialin/0000-0002-1990-1293
FU Suzhou Municipal Key Laboratory for Intelligent Virtual Engineering
FX No Statement Available
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   BAILEY IL, 1976, AM J OPTOM PHYS OPT, V53, P740
   Brown R., Compare Virtual Reality Headsets
   Carkeet A, 2021, OPHTHAL PHYSL OPT, V41, P1176, DOI 10.1111/opo.12882
   Chaplin P Kay Nottingham, 2011, NASN Sch Nurse, V26, P221
   Eisenberg E, 2020, PROC SPIE, V11310, DOI 10.1117/12.2546613
   Erickson A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P434, DOI [10.1109/VR46266.2020.1580695145399, 10.1109/VR46266.2020.00-40]
   Eser I, 2008, J REFRACT SURG, V24, P685, DOI 10.3928/1081597X-20080901-07
   Fan Q, 2011, INVEST OPHTH VIS SCI, V52, P6059, DOI 10.1167/iovs.10-7108
   Finger RP, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081042
   Guo D, 2010, PROC CVPR IEEE, P515, DOI 10.1109/CVPR.2010.5540170
   Holden B, 2014, EYE, V28, P142, DOI 10.1038/eye.2013.256
   Holladay JT, 2004, J CATARACT REFR SURG, V30, P287, DOI 10.1016/j.jcrs.2004.01.014
   Hussain B, 2006, CLIN EXP OPHTHALMOL, V34, P6, DOI 10.1111/j.1442-9071.2006.01135.x
   Jin JX, 2015, BMC OPHTHALMOL, V15, DOI 10.1186/s12886-015-0052-9
   Jin X, 2022, J INTERIOR DES, V47, P31, DOI 10.1111/joid.12209
   Johnson CA, 1995, OPTOMETRY VISION SCI, V72, P864, DOI 10.1097/00006324-199512000-00004
   JONES RK, 1981, J EXP PSYCHOL HUMAN, V7, P30, DOI 10.1037/0096-1523.7.1.30
   Kappler Elizabeth, 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P2193, DOI 10.1177/1071181322661195
   Lee WJ, 2019, EYE, V33, P1145, DOI 10.1038/s41433-019-0376-4
   Lu T., 2023, Electronic Imaging, V35, P211
   Marsden Janet, 2014, Community Eye Health, V27, P16
   Mataftsi A, 2019, GRAEF ARCH CLIN EXP, V257, P1513, DOI 10.1007/s00417-019-04344-9
   Meta, Stacking the Optical Deck: Introducing Infinite Display + a Primeron Measuring Visual Quality in VR
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Panfili L, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P629, DOI 10.1109/VRW52623.2021.00197
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Piech C, 2020, AAAI CONF ARTIF INTE, V34, P471
   Pimax, Five ways the Crystal is different than other headsets
   Pohl G. S., 2013, P ACM S ONVIRTUAL RE, V2, P259, DOI [10.1145/2503713.25037521,6[31]K., DOI 10.1145/2503713.25037521,6[31]K]
   Rose K, 2000, BRIT J OPHTHALMOL, V84, P1031, DOI 10.1136/bjo.84.9.1031
   Rossi EA, 2010, NAT NEUROSCI, V13, P156, DOI 10.1038/nn.2465
   Sauer Y, 2022, VIRTUAL REAL-LONDON, V26, P1089, DOI 10.1007/s10055-021-00619-x
   Shen H. Y., 2022, MathematicalProblems in Engineering, V2022, DOI [10.1155/2022/12705652[35]D, DOI 10.1155/2022/12705652[35]D]
   Sproule David, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P547, DOI 10.1177/1071181319631488
   Varjo, Technical Specifications of Varjo VR-3
   Vinas M, 2013, OPTOMETRY VISION SCI, V90, P1430, DOI 10.1097/OPX.0000000000000063
   Wang JL, 2023, IEEE T VIS COMPUT GR, V29, P2478, DOI 10.1109/TVCG.2023.3247057
   Wang JL, 2023, VISUAL COMPUT, V39, P3373, DOI 10.1007/s00371-023-02976-x
   Wang JL, 2023, IEEE T GAMES, V15, P252, DOI 10.1109/TG.2022.3178539
   Wang R. Shi, 2022, Proc. ACM Comput. Graph. Interact. Tech., V5, DOI [10.1145/35226101,3[40]J, DOI 10.1145/35226101,3[40]J]
   Wang T, 2021, INT J OPHTHALMOL-CHI, V14, P536, DOI 10.18240/ijo.2021.04.09
   Xiang N, 2023, VISUAL COMPUT, V39, P3661, DOI 10.1007/s00371-023-02964-1
   Yadav Niteesh., Technical challenges for typography in AR/VR
   Ying GS, 2018, OPHTHAL EPIDEMIOL, V25, P1, DOI 10.1080/09286586.2017.1320413
   Zaman J., 2023, Annals of Biomedical Engineering, DOI [10.1007/s10439-023-03379-82[47]T, DOI 10.1007/S10439-023-03379-82[47]T]
   Zhan T, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101397
NR 47
TC 1
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2033
EP 2043
DI 10.1109/TVCG.2024.3372127
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400066
PM 38437113
DA 2024-11-06
ER

PT J
AU Li, M
   Pan, JJ
   Li, Y
   Gao, Y
   Qin, H
   Shen, Y
AF Li, Ming
   Pan, Junjun
   Li, Yu
   Gao, Yang
   Qin, Hong
   Shen, Yang
TI Multimodal Physiological Analysis of Impact of Emotion on Cognitive
   Control in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cognitive control; emotion; physiological signal; deep learning
AB Cognitive control is often perplexing to elucidate and can be easily influenced by emotions. Understanding the individual cognitive control level is crucial for enhancing VR interaction and designing adaptive and self-correcting VR/AR applications. Emotions can reallocate processing resources and influence cognitive control performance. However, current research has primarily emphasized the impact of emotional valence on cognitive control tasks, neglecting emotional arousal. In this study, we comprehensively investigate the influence of emotions on cognitive control based on the arousal-valence model. A total of 26 participants are recruited, inducing emotions through VR videos with high ecological validity and then performing related cognitive control tasks. Leveraging physiological data including EEG, HRV, and EDA, we employ classification techniques such as SVM, KNN, and deep learning to categorize cognitive control levels. The experiment results demonstrate that high-arousal emotions significantly enhance users' cognitive control abilities. Utilizing complementary information among multi-modal physiological signal features, we achieve an accuracy of 84.52% in distinguishing between high and low cognitive control. Additionally, time-frequency analysis results confirm the existence of neural patterns related to cognitive control, contributing to a better understanding of the neural mechanisms underlying cognitive control in VR. Our research indicates that physiological signals measured from both the central and autonomic nervous systems can be employed for cognitive control classification, paving the way for novel approaches to improve VR/AR interactions.
C1 [Li, Ming; Pan, Junjun; Gao, Yang] Beihang Univ, Beijing, Peoples R China.
   [Li, Yu; Shen, Yang] Beijing Normal Univ, Beijing, Peoples R China.
   [Qin, Hong] SUNY Stony Brook, Stony Brook, NY USA.
C3 Beihang University; Beijing Normal University; State University of New
   York (SUNY) System; Stony Brook University
RP Pan, JJ; Gao, Y (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM minglee@buaa.edu.cn; pan_junjun@buaa.edu.cn; yu.li@mail.bnu.edu.cn;
   gaoyangvr@buaa.edu.cn; qin@cs.stonybrook.edu; shenyang@bnu.edu.cn
RI Pan, Junjun/A-1316-2013; Gao, Yang/JQV-9627-2023
OI Gao, Yang/0000-0002-9149-3554; , Junjun/0000-0002-7991-9540; QIN,
   HONG/0000-0001-7699-1355
FU National Key R&D Program of China
FX No Statement Available
CR Alfeld P., 1984, Computer-Aided Geometric Design, V1, P169, DOI 10.1016/0167-8396(84)90029-3
   Antonenko P, 2010, EDUC PSYCHOL REV, V22, P425, DOI 10.1007/s10648-010-9130-y
   Ben Abdessalem H, 2017, LECT NOTES ARTIF INT, V10512, P133, DOI 10.1007/978-3-319-67615-9_12
   Benedek M, 2010, PSYCHOPHYSIOLOGY, V47, P647, DOI 10.1111/j.1469-8986.2009.00972.x
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Cao RC, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P729, DOI 10.1109/VR50410.2021.00100
   Chaumon M, 2015, J NEUROSCI METH, V250, P47, DOI 10.1016/j.jneumeth.2015.02.025
   Chiossi F, 2022, IT-INF TECHNOL, V64, P133, DOI 10.1515/itit-2022-0035
   Chiossi Francesco, 2023, EXTENDED ABSTRACTS 2, P1
   Clements GM, 2023, NEUROIMAGE, V270, DOI 10.1016/j.neuroimage.2023.119956
   Clements GM, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.621620
   Clements JM, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P451, DOI 10.1109/VR.2018.8446068
   Clore GL, 2007, TRENDS COGN SCI, V11, P393, DOI 10.1016/j.tics.2007.08.005
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Dolcos F, 2006, J NEUROSCI, V26, P2072, DOI 10.1523/JNEUROSCI.5042-05.2006
   Fairclough SH, 2005, INT J PSYCHOPHYSIOL, V56, P171, DOI 10.1016/j.ijpsycho.2004.11.003
   Fairclough SH, 2009, INTERACT COMPUT, V21, P133, DOI 10.1016/j.intcom.2008.10.011
   Fitzgibbon SP, 2007, J CLIN NEUROPHYSIOL, V24, P232, DOI 10.1097/WNP.0b013e3180556926
   Gerry L, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188479
   Gonthier C, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01822
   Gray JR, 2004, CURR DIR PSYCHOL SCI, V13, P46, DOI 10.1111/j.0963-7214.2004.00272.x
   Hinault T, 2019, HUM BRAIN MAPP, V40, P80, DOI 10.1002/hbm.24356
   Jacoby M, 2013, IEEE T NEUR SYS REH, V21, P182, DOI 10.1109/TNSRE.2012.2235184
   Johannessen E, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106393
   Johnson JA, 2005, CEREB CORTEX, V15, P1609, DOI 10.1093/cercor/bhi039
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kourtesis P, 2020, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00012
   Lawhern VJ, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aace8c
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   Li M, 2022, IEEE T VIS COMPUT GR, V28, P3832, DOI 10.1109/TVCG.2022.3203099
   Linnenbrink-Garcia L, 2011, CONTEMP EDUC PSYCHOL, V36, P1, DOI 10.1016/j.cedpsych.2010.11.004
   Loewenstein G, 2003, SER AFFECTIVE SCI, P619
   Luong T, 2022, IEEE T VIS COMPUT GR, V28, P5154, DOI 10.1109/TVCG.2021.3110459
   Luong T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P809, DOI [10.1109/vr.2019.8798029, 10.1109/VR.2019.8798029]
   MacPherson MK, 2017, J VOICE, V31, DOI 10.1016/j.jvoice.2016.10.021
   Mahjoory K, 2019, NEUROIMAGE, V188, P135, DOI 10.1016/j.neuroimage.2018.12.001
   Mayer R. E., 2005, The Cambridge handbook of multimedia learning, DOI DOI 10.1017/CBO9780511816819
   McCorry LK, 2007, AM J PHARM EDUC, V71, DOI 10.5688/aj710478
   Muñoz JE, 2021, IN SY AP IN WE HC, V12792, P559, DOI 10.1007/978-3-030-77857-6_40
   Parsons TD, 2018, IEEE T AFFECT COMPUT, V9, P66, DOI 10.1109/TAFFC.2016.2569086
   PEKRUN R, 1992, APPL PSYCHOL-INT REV, V41, P359, DOI 10.1111/j.1464-0597.1992.tb00712.x
   Plass JL, 2019, EDUC PSYCHOL REV, V31, P339, DOI 10.1007/s10648-019-09473-5
   Pratiher Sawon, 2022, Affective physiological state analysis and interpretable predictive modeling of marksmanship in Go/NoGo VR shootingdifficulty task
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sadaghiani S, 2016, TRENDS COGN SCI, V20, P805, DOI 10.1016/j.tics.2016.09.004
   Somarathna R, 2023, IEEE T AFFECT COMPUT, V14, P2626, DOI 10.1109/TAFFC.2022.3181053
   Stogios N, 2021, NPJ SCHIZOPHR, V7, DOI 10.1038/s41537-021-00151-6
   Stoll FM, 2016, CEREB CORTEX, V26, P1715, DOI 10.1093/cercor/bhv006
   Storbeck J, 2016, COGNITION EMOTION, V30, P925, DOI 10.1080/02699931.2015.1034091
   Straub E, 2020, COGNITION EMOTION, V34, P807, DOI 10.1080/02699931.2019.1666799
   Sztajzel J, 2004, SWISS MED WKLY, V134, P514
   Tian F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256211
   Vortmann LM, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463507
   Xiong RL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185122
NR 55
TC 0
Z9 0
U1 13
U2 15
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2044
EP 2054
DI 10.1109/TVCG.2024.3372101
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400072
PM 38437118
DA 2024-11-06
ER

PT J
AU Lee, S
   Viola, I
   Rossi, S
   Guo, ZR
   Reimat, I
   Lawicka, K
   Striner, A
   Cesar, P
AF Lee, Sueyoon
   Viola, Irene
   Rossi, Silvia
   Guo, Zhirui
   Reimat, Ignacio
   Lawicka, Kinga
   Striner, Alina
   Cesar, Pablo
TI Designing and Evaluating a VR Lobby for a Socially Enriching Remote
   Opera Watching Experience
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE User experience; Art; Motion pictures; Prototypes; Cultural differences;
   Usability; Training; Perfoming arts; Virtual reality; Collaborative
   interaction; Empirical studies in HCI; User studies
ID VIRTUAL-REALITY; MIXED REALITY
AB The latest social VR technologies have enabled users to attend traditional media and arts performances together while being geographically removed, making such experiences accessible despite budget, distance, and other restrictions. In this work, we aim at improving the way remote performances are shared by designing and evaluating a VR theatre lobby which serves as a space for users to gather, interact, and relive the common experience of watching a virtual opera. We conducted an initial test with experts (N=10, i.e., designers and opera enthusiasts) in pairs using our VR lobby prototype, developed based on the theoretical lobby design concept. A unique aspect of our experience is its highly realistic representation of users in the virtual space. The test results guided refinements to the VR lobby structure and implementation, aiming to improve the user experience and align it more closely with the social VR lobby's intended purpose. With the enhanced prototype, we ran a between-subject controlled study (N=40) to compare the user experience in the social VR lobby between individuals and paired participants. To do so, we designed and validated a questionnaire to measure the user experience in the VR lobby. Results of our mixed-methods analysis, including interviews, questionnaire results, and user behavior, reveal the strength of our social VR lobby in connecting with other users, consuming the opera in a deeper manner, and exploring new possibilities beyond what is common in real life. All supplemental materials are available at https://github.com/cwi-dis/IEEEVR2024-VRLobby.
C1 [Lee, Sueyoon; Viola, Irene; Rossi, Silvia; Guo, Zhirui; Reimat, Ignacio; Lawicka, Kinga; Striner, Alina; Cesar, Pablo] Ctr Wiskunde & Informat, Amsterdam, Netherlands.
   [Cesar, Pablo] Delft Univ Technol, Delft, Netherlands.
C3 Delft University of Technology
RP Lee, S (corresponding author), Ctr Wiskunde & Informat, Amsterdam, Netherlands.
EM sueyoon.lee@cwi.nl; irene.viola@cwi.nl; silvia.rossi@cwi.nl;
   zhirui.guo@cwi.nl; ignacio.reimat@cwi.nl; kinga.lawicka@cwi.nl;
   alina.striner@cwi.nl; pablo.cesar@cwi.nl
RI Viola, Irene/AAT-9714-2020
OI Guo, Zhirui/0009-0001-4495-5357; Lee, Sueyoon/0000-0001-5924-1704;
   Rossi, Silvia/0000-0002-2779-2314
FU European Union
FX No Statement Available
CR Arlati S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020261
   Benford S, 2001, COMMUN ACM, V44, P79, DOI 10.1145/379300.379322
   Benford S., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P242
   Benford S, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P709
   Benzecry CE, 2009, QUAL SOCIOL, V32, P131, DOI 10.1007/s11133-009-9123-7
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.0-178, 10.1109/VRW50115.2020.00098]
   Caro A., 2007, CONSUMING EXPERIENCE
   Cesar P., 2021, P 2021 CHI C HUMAN F, P1
   Charters E., 2003, BROCK EDUC, V12, P68, DOI [10.26522/brocked.v12i2.38, DOI 10.26522/BROCKED.V12I2.38]
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   Costello AB., 2005, Pract Assess Res Eval, V10, P1, DOI DOI 10.7275/JYJ1-4868
   Debska M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16193673
   Dembin R. M., 2016, Where the show begins in the lobby
   Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146
   Fontaine J.R. J., 2005, ENCY SOCIAL MEASUREM, P803, DOI [10.1016/B0-12-369398-5/00116-X, DOI 10.1016/B0-12-369398-5/00116-X]
   Gunkel S, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P233, DOI 10.1145/3210825.3213566
   Hall E. T., 1969, The hidden dimension: man's use of space in public and private
   Hansen AH, 2013, ELGAR ORIG REF, P209
   He LJ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281508
   Howard MC, 2016, INT J HUM-COMPUT INT, V32, P51, DOI 10.1080/10447318.2015.1087664
   Hudson S, 2019, J BUS RES, V100, P459, DOI 10.1016/j.jbusres.2018.10.062
   Hvass J, 2017, 2017 3DTV CONFERENCE: THE TRUE VISION - CAPTURE, TRANSMISSION AND DISPLAY OF 3D VIDEO (3DTV-CON)
   Jansen J, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P341, DOI 10.1145/3339825.3393578
   Jie Li, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382836
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kilpatrick D. R., 2010, The theatre lobby experience: the audience's perspective
   Le DA, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P485, DOI [10.1109/VRW50115.2020.00101, 10.1109/VRW50115.2020.0-175]
   Le QT, 2015, J INTELL ROBOT SYST, V79, P487, DOI 10.1007/s10846-014-0112-z
   Lee S, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P293, DOI 10.1145/3505284.3532980
   Lemmens JS, 2022, VIRTUAL REAL-LONDON, V26, P223, DOI 10.1007/s10055-021-00555-w
   Li J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375160
   Li J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300897
   Maguire M., 2017, ALL IRELAND J HIGHER, V3, P3551, DOI DOI 10.1109/TIA.2014.2306979
   Maslow A., 1943, Index of DOCS/Teacing {sp} Collection/Honolulu
   Matarasso F., 2013, UNESCO OBSERVATORY M, V3, P1
   McIntyre Morris Hargreaves., 2007, Audience Knowledge Digest: Why People Visit Museums and Galleries, and What Can Be Done to Attract Them
   Mekuria R, 2015, PROC SPIE, V9599, DOI 10.1117/12.2203312
   Montagud M, 2022, VIRTUAL REAL-LONDON, V26, P1593, DOI 10.1007/s10055-022-00651-5
   Monteiro D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P53, DOI 10.1109/AIVR.2018.00015
   Moreira C., 2022, IEEE Access
   Mueser D, 2018, INT J EVENT FESTIV M, V9, P183, DOI 10.1108/IJEFM-05-2018-0030
   Mystakidis S, 2020, INT CONF INFORM INTE, P365, DOI 10.1109/iisa50023.2020.9284417
   neill S., 2016, Participations: International Journal of Energy Research, V13, P24
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Pittarello F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399919
   Pitts SE, 2016, PSYCHOL MUSIC, V44, P1175, DOI 10.1177/0305735615615420
   Ramey HL, 2015, J ADOLESCENCE, V45, P237, DOI 10.1016/j.adolescence.2015.09.006
   Reidy B. K., 2016, Arts Council England, V11
   Reimat I, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6955, DOI 10.1145/3503161.3547732
   Rossi S, 2021, PROCEEDINGS OF THE 2021 INTERNATIONAL WORKSHOP ON IMMERSIVE MIXED AND VIRTUAL ENVIRONMENT SYSTEMS (MMVE '21), P1, DOI 10.1145/3458307.3463371
   Rostami A, 2022, PROCEEDINGS OF THE 2022 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2022, P95, DOI 10.1145/3505284.3529966
   Rothe S, 2021, VIRTUAL REAL-LONDON, V25, P613, DOI 10.1007/s10055-020-00472-4
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Scorolli C, 2023, COMPUT HUM BEHAV, V149, DOI 10.1016/j.chb.2023.107910
   Sedan CI, 2013, SIMULAT GAMING, V44, P821, DOI 10.1177/1046878113514807
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Striner Alina, 2021, P 2021 CHI C HUM FAC, P1, DOI DOI 10.1145/3411764.3445511
   Tcha-Tokey K, 2016, VRIC'16: PROCEEDINGS OF THE 2016 VIRTUAL REALITY INTERNATIONAL CONFERENCE, DOI 10.1145/2927929.2927955
   Van Schaik P, 2004, CYBERPSYCHOL BEHAV, V7, P540, DOI 10.1089/1094931042403145
   Vinayagamoorthy V., 2004, 7 ANN INT PRESENCE W, P148
   Viola I, 2023, IEEE MULTIMEDIA, V30, P48, DOI 10.1109/MMUL.2023.3263943
   Walmsley Ben., 2011, J CUSTOMER BEHAV, V10, P335, DOI DOI 10.1362/147539211X13210329822545
   Webb AM, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P432, DOI 10.1145/2818048.2819974
   Weber S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.628298
   Williamson J., 2021, P 2021 CHI C HUMAN F, P1
   Zheleva A., 2021, Augmented Reality and Virtual Reality: New Trends in Immersive Technology, P125
   Zhou Q., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI DOI 10.1145/3411764.3445804
   Zizza C, 2018, CONSUM COMM NETWORK
NR 69
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2055
EP 2065
DI 10.1109/TVCG.2024.3372081
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400009
PM 38437080
DA 2024-11-06
ER

PT J
AU Vallageas, V
   Aissaoui, R
   Willaert, I
   Labbé, DR
AF Vallageas, Valentin
   Aissaoui, Rachid
   Willaert, Iris
   Labbe, David R.
TI Embodying a self-avatar with a larger leg: its impacts on motor control
   and dynamic stability
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE H.5.1 [Information Interfaces and Presentation]: Multimedia Information
   Systems-Artificial, Augmented, and Virtual Realities; H.5.2 [Information
   Interfaces and Presentation]: User Interfaces-Evaluation/Methodology
ID ANTICIPATORY POSTURAL ADJUSTMENTS; CENTER-OF-MASS; GAIT INITIATION;
   BODY; OWNERSHIP; REPRESENTATION; EMBODIMENT; LOCATION; SENSE; ARM
AB Several studies have shown that users of immersive virtual reality can feel high levels of embodiment in self-avatars that have different morphological proportions than those of their actual bodies. Deformed and unrealistic morphological modifications are accepted by embodied users, underlying the adaptability of one's mental map of their body (body schema) in response to incoming sensory feedback. Before initiating a motor action, the brain uses the body schema to plan and sequence the necessary movements. Therefore, embodiment in a self-avatar with a different morphology, such as one with deformed proportions, could lead to changes in motor planning and execution. In this study, we aimed to measure the effects on movement planning and execution of embodying a self-avatar with an enlarged lower leg on one side. Thirty participants embodied an avatar without any deformations, and with an enlarged dominant or non-dominant leg, in randomized order. Two different levels of embodiment were induced, using synchronous or asynchronous visuotactile stimuli. In each condition, participants performed a gait initiation task. Their center of mass and center of pressure were measured, and the margin of stability (MoS) was computed from these values. Their perceived level of embodiment was also measured, using a validated questionnaire. Results show no significant changes on the biomechenical variables related to dynamic stability. Embodiment scores decreased with asynchronous stimuli, without impacting the measures related to stability. The body schema may not have been impacted by the larger virtual leg. However, deforming the self-avatar's morphology could have important implications when addressing individuals with impaired physical mobility by subtly influencing action execution during a rehabilitation protocol.
C1 [Vallageas, Valentin; Aissaoui, Rachid; Willaert, Iris; Labbe, David R.] Ecole Technol Super, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada
RP Vallageas, V (corresponding author), Ecole Technol Super, Montreal, PQ, Canada.
EM valentin.vallageas.1@etsmtl.net; rachid.aissaoui@etsmtl.ca;
   iris.willaert.1@ens.etsmtl.ca; david.labbe@etsmtl.ca
CR [Anonymous], 2017, Int. J. Hum. Factors Model. Simul., V5, P306, DOI [10.1504/IJHFMS.2017.087016, DOI 10.1504/IJHFMS.2017.087016]
   [Anonymous], 2013, Anthropometric Survey of U.S. Marine Corps Personnel: Methods and Summary Statistics
   [Anonymous], 2012, World J. Orthop., V3, P75, DOI [10.5312/wjo.v3.i6.75, DOI 10.5312/WJO.V3.I6.75]
   Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Asai T, 2015, EXP BRAIN RES, V233, P777, DOI 10.1007/s00221-014-4153-0
   Azuma T, 2007, GAIT POSTURE, V26, P526, DOI 10.1016/j.gaitpost.2006.11.203
   Banakou D, 2013, P NATL ACAD SCI USA, V110, P12846, DOI 10.1073/pnas.1306779110
   Bernardi NF, 2013, EXP BRAIN RES, V226, P585, DOI 10.1007/s00221-013-3467-7
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Buetler KA, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.787487
   Caderby T, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00127
   Camponogara I, 2023, NEUROSCI BIOBEHAV R, V151, DOI 10.1016/j.neubiorev.2023.105228
   Charbonneau P., 2017, 2017 INT C VIRTUALRE, P1, DOI [10.1109/ICVR.2017.8007535, DOI 10.1109/ICVR.2017.8007535, DOI 10.1145/2811266]
   D'Angelo M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32238-z
   Day BL, 2018, HAND CLINIC, V159, P107, DOI 10.1016/B978-0-444-63916-5.00006-9
   Dupraz L, 2023, PSYCHOL RES-PSYCH FO, V87, P462, DOI 10.1007/s00426-022-01675-x
   Elkin Lisa A., 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P754, DOI 10.1145/3472749.3474784
   Fabre M, 2020, GAIT POSTURE, V80, P246, DOI 10.1016/j.gaitpost.2020.06.002
   Fuchs X, 2016, SCI REP-UK, V6, DOI 10.1038/srep24362
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Haans A, 2012, INTERACT COMPUT, V24, P211, DOI 10.1016/j.intcom.2012.04.010
   Hof AL, 2005, J BIOMECH, V38, P1, DOI 10.1016/j.jbiomech.2004.03.025
   Imaizumi S, 2016, CONSCIOUS COGN, V45, P75, DOI 10.1016/j.concog.2016.08.019
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kilteni K, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040867
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Kondo S., 2018, ICAT EGVE 2018 INT C, DOI [10.2312/EGVE.20181310, DOI 10.2312/EGVE.20181310]
   Kording KP, 2006, TRENDS COGN SCI, V10, P319, DOI 10.1016/j.tics.2006.05.003
   Lafond D, 2004, J BIOMECH, V37, P1421, DOI 10.1016/S0021-9290(03)00251-3
   Laha B, 2016, PRESENCE-VIRTUAL AUG, V25, P129, DOI 10.1162/PRES_a_00251
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lilija K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI 10.1109/VR50410.2021.00069
   Longo MR, 2008, COGNITION, V107, P978, DOI 10.1016/j.cognition.2007.12.004
   Matamala-Gomez M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01962
   Mille ML, 1998, NEUROSCI LETT, V242, P61, DOI 10.1016/S0304-3940(98)00047-0
   Mölbert SC, 2018, PSYCHOL MED, V48, P642, DOI 10.1017/S0033291717002008
   Newport R, 2010, EXP BRAIN RES, V204, P385, DOI 10.1007/s00221-009-2104-y
   Normand JM, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0016128
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Patchay S, 2003, GAIT POSTURE, V18, P85, DOI 10.1016/S0966-6362(02)00167-4
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Popovic I. P. I., 2000, J. Biomech., P10
   Preston C, 2011, NEUROCASE, V17, P473, DOI 10.1080/13554794.2010.532504
   Serino A, 2013, CONSCIOUS COGN, V22, P1239, DOI 10.1016/j.concog.2013.08.013
   Steptoe W, 2013, IEEE T VIS COMPUT GR, V19, P583, DOI 10.1109/TVCG.2013.32
   Tajadura-Jiménez A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2943, DOI 10.1145/2702123.2702374
   Tajadura-Jiménez A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00689
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Walsh LD, 2011, J PHYSIOL-LONDON, V589, P3009, DOI 10.1113/jphysiol.2011.204941
   Welniarz Q, 2021, FRONT SYST NEUROSCI, V15, DOI 10.3389/fnsys.2021.644059
   Willaert I, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P783, DOI 10.1109/VRW55335.2022.00247
   Winter D.A., 2009, Biomechanics and motor control of human movement, V4th, DOI 10.1002/9780470549148
   WINTER DA, 1993, NEUROSCI RES COMMUN, V12, P141
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wolf E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P65, DOI 10.1109/VR50410.2021.00027
   Won AS, 2015, J COMPUT-MEDIAT COMM, V20, P241, DOI 10.1111/jcc4.12107
   Yiou E, 2017, WORLD J ORTHOP, V8, P815, DOI 10.5312/wjo.v8.i11.815
   Yiou E, 2016, EXP BRAIN RES, V234, P1363, DOI 10.1007/s00221-015-4319-4
NR 60
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2066
EP 2076
DI 10.1109/TVCG.2024.3372084
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400023
PM 38437132
DA 2024-11-06
ER

PT J
AU Zhang, TY
   Shen, YR
   Zhao, GR
   Wang, L
   Chen, XM
   Bai, L
   Zhou, YF
AF Zhang, Tongyu
   Shen, Yiran
   Zhao, Guangrong
   Wang, Lin
   Chen, Xiaoming
   Bai, Lu
   Zhou, Yuanfeng
TI Swift-Eye: Towards Anti-blink Pupil Tracking for Precise and Robust
   High-Frequency Near-Eye Movement Analysis with Event Cameras
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Eye tracking; event camera; feature fusion
ID GAZE; TECHNOLOGY
AB Eye tracking has shown great promise in many scientific fields and daily applications, ranging from the early detection of mental health disorders to foveated rendering in virtual reality (VR). These applications all call for a robust system for high-frequency near-eye movement sensing and analysis in high precision, which cannot be guaranteed by the existing eye tracking solutions with CCD/CMOS cameras. To bridge the gap, in this paper, we propose Swift-Eye, an offline precise and robust pupil estimation and tracking framework to support high-frequency near-eye movement analysis, especially when the pupil region is partially occluded. Swift-Eye is built upon the emerging event cameras to capture the high-speed movement of eyes in high temporal resolution. Then, a series of bespoke components are designed to generate high-quality near-eye movement video at a high frame rate over kilohertz and deal with the occlusion over the pupil caused by involuntary eye blinks. According to our extensive evaluations on EV-Eye, a large-scale public dataset for eye tracking using event cameras, Swift-Eye shows high robustness against significant occlusion. It can improve the IoU and F1-score of the pupil estimation by 20% and 12.5% respectively, compared with the second-best competing approach, when over 80% of the pupil region is occluded by the eyelid. Lastly, it provides continuous and smooth traces of pupils in extremely high temporal resolution and can support high-frequency eye movement analysis and a number of potential applications, such as mental health diagnosis, behaviour-brain association, etc. The implementation details and source codes can be found at https://github.com/ztysdu/Swift-Eye.
C1 [Zhang, Tongyu; Shen, Yiran; Zhao, Guangrong; Zhou, Yuanfeng] Shandong Univ, Sch Software, Jinan, Peoples R China.
   [Bai, Lu] Shandong Univ, C FAIR, Jinan, Peoples R China.
   [Bai, Lu] Shandong Res Inst Ind Technol, Dezhou, Peoples R China.
   [Chen, Xiaoming] Beijing Technol & Business Univ, Beijing, Peoples R China.
   [Wang, Lin] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Shandong University; Shandong University; Beijing Technology & Business
   University; Hong Kong University of Science & Technology
RP Shen, YR (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.; Bai, L (corresponding author), Shandong Univ, C FAIR, Jinan, Peoples R China.; Bai, L (corresponding author), Shandong Res Inst Ind Technol, Dezhou, Peoples R China.
EM tongyu.zhang@mail.sdu.edu.cn; yiran.shen@sdu.edu.cn;
   guangrong.zhao@sdu.edu.cn; linwang@ust.hk; xiaoming.chen@btbu.edu.cn;
   lubai@sdu.edu.cn; yfzhou@sdu.edu.cn
RI Zhou, Yuanfeng/AAT-4670-2020; wang, Lin/GQO-7901-2022; Zhang,
   Tongyu/LMP-2199-2024
OI Shen, Yiran/0000-0003-1385-1480; Zhao, Guangrong/0000-0002-4703-9397;
   Chen, Xiaoming/0000-0002-7503-3021
FU National Natural Science Foundation of China
FX No Statement Available
CR ABRAMS RA, 1989, J EXP PSYCHOL HUMAN, V15, P529, DOI 10.1037/0096-1523.15.3.529
   Adhanom IB, 2023, VIRTUAL REAL-LONDON, V27, P1481, DOI 10.1007/s10055-022-00738-z
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Angelopoulos AN, 2021, IEEE T VIS COMPUT GR, V27, P2577, DOI 10.1109/TVCG.2021.3067784
   Bao YW, 2023, Symposium Virtual Re, P22, DOI 10.1109/VR55154.2023.00018
   Boraston Z, 2007, J PHYSIOL-LONDON, V581, P893, DOI 10.1113/jphysiol.2007.133587
   Clarke AH, 2002, BEHAV RES METH INS C, V34, P549, DOI 10.3758/BF03195484
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Eckstein MK, 2017, DEV COGN NEUROS-NETH, V25, P69, DOI 10.1016/j.dcn.2016.11.001
   Feng Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P399, DOI 10.1109/VR51125.2022.00059
   Fernandes AS, 2023, IEEE T VIS COMPUT GR, V29, P2269, DOI 10.1109/TVCG.2023.3247058
   foveator, Extreme eye tracking with event cameras
   Fuhl W, 2015, LECT NOTES COMPUT SC, V9256, P39, DOI 10.1007/978-3-319-23192-1_4
   Gallego G, 2022, IEEE T PATTERN ANAL, V44, P154, DOI 10.1109/TPAMI.2020.3008413
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Halir R, 1998, WSCG '98, VOL 1, P125
   Harezlak K, 2018, COMPUT MED IMAG GRAP, V65, P176, DOI 10.1016/j.compmedimag.2017.04.006
   inivation, Davis346 event camera
   Kiili K, 2014, INT J SERIOUS GAMES, V1, P51, DOI 10.17083/ijsg.v1i2.15
   Kiranyaz S, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107398
   Kothari RS, 2021, IEEE T VIS COMPUT GR, V27, P2757, DOI 10.1109/TVCG.2021.3067765
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li D., 2005, 2005 IEEE COMP SOC C, P79, DOI [DOI 10.1109/CVPR.2005.531, 10.1109/CVPR.2005.531]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lohr D, 2022, IEEE T BIOM BEHAV ID, V4, P276, DOI 10.1109/TBIOM.2022.3167633
   Majaranta P., 2014, Human-Computer Interaction Series, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Makowski S., 2020, IEEEIAPR INT JOINT, P1, DOI [DOI 10.1109/ijcb48548.2020.9304900, 10.1109/IJCB48548.2020.9304900, DOI 10.1109/IJCB48548.2020.9304900]
   Rappa NA, 2022, INTERACT LEARN ENVIR, V30, P1338, DOI 10.1080/10494820.2019.1702560
   Singh R, 2023, Symposium Virtual Re, P205, DOI 10.1109/VR55154.2023.00036
   Suvorov R, 2021, arXiv
   Tao L, 2020, NEUROL SCI, V41, P1697, DOI 10.1007/s10072-020-04310-y
   Tulyakov S, 2021, PROC CVPR IEEE, P16150, DOI 10.1109/CVPR46437.2021.01589
   Vaswani A, 2017, ADV NEUR IN, V30
   wikipedia, Wikipedia blinking
   wikipedia, Wikipedia saccade
   Wu Zhengyang., 2019, Eyenet: A multi-task network for off-axis eye gaze estimation and user understanding
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Zhao G., 2023, 37 C NEURAL INFORM P
   Zhou Y, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P7331, DOI 10.1145/3503161.3548541
NR 40
TC 2
Z9 2
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2077
EP 2086
DI 10.1109/TVCG.2024.3372039
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400003
PM 38437077
DA 2024-11-06
ER

PT J
AU Javerliat, C
   Villenave, S
   Raimbaud, P
   Lavoue, G
AF Javerliat, Charles
   Villenave, Sophie
   Raimbaud, Pierre
   Lavoue, Guillaume
TI PLUME: Record, Replay, Analyze and Share User Behavior in 6DoF XR
   Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Physiology; Three-dimensional displays; X reality;
   Visualization; Trajectory; Data visualization; Extended Reality; Virtual
   Reality; User Behavior; Human-Computer Interaction; Quality of
   Experience; Data Collection; Physiological Signals
ID VIRTUAL-REALITY; SICKNESS; TRACKING
AB From education to medicine to entertainment, a wide range of industrial and academic fields now utilize eXtended Reality (XR) technologies. This diversity and growing use are boosting research and leading to an increasing number of XR experiments involving human subjects. The main aim of these studies is to understand the user experience in the broadest sense, such as the user cognitive and emotional states. Behavioral data collected during XR experiments, such as user movements, gaze, actions, and physiological signals constitute precious assets for analyzing and understanding the user experience. While they contribute to overcome the intrinsic flaws of explicit data such as post-experiment questionnaires, the required acquisition and analysis tools are costly and challenging to develop, especially for 6DoF (Degrees of Freedom) XR experiments. Moreover, there is no common format for XR behavioral data, which restrains data-sharing, and thus hinders wide usages across the community, replicability of studies, and the constitution of large datasets or meta-analysis. In this context, we present PLUME, an open-source software toolbox (PLUME Recorder, PLUME Viewer, PLUME Python) that allows for the exhaustive record of XR behavioral data (including synchronous physiological signals), their offline interactive replay and analysis (with a standalone application), and their easy sharing due to our compact and interoperable data format. We believe that PLUME can greatly benefit the scientific community by making the use of behavioral and physiological data available for the greatest, contributing to the reproducibility and replicability of XR user studies, enabling the creation of large datasets, and contributing to a deeper understanding of user experience.
C1 [Javerliat, Charles; Villenave, Sophie; Raimbaud, Pierre; Lavoue, Guillaume] Ecole Cent Lyon, CNRS, ENISE, LIRIS UMR5025, Ecully, France.
C3 Centre National de la Recherche Scientifique (CNRS); Ecole Centrale de
   Lyon
RP Javerliat, C (corresponding author), Ecole Cent Lyon, CNRS, ENISE, LIRIS UMR5025, Ecully, France.
EM charles.javerliat@ec-lyon.fr; sophie.villenave@ec-lyon.fr;
   pierre.raimbaud.pr@gmail.com; guillaume.lavoue@enise.ec-lyon.fr
RI Raimbaud, Pierre/KDM-8260-2024
OI Raimbaud, Pierre/0000-0002-5584-8100; Javerliat,
   Charles/0000-0003-0748-5541; Villenave, Sophie/0000-0002-6152-9800
FU French National Research Agency as part of the RENFORCE
FX No Statement Available
CR Annett J, 2003, HUM FAC ER, P17
   Asish S M., 2022, Virtual Worlds, V1, P42, DOI [10.3390/virtualworlds10100049, DOI 10.3390/VIRTUALWORLDS10100049]
   Balan O, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020496
   Beaton D. E., Guidelines for the Process of Cross-Cultural Adaptation of Self-Report Measures
   Bellazzi A, 2022, BUILD ENVIRON, V209, DOI 10.1016/j.buildenv.2021.108674
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Bowman DA, 1999, J VISUAL LANG COMPUT, V10, P37, DOI 10.1006/jvlc.1998.0111
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Brookes J, 2020, BEHAV RES METHODS, V52, P455, DOI 10.3758/s13428-019-01242-0
   Brunner C., Sig Viewer repository
   Buschel Wolfgang, 2021, P 2021 CHI C HUM FAC, P1, DOI [DOI 10.1145/3411764.3445651, 10.1145/3411764.3445651]
   Choi Bernard C K, 2005, Prev Chronic Dis, V2, pA13
   Cignoni P., Meshlab website
   Cognitive3D, Collect and measure spatial data to bring visibility to user participation, and optimize simulations for success
   Cousins S., POINT CLOUD LIB
   David-John B, 2023, IEEE T VIS COMPUT GR, V29, P2774, DOI 10.1109/TVCG.2023.3247048
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Deuchler J, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P485, DOI 10.1109/VRW58643.2023.00105
   Ding XY, 2020, Arxiv, DOI arXiv:2005.13127
   Fincham E, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P501, DOI 10.1145/3303772.3303775
   Girardeau-Montaut D, CLOUDCOMPARE 3D POIN
   Gorisse G, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3534472
   Goude I., 2023, IEEE Transactions on Visualization and Computer Graphics, P3
   Graf S., 2020, P 26 ACM S VIRTUAL R, P1
   Guimard Q, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P252, DOI 10.1145/3524273.3532895
   Halbig A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694567
   HART S G, 1988, P139
   Hepperle D, 2021, INT SYM MIX AUGMENT, P100, DOI 10.1109/ISMAR-Adjunct54149.2021.00030
   Homps F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P729, DOI [10.1109/VR46266.2020.000-8, 10.1109/VR46266.2020.1581269207852]
   Hu ZM, 2021, IEEE T VIS COMPUT GR, V27, P2681, DOI 10.1109/TVCG.2021.3067779
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Iop A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166067
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Koulieris GA, 2015, ACM T APPL PERCEPT, V11, DOI 10.1145/2637479
   Kurita K., 2012, Kansei Engineering International Journal, V11, P183
   Lanier M, 2019, COMPUT HUM BEHAV, V100, P70, DOI 10.1016/j.chb.2019.06.015
   Lavoué É, 2021, INT J HUM-COMPUT ST, V154, DOI 10.1016/j.ijhcs.2021.102670
   Lavoué G, 2018, COMPUT GRAPH FORUM, V37, P191, DOI 10.1111/cgf.13353
   Lemic F, 2022, IEEE GLOB COMM CONF, P6139, DOI 10.1109/GLOBECOM48099.2022.10001349
   Marañes C, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P73, DOI [10.1109/VR46266.2020.00-79, 10.1109/VR46266.2020.1580727911717]
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Matthews S, 2020, SYMP VIRTUAL AUGMENT, P398, DOI 10.1109/SVR51698.2020.00066
   Maurus Michael., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, P295, DOI [10.1145/2578153.25782043,8, DOI 10.1145/2578153.25782043,8, 10.1145/2578153.2578204]
   McKinney W., Pandas Dataframe documentation
   Microsoft, MSDN Stopwatch documentation
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Murgia A, 2008, IEEE ACM DIS SIM, P252, DOI 10.1109/DS-RT.2008.25
   Nebeling M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376330
   Nvidia, NVIDIA VCR
   Ojeda A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00121
   Pfeiffer T., 2012, Proceedings of the Symposium on Eye Tracking Research and Applications, P29, DOI DOI 10.1145/2168556.2168560
   Pfeiffer T, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P95, DOI 10.1145/2857491.2857541
   Raimbaud P., 2020, PhD thesis, P3
   Raimbaud P, 2023, PROCEEDINGS OF THE ACM SYMPOSIUM ON APPLIED PERCEPTION, SAP 2023, DOI 10.1145/3605495.3605796
   Reipschläger P, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517676
   Rennes I., Virtual Crowds! CrowdMP is a Unity project used as an exper imentation platform
   Robert F, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2023, P14, DOI 10.1145/3573381.3596150
   Rossi S, 2023, PROCEEDINGS OF THE 2023 PROCEEDINGS OF THE 14TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2023, P39, DOI 10.1145/3587819.3590976
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   S. C. for Computational Neuroscience, A integration approach of the LabStreamingLayer framework for Unity3D
   S. C. for Computational Neuroscience, LabStreaminglayer super repository comprising submodules for LSL and associated apps
   Sitzmann V, 2017, Arxiv, DOI arXiv:1612.04335
   Slater M., 1994, Presence: Teleoperators Virtual Environ, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Steed A., 2022, Frontiers in Virtual Reality, V3
   Stellmach S., 2010, P S EYE TRACK RES AP, P109, DOI [DOI 10.1145/1743666.1743693, DOI 10.1145/1743666]
   Sundstedt V, 2022, FRONT NEUROERGONOM, V3, DOI 10.3389/fnrgo.2022.910019
   Systems B., Complete VR eye tracking system-1 user
   Tabbaa L, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3495002
   Tartarisco G, 2015, INTERACT COMPUT, V27, P521, DOI 10.1093/iwc/iwv010
   Tcha-Tokey K., 2016, International Journal of Virtual Reality, V16, P33, DOI [10.20870/ijvr.2016.16.1.2880, 10.20870/IJVR.2016.16.1.2880, DOI 10.20870/IJVR.2016.16.1.2880]
   Tobii, Tobii Ocumen software website
   Tremmel C, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00401
   Unity, Xr interaction toolkit
   Unity Technologies, Unity Real-Time Development Platform - 3D, 2D, VR & AR Engine
   Villenave S, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P341, DOI 10.1145/3524273.3532909
   Wang JL, 2023, IEEE T VIS COMPUT GR, V29, P2478, DOI 10.1109/TVCG.2023.3247057
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wu H.-Y., 2022, Proceedings of the ACM on Human-Computer Interaction, DOI [10.1145/35322083,4, DOI 10.1145/35322083,4]
   Yuksel C., 2008, Technical report, P7
NR 80
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2087
EP 2097
DI 10.1109/TVCG.2024.3372107
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400028
PM 38437111
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhang, GF
   Yuan, J
   Liu, HM
   Peng, Z
   Li, CL
   Wang, ZB
   Bao, HJ
AF Zhang, Guofeng
   Yuan, Jin
   Liu, Haomin
   Peng, Zhen
   Li, Chunlei
   Wang, Zibin
   Bao, Hujun
TI 100-Phones: A Large VI-SLAM Dataset for Augmented Reality Towards Mass
   Deployment on Mobile Phones
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented Reality; Dataset; Benchmark; VI-SLAM
ID MONOCULAR SLAM; ROBUST; VERSATILE; ODOMETRY
AB Visual-inertial SLAM (VI-SLAM) is a key technology for Augmented Reality (AR), which allows the AR device to recover its 6-DoF motion in real-time in order to render the virtual content with the corresponding pose. Nowadays, smartphones are still the mainstream devices for ordinary users to experience AR. However the current VI-SLAM methods, although performing well on high-end phones, still face robustness challenges when deployed on a larger stock of mid- and low-end phones. Existing VI-SLAM datasets use either very ideal sensors or only a limited number of devices for data collection, which cannot reflect the capability gaps that VI-SLAM methods need to solve when deployed on a large variety of phone models. This work proposes 100-Phones. the first VI-SLAM dataset covering a wide range of mainstream phones in the market. The dataset consists of 350 sequences collected by 100 different models of phones. Through analysis and experiments on the collected data, we conclude that the quality of visual-inertial data vary greatly among the mainstream phones, and the current open source VI-SLAM methods still have serious robustness issues when it comes to mass deployment on mobile phones. We release the dataset to facilitate the robustness improvement of VI-SLAM and to promote the mass popularization of AR. Project page: https://github.com/zju3dv/100-Phones.
C1 [Zhang, Guofeng; Bao, Hujun] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
   [Yuan, Jin; Liu, Haomin; Peng, Zhen; Li, Chunlei; Wang, Zibin] SenseTime, Hong Kong, Peoples R China.
C3 Zhejiang University
RP Bao, HJ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM zhangguofeng@zju.edu.cn; yuanjin1@sensetime.com; 172753015@qq.com;
   pengzhen1@sensetime.com; lichunlei@sensetime.com;
   wangzibin@sensetime.com; baohujun@zju.edu.cn
RI Liu, Haomin/IXW-5373-2023; Zhao, Gang/JMC-6248-2023
OI Zhang, Guofeng/0000-0001-5661-8430; Bao, Hujun/0000-0002-2662-0334
FU NSF of China
FX No Statement Available
CR Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chen DP, 2021, INT SYM MIX AUGMENT, P275, DOI 10.1109/ISMAR52148.2021.00043
   Delmerico J, 2018, IEEE INT CONF ROBOT, P2502
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI [10.1109/ICRA40945.2020.9196524, 10.1109/icra40945.2020.9196524]
   Hartley R., 2004, Multiple View Geometry in Computer Vision, V2nd ed., DOI [10.1016/S0143-8166(01)00145-2, 10.1017/CBO9780511811685]
   He YJ, 2023, PROC CVPR IEEE, P739, DOI 10.1109/CVPR52729.2023.00078
   Holzwarth Valentin, 2021, ICVARS 2021: 2021 the 5th International Conference on Virtual and Augmented Reality Simulations, P42, DOI 10.1145/3463914.3463921
   Ichikari R., 2017, INT C ARTIFICIAL REA, P229
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jinyu L., 2019, Virtual Real. Intell. Hardw., V1, P386, DOI [10.1016/j.vrih.2019.07.002, DOI 10.1016/J.VRIH.2019.07.002]
   Klein George, 2007, P1
   Lee D, 2021, PROC CVPR IEEE, P3226, DOI 10.1109/CVPR46437.2021.00324
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Li PL, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P11, DOI 10.1109/ISMAR.2017.18
   Liu H., 2023, IEEE Transactions on Circuits and Systems for Video Technology, DOI [10.1109/TCSVT.2023.33061602,6, DOI 10.1109/TCSVT.2023.33061602,6]
   Liu HM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P219, DOI 10.1109/ISMAR-Adjunct51615.2020.00065
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Liu HM, 2016, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR.2016.24
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Olson E, 2011, IEEE INT CONF ROBOT
   Oth L, 2013, PROC CVPR IEEE, P1360, DOI 10.1109/CVPR.2013.179
   Pfrommer Bernd, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3847, DOI 10.1109/ICRA.2017.7989443
   Qin T, 2018, IEEE INT C INT ROBOT, P3662, DOI 10.1109/IROS.2018.8593603
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Rosinol A, 2023, IEEE INT C INT ROBOT, P3437, DOI 10.1109/IROS55552.2023.10341922
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sarlin PE, 2022, LECT NOTES COMPUT SC, V13667, P686, DOI 10.1007/978-3-031-20071-7_40
   Schönberger JL, 2017, LECT NOTES COMPUT SC, V10111, P321, DOI 10.1007/978-3-319-54181-5_21
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Spera E, 2021, IEEE T CIRC SYST VID, V31, P1253, DOI 10.1109/TCSVT.2019.2941040
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Teed Z, 2021, ADV NEUR IN, V34
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   von Stumberg L, 2022, IEEE ROBOT AUTOM LET, V7, P1408, DOI 10.1109/LRA.2021.3140129
   Wang C, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P366, DOI 10.1109/ISMAR-Adjunct.2019.00-10
   Wu Kejian J., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5155, DOI 10.1109/ICRA.2017.7989603
   Wu KJ, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Xue F, 2019, PROC CVPR IEEE, P8567, DOI 10.1109/CVPR.2019.00877
   Zhu Z., 2023, arXiv
NR 58
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2098
EP 2108
DI 10.1109/TVCG.2024.3372133
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400045
PM 38437081
DA 2024-11-06
ER

PT J
AU Boban, L
   Boulic, R
   Herbelin, B
AF Boban, Loen
   Boulic, Ronan
   Herbelin, Bruno
TI In Case of Doubt, One Follows One's Self: The Implicit Guidance of the
   Embodied Self-Avatar
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Distortion; Motors; Behavioral sciences; Task analysis;
   Visualization; Rubber; Virtual Reality; virtual embodiment; sense of
   body ownership; sense of agency; self-avatar follower effect
ID SENSE; BODY; MOVEMENT
AB The sense of embodiment in virtual reality (VR) is commonly understood as the subjective experience that one's physical body is substituted by a virtual counterpart, and is typically achieved when the avatar's body, seen from a first-person view, moves like one's physical body. Embodiment can also be experienced in other circumstances (e.g., in third-person view) or with imprecise or distorted visuo-motor coupling. It was moreover observed, in various cases of small or progressive temporal and spatial manipulations of avatars' movements, that participants may spontaneously follow the movement shown by the avatar. The present work investigates whether, in some specific contexts, participants would follow what their avatar does even when large movement discrepancies occur, thereby extending the scope of understanding of the self-avatar follower effect beyond subtle changes of motion or speed manipulations. We conducted an experimental study in which we introduced uncertainty about which movement to perform at specific times and analyzed participants' movements and subjective feedback after their avatar showed them an incorrect movement. Results show that, when in doubt, participants were influenced by their avatar's movements, leading them to perform that particular error twice more often than normal. Importantly, results of the embodiment score indicate that participants experienced a dissociation with their avatar at those times. Overall, these observations not only demonstrate the possibility of provoking situations in which participants follow the guidance of their avatar for large motor distortions, despite their awareness about the avatar movement disruption and on the possible influence it had on their choice, and, importantly, exemplify how the cognitive mechanism of embodiment is deeply rooted in the necessity of having a body.
C1 [Boban, Loen; Boulic, Ronan; Herbelin, Bruno] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Boban, L (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM loen.boban@epfl.ch; ronan.boulic@epfl.ch; bruno.herbelin@epfl.ch
OI Boban, Loen/0000-0001-6835-0056
FU Fonds National Suisse de la Recherche Scientifique
FX No Statement Available
CR Argelaguet F, 2016, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2016.7504682
   Asai T, 2015, EXP BRAIN RES, V233, P777, DOI 10.1007/s00221-014-4153-0
   Atkinson R.C., 1968, The Psychology of Learning and Motivation, V2, P89, DOI [DOI 10.1016/S0079-7421(08)60422-3, 10.1016/S0079-7421(08)60422-3]
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   BADDELEY A, 1992, Science (Washington D C), V255, P556, DOI 10.1016/j.cub.2009.12.014
   Blanke O, 2015, NEURON, V88, P145, DOI 10.1016/j.neuron.2015.09.029
   Blanke O, 2012, NAT REV NEUROSCI, V13, P556, DOI 10.1038/nrn3292
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Boban L, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1073549
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bourdin P, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-56034-5
   Burin D, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209899
   Cheymol A., 2023, IEEE Transactions on Visualizationand Computer Graphics, V1
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   Debarba Henrique G., 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P67, DOI 10.1109/3DUI.2015.7131728
   Debarba HG, 2018, COMPUT GRAPH-UK, V76, P142, DOI 10.1016/j.cag.2018.09.001
   Debarba HG, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0190109
   Delahaye M, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0266212
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Farrer C, 2008, BEHAV NEUROL, V19, P53, DOI 10.1155/2008/425267
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Friston KJ, 2010, BIOL CYBERN, V102, P227, DOI 10.1007/s00422-010-0364-z
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Haggard P, 2012, CURR BIOL, V22, pR390, DOI 10.1016/j.cub.2012.02.040
   Herbelin R., 2016, Technical report, V1
   Kalckert A, 2014, CONSCIOUS COGN, V30, P118, DOI 10.1016/j.concog.2014.08.022
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kokkinara E, 2015, ACM T APPL PERCEPT, V13, DOI 10.1145/2818998
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lanillos P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02200-7
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lenggenhager B, 2007, SCIENCE, V317, P1096, DOI 10.1126/science.1143439
   Maselli A, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010095
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Pavone EF, 2016, J NEUROSCI, V36, P268, DOI 10.1523/JNEUROSCI.0494-15.2016
   Porssut T, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0282967
   Porssut T, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0255554
   Porssut T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P529, DOI [10.1109/VR.2019.8797716, 10.1109/vr.2019.8797716]
   Porssut Y., 2021, IEEE Transactionson Visualization and Computer Graphics, V28, P3193
   Rietzler F., 2017, INPROCEEDINGS 23 ACM, P1, DOI [10.1145/3139131.31391451,2[44]N, DOI 10.1145/3139131.31391451,2[44]N]
   Sajid N, 2021, NEURAL COMPUT, V33, P674, DOI 10.1162/neco_a_01357
   Salomon R, 2016, SCI REP-UK, V6, DOI 10.1038/srep25847
   SMYTH MM, 1988, Q J EXP PSYCHOL-A, V40, P497, DOI 10.1080/02724988843000041
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Wachowicz F, 2011, DANCE RES, V29, P450, DOI 10.3366/drs.2011.0028
NR 47
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2109
EP 2118
DI 10.1109/TVCG.2024.3372042
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400008
PM 38437112
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Liu, WY
   Zhang, YY
   Zhang, BQ
   Xiong, QQ
   Zhao, H
   Li, S
   Liu, J
   Bian, YL
AF Liu, Weiying
   Zhang, Yanyan
   Zhang, Baiqiao
   Xiong, Qianqian
   Zhao, Hong
   Li, Sheng
   Liu, Juan
   Bian, Yulong
TI Self-Guided DMT: Exploring a Novel Paradigm of Dance Movement Therapy in
   Mixed Reality for Children with ASD
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Autism spectrum disorder; dance movement therapy; mixed reality;
   self-guided; virtual agent
ID AUTISM SPECTRUM DISORDER; EFFICACY; IDENTIFICATION; PERFORMANCE;
   ADOLESCENTS; SIMILARITY; MOTOR
AB Children diagnosed with Autism Spectrum Disorder (ASD) often exhibit motor disorders. Dance Movement Therapy (DMT) has shown great potential for improving the motor control ability of children with ASD. However, traditional DMT methods often lack vividness and are difficult to implement effectively. To address this issue, we propose a Mixed Reality DMT approach, utilizing interactive virtual agents. This approach offers immersive training content and multi-sensory feedback. To improve the training performance of children with ASD, we introduce a novel training paradigm featuring a self-guided mode. This paradigm enables the rapid creation of a virtual twin agent of the child with ASD using a single photo to embody oneself, which can then guide oneself during training. We conducted an experiment with the participation of 24 children diagnosed with ASD (or ASD propensity), recording their training performance under various experimental conditions. Through expert rating, behavior coding of training sessions, and statistical analysis, our findings revealed that the use of the twin agent for self-guidance resulted in noticeable improvements in the training performance of children with ASD. These improvements were particularly evident in terms of enhancing movement quality and refining overall target-related responses. Our study holds clinical potential in the field of medical treatment and rehabilitation for children with ASD.
C1 [Liu, Weiying; Zhang, Baiqiao; Xiong, Qianqian; Zhao, Hong; Liu, Juan; Bian, Yulong] Shandong Univ, Weihai 264209, Peoples R China.
   [Zhang, Yanyan] Weihai Maternal Child Hlth Care Hosp, Weihai, Peoples R China.
   [Li, Sheng] Peking Univ, Beijing 100871, Peoples R China.
C3 Shandong University; Peking University
RP Liu, J (corresponding author), Shandong Univ, Weihai 264209, Peoples R China.; Li, S (corresponding author), Peking Univ, Beijing 100871, Peoples R China.
EM 202237565@mail.sdu.edu.cn; 270700475@qq.com; baiqiao@mail.sdu.edu.cn;
   causeimbatman@mail.sdu.edu.cn; zhaohong1229@sdu.edu.cn;
   lisheng@pku.edu.cn; zzzliujuan@sdu.edu.cn; bianyulong@sdu.edu.cn
RI Zhang, Yanyan/AFT-0833-2022
OI Li, Sheng/0000-0002-8901-2184
FU National Key R&D Program of China
FX No Statement Available
CR Abbasi J, 2017, JAMA-J AM MED ASSOC, V317, P346, DOI 10.1001/jama.2016.18122
   Aithal S, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.588418
   Andsager JL, 2006, COMMUN RES, V33, P3, DOI 10.1177/0093650205283099
   Bai Z, 2015, IEEE T VIS COMPUT GR, V21, P598, DOI 10.1109/TVCG.2014.2385092
   Bailenson JN, 2008, J APPL SOC PSYCHOL, V38, P2673, DOI 10.1111/j.1559-1816.2008.00409.x
   BANDURA A, 1961, J ABNORM SOC PSYCH, V63, P311, DOI 10.1037/h0040351
   Bandura A, 2001, MEDIA PSYCHOL, V3, P265, DOI 10.1207/S1532785XMEP0303_03
   BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191
   Bandura A., 1977, Social learning theory, V1, P2
   Banire B, 2021, UNIVERSAL ACCESS INF, V20, P785, DOI 10.1007/s10209-020-00749-0
   Bekele E, 2013, IEEE T VIS COMPUT GR, V19, P711, DOI 10.1109/TVCG.2013.42
   Bian YL, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384529
   Bian YL, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018)
   Biocca F., 1997, J COMPUT-MEDIAT COMM, V3, P0, DOI [DOI 10.1111/J.1083-6101.1997.TB00070.X, https://doi.org/10.1111/j.1083-6101.1997.tb00070.x, 10.1111/j.1083-6101.1997.tb00070.x]
   Cassidy A., 2021, Encyclopedia of AutismSpectrum Disorders, P462, DOI [10.1007/978-3-319-91280-6_1367, DOI 10.1007/978-3-319-91280-6_1367]
   Chen Xinyu, 2022, 2022 Asia-Pacific Computer Technologies Conference (APCT), P7, DOI 10.1109/APCT55107.2022.00016
   Constantin A, 2017, COMPUT HUM BEHAV, V75, P404, DOI 10.1016/j.chb.2017.05.030
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   de Natale ER, 2017, NEUROREHABILITATION, V40, P141, DOI 10.3233/NRE-161399
   Dechsling A, 2022, J AUTISM DEV DISORD, V52, P4692, DOI 10.1007/s10803-021-05338-5
   DeJesus BM, 2020, COMPLEMENT THER MED, V49, DOI 10.1016/j.ctim.2020.102299
   Delabary MD, 2018, AGING CLIN EXP RES, V30, P727, DOI 10.1007/s40520-017-0836-2
   Dowrick P. W., 2022, Self-modeling: Falling a sleep following a picture-basedplan, P151, DOI [10.1007/978-3-030-99134-0_112, DOI 10.1007/978-3-030-99134-0_112]
   Dowrick PW, 2012, PSYCHOL SCHOOLS, V49, P30, DOI 10.1002/pits.20613
   Dowrick PW, 1999, APPL PREV PSYCHOL, V8, P23, DOI 10.1016/S0962-1849(99)80009-2
   Eberhard-Kaechele M., 2020, Trauma in the Creative and Embodied Therapies, DOI [10.4324/9781351066266-82, DOI 10.4324/9781351066266-82]
   Fox J, 2009, MEDIA PSYCHOL, V12, P1, DOI 10.1080/15213260802669474
   Franklin S., 1997, Intelligent Agents III. Agent Theories, Architectures, and Languages. ECAI '96 Workshop (ATAL) Proceedings, P21, DOI 10.1007/BFb0013570
   Fraser DW, 2020, FOCUS AUTISM DEV DIS, V35, P3, DOI 10.1177/1088357619844696
   Frith U., 2003, Autism: Explaining the enigma, P8
   Happé F, 1999, TRENDS COGN SCI, V3, P216, DOI 10.1016/S1364-6613(99)01318-2
   Hatch B, 2023, PSYCHOL SCHOOLS, V60, P295, DOI 10.1002/pits.22808
   Hilmert CJ, 2006, J PERS SOC PSYCHOL, V90, P440, DOI 10.1037/0022-3514.90.3.440
   Huang YC, 2019, LECT NOTES COMPUT SC, V11575, P283, DOI 10.1007/978-3-030-21565-1_19
   Jackson JW, 2002, J EXP EDUC, V70, P243, DOI 10.1080/00220970209599508
   Jennings NR., 1998, Autonomous agents and multi-agent systems, V1, P7, DOI [DOI 10.1023/A:1010090405266, 10.1023/A:1010090405266]
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Karkou V, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00936
   Kita Y, 2011, BRAIN DEV-JPN, V33, P494, DOI 10.1016/j.braindev.2010.11.007
   Ko KS, 2023, ART PSYCHOTHER, V85, DOI 10.1016/j.aip.2023.102062
   Kumazaki H, 2019, J AUTISM DEV DISORD, V49, P1700, DOI 10.1007/s10803-018-3841-1
   Li S, 2022, IEEE T VIS COMPUT GR, V28, P3035, DOI 10.1109/TVCG.2020.3044563
   Liu J, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-2941-7
   Liu WY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11135799
   Maenner MJ, 2021, MMWR SURVEILL SUMM, V70, DOI [10.15585/mmwr.ss7011a1, 10.15585/mmwr.ss7010a1]
   Mei C, 2015, ASSETS'15: PROCEEDINGS OF THE 17TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS & ACCESSIBILITY, P155, DOI 10.1145/2700648.2809863
   Mei C, 2015, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2015.7223382
   MEICHENBAUM DH, 1971, J PERS SOC PSYCHOL, V17, P298, DOI 10.1037/h0030593
   Miller SA, 2015, J APPL BEHAV ANAL, V48, P194, DOI 10.1002/jaba.187
   Mosher MA, 2022, REV J AUTISM DEV DIS, V9, P334, DOI 10.1007/s40489-021-00259-6
   Mottron L, 2006, J AUTISM DEV DISORD, V36, P27, DOI 10.1007/s10803-005-0040-7
   Mottron L., 2001, Enhanced perceptual functioning in thedevelopment of autism, DOI [10.4324/9781410600196-148, DOI 10.4324/9781410600196-148]
   Mulligan J., 2022, Childand Adolescent Psychiatry and Mental Health, V16, P1, DOI [10.1186/s13034-022-00495-64, DOI 10.1186/S13034-022-00495-64]
   Niswanger R., IN2023 IEEEACMCONFER
   Perkins R., Psychology and Psychotherapy
   Ridderinkhof A, 2020, J ATTEN DISORD, V24, P681, DOI 10.1177/1087054718797428
   Scotland E., 1969, Advances in experimental social psychology, V4, P271, DOI 10.1016/s0065-2601(08)60080-53
   Souza-Santos C, 2018, CLIN NEUROPSYCHIATR, V15, P284
   Spitzer R. L., 1994, DSM-IV casebook: A learning companion to the Diagnostic and Statistical Manual of Mental Disorders, DOI [10.1176/appi.books.97815856226651, DOI 10.1176/APPI.BOOKS.97815856226651]
   Stajkovic AD, 1998, PSYCHOL BULL, V124, P240, DOI 10.1037/0033-2909.124.2.240
   Takahashi H, 2019, AM J DANCE THER, V41, P55, DOI 10.1007/s10465-019-09296-5
   Tanaka H, 2016, ACM T INTERACT INTEL, V6, DOI 10.1145/2937757
   Valencia K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204485
   Vishwakarma A., 2019, Unfold-An Interactive Experience on Mixed Reality Platform to Solve Communication Problems Faced by Children with ASD in the Age Group of 4-7 Years, V1, P2
   Wilson CE, 2011, Q J EXP PSYCHOL, V64, P1939, DOI 10.1080/17470218.2011.603052
   Zhang L., 2020, IEEE transactions on learning technologies, V14, P338
   Zhang L, 2021, IEEE T LEARN TECHNOL, V14, P338, DOI [10.1109/TLT.2020.3029223, 10.1109/tlt.2020.3029223]
   Zhao WB, 2020, COMPUTER, V53, P26, DOI 10.1109/MC.2019.2915979
NR 68
TC 1
Z9 1
U1 11
U2 11
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2119
EP 2128
DI 10.1109/TVCG.2024.3372063
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400034
PM 38457325
DA 2024-11-06
ER

PT J
AU Qu, Q
   Liang, HX
   Chen, XM
   Chung, YY
   Shen, YR
AF Qu, Qiang
   Liang, Hanxue
   Chen, Xiaoming
   Chung, Yuk Ying
   Shen, Yiran
TI NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF
   and Neural View Synthesis Methods
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Perceptual Quality Assessment; Quality of Experience (QoE); Immersive
   Experience; No-Reference Quality Assessment; Novel View Synthesis; 3D
   Reconstruction; Neural Radiance Fields (NeRF)
ID SIMILARITY INDEX; IMAGE; INFORMATION; DEVIATION; EFFICIENT
AB Neural View Synthesis (NVS) has demonstrated efficacy in generating high-fidelity dense viewpoint videos using a image set with sparse views. However, existing quality assessment methods like PSNR, SSIM, and LPIPS are not tailored for the scenes with dense viewpoints synthesized by NVS and NeRF variants, thus, they often fall short in capturing the perceptual quality, including spatial and angular aspects of NVS-synthesized scenes. Furthermore, the lack of dense ground truth views makes the full reference quality assessment on NVS-synthesized scenes challenging. For instance, datasets such as LLFF provide only sparse images, insufficient for complete full-reference assessments. To address the issues above, we propose NeRF-NQA, the first no-reference quality assessment method for densely-observed scenes synthesized from the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment strategy, integrating both viewwise and pointwise approaches, to evaluate the quality of NVS-generated scenes. The viewwise approach assesses the spatial quality of each individual synthesized view and the overall inter-views consistency, while the pointwise approach focuses on the angular qualities of scene surface points and their compound inter-point quality. Extensive evaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality assessment methods (from fields of image, video, and light-field assessment). The results demonstrate NeRF-NQA outperforms the existing assessment methods significantly and it shows substantial superiority on assessing NVS-synthesized scenes without references. An implementation of this paper are available at https://github.com/VincentQQu/NeRF-NQA.
C1 [Qu, Qiang; Chung, Yuk Ying] Univ Sydney, Sch Comp Sci, Sydney, Australia.
   [Liang, Hanxue] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England.
   [Chen, Xiaoming] Beijing Technol & Business Univ, Sch Comp & Artificial Intelligence, Beijing, Peoples R China.
   [Shen, Yiran] Shandong Univ, Sch Software, Shandong, Peoples R China.
C3 University of Sydney; University of Cambridge; Beijing Technology &
   Business University; Shandong University
RP Shen, YR (corresponding author), Shandong Univ, Sch Software, Shandong, Peoples R China.
EM vincent.qu@sydney.edu.au; hl589@cam.ac.uk; xiaoming.chen@btbu.edu.cn;
   vera.chung@sydney.edu.au; yiran.shen@sdu.edu
OI Chen, Xiaoming/0000-0002-7503-3021; Qu, Qiang/0000-0002-6648-5050; Shen,
   Yiran/0000-0003-1385-1480
FU Beijing Natural Science Foundation
FX No Statement Available
CR Andersen D, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P501, DOI 10.1109/VR.2018.8446560
   Balanov A, 2015, IEEE IMAGE PROC, P2105, DOI 10.1109/ICIP.2015.7351172
   Barron JT, 2022, PROC CVPR IEEE, P5460, DOI 10.1109/CVPR52688.2022.00539
   Chang Angel, 2017, ARXIV
   Chen AP, 2022, LECT NOTES COMPUT SC, V13692, P333, DOI 10.1007/978-3-031-19824-3_20
   Chen T, 2020, PR MACH LEARN RES, V119
   Colburn A, 2013, IEEE T VIS COMPUT GR, V19, P56, DOI 10.1109/TVCG.2012.95
   Dekking F. M., 2005, A Modern Introduction to Probability and Statistics, DOI 10.1007/1-84628-168-7
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Fridovich-Keil S, 2022, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR52688.2022.00542
   Gruber L, 2014, 2014 IEEE VIRTUAL REALITY (VR), P15, DOI 10.1109/VR.2014.6802044
   Hauswiesner S, 2013, IEEE T VIS COMPUT GR, V19, P1552, DOI 10.1109/TVCG.2013.67
   Howard A.G., 2017, MOBILENETS EFFICIENT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Jiang W, 2022, LECT NOTES COMPUT SC, V13692, P402, DOI 10.1007/978-3-031-19824-3_24
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kerbl B, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592433
   Kingma D.P., 2014, P INT C LEARNING REP
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Li LY, 2007, IEEE T VIS COMPUT GR, V13, P630, DOI 10.1109/TVCG.2007.1009
   Li Z., 2016, Netflix Tech Blog, V6, P2
   Liang H., 2023, ARXIV
   Mantiuk RK, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459831
   Mikhailiuk A, 2021, INT C PATT RECOG, P2559, DOI 10.1109/ICPR48806.2021.9412676
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Nafchi HZ, 2016, IEEE ACCESS, V4, P5579, DOI 10.1109/ACCESS.2016.2604042
   Paszke A, 2019, ADV NEUR IN, V32
   Perez-Ortiz M., 2017, arXiv
   Poullis C, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P153
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   Qi C. R., 2017, PROC CVPR IEEE, P652
   Qu Q, 2023, IEEE T VIS COMPUT GR, V29, P2239, DOI 10.1109/TVCG.2023.3247069
   Qu Q, 2021, IEEE T BROADCAST, V67, P837, DOI 10.1109/TBC.2021.3099737
   Reisenhofer R, 2018, SIGNAL PROCESS-IMAGE, V61, P33, DOI 10.1016/j.image.2017.11.001
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Song LC, 2023, IEEE T VIS COMPUT GR, V29, P2732, DOI 10.1109/TVCG.2023.3247082
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Subramanyam S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P127, DOI [10.1109/VR46266.2020.00-73, 10.1109/VR46266.2020.1581260728335]
   Suhail M, 2022, PROC CVPR IEEE, P8259, DOI 10.1109/CVPR52688.2022.00809
   Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tukey J. W., 1977, EXPLORATORY DATA ANA, V2
   Wang JY, 2023, AAAI CONF ARTIF INTE, P2555
   Wang K., 2022, IEEE Transactions on Visualization and Computer Graphics
   Wang P., 2022, ARXIV
   Wang QQ, 2021, PROC CVPR IEEE, P4688, DOI 10.1109/CVPR46437.2021.00466
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Whitlock M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P616, DOI [10.1109/VR46266.2020.00-20, 10.1109/VR46266.2020.1582298687237]
   Wizadwongsa S, 2021, PROC CVPR IEEE, P8530, DOI 10.1109/CVPR46437.2021.00843
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zwillinger Daniel, 1999, CRC Standard Probability and Statistics Tables and Formulae, DOI DOI 10.1201/9780367802417
NR 65
TC 0
Z9 0
U1 9
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2129
EP 2139
DI 10.1109/TVCG.2024.3372037
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400041
PM 38437095
DA 2024-11-06
ER

PT J
AU Westermeier, F
   Brübach, L
   Wienrich, C
   Latoschik, ME
AF Westermeier, Franziska
   Bruebach, Larissa
   Wienrich, Carolin
   Latoschik, Marc Erich
TI Assessing Depth Perception in VR and Video See-Through AR: A Comparison
   on Distance Judgment, Performance, and Preference
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Depth perception; VR; AR; video see-through; egocentric distance
   judgment; task performance; user preference
ID VIRTUAL-REALITY; AUGMENTED REALITY; ANOVA
AB Spatial User Interfaces along the Reality-Virtuality continuum heavily depend on accurate depth perception. However, current display technologies still exhibit shortcomings in the simulation of accurate depth cues, and these shortcomings also vary between Virtual or Augmented Reality (VR, AR: eXtended Reality (XR) for short). This article compares depth perception between VR and Video See-Through (VST) AR. We developed a digital twin of an existing office room where users had top erform five depth-dependent tasks in VR and VST AR. Thirty-two participants took part in a user study using a 1 x 4 within-subjects design. Our results reveal higher misjudgment rates in VST AR due to conflicting depth cues between virtual and physical content. Increased head movements observed in participants were interpreted as a compensatory response to these conflicting cues. Furthermore, a longer task completion time in the VST AR condition indicates a lower task performance in VST AR. Interestingly, while participants rated the VR condition as easier and contrary to the increased misjudgments and lower performance with the VST AR display, a majority still expressed a preference for the VST AR experience. We discuss and explain these findings with the high visual dominance and referential power of the physical content in the VST AR condition, leading to a higher spatial presence and plausibility.
C1 [Westermeier, Franziska] Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.
   [Westermeier, Franziska; Bruebach, Larissa] Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp, Wurzburg, Germany.
   [Wienrich, Carolin] Univ Wurzburg, PIIS Grp, Wurzburg, Germany.
   [Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg; University of Wurzburg;
   University of Wurzburg
RP Westermeier, F (corresponding author), Univ Wurzburg, Human Comp Interact HCI Grp, Wurzburg, Germany.; Westermeier, F (corresponding author), Univ Wurzburg, Psychol Intelligent Interact Syst PIIS Grp, Wurzburg, Germany.
EM franziska.westermeier@uni-wuerzburg.de;
   larissa.bruebach@uni-wuerzburg.de; carolin.wienrich@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
OI Wienrich, Carolin/0000-0003-3052-7172; Westermeier,
   Franziska/0000-0003-2534-4857; Brubach, Larissa/0000-0003-0171-7305
FU Bavarian State Ministry For Digital Affairs
FX No Statement Available
CR Adams H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P792, DOI 10.1109/VR51125.2022.00101
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Ballestin G, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P184, DOI 10.1109/ISMAR-Adjunct.2018.00063
   Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bodenheimer B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P35
   Brubach L, 2022, IEEE T VIS COMPUT GR, V28, P2267, DOI 10.1109/TVCG.2022.3150496
   Cidota MA, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P172, DOI [10.1109/ISMAR-Adjunct.2016.0070, 10.1109/ISMAR-Adjunct.2016.61]
   Cooper EA, 2023, ANNU REV VIS SCI, V9, P455, DOI 10.1146/annurev-vision-111022-123758
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   El Jamiy F, 2019, IET IMAGE PROCESS, V13, P707, DOI 10.1049/iet-ipr.2018.5920
   Gagnon HC, 2020, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2020), DOI 10.1145/3385955.3407933
   HART S G, 1988, P139
   Hartmann T, 2016, J MEDIA PSYCHOL-GER, V28, P1, DOI 10.1027/1864-1105/a000137
   HARWELL MR, 1992, J EDUC STAT, V17, P315, DOI 10.2307/1165127
   HENRY D, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P33, DOI 10.1109/VRAIS.1993.380801
   Howard I. P., 2002, Depth perception, V2, P2
   Hubona GS, 2005, LECT NOTES COMPUT SC, V3345, P104
   Jones JA, 2008, APGV 2008: PROCEEDINGS OF THE SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, P9
   Kelly JW, 2023, IEEE T VIS COMPUT GR, V29, P4978, DOI 10.1109/TVCG.2022.3196606
   Kelly JW, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.850471
   Kern Florian, 2023, 2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct), P74, DOI 10.1109/ISMAR-Adjunct60411.2023.00023
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489949
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Krichenbauer M, 2018, IEEE T VIS COMPUT GR, V24, P1038, DOI 10.1109/TVCG.2017.2658570
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Lugrin J.L., 2013, Proceedings of the 19th ACM Symposium on Virtual Reality Software and Technology, P49, DOI [10.1145/2503713.25037305, DOI 10.1145/2503713.25037305]
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Normand Jean-Marie., 2012, Proceedings of the 3rd Augmented Human International Conference, P18, DOI [DOI 10.1145/2160125.2160143, 10.1145/2160125.2160143]
   Oberdörfer S, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.679277
   Pfeil K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445223
   Ping JM, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1124, DOI [10.1109/vr.2019.8798174, 10.1109/VR.2019.8798174]
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Ries Brian, 2008, P 2008 ACM S VIRT RE, P167, DOI DOI 10.1145/1450579.1450614
   Schmider E, 2010, METHODOLOGY-EUR, V6, P147, DOI 10.1027/1614-2241/a000016
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   Vallat R., 2018, JOSS, V3, P1026, DOI [10.21105/joss.01026, DOI 10.21105/JOSS.01026]
   Vaziri K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P336, DOI 10.1109/VR50410.2021.00056
   Vorderer P., 2003, Report to the European Community, Project Presence: MEC (IST-2001- 37661), P6
   Westermeier F, 2023, 29TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2023, DOI 10.1145/3611659.3617227
   Westermeier F, 2023, IEEE T VIS COMPUT GR, V29, P2680, DOI 10.1109/TVCG.2023.3247046
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Willemsen P., 2004, P 1 S APPL PERC GRAP, P35, DOI [DOI 10.1145/1012551.1012558, 10.1145/1012551.1012558]
NR 47
TC 2
Z9 2
U1 6
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2140
EP 2150
DI 10.1109/TVCG.2024.3372061
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400029
PM 38437131
OA hybrid
DA 2024-11-06
ER

PT J
AU Takeuchi, M
   Kusuyama, H
   Iwai, D
   Sato, K
AF Takeuchi, Masaki
   Kusuyama, Hiroki
   Iwai, Daisuke
   Sato, Kosuke
TI Projection Mapping under Environmental Lighting by Replacing Room Lights
   with Heterogeneous Projectors
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Augmented reality; projection mapping; cooperative distributed projector
   optimization; large-aperture projector
ID LAMPS
AB Projection mapping (PM) is a technique that enhances the appearance of real-world surfaces using projected images, enabling multiple people to view augmentations simultaneously, thereby facilitating communication and collaboration. However, PM typically requires a dark environment to achieve high-quality projections, limiting its practicality. In this paper, we overcome this limitation by replacing conventional room lighting with heterogeneous projectors. These projectors replicate environmental lighting by selectively illuminating the scene, excluding the projection target. Our contributions include a distributed projector optimization framework designed to effectively replicate environmental lighting and the incorporation of a large-aperture projector, in addition to standard projectors, to reduce high-luminance emitted rays and hard shadows-undesirable factors for collaborative tasks in PM. We conducted a series of quantitative and qualitative experiments, including user studies, to validate our approach. Our findings demonstrate t hat our projector-based lighting system significantly enhancesthe contrast and realism of PM results even under e nvironmental lighting compared to typical lights. Furthermore, our method facilitates a substantial shift in the perceived color mode from the undesirable aperture-color mode, where observers perceive the projected object as self-luminous, to the surface-color mode in PM.
C1 [Takeuchi, Masaki; Kusuyama, Hiroki; Iwai, Daisuke; Sato, Kosuke] Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
C3 Osaka University
RP Takeuchi, M (corresponding author), Osaka Univ, Grad Sch Engn Sci, Osaka, Japan.
EM m.takeuchi@sens.sys.es.osaka-u.ac.jp;
   hiroki.kusuyama@sens.sys.es.osaka-u.ac.jp;
   daisuke.iwai.es@osaka-u.ac.jp; sato@sys.es.osaka-u.ac.jp
OI Takeuchi, Masaki/0000-0002-0773-7705; Kusuyama,
   Hiroki/0009-0007-9406-2120; Sato, Kosuke/0000-0003-1429-9990
FU JSPS KAKENHI
FX No Statement Available
CR Abdelhamed A, 2021, PROC CVPR IEEE, P6633, DOI 10.1109/CVPR46437.2021.00657
   Bandyopadhyay D, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P207, DOI 10.1109/ISAR.2001.970539
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O, 2005, IEEE MULTIMEDIA, V12, P16, DOI 10.1109/MMUL.2005.9
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Bimber O, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P186, DOI 10.1109/ISMAR.2002.1115088
   Bimber O., 2005, Spatial augmented reality: merging real and virtual worlds
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Boyd Stephen, 2015, About us
   Cascini G, 2020, COMPUT IND, V123, DOI 10.1016/j.compind.2020.103308
   Erel Yotam, 2023, IEEE Trans Vis Comput Graph, V29, P4339, DOI 10.1109/TVCG.2023.3320256
   Fender AR, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P106, DOI 10.1145/3132272.3134117
   Flagg Matthew, 2006, UIST'06, P235, DOI DOI 10.1145/1166253.1166290
   Grundhöfer A, 2015, IEEE T IMAGE PROCESS, V24, P5086, DOI 10.1109/TIP.2015.2478388
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Guarnera G. C., 2022, EUROGRAPHICS S RENDE, DOI [10.2312/sr.20221150, DOI 10.2312/SR.20221150]
   Hiratani K, 2023, IEEE T VIS COMPUT GR, V29, P2280, DOI 10.1109/TVCG.2023.3247104
   Huang BY, 2022, IEEE T PATTERN ANAL, V44, P2953, DOI 10.1109/TPAMI.2021.3050124
   Iwai D., 2006, P ACM S VIRT REAL SO, P112, DOI DOI 10.1145/1180495.1180519
   Iwai D, 2018, IEEE ACCESS, V6, P6293, DOI 10.1109/ACCESS.2017.2781699
   Iwai D, 2011, VIRTUAL REAL-LONDON, V15, P147, DOI 10.1007/s10055-010-0159-5
   Jaynes C, 2004, IEEE T VIS COMPUT GR, V10, P290, DOI 10.1109/TVCG.2004.1272728
   Jones Brett, 2014, P 27 ANN ACM S US IN, P637, DOI [10.1145/2642918.2647383, DOI 10.1145/2642918.2647383]
   Katz D., 1935, The World of Colour, P6
   Kitajima Y., 2017, IEEE Transactions on Visualization andComputer Graphics, V23, P1
   LeGendre C., 2022, DIGITAL PRODUCTION S, DOI [10.1145/3543664.35436812, DOI 10.1145/3543664.35436812]
   LeGendre C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925934
   Maimone A, 2013, P IEEE VIRT REAL ANN, P23, DOI 10.1109/VR.2013.6549352
   Marner MR, 2014, IEEE COMPUT GRAPH, V34, P74, DOI 10.1109/MCG.2014.117
   Matsushita K., 2011, P 2NDAUGMENTED HUMAN
   Menk C, 2013, IEEE T VIS COMPUT GR, V19, P236, DOI 10.1109/TVCG.2012.146
   Morimoto T, 2021, J VISION, V21, DOI 10.1167/jov.21.13.3
   Nagase M., 2011, Virtual Reality, V15, P3
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Nomoto T, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3407297
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Raskar G., 1998, P 25 ANN C COMP GRAP, P179
   Raskar R, 2004, ACM T GRAPHIC, V23, P406, DOI 10.1145/1015706.1015738
   Rivers A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366176
   Schmidt S, 2019, COMPUT GRAPH-UK, V83, P1, DOI 10.1016/j.cag.2019.06.002
   Shi JS, 2014, PROC SPIE, V9273, DOI 10.1117/12.2071915
   Siegl C., 2017, ComputationalVisual Media, V3, P263, DOI [10.1007/s41095-017-0090-82,3, DOI 10.1007/S41095-017-0090-82,3]
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Sukthankar R, 2001, PROC CVPR IEEE, P151
   Takeuchi Y, 2022, IEEE ACCESS, V10, P939, DOI 10.1109/ACCESS.2021.3139108
   Takeuchi Y, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P39, DOI 10.1145/2992154.2992188
   Takezawa T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P251, DOI [10.1109/vr.2019.8797923, 10.1109/VR.2019.8797923]
   Tsukamoto J, 2015, IEEE T VIS COMPUT GR, V21, P1221, DOI 10.1109/TVCG.2015.2459905
   UCHIKAWA H, 1989, VISION RES, V29, P881, DOI 10.1016/0042-6989(89)90099-0
   Uchikawa K, 2001, J OPT SOC AM A, V18, P737, DOI 10.1364/JOSAA.18.000737
   Underkofer John, 1999, P SIGCHI C HUM FACT, P386, DOI DOI 10.1145/302979.303114
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yasui M., 2021, SIGGRAPH ASIA 2021 P, DOI [10.1145/3476124.34886243, DOI 10.1145/3476124.34886243]
   Zhong FC, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480513
   Zhou Z, 2015, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2015.7223335
NR 58
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2151
EP 2161
DI 10.1109/TVCG.2024.3372031
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400054
PM 38437091
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Salagean, A
   Wu, M
   Fletcher, G
   Cosker, D
   Fraser, DS
AF Salagean, Anca
   Wu, Michelle
   Fletcher, George
   Cosker, Darren
   Fraser, Danae Stanton
TI The Utilitarian Virtual Self - Using Embodied Personalized Avatars to
   Investigate Moral Decision-Making in Semi-Autonomous Vehicle Dilemmas
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ethics; Avatars; Motor drives; Decision making; Automobiles; Electronic
   mail; Vehicles; Human-centered computing-Empirical studies in HCI;
   Virtual reality; Usability testing
ID BODY OWNERSHIP; ENVIRONMENTS; JUDGMENT; SENSE; EXPERIENCE; BEHAVIOR
AB Embodied personalized avatars are a promising new tool to investigate moral decision-making by transposing the user into the "middle of the action" in moral dilemmas. Here, we tested whether avatar personalization and motor control could impact moral decision-making, physiological reactions and reaction times, as well as embodiment, presence and avatar perception. Seventeen participants, who had their personalized avatars created in a previous study, took part in a range of incongruent (i.e., harmful action led to better overall outcomes) and congruent (i.e., harmful action led to trivial outcomes) moral dilemmas as the drivers of a semi-autonomous car. They embodied four different avatars (counterbalanced - personalized motor control, personalized no motor control, generic motor control, generic no motor control). Overall, participants took a utilitarian approach by performing harmful actions only to maximize outcomes. We found increased physiological arousal (SCRs and heart rate) for personalized avatars compared to generic avatars, and increased SCRs in motor control conditions compared to no motor control. Participants had slower reaction times when they had motor control over their avatars, possibly hinting at more elaborate decision-making processes. Presence was also higher in motor control compared to no motor control conditions. Embodiment ratings were higher for personalized avatars, and generally, personalization and motor control were perceptually positive features. These findings highlight the utility of personalized avatars and open up a range of future research possibilities that could benefit from the affordances of this technology and simulate, more closely than ever, real-life action.
C1 [Salagean, Anca] Univ Bath, Comp Sci Dept, Bath, England.
   [Salagean, Anca; Fraser, Danae Stanton] Univ Bath, Psychol Dept, Bath, England.
   [Wu, Michelle; Fletcher, George; Cosker, Darren] Univ Bath, CAMERA, Bath, England.
   [Cosker, Darren] Microsoft UK, London, England.
C3 University of Bath; University of Bath; University of Bath
RP Salagean, A (corresponding author), Univ Bath, Comp Sci Dept, Bath, England.; Salagean, A (corresponding author), Univ Bath, Psychol Dept, Bath, England.
EM as3101@bath.ac.uk; mw2634@bath.ac.uk; gf321@bath.ac.uk;
   dpc22@bath.ac.uk; pssds@bath.ac.uk
OI Stanton Fraser, Danae/0000-0002-3062-731X; Cosker,
   Darren/0000-0001-5177-4741
FU Bristol and Bath Creative R&D funded by the AHRC Creative Industries
   Cluster Programme
FX No Statement Available
CR Achenbach J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139154
   [Anonymous], 2011, P HCI 2011 25 BCS C, DOI DOI 10.14236/EWIC/HCI2011.26
   Azuma MC, 2023, ERGONOMICS, V66, P246, DOI 10.1080/00140139.2022.2076906
   Banakou D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00917
   Bartl A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694617
   Blanca MJ, 2017, PSICOTHEMA, V29, P552, DOI 10.7334/psicothema2016.383
   Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654
   Boucsein W, 2012, PSYCHOPHYSIOLOGY, V49, P1017, DOI 10.1111/j.1469-8986.2012.01384.x
   Braithwaite J. J., 2013, PSYCHOPHYSIOLOGY, V49, P1017, DOI DOI 10.1111/J.1469-8986.2012.01384.X
   Brown H., 2021, Doctoral Thesis
   Caserman P, 2020, IEEE T VIS COMPUT GR, V26, P3089, DOI 10.1109/TVCG.2019.2912607
   Conway P, 2013, J PERS SOC PSYCHOL, V104, P216, DOI 10.1037/a0031021
   Cushman F, 2013, PERS SOC PSYCHOL REV, V17, P273, DOI 10.1177/1088868313495594
   Cushman F, 2012, EMOTION, V12, P2, DOI 10.1037/a0025071
   Farmer H, 2012, CONSCIOUS COGN, V21, P1242, DOI 10.1016/j.concog.2012.04.011
   Faulhaber AK, 2019, SCI ENG ETHICS, V25, P399, DOI 10.1007/s11948-018-0020-x
   Figner B., 2011, A Handbook of Process Tracing Methods for Decision Research: A Critical Review and User's Guide, P163
   Francis KB, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13909-9
   Francis KB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0164374
   Frank DA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49411-7
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Gall D, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.674179
   Gawronski B, 2017, SOC NEUROSCI-UK, V12, P626, DOI 10.1080/17470919.2016.1248787
   Geisslinger M, 2023, NAT MACH INTELL, V5, P137, DOI 10.1038/s42256-022-00607-z
   González-Franco M, 2010, P IEEE VIRT REAL ANN, P111, DOI 10.1109/VR.2010.5444805
   Goodall NJ, 2014, TRANSPORT RES REC, P58, DOI 10.3141/2424-07
   Greene JD, 2004, NEURON, V44, P389, DOI 10.1016/j.neuron.2004.09.027
   Greene JD, 2001, SCIENCE, V293, P2105, DOI 10.1126/science.1062872
   Greene JD, 2008, COGNITION, V107, P1144, DOI 10.1016/j.cognition.2007.11.004
   Hazra A, 2016, INDIAN J DERMATOL, V61, P10, DOI 10.4103/0019-5154.173988
   Horn C, 2006, GROUNDWORK FOR THE METAPHYSICS OF MORALS, P1, DOI 10.1515/9783110204551
   Kallioinen Noa, 2019, Front Psychol, V10, P2415, DOI 10.3389/fpsyg.2019.02415
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kirchmair L, 2023, NAT MACH INTELL, V5, P814, DOI 10.1038/s42256-023-00706-5
   Koenigs M, 2007, NATURE, V446, P908, DOI 10.1038/nature05631
   Kokkinara E, 2014, PERCEPTION, V43, P43, DOI 10.1068/p7545
   Lin JH, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.974652
   Madary M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00003
   McDonnell R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185587
   Mendez MF, 2005, COGN BEHAV NEUROL, V18, P193, DOI 10.1097/01.wnn.0000191292.17964.bb
   Mill John S., 1861, UTILITARIANISM
   Navarrete CD, 2012, EMOTION, V12, P364, DOI 10.1037/a0025561
   Ni BK, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1063607
   Niforatos E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376788
   OLDFIELD RC, 1971, NEUROPSYCHOLOGIA, V9, P97, DOI 10.1016/0028-3932(71)90067-4
   Pan XN, 2011, LECT NOTES COMPUT SC, V6975, P52, DOI 10.1007/978-3-642-24571-8_6
   Patil I, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00501
   Patil I, 2014, SOC NEUROSCI-UK, V9, P94, DOI 10.1080/17470919.2013.870091
   Patil M. M., 2020, Journal of Personality and Social Psychology, P1
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Pyasik M, 2021, COGNITION, V212, DOI 10.1016/j.cognition.2021.104693
   Qian LX, 2023, TECHNOL FORECAST SOC, V188, DOI 10.1016/j.techfore.2022.122267
   Ratan R, 2020, MEDIA PSYCHOL, V23, P651, DOI 10.1080/15213269.2019.1623698
   Reynolds CJ, 2019, COGNITION, V192, DOI 10.1016/j.cognition.2019.06.005
   Salagean A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581182
   Salagean A, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3487563
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schultze U, 2010, J INF TECHNOL-UK, V25, P434, DOI 10.1057/jit.2010.25
   Skulmowski A, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00426
   Slater M., 2020, FRONT VIRTUAL REAL, V1, DOI DOI 10.3389/FRVIR.2020.00001
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2009, ANU PSICOL, V40, P193
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Sood S, 2005, ORGAN BEHAV HUM DEC, V98, P144, DOI 10.1016/j.obhdp.2005.05.005
   Sütfeld LR, 2017, FRONT BEHAV NEUROSCI, V11, DOI 10.3389/fnbeh.2017.00122
   Tassy S, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00250
   Thomson J., 1986, RIGHTS RESTITUTION R
   THOMSON JJ, 1985, YALE LAW J, V94, P1395, DOI 10.2307/796133
   Uijong J, 2019, IEEE T VIS COMPUT GR, V25, P1898, DOI 10.1109/TVCG.2019.2899227
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wang HR, 2023, LECT NOTES ARTIF INT, V14018, P560, DOI 10.1007/978-3-031-35389-5_39
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1031093
   Wu TLY, 2019, INT J HUM-COMPUT INT, V35, P1569, DOI 10.1080/10447318.2018.1555736
   Yee N, 2007, HUM COMMUN RES, V33, P271, DOI 10.1111/j.1468-2958.2007.00299.x
   Youssef FF, 2012, PSYCHONEUROENDOCRINO, V37, P491, DOI 10.1016/j.psyneuen.2011.07.017
   Zhu AR, 2022, PERS INDIV DIFFER, V186, DOI 10.1016/j.paid.2021.111356
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
NR 79
TC 0
Z9 0
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2162
EP 2172
DI 10.1109/TVCG.2024.3372121
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400018
PM 38437115
DA 2024-11-06
ER

PT J
AU Cao, X
   Li, J
   Zhao, PP
   Li, JC
   Qin, XY
AF Cao, Xin
   Li, Jia
   Zhao, Panpan
   Li, Jiachen
   Qin, Xueying
TI Corr-Track: Category-Level 6D Pose Tracking with Soft-Correspondence
   Matrix Estimation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Category-level object pose estimation; object tracking
ID SURFACE
AB Category-level pose tracking methods can continuously track the pose of objects without requiring any prior knowledge of the specific shape of the tracked instance. This makes them advantageous in augmented reality and virtual reality applications. The key challenge is how to train neural networks to accurately predict the poses of objects they have never seen before and exhibit strong generalization performance. We propose a novel category-level 6D pose tracking method Corr-Track, which is capable of accurately tracking objects belonging to the same category from depth video streams. Our approach utilizes direct soft correspondence constraints to train a neural network, which estimates bidirectional soft correspondences between sparsely sampled point clouds of objects in two frames. We first introduce a soft correspondence matrix for pose tracking tasks and establish effective constraints through direct spatial point-to-point correspondence representations in the sparse point cloud correspondence matrix. We propose the "point cloud expansion" strategy to address the "point cloud shrinkage" problem resulting from soft correspondences. This strategy ensures that the corresponding point cloud accurately reproduces the shape of the target point cloud, leading to precise pose tracking results. We evaluated our approach on the NOCS-REAL275 and Wild6D dataset and observed superior performance compared to previous methods. Additionally, we conducted cross-category experiments that further demonstrated its generalization capability.
C1 [Cao, Xin; Li, Jia; Zhao, Panpan; Qin, Xueying] Shandong Univ, Sch Software, Jinan, Peoples R China.
   [Cao, Xin; Li, Jia; Zhao, Panpan; Qin, Xueying] Minist Educ, Engn Res Ctr Digital Media Technol, Beijing, Peoples R China.
   [Li, Jiachen] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Shandong University; Zhejiang University
RP Cao, X (corresponding author), Shandong Univ, Sch Software, Jinan, Peoples R China.; Cao, X (corresponding author), Minist Educ, Engn Res Ctr Digital Media Technol, Beijing, Peoples R China.
EM sdu_cx@mail.sdu.edu.cn; lirity1024@outlook.com;
   zhaopanpan@mail.sdu.edu.cn; lijiachen93@zju.edu.cn; qxy@sdu.edu.cn
FU National Key R&D Program of China
FX No Statement Available
CR Aoki Y., 2019, IEEE C COMP VIS PATT, P2
   Brachmann E, 2019, IEEE I CONF COMP VIS, P4321, DOI 10.1109/ICCV.2019.00442
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Chen K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2753, DOI 10.1109/ICCV48922.2021.00277
   Chen Wang, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10059, DOI 10.1109/ICRA40945.2020.9196679
   Chen W, 2021, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR46437.2021.00163
   Cuturi M., 2013, Advances in Neural Information Processing Systems, V2, P2292
   Dai QY, 2022, LECT NOTES COMPUT SC, V13699, P374, DOI 10.1007/978-3-031-19842-7_22
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Dengsheng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11970, DOI 10.1109/CVPR42600.2020.01199
   Di Y, 2022, PROC CVPR IEEE, P6771, DOI 10.1109/CVPR52688.2022.00666
   Dong Z, 2017, ISPRS J PHOTOGRAMM, V130, P431, DOI 10.1016/j.isprsjprs.2017.06.012
   Fan Zhaoxin, 2021, arXiv
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Li B, 2022, COMPUT METH PROG BIO, V220, DOI 10.1016/j.cmpb.2022.106782
   Li ZY, 2023, Arxiv, DOI [arXiv:2312.02284, 10.48550/ARXIV.2312.022849, DOI 10.48550/ARXIV.2312.022849]
   Lin HT, 2022, PROC CVPR IEEE, P6697, DOI 10.1109/CVPR52688.2022.00659
   Lin JH, 2022, LECT NOTES COMPUT SC, V13669, P19, DOI 10.1007/978-3-031-20077-9_2
   Lin JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3540, DOI 10.1109/ICCV48922.2021.00354
   Lin Yunzhi, 2022, 2022 International Conference on Robotics and Automation (ICRA), P1258, DOI 10.1109/ICRA46639.2022.9811720
   Lindenberger P, 2023, Arxiv, DOI arXiv:2306.13643
   Liu JH, 2023, Arxiv, DOI arXiv:2303.13479
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu WX, 2019, IEEE I CONF COMP VIS, P12, DOI 10.1109/ICCV.2019.00010
   Luo ZX, 2019, PROC CVPR IEEE, P2522, DOI 10.1109/CVPR.2019.00263
   Pan Y, 2018, INT CONF 3D VISION, P180, DOI 10.1109/3DV.2018.00030
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Sajjan S, 2020, IEEE INT CONF ROBOT, P3634, DOI 10.1109/ICRA40945.2020.9197518
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499
   Sarode V, 2019, Arxiv, DOI [arXiv:1908.07906, DOI 10.48550/ARXIV.1908.07906]
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343
   Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881
   Sun JT, 2022, IEEE INT C INT ROBOT, P1556, DOI 10.1109/IROS47612.2022.9982183
   Tian M., 2020, Lecture Notes in Computer Science, V12366, P2
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wang JZ, 2021, IEEE INT C INT ROBOT, P4807, DOI 10.1109/IROS51168.2021.9636212
   Wang Y, 2019, 33 C NEURAL INFORM P, V32
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wen BW, 2021, IEEE INT C INT ROBOT, P8067, DOI 10.1109/IROS51168.2021.9635991
   Weng YJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13189, DOI 10.1109/ICCV48922.2021.01296
   Xie YY, 2021, INT C PATT RECOG, P2779, DOI 10.1109/ICPR48806.2021.9413319
   Yew Z. J., 2020, 2020 IEEE CVF C COMP
   Ze Y, 2022, P ADV NEUR INF PROC, V35, P27469
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang JH, 2022, IEEE T PATTERN ANAL, V44, P3110, DOI 10.1109/TPAMI.2020.3048013
   Zhang R, 2022, LECT NOTES COMPUT SC, V13661, P655, DOI 10.1007/978-3-031-19769-7_38
   Zheng LF, 2023, PROC CVPR IEEE, P17163, DOI 10.1109/CVPR52729.2023.01646
   Zhu LY, 2021, PROC CVPR IEEE, P4647, DOI 10.1109/CVPR46437.2021.00462
   Zodage T, 2020, INT CONF 3D VISION, P603, DOI 10.1109/3DV50981.2020.00070
NR 55
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2173
EP 2183
DI 10.1109/TVCG.2024.3372111
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400062
PM 38437129
DA 2024-11-06
ER

PT J
AU Kim, H
   Jeon, SB
   Lee, IK
AF Kim, Hyunjeong
   Jeon, Sang-Bin
   Lee, In-Kwon
TI Locomotion Techniques for Dynamic Environments: Effects on Spatial
   Knowledge and User Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Locomotion technique; Dynamic environment; Spatial knowledge; user
   experience; Redirected walking; teleportation; joystick
ID WALKING-IN-PLACE; REDIRECTED WALKING; VIRTUAL-REALITY; MOVEMENT; TRAVEL
AB Various locomotion techniques are used to navigate and find way through space in virtual environments (VE), and each technique provides different experiences and performances to users. Previous studies have primarily focused on static environments, whereas there is a need for research from a different perspective of dynamic environments because there are many moving objects in VE, such as other users. In this study, we compare the effects of different locomotion techniques on the user's spatial knowledge and experience, depending on whether the virtual objects are moving or not. The investigated locomotion techniques include joystick, teleportation, and redirected walking (RDW), all commonly used for VR navigation. The results showed that the differences in spatial knowledge and user experience provided by different locomotion techniques can vary depending on whether the environment is static or dynamic. Our results also showed that for a given VE, there are different locomotion techniques that induce fewer collisions between the user and other objects, or reduce the time it takes the user to perform a given task. This study suggests that when designing a locomotion interface for a specific VR application, it is possible to improve the user's spatial knowledge and experience by recommending different locomotion techniques depending on the degree of environment dynamism and and type of task.
C1 [Kim, Hyunjeong; Jeon, Sang-Bin; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Yonsei, South Korea.
C3 Yonsei University
RP Lee, IK (corresponding author), Yonsei Univ, Dept Comp Sci, Yonsei, South Korea.
EM hcihjkim@yonsei.ac.kr; ludens0508@yonsei.ac.kr; iklee@yonsei.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Kim, Hyunjeong/0000-0003-0156-5436; Lee, In-Kwon/0000-0002-1534-1882
FU National Research Foundation of Korea
FX No Statement Available
CR Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Allen Gary., 2004, HUMAN SPATIAL MEMORY
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2288, DOI 10.1109/TVCG.2022.3150466
   Bakker NH, 2003, HUM FACTORS, V45, P160, DOI 10.1518/hfes.45.1.160.27234
   Basili P, 2013, GAIT POSTURE, V37, P385, DOI 10.1016/j.gaitpost.2012.08.003
   Blanke O, 2009, TRENDS COGN SCI, V13, P7, DOI 10.1016/j.tics.2008.10.003
   Bohannon RW, 1997, AGE AGEING, V26, P15, DOI 10.1093/ageing/26.1.15
   Boletsis C, 2019, ADV HUM-COMPUT INTER, V2019, DOI 10.1155/2019/7420781
   Bolte F., 2011, P VIRT REAL INT C, V1
   Botvinick M, 1998, NATURE, V391, P756, DOI 10.1038/35784
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooke J., 1995, USABILITY EVAL IND, P189
   Bruder G, 2015, IEEE T VIS COMPUT GR, V21, P539, DOI 10.1109/TVCG.2015.2391864
   Buttussi F, 2023, INT J HUM-COMPUT ST, V177, DOI 10.1016/j.ijhcs.2023.103067
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Chihak BJ, 2010, J EXP PSYCHOL HUMAN, V36, P1535, DOI 10.1037/a0020560
   Cho YH, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P448, DOI 10.1109/VR50410.2021.00068
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   Coomer N, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225175
   CUTTING JE, 1995, PSYCHOL REV, V102, P627, DOI 10.1037/0033-295X.102.4.627
   Darken RP, 2002, HUM FAC ER, P493
   Erickson KI, 2011, P NATL ACAD SCI USA, V108, P3017, DOI 10.1073/pnas.1015950108
   Fan CW, 2023, Symposium Virtual Re, P53, DOI 10.1109/VR55154.2023.00021
   Frissen I, 2011, EXP BRAIN RES, V212, P163, DOI 10.1007/s00221-011-2717-9
   Frommel J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'17), DOI 10.1145/3102071.3102082
   HART S G, 1988, P139
   Hashemian AM, 2017, LECT NOTES COMPUT SC, V10280, P15, DOI 10.1007/978-3-319-57987-0_2
   Huang S.-K., 2023, IEEE transactions on visualizationand computer graphics, V2
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim H, 2018, PSYCHIAT INVEST, V15, P935, DOI 10.30773/pi.2018.06.28.3
   Kyriakou M, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1729
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Lee S.-B., 2023, arXiv preprintarXiv:2306.11433, V2
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Martinez ES, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P270, DOI 10.1109/VR51125.2022.00046
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Mousas C, 2021, VISUAL COMPUT, V37, P2823, DOI 10.1007/s00371-021-02202-6
   NCD Risk Factor Collaboration (NCD-RisC), 2016, Elife, V5, DOI 10.7554/eLife.13410
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Olivier Anne-Helene, 2018, IEEE Transactions on Visualization and Computer Graphics, V24, P2251, DOI 10.1109/TVCG.2017.2714665
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Petkova VI, 2011, FRONT PSYCHOL, V2, DOI 10.3389/fpsyg.2011.00035
   Prinz LM, 2023, IEEE T VIS COMPUT GR, V29, P5208, DOI 10.1109/TVCG.2022.3206915
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Razzaque S., 2005, Redirected Walking
   Reason J.T., 1975, Motion sickness, V2
   Rebenitsch Lisa, 2015, The ACM Magazine for Students, V22, P46, DOI [10.1145/2810054, DOI 10.1145/2810054]
   Ruddle RA, 2006, PSYCHOL SCI, V17, P460, DOI 10.1111/j.1467-9280.2006.01728.x
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Scavarelli R. J., 2017, P 2017 CHI C HUM FAC, P2915
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   Williams B, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265961
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Wilson PT, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P243, DOI 10.1145/3013971.3014010
NR 66
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2184
EP 2194
DI 10.1109/TVCG.2024.3372074
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400021
PM 38437127
DA 2024-11-06
ER

PT J
AU Park, J
   Choi, Y
   Lee, KM
AF Park, Jieun
   Choi, Youjin
   Lee, Kyung Myun
TI Research Trends in Virtual Reality Music Concert Technology: A
   Systematic Literature Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Music Concert; Interaction; Evaluation Metric
ID SOCIAL PRESENCE; FLOW; PERFORMANCE; EXPERIENCE
AB Advances in virtual reality (VR) technology have sparked novel avenues of growth in the musical domain. Following the COVID-19 pandemic, the rise of VR technology has led to growing interest in VR music concerts as an alternative to traditional live concerts. These virtual settings can provide immersion like attending real concerts for physically distant audiences and performers, and also can offer new creative possibilities. VR music concert research is still in its infancy, and advances in technologies such as multimodal devices are rapidly expanding the diversity of research, requiring a unified understanding of the field. To identify trends in VR music concert technology, we conducted a PRISMA-based systematic literature review covering the period from 2018 to 2023. After a thorough screening process, a total of 27 papers were selected for review. The studies were classified and analyzed based on the research topic (audience, performer, concert venue), interaction type (user-environment, user-user), and hardware used (head-mounted display, additional hardware). Furthermore, we categorized the evaluation metrics into user experience, usability, and performance. Our review contributes to advancing the understanding of recent developments in VR music concert technology, shedding light on the diversification and potential of this emerging field.
C1 [Park, Jieun; Choi, Youjin; Lee, Kyung Myun] Korea Adv Inst Sci & Technol, Dajeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Park, J (corresponding author), Korea Adv Inst Sci & Technol, Dajeon, South Korea.
EM pjepsh@kaist.ac.kr; dbwls3363@kaist.ac.kr; kmlee2@kaist.ac.kr
RI Lee, Kyung/G-3057-2016
OI Lee, Kyung Myun/0000-0003-4118-0979; Park, Jieun/0009-0000-5985-7488;
   Choi, Youjin/0009-0003-1326-3387
FU NRF
FX No Statement Available
CR Abe M, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P827, DOI 10.1109/VRW55335.2022.00269
   Adeoye-Olatunde OA, 2021, J AM COLL CLIN PHARM, V4, P1358, DOI 10.1002/jac5.1441
   Athif M, 2020, IEEE ENG MED BIO, P3035, DOI 10.1109/EMBC44109.2020.9176022
   Beacco A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P538, DOI 10.1109/VR50410.2021.00078
   BEVAN N, 1994, BEHAV INFORM TECHNOL, V13, P132, DOI 10.1080/01449299408914592
   Bevan N, 2015, LECT NOTES COMPUT SC, V9169, P143, DOI 10.1007/978-3-319-20901-2_13
   Bian YL, 2016, PERS UBIQUIT COMPUT, V20, P821, DOI 10.1007/s00779-016-0953-5
   Bolarinwa Oladimeji Akeem, 2015, Niger Postgrad Med J, V22, P195, DOI 10.4103/1117-1936.173959
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brown SC, 2017, MUSIC SCI, V21, P233, DOI 10.1177/1029864916650719
   Bulu ST, 2012, COMPUT EDUC, V58, P154, DOI 10.1016/j.compedu.2011.08.024
   Cacciuttolo L., 2021, ACM SIGGRAPH 2021 IM, DOI [10.1145/3450615.34649501, DOI 10.1145/3450615.34649501]
   Caruelle D, 2019, J BUS RES, V104, P146, DOI 10.1016/j.jbusres.2019.06.041
   Chadegani A. A., 2013, Asian Social Science, V9, DOI [10.5539/ass.v9n5p182, DOI 10.5539/ASS.V9N5P182]
   Chen YX, 2023, SAGE OPEN, V13, DOI 10.1177/21582440231181585
   Chen YX, 2022, PERCEPTION, V51, P889, DOI 10.1177/03010066221125864
   Chen YX, 2023, PSYCHOL MUSIC, V51, P782, DOI 10.1177/03057356221110631
   Chen YX, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107544
   Cortellessa V., 2011, What Is Software Performance?, P1, DOI [10.1007/978-3-642-13621-4_17, DOI 10.1007/978-3-642-13621-4_17]
   Csikszentmihalyi M., 2014, FLOW FDN POSITIVE PS, DOI [DOI 10.1007/978-94-017-9088-815, 10.1007/978-94-017-9088-8, DOI 10.1007/978-94-017-9088-8, 10.1007/978-94-017-9088-8_2]
   Czepiel A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00492-3
   Dahl S, 2007, MUSIC PERCEPT, V24, P433, DOI 10.1525/MP.2007.24.5.433
   Dotov D, 2021, Q J EXP PSYCHOL, V74, P1037, DOI 10.1177/1747021821991793
   Droste M, 2018, PROCEEDINGS OF THE SECOND AFRICAN CONFERENCE FOR HUMAN COMPUTER INTERACTION: THRIVING COMMUNITIES (AFRICHI), P291, DOI 10.1145/3283458.3283501
   Engeser S, 2008, MOTIV EMOTION, V32, P158, DOI 10.1007/s11031-008-9102-4
   Frank Matthias, 2022, AM'22: AudioMostly 2022, P80, DOI 10.1145/3561212.3561216
   Hajika R, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P15, DOI 10.1145/3355355.3361894
   Hamilton R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1510, DOI [10.1109/VR.2019.8798166, 10.1109/vr.2019.8798166]
   Horie R, 2018, ADV INTELL SYST, V585, P276, DOI 10.1007/978-3-319-60495-4_30
   Hwang Y, 2015, TELEMAT INFORM, V32, P755, DOI 10.1016/j.tele.2015.03.006
   Ishiyama T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P990, DOI [10.1109/vr.2019.8797883, 10.1109/VR.2019.8797883]
   ISO, 1998, 1998924111 ISO
   Jackson SA, 1996, J SPORT EXERCISE PSY, V18, P17, DOI 10.1123/jsep.18.1.17
   Jung KYE, 2024, VIRTUAL REAL-LONDON, V28, DOI 10.1007/s10055-023-00910-z
   Jung K, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P579, DOI 10.1109/VRW58643.2023.00132
   Kaneko T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P124, DOI 10.1109/AIVR.2018.00025
   Kasuya T, 2019, 2019 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), DOI 10.1109/gem.2019.8811549
   Kim M, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, DOI 10.1145/3503161.3548347
   Laeng B, 2012, PERSPECT PSYCHOL SCI, V7, P18, DOI 10.1177/1745691611427305
   Lalioti V, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489896
   Li Y.X., 2019, VRIH, V56, P84, DOI DOI 10.3724/SP.J.2096-5796.2018.0006
   Martin AJ, 2008, MOTIV EMOTION, V32, P141, DOI 10.1007/s11031-008-9094-0
   Munoz-Gonzalez Angel, 2021, 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE), P174, DOI 10.1109/GCCE53005.2021.9621854
   Munoz-Gonzalez A, 2022, IEEE T HUM-MACH SYST, V52, P248, DOI 10.1109/THMS.2021.3134555
   Onderdijk KE, 2023, VIRTUAL REAL-LONDON, V27, P2383, DOI 10.1007/s10055-023-00814-y
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Petrovic N, 2020, 2020 55TH INTERNATIONAL SCIENTIFIC CONFERENCE ON INFORMATION, COMMUNICATION AND ENERGY SYSTEMS AND TECHNOLOGIES (IEEE ICEST 2020), P33, DOI [10.1109/ICEST49890.2020.9232713, 10.1109/icest49890.2020.9232713]
   Petrovic N, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P118, DOI [10.1109/zinc50678.2020.9161792, 10.1109/ZINC50678.2020.9161792]
   Ppali S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501922
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Slater M, 1999, PRESENCE-TELEOP VIRT, V8, P560, DOI 10.1162/105474699566477
   Slater M, 2023, VIRTUAL REAL-LONDON, V27, P651, DOI 10.1007/s10055-022-00685-9
   Son S, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P657, DOI 10.1109/VRW58643.2023.00171
   Subha DP, 2010, J MED SYST, V34, P195, DOI 10.1007/s10916-008-9231-z
   Swarbrick D, 2019, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02682
   Tian Y, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01121
   Turchet L, 2021, IEEE ACCESS, V9, P15810, DOI 10.1109/ACCESS.2021.3052931
   Ulrich M, 2016, SOC COGN AFFECT NEUR, V11, P496, DOI 10.1093/scan/nsv133
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Van Kerrebroeck B, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.663725
   Wang MJ, 2022, APPL MATH NONLIN SCI, DOI 10.2478/amns.2022.2.0138
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
   Wolf S, 2015, BIOL PSYCHOL, V105, P95, DOI 10.1016/j.biopsycho.2015.01.007
   Yakura H, 2020, INT SYM MIX AUGMENT, P555, DOI 10.1109/ISMAR50242.2020.00083
   Yamamoto T., 1999, IEEE SMC 99 C P 1999, V5, P8
   Yan S., 2020, SIGGRAPH AS 2020 POS, DOI [10.1145/3415264.34254663,4,8, DOI 10.1145/3415264.34254663,4,8]
   Yang T, 2012, INT J HUM-COMPUT INT, V28, P308, DOI 10.1080/10447318.2011.586320
NR 68
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2195
EP 2205
DI 10.1109/TVCG.2024.3372069
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400055
PM 38437121
DA 2024-11-06
ER

PT J
AU Combe, T
   Fribourg, R
   Detto, L
   Norm, JM
AF Combe, Theo
   Fribourg, Rebecca
   Detto, Lucas
   Norm, Jean-Marie
TI Exploring the Influence of Virtual Avatar Heads in Mixed Reality on
   Social Presence, Performance and User Experience in Collaborative Tasks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Collaboration; Task analysis; Faces; Resists; Mixed reality;
   Cameras; Mixed Reality; Avatar Representation
ID COMMUNICATION; ENVIRONMENTS
AB In Mixed Reality (MR), users' heads are largely (if not completely) occluded by the MR Head-Mounted Display (HMD) they are wearing. As a consequence, one cannot see their facial expressions and other communication cues when interacting locally. In this paper, we investigate how displaying virtual avatars' heads on-top of the (HMD-occluded) heads of participants in a Video See-Through (VST) Mixed Reality local collaborative task could improve their collaboration as well as social presence. We hypothesized that virtual heads would convey more communicative cues (such as eye direction or facial expressions) hidden by the MR HMDs and lead to better collaboration and social presence. To do so, we conducted a between-subject study ($\mathrm{n}=88$) with two independent variables: the type of avatar (CartoonAvatar/RealisticAvatar/NoAvatar) and the level of facial expressions provided (HighExpr/LowExpr). The experiment involved two dyadic communication tasks: (i) the "20-question" game where one participant asks questions to guess a hidden word known by the other participant and (ii) a urban planning problem where participants have to solve a puzzle by collaborating. Each pair of participants performed both tasks using a specific type of avatar and facial animation. Our results indicate that while adding an avatar's head does not necessarily improve social presence, the amount of facial expressions provided through the social interaction does have an impact. Moreover, participants rated their performance higher when observing a realistic avatar but rated the cartoon avatars as less uncanny. Taken together, our results contribute to a better understanding of the role of partial avatars in local MR collaboration and pave the way for further research exploring collaboration in different scenarios, with different avatar types or MR setups.
C1 [Combe, Theo; Fribourg, Rebecca; Norm, Jean-Marie] Nantes Univ, Ecole Cent Nantes, LS2N PACCE, UMR 6004, Nantes, France.
   [Detto, Lucas] Nantes Univ, ENSA Nantes, Ecole Cent Nantes, CNRS,AAU CRENAU,UMR 1563, Nantes, France.
C3 Nantes Universite; Ecole Centrale de Nantes; Nantes Universite; Ecole
   Centrale de Nantes; Centre National de la Recherche Scientifique (CNRS);
   CNRS - Institute for Humanities & Social Sciences (INSHS)
RP Combe, T (corresponding author), Nantes Univ, Ecole Cent Nantes, LS2N PACCE, UMR 6004, Nantes, France.
EM theo.combe@ec-nantes.fr; rebecca.fribourg@ec-nantes.fr;
   lucas.detto@eleves.ec-nantes.fr; jean-marie.normand@ec-nantes.fr
OI Combe, Theo/0000-0003-1209-5580
CR Aburumman N, 2022, INT J HUM-COMPUT ST, V164, DOI 10.1016/j.ijhcs.2022.102819
   Anjyo K., 2018, Handbook of Human Motion, P2145, DOI [10.1007/978-3-319-14418-425, DOI 10.1007/978-3-319-14418-425]
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Bente G., 2007, PRES 2007 P 10 ANN I
   Bente G, 2008, HUM COMMUN RES, V34, P287, DOI 10.1111/j.1468-2958.2008.00322.x
   Billinghurst M, 2003, INT J HUM-COMPUT INT, V16, P395, DOI 10.1207/S15327590IJHC1603_2
   Biocca E., 2002, P 5 ANN INT WORKSH P, P2
   Biocca F., 2001, 4 ANN INT WORKSH PRE, P1
   Cho S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P26, DOI [10.1109/VR46266.2020.1581170537418, 10.1109/VR46266.2020.00-84]
   Choudhary Z, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P425, DOI [10.1109/VR46266.2020.00-41, 10.1109/VR46266.2020.1581089101511]
   Dubosc C, 2021, COMPUT GRAPH-UK, V101, P82, DOI 10.1016/j.cag.2021.08.011
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Harms C., 2004, P 7 ANN INT WORKSH P, P246
   HART S G, 1988, P139
   Heidicker P, 2017, IEEE SYMP 3D USER, P233, DOI 10.1109/3DUI.2017.7893357
   Hepperle D, 2022, VISUAL COMPUT, V38, P1227, DOI 10.1007/s00371-021-02151-0
   Herrera F, 2018, PRESENCE-VIRTUAL AUG, V27, P163, DOI 10.1162/PRES_a_00324
   Higgins D, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.668499
   Ho CC, 2017, INT J SOC ROBOT, V9, P129, DOI 10.1007/s12369-016-0380-9
   Joiner R., 2002, P C COMP SUPP COLL L, P371
   Jongerius C, 2020, J NONVERBAL BEHAV, V44, P363, DOI 10.1007/s10919-020-00333-3
   Kaliisa R, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100073
   KENDON A, 1969, BRIT J PSYCHOL, V60, P481, DOI 10.1111/j.2044-8295.1969.tb01222.x
   Kreijns K, 2003, COMPUT HUM BEHAV, V19, P335, DOI 10.1016/S0747-5632(02)00057-2
   Kruzic CO, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76672-4
   Kullmann Peter, 2023, 2023 CHI C HUM FACT, DOI DOI 10.1145/3544549.3585617
   Lankes Michael, 2018, P 13 INT C FDN DIGIT, DOI [10.1145/3235765.3235766, DOI 10.1145/3235765.3235766]
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Mai C, 2017, 16TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2017), P515, DOI 10.1145/3152832.3157813
   Manor BR, 2003, J NEUROSCI METH, V128, P85, DOI 10.1016/S0165-0270(03)00151-1
   Matsuda N, 2021, SIGGRAPH '21: ACM SIGGRAPH 2021 EMERGING TECHNOLOGIES, DOI 10.1145/3450550.3465338
   McDonnell R., 2012, Motion in Games, P8
   Meier A, 2007, INT J COMP-SUPP COLL, V2, P63, DOI 10.1007/s11412-006-9005-x
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Morin DG, 2023, VIRTUAL REAL-LONDON, V27, P2129, DOI 10.1007/s10055-023-00785-0
   Mottelson A, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3590767
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   O'Brien HL, 2018, INT J HUM-COMPUT ST, V112, P28, DOI 10.1016/j.ijhcs.2018.01.004
   OBrien H., 2016, Why Engagement Matters, P27, DOI DOI 10.1007/978-3-319-27446-126
   Oyama E, 2021, ADV ROBOTICS, V35, P1223, DOI 10.1080/01691864.2021.1976670
   Pan Y, 2023, IEEE T VIS COMPUT GR, V29, P2527, DOI 10.1109/TVCG.2023.3247101
   Park S, 2019, ROUTL ADV KOREAN STU, P3
   Piumsomboon T, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173620
   Piumsomboon T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3186495
   Prytz E., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P119, DOI 10.1109/ISMAR.2010.5643559
   Rebol M, 2022, INT SYM MIX AUGMENT, P346, DOI 10.1109/ISMAR55827.2022.00050
   Rogers SL, 2022, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.750729
   Seymour M, 2021, J ASSOC INF SYST, V22, P591, DOI 10.17705/1jais.00674
   Shin M, 2019, COMPUT HUM BEHAV, V94, P100, DOI 10.1016/j.chb.2019.01.016
   Stefanova M. P., 2020, PhD thesis, P3
   Sterna R, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.705448
   Swinth K., 2002, P 5 ANN INT WORKSH P, V392, P3
   Tanenbaum TJ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376606
   Torre I, 2019, PROCEEDINGS OF THE 12TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2019, DOI 10.1145/3359566.3360065
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Visconti A, 2023, COMPUT ANIMAT VIRT W, V34, DOI 10.1002/cav.2188
   Waldow K, 2019, LECT NOTES COMPUT SC, V11883, P246, DOI 10.1007/978-3-030-31908-3_15
   Wang P, 2023, VIRTUAL REAL-LONDON, V27, P1409, DOI 10.1007/s10055-023-00748-5
   Wiltshire TravisJ., 2013, P HUMAN FACTORS ERGO, V57, P1273, DOI [DOI 10.1177/1541931213571282, DOI 10.1177/15419312135712826]
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yu K, 2022, IEEE T VIS COMPUT GR, V28, P2190, DOI 10.1109/TVCG.2022.3150520
   Zhao YJ, 2018, Arxiv, DOI arXiv:1807.08772
   Zhao YJ, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P267, DOI [10.1109/vr.2019.8797925, 10.1109/VR.2019.8797925]
   Zibrek K, 2019, ACM T APPL PERCEPT, V16, DOI 10.1145/3349609
   Zibrek K, 2018, IEEE T VIS COMPUT GR, V24, P1681, DOI 10.1109/TVCG.2018.2794638
NR 68
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2206
EP 2216
DI 10.1109/TVCG.2024.3372051
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400060
PM 38437082
DA 2024-11-06
ER

PT J
AU Yasui, M
   Iwataki, R
   Ishikawa, M
   Watanabe, Y
AF Yasui, Masahiko
   Iwataki, Ryota
   Ishikawa, Masatoshi
   Watanabe, Yoshihiro
TI Projection Mapping with a Brightly Lit Surrounding Using a Mixed Light
   Field Approach
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Lighting; Light fields; Lenses; Electronic mail; Visualization;
   Photography; Optical imaging; Projection mapping; Ambient lighting;
   Light field; Integral photography
AB Projection mapping (PM) exhibits suboptimal performance in well-lit environments because of the interference caused by ambient light. This interference degrades the contrast of the projected images. Consequently, conventional methodologies restrict the application of PM to dimly lit settings, leading to an unnatural visual experience, as only the PM target is prominently illuminated. To overcome these limitations, we introduce an innovative approach that leverages a mixed light field, blending traditional PM with ray-controllable ambient lighting. This methodological combination, despite its simplicity, is effective because it ensures that the projector exclusively illuminates the PM target, preserving the optimal contrast. Precise control of ambient light rays is essential to prevent them from illuminating the PM target while adequately illuminating the surrounding environment. Furthermore, we propose the integration of a kaleidoscopic array with integral photography to generate dense light fields for ray-controllable ambient lighting. Additionally, we present an efficient binary-search-based calibration method tailored to this intricate optical system. Our optical simulations and the developed system collectively validate the effectiveness of our approach. Our results show that PM targets and ordinary objects coexist naturally in environments that are brightly lit as a result of our method, enhancing the overall visual experience.
C1 [Yasui, Masahiko; Iwataki, Ryota; Ishikawa, Masatoshi; Watanabe, Yoshihiro] Tokyo Inst Technol, Tokyo, Japan.
   [Yasui, Masahiko] Konica Minolta, Chiyoda City, Tokyo, Japan.
C3 Institute of Science Tokyo; Tokyo Institute of Technology; Konica
   Minolta Inc.
RP Yasui, M (corresponding author), Tokyo Inst Technol, Tokyo, Japan.; Yasui, M (corresponding author), Konica Minolta, Chiyoda City, Tokyo, Japan.
EM yasuimasahiko@gmail.com; iwataki.r.aa@m.titech.ac.jp;
   ishikawa@ishikawa-vision.org; watanabe.y.cl@m.titech.ac.jp
OI Ishikawa, Masatoshi/0000-0002-6096-830X
FU JSPS KAKENHI
FX No Statement Available
CR Akiyama R, 2021, IEEE T VIS COMPUT GR, V27, P2041, DOI 10.1109/TVCG.2019.2940453
   Amano T., 2022, 2022 EUROXR C, P81
   [Anonymous], INORI (Prayer)
   [Anonymous], Light Barrier, VThird
   Bermano AH, 2017, COMPUT GRAPH FORUM, V36, P311, DOI 10.1111/cgf.13128
   Bimber O., 2005, SPATIAL AUGMENTED RE, DOI [DOI 10.1201/B10624, 10.1201/B10624]
   Bokaris PA, 2019, SA'19: SIGGRAPH ASIA 2019 XR, P21, DOI 10.1145/3355355.3361885
   Chen B, 2019, OPT EXPRESS, V27, P21999, DOI 10.1364/OE.27.021999
   Debevec P, 2002, ACM T GRAPHIC, V21, P547
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Fujigaki S, 2019, IEEE IMAGE PROC, P3532, DOI [10.1109/icip.2019.8803430, 10.1109/ICIP.2019.8803430]
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Han JY, 2003, ACM T GRAPHIC, V22, P741, DOI 10.1145/882262.882341
   Hashiomoto N., 2018, ACM SIGGRAPH 2018 PO, P1
   Hiratani K, 2023, IEEE T VIS COMPUT GR, V29, P2280, DOI 10.1109/TVCG.2023.3247104
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1419, DOI 10.1145/3025453.3025860
   Hong-Nien Chen, 2019, 2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media). Proceedings, P102, DOI 10.1109/Ubi-Media.2019.00028
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Iwai D., 2021, arXiv
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Koshino S., 2021, SIGGRAPH Asia 2021 Real-Time Live!
   Kurth P, 2022, IEEE T VIS COMPUT GR, V28, P3607, DOI 10.1109/TVCG.2022.3203085
   LeGendre C, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925934
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Mohan A, 2007, IEEE T VIS COMPUT GR, V13, P652, DOI 10.1109/TVCG.2007.1008
   Morimoto T, 2021, J VISION, V21, DOI 10.1167/jov.21.13.3
   Murmann L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980219
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nishino H, 2018, ANN SURG, V267, P1134, DOI 10.1097/SLA.0000000000002172
   Nomoto T., 2020, SIGGRAPH Asia 2020 Emerging Technologies, P1
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Okano F, 1997, APPL OPTICS, V36, P1598, DOI 10.1364/AO.36.001598
   Park MK, 2015, J COMPUT DES ENG, V2, P38, DOI 10.1016/j.jcde.2014.11.004
   Peers P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1477926.1477929
   Radonjic A, 2011, CURR BIOL, V21, P1931, DOI 10.1016/j.cub.2011.10.013
   Ren PR, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766899
   Sakai H., 2009, SID symposium digest of technical papers, V40, P611, DOI [10.1889/1.3256853, DOI 10.1889/1.3256853.(2009]
   Schmid M, 2021, OPT LETT, V46, P2485, DOI 10.1364/OL.423196
   Sen P, 2005, ACM T GRAPHIC, V24, P745, DOI 10.1145/1073204.1073257
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Srikanth Manohar., 2014, Proceedings of the Workshop on Computational Aesthetics, P57
   Takeuchi M, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P653, DOI 10.1109/VRW58643.2023.00169
   Takeuchi Y, 2022, IEEE ACCESS, V10, P939, DOI 10.1109/ACCESS.2021.3139108
   Takeuchi Y, 2016, PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES, (ISS 2016), P39, DOI 10.1145/2992154.2992188
   Thakur S, 2022, LECT NOTES COMPUT SC, V13303, P180, DOI 10.1007/978-3-031-05409-9_14
   Tsurumi N., 2023, International Federation of Societies of Cosmetic Chemists
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Wang JP, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531335
   Wetzstein G, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P391, DOI 10.1109/PG.2007.47
   Yamamoto K, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545690
   Yamasaki M., 2009, Stereoscopic Displays and Applications XX, V7237, P3
   Yano H, 2018, SIGGRAPH'18: ACM SIGGRAPH 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3214907.3214917
   Yasui M, 2021, OPT EXPRESS, V29, P12066, DOI 10.1364/OE.418729
   Zhou Z, 2015, P IEEE VIRT REAL ANN, P135, DOI 10.1109/VR.2015.7223335
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2217
EP 2227
DI 10.1109/TVCG.2024.3372132
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400070
PM 38446649
OA hybrid
DA 2024-11-06
ER

PT J
AU Mikawa, Y
   Fukiage, T
AF Mikawa, Yuri
   Fukiage, Taiki
TI Low-Latency Ocular Parallax Rendering and Investigation of Its Effect on
   Depth Perception in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Ocular parallax; eye's front-nodal-point tracking; low-latency feedback
   system; depth perception; binocular fusion
ID EYE-MOVEMENTS; GAZE-CONTINGENT; PUPIL CENTER; MOTION; STEREOPSIS; SHIFT
AB With a demand for an immersive experience in virtual/augmented reality (VR/AR) displays, recent efforts have incorporated eye states, such as focus and fixation, into display graphics. Among these, ocular parallax, a small parallax generated by eye rotation, has received considerable attention for its impact on depth perception. However, the substantial latency of head-mounted displays (HMDs) has made it challenging to accurately assess its true effect during free eye movements. To address this issue, we propose a high-speed (360 Hz) and low-latency (4.8 ms) ocular parallax rendering system with a custom-built eye tracker. Using this proposed system, we conducted an investigation to determine the latency requirements necessary for achieving perceptually stable ocular parallax rendering. Our findings indicate that, in binocular viewing, ocular parallax rendering is perceived as significantly less stable than conventional rendering when the latency exceeds 43.72 ms at 1.3 D and 21.50 ms at 2.0 D. We also evaluated the effects of ocular parallax rendering on binocular fusion and monocular depth perception under free viewing conditions. The results demonstrated that ocular parallax rendering can enhance binocular fusion but has a limited impact on depth perception under monocular viewing conditions when latency is minimized.
C1 [Mikawa, Yuri; Fukiage, Taiki] NTT Commun Labs, Tokyo, Japan.
RP Mikawa, Y (corresponding author), NTT Commun Labs, Tokyo, Japan.
EM yuri.mikawa@gmail.com; taiki.fukiage@ntt.com
FU JST, ACT-X
FX No Statement Available
CR Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Atchison DA, 2017, HANDBOOK OF VISUAL OPTICS: FUNDAMENTALS AND EYE OPTICS, VOL I, P235
   Atchison DA, 2014, INVEST OPHTH VIS SCI, V55, P5862, DOI 10.1167/iovs.14-14212
   Bernhard M., 2014, Proceedings of the Symposium on Eye Tracking Research and Applications, P111
   BINGHAM GP, 1993, VISION RES, V33, P777, DOI 10.1016/0042-6989(93)90197-5
   Chwesiuk R., 2016, InEurographics (Posters), P13
   Dierkes K, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319819
   Dierkes K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204525
   Duchowski D. H., 2014, P ACM S APPL PERC, P39, DOI DOI 10.1145/2628257.2628259
   Ebner C, 2022, IEEE T VIS COMPUT GR, V28, P2256, DOI 10.1109/TVCG.2022.3150504
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Frey J, 2011, J NEUROSCI, V31, P17069, DOI 10.1523/JNEUROSCI.2192-11.2011
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Gharat A, 2012, J NEUROPHYSIOL, V108, P1228, DOI 10.1152/jn.00840.2011
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Guestrin E. D., 2010, PhD thesis, P2
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   HALPERN DL, 1991, VISION RES, V31, P1611, DOI 10.1016/0042-6989(91)90137-T
   Hsiao L, 2022, ACM SIGCOMM COMP COM, V52, P11, DOI 10.1145/3523230.3523233
   Ishii I, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1916, DOI 10.1109/ROBOT.1999.770388
   Itoh Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453157
   Jang C, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275069
   Jerald J, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P211, DOI 10.1109/VR.2009.4811025
   Jones JA, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P221, DOI 10.1109/3DUI.2016.7460055
   Kane D, 2014, J NEUROSCI, V34, P1397, DOI 10.1523/JNEUROSCI.1652-13.2014
   Kellnhofer P, 2014, PROC SPIE, V9011, DOI 10.1117/12.2032389
   Kim D, 2012, IEEE T CIRC SYST VID, V22, P811, DOI 10.1109/TCSVT.2012.2186738
   Konrad R, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3361330
   Krajancich B, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417820
   Kudo H., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P34, DOI 10.1109/ICSMC.1999.825203
   Kudo H, 1998, P ANN INT IEEE EMBS, V20, P3180, DOI 10.1109/IEMBS.1998.746169
   Kudo H, 2000, P ANN INT IEEE EMBS, V22, P548, DOI 10.1109/IEMBS.2000.900798
   Lai CC, 2015, IEEE T CIRC SYST VID, V25, P24, DOI 10.1109/TCSVT.2014.2329362
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Le Chenechal M., 2018, ICAT EGVE 2018
   LIT A, 1949, AM J PSYCHOL, V62, P159, DOI 10.2307/1418457
   Lu C, 2020, INT SYM MIX AUGMENT, P320, DOI 10.1109/ISMAR50242.2020.00058
   Maiello G, 2014, J VISION, V14, DOI 10.1167/14.8.13
   Maimone A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073624
   Mekni M., 2014, Appl. Comput. Sci., V20, P205
   Mikawa Y, 2022, IEEE T VIS COMPUT GR, V28, P4016, DOI 10.1109/TVCG.2021.3111085
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Mizushina H, 2023, IEEE T IND APPL, V59, P7813, DOI 10.1109/TIA.2023.3302275
   Nawrot M, 2003, VISION RES, V43, P1553, DOI 10.1016/S0042-6989(03)00144-5
   Ng A, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P453
   Oberhauser M, 2017, COGN TECHNOL WORK, V19, P263, DOI 10.1007/s10111-017-0421-7
   Padmanaban N, 2017, P NATL ACAD SCI USA, V114, P2183, DOI 10.1073/pnas.1617251114
   PRESTRUDE AM, 1971, VISION RES, V11, P351, DOI 10.1016/0042-6989(71)90246-X
   Pupil Labs GmbH, 2021, Pupil Labs VR/AR, P2
   Reingold EM, 2003, HUM FACTORS, V45, P307, DOI 10.1518/hfes.45.2.307.27235
   ROGERS BJ, 1974, VISION RES, V14, P181, DOI 10.1016/0042-6989(74)90099-6
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Shuhaiber JH, 2004, ARCH SURG-CHICAGO, V139, P170, DOI 10.1001/archsurg.139.2.170
   Stein N, 2021, I-PERCEPTION, V12, DOI 10.1177/2041669520983338
   Swirski N., 2013, P PETMEI, P1
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Wedel M., 2017, Rev. Mark. Res., P123
   Wexler M, 2001, NATURE, V409, P85, DOI 10.1038/35051081
   Zannoli M, 2016, J VISION, V16, DOI 10.1167/16.6.17
   Zhao ZT, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-35834-4
NR 61
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2228
EP 2238
DI 10.1109/TVCG.2024.3372078
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400026
PM 38442067
DA 2024-11-06
ER

PT J
AU Nair, V
   Guo, WB
   Wang, R
   O'Brien, JF
   Rosenberg, L
   Song, D
AF Nair, Vivek
   Guo, Wenbo
   Wang, Rui
   O'Brien, James F.
   Rosenberg, Louis
   Song, Dawn
TI Berkeley Open Extended Reality Recordings 2023 (BOXRR-23): 4.7 Million
   Motion Capture Recordings from 105,000 XR Users
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Recording; Motion capture; X reality; Brushes; Tracking; Games;
   Internet; Dataset; virtual reality; extended reality; motion capture;
   big data
AB Extended reality (XR) devices such as the Meta Quest and Apple Vision Pro have seen a recent surge in attention, with motion tracking "telemetry" data lying at the core of nearly all XR and metaverse experiences. Researchers are just beginning to understand the implications of this data for security, privacy, usability, and more, but currently lack large-scale human motion datasets to study. The BOXRR-23 dataset contains 4,717,215 motion capture recordings, voluntarily submitted by 105,852 XR device users from over 50 countries. BOXRR-23 is over 200 times larger than the largest existing motion capture research dataset and uses a new, highly efficient and purpose-built XR Open Recording (XROR) file format.
C1 [Nair, Vivek; O'Brien, James F.; Song, Dawn] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Guo, Wenbo] Purdue Univ, W Lafayette, IN USA.
   [Wang, Rui] Carnegie Mellon, Pittsburgh, PA USA.
   [Rosenberg, Louis] Unanimous, Pismo Beach, CA USA.
C3 University of California System; University of California Berkeley;
   Purdue University System; Purdue University; Carnegie Mellon University
RP Nair, V (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM vcn@berkeley.edu; henrygwb@purdue.edu; ruiwang3@andrew.cmu.edu;
   job@berkeley.edu; louis@unanimous.ai; dawnsong@berkeley.edu
OI O'Brien, James/0000-0001-9513-0542; Rosenberg, Louis/0000-0003-3457-1429
FU Minderoo foundation
FX No Statement Available
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Dent S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258000
   Douglas A., 2012, Applied Computing, V1
   Du YM, 2023, PROC CVPR IEEE, P481, DOI 10.1109/CVPR52729.2023.00054
   Durbin J., 2017, Report: Vive Users Are 95 Percent Male And Spend 5 Hours Per Week in VR, P6
   Fan L., 2022, 36 C NEUR INF PROC S
   FROMM C, 1977, NEUROSCI LETT, V5, P259, DOI 10.1016/0304-3940(77)90076-3
   Gebru T, 2021, Arxiv, DOI arXiv:1803.09010
   Ghorbani S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253157
   Holland S, 2018, Thedataset nutrition label: A framework to drive higher data quality standards, V1, P7
   Hoyet L., 2012, P ACM SIGGRAPH S INT, P79
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang P., 2022, Avatarposer: Articulated full-body pose tracking from sparse motionsensing, V4
   Ke Q., LightGBM: A Highly Efficient Gradient Boosting Decision Tree
   Kingma D.P., 2014, P INT C LEARNING REP
   Koch E., 2021, Reduced, reused andrecycled: The life of a dataset in machine learning research, V6
   Liebers M., 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764.34455282, DOI 10.1145/3411764.34455282]
   Loper M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661273
   Lundberg SM, 2017, ADV NEUR IN, V30
   Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554
   Mandery C, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P329, DOI 10.1109/ICAR.2015.7251476
   Miller E. Han, 2023, A large-scale study of personal identifiability of virtual reality motion overtime, V2, P5
   Miller F., 2020, Scientific Reports, V10, P10, DOI [10.1038/s41598-020-74486-y2,3,6[28]M.R., DOI 10.1038/S41598-020-74486-Y2,3,6[28]M.R]
   Miller R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P311, DOI [10.1109/VRW50115.2020.00070, 10.1109/VRW50115.2020.0-206]
   Moore AG, 2021, INT SYM MIX AUGMENT, P221, DOI 10.1109/ISMAR52148.2021.00037
   Muller T., 2007, Documentation mocap database hdm05, V2
   Nair C., 2023, Inferring private personal attributes of virtualreality users from head and hand motion data, V4
   Nair G. M., 2023, Going incognito in the metaverse, V4
   Nair V., 2023, Results of the 2023 census ofbeat saber users: Virtual reality gaming population insights and factorsaffecting virtual reality e-sports performance, V5
   Nair V, 2023, PROCEEDINGS OF THE 32ND USENIX SECURITY SYMPOSIUM, P895
   Nair W., 2023, Unique identification of 50,000+ virtual reality users from head& hand motion data
   Nair W., 2023, Deep motionmasking for secure, usable, and scalable real-time anonymization of virtualreality motion data, V4
   Pagano P., 2022, Bias andunfairness in machine learning models: a systematic literature review,, V6
   Pfeuffer K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300340
   Ponton JL, 2022, COMPUT GRAPH FORUM, V41, P107, DOI 10.1111/cgf.14628
   Rahman D., 2021, 35 C NEUR INF PROC S
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Torre J. K., 2008, database, V2
   Tricomi P. P., 2022, You can't hide behind your headset: User profiling in augmented and virtual reality, P2
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Trumble M., 2017, 2017 BRIT MACH VIS C, P2
   Vitaladevuni S. N. P., 2007, PhD thesis
   Wobbeking J., 2022, Beat Saber generated more revenue in 2021 than the next five biggest apps combined, P1
NR 44
TC 0
Z9 0
U1 6
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2239
EP 2246
DI 10.1109/TVCG.2024.3372087
PG 8
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400074
PM 38437078
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Krasner, A
   Gabbard, J
AF Krasner, Alexander
   Gabbard, Joseph
TI MusiKeys: Exploring Haptic-to-Auditory Sensory Substitution to Improve
   Mid-Air Text-Entry
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Extended reality; Spatial computing; Mid-air
   text-entry; Sensory substitution; Human-computer interaction (HCI)
AB Physical QWERTY keyboards are the current standard for performing precision text-entry with extended reality devices. Ideally, there would exist a comparable, self-contained solution that works anywhere, without requiring external keyboards. Unfortunately, when physical keyboards are recreated virtually, we currently lose critical haptic feedback information from the sense of touch, which impedes typing. In this paper, we introduce the MusiKeys Technique, which uses auditory feedback in virtual reality to communicate missing haptic feedback information typists normally receive when using a physical keyboard. To examine this concept, we conducted a user study with 24 participants which encompassed four mid-air virtual keyboards augmented with increasing amounts of feedback information, along with a fifth physical keyboard for reference. Results suggest that providing clicking feedback on key-press and key-release improves typing performance compared to not providing auditory feedback, which is consistent with the literature. We also found that audio can serve as a substitute for information contained in haptic feedback, in that users can accurately perceive the presented information. However, under our specific study conditions, this awareness of the feedback information did not yield significant differences in typing performance. Our results suggest this kind of feedback replacement can be perceived by users but needs more research to tune and improve the specific techniques.
C1 [Krasner, Alexander; Gabbard, Joseph] Virginia Tech, Blacksburg, VA 24061 USA.
C3 Virginia Polytechnic Institute & State University
RP Krasner, A (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.
EM akrasner@vt.edu; jgabbard@vt.edu
OI Krasner, Alexander/0000-0002-1017-0332
CR Batmaz AU, 2022, PROCEEDINGS OF THE 2022 ACM SYMPOSIUM ON SPATIAL USER INTERACTION, SUI 2022, DOI 10.1145/3565970.3567702
   Batmaz AU, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P189, DOI 10.1109/VRW52623.2021.00042
   Belardinelli MO, 2009, LECT NOTES COMPUT SC, V5615, P557, DOI 10.1007/978-3-642-02710-9_62
   Bermejo C., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, P26, DOI [10.1145/34571413, DOI 10.1145/34571413]
   Bowman D. A., 2002, Proceedings of the Human Factors and Ergonomics Society 46th Annual Meeting, P2154
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Chuah S. H.-W., 2018, SSRN Electronic Journal, V12, DOI [10.2139/SSRN.33004691, DOI 10.2139/SSRN.33004691]
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Fashimpaur J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382888
   Gil H., 2020, P ACM S VIRT REAL SO, V11, DOI [10.1145/3385956.34189631,2, DOI 10.1145/3385956.34189631,2]
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   HART S G, 1988, P139
   Kim JR, 2014, IEEE HAPTICS SYM, P227, DOI 10.1109/HAPTICS.2014.6775459
   Lee LH, 2019, INT CONF PERVAS COMP, DOI 10.1109/percom.2019.8767420
   Loomis J. M., 2002, Converging technologies for improving human performance, V213
   Pujari V., 2019, Journal of Advanced Medical and Dental Sciences Research
   Sand Antti., 2015, Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology, P51, DOI [DOI 10.1145/2821592.2821593, 10.1145/2821592.28215932[19]J, DOI 10.1145/2821592.28215932[19]J]
   Shen JX, 2022, INT SYM MIX AUGMENT, P702, DOI 10.1109/ISMAR55827.2022.00088
   Shull PB, 2015, J NEUROENG REHABIL, V12, DOI 10.1186/s12984-015-0055-z
   Simeone A, 2023, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-3-031-05804-2_1
   Singhal R. H., 2022, C HUMAN FACTORS COMP, V4, DOI [10.1145/3491102.35021001,2[23]R.W., DOI 10.1145/3491102.35021001,2[23]R.W]
   Soukoreff R.W., 2001, CHI '01 extended abstracts on Human factors in computing systems, CHI EA '01, P319, DOI [10.1145/634067.634256, DOI 10.1145/634067.634256]
   Soukoreff R. W., 2003, P SIGCHI C HUM FACT, P113, DOI DOI 10.1145/642611.642632
   Thome C.-T., 2006, BME, V200, P300
   Wang Cheng-Yao, 2015, P 17 INT C HUM COMP, P153, DOI [DOI 10.1145/2785830.2785886, DOI 10.1145/2785830.27858862]
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Xu WG, 2019, INT SYM MIX AUGMENT, P279, DOI 10.1109/ISMAR.2019.00026
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yildirim C., 2022, International Journal of HumanComputer Interaction, V2, P8, DOI [10.1080/10447318.2022.21073302,8, DOI 10.1080/10447318.2022.21073302,8]
   Zhang R., 2005, P 21 SPRING C COMP G, DOI [10.1145/10901222,8</p>\n, DOI 10.1145/10901222,8</P>]
NR 31
TC 1
Z9 1
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2247
EP 2256
DI 10.1109/TVCG.2024.3372065
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400015
PM 38437075
DA 2024-11-06
ER

PT J
AU Wilson, E
   Ibragimov, A
   Proulx, MJ
   Tetali, SD
   Butler, K
   Jain, E
AF Wilson, Ethan
   Ibragimov, Azim
   Proulx, Michael J.
   Tetali, Sai Deep
   Butler, Kevin
   Jain, Eakta
TI Privacy-Preserving Gaze Data Streaming in Immersive Interactive Virtual
   Reality: Robustness and User Experience
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; privacy; eye tracking
ID EYE-TRACKING; VR; PREDICTION; MOVEMENTS
AB Eye tracking is routinely being incorporated into virtual reality (VR) systems. Prior research has shown that eye tracking data, if exposed, can be used for re-identification attacks [14]. The state of our knowledge about currently existing privacy mechanisms is limited to privacy-utility trade-off curves based on data-centric metrics of utility, such as prediction error, and black-box threat models. We propose that for interactive VR applications, it is essential to consider user-centric notions of utility and a variety of threat models. We develop a methodology to evaluate real-time privacy mechanisms for interactive VR applications that incorporate subjective user experience and task performance metrics. We evaluate selected privacy mechanisms using this methodology and find that re-identification accuracy can be decreased to as low as 14% while maintaining a high usability score and reasonable task performance. Finally, we elucidate three threat scenarios (black-box, black-box with exemplars, and white-box) and assess how well the different privacy mechanisms hold up to these adversarial scenarios. This work advances the state of the art in VR privacy by providing a methodology for end-to-end assessment of the risk of re-identification attacks and potential mitigating solutions. f
C1 [Wilson, Ethan; Ibragimov, Azim; Butler, Kevin; Jain, Eakta] Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
   [Proulx, Michael J.] Meta Real Labs Res, Redmond, WA USA.
   [Tetali, Sai Deep] Meta Real Labs, Burlingame, CA USA.
C3 State University System of Florida; University of Florida
RP Wilson, E (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
EM ethanwilson@ufl.edu; a.ibragimov@ufl.edu; michaelproulx@meta.com;
   saideept@meta.com; butler@ufl.edu; ejain@ufl.edu
RI Wilson, Ethan/JMB-1659-2023
OI Wilson, Ethan/0000-0003-0944-2641
FU NSF
FX No Statement Available
CR Abrash M., AR and VR. Latency - the sine qua non of
   [Anonymous], Apple vision pro
   [Anonymous], Meta quest pro
   Atienza R, 2016, IEEE REGION 10 SYMP, P110, DOI 10.1109/TENCONSpring.2016.7519387
   Berkovsky S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300451
   Bozkir E, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255979
   business.vive, Vive Focus 3 Eye Tracker
   David-John B., 2021, ACM S EYE TRACK RES, P1, DOI [10.1145/3448018.34580081,2,3, DOI 10.1145/3448018.34580081,2,3]
   David-John B, 2023, IEEE T VIS COMPUT GR, V29, P2774, DOI 10.1109/TVCG.2023.3247048
   David-John B, 2022, 2022 ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, ETRA 2022, DOI 10.1145/3517031.3529618
   David-John B, 2021, IEEE T VIS COMPUT GR, V27, P2555, DOI 10.1109/TVCG.2021.3067787
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Duchowski A. T., 2000, P S EYE TRACK RES AP, P89, DOI DOI 10.1145/355017.355031
   Erdemir E, 2021, IEEE T INF FOREN SEC, V16, P389, DOI 10.1109/TIFS.2020.3013200
   Fernandes AS, 2023, IEEE T VIS COMPUT GR, V29, P2269, DOI 10.1109/TVCG.2023.3247058
   Friedman L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111144
   Garau M., 2003, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI'03, P529, DOI DOI 10.1145/642611.642703
   George A, 2016, PATTERN RECOGN LETT, V82, P207, DOI 10.1016/j.patrec.2015.11.020
   Gowases Teresia., 2008, P INT C ADV LEARN TE, P773
   Griffith H, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00959-y
   Guenter B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366183
   Hu ZM, 2020, IEEE T VIS COMPUT GR, V26, P1902, DOI 10.1109/TVCG.2020.2973473
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Jia SH, 2018, 2018 9TH IEEE INTERNATIONAL CONFERENCE ON BIG KNOWLEDGE (ICBK), P57, DOI 10.1109/ICBK.2018.00016
   John B., 2020, ACM S EYE TRACK RES, P1, DOI [10.1145/3379157.33905122, DOI 10.1145/3379157.33905122]
   John B, 2020, IEEE T VIS COMPUT GR, V26, P1880, DOI 10.1109/TVCG.2020.2973052
   Kaplanyan AS, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356557
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Komogortsev O. V., 2012, Technical Report TXSTATE-CS-TR-2012-6, P6
   LEWIS JR, 1992, PROCEEDINGS OF THE HUMAN FACTORS SOCIETY, 36TH ANNUAL MEETING, VOLS 1 AND 2, P1259, DOI 10.1177/154193129203601617
   Li JJ, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1793
   Lin L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P510, DOI 10.1109/vr.2019.8797787
   Liu A, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319823
   Liu R, 2022, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.792069
   Lohr D. J., 2020, ACM S EYE TRACK RES, P1, DOI DOI 10.1145/3379157.3391420
   Lohr D, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02075-5
   Lohr D, 2022, IEEE T INF FOREN SEC, V17, P3151, DOI 10.1109/TIFS.2022.3201369
   Lohr D, 2022, IEEE T BIOM BEHAV ID, V4, P276, DOI 10.1109/TBIOM.2022.3167633
   Lopes P., 2020, P 13 ACM SIGGRAPH C, P1, DOI [10.1145/3424636.34269069, DOI 10.1145/3424636.34269069]
   Lungaro P, 2018, IEEE T VIS COMPUT GR, V24, P1535, DOI 10.1109/TVCG.2018.2794119
   magicleap, Magic Leap | Devices
   magicleap, Magic Leap 2 Devices
   Makowski Silvia, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P506, DOI 10.1109/TBIOM.2021.3116875
   Marucci M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84196-8
   McCormick M, 2008, ADV INF SEC, V39, P53
   Microsoft, HoloLens 2 hardware-Microsoft Learn
   Miller MR, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74486-y
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P409, DOI 10.1109/VR51125.2022.00060
   Miller R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P563, DOI 10.1109/VR51125.2022.00076
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Negin M, 2000, COMPUTER, V33, P70, DOI 10.1109/2.820042
   Normoyle Aline., 2013, Proceedings of motion on games, P141, DOI [10.1145/2522628.2522630, DOI 10.1145/2522628.2522630]
   Orlov PA, 2015, PERCEPTION, V44, P1136, DOI 10.1177/0301006615594910
   Orquin JL, 2016, J BEHAV DECIS MAKING, V29, P103, DOI 10.1002/bdm.1867
   Papadimitriou S, 2007, ELE COM ENG, P459
   Peng SY, 2022, 2022 ACM SYMPOSIUM ON EYE TRACKING RESEARCH AND APPLICATIONS, ETRA 2022, DOI 10.1145/3517031.3531631
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Reichenberger J, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00035
   Ruhland K., 2015, P ACM SIGGRAPH S APP, P19, DOI [10.1145/2804408.28044241,2, DOI 10.1145/2804408.28044241,2]
   Sammaknejad N, 2017, ADV COGN PSYCHOL, V13, P232, DOI 10.5709/acp-0223-1
   Sanches CL, 2017, PROC INT CONF DOC, P28, DOI 10.1109/ICDAR.2017.377
   Sannon Shruti, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555556
   Schroeder C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376534
   Seele S, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P531, DOI 10.1145/3116595.3116619
   Selinger E., 2023, Privacy Studies Journal, V2, P1, DOI [10.7146/psj.v2i.134656, DOI 10.7146/PSJ.V2I.134656]
   Shadiev R, 2023, COMPUT EDUC, V196, DOI 10.1016/j.compedu.2022.104681
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101153
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Steil J, 2019, ETRA 2019: 2019 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, DOI 10.1145/3314111.3319915
   Sun JL, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.972773
   Tanriverdi V., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P265, DOI 10.1145/332040.332443
   Ugwitz P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031027
   Vargas-Cuentas NI, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188826
   vive, Vive Pro Eye Overview
   Wan GB, 2019, J AUTISM DEV DISORD, V49, P209, DOI 10.1007/s10803-018-3690-y
   Wang CC, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131911058
   Wei S, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE MEDIA EXPERIENCES, IMX 2023, P216, DOI 10.1145/3573381.3596467
   Weier M, 2018, ACM T APPL PERCEPT, V15, DOI 10.1145/3238301
   Weier M, 2016, COMPUT GRAPH FORUM, V35, P289, DOI 10.1111/cgf.13026
   Xiang H., 2022, 2022 8 INT C IMM LEA, P1, DOI [10.23919/iLRN55037.2022.9815935, DOI 10.23919/ILRN55037.2022.9815935]
   Xu YY, 2018, PROC CVPR IEEE, P5333, DOI 10.1109/CVPR.2018.00559
   Zhang AT, 2018, IEEE IMAGE PROC, P2660, DOI 10.1109/ICIP.2018.8451219
   Zito GA, 2015, BMC GERIATR, V15, DOI 10.1186/s12877-015-0175-0
NR 83
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2257
EP 2268
DI 10.1109/TVCG.2024.3372032
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400016
PM 38457326
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Mishra, S
   Corro-Flores, M
   Krum, D
   Forouzesh, N
AF Mishra, Shivam
   Corro-Flores, Missael
   Krum, David
   Forouzesh, Negin
TI Molecular Docking Improved with Human Spatial Perception Using Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Proteins; Three-dimensional displays; Visualization; Drugs; Force;
   Trajectory; Virtual reality; Molecular Dynamics Simulation; Molecular
   Docking; Virtual Reality
ID HIV-1 PROTEASE
AB Adaptive steered molecular dynamics (ASMD) is a computational biophysics method in which an external force is applied to a selected set of atoms or a specific reaction coordinate to induce a particular molecular motion. Virtual reality (VR) based methods for protein-ligand docking are beneficial for visualizing on-the-fly interactive molecular dynamics and performing promising docking trajectories. In this paper, we propose a novel method to guide ASMD with optimal trajectories collected from human experiences using interactive molecular dynamics in virtual reality (iMD-VR). We also explain the benefits of using VR as a tool for expediting the process of ligand binding, outlining an experimental protocol that enables iMD-VR users to guide Amprenavir into and out of the binding pockets of HIV-1 protease and recreate their respective crystallographic binding poses within 5 minutes. Later, we discuss our analysis of the results from iMD-VR-assisted ASMD simulation and assess its performance compared to a standard ASMD simulation. From the accuracy point of view, our proposed method calculates higher Potential Mean Force (PMF) values consistently relative to a standard ASMD simulation with an almost twofold increase in all the experiments. Finally, we describe the novelty of the research and discuss results showcasing a faster and more effective convergence of the ligand to the protein's binding site as compared to a standard molecular dynamics simulation, proving the effectiveness of VR in the field of drug discovery. Future work includes the development of an artificial intelligence algorithm capable of predicting optimal binding trajectories for many protein-ligand pairs, as well as the required force needed to steer the ligand to follow the said trajectory.
C1 [Mishra, Shivam; Krum, David; Forouzesh, Negin] Calif State Univ Los Angeles, Dept Comp Sci, Los Angeles, CA 90032 USA.
   [Corro-Flores, Missael] Calif State Univ Los Angeles, Dept Phys & Astron, Los Angeles, CA USA.
C3 California State University System; California State University Los
   Angeles; California State University System; California State University
   Los Angeles
RP Mishra, S (corresponding author), Calif State Univ Los Angeles, Dept Comp Sci, Los Angeles, CA 90032 USA.
EM smishra7@calstatela.edu; mcorrof@calstatela.edu; dkrum@calstatela.edu;
   neginf@calstatela.edu
RI Forouzesh, Negin/ABB-2612-2020
OI Forouzesh, Negin/0000-0003-2293-0391; Corro-Flores,
   Missael/0009-0008-3079-1460
FU NSF
FX No Statement Available
CR Bharatam PV, 2021, Drug Discovery and Development, P137
   Bird JM, 2020, J SPORT PSYCHOL ACTI, V11, P115, DOI 10.1080/21520704.2018.1563573
   Brik A, 2003, ORG BIOMOL CHEM, V1, P5, DOI 10.1039/b208248a
   Calvelo M, 2020, COMPUT STRUCT BIOTEC, V18, P2621, DOI 10.1016/j.csbj.2020.09.018
   Case D. A., 2016, AMBER
   Case DA, 2023, J CHEM INF MODEL, V63, P6183, DOI 10.1021/acs.jcim.3c01153
   Deeks HM, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228461
   Forouzesh N, 2021, MOLECULES, V26, DOI 10.3390/molecules26082383
   Hilty DM, 2020, Journal of Technology in Behavioral Science, V5, P178, DOI [DOI 10.1007/S41347-020-00126-X, 10.1007/s41347-020-00126-x]
   JamiesonBinnie A. D., 2020, ACM SIGGRAPH 2020 IM, P2, DOI [10.1145/3388536.3407891, DOI 10.1145/3388536.3407891]
   Jarzynski C, 1997, PHYS REV LETT, V78, P2690, DOI 10.1103/PhysRevLett.78.2690
   Jorgensen WL, 2004, SCIENCE, V303, P1813, DOI 10.1126/science.1096361
   KIM EE, 1995, J AM CHEM SOC, V117, P1181, DOI 10.1021/ja00108a056
   Kingsley LJ, 2019, J MOL GRAPH MODEL, V89, P234, DOI 10.1016/j.jmgm.2019.03.010
   Li R., 2019, Ccamlr Science, V26, P2
   Lütjens M, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3010009
   Mahanti M., 2016, Flap dynamics in aspartic proteases: A computational perspective, P2
   Maier JA, 2015, J CHEM THEORY COMPUT, V11, P3696, DOI 10.1021/acs.jctc.5b00255
   Mishra N., 2012, Algorithms and Methods in Structural Bioinformatics, P1
   O'Connor MB, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5092590
   Onufriev A, 2004, PROTEINS, V55, P383, DOI 10.1002/prot.20033
   Ozer G, 2010, J CHEM THEORY COMPUT, V6, P3026, DOI 10.1021/ct100320g
   Poyade M, 2021, ACS CHEM HEALTH SAFE, V28, P55, DOI 10.1021/acs.chas.0c00105
   Salo-Ahen OMH, 2021, PROCESSES, V9, DOI 10.3390/pr9010071
   Shakya D. S., 2019, Journal of Innovative Image Processing, V1, P102
   Simmerling C, 2002, J AM CHEM SOC, V124, P11258, DOI 10.1021/ja0273851
   Walters RK, 2022, EXPERT OPIN DRUG DIS, V17, P685, DOI 10.1080/17460441.2022.2079632
   Wang JM, 2004, J COMPUT CHEM, V25, P1157, DOI 10.1002/jcc.20035
   Zonta N, 2009, ANTIVIR RES, V82, pA74, DOI 10.1016/j.antiviral.2009.02.196
NR 29
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2269
EP 2275
DI 10.1109/TVCG.2024.3372128
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400007
PM 38451773
DA 2024-11-06
ER

PT J
AU Hoshikawa, Y
   Fujita, K
   Takashima, K
   Fjeld, M
   Kitamura, Y
AF Hoshikawa, Yukai
   Fujita, Kazuyuki
   Takashima, Kazuki
   Fjeld, Morten
   Kitamura, Yoshifumi
TI RedirectedDoors plus : Door-Opening Redirection with Dynamic Haptics in
   Room-Scale VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Haptic interfaces; Robots; Legged locomotion; Visualization; Guidelines;
   Virtual environments; Wheels; Redirected Walking; Visuo-haptic
   redirection; Encounter-type haptic device; Virtual reality
ID WALKING; REAL
AB RedirectedDoors is a visuo-haptic door-opening redirection technique in VR, and it has shown promise in its ability to efficiently compress the physical space required for a room-scale VR experience. However, its previous implementation has only supported laboratory experiments with a single door opening at a fixed location. To significantly expand this technique for room-scale VR, we have developed RedirectedDoors+, a robot-based system that permits consecutive door-opening redirection with haptics. Specifically, our system is mainly achieved with the use of three components: (1) door robots, a small number of wheeled robots equipped with a doorknob-like prop, (2) a robot-positioning algorithm that arbitrarily positions the door robots to provide the user with just-in-time haptic feedback during door opening, and (3) a user-steering algorithm that determines the redirection gain for every instance of door opening to keep the user away from the boundary of the play area. Results of simulated VR exploration in six virtual environments reveal our system's performance relative to user walking speed, paths, and number of door robots, from which we derive its usage guidelines. We then conduct a user study ($N=12$) in which participants experience a walkthrough application using the actual system. The results demonstrate that the system is able to provide haptic feedback while redirecting the user within a limited play area.
C1 [Hoshikawa, Yukai; Fujita, Kazuyuki; Takashima, Kazuki; Kitamura, Yoshifumi] Tohoku Univ, Sendai, Miyagi, Japan.
   [Fjeld, Morten] Univ Bergen, Bergen, Norway.
   [Fjeld, Morten] Chalmers Univ Technol, Gothenburg, Sweden.
C3 Tohoku University; University of Bergen; Chalmers University of
   Technology
RP Hoshikawa, Y (corresponding author), Tohoku Univ, Sendai, Miyagi, Japan.
EM yukai.hoshikawa.r4@alumni.tohoku.ac.jp; k-fujita@riec.tohoku.ac.jp;
   takashima@riec.tohoku.ac.jp; Morten.Fjeld@uib.no;
   kitamura@riec.tohoku.ac.jp
OI Fujita, Kazuyuki/0000-0002-1039-0167; /0000-0002-9562-5147
FU JSPS
FX No Statement Available
CR Abdullah M, 2018, IEEE HAPTICS SYM, P334, DOI 10.1109/HAPTICS.2018.8357197
   Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300589
   Achberger Alexander, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P841, DOI 10.1145/3472749.3474790
   [Anonymous], 2016, ISO/TS 15066:2016 Robots and robotic devices-Collaborative robots
   Azmandian M, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P9, DOI 10.1109/WEVR.2016.7859537
   Bouzbib G., 2020, Association for Computing Machinery, P209, DOI [10.1145/3379337.34158911,3[6, DOI 10.1145/3379337.34158911,3[6]
   Brooks FP, 1999, IEEE COMPUT GRAPH, V19, P16, DOI 10.1109/38.799723
   Castelli L, 2008, COMPUT HUM BEHAV, V24, P1643, DOI 10.1016/j.chb.2007.06.005
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Ciumedean C., 2020, InProc. SUI. Associ-ation for Computing Machinery, DOI [10.1145/3385959.34184532[11]R, DOI 10.1145/3385959.34184532[11]R]
   Cools R, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357580
   Gonzalez Eric J., 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P236, DOI 10.1145/3379337.3415870
   He ZY, 2017, UIST'17 ADJUNCT: ADJUNCT PUBLICATION OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P17, DOI 10.1145/3131785.3131795
   Hirt C, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P524, DOI 10.1109/VR51125.2022.00072
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Horie A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P260, DOI 10.1109/VR50410.2021.00048
   Hoshikawa K., 2022, INPROC SIGGRAPH ASIA, DOI [10.1145/3550472.35584051,2[18]Y, DOI 10.1145/3550472.35584051,2[18]Y]
   Hoshikawa Y, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P464, DOI 10.1109/VR51125.2022.00066
   Insko Brent Edward, 2001, Passive Haptics Significantly Enhances Virtual Environments
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kohli L., 2005, Proceedings of the 2005 international conference on Augmented tele-existence, P253
   Kudry Peter, 2022, RACS '22: Proceedings of the Conference on Research in Adaptive and Convergent Systems, P178, DOI 10.1145/3538641.3561507
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Mack A, 2003, CURR DIR PSYCHOL SCI, V12, P180, DOI 10.1111/1467-8721.01256
   Martin NAA, 2013, PROC CIRP, V7, P509, DOI 10.1016/j.procir.2013.06.024
   Matsumoto K, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365705
   Matsumoto K, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132821
   Matsumoto K, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P105, DOI 10.1109/3DUI.2016.7460038
   Matsumoto Y., 2016, InProc. SIGGRAPH Emerging Technologies, DOI [10.1145/2929464.29294822[28]K., DOI 10.1145/2929464.29294822[28]K]
   Mendez S., 2022, INPROC SIGGRAPH ASIA, DOI [10.1145/3550472.35584063, DOI 10.1145/3550472.35584063]
   Mercado VR, 2021, IEEE T HAPTICS, V14, P449, DOI 10.1109/TOH.2021.3061150
   Mortezapoor S, 2023, Symposium Virtual Re, P297, DOI 10.1109/VR55154.2023.00045
   Nagai K, 2015, SIGGRAPH ASIA 2015 HAPTIC MEDIA AND CONTENTS DESIGN (SA'15), DOI 10.1145/2818384.2818403
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Onishi Y, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545615
   Peck TC, 2021, IEEE COMPUT GRAPH, V41, P133, DOI 10.1109/MCG.2021.3113455
   Peck TC, 2020, IEEE T VIS COMPUT GR, V26, P1945, DOI 10.1109/TVCG.2020.2973498
   Peck TC, 2009, IEEE T VIS COMPUT GR, V15, P383, DOI 10.1109/TVCG.2008.191
   Razzaque S., 2001, P 22 ANN C EUR ASS C, P289, DOI DOI 10.2312/EGS.20011036
   Salomoni Paola, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P387, DOI 10.1109/CCNC.2016.7444811
   Schmelter T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451264
   Shaqiri A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25298-8
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.1581330966612, 10.1109/VR46266.2020.00082]
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sra M, 2018, DIS 2018: PROCEEDINGS OF THE 2018 DESIGNING INTERACTIVE SYSTEMS CONFERENCE, P59, DOI 10.1145/3196709.3196792
   Steinicke F., 2008, Proc. Virtual Reality International Conference (VRIC), P15
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Suma E. A., 2011, INIEEE VR WORKSHOPS, P33
   Suzuki R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376523
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Teng SY, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P639, DOI 10.1145/3332165.3347958
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   Wang CH, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P331, DOI [10.1109/vr.2019.8798255, 10.1109/VR.2019.8798255]
   Wang YT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376286
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2023, IEEE INT CONF ROBOT, P12478, DOI 10.1109/ICRA48891.2023.10160996
   Yamaguchi K, 2016, SUI'16: PROCEEDINGS OF THE 2016 SYMPOSIUM ON SPATIAL USER INTERACTION, P43, DOI 10.1145/2983310.2985746
   Yamaguchi S., 2023, INSIGGRAPHASIA 2023, DOI [10.1145/3610541.36145741,3[63]K, DOI 10.1145/3610541.36145741,3[63]K]
   Yan Yixian, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P223, DOI 10.1145/3379337.3415859
   Yu R, 2017, IEEE SYMP 3D USER, P116, DOI 10.1109/3DUI.2017.7893327
   Zank M, 2017, IEEE SYMP 3D USER, P120, DOI 10.1109/3DUI.2017.7893328
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 67
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2276
EP 2286
DI 10.1109/TVCG.2024.3372105
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400071
PM 38466596
OA hybrid
DA 2024-11-06
ER

PT J
AU Lee, G
   Lee, DY
   Su, GM
   Manocha, D
AF Lee, Geonsun
   Lee, Dae Yeol
   Su, Guan-Ming
   Manocha, Dinesh
TI "May I Speak?": Multi-Modal Attention Guidance in Social VR Group
   Conversations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Social VR; Attention Guidance; Multi-modal Interaction; Group
   Conversations; Turn-taking
AB In this paper, we present a novel multi-modal attention guidance method designed to address the challenges of turn-taking dynamics in meetings and enhance group conversations within virtual reality (VR) environments. Recognizing the difficulties posed by a confined field of view and the absence of detailed gesture tracking in VR, our proposed method aims to mitigate the challenges of noticing new speakers attempting to join the conversation. This approach tailors attention guidance, providing a nuanced experience for highly engaged participants while offering subtler cues for those less engaged, thereby enriching the overall meeting dynamics. Through group interview studies, we gathered insights to guide our design, resulting in a prototype that employs light as a diegetic guidance mechanism, complemented by spatial audio. The combination creates an intuitive and immersive meeting environment, effectively directing users' attention to new speakers. An evaluation study, comparing our method to state-of-the-art attention guidance approaches, demonstrated significantly faster response times (p < 0.001), heightened perceived conversation satisfaction (p < 0.001), and preference (p < 0.001) for our method. Our findings contribute to the understanding of design implications for VR social attention guidance, opening avenues for future research and development.
C1 [Lee, Geonsun; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
   [Lee, Dae Yeol; Su, Guan-Ming] Dolby Labs, San Francisco, CA USA.
C3 University System of Maryland; University of Maryland College Park;
   Dolby Laboratories, Inc.
RP Lee, G (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM gsunlee@cs.umd.edu; DaeYeol.Lee@dolby.com; guanming.su@dolby.com;
   dmanocha@cs.umd.edu
OI Lee, Geonsun/0000-0001-9401-8559; Lee, Dae Yeol/0000-0001-9990-5253;
   Manocha, Dinesh/0000-0001-7047-9801
CR Yassien A., INPROCEEDINGS 11 NOR
   Zhang X., 2020, INPROCEEDINGS 4 INT, P31
NR 2
TC 1
Z9 1
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2287
EP 2297
DI 10.1109/TVCG.2024.3372119
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400024
PM 38451772
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Aoki, H
   Tochimoto, T
   Hiroi, Y
   Itoh, Y
AF Aoki, Hiroto
   Tochimoto, Takumi
   Hiroi, Yuichi
   Itoh, Yuta
TI Towards Co-Operative Beaming Displays: Dual Steering Projectors for
   Extended Projection Volume and Head Orientation Range
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Near-eye display; Augmented reality; Projectors
AB Existing near-eye displays (NEDs) have trade-offs related to size, weight, computational resources, battery life, and body temperature. A recent paradigm, beaming display, addresses these trade-offs by separating the NED into a steering projector (SP) for image presentation and a passive headset worn by the user. However, the beaming display has issues with the projection area of a single SP and has severe limitations on the head orientation and pose that the user can move. In this study, we distribute dual steering projectors in the scene to extend the head orientation and pose of the beaming display by coordinating the dual projections on a passive headset. For cooperative control of each SP, we define a geometric model of the SPs and propose a calibration and projection control method designed for multiple projectors. We present implementations of the system along with evaluations showing that the precision and delay are 1.8 similar to 5.7 mm and 14.46 ms, respectively, at a distance of about 1 m from the SPs. From this result, our prototype with multiple SPs can project images in the projection area (20 mm x 30mm) of the passive headset while extending the projectable head orientation. Furthermore, as applications of cooperative control by multiple SPs, we show the possibility of multiple users, improving dynamic range and binocular presentation.
C1 [Aoki, Hiroto; Itoh, Yuta] Univ Tokyo, Tokyo, Japan.
   [Tochimoto, Takumi] Tokyo Inst Technol, Tokyo, Japan.
   [Hiroi, Yuichi] Cluster Metaverse Lab, Tokyo, Japan.
C3 University of Tokyo; Institute of Science Tokyo; Tokyo Institute of
   Technology
RP Aoki, H (corresponding author), Univ Tokyo, Tokyo, Japan.
EM aoki-hiroto633@g.ecc.u-tokyo.ac.jp; takumi.tochimoto@ar.c.titech.ac.jp;
   y.hiroi@cluster.mu; yuta.itoh@iii.u-tokyo.ac.jp
RI Hiroi, Yuichi/KGM-7451-2024
OI Hiroi, Yuichi/0000-0001-8567-6947; Itoh, Yuta/0000-0002-5901-797X
FU JST FOREST
FX No Statement Available
CR Aksit K, 2023, Arxiv, DOI arXiv:2212.05057
   Blate A, 2019, IEEE T VIS COMPUT GR, V25, P1970, DOI 10.1109/TVCG.2019.2899233
   Bradski G, 2000, DR DOBBS J, V25, P120
   Chakravarthula P, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417846
   Forsyth D. A., 2003, printice hall, P3
   Hiroi Y, 2023, IEEE T VIS COMPUT GR, V29, P4761, DOI 10.1109/TVCG.2023.3320212
   Itoh Y, 2021, IEEE T VIS COMPUT GR, V27, P2659, DOI 10.1109/TVCG.2021.3067764
   Iwai D, 2015, IEEE T CIRC SYST VID, V25, P547, DOI 10.1109/TCSVT.2014.2352500
   Kitajima Y, 2017, IEEE T VIS COMPUT GR, V23, P2419, DOI 10.1109/TVCG.2017.2734478
   Koulieris GA, 2019, COMPUT GRAPH FORUM, V38, P493, DOI 10.1111/cgf.13654
   Kress B, 2013, PROC SPIE, V8720, DOI 10.1117/12.2015654
   Kress BC, 2019, PROC SPIE, V11062, DOI 10.1117/12.2527680
   Lincoln P, 2016, IEEE T VIS COMPUT GR, V22, P1367, DOI 10.1109/TVCG.2016.2518038
   Maruyama M, 2018, IEEE WINT CONF APPL, P921, DOI 10.1109/WACV.2018.00106
   Mikawa Y, 2022, IEEE T VIS COMPUT GR, V28, P4016, DOI 10.1109/TVCG.2021.3111085
   Mikawa Y, 2021, 2021 60TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P137
   Mikawa Y, 2018, SA'18: SIGGRAPH ASIA 2018 EMERGING TECHNOLOGIES, DOI 10.1145/3275476.3275481
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Munoz-Salinas R., Aruco library
   Nitta M, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281535
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Okumura K, 2013, IEEE INT CON MULTI
   Okumura K, 2011, IEEE INT CONF ROBOT, DOI 10.1109/ICRA.2011.5980080
   Peng YF, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417802
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Sueishi T, 2015, IEEE INT C INT ROBOT, P3064, DOI 10.1109/IROS.2015.7353800
   Sueishi T, 2015, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2015.7223330
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Wan DR, 2008, COMPUT VIS IMAGE UND, V112, P184, DOI 10.1016/j.cviu.2008.02.005
   Wang LH, 2020, ACM SIGGRAPH 2020 EMERGING TECHNOLOGIES, DOI 10.1145/3388534.3408333
   Wang LH, 2014, OPT EXPRESS, V22, P19448, DOI 10.1364/OE.22.019448
   Watanabe Yoshihiro, 2015, 22 INT DISPL WORKSH, P1421
   Wilson AD, 2012, UIST'12: PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P413
   Yamamoto K., 2022, IEEE TVCG, P1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 36
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2309
EP 2318
DI 10.1109/TVCG.2024.3372118
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400064
PM 38530726
DA 2024-11-06
ER

PT J
AU Stranner, M
   Fleck, P
   Schmalstieg, D
   Arth, C
AF Stranner, Marco
   Fleck, Philipp
   Schmalstieg, Dieter
   Arth, Clemens
TI Instant Segmentation and Fitting of Excavations in Subsurface Utility
   Engineering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Excavation; Point cloud compression;
   Documentation; Fitting; Task analysis; Solid modeling; Augmented
   Reality; Localization; 3D Models; Geometric Constraints; Segmentation;
   Infrastructure
AB Using augmented reality for subsurface utility engineering (SUE) has benefited from recent advances in sensing hardware, enabling the first practical and commercial applications. However, this progress has uncovered a latent problem - the insufficient quality of existing SUE data in terms of completeness and accuracy. In this work, we present a novel approach to automate the process of aligning existing SUE databases with measurements taken during excavation works, with the potential to correct the deviation from the as-planned to as-built documentation, which is still a big challenge for traditional workers at sight. Our segmentation algorithm performs infrastructure segmentation based on the live capture of an excavation on site. Our fitting approach correlates the inferred position and orientation with the existing digital plan and registers the as-planned model into the as-built state. Our approach is the first to circumvent tedious postprocessing, as it corrects data online and on-site. In our experiments, we show the results of our proposed method on both synthetic data and a set of real excavations.
C1 [Stranner, Marco; Fleck, Philipp; Schmalstieg, Dieter; Arth, Clemens] Graz Univ Technol, Graz, Austria.
C3 Graz University of Technology
RP Fleck, P (corresponding author), Graz Univ Technol, Graz, Austria.
EM m.stranner@icg.tugraz.at; philipp.fleck@icg.tugraz.at;
   dieter@icg.tugraz.at; arth@icg.tugraz.at
FU European Union
FX No Statement Available
CR Agarwal S., 2022, Ceres Solver, V3, P5
   Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   Vo AV, 2015, ISPRS J PHOTOGRAMM, V104, P88, DOI 10.1016/j.isprsjprs.2015.01.011
   [Anonymous], 2004, Technical report
   Bellekens B., 2014, AMBIENT 2014 4 INT C
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Broome R., 2019, Utility strike damage report
   Covaciu Dinu, 2016, Applied Mechanics and Materials, V822, P321, DOI 10.4028/www.scientific.net/AMM.822.321
   Crevier D., 1993, 1993 Canadian Conference on Electrical and Computer Engineering (Cat. No.93TH0590-0), P1250, DOI 10.1109/CCECE.1993.332483
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dorninger P., 2007, International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514
   Furgale P, 2012, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2012.6225005
   Gelfand N., 2004, Proceeding of the Symposium on Geometric Processing, P219, DOI DOI 10.1145/1057432.10574612
   Green WR, 2015, PROCEEDINGS OF THE 2015 PATTERN RECOGNITION ASSOCIATION OF SOUTH AFRICA AND ROBOTICS AND MECHATRONICS INTERNATIONAL CONFERENCE (PRASA-ROBMECH), P54, DOI 10.1109/RoboMech.2015.7359498
   Guerrero P, 2018, Arxiv, DOI arXiv:1710.04954
   Hansen L., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLVI-4/W4-2021, P25, DOI [DOI 10.5194/ISPRS-ARCHIVES-XLVI-4-W4-2021-25-20212, 10.5194/isprs-archives-XLVI-4-W4-2021-25-20212]
   Hansen L., 2021, PhD thesis, DOI [10.54337/aau4664079953, DOI 10.54337/AAU4664079953]
   Hansen L., 2021, Workingpaper
   Hansen L., 2021, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLVI-4/W4-2021, P43, DOI [10.5194/isprs-archives-XLVI-4-W4-2021-43-2021, DOI 10.5194/ISPRS-ARCHIVES-XLVI-4-W4-2021-43-2021]
   Hansen LH, 2021, IEEE T VIS COMPUT GR, V27, P4119, DOI 10.1109/TVCG.2021.3106479
   HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063
   Hartley R., 2003, Multiple view geometry in computer vision, V2, P2
   Iannizzotto G, 2000, IEEE T IMAGE PROCESS, V9, P1232, DOI 10.1109/83.847835
   Kaganami Hassana Grema, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1217, DOI 10.1109/IIH-MSP.2009.13
   Kang ZZ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117341
   Krumm J., 2000, Intersection of two planes, V6
   Kundu A., 2020, P EUR C COMP VIS, P518, DOI DOI 10.1007/978-3-030-58586-0_31
   Lafarge F, 2012, INT J COMPUT VISION, V99, P69, DOI 10.1007/s11263-012-0517-8
   Lari Z, 2014, ISPRS J PHOTOGRAMM, V93, P192, DOI 10.1016/j.isprsjprs.2013.12.001
   Li LX, 2019, PROC CVPR IEEE, P2647, DOI 10.1109/CVPR.2019.00276
   Makana LO, 2020, INFRASTRUCT ASSET MA, V7, P64, DOI 10.1680/jinam.17.00033
   Maurell IP, 2021, 2021 LATIN AMERICAN ROBOTICS SYMPOSIUM / 2021 BRAZILIAN SYMPOSIUM ON ROBOTICS / 2021 WORKSHOP OF ROBOTICS IN EDUCATION (LARS-SBR-WRE 2021), P108, DOI 10.1109/LARS/SBR/WRE54079.2021.9605458
   Min S, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P246
   Murtiyoso A., 2021, Int. Arch. Photogram. Rem. Sens. Spatial Inf. Sci., V43, P201
   ODA K., 2004, Journal of the Japan society of photogrammetry and remote sensing, V43, P16, DOI [10.4287/jsprs.43.5162, DOI 10.4287/JSPRS.43.5162]
   Pellis E, 2022, INT ARCH PHOTOGRAMM, P429, DOI 10.5194/isprs-archives-XLVI-2-W1-2022-429-2022
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2018, Arxiv, DOI [arXiv:1711.08488, 10.48550/arXiv.1711.08488]
   Rabbani T., 2005, PROC ISPRS WORKSHOP, V36, P2
   Romanengo C, 2023, COMPUT AIDED DESIGN, V157, DOI 10.1016/j.cad.2023.103479
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6
   Schall G, 2013, PERS UBIQUIT COMPUT, V17, P1533, DOI 10.1007/s00779-012-0599-x
   Schall G, 2009, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2009.5336489
   Schall G, 2008, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2008.4637332
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   SCHWARTZ JT, 1987, INT J ROBOT RES, V6, P29, DOI 10.1177/027836498700600203
   Segal A., 2009, PROC ROBOTICS SCI SY, DOI [10.15607/RSS.2009.V.0212, DOI 10.15607/RSS.2009.V.0212]
   Soria G, 2018, J COMPUT INF SCI ENG, V18, DOI 10.1115/1.4040460
   Spreafico F., 2021, INT ARCH PHOTOGRAMME, V43, P63
   Stranner M., 2023, Masters thesis, P3
   Strom J, 2010, IEEE INT C INT ROBOT, P2131, DOI 10.1109/IROS.2010.5650459
   Tang J., 2010, 2010 2 INT C COMP EN, V6, pV6, DOI [10.1109/ICCET.2010.5486012, DOI 10.1109/ICCET.2010.5486012]
   Tarsha-Kurdi F., 2007, ISPRS WORKSHOP LASER, VXXXVI, P2
   The CGAL Project, 2023, CGAL User and Reference Manual, V2, P5
   Tovari D., 2012, International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, V36, P2
   Trigo G., 2011, 2011 IEEE 73 VEHICUL, P1, DOI [10.1109/VETECS.2011.5956715, DOI 10.1109/VETECS.2011.5956715]
   Vogt M, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9020025
   Vosselman G., 2001, International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, VXXXIV, P2
   Xu JQ, 2021, FRONT BUILT ENVIRON, V7, DOI 10.3389/fbuil.2021.640732
   Xu Y., 2017, ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences, VIV-1/W1, P43, DOI [10.5194/isprs-annals-IV-1-W1, DOI 10.5194/ISPRS-ANNALS-IV-1-W1]
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yoon JH, 2010, PROCEEDINGS OF THE ASME DYNAMIC SYSTEMS AND CONTROL CONFERENCE 2010, VOL 2, P863
   Zhou Y, 2017, Arxiv, DOI arXiv:1711.06396
   Zollmann Stefanie, 2014, P 26 AUSTR COMP HUM, P194, DOI DOI 10.1145/2686612.2686642
NR 67
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2319
EP 2329
DI 10.1109/TVCG.2024.3372064
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400001
PM 38437110
OA hybrid
DA 2024-11-06
ER

PT J
AU Wen, EL
   Gupta, C
   Sasikumar, P
   Billinghurst, M
   Wilmott, J
   Skow, E
   Dey, A
   Nanayakkara, S
AF Wen, Elliott
   Gupta, Chitralekha
   Sasikumar, Prasanth
   Billinghurst, Mark
   Wilmott, James
   Skow, Emily
   Dey, Arindam
   Nanayakkara, Suranga
TI VR.net: A Real-world Dataset for Virtual Reality Motion Sickness
   Research
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Motion Sickness; Virtual Reality; Machine Learning
ID VISUALLY-INDUCED MOTION; FIELD-OF-VIEW; SIMULATOR SICKNESS; HEART-RATE;
   CYBERSICKNESS; VECTION; DEPTH; ANGLE; PITCH; GAZE
AB Researchers have used machine learning approaches to identify motion sickness in VR experience. These approaches would certainly benefit from an accurately labeled, real-world, diverse dataset that enables the development of generalizable ML models. We introduce 'VR.net', a dataset comprising 165-hour gameplay videos from 100 real-world games spanning ten diverse genres, evaluated by 500 participants. VR.net accurately assigns 24 motion sickness-related labels for each video frame, such as camera/object movement, depth of field, and motion flow. Building such a dataset is challenging since manual labeling would require an infeasible amount of time. Instead, we implement a tool to automatically and precisely extract ground truth data from 3D engines' rendering pipelines without accessing VR games' source code. We illustrate the utility of VR.net through several applications, such as risk factor detection and sickness level prediction. We believe that the scale, accuracy, and diversity of VR.net can offer unparalleled opportunities for VR motion sickness research and beyond.We also provide access to our data collection tool, enabling researchers to contribute to the expansion of VR.net.
C1 [Wen, Elliott; Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
   [Gupta, Chitralekha; Sasikumar, Prasanth; Nanayakkara, Suranga] Natl Univ Singapore, Singapore, Singapore.
   [Wilmott, James; Skow, Emily; Dey, Arindam] Meta Real Labs, Burlingame, CA USA.
C3 University of Auckland; National University of Singapore
RP Wen, EL (corresponding author), Univ Auckland, Auckland, New Zealand.
EM jq.elliott.wen@gmail.com; Chitralekha@ahlab.org; Prasanth@ahlab.org;
   mark.billinghurst@auckland.ac.nz; jwilmott@meta.com; emilyskow@meta.com;
   aridey@meta.com; suranga@ahlab.org
RI Billinghurst, Mark/AAJ-4236-2020; Gupta, Chitralekha/AAF-8617-2019
OI NANAYAKKARA, SURANGA/0000-0001-7441-5493
CR Adhanom IB, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P645, DOI [10.1109/VR46266.2020.00-17, 10.1109/VR46266.2020.1581314696458]
   Alloghani M., 2020, Supervised and unsupervised learning for data science, P3, DOI [10.1007/978-3-030-22475-2, 10.1007/978-3-030-22475-21, 10.1007/978-3-030-22475-2_1]
   [Anonymous], 2023, Int. J. Comput. Digit. Syst, V5
   [Anonymous], Meta captures 90% of vr headset market share
   Arima M, 2004, OCEANS '04 MTS/IEEE TECHNO-OCEAN '04, VOLS 1- 2, CONFERENCE PROCEEDINGS, VOLS. 1-4, P1129
   Beggiato M, 2020, ADV INTELL SYST COMP, V1131, P932, DOI 10.1007/978-3-030-39512-4_142
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bonato F, 2009, AVIAT SPACE ENVIR MD, V80, P941, DOI 10.3357/ASEM.2394.2009
   Carnegie K, 2015, IEEE COMPUT GRAPH, V35, P34, DOI 10.1109/MCG.2015.98
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chardonnet M. A., 2015, INT C ART REAL TEL E, P9
   Cheng-Li Liu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P334, DOI 10.1109/FSKD.2012.6234149
   Diels C, 2007, AVIAT SPACE ENVIR MD, V78, P659
   Dong X, 2011, J EXP PSYCHOL-APPL, V17, P128, DOI 10.1037/a0024097
   Duh HBL, 2001, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2001.913791
   Ekman W. V., 1978, EnvironmentalPsychology & Nonverbal Behavior, V3
   Emoto M, 2008, DISPLAYS, V29, P90, DOI 10.1016/j.displa.2007.09.010
   Fan HQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3783, DOI 10.1145/3474085.3478329
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fifty C, 2021, ADV NEUR IN, V34
   Foxman M, 2022, IEEE T GAMES, V14, P466, DOI 10.1109/TG.2021.3119521
   Golding JF, 2012, AVIAT SPACE ENVIR MD, V83, P477, DOI 10.3357/ASEM.3095.2012
   Hell S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR), P153, DOI 10.1109/AIVR.2018.00032
   Holmes SR, 2001, J PSYCHOPHYSIOL, V15, P35, DOI 10.1027//0269-8803.15.1.35
   Johnson D. M., 2005, Introduction to and review of simulator sickness research, V1
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2019, DISPLAYS, V58, P71, DOI 10.1016/j.displa.2018.07.005
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2011, AVIAT SPACE ENVIR MD, V82, P1023, DOI 10.3357/ASEM.3078.2011
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim H., 2020, IEEE Trans-actions on Neural Networks and Learning Systems, V3
   Kim HG, 2021, AAAI CONF ARTIF INTE, V35, P836
   Kim HG, 2019, IEEE T IMAGE PROCESS, V28, P1646, DOI 10.1109/TIP.2018.2880509
   Kim W., 2018, 2018 10 INT C QUAL M, P1
   Kuiper OX, 2020, APPL ERGON, V85, DOI 10.1016/j.apergo.2020.103068
   LaCount LT, 2009, COMPUT CARDIOL, V36, P49
   Lee JY, 2017, SIGGRAPH ASIA 2017 POSTERS (SA'17), DOI 10.1145/3145690.3145697
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Li JY, 2021, AUTOMOTIVEUI '21: 13TH INTERNATIONAL ACM CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P28, DOI [10.1145/3409118.3475137, 10.1145/34091183475137]
   Liao CY, 2020, IEEE ACCESS, V8, P126784, DOI 10.1109/ACCESS.2020.3008165
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Martirosov S, 2022, VIRTUAL REAL-LONDON, V26, P15, DOI 10.1007/s10055-021-00507-4
   Naeem A., An unsupervised machinelearning algorithms: Comprehensive review
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Padmanaban N, 2018, IEEE T VIS COMPUT GR, V24, P1594, DOI 10.1109/TVCG.2018.2793560
   Park SH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1016/j.cap.2022.08.010, 10.1145/3491102.3501847]
   Proffitt DR, 1995, PSYCHON B REV, V2, P409, DOI 10.3758/BF03210980
   Sangmin Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P170, DOI 10.1007/978-3-030-58592-1_11
   Saredakis D, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00096
   Smyth J, 2021, APPL ERGON, V92, DOI 10.1016/j.apergo.2020.103315
   So RHY, 2001, HUM FACTORS, V43, P452, DOI 10.1518/001872001775898223
   So RHY, 2001, PRESENCE-TELEOP VIRT, V10, P193, DOI 10.1162/105474601750216803
   Solorio-Fernández S, 2020, ARTIF INTELL REV, V53, P907, DOI 10.1007/s10462-019-09682-y
   Tan RC, 2022, IEEE INTELL SYST, V37, P86, DOI 10.1109/MIS.2022.3208485
   Terenzi Lorenzo, 2020, AIAA SCITECH 2020 FO
   Tong Z, 2022, Arxiv, DOI arXiv:2203.12602
   Totosis N, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P552, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00104
   Tychsen L, 2020, AM J OPHTHALMOL, V209, P151, DOI 10.1016/j.ajo.2019.07.020
   Wen E, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545656
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Wibirama S, 2014, IEEE ENG MED BIO, P4803, DOI 10.1109/EMBC.2014.6944698
   Xue A. El Ali, 2021, IEEE Transactions on Multimedia, V2
   Zuzewicz K, 2011, INT J OCCUP SAF ERGO, V17, P403
NR 64
TC 1
Z9 1
U1 11
U2 12
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2330
EP 2336
DI 10.1109/TVCG.2024.3372044
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400053
PM 38437109
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Zhou, YQ
   Popescu, V
AF Zhou, Yuqi
   Popescu, Voicu
TI CloVR: Fast-Startup Low-Latency Cloud VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Servers; Rendering (computer graphics); Visualization; Geometry; Low
   latency communication; Headphones; Cloud computing; Cloud VR; Near-Far
   Partitioning
AB VR headsets have limited rendering capability, which limits the size and detail of the virtual environment (VE) that can be used in VR applications. One solution is cloud VR, where the "thin" VR clients are assisted by a server. This paper describes Cio VR, a cloud VR system that provides fast loading times, as needed to let users see and interact with the VE quickly at session startup or after teleportation. The server reduces the original VE to a compact representation through near-far partitioning. The server renders the far region to an environment map which it sends to the client together with the near region geometry, from which the client renders quality frames locally, with low latency. The near region starts out small and grows progressively, with strict visual continuity, minimizing startup time. The low-latency and fast-startup advantages of CloVR have been validated in a user study where groups of 8 participants wearing all-in-one VR headsets (Quest 2's) were supported by a laptop server to run a collaborative VR application with a 25 million triangle VE.
C1 [Zhou, Yuqi; Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Zhou, YQ (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM zhou1168@purdue.edu; popescu@purdue.edu
FU National Science Foundation
FX No Statement Available
CR [Anonymous], Oculus headset
   [Anonymous], Unity 3d engine
   BLINN JF, 1976, COMMUN ACM, V19, P542, DOI 10.1145/965143.563322
   Feng TT, 2020, IEEE T MULTIMEDIA, V22, P2963, DOI 10.1109/TMM.2019.2962313
   Fink L, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P88, DOI [10.1109/vr.2019.8798283, 10.1109/VR.2019.8798283]
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Han B, 2020, MOBICOM '20: PROCEEDINGS OF THE 26TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2020), P137, DOI 10.1145/3372224.3380888
   He J, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P482, DOI 10.1145/3210240.3210323
   Hladky J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356530
   IBM Corporation, 2022, IBM SPSS statistics, V29th ed.
   Kämäräinen T, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1181, DOI 10.1145/3240508.3240620
   Kelkkanen V, 2021, INT J COMPUT GAMES T, V2021, DOI 10.1155/2021/6676644
   Kim J, 2020, P ACM COMPUT GRAPH, V3, DOI 10.1145/3406187
   Koch T, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3451266
   Lai ZQ, 2017, PROCEEDINGS OF THE 23RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '17), P409, DOI 10.1145/3117811.3117815
   Lee J., 2020, InProc. ACM MobiCom, V2
   Liu TY, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P881, DOI 10.1109/MICRO50266.2020.00076
   Luebke B. Watson, 2002, Level ofDetail for 3D Graphics, V2
   Meehan M, 2003, P IEEE VIRT REAL ANN, P141, DOI 10.1109/VR.2003.1191132
   Mehrabi A, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3429441
   Nadir Z, 2021, IEEE NETWORK, V35, P299, DOI 10.1109/MNET.121.2100172
   Park J, 2021, IEEE T VIS COMPUT GR, V27, P2746, DOI 10.1109/TVCG.2021.3067768
   Popescu V, 2022, INT SYM MIX AUGMENT, P35, DOI 10.1109/ISMAR55827.2022.00017
   Qian F, 2019, HOTMOBILE '19 - PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS, P135, DOI 10.1145/3301293.3302358
   Qian F, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P99, DOI 10.1145/3241539.3241565
   Schollmeyer A, 2017, IEEE T VIS COMPUT GR, V23, P1285, DOI 10.1109/TVCG.2017.2657078
   Schütz M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P103, DOI [10.1109/vr.2019.8798284, 10.1109/VR.2019.8798284]
   Stengel M, 2021, MMSYS '21: PROCEEDINGS OF THE 2021 MULTIMEDIA SYSTEMS CONFERENCE, P159, DOI 10.1145/3458305.3463379
   Stotko S., 2018, CoRR, abs/1805.03709
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilcoxon F., 1992, Individual comparisons by ranking methods, P5
   Zhang A, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P137
   Zhao SM, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533563
   Zhou P, 2021, IEEE T NETW SCI ENG, V8, P419, DOI 10.1109/TNSE.2020.3038998
   Zhou Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3452097
NR 35
TC 0
Z9 0
U1 5
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2337
EP 2346
DI 10.1109/TVCG.2024.3372059
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400006
PM 38437098
DA 2024-11-06
ER

PT J
AU Wang, YX
   Ling, HB
   Huang, BY
AF Wang, Yuxi
   Ling, Haibin
   Huang, Bingyao
TI ViComp: Video Compensation for Projector-Camera Systems
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptation models; Image color analysis; Distortion; Training;
   Reflectivity; Computational modeling; Synchronization; Projector
   compensation; Video compensation; Spatial augmented reality;
   Projector-camera system; Continuous projection mapping
ID STRUCTURED-LIGHT; ADAPTATION
AB Projector video compensation aims to cancel the geometric and photometric distortions caused by non-ideal projection surfaces and environments when projecting videos. Most existing projector compensation methods start by projecting and capturing a set of sampling images, followed by an offline compensation model training step. Thus, abundant user effort is required before the users can watch the video. Moreover, the sampling images have little prior knowledge of the video content and may lead to suboptimal results. To address these issues, this paper builds a video compensation system that can online adapt the compensation parameters. Our approach consists of five threads and can perform compensation, projection, capturing, and short-term and long-term model updates in parallel. Due to the parallel mechanism, rather than projecting and capturing hundreds of sampling images and training the model offline, we can directly use the projected and captured video frames for model updates on the fly. To quickly apply to the new environment, we introduce a deep learning-based compensation model that integrates a fixed transformer-based method and a novel CNN-based network. Moreover, for fast convergence and to reduce error accumulation during fine-tuning, we present a strategy that cooperates with short-term and long-term memory model updates. Experiments show that it significantly outperforms state-of-the-art baselines.
C1 [Wang, Yuxi] Hangzhou Dianzi Univ, Hangzhou, Peoples R China.
   [Ling, Haibin] SUNY Stony Brook, Stony Brook, NY USA.
   [Huang, Bingyao] Southwest Univ, Chongqing, Peoples R China.
C3 Hangzhou Dianzi University; State University of New York (SUNY) System;
   Stony Brook University; Southwest University - China
RP Huang, BY (corresponding author), Southwest Univ, Chongqing, Peoples R China.
EM yxwang@hdu.edu.cn; haibin.ling@stonybrook.edu; bhuang@swu.edu.cn
RI Huang, Bingyao/AAH-9030-2019
OI Huang, Bingyao/0000-0002-8647-5730; Ling, Haibin/0000-0003-4094-8413
FU Nature Science Foundation of China
FX No Statement Available
CR Akiyama R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P741, DOI 10.1109/VRW55335.2022.00226
   B. O. Community, 2018, Blender-a 3D modelling and rendering package
   Bimber O, 2005, COMPUTER, V38, P48, DOI 10.1109/MC.2005.17
   Bimber O., 2006, IEEE VIRTUAL REALITY, P320
   Bimber O, 2008, COMPUT GRAPH FORUM, V27, P2219, DOI 10.1111/j.1467-8659.2008.01175.x
   Bokaris P.-A., 2015, EUR C COMP VIS WORKS, P2
   Bokaris PA, 2015, IEEE IMAGE PROC, P2675, DOI 10.1109/ICIP.2015.7351288
   Brahma D, 2023, PROC CVPR IEEE, P3582, DOI 10.1109/CVPR52729.2023.00349
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Döbler M, 2023, PROC CVPR IEEE, P7704, DOI 10.1109/CVPR52729.2023.00744
   Erel Yotam, 2023, IEEE Trans Vis Comput Graph, V29, P4339, DOI 10.1109/TVCG.2023.3320256
   Fujii K, 2005, PROC CVPR IEEE, P1180
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Grundhöfer A, 2018, COMPUT GRAPH FORUM, V37, P653, DOI 10.1111/cgf.13387
   Hamasaki T, 2018, IEEE T VIS COMPUT GR, V24, P1457, DOI 10.1109/TVCG.2018.2793659
   Hashimoto N, 2021, VISUAL COMPUT, V37, P175, DOI 10.1007/s00371-019-01790-8
   Hashimoto N, 2017, INT J COMPUT GAMES T, V2017, DOI 10.1155/2017/4936285
   Huang BY, 2022, IEEE T PATTERN ANAL, V44, P2953, DOI 10.1109/TPAMI.2021.3050124
   Huang BY, 2021, IEEE T VIS COMPUT GR, V27, P2725, DOI 10.1109/TVCG.2021.3067771
   Huang BY, 2019, PROC CVPR IEEE, P6803, DOI 10.1109/CVPR.2019.00697
   Huang ZY, 2022, LECT NOTES COMPUT SC, V13677, P668, DOI 10.1007/978-3-031-19790-1_40
   Ibrahim MT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P905, DOI 10.1109/VRW58643.2023.00295
   Iwasawa Y, 2021, ADV NEUR IN
   Kagami S, 2019, IEEE T VIS COMPUT GR, V25, P3094, DOI 10.1109/TVCG.2019.2932248
   Kageyama Y, 2022, IEEE T VIS COMPUT GR, V28, P2223, DOI 10.1109/TVCG.2022.3150465
   Kemmoku Y, 2016, ADJUNCT PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P288, DOI [10.1109/ISMAR-Adjunct.2016.88, 10.1109/ISMAR-Adjunct.2016.0097]
   Kingma D.P., 2014, P INT C LEARNING REP
   Kurth Philipp, 2020, 2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), P174, DOI 10.1109/ISMAR50242.2020.00039
   Li Y., 2023, IEEE Transactions on Visualization and Computer Graphics, P1
   Low KL, 2003, P IEEE VIRT REAL ANN, P110
   Majumder A, 2015, P IEEE VIRT REAL ANN, P339, DOI 10.1109/VR.2015.7223434
   Miyashita L, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275045
   Miyatake Y, 2023, IEEE T VIS COMPUT GR, V29, P2005, DOI 10.1109/TVCG.2021.3136214
   Narita G, 2017, IEEE T VIS COMPUT GR, V23, P1235, DOI 10.1109/TVCG.2016.2592910
   Nguyen AT, 2023, PROC CVPR IEEE, P24162, DOI 10.1109/CVPR52729.2023.02314
   Özacar K, 2015, P IEEE VIRT REAL ANN, P255, DOI 10.1109/VR.2015.7223392
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park H, 2008, IEEE T CIRC SYST VID, V18, P110, DOI 10.1109/TCSVT.2007.903322
   Raskar R., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P109, DOI 10.1109/VR.2000.840488
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roosendaal T., 2012, cloud.blender.org/spring.
   Roosendaal T., 2008, Big buck bunny
   Shahpaski M, 2017, PROC CVPR IEEE, P3596, DOI 10.1109/CVPR.2017.383
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shih KT, 2021, IEEE T IMAGE PROCESS, V30, P418, DOI 10.1109/TIP.2020.3036768
   Siegl C, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818111
   Soucek T, 2020, arXiv, DOI DOI 10.48550/ARXIV.2008.04838
   Sugimoto M, 2021, IEEE T VIS COMPUT GR, V27, P4161, DOI 10.1109/TVCG.2021.3106511
   Sun Y., 2020, ICML, P9229
   Tarvainen A, 2017, ADV NEUR IN, V30
   Ueda T, 2020, IEEE T VIS COMPUT GR, V26, P2051, DOI 10.1109/TVCG.2020.2973496
   Wang E., 2021, ARXIV
   Wang Q, 2022, PROC CVPR IEEE, P7191, DOI 10.1109/CVPR52688.2022.00706
   Wang YM, 2017, IEEE IMAGE PROC, P2726, DOI 10.1109/ICIP.2017.8296778
   Wang YX, 2023, Symposium Virtual Re, P135, DOI 10.1109/VR55154.2023.00029
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe Y, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P52, DOI 10.1109/ISMAR.2017.22
   Yuqi Li, 2012, 2012 International Conference on Virtual Reality and Visualization (ICVRV 2012), P7, DOI 10.1109/ICVRV.2012.15
   Zheng RD, 2018, IEEE INT SYMP CIRC S
NR 60
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2347
EP 2356
DI 10.1109/TVCG.2024.3372079
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400012
PM 38437096
DA 2024-11-06
ER

PT J
AU Kern, F
   Tschanter, J
   Latoschik, ME
AF Kern, Florian
   Tschanter, Jonathan
   Latoschik, Marc Erich
TI Handwriting for Text Input and the Impact of XR Displays, Surface
   Alignments, and Sentence Complexities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE VR; AR; XR; physically aligned; mid-air; text input; handwriting;
   digital ink; recognition; phrase set; digital twin
ID RECOGNITION; ONLINE; PEN
AB Text input is desirable across various eXtended Reality (XR) use cases and is particularly crucial for knowledge and office work. This article compares handwriting text input between Virtual Reality (VR) and Video See-Through Augmented Reality (VST AR), facilitated by physically aligned and mid-air surfaces when writing simple and complex sentences. In a 2x2x2 experimental design, 72 participants performed two ten-minute handwriting sessions, each including ten simple and ten complex sentences representing text input in real-world scenarios. Our developed handwriting application supports different XR displays, surface alignments, and handwriting recognition based on digital ink. We evaluated usability, user experience, task load, text input performance, and handwriting style. Our results indicate high usability with a successful transfer of handwriting skills to the virtual domain. XR displays and surface alignments did not impact text input speed and error rate. However, sentence complexities did, with participants achieving higher input speeds and fewer errors for simple sentences (17.85 WPM, 0.51% MSD ER) than complex sentences (15.07 WPM, 1.74% MSD ER). Handwriting on physically aligned surfaces showed higher learnability and lower physical demand, making them more suitable for prolonged handwriting sessions. Handwriting on mid-air surfaces yielded higher novelty and stimulation ratings, which might diminish with more experience. Surface alignments and sentence complexities significantly affected handwriting style, leading to enlarged and more connected cursive writing in both mid-air and for simple sentences. The study also demonstrated the benefits of using XR controllers in a pen-like posture to mimic styluses and pressure-sensitive tips on physical surfaces for input detection. We additionally provide a phrase set of simple and complex sentences as a basis for future text input studies, which can be expanded and adapted.
C1 [Kern, Florian; Tschanter, Jonathan; Latoschik, Marc Erich] Univ Wurzburg, HCI Grp, Wurzburg, Germany.
   [Tschanter, Jonathan] Univ Wurzburg, PIIS Grp, Wurzburg, Germany.
C3 University of Wurzburg; University of Wurzburg
RP Kern, F (corresponding author), Univ Wurzburg, HCI Grp, Wurzburg, Germany.
EM florian.kern@uni-wuerzburg.de; jonathan.tschanter@uni-wuerzburg.de;
   marc.latoschik@uni-wuerzburg.de
OI Kern, Florian/0000-0001-7092-4872; Tschanter,
   Jonathan/0000-0002-6983-6063
FU German Federal Ministry of Education and Research
FX No Statement Available
CR Adams H, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P792, DOI 10.1109/VR51125.2022.00101
   Arif AS, 2009, IEEE TIC-STH 09: 2009 IEEE TORONTO INTERNATIONAL CONFERENCE: SCIENCE AND TECHNOLOGY FOR HUMANITY, P100, DOI 10.1109/TIC-STH.2009.5444533
   Arora R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5643, DOI 10.1145/3025453.3025474
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P23, DOI [10.1109/VRW50115.2020.00012, 10.1109/VRW50115.2020.0-264]
   Batmaz AU, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P184, DOI [10.1109/VR46266.2020.1581205539914, 10.1109/VR46266.2020.00-67]
   Biener V, 2023, HUM-COMPUT INT-SPRIN, P21, DOI 10.1007/978-3-031-05804-2_2
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Bowers B, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P220, DOI 10.1109/VRW52623.2021.00048
   Bowers B, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P1, DOI 10.1109/VRW50115.2020.0-268
   Brooke J., 1995, USABILITY EVAL IND, P189
   Brown C. M., 1988, Proceedings of the Human Factors Society, V32, P381
   Bunke H., 1995, Pattern Recognition, V28, P1399, DOI 10.1016/0031-3203(95)00013-P
   Chen C, 2022, INT SYM MIX AUGMENT, P384, DOI 10.1109/ISMAR55827.2022.00054
   Chen YT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P172, DOI [10.1109/VR.2019.8798338, 10.1109/vr.2019.8798338]
   Cheng YF, 2022, INT SYM MIX AUGMENT, P150, DOI 10.1109/ISMAR55827.2022.00029
   O'Riordan B., 2005, Journal of Computer Sciences, V1, P189, DOI [10.1016/j.tele.2004.12.001, 10.3844/jcssp.2005.189.199]
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Elmgren R., 2017, Handwriting in VR as a Text Input Method, P9
   Fang FY, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569461
   Field AP, 2017, BEHAV RES THER, V98, P19, DOI 10.1016/j.brat.2017.05.013
   Fourrier N, 2023, IEEE T VIS COMPUT GR, V29, P4438, DOI 10.1109/TVCG.2023.3320215
   Gerth S, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01308
   González G, 2009, NEW TRENDS ON HUMAN-COMPUTER INTERACTION: RESEARCH, DEVELOPMENT, NEW TOOLS AND METHODS, P109, DOI 10.1007/978-1-84882-352-5_11
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P151, DOI 10.1109/VR.2018.8446250
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Karthi M., 2020, Procedia Computer Science, V172, P1016, DOI [10.1016/j.procs.2020.05.1492,9, DOI 10.1016/J.PROCS.2020.05.1492,9]
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kern F., 2023, 2023 IEEE INT S MIXE, P74, DOI [10.1109/ISMAR-Adjunct60411.2023.00023, DOI 10.1109/ISMAR-ADJUNCT60411.2023.00023]
   Kern Florian, 2023, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2023.3247098
   Kern F, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P502, DOI 10.1109/VRW58643.2023.00109
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489949
   Kern F, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489940
   Kern F, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684498
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kiefer M, 2015, ADV COGN PSYCHOL, V11, P136, DOI 10.5709/acp-0178-7
   Knierim P, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173919
   Kristensson PO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P567
   Kristensson Per Ola, 2012, P 2012 ACM INT C INT, P29, DOI [DOI 10.1145/2166966.2166972, 10.1145/2166966.2166972]
   Kruijff Ernst, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P3, DOI 10.1109/ISMAR.2010.5643530
   Lages WS, 2019, PROCEEDINGS OF IUI 2019, P356, DOI 10.1145/3301275.3302278
   Latoschik ME, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.694433
   Latoschik ME, 2019, IEEE T VIS COMPUT GR, V25, P2134, DOI 10.1109/TVCG.2019.2899250
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LEWIS JR, 1995, INT J HUM-COMPUT INT, V7, P57, DOI 10.1080/10447319509526110
   MacKenzie I.S., 2003, CHI 03 EXTENDED ABST, P754, DOI DOI 10.1145/765891.765971
   Mair P, 2020, BEHAV RES METHODS, V52, P464, DOI 10.3758/s13428-019-01246-w
   McGill M, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3490495
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   Morehead K, 2019, EDUC PSYCHOL REV, V31, P753, DOI 10.1007/s10648-019-09468-2
   Morehead K, 2019, MEMORY, V27, P807, DOI 10.1080/09658211.2019.1569694
   Mueller PA, 2014, PSYCHOL SCI, V25, P1159, DOI 10.1177/0956797614524581
   Askvik EO, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01810
   Pham D.-M., 2019, 25 ACM S VIRTUAL REA, P1, DOI [10.1145/3359996.33642652,3,9, DOI 10.1145/3359996.33642652,3,9]
   Pham DM, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364264
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Poupyrev I, 1998, P IEEE VIRT REAL ANN, P126, DOI 10.1109/VRAIS.1998.658467
   Schmalstieg D., 2016, Addison-Wesley usability and HCI series
   Schrepp D. M., 2019, User Experience Questionnaire Handbook, P6
   Selin A.-S., 2003, Pencil grip: a descriptive model and four empirical studies, V3, P9
   Skarbez R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647997
   van der Meer ALH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00706
   Vashist Prem Chand, 2020, 2020 International Conference on Computation, Automation and Knowledge Management (ICCAKM). Proceedings, P456, DOI 10.1109/ICCAKM46823.2020.9051464
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Vertanen K., 2011, P 13 INT C HUM COMP, P295, DOI [DOI 10.1145/2037373.2037418, 10.1145/2037373.2037418]
   Viciana-Abad R, 2010, PRESENCE-TELEOP VIRT, V19, P197, DOI 10.1162/pres.19.3.197
   Westermeier F, 2023, 29TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2023, DOI 10.1145/3611659.3617227
   Wienrich C, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.694315
   Wilcox R. R., 2017, Introduction to robust estimation and hypothesis testing, V4th, P6
   Zielasko D., 2020, PhD Thesis,
   Zielasko D, 2019, 2019 IEEE 5TH WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), DOI 10.1109/wevr.2019.8809589
NR 72
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2357
EP 2367
DI 10.1109/TVCG.2024.3372124
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400035
PM 38442066
OA hybrid
DA 2024-11-06
ER

PT J
AU Tian, N
   Boulic, R
AF Tian, Nana
   Boulic, Ronan
TI Who says you are so sick? An investigation on individual susceptibility
   to cybersickness triggers using EEG, EGG and ECG
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Gybersickness; Individual Susceptibility;
   Electrocardiogram; Electrogastrogram; Electroencephalogram
ID ELECTROGASTROGRAPHY
AB In this research paper, we conducted a study to investigate the connection between three objective measures: Electrocardiogram(EGG), Electrogastrogram (EGG), and Electroencephalogram (EEG), and individuals' susceptibility to cybersickness. Our primary objective was to identify which of these factors plays a central role in causing discomfort when experiencing rotations along three different axes: Roll, Pitch, and Yaw. This study involved 35 participants who were tasked with destroying asteroids using their eye gaze while undergoing passive rotations in four separate sessions. The results, when combined with subjective measurements (specifically, Fast motion sickness questionnaire (FMS) and Simulator sickness questionnaire (SSQ) score), demonstrated that EGG measurements were superior in detecting symptoms associated with nausea. As for ECG measurements, our observations did reveal significant changes in Heart Rate Variability (HRV) parameters. However, we caution against relying solely on ECG as a dependable indicator for assessing the extent of cybersickness. Most notably, EEG signals emerged as a crucial resource for discerning individual differences related to these rotational axes. Our findings were significant not only in the context of periodic activities but also underscored the potential of aperiodic activities in detecting the severity of cybersickness and an individual's susceptibility to rotational triggers.
C1 [Tian, Nana; Boulic, Ronan] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Tian, N (corresponding author), Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
EM nana.tian@epfl.ch; ronan.boulic@epfl.ch
FU Fonds National Suisse de la Recherche Scientifique under the Sinergia
FX No Statement Available
CR Ahn MH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.600839
   Andrievskaia P, 2023, EXP BRAIN RES, DOI 10.1007/s00221-023-06690-x
   Camargo A, 2008, SOURCE CODE BIOL MED, V3, DOI 10.1186/1751-0473-3-15
   Chang E, 2023, VIRTUAL REAL-LONDON, V27, P2073, DOI 10.1007/s10055-023-00795-y
   Chang E, 2022, VIRTUAL REAL-LONDON, V26, P1193, DOI 10.1007/s10055-021-00622-2
   CHEN J, 1991, MED BIOL ENG COMPUT, V29, P339, DOI 10.1007/BF02441653
   Chen YC, 2010, NEUROIMAGE, V49, P2862, DOI 10.1016/j.neuroimage.2009.10.005
   Choi MH, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P20
   Cortes CAT, 2023, Symposium Virtual Re, P94, DOI 10.1109/VR55154.2023.00025
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Donoghue T, 2020, NAT NEUROSCI, V23, P1655, DOI 10.1038/s41593-020-00744-x
   Farmer AD, 2015, J PHYSIOL-LONDON, V593, P1183, DOI 10.1113/jphysiol.2014.284240
   Garrido LE, 2022, VIRTUAL REAL-LONDON, V26, P1347, DOI 10.1007/s10055-022-00636-4
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Henry EH, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.809714
   Hill AT, 2022, DEV COGN NEUROS-NETH, V54, DOI 10.1016/j.dcn.2022.101076
   Hu R, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12040447
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Jang KM, 2022, APPL ERGON, V102, DOI 10.1016/j.apergo.2022.103731
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Khaitami, 2019, 2019 International Seminar on Intelligent Technology and Its Applications (ISITIA), P325, DOI 10.1109/ISITIA.2019.8937083
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kiryu T, 2007, LECT NOTES COMPUT SC, V4563, P262
   Klimesch W, 2012, TRENDS COGN SCI, V16, P606, DOI 10.1016/j.tics.2012.10.007
   Koch KL, 2014, EXP BRAIN RES, V232, P2553, DOI 10.1007/s00221-014-4007-9
   Komorowski D, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0054-0
   Krokos E, 2022, VIRTUAL REAL-LONDON, V26, P77, DOI 10.1007/s10055-021-00517-2
   Li G, 2023, Symposium Virtual Re, P328, DOI 10.1109/VR55154.2023.00048
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   Luong T, 2022, INT SYM MIX AUGMENT, P307, DOI 10.1109/ISMAR55827.2022.00046
   MacArthur Cayley., 2021, Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems
   Min BC, 2004, APPL ERGON, V35, P549, DOI 10.1016/j.apergo.2004.06.002
   Nam S, 2022, FRONT HUM NEUROSCI, V16, DOI 10.3389/fnhum.2022.857768
   Nichols TE, 2002, HUM BRAIN MAPP, V15, P1, DOI 10.1002/hbm.1058
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Ozkan A, 2023, DISPLAYS, V78, DOI 10.1016/j.displa.2023.102415
   Park S, 2022, VIRTUAL REAL-LONDON, V26, P979, DOI 10.1007/s10055-021-00600-8
   Pham T, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21123998
   Rebenitsch L, 2016, VIRTUAL REAL-LONDON, V20, P101, DOI 10.1007/s10055-016-0285-9
   Ribas Valdenilson Ribeiro, 2018, Dement. neuropsychol., V12, P264, DOI 10.1590/1980-57642018dn12-030007
   Riezzo G, 1998, DIGEST DIS SCI, V43, P1646, DOI 10.1023/A:1018894511181
   Riezzo G, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/282757
   Shaffer F, 2017, FRONT PUBLIC HEALTH, V5, DOI 10.3389/fpubh.2017.00258
   Tian N, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P289, DOI 10.1109/VRW58643.2023.00068
   Tian P., 2022, VirtualReality, P1
   Watanabe H, 2008, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON UNIVERSAL COMMUNICATION, P210, DOI 10.1109/ISUC.2008.11
   Wibirama S, 2018, ENTERTAIN COMPUT, V26, P117, DOI 10.1016/j.entcom.2018.02.003
   Wilson LE, 2022, ELIFE, V11, DOI 10.7554/eLife.77348
   Yeo SS, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21307-z
   Yin JY, 2013, J NEUROGASTROENTEROL, V19, P5, DOI 10.5056/jnm.2013.19.1.5
NR 50
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2379
EP 2389
DI 10.1109/TVCG.2024.3372066
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400050
PM 38437101
OA hybrid, Green Submitted
DA 2024-11-06
ER

PT J
AU Curiel, RC
   Nakamura, T
   Kuzuoka, H
   Kanaya, T
   Prahm, C
   Matsumoto, K
AF Curiel, Rodrigo Cerecero
   Nakamura, Takuto
   Kuzuoka, Hideaki
   Kanaya, Takafumi
   Prahm, Cosima
   Matsumoto, Keigo
TI Virtual Reality Self Co-Embodiment: An Alternative to Mirror Therapy for
   Post-Stroke Upper Limb Rehabilitation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human-centered computing; user interfaces; virtual reality;
   rehabilitation techniques; virtual embodiment; stroke recovery; motor
   imagery
ID STROKE
AB We present Virtual Reality Self Co-embodiment, a new method for post-stroke upper limb rehabilitation. It is inspired by mirror therapy, where the patient's healthy arm is involved in recovering the affected arm's motion. By tracking the user's head, wrists, and fingers' positions, our new approach allows the handicapped arm to control a digital avatar in order to pursue a reaching task. We apply the concept of virtual co-embodiment to use the information from the unaffected arm and complete the affected limb's impaired motion, which is our added unique feature. This requires users to mechanically involve the incapacitated area as much as possible, prioritizing actual movement rather than the sole imagination of it. As a result, subjects will see a seemingly normally functional virtual arm primarily controlled by their handicapped extremity, but with the constant support of their healthy limb's motion. Our experiment compares the task execution performance and embodiment perceived when interacting with both mirror therapy and our proposed technique. We found that our approach's provided sense of ownership is mildly impacted by users' motion planning response times, which mirror therapy does not exhibit. We also observed that mirror therapy's sense of ownership is moderately affected by the subject's proficiency while executing the assigned task, which our new method did not display. The results indicate that our proposed method provides similar embodiment and rehabilitation capabilities to those perceived from existing mirror therapy. This experiment was performed in healthy individuals to have an unbiased comparison of how mirror therapy's and VRSelfCo's task performance and degree of virtual embodiment compare, but future work explores the possibility of applying this new approach to actual post-stroke patients.
C1 [Curiel, Rodrigo Cerecero; Nakamura, Takuto; Kuzuoka, Hideaki; Kanaya, Takafumi; Matsumoto, Keigo] Univ Tokyo, Tokyo, Japan.
   [Prahm, Cosima] Med Univ Vienna, Vienna, Austria.
C3 University of Tokyo; Medical University of Vienna
RP Curiel, RC (corresponding author), Univ Tokyo, Tokyo, Japan.
EM rodrigo.curiel@cyber.t.u-tokyo.ac.jp; n.takuto@cyber.t.u-tokyo.ac.jp;
   kuzuoka@cyber.t.u-tokyo.ac.jp; kanaya-nii@cyber.t.u-tokyo.ac.jp;
   cosima.prahm@med.uni-tuebingen.de; matsumoto@cyber.t.u-tokyo.ac.jp
RI Prahm, Cosima/AAI-6141-2020
OI Prahm, Cosima/0000-0001-9379-5110; Nakamura, Takuto/0000-0003-3866-4745;
   Kuzuoka, Hideaki/0000-0003-1252-7814; Matsumoto,
   Keigo/0000-0002-0038-0678
FU New Energy and Industrial Technology Development Organization
FX No Statement Available
CR [Anonymous], 2019, Singapore Med J, V60, DOI 10.11622.20191582[3]C.S.
   Cha K, 2021, J NEUROENG REHABIL, V18, DOI 10.1186/s12984-021-00957-6
   Chohan P. K., Long-term complications ofstroke and secondary prevention: an overview for primary care physicians
   Choy CS, 2023, BIOMED ENG ONLINE, V22, DOI 10.1186/s12938-023-01124-9
   Fribourg R, 2021, IEEE T VIS COMPUT GR, V27, P4023, DOI 10.1109/TVCG.2020.2999197
   Gandhi A., 2020, Ther Clin Risk Manag., DOI [10.7748/ns2012.07.26.44.35.c91912, DOI 10.7748/NS2012.07.26.44.35.C91912]
   Jaques Silva, 2023, Stroke Researchand Treatment., DOI [10.1155/2023/50806992, DOI 10.1155/2023/50806992]
   Jo H., 2022, Brain Sciences, V12, DOI [10.3390/brainsci120302972, DOI 10.3390/BRAINSCI120302972]
   Kirch W, 2008, Encyclopedia of Public Health, V1, DOI [10.1007/978-1-4020-5614-72569, DOI 10.1007/978-1-4020-5614-72569]
   Li P., 2021, Frontiers in Neurology, V12, DOI 10.3389.2021.7742473
   Mar C., 2020, The self-avatar follower effect in virtual reality, P18, DOI [10.1109/VR46266.2020.000193[13]P, DOI 10.1109/VR46266.2020.000193[13]P]
   Mateos-Aparicio P, 2019, FRONT CELL NEUROSCI, V13, DOI 10.3389/fncel.2019.00066
   Medicine N., 2023, NM Stroke and Cerebrovascular Care, P2
   Meta Platforms Inc, 2021, Oculus SDK for Windows., V4
   N. Group, 2016, NOI Resources., V5
   Ota T, 2023, IEEE ACCESS, V11, P50841, DOI 10.1109/ACCESS.2023.3279269
   Puderbaugh P. D., NIH Bookshelf, V2
   Regenbrecht S., 2014, Proceedingsof the IEEE, V102, DOI [10.1109/JPROC.2013.22941782[19]D, DOI 10.1109/JPROC.2013.22941782[19]D]
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Sabate B. Gonzalez, 2004, Neuropsychologia, V42, DOI [10.1016/j.neuropsychologia.2003.12.0153[21]A, DOI 10.1016/J.NEUROPSYCHOLOGIA.2003.12.0153[21]A]
   Salagean E., Meetingyour virtual twin: Effects of photorealism and personalization on embod-\n[1]K
   Samuelkamaleshkumar S, 2014, ARCH PHYS MED REHAB, V95, P2000, DOI 10.1016/j.apmr.2014.06.020
   Shapi'i A, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/493562
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Stippich C, 2002, NEUROSCI LETT, V331, P50, DOI 10.1016/S0304-3940(02)00826-1
   Studios B., 2022, Unity's Asset Store., P4
   Thieme H, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008449.pub3
   Torres-Parada M., 2020, Nrazilian Journal of Physical Therapy., DOI 10.1016.bjpt.2019.02.0101
   Unity Technologies, 2020, Animation Rigging., P4
   Vural SP, 2016, ARCH PHYS MED REHAB, V97, P575, DOI 10.1016/j.apmr.2015.12.008
   Wittkopf PG, 2017, REV ASSOC MED BRAS, V63, P1000, DOI 10.1590/1806-9282.63.11.1000
   Xu Q, 2017, CLIN REHABIL, V31, P1583, DOI 10.1177/0269215517705689
   Zhu Y, 2013, NEURAL REGEN RES, V8, P2389, DOI 10.3969/j.issn.1673-5374.2013.25.010
NR 33
TC 0
Z9 0
U1 10
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2390
EP 2399
DI 10.1109/TVCG.2024.3372035
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400027
PM 38437102
DA 2024-11-06
ER

PT J
AU Chandio, Y
   Interrante, V
   Anwar, FM
AF Chandio, Yasra
   Interrante, Victoria
   Anwar, Fatima M.
TI Human Factors at Play: Understanding the Impact of Conditioning on
   Presence and Reaction Time in Mixed Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed Reality; Presence; Conditioning
ID VIRTUAL-REALITY; WORKING-MEMORY; EXPERIENCE; TASK; INFORMATION; BEHAVIOR
AB A prerequisite to improving the presence of a user in mixed reality (MR) is the ability to measure and quantify presence. Traditionally, subjective questionnaires have been used to assess the level of presence. However, recent studies have shown that presence is correlated with objective and systemic human performance measures such as reaction time. These studies analyze the correlation between presence and reaction time when technical factors such as object realism and plausibility of the object's behavior change. However, additional psychological and physiological human factors can also impact presence. It is unclear if presence can be mapped to and correlated with reaction time when human factors such as conditioning are involved. To answer this question, we conducted an exploratory study (N=60) where the relationship between presence and reaction time was assessed under three different conditioning scenarios: control, positive, and negative. We demonstrated that human factors impact presence. We found that presence scores and reaction times are significantly correlated (correlation coefficient of -0.64), suggesting that the impact of human factors on reaction time correlates with its effect on presence. In demonstrating that, our study takes another important step toward using objective and systemic measures like reaction time as a presence measure.
C1 [Chandio, Yasra; Anwar, Fatima M.] Univ Massachusetts Amherst, Amherst, MA 01003 USA.
   [Interrante, Victoria] Univ Minnesota Twin Cities, Minneapolis, MN USA.
C3 University of Massachusetts System; University of Massachusetts Amherst;
   University of Minnesota System; University of Minnesota Twin Cities
RP Chandio, Y (corresponding author), Univ Massachusetts Amherst, Amherst, MA 01003 USA.
EM ychandio@umass.edu; interran@umn.edu; fanwar@umass.edu
OI Chandio, Yasra/0000-0002-3436-6452; Interrante,
   Victoria/0000-0002-3313-6663; Anwar, Fatima/0000-0001-7119-7232
FU NSF
FX No Statement Available
CR [Anonymous], Hololens 2
   [Anonymous], Intractable objects.
   [Anonymous], 2000, PhD thesis
   [Anonymous], Microsoft spatializer.
   Barfield S., 1993, Advances in Human FactorsErgonomics, V19
   BARGH JA, 1982, J PERS SOC PSYCHOL, V43, P437, DOI 10.1037/0022-3514.43.3.437
   Basdogan C.-H., 2000, ACMTransactions on Computer-Human Interaction, V7
   Baumgartner T, 2006, CYBERPSYCHOL BEHAV, V9, P30, DOI 10.1089/cpb.2006.9.30
   Benford S., 1998, ACM Transactions on Computer-Human Interaction, V5, P185, DOI 10.1145/292834.292836
   Berch DB, 1998, BRAIN COGNITION, V38, P317, DOI 10.1006/brcg.1998.1039
   Botella C, 2017, CURR PSYCHIAT REP, V19, DOI 10.1007/s11920-017-0788-4
   Bracken C., 2010, Journal of Media Psychology
   Bruce M, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P179, DOI 10.1109/VR.2009.4811020
   Chandio Y, 2024, IEEE T VIS COMPUT GR, V30, P5976, DOI 10.1109/TVCG.2023.3319563
   Colomb B., T. D.
   Cook T. D., 1979, QUASIEXPERIMENTATION, V351
   de Kort YAW, 2006, J ENVIRON PSYCHOL, V26, P309, DOI 10.1016/j.jenvp.2006.09.001
   de Tinguy X, 2019, 2019 IEEE WORLD HAPTICS CONFERENCE (WHC), P580, DOI [10.1109/whc.2019.8816164, 10.1109/WHC.2019.8816164]
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Feng J, 2007, PSYCHOL SCI, V18, P850, DOI 10.1111/j.1467-9280.2007.01990.x
   Festinger L., 1957, SELECTIVE EXPOSURE T, V16, P3, DOI DOI 10.1146/annurev.ecolsys.35.021103.105711
   Freeman J, 2000, PRESENCE-TELEOP VIRT, V9, P149, DOI 10.1162/105474600566691
   Freeman J, 1999, PRESENCE-TELEOP VIRT, V8, P1, DOI 10.1162/105474699566017
   Gaggioli A, 2003, EMERG COMMUNICAT, V5, P121
   Gandy R., 2010, IEEE INT S MIX AUG R
   Giesel M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78378-z
   Glotzbach-Schoon E., 2013, e-Neuroforum, V4, P63
   GRAHAM FK, 1992, ATTENTION AND INFORMATION PROCESSING IN INFANTS AND ADULTS, P3
   Grassini K., 2020, Frontiers in Psychol, V11
   Green CS, 2003, NATURE, V423, P534, DOI 10.1038/nature01647
   Grillon C, 2006, BIOL PSYCHIAT, V60, P752, DOI 10.1016/j.biopsych.2006.03.072
   Hansberger JT, 2017, LECT NOTES COMPUT SC, V10280, P505, DOI 10.1007/978-3-319-57987-0_41
   Jamalian N, 2022, INT SYM MIX AUGMENT, P768, DOI 10.1109/ISMAR55827.2022.00095
   Jang Y, 2019, TELEMAT INFORM, V42, DOI 10.1016/j.tele.2019.101239
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jicol C. H., 2021, P 2021 CHI C HUM FAC, P1
   Jicol Crescent, 2023, P 2023 CHI C HUM FAC, P1
   Kahneman P.S. Daniel., 1982, JUDGMENT UNCERTAINTY
   Kane MJ, 2007, J EXP PSYCHOL LEARN, V33, P615, DOI 10.1037/0278-7393.33.3.615
   Kazdin AE, 2003, J CHILD PSYCHOL PSYC, V44, P1116, DOI 10.1111/1469-7610.00195
   Kim T. H., 2021, Electronics, V10
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Latoschik C., 2022, Frontiers in Virtual Reality, V3
   Ling Y, 2013, COMPUT HUM BEHAV, V29, P1519, DOI 10.1016/j.chb.2012.12.010
   Lombard M., 1997, Journal of Computer-Mediated Communication, V3, pJCMC321, DOI 10.1111/j.1083-6101.1997.tb00072.x
   Meehan M, 2002, ACM Trans-actions on Graphics, V21
   Microsoft, 2023, Types of Mixed Reality Apps
   Microsoft, 2023, Direct hand manipulation in hololens2
   Milgram H., 1995, SPIE
   Nesbitt K, 2017, DISPLAYS, V48, P1, DOI 10.1016/j.displa.2017.01.002
   Nunez D, 2004, P 3 INT C COMP GRAPH
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Paes D, 2021, AUTOMAT CONSTR, V130, DOI 10.1016/j.autcon.2021.103849
   Pavlov IP, 2010, ANN NEUROSCI, V17, P136, DOI 10.5214/ans.0972-7531.1017309
   Pimentel D, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.634520
   Prothero D.E., 1995, P C EXP MEAS SIT AW
   Putze D., 2020, P 2020 CHI C HUM FAC
   Regenbrecht H, 2021, Arxiv, DOI arXiv:2103.02831
   Rescorla R.A., 1972, PSYCHOL LEARNING MOT, V6, P1
   Riva F., 2003, Being there: Concepts,effects and measurement of user presence in synthetic environments, V5, P62
   Rizzolatti G, 2004, ANNU REV NEUROSCI, V27, P169, DOI 10.1146/annurev.neuro.27.070203.144230
   Safikhani S, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489884
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schubert T W., 2003, Zeitschrift fur Medienpsychologie, V15
   Schwind V, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300590
   Schwind V, 2017, CHI PLAY'17: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P507, DOI 10.1145/3116595.3116596
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sheridan ThomasB., 1992, Presence Teleoperators Virtual Environ, V1
   Skinner BF., 1938, The Behavior of Organisms: An Experimental Analysis
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., 1999, EUR WORKSH VIRT ENV
   Slater M., 1995, ACM Transactionson Computer-Human Interaction, V2
   Slater M, 2009, PHILOS T R SOC B, V364, P3549, DOI 10.1098/rstb.2009.0138
   Slater V., 1996, P ACM S VIRT REAL SO
   Steed Y., 2016, InIEEE Virtual Reality
   Steuer J., 1995, Communication in the age of virtual reality, V33, P37
   Stevens B, 2002, PRESENCE-TELEOP VIRT, V11, P79, DOI 10.1162/105474602317343677
   Stevens J., 2000, INT WORKSH HAPT COMP
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Szczurowski M., 2017, 23 INT C VIRT SYST M
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   Vroom V.H., 1964, Work and motivation
   Wagner W., 2009, Presence, V18
   Weech S, 2020, INT J HUM-COMPUT ST, V138, DOI 10.1016/j.ijhcs.2020.102398
   Westermeier F., 2022, IEEE Transactions on Visualization andComputer Graphics, V28
   Westermeier F, 2023, IEEE T VIS COMPUT GR, V29, P2680, DOI 10.1109/TVCG.2023.3247046
   Wienrich P., 2021, Frontiers in Virtual Reality, V2
   Wiesing M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231152
   Wilson S., 1997, InHCI
   Witmer M. J., 1998, Presence: Teleoperators & VirtualEnvironments, V7
   Zimmons P, 2003, P IEEE VIRT REAL ANN, P293, DOI 10.1109/VR.2003.1191170
NR 95
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2400
EP 2410
DI 10.1109/TVCG.2024.3372120
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400030
PM 38437088
DA 2024-11-06
ER

PT J
AU Gao, BY
   Shao, T
   Tu, HW
   Ma, QZ
   Liu, ZT
   Han, T
AF Gao, Bo Yu
   Shao, Tong
   Tu, Huawei
   Ma, Qizi
   Liu, Zitao
   Han, Teng
TI Exploring Bimanual Haptic Feedback for Spatial Search in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Bimanual Haptic Feedback; Spatial Search; Controllers; Virtual Reality
ID DISPLAY; DESIGN; GUIDANCE
AB Spatial search tasks are common and crucial in many Virtual Reality (VR) applications. Traditional methods to enhance the performance of spatial search often employ sensory cues such as visual, auditory, or haptic feedback. However, the design and use of bimanual haptic feedback with two VR controllers for spatial search in VR remains largely unexplored. In this work, we explored bimanual haptic feedback with various combinations of haptic properties, where four types of bimanual haptic feedback were designed, for spatial search tasks in VR. Two experiments were designed to evaluate the effectiveness of bimanual haptic feedback on spatial direction guidance and search in VR. The results from the first experiment reveal that our proposed bimanual haptic schemes significantly enhanced the recognition of spatial directions in terms of accuracy and speed compared to spatial audio feedback. The second experiment's findings suggest that the performance of bimanual haptic feedback was comparable to or even better than the visual arrow, especially in reducing the angle of head movement and enhancing searching targets behind the participants, which was supported by subjective feedback as well. Based on these findings, we have derived a set of design recommendations for spatial search using bimanual haptic feedback in VR.
C1 [Gao, Bo Yu; Shao, Tong; Ma, Qizi; Liu, Zitao] Jinan Univ, Guangzhou, Peoples R China.
   [Tu, Huawei] La Trobe Univ, Melbourne, Australia.
   [Han, Teng] Chinese Acad Sci, Inst Software, Beijing, Peoples R China.
   [Han, Teng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
C3 Jinan University; La Trobe University; Chinese Academy of Sciences;
   Institute of Software, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Gao, BY (corresponding author), Jinan Univ, Guangzhou, Peoples R China.; Tu, HW (corresponding author), La Trobe Univ, Melbourne, Australia.
EM bygao@jnu.edu.cn; shaot@stu2021.jnu.edu.cn; h.tu@latrobe.edu.au;
   202334511026@stu.jnu.edu.cn; liuzitao@jnu.edu.cn; hanteng@iscas.ac.cn
RI Gao, Boyu/JNE-3525-2023
OI Gao, BoYu/0000-0001-8523-2828; Tu, Huawei/0000-0001-9689-9767
FU National Key R&D Program of China
FX No Statement Available
CR Azadi M, 2014, IEEE T HAPTICS, V7, P14, DOI 10.1109/TOH.2013.2296051
   Bala P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300925
   Bark K, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P71
   Beattie D, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P189, DOI 10.1145/2639189.2641206
   Bial D., 2011, CHI'11, P1273, DOI DOI 10.1145/1979742.1979760
   Binetti N, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102032
   Boll S, 2011, IEEE PERVAS COMPUT, V10, P35, DOI 10.1109/MPRV.2011.39
   Bork F, 2018, IEEE T VIS COMPUT GR, V24, P2983, DOI 10.1109/TVCG.2018.2868584
   Boukhris Sabrine, 2017, Human-Computer Interaction: Interaction Contexts. 19th International Conference, held as part of HCI International 2017. Proceedings: LNCS 10272, P35, DOI 10.1007/978-3-319-58077-7_3
   Brown C, 2017, P IEEE VIRT REAL ANN, P377, DOI 10.1109/VR.2017.7892334
   Chang HY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P927, DOI 10.1145/3242587.3242588
   Chen TZ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281516
   Choi S, 2013, P IEEE, V101, P2093, DOI 10.1109/JPROC.2012.2221071
   Cosgun A, 2014, IEEE INT CONF ROBOT, P6350, DOI 10.1109/ICRA.2014.6907796
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   Elsayed H, 2023, PROCEEDINGS OF THE 4TH AUGMENTED HUMANS INTERNATIONAL CONFERENCE 2023, AHS2023, P35, DOI 10.1145/3582700.3582701
   Erp JBV., 2005, ACM T APPL PERCEPT, V2, P106, DOI DOI 10.1145/1060581.1060585
   Gao BY, 2021, J SYST ARCHITECT, V117, DOI 10.1016/j.sysarc.2021.102096
   Gao B, 2019, INT J HUM-COMPUT INT, V35, P831, DOI 10.1080/10447318.2018.1498654
   Gao B, 2018, INT CONF BIG DATA, P475, DOI 10.1109/BigComp.2018.00076
   García-Valle G, 2016, LECT NOTES COMPUT SC, V9775, P251, DOI 10.1007/978-3-319-42324-1_25
   Geronazzo M, 2016, INT J HUM-COMPUT ST, V85, P4, DOI 10.1016/j.ijhcs.2015.08.004
   Günther S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P273, DOI 10.1145/3197768.3197785
   HART S G, 1988, P139
   Hulin Thomas, 2011, IEEE International Conference on Robotics and Automation, P3441
   Jones LA, 2008, HUM FACTORS, V50, P90, DOI 10.1518/001872008X250638
   Kaul OB, 2017, LECT NOTES COMPUT SC, V10516, P289, DOI 10.1007/978-3-319-68059-0_19
   Kaul OB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3729, DOI 10.1145/3025453.3025684
   Kiss F, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174191
   Kron A, 2004, IEEE INT CONF ROBOT, P1968, DOI 10.1109/ROBOT.2004.1308112
   Lange D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376803
   Lindeman R. W., 2006, Virtual Reality, V9, P203, DOI DOI 10.1007/S10055-005-0010-6
   Lindeman R.W., 2005, CHI'05, P271, DOI DOI 10.1145/1054972.1055010
   Marquardt A, 2020, IEEE T VIS COMPUT GR, V26, P3389, DOI 10.1109/TVCG.2020.3023605
   Meier A., 2015, P 2 INT WORKSHOP SEN, P1
   Meli L, 2014, IEEE T BIO-MED ENG, V61, P1318, DOI 10.1109/TBME.2014.2303052
   Meshram A, 2014, INT SYM MIX AUGMENT, P53, DOI 10.1109/ISMAR.2014.6948409
   Meshram VV, 2019, IEEE T HUM-MACH SYST, V49, P449, DOI 10.1109/THMS.2019.2931745
   Minamizawa K, 2008, LECT NOTES COMPUT SC, V5024, P458, DOI 10.1007/978-3-540-69057-3_59
   Mirzaei M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222794
   Morioka M, 2006, J SOUND VIB, V295, P633, DOI 10.1016/j.jsv.2006.01.029
   Murayama J., 2004, P EUROHAPTICS 2004, P138
   Nonino E, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR-Adjunct54149.2021.00070
   Nukarinen T, 2015, 2015 IEEE WORLD HAPTICS CONFERENCE (WHC), P345, DOI 10.1109/WHC.2015.7177736
   Oliveira VAD, 2014, LECT NOTES COMPUT SC, V8619, P104, DOI 10.1007/978-3-662-44196-1_14
   Oliveira VAD, 2014, LECT NOTES COMPUT SC, V8618, P309, DOI 10.1007/978-3-662-44193-0_39
   Panëels S, 2013, 2013 WORLD HAPTICS CONFERENCE (WHC), P407, DOI 10.1109/WHC.2013.6548443
   Peer A, 2008, IEEE-ASME T MECH, V13, P416, DOI 10.1109/TMECH.2008.2001690
   Peiris RL, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300400
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Plaisier Myrthe A., 2012, Haptics: Perception, Devices, Mobility, and Communication. Proceedings International Conference (EuroHaptics 2012), P127, DOI 10.1007/978-3-642-31404-9_22
   Prouzeau A, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300555
   Renner P, 2017, IEEE SYMP 3D USER, P186, DOI 10.1109/3DUI.2017.7893338
   Ro H, 2017, IEEE SYS MAN CYBERN, P2873, DOI 10.1109/SMC.2017.8123063
   Rothe S, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3143421
   Ryu N., 2021, P 2021 CHI C HUMAN F, P1
   Schmitz A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P63, DOI [10.1109/VR46266.2020.00-80, 10.1109/VR46266.2020.1581102716289]
   Sherrick C., 1991, The psychology of touch, P189
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Song Q., 2022, CHI C HUMAN FACTORS, P1
   Strasnick E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174218
   Talvas A, 2014, IEEE T HAPTICS, V7, P285, DOI 10.1109/TOH.2014.2314456
   Tan H., 2003, A haptic back display for attentional and directional cueing
   Tan HZ, 2010, IEEE T HAPTICS, V3, P98, DOI [10.1109/TOH.2009.46, 10.1109/ToH.2009.46]
   Ternes D, 2008, LECT NOTES COMPUT SC, V5024, P199, DOI 10.1007/978-3-540-69057-3_24
   Tsai HR, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445262
   Turchet L, 2013, IEEE T HAPTICS, V6, P35, DOI [10.1109/TOH.2012.51, 10.1109/ToH.2012.51]
   Unity, Xr interaction toolkit
   van Erp J. B., 2007, TACTILE DISPLAYS NAV
   Velázquez R, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040578
   Wagner U, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581423
   Wallgrün JO, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P83, DOI [10.1109/VR46266.2020.00-78, 10.1109/VR46266.2020.1581092881445]
   Wang D., 2006, Computational Auditory Scene Analysis: Principles, Algorithms, and Applications
   Wang Y., 2020, P 2020 CHI C HUMAN F, P1
   Wang YL, 2016, INT J HUM-COMPUT ST, V89, P24, DOI 10.1016/j.ijhcs.2016.01.004
   Way T P, 1997, IEEE Trans Rehabil Eng, V5, P81, DOI 10.1109/86.559353
   Wenbai Xue, 2022, Cross-Cultural Design. Applications in Learning, Arts, Cultural Heritage, Creative Industries, and Virtual Reality: 14th International Conference, CCD 2022, Held as Part of the 24th HCI International Conference, HCII 2022, Proceedings. Lecture Notes in Computer Science (13312), P520, DOI 10.1007/978-3-031-06047-2_39
   WENZEL EM, 1993, J ACOUST SOC AM, V94, P111, DOI 10.1121/1.407089
   Wightman F.L., 1997, BINAURAL SPATIAL HEA, P1
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yamazaki Y, 2023, Symposium Virtual Re, P276, DOI 10.1109/VR55154.2023.00043
   Yoshimura A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1255, DOI 10.1109/vr.2019.8798327
NR 82
TC 0
Z9 0
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2422
EP 2433
DI 10.1109/TVCG.2024.3372045
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400032
PM 38437136
DA 2024-11-06
ER

PT J
AU Do, TD
   Protko, CI
   Mcmahan, RP
AF Do, Tiffany D.
   Protko, Camille Isabella
   Mcmahan, Ryan P.
TI Stepping into the Right Shoes: The Effects of User-Matched Avatar
   Ethnicity and Gender on Sense of Embodiment in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; User experience; Statistics; Sociology; Particle measurements;
   Games; Atmospheric measurements; Virtual reality; sense of embodiment;
   avatars; diversity
ID BODY; IMPACT; REPRESENTATION
AB In many consumer virtual reality (VR) applications, users embody predefined characters that offer minimal customization options, frequently emphasizing storytelling over user choice. We explore whether matching a user's physical characteristics, specifically ethnicity and gender, with their virtual self-avatar affects their sense of embodiment in VR. We conducted a 2 x 2 within-subjects experiment (n = 32) with a diverse user population to explore the impact of matching or not matching a user's self-avatar to their ethnicity and gender on their sense of embodiment. Our results indicate that matching the ethnicity of the user and their self-avatar significantly enhances sense of embodiment regardless of gender, extending across various aspects, including appearance, response, and ownership. We also found that matching gender significantly enhanced ownership, suggesting that this aspect is influenced by matching both ethnicity and gender. Interestingly, we found that matching ethnicity specifically affects self-location while matching gender specifically affects one's body ownership.
C1 [Do, Tiffany D.; Protko, Camille Isabella; Mcmahan, Ryan P.] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Do, TD (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.
EM tiffany.do@ucf.edu; ca916041@ucf.edu; rpm@ucf.edu
OI Do, Tiffany D./0000-0003-3323-4586; McMahan, Ryan/0000-0001-9357-9696
FU The University of Central Florida
FX No Statement Available
CR Ambron E, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.884189
   Aseeri S, 2021, IEEE T VIS COMPUT GR, V27, P2608, DOI 10.1109/TVCG.2021.3067783
   Ash E, 2016, GAMES CULT, V11, P422, DOI 10.1177/1555412014568870
   Bartl A, 2022, INT SYM MIX AUGMENT, P260, DOI 10.1109/ISMAR55827.2022.00041
   Chang F, 2019, CYBERPSYCH BEH SOC N, V22, P634, DOI 10.1089/cyber.2019.0106
   Chen VHH, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5080042
   Cheymol A, 2023, IEEE T VIS COMPUT GR, V29, P4426, DOI 10.1109/TVCG.2023.3320209
   Dewez D, 2019, INT SYM MIX AUGMENT, P123, DOI 10.1109/ISMAR.2019.00-12
   Do TD, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1248915
   Döllinger N, 2023, INT SYM MIX AUGMENT, P483, DOI 10.1109/ISMAR59233.2023.00063
   Eubanks JC, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.647896
   Eubanks JC, 2020, INT SYM MIX AUGMENT, P54, DOI 10.1109/ISMAR50242.2020.00025
   Fiedler ML, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P799, DOI 10.1109/VRW58643.2023.00242
   Freeman Guo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432938
   Fribourg R, 2020, IEEE T VIS COMPUT GR, V26, P2062, DOI 10.1109/TVCG.2020.2973077
   Fribourg R, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P273, DOI 10.1109/VR.2018.8448293
   Gonzalez-Franco M, 2020, IEEE T VIS COMPUT GR, V26, P2023, DOI 10.1109/TVCG.2020.2973075
   Gonzalez-Franco M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P941, DOI [10.1109/VR.2019.8798348, 10.1109/vr.2019.8798348]
   Herrera F, 2021, NEW MEDIA SOC, V23, P2189, DOI 10.1177/1461444821993121
   Jo D, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3141214
   Juliano JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041204
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Kilteni K, 2012, PRESENCE-TELEOP VIRT, V21, P373, DOI 10.1162/PRES_a_00124
   Kim H, 2023, IEEE T VIS COMPUT GR, V29, P4794, DOI 10.1109/TVCG.2023.3320240
   Latoschik ME, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139156
   Lopez S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300787
   Lugrin JL, 2015, P IEEE VIRT REAL ANN, P225, DOI 10.1109/VR.2015.7223377
   Mal D, 2023, IEEE T VIS COMPUT GR, V29, P2358, DOI 10.1109/TVCG.2023.3247089
   Marini M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.989582
   Maselli A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00083
   Ome M.T., 2009, Artifacts in Behavioral Research, P110
   Peck TC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376419
   Peck TC, 2021, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.575943
   Peck TC, 2018, IEEE T VIS COMPUT GR, V24, P1604, DOI 10.1109/TVCG.2018.2793598
   Peck TC, 2013, CONSCIOUS COGN, V22, P779, DOI 10.1016/j.concog.2013.04.016
   Pohl H, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.719506
   Radiah R, 2023, MULTIMODAL TECHNOLOG, V7, DOI 10.3390/mti7040038
   Ries V., 2009, P 16 ACM S VIRT REAL, P59, DOI [10.1145/1643928.16439433, DOI 10.1145/1643928.16439433, DOI 10.1145/1643928.1643943]
   Rosenblum LD, 1996, J EXP PSYCHOL HUMAN, V22, P318, DOI 10.1037/0096-1523.22.2.318
   Roth D, 2020, IEEE T VIS COMPUT GR, V26, P3546, DOI 10.1109/TVCG.2020.3023603
   Salagean A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581182
   Salmanowitz N, 2018, J LAW BIOSCI, V5, P174, DOI 10.1093/jlb/lsy005
   Schulze S, 2019, LECT NOTES COMPUT SC, V11574, P361, DOI 10.1007/978-3-030-21607-8_28
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Seitz KR, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P607, DOI [10.1109/VRW50115.2020.00154, 10.1109/VRW50115.2020.0-121]
   Spanlang B, 2014, FRONT ROBOT AI, DOI 10.3389/frobt.2014.00009
   Tsakiris M, 2006, CONSCIOUS COGN, V15, P423, DOI 10.1016/j.concog.2005.09.004
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Wu LF, 2024, HUM FACTORS, V66, P1504, DOI 10.1177/00187208221145264
NR 50
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2434
EP 2443
DI 10.1109/TVCG.2024.3372067
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400073
PM 38437125
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Xu, SZ
   Huang, K
   Fan, CW
   Zhang, SH
AF Xu, Sen-Zhe
   Huang, Kui
   Fan, Cheng-Wei
   Zhang, Song-Hai
TI Spatial Contraction Based on Velocity Variation for Natural Walking in
   Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Contracts; Visualization; Aerospace electronics;
   Virtual environments; Three-dimensional displays; Space stations;
   Virtual reality; spatial contraction; locomotion; redirected walking;
   velocity
ID SPEED
AB Virtual Reality (VR) offers an immersive 3D digital environment, but enabling natural walking sensations without the constraints of physical space remains a technological challenge. Previous VR locomotion methods, including game controller, teleportation, treadmills, walking-in-place, and redirected walking (RDW), have made strides towards overcoming this challenge. However, these methods also face limitations such as possible unnaturalness, additional hardware requirements, or motion sickness risks. This paper introduces "Spatial Contraction (SC)", an innovative VR locomotion method inspired by the phenomenon of Lorentz contraction in Special Relativity. Similar to the Lorentz contraction, our SC contracts the virtual space along the user's velocity direction in response to velocity variation. The virtual space contracts more when the user's speed is high, whereas minimal or no contraction happens at low speeds. We provide a virtual space transformation method for spatial contraction and optimize the user experience in smoothness and stability. Through SC, VR users can effectively traverse a longer virtual distance with a shorter physical walking. Different from locomotion gains, the spatial contraction effect is observable by the user and aligns with their intentions, so there is no inconsistency between the user's proprioception and visual perception. SC is a general locomotion method that has no special requirements for VR scenes. The experimental results of our live user studies in various virtual scenarios demonstrate that SC has a significant effect in reducing both the number of resets and the physical walking distance users need to cover. Furthermore, experiments have also demonstrated that SC has the potential for integration with existing locomotion techniques such as RDW.
C1 [Xu, Sen-Zhe; Huang, Kui; Fan, Cheng-Wei; Zhang, Song-Hai] Tsinghua Univ, Beijing, Peoples R China.
   [Zhang, Song-Hai] Qinghai Univ, Qinghai, Peoples R China.
C3 Tsinghua University; Qinghai University
RP Xu, SZ (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM xsz15@tsinghua.org.cn; huangk21@mails.tsinghua.edu.cn;
   fcw20@mails.tsinghua.edu.cn; shz@tsinghua.edu.cn
OI Xu, Sen-Zhe/0000-0003-2669-7814; Huang, Kui/0009-0005-5411-581X
FU National Key Research and Development Program of China
FX No Statement Available
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Al Zayer M, 2020, IEEE T VIS COMPUT GR, V26, P2315, DOI 10.1109/TVCG.2018.2887379
   Anderson FC, 2001, J BIOMECH ENG-T ASME, V123, P381, DOI 10.1115/1.1392310
   ANDRIACCHI TP, 1977, J BIOMECH, V10, P261, DOI 10.1016/0021-9290(77)90049-5
   Azmandian T., Physical SpaceRequirements for Redirected Walking: How Size and Shape Affect Per-formance
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Boletsis C, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6090072
   Bozgeyikli E, 2019, INT J HUM-COMPUT ST, V122, P38, DOI 10.1016/j.ijhcs.2018.08.002
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cakmak H., INACM SIGGRAPH 2014, DOI [10.1145/2614066.26141052[11]Z.-Y, DOI 10.1145/2614066.26141052[11]Z.-Y]
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Cherni N., 2020, International Journal of Virtual Reality, DOI [10.20870/IJVR.2020.20.1.31832,3,6[13]C, DOI 10.20870/IJVR.2020.20.1.31832,3,6[13]C]
   Ciumedean C, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P389, DOI 10.1109/VRW52623.2021.00081
   Darken W. R., 1997, INACM SYMPOSIUMNON U, DOI [10.1145/263407.2635503, DOI 10.1145/263407.2635503]
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Han J, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P167, DOI 10.1109/VR51125.2022.00035
   Interrante B., 2007, IN2007 IEEE S 3D USE, DOI [10.1109/3DUI.2007.3407913[21]R.S., DOI 10.1109/3DUI.2007.3407913[21]R.S]
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kim D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P379, DOI 10.1109/VR51125.2022.00057
   Lai CY, 2020, INT SYM MIX AUGMENT, P627, DOI 10.1109/ISMAR50242.2020.00091
   LaViola Jr E., 2017, Addison-Wesley Professional, V2
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Liu J, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P521, DOI 10.1145/3242587.3242601
   Lugrin JL, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364780
   Martinez ES, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P270, DOI 10.1109/VR51125.2022.00046
   Marwecki P., 2018, InUser Interface Software andTechnology, DOI [10.1145/3242587.32426483[32]D, DOI 10.1145/3242587.32426483[32]D]
   Medeiros D, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P327, DOI 10.1145/2993369.2996348
   Medina R., 2008, P HUMAN FACTORS ERGO, P3, DOI [10.1177/1541931208052027043[34]J, DOI 10.1177/1541931208052027043[34]J]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Mohler B., 2015, ICAT EGVE2015 INT C, DOI [10.2312/egve.201513152,6[6]E.R, DOI 10.2312/EGVE.201513152,6[6]E.R]
   Nescher T, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P15, DOI 10.1109/CW.2012.10
   Selzer MN, 2022, VIRTUAL REAL-LONDON, V26, P1459, DOI 10.1007/s10055-022-00640-8
   Peck TC, 2011, P IEEE VIRT REAL ANN, P55, DOI 10.1109/VR.2011.5759437
   Prinz T., 2022, IEEE transactions on visualizationand computer graphics, DOI [10.1109/TVCG.2022.32069152,6[38]S, DOI 10.1109/TVCG.2022.32069152,6[38]S]
   Pyo H., 2021, Ap-plied Sciences, V11, DOI [10.3390/app110942233[39]Y.Y., DOI 10.3390/APP110942233[39]Y.Y]
   Qian YY, 2016, SUI'18: PROCEEDINGS OF THE 2018 SYMPOSIUM ON SPATIAL USER INTERACTION, P130, DOI 10.1145/3267782.3267798
   Razzaque Z., 2001, InEurographics 2001 - Short Presentations, DOI [10.2312/egs.200110362[41]B.E., DOI 10.2312/EGS.200110362[41]B.E]
   Riecke D., 2021, IN2021 IEEE C VIRTUA, DOI [10.1109/vrw52623.2021.000752[42]M.M., DOI 10.1109/VRW52623.2021.000752[42]M.M]
   Samson MM, 2001, AGING CLIN EXP RES, V13, P16, DOI 10.1007/BF03351489
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke G., 2009, JVRB-Journal of Virtual Reality and Broadcasting, V6, DOI [10.20385/1860-2037/6.2009.22,6[46]F, DOI 10.20385/1860-2037/6.2009.22,6[46]F]
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Waller D, 2007, BEHAV RES METHODS, V39, P835, DOI 10.3758/BF03192976
   Wang Z.-Y., 2022, IEEE Transac-tions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32240733[55]L.E., DOI 10.1109/TVCG.2022.32240733[55]L.E]
   Warren LE, 2017, SUI'17: PROCEEDINGS OF THE 2017 SYMPOSIUM ON SPATIAL USER INTERACTION, P163, DOI 10.1145/3131277.3134359
   Xu SZ, 2024, IEEE T VIS COMPUT GR, V30, P1916, DOI 10.1109/TVCG.2023.3251648
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P2080, DOI 10.1109/TVCG.2021.3139990
NR 58
TC 0
Z9 0
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2444
EP 2453
DI 10.1109/TVCG.2024.3372109
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400025
PM 38437083
DA 2024-11-06
ER

PT J
AU Chen, JJ
   Hung, HC
   Sun, YR
   Chuang, JH
AF Chen, Jun-Jie
   Hung, Huan-Chang
   Sun, Yu-Ru
   Chuang, Jung-Hong
TI APF-S2T: Steering to Target Redirection Walking Based on Artificial
   Potential Fields
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Aerospace electronics; Virtual environments; Force;
   Vectors; Layout; Robots; Redirected walking; artificial potential field;
   locomotion; virtual reality
AB Redirected walking (RDW) enables users to walk naturally within a virtual environment that is larger than the physical environment. Recently, several artificial potential field (APF) and alignment-based redirected controllers have been developed and have been demonstrated to significantly outperform conventional controllers. APF Steer-to-Gradient (APF-S2G) and APF Redirected Walking (APF-RDW) utilize the negative gradient and the total force vector, respectively, which are localized to the user's position. These vectors usually point towards the opposite wall when the user is in corridors, resulting in frequent resets within those regions. This paper introduces the APF Steer-to-Target (APF-S2T), a redirected controller that first finds the target sample point with the lowest score in the user's walkable area in both physical and virtual environments. The score of a sample point is determined by the APF value at the point and the distance from the user's position. The direction from the user's position to the target point is then used as the steering direction for setting RDW gains. We conducted a simulation-based evaluation to compare APF-S2T, APF-S2G, APF-RDW, Visibility Polygon-based alignment (Vis.-Poly.) and Alignment-Optimized controllers in terms of the number of resets and the average distance between resets. The results indicated that APF-S2T significantly outperformed the state-of-the-art controllers.
C1 [Chen, Jun-Jie; Hung, Huan-Chang; Sun, Yu-Ru; Chuang, Jung-Hong] Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, JJ (corresponding author), Natl Yang Ming Chiao Tung Univ, Hsinchu, Taiwan.
EM jay8832791@gmail.com; hchung.cs10@nycu.edu.tw;
   yuru1219.cs11@nycu.edu.tw; jhchuang@cs.nycu.edu.tw
FU National Science and Technology Council, R.O.C.
FX No Statement Available
CR [Anonymous], 2024, HMD geometry database
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2277, DOI 10.1109/TVCG.2022.3150500
   Azmandian M, 2022, IEEE T VIS COMPUT GR, V28, P2288, DOI 10.1109/TVCG.2022.3150466
   Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Azmandian Mahdi, 2015, ICAT EGVE, DOI DOI 10.2312/EGVE.20151315
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Croucher C, 2024, IEEE T VIS COMPUT GR, V30, P5765, DOI 10.1109/TVCG.2023.3313439
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Fan CW, 2023, Symposium Virtual Re, P53, DOI 10.1109/VR55154.2023.00021
   Hirt Y., 2022, IN2022 IEEECONFERENC
   Hodgson E, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043604
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kwon SU, 2022, INT SYM MIX AUGMENT, P758, DOI 10.1109/ISMAR55827.2022.00094
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Nescher T, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P111, DOI 10.1109/3DUI.2014.6798851
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Peck TC, 2010, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2010.5444816
   Razzaque Z., 2001, InProceedings of Eurographics, V1, P2
   Ruddle RA, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1970378.1970384
   Ruddle RA, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1502800.1502805
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Suri S., 1986, 2 S COMPUTATIONAL GE, P14, DOI DOI 10.1145/10515.10517
   Thomas C. Hutton, 2020, INPROCEEDINGS 26 ACM, DOI [10.1145/3385956.34189663[33]J, DOI 10.1145/3385956.34189663[33]J]
   Thomas J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P317, DOI [10.1109/VRW50115.2020.00071, 10.1109/VRW50115.2020.0-205]
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Williams B, 2007, APGV 2007: SYMPOSIUM ON APPLIED PERCEPTION IN GRAPHICS AND VISUALIZATION, PROCEEDINGS, P41
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Wu XL, 2023, IEEE T VIS COMPUT GR, V29, P4556, DOI 10.1109/TVCG.2023.3320208
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   Xu SZ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P655, DOI 10.1109/VR51125.2022.00086
   Zanbaka B. C., 2005, IEEE Transactions on Visualizationand Computer Graphics, V11, P1
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 43
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2464
EP 2473
DI 10.1109/TVCG.2024.3372052
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400061
PM 38437126
DA 2024-11-06
ER

PT J
AU Lee, HJ
   Jeon, SB
   Cho, YH
   Lee, IK
AF Lee, Ho Jung
   Jeon, Sang-Bin
   Cho, Yong-Hun
   Lee, In-Kwon
TI Redirection Strategy Switching: Selective Redirection Controller for
   Dynamic Environment Adaptation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Redirected walking; Reinforcement learning
AB In this paper, we present the Selective Redirection Controller (SRC), which selects the optimal redirection controller based on the physical and virtual environment in Redirected Walking (RDW). The primary advantage of SRC over existing controllers is its dynamic switching among four different redirection controllers (S2C, TAPF, ARC, and SRL) based on the user's environment, as opposed to using a single fixed controller throughout the experience. By switching between redirection controllers based on the context around the user, SRC aims to optimize the advantages of each redirection strategy. The SRC model is trained using reinforcement learning to dynamically and instantaneously switch redirection controllers based on the user's environment. We evaluated the performance of SRC against traditional redirection controllers through simulations and user studies conducted in various physical and virtual environments. The findings indicate that SRC reduces the number of resets significantly compared to traditional redirection controllers. Heat map visualization was utilized during the development process to analyze which redirection controller SRC chooses based on the different environments around the user. SRC alternates between redirection techniques based on the user's environment, maximizing the advantages of each strategy for a superior RDW experience.
C1 [Lee, Ho Jung; Jeon, Sang-Bin; Lee, In-Kwon] Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
   [Cho, Yong-Hun] Korea Univ, Digital eXPerience Lab, Seoul, South Korea.
C3 Yonsei University; Korea University
RP Lee, HJ (corresponding author), Yonsei Univ, Dept Comp Sci, Seoul, South Korea.
EM dearshawn@yonsei.ac.kr; ludens0508@yonsei.ac.kr; maxburst88@gmail.com;
   iklee@yonsei.ac.kr
RI Lee, In-Kwon/AGP-6124-2022
OI Lee, In-Kwon/0000-0002-1534-1882; Lee, Ho Jung/0009-0008-3122-8493
FU National Research Foundation of Korea
FX No Statement Available
CR Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Sharma S., 2017, arXiv preprintarXiv:1702.06054, P447
   Shibayama W, 2020, LECT NOTES COMPUT SC, V12221, P33, DOI 10.1007/978-3-030-61864-3_4
   Stein N, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P493, DOI 10.1109/VR51125.2022.00069
   Steinicke F, 2009, JVRB-Journal of Virtual Reality and Broadcasting, V6
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma E. A., 2012, 2012 IEEE VIRT REAL, P154
   Suma EA, 2010, IEEE T VIS COMPUT GR, V16, P690, DOI 10.1109/TVCG.2009.93
   Sutton R. S., 1998, Introduction to reinforcement learning, V135, P255
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Usoh M., 2022, Walking>walking-in-place>flying, in virtual environmentsnon Visualization and Computer Graphics, V28, P3778, DOI [10.1109/TVCG.2022.3203095266S, DOI 10.1109/TVCG.2022.3203095266S]
   Zhang H., 2022, IEEE Transactions on Visualization andComputer Graphics, P1, DOI [10.1109/TVCG.2022.31586092,968, DOI 10.1109/TVCG.2022.31586092,968]
   Zhang H., 2022, IEEE Transactions on Visualization and Computer Graphics, V2, p967S
   Zmuda MA, 2013, IEEE T VIS COMPUT GR, V19, P1872, DOI 10.1109/TVCG.2013.88
NR 16
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2474
EP 2484
DI 10.1109/TVCG.2024.3372056
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400059
PM 38437097
DA 2024-11-06
ER

PT J
AU Lee, Y
   Shin, H
   Gil, YH
AF Lee, Yongho
   Shin, Heesook
   Gil, Youn-Hee
TI Measurement of Empathy in Virtual Reality with Head-Mounted Displays: A
   Systematic Review
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; empathy; measurement; systematic review
ID COGNITIVE EMPATHY; ASPERGER-SYNDROME; STATE EMPATHY; SCALE;
   QUESTIONNAIRE; VALIDATION; DISTRESS; SYMPATHY; STUDENTS; BEHAVIOR
AB We present a systematic review of 111 papers that measure the impact of virtual experiences created through head-mounted displays (HMDs) on empathy. Our goal was to analyze the conditions and the extent to which virtual reality (VR) enhances empathy. To achieve this, we categorized the relevant literature according to measurement methods, correlated human factors, viewing experiences, topics, and participants. Meta-analysis was performed based on categorized themes, and under specified conditions, we found that VR can improve empathy. Emotional empathy increased temporarily after the VR experience and returned to its original level over time, whereas cognitive empathy remained enhanced. Furthermore, while VR did not surpass 2D video in improving emotional empathy, it did enhance cognitive empathy, which is associated with embodiment. Our results are consistent with existing research suggesting differentiation between cognitive empathy (influenced by environmental factors and learnable) and emotional empathy (highly heritable and less variable). Interactivity, target of empathy, and point of view were not found to significantly affect empathy, but participants' age and nationality were found to influence empathy levels. It can be concluded that VR enhances cognitive empathy by immersing individuals in the perspective of others and that storytelling and personal characteristics are more important than the composition of the VR scene. Our findings provide guiding information for creating empathy content in VR and designing experiments to measure empathy.
C1 [Lee, Yongho; Shin, Heesook; Gil, Youn-Hee] Elect & Telecommun Res Inst, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Lee, Y (corresponding author), Elect & Telecommun Res Inst, Daejeon, South Korea.
EM jason0720@etri.re.kr; hsshin8@etri.re.kr; yhgil@etri.re.kr
OI Lee, Yongho/0009-0002-9511-992X
FU Electronics and Telecommunications Research Institute
FX No Statement Available
CR Aan Het Rot M, 2014, BRIT J PSYCHOL, V105, P173, DOI 10.1111/bjop.12029
   Abramson L, 2020, NEUROSCI BIOBEHAV R, V114, P113, DOI 10.1016/j.neubiorev.2020.03.023
   Ahn SJ, 2013, MEDIA PSYCHOL, V16, P7, DOI 10.1080/15213269.2012.755877
   Ayache J, 2024, PERS INDIV DIFFER, V219, DOI 10.1016/j.paid.2023.112478
   Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1017/S0021963001006643
   Baron-Cohen S, 2004, J AUTISM DEV DISORD, V34, P163, DOI 10.1023/B:JADD.0000022607.19833.00
   Barreda-Angeles M, 2020, CYBERPSYCH BEH SOC N, V23, P683, DOI 10.1089/cyber.2019.0665
   BATSON CD, 1987, J PERS, V55, P19, DOI 10.1111/j.1467-6494.1987.tb00426.x
   Bernhardt BC, 2012, ANNU REV NEUROSCI, V35, P1, DOI 10.1146/annurev-neuro-062111-150536
   Bevan C, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300736
   Blythe J, 2021, PEOPLE NAT, V3, P1284, DOI 10.1002/pan3.10253
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brooks C., 1959, Understanding fiction, P3
   BRYANT BK, 1982, CHILD DEV, V53, P413, DOI 10.1111/j.1467-8624.1982.tb01331.x
   Bucchioni G, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125871
   Cao BL, 2015, COMPUT HUM BEHAV, V52, P458, DOI 10.1016/j.chb.2015.06.009
   Chang E, 2020, INT J HUM-COMPUT INT, V36, P1658, DOI 10.1080/10447318.2020.1778351
   Chopik WJ, 2017, J CROSS CULT PSYCHOL, V48, P23, DOI 10.1177/0022022116673910
   Christofi M, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01242
   Christov-Moore L, 2014, NEUROSCI BIOBEHAV R, V46, P604, DOI 10.1016/j.neubiorev.2014.09.001
   Collins K, 2017, J APPL RES INTELLECT, V30, P133, DOI 10.1111/jar.12226
   Curran MT, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300844
   D'Errico F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041196
   DAVIS MH, 1983, J PERS SOC PSYCHOL, V44, P113, DOI 10.1037/0022-3514.44.1.113
   Du HY, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P687, DOI 10.1109/VRW58643.2023.00186
   EISENBERG N, 1989, J PERS SOC PSYCHOL, V57, P55, DOI 10.1037/0022-3514.57.1.55
   Eisenberg N, 2005, J RES ADOLESCENCE, V15, P235, DOI 10.1111/j.1532-7795.2005.00095.x
   Ekman P., 2007, Emotions revealed: Recognizing faces and feelings to improve communication and emotional life, P3
   Eres R, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00176
   Escalas JE, 2003, J CONSUM RES, V29, P566, DOI 10.1086/346251
   Fernandez-Pinto i, 2008, Tesi de empatia cognitiva y afectiva, P3
   Formosa NJ, 2018, AUST J PSYCHOL, V70, P57, DOI 10.1111/ajpy.12167
   Francis KB, 2018, BRIT J PSYCHOL, V109, P442, DOI 10.1111/bjop.12276
   Gardhouse K., 2013, CAMBRIDGE HDB HUMAN, P57
   Hamilton-Giachritsis C, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21036-2
   Harrer M., 2021, Doing meta-analysis with R: A hands-on guide, P9
   Hedges LV, 2004, PSYCHOL METHODS, V9, P426, DOI 10.1037/1082-989X.9.4.426
   Hojat M., 2007, Empathy in patient care: antecedents, development, measurement, and outcomes, V77
   Howard MC, 2020, COMPUT EDUC, V144, DOI 10.1016/j.compedu.2019.103707
   Iacoboni M, 2009, ANNU REV PSYCHOL, V60, P653, DOI 10.1146/annurev.psych.60.110707.163604
   Ingram KM, 2019, J ADOLESCENCE, V71, P72, DOI 10.1016/j.adolescence.2018.12.006
   Jacob ME, 2016, HAND CLINIC, V138, P3, DOI 10.1016/B978-0-12-802973-2.00001-X
   Jicol C, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502129
   Jolliffe D, 2006, J ADOLESCENCE, V29, P589, DOI 10.1016/j.adolescence.2005.08.010
   Käthner I, 2022, BRIT J HEALTH PSYCH, V27, P434, DOI 10.1111/bjhp.12553
   Kamas L, 2021, J BEHAV EXP ECON, V92, DOI 10.1016/j.socec.2020.101654
   Kim J, 2020, BMC PSYCHOL, V8, DOI 10.1186/s40359-020-00418-0
   Konrath SH, 2011, PERS SOC PSYCHOL REV, V15, P180, DOI 10.1177/1088868310377395
   KREHBIEL T.C., 2004, DECISION SCI J INNOV, V2, P97, DOI [DOI 10.1111/J.0011-7315.2004.00025.X, 10.1111/j.0011-7315.2004.00025.x]
   Krznaric R., 2015, TarcherPerigee, P1
   Lam T. C. M., 2011, Journal of MultidisciplinaryEvaluation, V7, P1
   Lambe I.. J., 2022, International Journal of Bullying Prevention, P1
   Lamm C, 2015, NEUROSCI RES, V90, P15, DOI 10.1016/j.neures.2014.10.008
   Lee HM, 2023, INT J HUM-COMPUT ST, V176, DOI 10.1016/j.ijhcs.2023.103042
   Lenzner T, 2012, FIELD METHOD, V24, P409, DOI 10.1177/1525822X12448166
   Levett-Jones T, 2017, NURS EDUC TODAY, V59, P75, DOI 10.1016/j.nedt.2017.09.007
   Lima FFD, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.781346
   Martingano A. J., 2021, Technology, Mind, and Behavior, V1
   Merino L, 2020, INT SYM MIX AUGMENT, P438, DOI 10.1109/ISMAR50242.2020.00069
   Meta, 2023, Get teens started with parental supervision
   Michaels TM, 2014, PSYCHIAT RES, V220, P803, DOI 10.1016/j.psychres.2014.08.054
   Milk Chris., 2015, Ted Talk
   Morse J M, 1992, Image J Nurs Sch, V24, P273
   Muravevskaia Ekaterina, 2023, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2022.100561
   Nicovich SG, 2005, J COMPUT-MEDIAT COMM, V10
   O'Brien E, 2013, J GERONTOL B-PSYCHOL, V68, P168, DOI 10.1093/geronb/gbs055
   Paananen V., 2022, arXiv
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pan XN, 2018, BRIT J PSYCHOL, V109, P395, DOI 10.1111/bjop.12290
   Polich J, 2007, CLIN NEUROPHYSIOL, V118, P2128, DOI 10.1016/j.clinph.2007.04.019
   Pommier E. A., 2010, doctoral dissertation, P3
   Pressgrove G, 2020, INT J NONPROFIT VOLU, DOI 10.1002/nvsm.1689
   Raz G, 2020, NEUROIMAGE, V207, DOI 10.1016/j.neuroimage.2019.116351
   Reid C, 2013, BRIT J DEV PSYCHOL, V31, P231, DOI 10.1111/bjdp.12002
   Reniers RLEP, 2011, J PERS ASSESS, V93, P84, DOI 10.1080/00223891.2010.528484
   Rueda J, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.506984
   Salminen M, 2022, IEEE T AFFECT COMPUT, V13, P746, DOI 10.1109/TAFFC.2019.2958657
   Sassenrath C, 2020, SOC PSYCHOL PERS SCI, V11, P752, DOI 10.1177/1948550619884566
   Schulte-Rüther M, 2008, NEUROIMAGE, V42, P393, DOI 10.1016/j.neuroimage.2008.04.180
   Shen LJ, 2010, WESTERN J COMM, V74, P504, DOI 10.1080/10570314.2010.512278
   Spreng RN, 2009, J PERS ASSESS, V91, P62, DOI 10.1080/00223890802484381
   Stargatt J, 2021, J ALZHEIMERS DIS, V84, P1247, DOI 10.3233/JAD-210723
   Stavroulia KE, 2023, COMPUT EDUC, V197, DOI 10.1016/j.compedu.2023.104739
   Stevens F, 2021, NEUROPSYCHOLOGIA, V159, DOI 10.1016/j.neuropsychologia.2021.107925
   Thériault R, 2021, Q J EXP PSYCHOL, V74, P2057, DOI 10.1177/17470218211024826
   van Rijn H, 2011, CODESIGN, V7, P65, DOI 10.1080/15710882.2011.609889
   Vargas EP, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.993162
   Ventura S., 2023, Empathy-Advanced Research and Applications, P51
   Ventura S, 2020, CYBERPSYCH BEH SOC N, V23, P667, DOI 10.1089/cyber.2019.0681
   Villalba EE, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107272
   Walewijns D, 2023, COMPUT HUM BEHAV, V145, DOI 10.1016/j.chb.2023.107758
   Wilding C, 2023, J APPL RES INTELLECT, V36, P132, DOI 10.1111/jar.13042
   Winkler N., 2020, Lose yourself in vr. exploring the effects of virtual reality on individuals immersion, P9
   Wohlin C., 2014, ACM INT C P SER, P1, DOI [DOI 10.1145/2601248.2601268, 10.1145/2601248, DOI 10.1145/2601248]
   Yang CY, 2009, BRAIN RES, V1251, P176, DOI 10.1016/j.brainres.2008.11.062
NR 95
TC 1
Z9 1
U1 8
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2485
EP 2495
DI 10.1109/TVCG.2024.3372076
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400017
PM 38437085
DA 2024-11-06
ER

PT J
AU Cai, ZJ
   Ma, YH
   Lu, F
AF Cai, Zhuojiang
   Ma, Yuhan
   Lu, Feng
TI Robust Dual-Modal Speech Keyword Spotting for XR Headsets
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Speech interaction; extended reality; keyword spotting; multimodal
   interaction
ID RECOGNITION; GESTURE
AB While speech interaction finds widespread utility within the Extended Reality (XR) domain, conventional vocal speech keyword spotting systems continue to grapple with formidable challenges, including suboptimal performance in noisy environments, impracticality in situations requiring silence, and susceptibility to inadvertent activations when others speak nearby. These challenges, however, can potentially be surmounted through the cost-effective fusion of voice and lip movement information. Consequently, we propose a novel vocal-echoic dual-modal keyword spotting system designed for XR headsets. We devise two different modal fusion approches and conduct experiments to test the system's performance across diverse scenarios. The results show that our dual-modal system not only consistently outperforms its single-modal counterparts, demonstrating higher precision in both typical and noisy environments, but also excels in accurately identifying silent utterances. Furthermore, we have successfully applied the system in real-time demonstrations, achieving promising results. The code is available at https://github.com/caizhuojiang/VE-KWS.
C1 [Cai, Zhuojiang; Ma, Yuhan; Lu, Feng] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University
RP Lu, F (corresponding author), Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM caizhuojiang@buaa.edu.cn; raphael.mayuhan@buaa.edu.cn;
   lufeng@buaa.edu.cn
RI Ma, Yuhan/HMD-8720-2023
OI Lu, Feng/0000-0001-9064-7964; Cai, Zhuojiang/0009-0005-3404-118X
CR Bedri A, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.310
   Berg A, 2021, INTERSPEECH, P4249, DOI 10.21437/Interspeech.2021-1286
   Cheah J. M., 2018, INPROCEED INGS 11 IN, P56, DOI 10.5220
   Chen G., 2014, ICASSP, P4087, DOI [DOI 10.1109/ICASSP.2014.6854370, DOI 10.1109/ICASSP.2014.68543702[5]T]
   Choi S, 2019, Arxiv, DOI arXiv:1904.03814
   Cioflan C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P82, DOI 10.1109/AICAS54282.2022.9869990
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Ding RW, 2018, IEEE IMAGE PROC, P4138, DOI 10.1109/ICIP.2018.8451096
   Elepfandt M., 2012, INPROCEEDINGS 4 WORK, P1, DOI [10.1145/2401836.24018482[11]I, DOI 10.1145/2401836.24018482[11]I]
   Fung I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2511, DOI 10.1109/ICASSP.2018.8462280
   Gales MJF, 2017, LECT NOTES ARTIF INT, V10458, P3, DOI 10.1007/978-3-319-66429-3_1
   Gao Y, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411830
   Grinshpoon A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P751, DOI 10.1109/VR.2018.8446259
   Hofe R, 2013, SPEECH COMMUN, V55, P22, DOI 10.1016/j.specom.2012.02.001
   Hombeck J, 2023, Symposium Virtual Re, P123, DOI 10.1109/VR55154.2023.00028
   Kapur A, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P43, DOI 10.1145/3172944.3172977
   Kaur M., Where is "it"? Event Synchronization in Gaze-Speech Input Systems,, V2
   Kim B, 2022, Arxiv, DOI arXiv:2106.04140
   Kimura N, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451552
   Kimura N, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399852
   Kimura N, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300376
   Kumar R, 2018, INTERSPEECH, P1121
   Kunimi Y, 2022, PROCEEDINGS OF AUGMENTED HUMANS CONFERENCE 2022 (AHS 2022), P26, DOI 10.1145/3519391.3519399
   Lee KS, 2008, IEEE T BIO-MED ENG, V55, P930, DOI 10.1109/TBME.2008.915658
   Lee M, 2013, VIRTUAL REAL-LONDON, V17, P293, DOI 10.1007/s10055-013-0230-0
   Li K, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3534621
   Li R, 2019, PROCEEDINGS OF THE 10TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE 2019 (AH2019), DOI 10.1145/3311823.3311831
   López-Espejo I, 2022, IEEE ACCESS, V10, P4169, DOI 10.1109/ACCESS.2021.3139508
   Lopez-Espejo I, 2021, IEEE-ACM T AUDIO SPE, V29, P2254, DOI 10.1109/TASLP.2021.3092567
   Michaely AH, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P272, DOI 10.1109/ASRU.2017.8268946
   Monteiro P, 2021, IEEE T VIS COMPUT GR, V27, P2702, DOI 10.1109/TVCG.2021.3067687
   Piumsomboon T, 2014, INT SYM MIX AUGMENT, P73, DOI 10.1109/ISMAR.2014.6948411
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Prabhavalkar R, 2015, INT CONF ACOUST SPEE, P4704, DOI 10.1109/ICASSP.2015.7178863
   Rantamaa HR, 2022, INT J COMPUT ASS RAD, V17, P1981, DOI 10.1007/s11548-022-02685-1
   Rekimoto J, 2021, PROCEEDINGS OF THE AUGMENTED HUMANS CONFERENCE 2021, AHS 2021, P91, DOI 10.1145/3458709.3458941
   Rohlicek J. R., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P627, DOI 10.1109/ICASSP.1989.266505
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   Rosenberg A, 2017, INT CONF ACOUST SPEE, P5280, DOI 10.1109/ICASSP.2017.7953164
   Sainath TN, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1478
   Shi BW, 2022, Arxiv, DOI arXiv:2201.01763
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Tang RP, 2018, Arxiv, DOI arXiv:1710.10361
   Thiemann J., 2013, The Diverse Environments Multichannet. Acoustic Noise Database (DEMAND): A database of multichannel environmental noise recordings, DOI [10.1121/1.47995975, DOI 10.1121/1.47995975]
   Tuochao Chen, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P112, DOI 10.1145/3379337.3415879
   Vygon Roman, 2021, Speech and Computer: 23rd International Conference, SPECOM 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12997), P773, DOI 10.1007/978-3-030-87802-3_69
   Wang Y, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10070442
   Wang ZM, 2021, IEEE T HUM-MACH SYST, V51, P524, DOI 10.1109/THMS.2021.3097973
   Warden P, 2018, Arxiv, DOI arXiv:1804.03209
   WILPON JG, 1991, INT CONF ACOUST SPEE, P309, DOI 10.1109/ICASSP.1991.150338
   Xu K, 2018, IEEE INT CONF AUTOMA, P548, DOI 10.1109/FG.2018.00088
   Xu ML, 2020, INTERSPEECH, P2547, DOI 10.21437/Interspeech.2020-1045
   Zhang K., 2023, INPROCEEDINGS OFTHE, P1, DOI [10.1145/3544548.35808011,2,3,4[56]Y., DOI 10.1145/3544548.35808011,2,3,4[56]Y]
   Zhang Ruidong., 2021, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V5, P1, DOI DOI 10.1145/34949872[55]R
   Zhang YZ, 2021, UBICOMP/ISWC '21 ADJUNCT: PROCEEDINGS OF THE 2021 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2021 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P580, DOI 10.1145/3460418.3480163
   Zhou P, 2019, INT CONF ACOUST SPEE, P6565, DOI 10.1109/ICASSP.2019.8683733
   Zhuang YM, 2016, INTERSPEECH, P938, DOI 10.21437/Interspeech.2016-753
NR 57
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2507
EP 2516
DI 10.1109/TVCG.2024.3372092
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400057
PM 38437114
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ning, B
   Pei, MT
AF Ning, Bing
   Pei, Mingtao
TI Task and Environment-Aware Virtual Scene Rearrangement for Enhanced
   Safety in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Layout; Visualization; Virtual environments; User
   experience; Solid modeling; Navigation; VR safety; scene rearrangement;
   scene synthesis
ID REDIRECTED WALKING
AB Emerging VR applications have revolutionized user experiences by immersing individuals in digitally crafted environments. However, fully immersive experiences introduce new challenges, notably the risk of physical hazards when users are unaware of their surroundings. Existing solutions, including guardian spaces and locomotion systems, present trade-offs that either disrupt the immersive experience or risk inducing motion sickness. To address these challenges, we propose a novel approach that dynamically rearranges VR scenes according to users' physical spaces, seamlessly embedding physical constraints and interaction tasks into the virtual environment. We design a computational model to optimize the rearranged scene through a cost function, ensuring collision-free interactions while maintaining visual fidelity and the goal of interaction tasks. The experiments demonstrate improvements in user experience and safety, presenting an innovative solution to harmonize physical and virtual environments in VR applications.
C1 [Ning, Bing; Pei, Mingtao] Beijing Inst Technol, Beijing, Peoples R China.
   [Ning, Bing] Beijing Inst Fash Technol, Beijing, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Fashion Technology
RP Ning, B (corresponding author), Beijing Inst Technol, Beijing, Peoples R China.; Ning, B (corresponding author), Beijing Inst Fash Technol, Beijing, Peoples R China.
EM designbox@163.com; peimt@bit.edu.cn
FU National Natural Science Foundation of China
FX No Statement Available
CR Azmandian M, 2014, 2014 IEEE VIRTUAL REALITY (VR), P65, DOI 10.1109/VR.2014.6802053
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Chan ER, 2022, PROC CVPR IEEE, P16102, DOI 10.1109/CVPR52688.2022.01565
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Fan L., 2022, IEEE Transactions on Visualization and Computer Graphics
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Handa A, 2016, IEEE INT CONF ROBOT, P5737, DOI 10.1109/ICRA.2016.7487797
   Hassan M, 2021, PROC CVPR IEEE, P14703, DOI 10.1109/CVPR46437.2021.01447
   Huang S, 2023, PROC CVPR IEEE, P16750, DOI 10.1109/CVPR52729.2023.01607
   Kanamori K, 2018, INT SYM MIX AUGMENT, P80, DOI 10.1109/ISMAR.2018.00033
   Kim SW, 2023, PROC CVPR IEEE, P8496, DOI 10.1109/CVPR52729.2023.00821
   Kosiorek Adam R, 2021, ICML, P5742
   Lang YN, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P767, DOI [10.1109/VR.2019.8798018, 10.1109/vr.2019.8798018]
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Li CJ, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P665, DOI 10.1109/VRW52623.2021.00215
   Li YJ, 2021, INT SYM MIX AUGMENT, P21, DOI 10.1109/ISMAR52148.2021.00016
   Liang W., 2021, CHI C HUM FACT COMP, P1
   Liang W, 2019, IEEE T VIS COMPUT GR, V25, P1836, DOI 10.1109/TVCG.2019.2898721
   Lucero A., 2014, P C ADV COMP ENT TEC, P1
   Matsumoto K, 2021, INT SYM MIX AUGMENT, P498, DOI 10.1109/ISMAR52148.2021.00067
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Medeiros D, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P21, DOI 10.1109/VR50410.2021.00022
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Nguyen A., 2021, PhD thesis
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Po RY, 2023, Arxiv, DOI arXiv:2303.12218
   Purkait Pulak, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P155, DOI 10.1007/978-3-030-58586-0_10
   Qi SY, 2018, PROC CVPR IEEE, P5899, DOI 10.1109/CVPR.2018.00618
   Sayyad E, 2020, INT SYM MIX AUGMENT, P608, DOI 10.1109/ISMAR50242.2020.00088
   Schäfer A, 2022, LECT NOTES COMPUT SC, V13484, P191, DOI 10.1007/978-3-031-16234-3_11
   Schulz P., 2019, CHI C HUM FACT COMP, P1
   Shapira L, 2016, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2016.23
   Shimizu M, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489897
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Steinicke F, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P217, DOI 10.1109/CW.2008.53
   Talton JO, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944851
   Valentini I, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P44, DOI [10.1109/VR46266.2020.00-82, 10.1109/VR46266.2020.1581503942658]
   Wang WB, 2019, PROC CVPR IEEE, P8180, DOI 10.1109/CVPR.2019.00838
   Wang Z., 2022, Advances in Neural Information Processing Systems, V35, P14959
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   Yan YK, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3380983
   Yang J, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P1093, DOI 10.1145/3332165.3347875
   Yeh YT, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185552
   Yu LF, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964981
   Zhang YR, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P674, DOI 10.1109/VR51125.2022.00088
NR 51
TC 0
Z9 0
U1 7
U2 8
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2517
EP 2526
DI 10.1109/TVCG.2024.3372115
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400043
PM 38437138
DA 2024-11-06
ER

PT J
AU Ibrahim, MT
   Gopi, M
   Majumder, A
AF Ibrahim, Muhammad Twaha
   Gopi, M.
   Majumder, Aditi
TI Real-Time Seamless Multi-Projector Displays on Deformable Surfaces
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cameras; Calibration; Three-dimensional displays; Shape; Surface
   reconstruction; Real-time systems; Surface fitting; Computing
   Methodologies; Artificial Intelligence; Computer Vision; Image and Video
   Acquisition
ID CALIBRATION
AB Prior works on multi-projector displays have focused primarily on static rigid objects, some focusing on dynamic rigid objects. However, works on projection based displays on deformable dynamic objects have focused only on small scale single projector displays. Tracking a deformable dynamic surface and updating projections precisely in real time on it is a significantly challenging task, even for a single projector system. In this paper, we present the first end-to-end solution for achieving a real-time, seamless display on deformable surfaces using mutliple unsychronized projectors without requiring any prior knowledge of the surface or device parameters. The system first accurately calibrates multiple RGB-D cameras and projectors using the deformable display surface itself, and then using those calibrated devices, tracks the continuous changes in the surface shape. Based on the deformation and projector calibration, the system warps and blends the image content in real-time to create a seamless display on a surface that continuously changes shape. Using multiple projectors and RGB-D cameras, we provide the much desired aspect of scale to the displays on deformable surfaces. Most prior dynamic multi-projector systems assume rigid objects and depend critically on the constancy of surface normals and non-existence of local shape deformations. These assumptions break in deformable surfaces making prior techniques inapplicable. Point-based correspondences become inadequate for calibration, exacerbated with no synchronization between the projectors. A few works address non-rigid objects with several restrictions like targeting semi-deformable surfaces (e.g. human face), or using single coaxial (optically aligned) projector-camera pairs, or temporally synchronized cameras. We break loose from such restrictions and handle multiple projector systems for dynamic deformable fabric-like objects using temporally unsynchronized devices. We devise novel methods using ray and plane-based constraints imposed by the pinhole camera model to address these issues and design new blending methods dependent on 3D distances suitable for deformable surfaces. Finally, unlike all prior work with rigid dynamic surfaces that use a single RGB-D camera, we devise a method that involve all RGB-D cameras for tracking since the surface is not seen completely by a single camera. These methods enable a seamless display at scale in the presence of continuous movements and deformations. This work has tremendous applications on mobile and expeditionary systems where environmentals (e.g. wind, vibrations, suction) cannot be avoided. One can create large displays on tent walls in remote, austere military or emergency operations in minutes to support large scale command and control, mission rehearsal or training operations. It can be used to create displays on mobile and inflatable objects for tradeshows/events and touring edutainment applications.
C1 [Ibrahim, Muhammad Twaha; Gopi, M.; Majumder, Aditi] Univ Calif Irvine, Irvine, CA 92697 USA.
C3 University of California System; University of California Irvine
RP Ibrahim, MT (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.
EM muhammti@uci.edu; gopi@ics.uci.edu; majumder@ics.uci.edu
RI Ibrahim, Muhammad Twaha/ADD-8310-2022
OI Ibrahim, Muhammad Twaha/0000-0001-9286-6124
FU US Air Force
FX No Statement Available
CR Ahmed K. H., 2019, Journal of ElectronicImaging, V28
   Asayama H, 2018, IEEE T VIS COMPUT GR, V24, P1077, DOI 10.1109/TVCG.2017.2657634
   Audet Samuel, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P47, DOI 10.1109/CVPR.2009.5204319
   Bermano A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508416
   Bi B., 2016, P ACM S APPL PERC, P19, DOI [10.1145/2931002.2931016, DOI 10.1145/2931002.2931016]
   Bouman KL, 2013, IEEE I CONF COMP VIS, P1984, DOI 10.1109/ICCV.2013.455
   Chen R., 2001, CVPRTechnical Sketch, p10Z
   Feng D., 2019, IEEE Transactions on Instru-mentation and Measurement, V69, p11Y
   Fujimoto Y, 2014, IEEE T VIS COMPUT GR, V20, P540, DOI 10.1109/TVCG.2014.25
   Hashimoto R., 2017, International Journal of ComputerGames Technology, p13B
   Hasker E, 2007, IEEE T VIS COMPUT GR, V13, P1368, DOI 10.1109/TVCG.2007.70586
   Hasker ES, 2006, IEEE T VIS COMPUT GR, V12, P1101, DOI 10.1109/TVCG.2006.121
   Huang BY, 2021, IEEE T AUTOM SCI ENG, V18, P1049, DOI 10.1109/TASE.2020.2994223
   Huang BY, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P15, DOI 10.1109/ISMAR-Adjunct.2018.00023
   Ibrahim G., 2020, 26 ACM S VIRT REAL S, P1
   Ibrahim M. T., 2023, 2023 22 IEEE INT S M
   Ibrahim MT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P905, DOI 10.1109/VRW58643.2023.00295
   Ibrahim MT, 2022, COMPUT GRAPH-UK, V103, P61, DOI 10.1016/j.cag.2022.01.004
   Juarez-Salazar V. H., 2019, Optics and Lasersin Engineering, V120, pn21S
   Kagami S, 2019, IEEE T VIS COMPUT GR, V25, P3094, DOI 10.1109/TVCG.2019.2932248
   Kawabe T., 2016, ACM Trans. Appl. Percept., p23P
   Kurth M., 2022, IEEE Transactions on Visualization and Computer Graphics, p25V
   Kurth P, 2018, IEEE T VIS COMPUT GR, V24, P2886, DOI 10.1109/TVCG.2018.2868530
   Lange C., 2016, Augmented Reality, Virtual Reality, and Computer Graph-ics, V9769, p26V
   Lange V., 2017, Proceedings of the European Association for Computer Graphics: Short Papers, page, P1
   Lincoln G., 2011, 2011 IEEE VIRT REAL, p28A
   Majumder A, 2005, ACM T GRAPHIC, V24, P118, DOI 10.1145/1037957.1037964
   Miyashita Y., 2018, ACM Trans. Graph., p31D
   Miyazaki N., 2018, 2018 INT WORKSH ADV, p32D
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Narita Y., 2015, P 21 ACM S VIRT REAL, p34G
   Narita Y., 2016, IEEE transactions on visualization and computer graphics, V23, p35T
   Nomoto T, 2022, IEEE T VIS COMPUT GR, V28, P2125, DOI 10.1109/TVCG.2022.3150488
   Punpongsanon D., 2020, IEEE T VISUALIZATION, p39R
   Punpongsanon D., 2013, SIGGRAPH AS 2013 EM, p37P
   Punpongsanon D., 2015, Virtual Reality, V19, p38P
   Raskar G., 2001, RENDERING TECHNIQUES, V12, p43C
   Raskar G., 1998, P 25 ANN C COMP GRAP, P179
   Raskar M., 1998, EUR WORKSH REND TECH, pn41R
   Raskar R., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P161, DOI 10.1109/VISUAL.1999.809883
   Resch C, 2014, INT SYM MIX AUGMENT, P151, DOI 10.1109/ISMAR.2014.6948421
   Resch H., 2015, IEEE Transactionson Visualization and Computer Graphics, V21, p45P
   Roman P, 2010, IEEE T VIS COMPUT GR, V16, P1623, DOI 10.1109/TVCG.2010.128
   Sajadi A., 2009, IEEE Transactions onVisualization and Computer Graphics, V10, p47B
   Sajadi A., 2010, P 17 ACM S VIRT REAL, p49B
   Sajadi B, 2010, P IEEE VIRT REAL ANN, P155, DOI 10.1109/VR.2010.5444797
   Sajadi B, 2011, IEEE T VIS COMPUT GR, V17, P1209, DOI 10.1109/TVCG.2011.33
   Sen B., 2005, ACM SIGGRAPH 2005 PA, p51M
   Shahpaski M., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P4885
   Shimazu S., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P235, DOI 10.1109/ISMAR.2011.6092393
   Siegl C, 2017, IEEE T VIS COMPUT GR, V23, P2440, DOI 10.1109/TVCG.2017.2734428
   Siegl M., 2016, InSIGGRAPH ASIA2016 Technical Briefs, p54C
   Siegl M., 2015, ACM Trans. Graph., p55C
   Sueishi T, 2015, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2015.7223330
   Tehrani M., 2019, IEEE Transactions on Visualization and Com-puter Graphics, V27, P2265
   Tehrani M. T., 2023, IEEE Trans-actions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2023.327743659M, DOI 10.1109/TVCG.2023.327743659M]
   Waldner C., 2008, Emerging displaytechnologies, P1
   Wang LH, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313246
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watanabe M., 2018, SIGGRAPH AS 2018 EM, P1
   Willi A., 2017, 2017 IEEE INT S MIX, p63S
   Yamazaki M., 2011, CVPR 2011 WORKSH, p64L
   Yang LM, 2016, INT SYM MIX AUGMENT, P63, DOI 10.1109/ISMAR.2016.22
   Yang RG, 2001, IEEE VISUAL, P167, DOI 10.1109/VISUAL.2001.964508
   Zhou Y, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P781, DOI 10.1145/2858036.2858329
NR 65
TC 0
Z9 1
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2527
EP 2537
DI 10.1109/TVCG.2024.3372097
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400002
PM 38437087
DA 2024-11-06
ER

PT J
AU Pan, Y
   Tan, S
   Cheng, SR
   Lin, QF
   Zeng, ZJ
   Mitchell, K
AF Pan, Ye
   Tan, Shuai
   Cheng, Shengran
   Lin, Qunfen
   Zeng, Zijiao
   Mitchell, Kenny
TI Expressive Talking Avatars
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human computer interaction (HCI); HCI design and evaluation methods;
   User studies; Computer graphics; Graphics systems and interfaces;
   Virtual reality; Human-centered computing
AB Stylized avatars are common virtual representations used in VR to support interaction and communication between remote collaborators. However, explicit expressions are notoriously difficult to create, mainly because most current methods rely on geometric markers and features modeled for human faces, not stylized avatar faces. To cope with the challenge of emotional and expressive generating talking avatars, we build the Emotional Talking Avatar Dataset which is a talking-face video corpus featuring 6 different stylized characters talking with 7 different emotions. Together with the dataset, we also release an emotional talking avatar generation method which enables the manipulation of emotion. We validated the effectiveness of our dataset and our method in generating audio based puppetry examples, including comparisons to state-of-the-art techniques and a user study. Finally, various applications of this method are discussed in the context of animating avatars in VR.
C1 [Pan, Ye; Tan, Shuai; Cheng, Shengran] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Lin, Qunfen; Zeng, Zijiao] Tencent Games, Shenzhen, Peoples R China.
   [Mitchell, Kenny] Edinburgh Napier Univ, Edinburgh, Scotland.
C3 Shanghai Jiao Tong University; Edinburgh Napier University
RP Pan, Y (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM whitneypanye@sjtu.edu.cn; tanshuai0219@sjtu.edu.cn;
   SR-Cheng@sjtu.edu.cn; volleylin@tencent.com; zijiaozeng@tencent.com;
   k.mitchell2@napier.ac.uk
RI Mitchell, Kenny/AAZ-3421-2020
OI Cheng, Shengran/0000-0003-4044-0185; Tan, Shuai/0000-0003-3322-5161;
   Mitchell, Kenny/0000-0003-2420-7447
FU National Natural Science Foundation of China
FX No Statement Available
CR Aneja D, 2018, IEEE WINT CONF APPL, P160, DOI 10.1109/WACV.2018.00024
   Aneja D, 2017, LECT NOTES COMPUT SC, V10112, P136, DOI 10.1007/978-3-319-54184-6_9
   Bao L., 2023, arXiv
   Berndt D.J., 1994, P 3 INT C KNOWL DISC, P359
   Brito C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P864, DOI [10.1109/vr.2019.8798303, 10.1109/VR.2019.8798303]
   Chen Q, 2023, Arxiv, DOI arXiv:2303.05322
   Cuturi M, 2017, PR MACH LEARN RES, V70
   Danieau F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P784, DOI [10.1109/vr.2019.8798208, 10.1109/VR.2019.8798208]
   Du CP, 2021, INTERSPEECH, P3136, DOI 10.21437/Interspeech.2021-802
   Edwards P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925984
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Faigin Gary, 2012, The artist's complete guide to facial expression
   Gururani S., 2023, P IEEECVF INT C COMP, P20914
   Hsu WN, 2021, IEEE-ACM T AUDIO SPE, V29, P3451, DOI 10.1109/TASLP.2021.3122291
   Ji X., 2022, ACM SIGGRAPH 2022 C, P1
   Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386
   Kaisiyuan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P700, DOI 10.1007/978-3-030-58589-1_42
   Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658
   Lewis John P, 2014, State of the Art Reports, V1, P2, DOI DOI 10.2312/EGST.20141042
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Li H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462019
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Logan B., 2000, P ISMIR, P1
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Malleson C, 2017, P IEEE VIRT REAL ANN, P447, DOI 10.1109/VR.2017.7892372
   Pan Y., 2023, P 31 ACM INT C MULT
   Pan Y, 2023, IEEE T VIS COMPUT GR, V29, P2527, DOI 10.1109/TVCG.2023.3247101
   Pan YF, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555408
   Ren Y., 2021, P INT C LEARN REPR
   Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009
   Richard A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1153, DOI 10.1109/ICCV48922.2021.00121
   Sakoe Hiroaki, 1971, 1971 P INT C AC BUD
   Tan S, 2023, IEEE I CONF COMP VIS, P22089, DOI 10.1109/ICCV51070.2023.02024
   Taylor S. L., 2012, P 11 ACM SIGGRAPHEUR, P275, DOI DOI 10.2312/SCA/SCA12/275-284
   Taylor S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073699
   Wu HZ, 2023, Arxiv, DOI arXiv:2308.05428
   Ye Z., 2023, arXiv
   Yi R, 2020, Arxiv, DOI arXiv:2002.10137
   Yoon B, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P547, DOI [10.1109/VR.2019.8797719, 10.1109/vr.2019.8797719]
   Zhou Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417774
   Zhou Y, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201292
NR 41
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2538
EP 2548
DI 10.1109/TVCG.2024.3372047
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400063
PM 38437076
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Gómez, V
   Figueroa, P
AF Gomez, Vivian
   Figueroa, Pablo
TI ProtoColVR: Requirements Gathering and Collaborative Rapid Prototyping
   of VR Training Simulators for Multidisciplinary Teams
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Simulation; Prototyping; Multidisciplinary;
   Methodology; Training
AB We present ProtoColVR, a methodology and a plugin designed for gathering requirements and collaborative rapid prototyping of virtual reality training simulators. Our methodology outlines the utilization of current technologies, the involvement of stakeholders during design and development, and the implementation of simulator creation through multiple iterations. We incorporate open-source tools and freely available environments like Twine and Unity to establish a reference implementation for requirements gathering and rapid prototyping. ProtoColVR is the outcome of our collaboration with a hospital and our Navy, and it has undergone testing in a development Jam. From these tests, we have gained valuable insights, including the ability to create functional prototypes within multidisciplinary teams, enhance communication among different roles, and streamline requirements gathering while improving our understanding of the virtualized environment.
C1 [Gomez, Vivian; Figueroa, Pablo] Univ los Andes, Bogota, Colombia.
C3 Universidad de los Andes (Colombia)
RP Gómez, V (corresponding author), Univ los Andes, Bogota, Colombia.
EM vn.gomez@uniandes.edu.co; pfiguero@uniandes.edu.co
OI Gomez, Vivian/0000-0002-1713-9311; Figueroa, Pablo/0000-0001-5412-8630
CR Abbas Y, 2023, INTERACT LEARN ENVIR, V31, P3698, DOI 10.1080/10494820.2021.1940215
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Barreto FM, 2017, XXXI BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING (SBES 2017), P261, DOI 10.1145/3131151.3131193
   Barreto Franciny M., 2014, P 24 ANN INT C COMP, P106
   BenMahmoud-Jouini C., 2020, Creativity andInnovation Management, DOI [10.1111/caim.123583[6]K, DOI 10.1111/CAIM.123583[6]K]
   Couperus K, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8062
   Dalladaku Y., 2020, Assessing the effectiveness of virtual reality in the training of army aviators
   Davis MJ, 2021, J TECHNOL HUMAN SERV, V39, P295, DOI 10.1080/15228835.2021.1915928
   DeMarco M. C., 2021, About entwee. m. c. de marco
   Di Loreto C, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P281, DOI 10.1109/VR.2018.8448292
   Doneda A. L., 2020, Helicopter visual signaling simulation: Integrating vr and ml into a low-cost solution to optimize brazilian navy training, DOI [10.1109/SVR51698.2020.00071, DOI 10.1109/SVR51698.2020.00071]
   E. Games, 2024, Unreal engine - game development platform
   Garcia C. S/n, 2004, Gdesk: Game discrete eventsimulation kernel, P121
   Girardi R., 2019, Virtual reality in army artillery observer training, DOI [10.1109/SVR.2019.000211,2, DOI 10.1109/SVR.2019.000211,2]
   Gomez V., 2022, Tweenity
   Gomez V., 2021, Virtual Reality and Intelligent Hardware, V3, P407, DOI [10.1016/j.vrih.2021.09.0022,3,5, DOI 10.1016/J.VRIH.2021.09.0022,3,5]
   Gómez V, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P452, DOI 10.1109/VRW52623.2021.00108
   Greunke L, 2016, IEEE T VIS COMPUT GR, V22, P1482, DOI 10.1109/TVCG.2016.2518098
   Gunn T, 2018, INTERACT LEARN ENVIR, V26, P613, DOI 10.1080/10494820.2017.1374981
   Hafsia M, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234298
   InkleStudios, 2024, Inklewriter - an online tool for writing and sharing interactive stories
   JamVR, 2022, Jamvr: The simulators to build
   JamVR, 2022, Jamvr: The built simulators
   Jeon SG, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364268
   King A., 2017, Practical game design
   Kraub A., 2021, Current practices, challenges, and design impli-cations for collaborative ar/vr application development, DOI [10.1145/3411764.34453351,2,3,4,9[28]C.D., DOI 10.1145/3411764.34453351,2,3,4,9[28]C.D]
   Mozilla, 2024, Mozilla hubs - virtual reality chatrooms
   Mozilla, 2024, Spoke - create social vr spaces
   N. N. Group, 2018, Beyond the nps: Measuring perceived usability with the sus, nasa-tlx, and the single ease question after tasks and usability tests
   Nebeling M., 2018, The trouble with augmented reality/virtualreality authoring tools, DOI [10.1109/ISMAR-Adjunct.2018.000981[32]I, DOI 10.1109/ISMAR-ADJUNCT.2018.000981[32]I]
   Nowak W., 2021, INPROCEEDINGS THE202, DOI [10.1145/3437378.34426933[17]L, DOI 10.1145/3437378.34426933[17]L]
   Petukhov I., 2019, Design model of a training simulator in virtual reality, P1
   Spatial, 2024, Spatial - virtual reality workspace
   Twinery, 2024, Twine - an open-source tool for interactive storytelling
   U. Technologies, 2024, Unity - game development platform
   Wikipedia, 2024, Altspacevr
   Wikipedia contributors, 2023, Game jam
   Xie B, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.645153
NR 38
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2549
EP 2558
DI 10.1109/TVCG.2024.3372057
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400020
PM 38437073
DA 2024-11-06
ER

PT J
AU Xiong, NC
   Liu, QQ
   Zhu, KN
AF Xiong, Ningchang
   Liu, Qingqin
   Zhu, Kening
TI PetPresence: Investigating the Integration of Real-World Pet Activities
   in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; Visualization; Virtual environments; Urban areas;
   Three-dimensional displays; Portals; Media; Virtual Reality; Haptics;
   Distractions; Presence; Pet
AB For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets' movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users' performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.
C1 [Xiong, Ningchang; Liu, Qingqin; Zhu, Kening] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Zhu, KN (corresponding author), City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.
EM nxiong9-c@my.cityu.edu.hk; neoliu@cityu.edu.hk; keninzhu@cityu.edu.hk
RI Zhu, Kening/AAI-8826-2020
OI Liu, Qingqin/0000-0002-2150-4078; ZHU, Kening/0000-0001-6740-4921
FU National Natural Science Foundation of China
FX No Statement Available
CR Applebaum JW, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10101882
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Basch CH, 2014, INJURY PREV, V20, DOI 10.1136/injuryprev-2013-041063
   Cheng LP, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P359, DOI [10.1109/vr.2019.8798074, 10.1109/VR.2019.8798074]
   Chung S, 2023, VISUAL COMPUT, V39, P3145, DOI 10.1007/s00371-022-02676-y
   Dao E., 2021, P 2021 CHI C HUM FAC, DOI DOI 10.1145/3411764.3445435
   Fang Cathy Mengying, 2023, 2023 CHI C HUM FACT, P1
   Flavián C, 2021, J BUS RES, V123, P289, DOI 10.1016/j.jbusres.2020.09.036
   Garau M, 2008, PRESENCE-TELEOP VIRT, V17, P293, DOI 10.1162/pres.17.3.293
   Ghosh S, 2018, IEEE T VIS COMPUT GR, V24, P1447, DOI 10.1109/TVCG.2018.2793698
   Golbeck J., 2012, CHI 12 EXTENDED ABST, P211, DOI [DOI 10.1145/2212776.2212799, 10.1145/2212776.2212799]
   Gonçalves G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3533377
   Gonçalves G, 2020, IEEE T VIS COMPUT GR, V26, P3231, DOI 10.1109/TVCG.2019.2926978
   Gottsacker M, 2021, INT SYM MIX AUGMENT, P310, DOI 10.1109/ISMAR52148.2021.00047
   Harley D, 2018, PROCEEDINGS OF THE TWELFTH INTERNATIONAL CONFERENCE ON TANGIBLE, EMBEDDED, AND EMBODIED INTERACTION (TEI'18), P386, DOI 10.1145/3173225.3173241
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hirskyj-Douglas Ilyena, 2018, Multimodal Technologies and Interaction, V2, DOI 10.3390/mti2020030
   Huard A, 2022, INT SYM MIX AUGMENT, P538, DOI 10.1109/ISMAR55827.2022.00070
   Insko Brent Edward, 2001, Passive Haptics Significantly Enhances Virtual Environments
   Judistira A. D., 2023, International Journal of Advanced Information Technology, V6, DOI [10.25124/ijait.v6i02.4351, DOI 10.25124/IJAIT.V6I02.4351]
   Jukan A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3041960
   Kanat-Maymon Y, 2021, J HAPPINESS STUD, V22, P1441, DOI 10.1007/s10902-020-00279-9
   Kern AC, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00020
   Kudo Yoshiki, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3486950
   Lee SP, 2006, PERS UBIQUIT COMPUT, V10, P301, DOI 10.1007/s00779-005-0051-6
   Lim S, 2023, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR59233.2023.00014
   Lin CL, 2017, INT CONF AFFECT, P362, DOI 10.1109/ACII.2017.8273625
   Liu Huimin., 2021, Graphics and Visual Computing, V4, P200020, DOI DOI 10.1016/J.GVC.2021.200020
   Mancini Clara, 2011, Interactions, V18, P69, DOI 10.1145/1978822.1978836
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Na HW, 2023, FRONT VET SCI, V10, DOI 10.3389/fvets.2023.1102937
   Na H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031159
   Norouzi N, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P400, DOI 10.1109/ISMAR-Adjunct.2019.000-1
   Norouzi N, 2019, INT SYM MIX AUGMENT, P157, DOI 10.1109/ISMAR.2019.000-8
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   Oh C, 2019, CYBERPSYCH BEH SOC N, V22, P365, DOI 10.1089/cyber.2018.0404
   Oxley JA, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.782023
   Piumsomboon T, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943696
   Ritvo S., 2014, P 2014 WORKSH ADV CO, P1
   Rodriguez KE, 2021, FRONT VET SCI, V7, DOI 10.3389/fvets.2020.619600
   Shih YS, 2016, INT CONF SYST SCI EN
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Slater M, 1998, HUM FACTORS, V40, P469, DOI 10.1518/001872098779591368
   Slater M, 2000, PRESENCE-TELEOP VIRT, V9, P413, DOI 10.1162/105474600566925
   Slater M., Enhancing our lives with immersive virtual reality
   Sra M, 2015, ADJ P 28 ANN ACM S U, P47, DOI [DOI 10.1145/2815585.2817802, 10.1145/2815585.2817802]
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Sra Misha., 2016, P 29 ANN S USER INTE, P29, DOI [DOI 10.1145/2984751.2984788, 10.1145/2984751.2984788]
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Usoh M, 2000, PRESENCE-TELEOP VIRT, V9, P497, DOI 10.1162/105474600566989
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   VORMBROCK JK, 1988, J BEHAV MED, V11, P509, DOI 10.1007/BF00844843
   Wang CH, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545686
   Wu SX, 2023, Symposium Virtual Re, P631, DOI 10.1109/VR55154.2023.00078
   Zenner A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188505
NR 56
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2559
EP 2569
DI 10.1109/TVCG.2024.3372095
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400014
PM 38437107
DA 2024-11-06
ER

PT J
AU Saeedpour-Parizi, MR
   Williams, NL
   Wong, TM
   Guan, PL
   Manocha, D
   Erkelens, IM
AF Saeedpour-Parizi, Mohammad R.
   Williams, Niall L.
   Wong, Tim
   Guan, Phillip
   Manocha, Dinesh
   Erkelens, Ian M.
TI Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye
   Stereoscopic Displays
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Radial optic flow; perceptual thresholds; motion perception;
   vergence-accommodation conflict; blink suppression
ID INDIVIDUAL-DIFFERENCES; VIRTUAL ENVIRONMENTS; SIMULATOR SICKNESS;
   SENSITIVITY; MOTION
AB We provide the first perceptual quantification of user's sensitivity to radial optic flow artifacts and demonstrate a promising approach for masking this optic flow artifact via blink suppression. Near-eye HMOs allow users to feel immersed in virtual environments by providing visual cues, like motion parallax and stereoscopy, that mimic how we view the physical world. However, these systems exhibit a variety of perceptual artifacts that can limit their usability and the user's sense of presence in VR. One well-known artifact is the vergence-accommodation conflict (VAC). Varifocal displays can mitigate VAC, but bring with them other artifacts such as a change in virtual image size (radial optic flow) when the focal plane changes. We conducted a set of psychophysical studies to measure users' ability to perceive this radial flow artifact before, during, and after self-initiated blinks. Our results showed that visual sensitivity was reduced by a factor of 10 at the start and for similar to 70 ms after a blink was detected. Pre- and post-blink sensitivity was, on average, similar to 0.15% image size change during normal viewing and increased to similar to 1.5- 2.0% during blinks. Our results imply that a rapid (under 70 ms) radial optic flow distortion can go unnoticed during a blink. Furthermore, our results provide empirical data that can be used to inform engineering requirements for both hardware design and software-based graphical correction algorithms for future varifocal near-eye displays. Our project website is available at https://gamma.umd.edu/ROF/.
C1 [Saeedpour-Parizi, Mohammad R.; Wong, Tim; Guan, Phillip; Erkelens, Ian M.] Meta Real Labs Res, Burlingame, CA USA.
   [Williams, Niall L.; Manocha, Dinesh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Williams, NL (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM rezasaeedpour@meta.com; niallw.phd@gmail.com; tlwong@meta.com;
   philguan@meta.com; dmanocha@umd.edu; ian.erkelens@meta.com
OI Manocha, Dinesh/0000-0001-7047-9801
FU Link Foundation Modeling, Simulation, Training
FX No Statement Available
CR Adier R. A., 1970, Physiology of the Eye: Clinical Applica non, P3
   Albert R, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/3127589
   Ang JWA, 2020, J VISION, V20, DOI 10.1167/jov.20.10.2
   Barfield W., 1995, Virmal Reality, V1, P1
   Bax M. R., 2002, IMAGE, P9
   Bharadwaj SR, 2009, J VISION, V9, DOI 10.1167/9.11.4
   Bonato F, 2008, PRESENCE-TELEOP VIRT, V17, P283, DOI 10.1162/pres.17.3.283
   Bristow D, 2005, CURR BIOL, V15, P1296, DOI 10.1016/j.cub.2005.06.025
   Bruce V., 2003, Visuti perception: Physiology, psychology, & ecology, P2
   Clifford CWG, 1999, VISION RES, V39, P2213, DOI 10.1016/S0042-6989(98)00314-9
   Cuturi L. E., 2014, Current Biology, V24, P3
   Doughty MJ, 2002, OPTOMETRY VISION SCI, V79, P439, DOI 10.1097/00006324-200207000-00013
   Ehrenstein W. IL, 1999, Modern techniques in neuroscience research, P2
   Erketens M., 2020, SID S, V51, P2
   FREEMAN TCA, 1992, VISION RES, V32, P81, DOI 10.1016/0042-6989(92)90115-Y
   Gescheider G. A., 2013, Psychophysics: the fundamentals, V1, P2
   GIBSON JJ, 1950, AM J PSYCHOL, V63, P367, DOI 10.2307/1418003
   Goettker A, 2020, J SOC INF DISPLAY, V28, P509, DOI 10.1002/jsid.912
   Guan P., 2022, ACM SIGGRAPH 2022 C, V2, P4
   Hendrix C, 1996, PRESENCE-TELEOP VIRT, V5, P274, DOI 10.1162/pres.1996.5.3.274
   Hettinger J., 1992, Presence: Teleoperators Virtual Environ., V1, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Holmqvist K., 2017, Faradigms and measures, V3, P5
   Hoppe D, 2018, P NATL ACAD SCI USA, V115, P2246, DOI 10.1073/pnas.1714220115
   Hung G. K., 1989, Experimenial neumlogy, V105, P8
   HUNG GK, 1990, EXP NEUROL, V110, P291, DOI 10.1016/0014-4886(90)90041-P
   Jones JA, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS, P77, DOI 10.1109/CTS.2015.7210403
   Joshi MR, 2015, VISION RES, V110, P68, DOI 10.1016/j.visres.2015.03.006
   Keeley S, 2023, AAAI CONF ARTIF INTE, P40
   Kennedy R. S., 2010, Applied ergonomics, V41, P3
   Kooijman L, 2024, BEHAV RES METHODS, V56, P2292, DOI 10.3758/s13428-023-02148-8
   Kramida G, 2016, IEEE T VIS COMPUT GR, V22, P1912, DOI 10.1109/TVCG.2015.2473855
   Lafer-Sousa R, 2015, CURR BIOL, V25, pR545, DOI 10.1016/j.cub.2015.04.053
   Langbehn E, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201335
   Lappe M, 1999, TRENDS COGN SCI, V3, P329, DOI 10.1016/S1364-6613(99)01364-9
   LaValle S. M., 2023, Virtual reality, P2
   Lee B, 2020, PROC SPIE, V11304, DOI 10.1117/12.2551400
   Leigh R. J., 2015, Contemporary Neurology, P3
   LIEBERMAN HR, 1982, BEHAV RES METH INSTR, V14, P21, DOI 10.3758/BF03202110
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   LUCE RD, 1958, PSYCHOL REV, V65, P222, DOI 10.1037/h0039821
   Lueder E, 2012, WILEY-SID SER DISPL, P1
   MANNING KA, 1984, VISION RES, V24, P521, DOI 10.1016/0042-6989(84)90105-6
   MORRONE MC, 1995, NATURE, V376, P507, DOI 10.1038/376507a0
   Nakano T, 2009, P ROY SOC B-BIOL SCI, V276, P3635, DOI 10.1098/rspb.2009.0828
   Nguyen A., 2018, P 24 ACM S VIRM REAL, P3
   Nguyen A., 2020, P 26 ACM S VIRM REAL, P1
   Owen L, 2021, Arxiv, DOI arXiv:2104.09549
   Piszczek M., 2023, Compensation of magnification variations in varifocal hmds by using a virtual camera, P2
   Rambold H, 2002, J NEUROPHYSIOL, V88, P1220, DOI 10.1152/jn.2002.88.3.1220
   Regan D., 1985, JOSA A, P3
   Robinett W., 1992, Presence: Teleoperators & VirmalEnvironmenis, V1, P6
   Rolland J. P., 1993, Citeseer, P6
   Slater M, 1997, PRESENCE-VIRTUAL AUG, V6, P603, DOI 10.1162/pres.1997.6.6.603
   Snowden RJ, 1996, J COGNITIVE NEUROSCI, V8, P435, DOI 10.1162/jocn.1996.8.5.435
   Snowden RJ, 1997, CURR BIOL, V7, P717, DOI 10.1016/S0960-9822(06)00329-0
   TOATES FM, 1972, PHYSIOL REV, V52, P828, DOI 10.1152/physrev.1972.52.4.828
   Tyler CW, 2012, J VISION, V12, DOI 10.1167/12.11.21
   VOLKMANN FC, 1986, VISION RES, V26, P1401, DOI 10.1016/0042-6989(86)90164-1
   WATSON BA, 1995, VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM '95, PROCEEDINGS, P172
   Wichmann FA, 2001, PERCEPT PSYCHOPHYS, V63, P1293, DOI 10.3758/BF03194544
   Williams N. L., 2019, IEEE transactions on visualizazion and computer graphics, V25, P8
   WITKIN HA, 1949, J PERS, V18, P145, DOI 10.1111/j.1467-6494.1949.tb01237.x
   Zenner A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580888
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zhan T., 2020, PhooniX, V1, P6
   Zhan T, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.201901360
   Zhao Y., 2023, ACM SIGGRAPH 2023 Emerging Technologies, P1
NR 68
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2570
EP 2579
DI 10.1109/TVCG.2024.3372075
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400019
PM 38437086
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Guo, ZX
   Wang, HY
   Deng, HX
   Xu, WE
   Baghaei, N
   Lo, CH
   Liang, HN
AF Guo, Zixuan
   Wang, Hongyu
   Deng, Hanxiao
   Xu, Wenge
   Baghaei, Nilufar
   Lo, Cheng-Hung
   Liang, Hai-Ning
TI Breaking the Isolation: Exploring the Impact of Passthrough in Shared
   Spaces on Player Performance and Experience in VR Exergames
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Passthrough; Exergames; Shared Spaces; Social
   Acceptability; Immersion
AB VR exergames offer an engaging solution to combat sedentary behavior and promote physical activity. However, challenges emerge when playing these games in shared spaces, particularly due to the presence of bystanders. VR's passthrough functionality enables players to maintain awareness of their surrounding environment while immersed in VR gaming, rendering it a promising solution to improve users' awareness of the environment. This study investigates the passthrough's impact on player performance and experiences in shared spaces, involving an experiment with 24 participants that examines Space (Office vs. Corridor) and Passthrough Function (With vs. Without). Results reveal that Passthrough enhances game performance and environmental awareness while reducing immersion. Players prefer an open area to an enclosed room, whether with or without Passthrough, finding it more socially acceptable. Additionally, Passthrough appears to encourage participation among players with higher self-consciousness, potentially alleviating their concerns about being observed by bystanders. Our findings provide valuable insights for designing VR experiences in shared spaces, underscoring the potential of VR's passthrough to enhance user experiences and promote VR adoption in these environments.
C1 [Guo, Zixuan; Wang, Hongyu; Deng, Hanxiao] Xian Jiaotong Liverpool Univ, Sch Adv Technol, Suzhou, Peoples R China.
   [Guo, Zixuan] Univ Liverpool, Dept Comp Sci, Liverpool, England.
   [Xu, Wenge] Birmingham City Univ, Sch Comp & Digital Technol, Birmingham, England.
   [Baghaei, Nilufar] Univ Queensland, Sch Elect Engn & Comp Sci, St Lucia, Australia.
   [Lo, Cheng-Hung] Xian Jiaotong Liverpool Univ, Dept Ind Design, Suzhou, Peoples R China.
   [Liang, Hai-Ning] Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
C3 Xi'an Jiaotong-Liverpool University; University of Liverpool; Birmingham
   City University; University of Queensland; Xi'an Jiaotong-Liverpool
   University; Xi'an Jiaotong-Liverpool University
RP Liang, HN (corresponding author), Xian Jiaotong Liverpool Univ, Dept Comp, Suzhou, Peoples R China.
EM Zixuan.Guo16@student.xjtlu.edu.cn; Hongyu.Wang20@student.xjtlu.edu.cn;
   Hanxiao.Deng22@student.xjtlu.edu.cn; Wenge.Xu@bcu.ac.uk;
   nilufar.baghaei@gmail.com; ChengHung.Lo@xjtlu.edu.cn;
   haining.liang@xjtlu.edu.cn
RI Lo, Cheng-Hung/ABG-7599-2020; Xu, Wenge/AAX-7883-2021; Baghaei,
   Nilufar/GYQ-6448-2022
OI Baghaei, Nilufar/0000-0003-1776-7075; deng, han
   xiao/0009-0005-4587-550X; Guo, Zixuan/0000-0002-0451-8988; Liang,
   Hai-Ning/0000-0003-3600-8955; Lo, Cheng-Hung/0000-0002-7199-9339; Wang,
   Hongyu/0000-0002-2288-5116; Xu, Wenge/0000-0001-7227-7437
FU This work was partially funded by the Suzhou Municipal Key Laboratory
   for Intelligent Virtual Engineering
FX No Statement Available
CR [Anonymous], 2003, The Journal of Strength & Conditioning Research, V17, P303
   Rico J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P887
   Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Vergari M, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P695, DOI 10.1109/VR50410.2021.00096
   von Willich J, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P487, DOI 10.1145/3322276.3322334
   vonGrunau M, 1995, PERCEPTION, V24, P1297, DOI 10.1068/p241297
   Wang B.-Y., 2022, INPROCEED INGS 35 AN, P1
   Wang J, 2004, J SCI MED SPORT, V7, P174, DOI 10.1016/S1440-2440(04)80007-0
   Williamson M., 2019, INPROCEEDINGS 2019 C, P1
   Xu H.-N., INPROCEEDINGSN
   Xu WG, 2021, JMIR SERIOUS GAMES, V9, DOI 10.2196/29330
NR 12
TC 1
Z9 1
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2580
EP 2590
DI 10.1109/TVCG.2024.3372114
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400033
PM 38437094
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Garzotto, F
   Gianotti, M
   Patti, A
   Pentimalli, F
   Vona, F
AF Garzotto, Franca
   Gianotti, Mattia
   Patti, Alberto
   Pentimalli, Francesca
   Vona, Francesco
TI Empowering Persons with Autism Through Cross-Reality and Conversational
   Agents
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Human computer interaction; Accessibility technologies; Interactive
   learning environments; Virtual reality; Augmented reality;
   Conversational agents
ID AUGMENTED REALITY; ADOLESCENTS; STUDENTS; ADULTS
AB Autism Spectrum Disorder is a neurodevelopmental condition that can affect autonomy and independence. Our research explores the integration of Cross-Reality and Conversational Agents for Autistic persons to improve ability and confidence in everyday life situations. We combine two technologies of the Virtual-Real continuum. User experiences unfold from the simulation of tasks in VR to the execution of similar tasks supported by AR in the real world. A speech-based Conversational Agent is integrated with both VR and AR. It provides contextualized help, promotes generalization, and stimulates users to apply what they learned in the virtual space. The paper presents the approach and describes an empirical study involving 17 young Autistic persons.
C1 [Garzotto, Franca; Gianotti, Mattia; Patti, Alberto; Pentimalli, Francesca; Vona, Francesco] Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy.
C3 Polytechnic University of Milan
RP Garzotto, F (corresponding author), Politecn Milan, Dept Elect Informat & Bioengn, Milan, Italy.
EM franca.garzotto@polimi.it; mattia.gianotti@polimi.it;
   alberto.patti@polimi.it; francesca.pentimalli@polimi.it;
   francesco.vona@polimi.it
RI Gianotti, Mattia/AAC-2326-2022; Garzotto, Franca/AAQ-7886-2020
OI Pentimalli, Francesca/0000-0002-5052-0560; Vona,
   Francesco/0000-0003-4558-4989; Gianotti, Mattia/0000-0001-6035-3367;
   Patti, Alberto/0000-0002-6871-7417
FU TIM Foundation Program "Liberi di comunicare"
FX No Statement Available
CR Adjorlu A, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P294, DOI 10.1109/ISMAR-Adjunct.2017.93
   Ali MR, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423900
   Allouch M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248448
   Berenguer C, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176143
   Bernardes M, 2015, 2015 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION PROCEEDINGS (ICVR), P127, DOI 10.1109/ICVR.2015.7358609
   Bradley R, 2018, J ENABLING TECHNOL, V12, P101, DOI 10.1108/JET-01-2018-0004
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Cha I, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445116
   Cihak DF, 2016, J SPEC EDUC TECHNOL, V31, P99, DOI 10.1177/0162643416651724
   Cowan RJ, 2007, PSYCHOL SCHOOLS, V44, P701, DOI 10.1002/pits.20259
   Feldman JI, 2018, NEUROSCI BIOBEHAV R, V95, P220, DOI 10.1016/j.neubiorev.2018.09.020
   Glaser N, 2022, VIRTUAL REAL-LONDON, V26, P1705, DOI 10.1007/s10055-022-00661-3
   Gonzalez L, 2018, Clarifai featured hack: Spectrum navigator is a GPS app that helps people navigate by landmark
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hartholt A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON HUMAN-AGENT INTERACTION (HAI'19), P205, DOI 10.1145/3349537.3352766
   Howlin P, 1998, J CHILD PSYCHOL PSYC, V39, P307, DOI 10.1111/1469-7610.00327
   Karami B, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.665326
   Ladner Richard E., 2015, INTERACTIONS, V22, P2, DOI [DOI 10.1145/2723869, 10.1145/2723869]
   LOVAAS OI, 1987, J CONSULT CLIN PSYCH, V55, P3, DOI 10.1037/0022-006X.55.1.3
   McCleery JP, 2020, AUTISM RES, V13, P1418, DOI 10.1002/aur.2352
   McCready M, 2022, IEEE INT SYMP M AU R, P183, DOI 10.1109/ISMAR-Adjunct57072.2022.00041
   McMahon D, 2015, J RES TECHNOL EDUC, V47, P157, DOI 10.1080/15391523.2015.1047698
   Miller IT, 2020, AUTISM ADULTHOOD, V2, P325, DOI 10.1089/aut.2019.0076
   Mirenda P. L., 1987, Handbook of autism and pervasive developmental disorders
   Nadel J., 2022, Autism and Socially Interactive Agents, V1st, P437, DOI [10.1145/3563659.3563673, DOI 10.1145/3563659.3563673]
   Parris J, 2019, Boise airport virtual reality experience will help children with autism
   Rao PA, 2008, J AUTISM DEV DISORD, V38, P353, DOI 10.1007/s10803-007-0402-4
   Razavi SZ, 2016, LECT NOTES ARTIF INT, V10011, P460, DOI 10.1007/978-3-319-47665-0_55
   Smith MJ, 2014, J AUTISM DEV DISORD, V44, P2450, DOI 10.1007/s10803-014-2113-y
   Soccini Agata Marta, 2020, Virtual Reality and Augmented Reality. 17th EuroVR International Conference, EuroVR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12499), P234, DOI 10.1007/978-3-030-62655-6_16
   Soriano LD, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-24478-x
   Tanaka H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182151
   Thomsen LA, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P50, DOI 10.1109/VRW52623.2021.00015
   Wang M, 2013, SCI WORLD J, DOI 10.1155/2013/716890
   Wang NJ, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531116
   Williams DL, 2015, AUTISM, V19, P859, DOI 10.1177/1362361315586171
   Williams DL, 2014, J AUTISM DEV DISORD, V44, P2908, DOI 10.1007/s10803-014-2190-y
NR 38
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2591
EP 2601
DI 10.1109/TVCG.2024.3372110
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400047
PM 38437092
DA 2024-11-06
ER

PT J
AU Seraji, MR
   Piray, P
   Zahednejad, V
   Stuerzlinger, W
AF Seraji, Mohammad Rajabi
   Piray, Parastoo
   Zahednejad, Vahid
   Stuerzlinger, Wolfgang
TI Analyzing User Behaviour Patterns in a Cross-Virtuality Immersive
   Analytics System
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Immersive Analytics; Cross-virtuality Analytics; Visualization;
   Human-computer Interaction
ID INFORMATION VISUALIZATION; REALITY; EXPLORATION
AB Recent work in immersive analytics suggests benefits for systems that support work across both 2D and 3D data visualizations, i.e., cross-virtuality analytics systems. Here, we introduce HybridAxes, an immersive visual analytics system that enables users to conduct their analysis either in 2D on desktop monitors or in 3D within an immersive AR environment - while enabling them to seamlessly switch and transfer their graphs between modes. Our user study results show that the cross-virtuality sub-systems in HybridAxes complement each other well in helping the users in their data-understanding journey. We show that users preferred using the AR component for exploring the data, while they used the desktop to work on more detail-intensive tasks. Despite encountering some minor challenges in switching between the two virtuality modes, users consistently rated the whole system as highly engaging, user-friendly, and helpful in streamlining their analytics processes. Finally, we present suggestions for designers of cross-virtuality visual analytics systems and identify avenues for future work.
C1 [Seraji, Mohammad Rajabi; Piray, Parastoo; Zahednejad, Vahid; Stuerzlinger, Wolfgang] Simon Fraser Univ, Burnaby, BC, Canada.
C3 Simon Fraser University
RP Seraji, MR (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM mrajabis@sfu.ca; ppa35@sfu.ca; vahid_zahednejad@sfu.ca; w.s@sfu.ca
OI Stuerzlinger, Wolfgang/0000-0002-7110-5024
FU Canadian NRC for funding
FX No Statement Available
CR Akpan IJ, 2019, SIMUL-T SOC MOD SIM, V95, P145, DOI 10.1177/0037549718757039
   Amar R, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P111, DOI 10.1109/INFVIS.2005.1532136
   Batmaz W., 2019, 2019 CHI C HUM FACT, P1, DOI [10.1145/3290607.33127523[4]H, DOI 10.1145/3290607.33127523[4]H]
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Blum G., 2019, InComputer Science Research Notes. Zapadoceskauniverzita, DOI [10.24132/CSRN.2019.2902.2.93[8]M, DOI 10.24132/CSRN.2019.2902.2.93[8]M]
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Cavallo M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P145, DOI [10.1109/vr.2019.8797733, 10.1109/VR.2019.8797733]
   Chakraborty S, 2021, LECT NOTES COMPUT SC, V12934, P610, DOI 10.1007/978-3-030-85613-7_39
   Concord-Consortium, 2014, Common online data analysis platform (CODAP)
   Cordeil B., 2020, Embodied Axes: Tangible, Actuated Interaction for3D Augmented Reality Data Spaces, V2, P1
   Cordeil M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376613
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/vr.2019.8797978, 10.1109/VR.2019.8797978]
   Cordeil M, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P71, DOI 10.1145/3126594.3126613
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Dwyer T, 2018, LECT NOTES COMPUT SC, V11190, P1, DOI 10.1007/978-3-030-01388-2_1
   El Meseery M., 2018, S BIG DAT VIS AN BDV, P70, DOI [10.1109/BDVA.2018.8534019, DOI 10.1109/BDVA.2018.85340193,5[19]B]
   Ens Barrett, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3446866
   Ens B, 2021, IEEE T VIS COMPUT GR, V27, P1193, DOI 10.1109/TVCG.2020.3030334
   Fisherkeller M., 1974, Science, V155, P279
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Garrido Daniel, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12742), P628, DOI 10.1007/978-3-030-77961-0_50
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Grasset Raphael, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P231, DOI 10.1109/ISMAR.2006.297819
   Hinckley Ken, 2010, P 23 ANN ACM S US IN, P27, DOI [DOI 10.1145/1866029.1866036, DOI 10.1145/1866029.18660362]
   Hubenschmid S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517550
   Jetter HC, 2021, ISS '21 COMPANION: COMPANION PROCEEDINGS OF THE 2021 CONFERENCE ON INTERACTIVE SURFACES AND SPACES SPONSORED, P46, DOI 10.1145/3447932.3487940
   Jo J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2660, DOI 10.1145/3025453.3025752
   Kosara R, 2006, IEEE T VIS COMPUT GR, V12, P558, DOI 10.1109/TVCG.2006.76
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Laramee RS, 2007, LECT NOTES COMPUT SC, V4417, P231
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   Lee B, 2019, PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS '19), P335, DOI 10.1145/3343055.3360746
   McIntire JP, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P1, DOI 10.1109/3DVis.2014.7160093
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Millais P, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188537
   Nielsen J, 2003, Usability 101: Introduction to Usability
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Reski N., 2020, P 11 NORD C HUM COMP
   Riegler A., 2020, XR@ISS, V11
   Rzeszotarski JM, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P897, DOI 10.1145/2556288.2557231
   Sadana R, 2014, IEEE T VIS COMPUT GR, V20, P1993, DOI 10.1109/TVCG.2014.2346249
   Saffo D, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581093
   Sicat R, 2019, IEEE T VIS COMPUT GR, V25, P715, DOI 10.1109/TVCG.2018.2865152
   Snowdon Dave., 2001, COLLABORATIVE VIRTUA, P3, DOI DOI 10.1007/978-1-4471-0685-2_1
   Stuerzlinger W, 2018, LECT NOTES COMPUT SC, V11190, P139, DOI 10.1007/978-3-030-01388-2_5
   Thomas J. J., 2005, Illuminating the path: The research and development agenda for visual analytics
   Tong W, 2023, Symposium Virtual Re, P387, DOI 10.1109/VR55154.2023.00054
   Wagner JA, 2020, IEEE T VIS COMPUT GR, V26, P514, DOI 10.1109/TVCG.2019.2934415
   Wang L., 2020, Towards an Understanding of Augmented Reality Extensions forExisting 3D Data Analysis Tools, P1
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Zaman C., 2018, 2018 CHI C HUM FACT, P1, DOI [10.1145/3170427.31885934\n, DOI 10.1145/3170427.31885934]
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2613
EP 2623
DI 10.1109/TVCG.2024.3372129
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400037
PM 38470602
DA 2024-11-06
ER

PT J
AU Friedl-Knirsch, J
   Stach, C
   Pointecker, F
   Anthes, C
   Roth, D
AF Friedl-Knirsch, Judith
   Stach, Christian
   Pointecker, Fabian
   Anthes, Christoph
   Roth, Daniel
TI A Study on Collaborative Visual Data Analysis in Augmented Reality with
   Asymmetric Display Types
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Collaboration; Data analysis; Three-dimensional displays; Augmented
   reality; Stereo image processing; Visualization; Resists; Augmented
   Reality; Empirical Studies
ID VISUALIZATION
AB Collaboration is a key aspect of immersive visual data analysis. Due to its inherent benefit of seeing co-located collaborators, augmented reality is often useful in such collaborative scenarios. However, to enable the augmentation of the real environment, there are different types of technology available. While there are constant developments in specific devices, each of these device types provide different premises for collaborative visual data analysis. In our work we combine handheld, optical see-through and video see-through displays to explore and understand the impact of these different device types in collaborative immersive analytics. We conducted a mixed-methods collaborative user study where groups of three performed a shared data analysis task in augmented reality with each user working on a different device, to explore differences in collaborative behaviour, user experience and usage patterns. Both quantitative and qualitative data revealed differences in user experience and usage patterns. For collaboration, the different display types influenced how well participants could participate in the collaborative data analysis, nevertheless, there was no measurable effect in verbal communication.
C1 [Friedl-Knirsch, Judith] Tech Univ Munich, Human Ctr Comp & Extended Real Lab, Munich, Germany.
   [Friedl-Knirsch, Judith; Stach, Christian; Pointecker, Fabian; Anthes, Christoph] Univ Appl Sci Upper Austria, Wels, Austria.
   [Roth, Daniel] Tech Univ Munich, Sch Med, Munich, Germany.
   [Roth, Daniel] Tech Univ Munich, Dept Clin Med Orthoped & Sports Orthoped, Hlth Human Ctr Comp & Extended Real Lab, Machine Intelligence Orthoped,Klinikum Rechts Isar, Munich, Germany.
C3 Technical University of Munich; Technical University of Munich;
   Technical University of Munich
RP Friedl-Knirsch, J (corresponding author), Tech Univ Munich, Human Ctr Comp & Extended Real Lab, Munich, Germany.; Friedl-Knirsch, J (corresponding author), Univ Appl Sci Upper Austria, Wels, Austria.
EM judith.friedl-knirsch@fh-ooe.at; christian.stach@fh-ooe.at;
   fabian.pointecker@fh-ooe.at; christoph.anthes@fh-ooe.at;
   daniel.roth@tum.de
OI Friedl-Knirsch, Judith/0000-0002-8350-0996
FU Government of Upper Austria
FX No Statement Available
CR Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Benko H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P132, DOI 10.1109/ISMAR.2004.23
   Benko Hrvoje, 2014, P 27 ANN ACM S US IN, P645, DOI DOI 10.1145/2642918.2647402
   Billinghurst M, 1999, MIXED REALITY, P261
   Billinghurst M., 1998, Virtual Reality, V3, P25, DOI 10.1007/BF01409795
   Billinghurst M, 2018, LECT NOTES COMPUT SC, V11190, P221, DOI 10.1007/978-3-030-01388-2_8
   Butscher S, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173664
   Butz A., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P35, DOI 10.1109/IWAR.1999.803804
   do Carmo RMC, 2007, IEEE INT CONF INF VI, P156
   Cavallo M, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364242
   Chandler T, 2015, 2015 BIG DATA VISUAL ANALYTICS (BDVA)
   Cordeil M, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P200, DOI [10.1109/vr.2019.8797978, 10.1109/VR.2019.8797978]
   Cordeil M, 2017, IEEE T VIS COMPUT GR, V23, P441, DOI 10.1109/TVCG.2016.2599107
   Das H., 1995, Telemanipulatorand Telepresence Technologies, P293, DOI [10.1117/12.1973221,2,3[40]D, DOI 10.1117/12.1973221,2,3[40]D]
   Friedl-Knirsch C., IN2023 IEEE IN TERNA, P65, DOI [10.1109/ISMAR-Adjunct60411.2023.000215[15]B, DOI 10.1109/ISMAR-ADJUNCT60411.2023.000215[15]B]
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Haller M., 2005, INPROCEEDINGS 2005IN, P40, DOI [DOI 10.1145/1152399.1152408, 10.1145/1152399.11524082, DOI 10.1145/1152399.11524082]
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Henrysson A, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P80
   Hubenschmid S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445298
   Johansen Robert, 1988, Groupware: Computer support for business teams
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Kiyokawa K, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P139, DOI 10.1109/ISMAR.2002.1115083
   Langner M., 2021, INPROCEEDINGS 2021 C, P1, DOI [10.1145/3411764.34455931,2[24]B, DOI 10.1145/3411764.34455931,2[24]B]
   Laugwitz T., Construction and Evaluation of aUser Experience Questionnaire
   Lee B, 2021, IEEE T VIS COMPUT GR, V27, P1171, DOI 10.1109/TVCG.2020.3030450
   MacWilliams A, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P123, DOI 10.1109/ISMAR.2003.1240695
   Mahmood E., 2018, IN2018 INT S BIG DAT, P1, DOI [10.1109/BDVA.2018.85338932[28]P, DOI 10.1109/BDVA.2018.85338932[28]P]
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Möhring M, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P252, DOI 10.1109/ISMAR.2004.63
   Nilsson S, 2009, INT SYM MIX AUGMENT, P3, DOI 10.1109/ISMAR.2009.5336522
   Ohshima T, 1998, P IEEE VIRT REAL ANN, P268, DOI 10.1109/VRAIS.1998.658505
   Phon DNE, 2014, INT CONF TEACH LEARN, P78, DOI 10.1109/LaTiCE.2014.23
   Pidel C, 2020, LECT NOTES COMPUT SC, V12242, P141, DOI 10.1007/978-3-030-58465-8_10
   Pointecker F., 2021, ISS 21 WORKSHOP P TR, DOI [10.18148/KOPS/352-2-1L3L2WNCU3TGB5, DOI 10.18148/KOPS/352-2-1L3L2WNCU3TGB5]
   Radu Iulian, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432944
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rekimoto J., 1996, P VIRTUAL SYSTEMS MU, P2
   Riegler A., 2020, INT WORKSHOP CROSS R
   Rolland R. L., Comparison of optical andvideo see-through, head-mounted displays
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Seraji MR, 2022, IEEE INT SYMP M AU R, P146, DOI 10.1109/ISMAR-Adjunct57072.2022.00035
   Sereno L., 2019, EuroVis 2019 - Posters, DOI [10.2312/EURP.201911362[43]M, DOI 10.2312/EURP.201911362[43]M]
   Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761
   Smiley B., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, p501:1, DOI [10.1145/34885465[46]T.A., DOI 10.1145/34885465[46]T.A]
   Syed TA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010146
   Szalavari Z., 1998, Virtual Reality, V3, P37, DOI 10.1007/BF01409796
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
NR 48
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2633
EP 2643
DI 10.1109/TVCG.2024.3372103
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400052
PM 38437119
OA hybrid
DA 2024-11-06
ER

PT J
AU Morgenstern, W
   Bagdasarian, MT
   Hilsmann, A
   Eisert, P
AF Morgenstern, Wieland
   Bagdasarian, Milena T.
   Hilsmann, Anna
   Eisert, Peter
TI Animatable Virtual Humans: Learning Pose-Dependent Human Representations
   in UV Space for Interactive Performance Synthesis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Geometry; Computational modeling; Shape;
   Real-time systems; X reality; Three-dimensional displays; Virtual
   Humans; Real-time Animation; Generative Neural Networks; Volumetric
   Video; XR Applications
AB We propose a novel representation of virtual humans for highly realistic real-time animation and rendering in 3D applications. We learn pose dependent appearance and geometry from highly accurate dynamic mesh sequences obtained from state-of-the-art multiview-video reconstruction. Learning pose-dependent appearance and geometry from mesh sequences poses significant challenges, as it requires the network to learn the intricate shape and articulated motion of a human body. However, statistical body models like SMPL provide valuable a-priori knowledge which we leverage in order to constrain the dimension of the search space, enabling more efficient and targeted learning and to define pose-dependency. Instead of directly learning absolute pose-dependent geometry, we learn the difference between the observed geometry and the fitted SMPL model. This allows us to encode both pose-dependent appearance and geometry in the consistent UV space of the SMPL model. This approach not only ensures a high level of realism but also facilitates streamlined processing and rendering of virtual humans in real-time scenarios.
C1 [Morgenstern, Wieland; Bagdasarian, Milena T.; Hilsmann, Anna; Eisert, Peter] Fraunhofer Heinrich Hertz Inst, HHI, Berlin, Germany.
   [Bagdasarian, Milena T.; Eisert, Peter] Humboldt Univ, Berlin, Germany.
C3 Fraunhofer Gesellschaft; Humboldt University of Berlin
RP Morgenstern, W (corresponding author), Fraunhofer Heinrich Hertz Inst, HHI, Berlin, Germany.
EM wieland.morgenstern@hhi.fraunhofer.de;
   milenat.bagdasarian@hhi.fraunhofer.de; anna.hilsmann@hhi.fraunhofer.de;
   peter.eisert@hhi.fraunhofer.de
RI Eisert, Peter/AAX-7968-2020
FU European Union
FX No Statement Available
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   [Anonymous], 2021, Github, V3
   B. O. Community, 2024, Blender - a 3D modelling and rendering package
   Bai K., ONNX: Open Neural Network Exchange
   Boukhayma A, 2019, IEEE T VIS COMPUT GR, V25, P2270, DOI 10.1109/TVCG.2018.2831233
   Bradski G, 2000, DR DOBBS J, V25, P120
   Fechteler P, 2019, COMPUT GRAPH FORUM, V38, P91, DOI 10.1111/cgf.13608
   Feng Y, 2021, INT CONF 3D VISION, P792, DOI 10.1109/3DV53792.2021.00088
   Gafni G, 2021, PROC CVPR IEEE, P8645, DOI 10.1109/CVPR46437.2021.00854
   Grassal PW, 2022, PROC CVPR IEEE, P18632, DOI 10.1109/CVPR52688.2022.01810
   Haas K.J., 2014, DISS WORCESTER POLYT, P484
   Habermann M, 2023, P ACM COMPUT GRAPH, V6, DOI 10.1145/3606927
   Jiang X., 2023, InProc. IEEE/CVF Con-ference on Computer Vision and Pattern Recognition (CVPR), V3
   Kingma J. L. Ba., 2015, 3 INT C LEARNING REP, V6
   Knoll W., 2024, INPROC INT C COMPUTE
   Liu LJ, 2021, IEEE T VIS COMPUT GR, V27, P4009, DOI 10.1109/TVCG.2020.2996594
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Ma SG, 2021, PROC CVPR IEEE, P64, DOI 10.1109/CVPR46437.2021.00013
   Morgenstern A., 2019, INPROCEEDINGS CVMP 2, P1
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Paier W, 2020, IET COMPUT VIS, V14, P359, DOI 10.1049/iet-cvi.2019.0790
   Park K, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480487
   Paszke A, 2019, ADV NEUR IN, V32
   Prokudin S, 2021, IEEE WINT CONF APPL, P1809, DOI 10.1109/WACV48630.2021.00185
   Regateiro J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.739010
   Sarkar L., 2021, arXiv, V3
   Schreer O, 2019, IEEE IMAGE PROC, P4310, DOI [10.1109/ICIP.2019.8803576, 10.1109/icip.2019.8803576]
   Shen KY, 2023, PROC CVPR IEEE, P16911, DOI 10.1109/CVPR52729.2023.01622
   Su SY, 2021, ADV NEUR IN, V34
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P601, DOI 10.1007/978-3-030-58548-8_35
   Wang X., 2022, arXiv, V3
   Weng CY, 2022, PROC CVPR IEEE, P16189, DOI 10.1109/CVPR52688.2022.01573
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Xu TH, 2022, PROC CVPR IEEE, P15862, DOI 10.1109/CVPR52688.2022.01542
   Zheng H., 2022, INPROC IEEECVFCONFER, ppag
   Zheng X. Zhao, 2023, ACM Trans. Graph., V42
   Zimmer A, 2023, COMPUT VIS MEDIA, V9, P123, DOI 10.1007/s41095-022-0272-x
NR 38
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2644
EP 2650
DI 10.1109/TVCG.2024.3372117
PG 7
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400011
PM 38466595
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Benda, B
   Rheault, B
   Lin, YN
   Ragan, ED
AF Benda, Brett
   Rheault, Benjamin
   Lin, Yanna
   Ragan, Eric D.
TI Examining Effects of Technique Awareness on the Detection of Remapped
   Hands in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Legged locomotion; Meters; Virtual environments; Turning;
   Three-dimensional displays; Bending; virtual reality; interaction
   techniques; human perception
ID REDIRECTED WALKING; ROTATION
AB Input remapping techniques have been widely explored to allow users in virtual reality to exceed both their own physical abilities, the limitations of physical space, or to facilitate interactions with real-world objects. Often considered is how these techniques can be applied to achieve maximum utility, but still be undetectable to users to maintain a sense of immersion and presence. Existing psychophysical methods used to determine these detection thresholds have known limitations: they are highly conservative lower bounds for detection and do not account for complex usage of the technique. Our work describes and evaluates a method for estimating detection that reduces these limitations and yields meaningful upper bounds. We present the findings of our work where we apply this method to a well-explored hand motion scaling technique. In wholly unaware cases, we determined that users may detect their hand speed as abnormal at around 3.37 times the normal speed, compared to a scale factor of 1.47 that was estimated using traditional methods when users knew the motion scaling was occurring. A considerable number of participants in unaware cases (12 of 56) never detected their hand speed increasing at all, even at the maximum scale factor of 5.0. The study demonstrates just how conservative the thresholds generated by traditional psychophysical methods can be compared to detection during naive usage, and our method can be modified and applied easily to other techniques.
C1 [Benda, Brett; Rheault, Benjamin; Lin, Yanna; Ragan, Eric D.] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32603 USA.
C3 State University System of Florida; University of Florida
RP Benda, B (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32603 USA.
EM brett.benda@ufl.edu; brheault@ufl.edu; linyanna@ufl.edu; eragan@ufl.edu
OI Benda, William/0000-0002-1825-6392
FU DARPA Perceptually-enabled Task Guidance (PTG) Program
FX No Statement Available
CR Abrahamyan A, 2016, P NATL ACAD SCI USA, V113, pE3548, DOI 10.1073/pnas.1518786113
   [Anonymous], 2005, Proc. of the 18th Annual ACM Symposium on User interface Software and Technology (UIST'05), DOI [10.1145/1095034.1095041, DOI 10.1145/1095034.1095041]
   Auteri C., 2013, The International Journal of Virtual Reality, V12, P66
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Balogun MB, 2019, AFRICON, DOI [10.1109/africon46755.2019.9133906, 10.1145/3290605.3300331]
   Benda B, 2020, INT SYM MIX AUGMENT, P269, DOI 10.1109/ISMAR50242.2020.00050
   Bolte Benjamin, 2010, P 17 ACM S VIRT REAL, P11
   Bowman DA, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2330667.2330687
   Burns E, 2005, P IEEE VIRT REAL ANN, P3
   Carvalheiro C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1146, DOI 10.1145/2964284.2964293
   Chance SS, 1998, PRESENCE-TELEOP VIRT, V7, P168, DOI 10.1162/105474698565659
   Cheng LP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3718, DOI 10.1145/3025453.3025753
   Clarence A, 2022, INT SYM MIX AUGMENT, P612, DOI 10.1109/ISMAR55827.2022.00078
   Cohn BA, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND VIRTUAL REALITY (AIVR 2020), P74, DOI 10.1109/AIVR50618.2020.00024
   CORNSWEET TN, 1962, AM J PSYCHOL, V75, P485, DOI 10.2307/1419876
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P341, DOI 10.1109/VR.2018.8448285
   Dennison MS, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1858, DOI [10.1109/VR.2019.8798297, 10.1109/vr.2019.8798297]
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.1581285352835, 10.1109/VR46266.2020.00-38]
   Farell B., 1999, Vision research: A practical guide to laboratory methods, V5, P129, DOI [10.1093/acprof:oso/9780198523192.003.0005, DOI 10.1093/ACPROF:OSO/9780198523192.003.0005]
   Feick M, 2023, Symposium Virtual Re, P194, DOI 10.1109/VR55154.2023.00035
   Feuchtner T, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P31, DOI 10.1145/3242587.3242594
   Frees S, 2005, P IEEE VIRT REAL ANN, P99
   Gescheider George A., 1997, Psychophysics, P261, DOI DOI 10.4324/9780203774458
   Gonzalez EJ, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364248
   Gonzalez EJ, 2019, ADJUNCT PUBLICATION OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'19 ADJUNCT), P4, DOI 10.1145/3332167.3357096
   Gonzalez-Franco M, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P18, DOI [10.1109/VR46266.2020.00-85, 10.1109/VR46266.2020.1580500165557]
   Han DT, 2018, IEEE T VIS COMPUT GR, V24, P1467, DOI 10.1109/TVCG.2018.2794659
   Hincapié-Ramos JD, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1063, DOI 10.1145/2556288.2557130
   Insko Brent Edward, 2001, Ph.D. Dissertation. Advisor(s) Brooks,Jr., Frederick P.
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kingdom F.A.A., 2010, Psychophysics: A Practical Introduction
   Kohm K, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3561055
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Lilija K, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P455, DOI 10.1109/VR50410.2021.00069
   Linares D, 2016, R J, V8, P122
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   Murillo RAM, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P759, DOI 10.1145/3126594.3126605
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Ogawa N, 2021, IEEE T VIS COMPUT GR, V27, P3182, DOI 10.1109/TVCG.2020.2964758
   Porssut T, 2022, IEEE T VIS COMPUT GR, V28, P3193, DOI 10.1109/TVCG.2021.3057797
   Poupyrev M., 1996, P 9 ANN ACM S USER I, P79, DOI DOI 10.1145/237091.237102
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Razzaque S., 2005, Redirected Walking
   Riecke B.E., 2012, vection") in virtual reality?, P17
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Sargunam SP, 2017, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2017.7892227
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Schwind V, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1577, DOI 10.1145/3025453.3025602
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Tieri G, 2015, EXP BRAIN RES, V233, P1247, DOI 10.1007/s00221-015-4202-3
   Tsakiris M, 2005, J EXP PSYCHOL HUMAN, V31, P80, DOI 10.1037/0096-1523.31.1.80
   Usoh M, 1999, COMP GRAPH, P359, DOI 10.1145/311535.311589
   Van Someren Maarten W, 1994, THINK ALOUD METHOD P, V11, P29
   Watson AB, 2017, J VISION, V17, DOI 10.1167/17.3.10
   Weise M., 2020, i-com, V19, P67, DOI [10.1515/icom-2020-0011, DOI 10.1515/ICOM-2020-0011]
   You C, 2022, INT SYM MIX AUGMENT, P603, DOI 10.1109/ISMAR55827.2022.00077
   Zenner A, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P75, DOI 10.1109/VR50410.2021.00028
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
NR 62
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2651
EP 2661
DI 10.1109/TVCG.2024.3372054
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400005
PM 38437116
DA 2024-11-06
ER

PT J
AU Raikwar, A
   Mifsud, D
   Wickens, CD
   Batmaz, AU
   Warden, AC
   Kelley, B
   Clegg, BA
   Ortega, FR
AF Raikwar, Aditya
   Mifsud, Domenick
   Wickens, Christopher D.
   Batmaz, Anil Ufuk
   Warden, Amelia C.
   Kelley, Brendan
   Clegg, Benjamin A.
   Ortega, Francisco R.
TI Beyond the Wizard of Oz: Negative Effects of Imperfect Machine Learning
   to Examine the Impact of Reliability of Augmented Reality Cues on Visual
   Search Performance
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Automation; Reliability; Machine learning; Task analysis;
   Search problems; Resists; Augmented Reality; Visual Search; Automation
   Bias; Imperfect Cues
ID AUTOMATION; TRUST; ALLOCATION; ATTENTION
AB Despite knowing exactly what an object looks like, searching for it in a person's visual field is a time-consuming and error-prone experience. In Augmented Reality systems, new algorithms are proposed to speed up search time and reduce human errors. However, these algorithms might not always provide 100% accurate visual cues, which might affect users' perceived reliability of the algorithm and, thus, search performance. Here, we examined the detrimental effects of automation bias caused by imperfect cues presented in the Augmented Reality head-mounted display using the YOLOv5 machine learning model. 53 participants in the two groups received either 100% accurate visual cues or 88.9% accurate visual cues. Their performance was compared with the control condition, which did not include any additional cues. The results show how cueing may increase performance and shorten search times. The results also showed that performance with imperfect automation was much worse than perfect automation and that, consistent with automation bias, participants were frequently enticed by incorrect cues.
C1 [Raikwar, Aditya; Warden, Amelia C.; Kelley, Brendan; Ortega, Francisco R.] Colorado State Univ, Ft Collins, CO 80523 USA.
   [Mifsud, Domenick] Georgia Inst Technol, Atlanta, GA USA.
   [Wickens, Christopher D.; Batmaz, Anil Ufuk] Concordia Univ, Montreal, PQ, Canada.
   [Clegg, Benjamin A.] Montana State Univ, Bozeman, MT USA.
C3 Colorado State University; University System of Georgia; Georgia
   Institute of Technology; Concordia University - Canada; Montana State
   University System; Montana State University Bozeman
RP Raikwar, A (corresponding author), Colorado State Univ, Ft Collins, CO 80523 USA.
EM adityaraikwar@gmail.com; dmifsud3@gatech.edu;
   chris.wickens@colostate.edu; ufuk.batmaz@concordia.ca;
   acwarden@colostate.edu; brendan.kelley@colostate.edu;
   benjamin.clegg@montana.edu; fortega@colostate.edu
RI Batmaz, Anil Ufuk/ABE-7803-2021
OI Warden, Amelia C./0000-0002-8916-1825; RAIKWAR,
   ADITYA/0009-0005-9427-9253; Clegg, Benjamin/0000-0001-6026-5076; BATMAZ,
   ANIL UFUK/0000-0001-7948-8093; Wickens, Christopher/0000-0002-6789-4446
FU NSF
FX No Statement Available
CR Barbotin N, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P213, DOI 10.1109/VR51125.2022.00040
   Bartlett ML, 2017, HUM FACTORS, V59, P881, DOI 10.1177/0018720817700258
   Beyer L, 2020, Arxiv, DOI [arXiv:2006.07159, DOI 10.48550/ARXIV.2006.07159]
   Biocca F., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1115
   Bitner MJ, 2002, ACAD MANAGE EXEC, V16, P96, DOI 10.5465/AME.2002.8951333
   Boskemper MM, 2022, HUM FACTORS, V64, P945, DOI 10.1177/0018720820983632
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Dodge S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017)
   Drury C., 1990, Visual search in industrial inspection
   Goh J., 2005, P HUMAN FACTORS ERGO, V49, P492, DOI [DOI 10.1177/154193120504900359, 10.1177/154193120504900359]
   Gramopadhye AK, 2002, INT J IND ERGONOM, V30, P181, DOI 10.1016/S0169-8141(02)00099-9
   Henderson SJ, 2009, INT SYM MIX AUGMENT, P135, DOI 10.1109/ISMAR.2009.5336486
   Hoff KA, 2015, HUM FACTORS, V57, P407, DOI 10.1177/0018720814547570
   Honda T, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00760
   Jocher Glenn, 2022, Zenodo
   Kumaran R, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581413
   LEE J, 1992, ERGONOMICS, V35, P1243, DOI 10.1080/00140139208967392
   Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392
   Lu WQ, 2014, IEEE T VIS COMPUT GR, V20, P404, DOI 10.1109/TVCG.2013.241
   Mifsud Domenick, 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P2198, DOI 10.1177/1071181322661143
   Phan MT, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1298, DOI 10.1109/ITSC.2016.7795724
   Mosier KL, 1999, HUM FAC ERG SOC P, P344
   NEISSER U, 1964, SCI AM, V210, P94, DOI 10.1038/scientificamerican0664-94
   openfoam, ABOUT US
   Parasuraman R, 2010, HUM FACTORS, V52, P381, DOI 10.1177/0018720810376055
   Patil D. K., 2022, PhD thesis
   POSNER MI, 1980, J EXP PSYCHOL GEN, V109, P160, DOI 10.1037/0096-3445.109.2.160
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Posner MI, 2016, Q J EXP PSYCHOL, V69, P1864, DOI 10.1080/17470218.2014.937446
   Sargent R., 2023, Human-Computer Interaction
   Schemmer M., 2022, On the influence of explainable ai on automation bias
   Seeliger A, 2024, INT J HUM-COMPUT INT, V40, P761, DOI 10.1080/10447318.2022.2122114
   Shneiderman B, 2021, ISSUES SCI TECHNOL, V37, P56
   shop.mattel, Mega bloks
   store.opencv, Oak-1
   Syiem BV., 2021, C HUMAN FACTORS COMP, DOI DOI 10.1145/3411764.3445580
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   varjo, Varjo xr-3
   Warden Amelia C., 2022, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P373, DOI 10.1177/1071181322661260
   Warden AC, 2023, IEEE T HUM-MACH SYST, V53, P1061, DOI 10.1109/THMS.2023.3302152
   Wickens C. D., 2023, Applied attention theory, V2nd
   Wolfe JM, 2021, PSYCHON B REV, V28, P1060, DOI 10.3758/s13423-020-01859-9
   Wu Chia-Chien, 2019, Vision (Basel), V3, DOI 10.3390/vision3020032
   Yantis S., 1993, CURR DIR PSYCHOL SCI, V2, P156, DOI [10.1111/1467-8721.ep10768973, DOI 10.1111/1467-8721.EP10768973]
   Yeh M, 2001, HUM FACTORS, V43, P355, DOI 10.1518/001872001775898269
   Yeh M, 2003, HUM FACTORS, V45, P390, DOI 10.1518/hfes.45.3.390.27249
   Yeh M, 1999, HUM FACTORS, V41, P524, DOI 10.1518/001872099779656752
NR 47
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2662
EP 2670
DI 10.1109/TVCG.2024.3372062
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400048
PM 38437133
DA 2024-11-06
ER

PT J
AU Gupta, K
   Zhang, YW
   Gunasekaran, TS
   Krishna, N
   Pai, YS
   Billinghurst, M
AF Gupta, Kunal
   Zhang, Yuewei
   Gunasekaran, Tamil Selvan
   Krishna, Nanditha
   Pai, Yun Suen
   Billinghurst, Mark
TI CAEVR: Biosignals-Driven Context-Aware Empathy in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE empathy; VR; metaverse; physiology; emotion; context-aware; virtual
   agents
ID SEX-DIFFERENCES; EXPERIENCE; ATTENTION; EMOTION; THETA; FLOW
AB There is little research on how Virtual Reality (VR) applications can identify and respond meaningfully to users' emotional changes. In this paper, we investigate the impact of Context-Aware Empathic VR (CAEVR) on the emotional and cognitive aspects of user experience in VR. We developed a real-time emotion prediction model using electroencephalography (EEG), electrodermal activity (EDA), and heart rate variability (HRV) and used this in personalized and generalized models for emotion recognition. We then explored the application of this model in a context-aware empathic (CAE) virtual agent and an emotion-adaptive (EA) VR environment. We found a significant increase in positive emotions, cognitive load, and empathy toward the CAE agent, suggesting the potential of CAEVR environments to refine user-agent interactions. We identify lessons learned from this study and directions for future work.
C1 [Gupta, Kunal; Zhang, Yuewei; Gunasekaran, Tamil Selvan; Pai, Yun Suen; Billinghurst, Mark] Univ Auckland, Auckland, New Zealand.
   [Krishna, Nanditha] Amrita Vishwa Vidyapeetham, Amritapuri, India.
C3 University of Auckland; Amrita Vishwa Vidyapeetham; Amrita Vishwa
   Vidyapeetham Amritapuri
RP Gupta, K (corresponding author), Univ Auckland, Auckland, New Zealand.
EM kunal.gupta@auckland.ac.nz; yzhb544@aucklanduni.ac.nz;
   themastergts007@gmail.com; nandithakrish4@gmail.com;
   yspai1412@gmail.com; mark.billinghurst@auckland.ac.nz
RI Krishna, Nanditha/AAE-1802-2019; Billinghurst, Mark/AAJ-4236-2020
OI Zhang, Yuewei/0000-0002-3829-445X; Gupta, Kunal/0000-0003-3963-8856;
   Krishna, Nanditha/0000-0001-5536-4993; Pai, Yun
   Suen/0000-0002-6090-2837; Gunasekaran, Tamil Selvan/0000-0001-7008-5458
FU Empathic Computing
FX No Statement Available
CR Abowd G. D., 2000, ACM Transactions on Computer-Human Interaction, V7, P29, DOI 10.1145/344949.344988
   Aftanas LI, 2001, NEUROSCI LETT, V310, P57, DOI 10.1016/S0304-3940(01)02094-8
   Almazan C. B., 2010, PhD thesis, P2
   Appelhans BM, 2006, REV GEN PSYCHOL, V10, P229, DOI 10.1037/1089-2680.10.3.229
   Bartram L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1364, DOI 10.1145/3025453.3026041
   Basar E, 2001, INT J PSYCHOPHYSIOL, V39, P241, DOI 10.1016/S0167-8760(00)00145-8
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Bouchard S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036169
   Bratman Michael., 1987, Intention, Plans, and Practical Reason, V10
   Brdiczka O, 2009, IEEE T AUTOM SCI ENG, V6, P588, DOI 10.1109/TASE.2008.2004965
   Brosch T, 2013, SWISS MED WKLY, V143, DOI 10.4414/smw.2013.13786
   Bunglowala A., 2015, International Journal of Research in Advent Technology, V1, P371
   Castro-Meneses LJ, 2020, ETR&D-EDUC TECH RES, V68, P181, DOI 10.1007/s11423-019-09681-4
   Chang Z, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.995090
   Chartrand T.L., 2005, The new unconscious, P334, DOI 10.1093/acprof:oso/9780195307696.003.0014
   Coan JA, 2006, PSYCHOL SCI, V17, P1032, DOI 10.1111/j.1467-9280.2006.01832.x
   Csikszentmihalyi M., 2014, Flow and the foundations of positive psychology, V10, P3
   Csikszentmihalyi M., 1992, OPTIMAL EXPERIENCE P, P3
   Cuff BMP, 2016, EMOT REV, V8, P144, DOI 10.1177/1754073914558466
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Davidson RJ, 1998, COGNITION EMOTION, V12, P307, DOI 10.1080/026999398379628
   Davis M. H., 2018, Empathy: A social psychological approach, P2
   de Graaf MMA, 2013, ROBOT AUTON SYST, V61, P1476, DOI 10.1016/j.robot.2013.07.007
   Dennemont Y, 2013, L N INST COMP SCI SO, V109, P30
   Devlin HC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0110470
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   Diaz FM, 2013, PSYCHOL MUSIC, V41, P42, DOI 10.1177/0305735611415144
   Fraser K, 2012, MED EDUC, V46, P1055, DOI 10.1111/j.1365-2923.2012.04355.x
   Gross JJ, 2015, PSYCHOL INQ, V26, P1, DOI 10.1080/1047840X.2014.940781
   Grubert J, 2017, IEEE T VIS COMPUT GR, V23, P1706, DOI 10.1109/TVCG.2016.2543720
   Gumbheer CP, 2022, EDUC INF TECHNOL, V27, P7491, DOI 10.1007/s10639-022-10942-8
   Gupta K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P756, DOI [10.1109/VR46266.2020.1581313729558, 10.1109/VR46266.2020.000-5]
   Gupta Kunal., 2020, P ACM S VIRTUAL REAL, DOI DOI 10.1145/3385956.3422122
   Hart S. G., 1986, Nasa task load index (tlx), V1, P5
   Hatfield E., 1993, Current directions in psychological science, V2, P96, DOI 10.1111/1467-8721.ep10770953
   Hess U, 2014, SOC PERSONAL PSYCHOL, V8, P45, DOI 10.1111/spc3.12083
   Hoffman M. L., 2001, Empathy and moral development: Implications for caring and justice, P2
   HOFFMAN ML, 1977, PSYCHOL BULL, V84, P712, DOI 10.1037/0033-2909.84.4.712
   Hongshen Chen, 2017, ACM SIGKDD Explorations Newsletter, V19, P25, DOI 10.1145/3166054.3166058
   Hurlbert AC, 2007, CURR BIOL, V17, pR623, DOI 10.1016/j.cub.2007.06.022
   IJsselsteijn W. A., 2013, The game experience questionnaire, P5
   Jarvela Simo, 2021, ACM Transactions on Social Computing, V4, DOI 10.1145/3449358
   Jurcak V, 2007, NEUROIMAGE, V34, P1600, DOI 10.1016/j.neuroimage.2006.09.024
   Knapp M. L., 2002, Handbook of interpersonal communication, P2
   KWALLEK N, 1988, PERCEPT MOTOR SKILL, V66, P123, DOI 10.2466/pms.1988.66.1.123
   Lampen Eva, 2020, Virtual, Augmented and Mixed Reality. Industrial and Everyday Life Applications. 12th International Conference, VAMR 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12191), P91, DOI 10.1007/978-3-030-49698-2_7
   Lang P., 1980, Technol. Ment. Health Care Deliv. Syst, V1, P119
   Lee S., 2004, C ARTIFICIAL REALITY, P2
   Liang Hui, 2023, 2023 9th International Conference on Virtual Reality (ICVR), P361, DOI 10.1109/ICVR57957.2023.10169325
   Liew TW, 2020, INFORM LEARN SCI, V121, P117, DOI 10.1108/ILS-11-2019-0124
   Linehan M. M., 1993, Skills training manual for treating borderline personality disorder, P4
   Lockwood PL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096555
   Lorenzetti V, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00390
   Makowski D, 2021, BEHAV RES METHODS, V53, P1689, DOI 10.3758/s13428-020-01516-y
   Marín-Morales J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185163
   Miller EK, 2015, DAEDALUS-US, V144, P112, DOI 10.1162/DAED_a_00320
   Moldoveanu A, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131810365
   Moon J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124623
   Oatley K, 2014, TRENDS COGN SCI, V18, P134, DOI 10.1016/j.tics.2013.12.004
   Ortega E, 2018, APPL PSYCHOPHYS BIOF, V43, P75, DOI 10.1007/s10484-017-9386-9
   Paiva A, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2912150
   Perera C, 2014, IEEE COMMUN SURV TUT, V16, P414, DOI 10.1109/SURV.2013.042313.00197
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Pinilla A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.630731
   Piumsomboon Thammathip, 2017, 2017 International Symposium on Ubiquitous Virtual Reality (ISUVR). Proceedings, P38, DOI 10.1109/ISUVR.2017.20
   POPE AT, 1995, BIOL PSYCHOL, V40, P187, DOI 10.1016/0301-0511(95)05116-3
   Prendinger H, 2004, LECT NOTES COMPUT SC, V3068, P53
   Preston SD, 2002, BEHAV BRAIN SCI, V25, P1, DOI 10.1017/S0140525X02000018
   Preston SD, 2007, EMPATHY IN MENTAL ILLNESS, P428, DOI 10.1017/CBO9780511543753.024
   Raja A, 2023, PROCEEDINGS OF 2023 MENSCH UND COMPUTER, MUC 2023, P354, DOI 10.1145/3603555.3608525
   Rashkin H, 2019, Arxiv, DOI arXiv:1811.00207
   Rheinberg F., 2003, Die erfassung des flowerlebens, P5
   Rodrigues SH, 2015, INTERACT COMPUT, V27, P371, DOI 10.1093/iwc/iwu001
   Rosenzweig Margaret Quinn, 2012, Nurse Pract, V37, P1, DOI 10.1097/01.NPR.0000408626.24599.9e
   Ryan N. S., 1998, Computer applications in archaeology, P2
   SCHILIT BN, 1994, IEEE NETWORK, V8, P22, DOI 10.1109/65.313011
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Seehausen M, 2016, BRAIN COGNITION, V103, P50, DOI 10.1016/j.bandc.2015.11.004
   SHAPIRO SS, 1965, BIOMETRIKA, V52, P591, DOI 10.1093/biomet/52.3-4.591
   Sheldon KM, 2015, J COLL STUDENT DEV, V56, P261, DOI 10.1353/csd.2015.0027
   Shin D, 2018, COMPUT HUM BEHAV, V78, P64, DOI 10.1016/j.chb.2017.09.012
   Stavrou NA, 2007, SPORT PSYCHOL, V21, P438, DOI 10.1123/tsp.21.4.438
   Sturmer S., 2009, PSYCHOL PROSOCIAL BE
   Thompson NM, 2019, PROG BRAIN RES, V247, P273, DOI 10.1016/bs.pbr.2019.03.024
   Tielman ML, 2017, TECHNOL HEALTH CARE, V25, P1081, DOI 10.3233/THC-170899
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yigitbas Enes, 2019, P MENSCH COMP 2019 H, P885, DOI DOI 10.1145/3340764.3349525
NR 88
TC 0
Z9 0
U1 8
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2671
EP 2681
DI 10.1109/TVCG.2024.3372130
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400013
PM 38437090
DA 2024-11-06
ER

PT J
AU Hiroi, Y
   Hiraki, T
   Itoh, Y
AF Hiroi, Yuichi
   Hiraki, Takefumi
   Itoh, Yuta
TI StainedSweeper: Compact, Variable-Intensity Light-Attenuation Display
   with Sweeping Tunable Retarders
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Light attenuation display; see-through display; augmented reality;
   time-multiplexing; polarized color filter
AB Light Attenuation Displays (LADs) are a type of Optical See-Through Head-Mounted Display (OST-HMD) that present images by attenuating incoming light with a pixel-wise polarizing color filter. Although LADs can display images in bright environments, there is a trade-off between the number of Spatial Light Modulators (SLMs) and the color gamut and contrast that can be expressed, making it difficult to achieve both high-fidelity image display and a small form factor. To address this problem, we propose StainedSweeper, a LAD that achieves both the wide color gamut and the variable intensity with a single SLM. Our system synchronously controls a pixel-wise Digital Micromirror Device (DMD) and a nonpixel polarizing color filter to pass light when each pixel is the desired color. By sweeping this control at high speed, the human eye perceives images in a time-multiplexed, integrated manner. To achieve this, we develop the OST-HMD design using a reflective Solc filter as a polarized color filter and a color reproduction algorithm based on the optimization of the time-multiplexing matrix for the selected primary color filters. Our proof-of-concept prototype showed that our single SLM design can produce subtractive images with variable contrast and a wider color gamut than conventional LADs.
C1 [Hiroi, Yuichi; Hiraki, Takefumi] Cluster Metaverse Lab, Tokyo, Japan.
   [Itoh, Yuta] Univ Tokyo, Tokyo, Japan.
C3 University of Tokyo
RP Hiroi, Y (corresponding author), Cluster Metaverse Lab, Tokyo, Japan.
EM y.hiroi@cluster.mu; t.hiraki@cluster.mu; yuta.itoh@iii.u-tokyo.ac.jp
RI Hiroi, Yuichi/KGM-7451-2024
OI Hiroi, Yuichi/0000-0001-8567-6947; Itoh, Yuta/0000-0002-5901-797X
FU JST FOREST
FX No Statement Available
CR Abu Aisheh M, 2023, NANOPHOTONICS-BERLIN, V12, P1115, DOI 10.1515/nanoph-2022-0656
   Abuleil MJ, 2014, OPT LETT, V39, P5487, DOI 10.1364/OL.39.005487
   Wilson A, 2022, IEEE T VIS COMPUT GR, V28, P4113, DOI 10.1109/TVCG.2021.3076069
   Xu YB, 2020, OPT EXPRESS, V28, P29740, DOI 10.1364/OE.402812
   Yang GW, 2010, APPL OPTICS, V49, P1280, DOI 10.1364/AO.49.001280
   YEH P, 1977, J OPT SOC AM, V67, P423, DOI 10.1364/JOSA.67.000423
   Zhang JG, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-16223-1
   Zhang Y, 2023, IEEE T VIS COMPUT GR, V29, P2700, DOI 10.1109/TVCG.2023.3247064
   Zhang Y, 2021, OPT EXPRESS, V29, P42751, DOI 10.1364/OE.444904
NR 9
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2682
EP 2692
DI 10.1109/TVCG.2024.3372058
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400067
PM 38437084
DA 2024-11-06
ER

PT J
AU Xu, SZ
   Chen, FXY
   Gong, R
   Zhang, FL
   Zhang, SH
AF Xu, Sen-Zhe
   Chen, Fiona Xiao Yu
   Gong, Ran
   Zhang, Fang-Lue
   Zhang, Song-Hai
TI BiRD: Using Bidirectional Rotation Gain Differences to Redirect Users
   during Back-and-forth Head Turns in Walking
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Birds; Gain measurement; Rotation measurement; Task
   analysis; Turning; Navigation; Redirected walking; virtual reality;
   rotation gain; detection thresholds; simulator sickness
AB Redirected walking (RDW) facilitates user navigation within expansive virtual spaces despite the constraints of limited physical spaces. It employs discrepancies between human visual-proprioceptive sensations, known as gains, to enable the remapping of virtual and physical environments. In this paper, we explore how to apply rotation gain while the user is walking. We propose to apply a rotation gain to let the user rotate by a different angle when reciprocating from a previous head rotation, to achieve the aim of steering the user to a desired direction. To apply the gains imperceptibly based on such a Bidirectional Rotation gain Difference (BiRD), we conduct both measurement and verification experiments on the detection thresholds of the rotation gain for reciprocating head rotations during walking. Unlike previous rotation gains which are measured when users are turning around in place (standing or sitting), BiRD is measured during users' walking. Our study offers a critical assessment of the acceptable range of rotational mapping differences for different rotational orientations across the user's walking experience, contributing to an effective tool for redirecting users in virtual environments.
C1 [Xu, Sen-Zhe; Chen, Fiona Xiao Yu; Gong, Ran; Zhang, Song-Hai] Tsinghua Univ, Tsinghua, Peoples R China.
   [Zhang, Fang-Lue] Victoria Univ Wellington, Wellington, New Zealand.
   [Zhang, Song-Hai] QingHai Univ, Xining, Peoples R China.
C3 Tsinghua University; Victoria University Wellington; Qinghai University
RP Xu, SZ (corresponding author), Tsinghua Univ, Tsinghua, Peoples R China.
EM xsz15@tsinghua.org.cn; xiaoyu-c23@mails.tsinghua.edu.cn;
   gongr19@mails.tsinghua.edu.cn; fanglue.zhang@vuw.ac.nz;
   shz@tsinghua.edu.cn
OI Xu, Sen-Zhe/0000-0003-2669-7814
FU National Key Research and Development Program of China
FX No Statement Available
CR Azmandian M, 2017, P IEEE VIRT REAL ANN, P91, DOI 10.1109/VR.2017.7892235
   Bachmann ER, 2019, IEEE T VIS COMPUT GR, V25, P2022, DOI 10.1109/TVCG.2019.2898764
   Bachmann ER, 2013, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2013.6549377
   Bruder F., 2009, Reorientation duringbody turns, P145, DOI [10.2312/EGVE/JVRC09/145-1523[6]Y., DOI 10.2312/EGVE/JVRC09/145-1523[6]Y]
   Bruder G., 2018, ICAT EGVE 2018 INT C, DOI [10.2312/egve.201813151,2[17]V, DOI 10.2312/EGVE.201813151,2[17]V]
   Bruder G, 2012, IEEE T VIS COMPUT GR, V18, P538, DOI 10.1109/TVCG.2012.55
   Chang YC, 2021, IEEE ACCESS, V9, P145083, DOI 10.1109/ACCESS.2021.3118056
   Chen ZY, 2021, INT SYM MIX AUGMENT, P184, DOI 10.1109/ISMAR52148.2021.00033
   Dong TY, 2023, IEEE T VIS COMPUT GR, V29, P2315, DOI 10.1109/TVCG.2023.3247107
   Dong TY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P626, DOI 10.1109/VR50410.2021.00088
   Dong TY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P146, DOI [10.1109/VR46266.2020.00-71, 10.1109/VR46266.2020.1581490806361]
   Dong X.-M., 2019, ACM Trans. Graph., V38, DOI [10.1145/33455543[12]L, DOI 10.1145/33455543[12]L]
   Fan H. Li, 2022, IEEE Transactions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.31792692[13]T, DOI 10.1109/TVCG.2022.31792692[13]T]
   Grechkin J., 2016, P ACM S APPL PERC, P113, DOI [DOI 10.1145/2931002.2931018, 10.1145/2931002.2931018.114E]
   Hamill J. Lim, 2020, Brain Sciences, V10, P2
   Hodgson E, 2013, IEEE T VIS COMPUT GR, V19, P634, DOI 10.1109/TVCG.2013.28
   Hutton S., Individualized Cal-ibration of Rotation Gain Thresholds for Redirected Walking
   Interrante B., 2007, IN2007 IEEE S 3D USE, DOI [10.1109/3DUI.2007.3407911,2[18]P.M., DOI 10.1109/3DUI.2007.3407911,2[18]P.M]
   Jaekl PM, 2005, EXP BRAIN RES, V163, P388, DOI 10.1007/s00221-004-2191-8
   Jeon SB, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530113
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Klein SA, 2001, PERCEPT PSYCHOPHYS, V63, P1421, DOI 10.3758/BF03194552
   Kruse L, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P305, DOI 10.1109/VR.2018.8446216
   Langbehn E, 2017, IEEE T VIS COMPUT GR, V23, P1349, DOI 10.1109/TVCG.2017.2657220
   Lee DY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P155, DOI [10.1109/VR46266.2020.1581309443724, 10.1109/VR46266.2020.00-70]
   Lee DY, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P63, DOI [10.1109/vr.2019.8798121, 10.1109/VR.2019.8798121]
   Li HY, 2020, IEEE ACCESS, V8, P180210, DOI 10.1109/ACCESS.2020.3027985
   Li YJ, 2022, J COMPUT SCI TECH-CH, V37, P561, DOI 10.1007/s11390-022-2266-7
   Linares D, 2016, R J, V8, P122
   Matsumoto K, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P101, DOI [10.1109/VR46266.2020.00-76, 10.1109/VR46266.2020.1581262503135]
   Messinger J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P72, DOI [10.1109/vr.2019.8797818, 10.1109/VR.2019.8797818]
   Neth CT, 2012, IEEE T VIS COMPUT GR, V18, P1041, DOI 10.1109/TVCG.2011.275
   Neth CT, 2011, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2011.5759454
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson NC, 2018, IEEE COMPUT GRAPH, V38, P44, DOI 10.1109/MCG.2018.111125628
   Paludan A, 2016, P IEEE VIRT REAL ANN, P259, DOI 10.1109/VR.2016.7504752
   Razzaque Z., 2001, InEurographics 2001 - Short Presentations, DOI [10.2312/egs.200110361[38]M, DOI 10.2312/EGS.200110361[38]M]
   Rietzler M, 2018, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2018.00041
   Sakono H, 2021, IEEE T VIS COMPUT GR, V27, P4278, DOI 10.1109/TVCG.2021.3106501
   Schmitz P, 2018, IEEE T VIS COMPUT GR, V24, P1623, DOI 10.1109/TVCG.2018.2793671
   Serafin S, 2013, P IEEE VIRT REAL ANN, P161, DOI 10.1109/VR.2013.6549412
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Steinicke F., 2008, Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST), P149, DOI DOI 10.1145/1450579.14506112[45]F
   Steinicke F, 2010, IEEE T VIS COMPUT GR, V16, P17, DOI 10.1109/TVCG.2009.62
   Strauss RR, 2020, IEEE T VIS COMPUT GR, V26, P1955, DOI 10.1109/TVCG.2020.2973060
   Suma EA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P43, DOI 10.1109/VR.2012.6180877
   Thomas J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P317, DOI [10.1109/VRW50115.2020.00071, 10.1109/VRW50115.2020.0-205]
   Thomas J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P56, DOI [10.1109/vr.2019.8797983, 10.1109/VR.2019.8797983]
   Wang S.-H., 2022, IEEEtransactions on visualization and computer graphics, V7
   Wang Z.-Y., 2022, IEEE Transac-tions on Visualization and Computer Graphics, P1, DOI [10.1109/TVCG.2022.32240733[52]N.L., DOI 10.1109/TVCG.2022.32240733[52]N.L]
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P4267, DOI 10.1109/TVCG.2021.3106432
   Williams NL, 2021, IEEE T VIS COMPUT GR, V27, P2535, DOI 10.1109/TVCG.2021.3067781
   Williams NL, 2019, IEEE T VIS COMPUT GR, V25, P3158, DOI 10.1109/TVCG.2019.2932213
   Xu J.-H., 2023, IEEE Transactions on Visualization and Computer Graphics, V3
   Xu SZ, 2022, IEEE T VIS COMPUT GR, V28, P3778, DOI 10.1109/TVCG.2022.3203095
   You C, 2022, INT SYM MIX AUGMENT, P603, DOI 10.1109/ISMAR55827.2022.00077
   Zhang SH, 2023, IEEE T VIS COMPUT GR, V29, P3327, DOI 10.1109/TVCG.2022.3158609
   Zhang SH, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P504, DOI 10.1109/VRW52623.2021.00134
NR 58
TC 0
Z9 0
U1 4
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2693
EP 2702
DI 10.1109/TVCG.2024.3372094
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400022
PM 38437103
DA 2024-11-06
ER

PT J
AU Jeong, S
   Kim, J
   Lee, J
AF Jeong, Sihyun
   Kim, Jinwook
   Lee, Jeongmi
TI The Differential Effects of Multisensory Attentional Cues on Task
   Performance in VR Depending on the Level of Cognitive Load and Cognitive
   Capacity
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Cognitive load; Visualization; Particle measurements;
   Atmospheric measurements; Search problems; Usability; Virtual Reality;
   Performance; Cognitive Load; Multisensory; Attentional Cue; Cognitive
   Capacity
ID WORKING-MEMORY; GAME; METAANALYSIS; KNOWLEDGE; TACTILE; SEARCH; AGE
AB As the utilization of VR is expanding across diverse fields, research on devising attentional cues that could optimize users' task performance in VR has become crucial. Since the cognitive load imposed by the context and the individual's cognitive capacity are representative factors that are known to determine task performance, we aimed to examine how the effects of multisensory attentional cues on task performance are modulated by the two factors. For this purpose, we designed a new experimental paradigm in which participants engaged in dual (N-back, visual search) tasks under different levels of cognitive load while an attentional cue (visual, tactile, or visuotactile) was presented to facilitate search performance. The results showed that multi-sensory attentional cues are generally more effective than uni-sensory cues in enhancing task performance, but the benefit of multi-sensory cues changes according to the level of cognitive load and the individual's cognitive capacity; the amount of benefit increases as the cognitive load is higher and the cognitive capacity is lower. The findings of this study provide practical implications for designing attentional cues to enhance VR task performance, considering both the complexity of the VR context and users' internal characteristics.
C1 [Jeong, Sihyun; Kim, Jinwook; Lee, Jeongmi] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, J (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM sihyunlyujeong@gmail.com; jinwook.kim31@kaist.ac.kr; jeongmi@kaist.ac.kr
RI ; Lee, Jeongmi/D-1912-2018
OI Kim, Jinwook/0000-0002-1962-5815; Jeong, Sihyun/0000-0002-5690-7213;
   Lee, Jeongmi/0000-0002-3403-8117
FU National Research Foundation of Korea
FX No Statement Available
CR Albus P, 2021, COMPUT EDUC, V166, DOI 10.1016/j.compedu.2021.104154
   Bailey R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1559755.1559757
   Bediou B, 2018, PSYCHOL BULL, V144, P77, DOI 10.1037/bul0000130
   Boot WR, 2008, ACTA PSYCHOL, V129, P387, DOI 10.1016/j.actpsy.2008.09.005
   BRITTON BK, 1982, J VERB LEARN VERB BE, V21, P421, DOI 10.1016/S0022-5371(82)90709-5
   Brünken R, 2003, EDUC PSYCHOL-US, V38, P53, DOI 10.1207/S15326985EP3801_7
   Burigat S, 2007, INT J HUM-COMPUT ST, V65, P945, DOI 10.1016/j.ijhcs.2007.07.003
   Chiossi Y., 2023, Proc. ACM Hum.-Comput. Interact, V7
   Chittaro L., Proceedings of the Working Conference on Advanced Visual Interfaces, ser. AVI '04. New York, NY, USA: ACM, P267
   Colzato LS, 2013, PSYCHOL RES-PSYCH FO, V77, P234, DOI 10.1007/s00426-012-0415-2
   Cooper N, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191846
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Ernst MO, 2002, NATURE, V415, P429, DOI 10.1038/415429a
   Gateau T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121279
   Gray R, 2002, EXP BRAIN RES, V145, P50, DOI 10.1007/s00221-002-1085-x
   Greenwood PM, 1999, PERCEPT PSYCHOPHYS, V61, P837, DOI 10.3758/BF03206901
   Grogorick S, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P563, DOI 10.1109/VR.2018.8446215
   Hamad A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191811278
   Hambrick DZ, 2002, COGNITIVE PSYCHOL, V44, P339, DOI 10.1006/cogp.2001.0769
   Hart S. G., 1982, INEIGHTH S PSYCHOL D, P478
   Hart S. G., 2006, PROCEEDINGSOF HUMAN, V50, P2
   Hart S.G., 1986, Human Productivity Enhancement, P396
   Hauck C, 2022, PSYCHOL RES-PSYCH FO, V86, P2128, DOI 10.1007/s00426-021-01640-0
   JUST MA, 1992, PSYCHOL REV, V99, P122, DOI 10.1037/0033-295X.99.1.122
   Kane MJ, 2007, J EXP PSYCHOL LEARN, V33, P615, DOI 10.1037/0278-7393.33.3.615
   Kim J, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0261298
   KIRCHNER WK, 1958, J EXP PSYCHOL, V55, P352, DOI 10.1037/h0043688
   Kosch T, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3582272
   Lange T. C., 2020, INPROCEEDINGS THE202, P1
   Lee BC, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101780
   Li G, 2020, J COGNITIVE NEUROSCI, V32, P1438, DOI 10.1162/jocn_a_01560
   Liu JS, 2021, IEEE T VIS COMPUT GR, V27, P4311, DOI 10.1109/TVCG.2021.3106476
   Longstaffe KA, 2014, ATTEN PERCEPT PSYCHO, V76, P49, DOI 10.3758/s13414-013-0575-1
   Marner MR, 2013, INT SYM MIX AUGMENT, P39, DOI 10.1109/ISMAR.2013.6671762
   Martin D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3508361
   Matthews F. Tian, 2020, Virtual Reality & Intelligent Hardware, P330
   Michail G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30007-6
   Miyake S, 2001, INT J PSYCHOPHYSIOL, V40, P233, DOI 10.1016/S0167-8760(00)00191-4
   Ngo MK, 2010, ATTEN PERCEPT PSYCHO, V72, P1654, DOI 10.3758/APP.72.6.1654
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Peng C, 2019, IEEE ACCESS, V7, P68878, DOI 10.1109/ACCESS.2019.2918846
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   pro Andrius Productions, 2016, Unity asset store, proprototype collection
   Putze F, 2019, IEEE ENG MED BIO, P3103, DOI [10.1109/EMBC.2019.8856386, 10.1109/embc.2019.8856386]
   Ramkumar A, 2017, INT J HUM-COMPUT INT, V33, P123, DOI 10.1080/10447318.2016.1220729
   ROCK I, 1964, SCIENCE, V143, P594, DOI 10.1126/science.143.3606.594
   Soret P., 2019, INPROCEEDINGS 11 ACM, P1
   Soto-Faraco S, 2005, PSYCHON B REV, V12, P1024, DOI 10.3758/BF03206438
   Souchet AD, 2022, INT J HUM-COMPUT INT, V38, P801, DOI 10.1080/10447318.2021.1976509
   Steenbergen L, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144364
   Stock AK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-04828-w
   Sweller J, 1998, EDUC PSYCHOL REV, V10, P251, DOI 10.1023/A:1022193728205
   SWELLER J, 1988, COGNITIVE SCI, V12, P257, DOI 10.1207/s15516709cog1202_4
   Talsma D, 2005, J COGNITIVE NEUROSCI, V17, P1098, DOI 10.1162/0898929054475172
   Tiraboschi GA, 2019, J COGN ENHANCE, V3, P436, DOI 10.1007/s41465-019-00130-x
   Townsend F. G., 1983, CUP Archive, V5, P6
   Trejo N. J., 2007, Foundations of Augmented Cognition, P13
   Unsworth N, 2015, PSYCHOL SCI, V26, P759, DOI 10.1177/0956797615570367
   van Ede F, 2012, J NEUROSCI, V32, P10408, DOI 10.1523/JNEUROSCI.1337-12.2012
   Wan CJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18375-y
   Whelan R. R., 2007, nEducational Research Review, P1
   Wickens C.D., 1991, Multiple-task performance, P3, DOI [10.1201/9781003069447-2, DOI 10.1201/9781003069447-2]
   Wickens CD, 2008, HUM FACTORS, V50, P449, DOI 10.1518/001872008X288394
   Yuan B, 2011, UNIVERSAL ACCESS INF, V10, P81, DOI 10.1007/s10209-010-0189-5
   Zagermann J, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P78, DOI 10.1145/2993901.2993908
   Zhang XC, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142416727
   Ziv R., 2022, Scientific Reports, V12, P2
NR 68
TC 1
Z9 1
U1 21
U2 21
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2703
EP 2712
DI 10.1109/TVCG.2024.3372126
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400051
PM 38437135
DA 2024-11-06
ER

PT J
AU Tian, F
   Ni, ST
   Zhang, XY
   Chen, F
   Zhu, QL
   Xu, CY
   Li, YZ
AF Tian, Feng
   Ni, Shuting
   Zhang, Xiaoyue
   Chen, Fei
   Zhu, Qiaolian
   Xu, Chunyi
   Li, Yuzhi
TI Enhancing Tai Chi Training System: Towards Group-Based and
   Hyper-Realistic Training Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual reality; social experience; action guidance trajectories; hand
   movement trajectories analysis; hyper-realistic
AB In this article, we propose a lightweight and flexible enhanced Tai Chi training system composed of multiple standalone virtual reality (VR) devices. The system aims to enable a hyper-realistic multi-user action training platform at low cost by displaying real-time action guidance trajectories, providing real-world impossible visual effects and functions, and rapidly enhancing movement precision and communication interest for learners. We objectively evaluate participants' action quality at different levels of immersion, including traditional coach guidance (TCG), VR, and mixed reality (MR), along with subjective measures like motion sickness, quality of interaction, social meaning, presence/immersion to comprehensively explore the system's feasibility. The results indicate VR performs the best in training accuracy, but MR provides superior social experience and relatively high accuracy. Unlike TCG, MR offers hyper-realistic hand movement trajectories and Tai Chi social references. Compared with VR, MR provides more realistic avatar companions and a safer environment. In summary, MR balances accuracy and social experience.
C1 [Tian, Feng; Ni, Shuting; Zhang, Xiaoyue; Chen, Fei; Zhu, Qiaolian; Xu, Chunyi; Li, Yuzhi] Shanghai Univ, Shanghai, Peoples R China.
C3 Shanghai University
RP Tian, F (corresponding author), Shanghai Univ, Shanghai, Peoples R China.
EM ouman@shu.edu.cn; shangkenst@shu.edu.cn; zxy0716@shu.edu.cn;
   buer2001@shu.edu.cn; gjky@shu.edu.cn; xcy2008@shu.edu.cn;
   shadowmcv@shu.edu.cn
OI Li, Yuzhi/0009-0009-7050-7775
FU Shanghai University Interdisciplinary Joint Project
FX No Statement Available
CR [Anonymous], 2020, IN2020 IEEE C VIRTUA, P858, DOI [10.1109/VRW50115.2020.002821,2,3[39]W.-L, DOI 10.1109/VRW50115.2020.002821,2,3[39]W.-L]
   Tsai WL, 2022, IEEE T VIS COMPUT GR, V28, P2970, DOI 10.1109/TVCG.2020.3046326
   Wang MJ, 2022, IEEE T LEARN TECHNOL, V15, P685, DOI 10.1109/TLT.2022.3210828
   Weidner F, 2023, IEEE T VIS COMPUT GR, V29, P2596, DOI 10.1109/TVCG.2023.3247072
   Weissker T, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P719, DOI 10.1109/VRW55335.2022.00215
   Winkler A, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555411
   Zeng YQ, 2021, 2021 IEEE 7TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2021), P240, DOI 10.1109/ICVR51878.2021.9483700
   Zhao CJ, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/2446413
NR 8
TC 1
Z9 1
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2713
EP 2723
DI 10.1109/TVCG.2024.3372099
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400068
PM 38457324
DA 2024-11-06
ER

PT J
AU Jackson, B
   Lor, L
   Heggeseth, BC
AF Jackson, Bret
   Lor, Linda
   Heggeseth, Brianna C.
TI Workspace Guardian: Investigating Awareness of Personal Workspace
   Between Co-Located Augmented Reality Users
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed reality; augmented reality; three-dimensional displays
AB As augmented reality (AR) systems proliferate and the technology gets smaller and less intrusive, we imagine a future where many AR users will interact in the same physical locations (e.g., in shared work places and public spaces). While previous research has explored AR collaboration in these spaces, our focus is on co-located but independent work. In this paper, we explore co-located AR user behavior and investigate techniques for promoting awareness of personal workspace boundaries. Specifically, we compare three techniques: showing all virtual content, visualizing bounding box outlines of content, and a self-defined workspace boundary. The findings suggest that a self-defined boundary led to significantly more personal workspace encroachments.
C1 [Jackson, Bret; Lor, Linda; Heggeseth, Brianna C.] Macalester Coll, St Paul, MN 55105 USA.
C3 Macalester College
RP Jackson, B (corresponding author), Macalester Coll, St Paul, MN 55105 USA.
EM bjackson@macalester.edu; llor@macalester.edu; bheggese@macalester.edu
FU Clare Booth Luce Foundation
FX No Statement Available
CR [Anonymous], 2023, Proceedings of the ACM on Interactive, Mobile, Wear-able and Ubiquitous Technologies, V6, DOI [10.1145/35695017, DOI 10.1145/35695017]
   Hagan J. R., 2022, INPROCEEDINGS 2022 I, DOI [10.1145/3531073.35310797[42]J.O', DOI 10.1145/3531073.35310797[42]J.O]
   Hagan J. R., 2023, INPROCEEDINGS 2023 C, DOI [10.1145/3544548.35810182[43]J.O', DOI 10.1145/3544548.35810182[43]J.O]
   O'Hagan J, 2021, INT SYM MIX AUGMENT, P211, DOI 10.1109/ISMAR52148.2021.00036
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P19, DOI 10.1145/3393712.3395339
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Paavilainen J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2493, DOI 10.1145/3025453.3025871
   Pierce JL, 2003, REV GEN PSYCHOL, V7, P84, DOI 10.1037/1089-2680.7.1.84
   Poretski J., 2018, P ACM HUMAN COMPUTER, DOI [10.1145/32744112\nR.R, DOI 10.1145/32744112]
   Poretski L, 2021, INT J HUM-COMPUT ST, V150, DOI 10.1016/j.ijhcs.2021.102611
   Wehbe RR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376319
   Wu SX, 2023, Symposium Virtual Re, P631, DOI 10.1109/VR55154.2023.00078
   Yang KT, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P499, DOI 10.1145/3242587.3242630
   Yu JQ, 2022, ETR&D-EDUC TECH RES, V70, P1169, DOI 10.1007/s11423-022-10122-y
   Zibrek K, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419985
NR 15
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2724
EP 2733
DI 10.1109/TVCG.2024.3372073
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400056
PM 38437099
DA 2024-11-06
ER

PT J
AU Ai, H
   Cao, ZD
   Lu, HN
   Chen, C
   Ma, J
   Zhou, PY
   Kim, TK
   Hui, P
   Wang, L
AF Ai, Hao
   Cao, Zidong
   Lu, Haonan
   Chen, Chen
   Ma, Jian
   Zhou, Pengyuan
   Kim, Tae-Kyun
   Hui, Pan
   Wang, Lin
TI Dream360: Diverse and Immersive Outdoor Virtual Scene Creation via
   Transformer-Based 360° Image Outpainting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 360 image outpainting; virtual scene creation; vision transformer
AB 360 degrees images, with a field-of-view (FoV) of 180 degrees x 360 degrees, provide immersive and realistic environments for emerging virtual reality (VR) applications, such as virtual tourism, where users desire to create diverse panoramic scenes from a narrow FoV photo they take from a viewpoint via portable devices. It thus brings us to a technical challenge: 'How to allow the users to freely create diverse and immersive virtual scenes from a narrow FoV image with a specified viewport?' To this end, we propose a transformer-based 360 degrees image outpainting framework called Dream360, which can generate diverse, high-fidelity, and high-resolution panoramas from user-selected viewports, considering the spherical properties of 360 degrees images. Compared with existing methods, e.g., [3], which primarily focus on inputs with rectangular masks and central locations while overlooking the spherical property of 360 degrees images, our Dream360 offers higher outpainting flexibility and fidelity based on the spherical representation. Dream360 comprises two key learning stages: (I) codebook-based panorama outpainting via Spherical-VQGAN (S-VQGAN), and (II) frequency-aware refinement with a novel frequency-aware consistency loss. Specifically, S-VQGAN learns a sphere-specific codebook from spherical harmonic (SH) values, providing a better representation of spherical data distribution for scene modeling. The frequency-aware refinement matches the resolution and further improves the semantic consistency and visual fidelity of the generated results. Our Dream360 achieves significantly lower Frechet Inception Distance (FID) scores and better visual fidelity than existing methods. We also conducted a user study involving 15 participants to interactively evaluate the quality of the generated results in VR, demonstrating the flexibility and superiority of our Dream360 framework.
C1 [Ai, Hao; Cao, Zidong; Hui, Pan; Wang, Lin] HKUST GZ, Guangzhou, Peoples R China.
   [Lu, Haonan; Chen, Chen; Ma, Jian] OPPO, Shenzhen, Peoples R China.
   [Zhou, Pengyuan] USTC, Hefei, Peoples R China.
   [Kim, Tae-Kyun] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Kim, Tae-Kyun] ICI PLC, London, England.
   [Hui, Pan; Wang, Lin] HKUST, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Korea Advanced Institute of Science & Technology (KAIST);
   Imperial Chemical Industries; Hong Kong University of Science &
   Technology
RP Ai, H (corresponding author), HKUST GZ, Guangzhou, Peoples R China.
EM aihao199712@gmail.com; zcao740@connect.hkust-gz.edu.cn;
   luhaonan@oppo.com; chenchen4@oppo.com; majian2@oppo.com;
   pyzhou@ustc.edu.cn; kimtaekyun@kaist.ac.kr; panhui@ust.hk;
   linwang@ust.hk
RI Kim, Tae-Kyun/HTL-2208-2023; Zhou, Pengyuan/AAJ-2139-2021; JIAN,
   MA/KQU-7977-2024; Ai, Hao/KHV-9503-2024
OI Zhou, Pengyuan/0000-0002-7909-4059
FU OPPO Research Fund
FX No Statement Available
CR Ai H, 2023, PROC CVPR IEEE, P13273, DOI 10.1109/CVPR52729.2023.01275
   Akimoto N, 2022, PROC CVPR IEEE, P11431, DOI 10.1109/CVPR52688.2022.01115
   Akimoto N, 2019, IEEE IMAGE PROC, P4704, DOI [10.1109/ICIP.2019.8803435, 10.1109/icip.2019.8803435]
   Ardouin J, 2014, 2014 IEEE VIRTUAL REALITY (VR), P3, DOI 10.1109/VR.2014.6802042
   Arora N, 2022, IEEE T VIS COMPUT GR, V28, P2135, DOI 10.1109/TVCG.2022.3150473
   Cai M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13910, DOI 10.1109/ICCV48922.2021.01367
   Cao Mingdeng, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1731, DOI 10.1109/CVPRW59228.2023.00174
   Chang HW, 2022, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR52688.2022.01103
   Chen YB, 2022, LECT NOTES COMPUT SC, V13677, P170, DOI 10.1007/978-3-031-19790-1_11
   Chen ZX, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555447
   Cheng YC, 2022, PROC CVPR IEEE, P11421, DOI 10.1109/CVPR52688.2022.01114
   Eder M, 2020, PROC CVPR IEEE, P12423, DOI 10.1109/CVPR42600.2020.01244
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   Fuchs FB, 2020, ADV NEUR IN, V33
   Fuoli D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2340, DOI 10.1109/ICCV48922.2021.00236
   Gal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459836
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Hara T, 2021, AAAI CONF ARTIF INTE, V35, P1513
   Hensel M, 2017, ADV NEUR IN, V30
   Iketani S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P615, DOI [10.1109/VRW50115.2020.00158, 10.1109/VRW50115.2020.0-117]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang LM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13899, DOI 10.1109/ICCV48922.2021.01366
   Jin X, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02367-3
   Jung S, 2021, AAAI CONF ARTIF INTE, V35, P1734
   Kim K, 2021, IEEE WINT CONF APPL, P2121, DOI 10.1109/WACV48630.2021.00217
   Liao K, 2023, Arxiv, DOI arXiv:2204.08563
   Lil YJ, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P1, DOI 10.1109/VR51125.2022.00017
   Liu CL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P575, DOI 10.1109/VRW50115.2020.00285
   Liu KL, 2019, IEEE I CONF COMP VIS, P6391, DOI 10.1109/ICCV.2019.00648
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marrinan T., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P1
   Martin D, 2022, IEEE T VIS COMPUT GR, V28, P2003, DOI 10.1109/TVCG.2022.3150502
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mirza M., 2014, arXiv preprint arXiv:1411.1784, DOI 10.48550/arXiv.1411.1784
   Parmar G, 2022, PROC CVPR IEEE, P11400, DOI 10.1109/CVPR52688.2022.01112
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng JL, 2021, PROC CVPR IEEE, P10770, DOI 10.1109/CVPR46437.2021.01063
   Pessoa S, 2010, P IEEE VIRT REAL ANN, P3, DOI 10.1109/VR.2010.5444836
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Ramamoorthi R, 2004, ACM T GRAPHIC, V23, P1004, DOI 10.1145/1027411.1027416
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Singhal U., 2020, NeurIPS, V2, P4
   Suh D.Y., 2020, arXiv
   Sumantri JS, 2020, IEEE WINT CONF APPL, P2375, DOI [10.1109/wacv45572.2020.9093582, 10.1109/WACV45572.2020.9093582]
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   van den Oord A, 2017, ADV NEUR IN, V30
   Vaswani A, 2017, ADV NEUR IN, V30
   Vermast A, 2023, IEEE T VIS COMPUT GR, V29, P2547, DOI 10.1109/TVCG.2023.3247462
   Walker J, 2016, Arxiv, DOI arXiv:1606.07873
   Wallgrün JO, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P83, DOI [10.1109/VR46266.2020.00-78, 10.1109/VR46266.2020.1581092881445]
   Wang JH, 2023, Arxiv, DOI arXiv:2308.14686
   Wang LL, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P170, DOI 10.1109/VR50410.2021.00038
   Wang M., 2014, ACM Transactions on Graphics (TOG), V33, P2
   Wang M, 2020, INT SYM MIX AUGMENT, P174, DOI [10.1109/1SMA1R50242.2020.00040, 10.1109/ISMAR50242.2020.00040]
   Wang TF, 2022, PROC CVPR IEEE, P11369, DOI 10.1109/CVPR52688.2022.01109
   Wang Y, 2019, PROC CVPR IEEE, P1399, DOI 10.1109/CVPR.2019.00149
   Wu TH, 2024, Arxiv, DOI arXiv:2307.03177
   Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991
   Xin HG, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480563
   Xu D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P703, DOI [10.1109/VRW50115.2020.00202, 10.1109/VRW50115.2020.00-73]
   Yang CA, 2022, PROC CVPR IEEE, P15596, DOI 10.1109/CVPR52688.2022.01517
   Yu YC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P69, DOI 10.1145/3474085.3475436
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao L, 2020, PROC CVPR IEEE, P5740, DOI 10.1109/CVPR42600.2020.00578
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhu YC, 2020, IEEE T MULTIMEDIA, V22, P2331, DOI 10.1109/TMM.2019.2957986
NR 68
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2734
EP 2744
DI 10.1109/TVCG.2024.3372085
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400065
PM 38437117
DA 2024-11-06
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Raveendranath, B
   Canales, R
   Sarno, DM
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Rohith
   Venkatakrishnan, Roshan
   Raveendranath, Balagopal
   Canales, Ryan
   Sarno, Dawn M.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI The Effects of Secondary Task Demands on Cybersickness in Active
   Exploration Virtual Reality Experiences
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Cybersickness; Navigation; Motion sickness;
   Visualization; Skin; Virtual environments; Virtual Reality; Secondary
   Task Demand; Active Exploration; Electrodermal Activity
ID N-BACK TASK; MOTION SICKNESS; DRIVER DISTRACTION; WORKING-MEMORY;
   QUESTIONNAIRE; PERFORMANCE; SUSCEPTIBILITY; METAANALYSIS; MUSIC; SPEED
AB Active exploration in virtual reality (VR) involves users navigating immersive virtual environments, going from one place to another. While navigating, users often engage in secondary tasks that require attentional resources, as in the case of distracted driving. Inspired by research generally studying the effects of task demands on cybersickness (CS), we investigated how the attentional demands specifically associated with secondary tasks performed during exploration affect CS. Downstream of this, we studied how increased attentional demands from secondary tasks affect spatial memory and navigational performance. We discuss the results of a multi-factorial between-subjects study, manipulating a secondary task's demand across two levels and studying its effects on CS in two different sickness-inducing levels of an exploration experience. The secondary task's demand was manipulated by parametrically varying n in an aural n-back working memory task and the provocativeness of the experience was manipulated by varying how frequently users experienced a yaw-rotational reorientation effect during the exploration. Results revealed that increases in the secondary task's demand increased sickness levels, also resulting in a higher temporal onset rate, especially when the experience was not already highly sickening. Increased attentional demand from the secondary task also vitiated navigational performance and spatial memory. Overall, increased demands from secondary tasks performed during navigation produce deleterious effects on the VR experience.
C1 [Venkatakrishnan, Rohith; Venkatakrishnan, Roshan] Univ Florida, Res Associates, Gainesville, FL 32611 USA.
   [Raveendranath, Balagopal; Canales, Ryan] Clemson Univ, Clemson, SC USA.
   [Sarno, Dawn M.] Clemson Univ, Dept Psychol, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 State University System of Florida; University of Florida; Clemson
   University; Clemson University; National Yang Ming Chiao Tung
   University; Clemson University
RP Venkatakrishnan, R (corresponding author), Univ Florida, Res Associates, Gainesville, FL 32611 USA.
EM rohith.venkatakr@ufl.edu; rvenkatakrishnan@ufl.edu;
   braveen@g.clemson.edu; rcanale@g.clemson.edu; dmsarno@clemson.edu;
   wclin@cs.nctu.edu.tw; arobb@clemson.edu; sbabu@clemson.edu
RI Venkatakrishnan, Rohith/JCE-8736-2023; Venkatakrishnan,
   Roshan/JDC-3508-2023
OI Robb, Andrew/0000-0002-0398-5576; Canales, Ryan/0000-0003-0554-7817;
   Venkatakrishnan, Rohith/0000-0002-8484-3915; Babu,
   Sabarish/0000-0002-8348-0534; Sarno, Dawn/0000-0001-5605-5957;
   Venkatakrishnan, Roshan/0000-0002-6538-627X
FU US National Science Foundation (CISE IIS HCC)
FX No Statement Available
CR Açikel BY, 2018, SIMULAT GAMING, V49, P27, DOI 10.1177/1046878117750417
   Ang S, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P428, DOI 10.1109/VR51125.2022.00062
   Blanco M, 2006, ACCIDENT ANAL PREV, V38, P895, DOI 10.1016/j.aap.2006.02.015
   Bos JE, 2005, AVIAT SPACE ENVIR MD, V76, P1111
   Bos JE, 2015, J VESTIBUL RES-EQUIL, V25, P23, DOI 10.3233/VES-150541
   Bowman D. A., 1998, Virtual Reality, V3, P120, DOI 10.1007/BF01417673
   Braithwaite J.J., 2013, PSYCHOPHYSIOLOGY, P1
   Burte H, 2012, P ANN M COGN SCI SOC, V34
   Burte H, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0057-4
   Collet C, 2009, APPL ERGON, V40, P1041, DOI 10.1016/j.apergo.2009.01.007
   Davis Simon, 2014, P 2014 C INT ENT, P1
   Dawson ME., 2017, The electrodermal system
   Fang J, 2014, TRANSPORT RES REC, P26, DOI 10.3141/2434-04
   Farmani Y., 2018, P 44 GRAPH INT C, P168, DOI [10.20380/GI2018.21, DOI 10.20380/GI2018.23, 10.20380/GI201 8.23, 10.20380/GI2018.23]
   Ferdinand AO, 2014, AM J PUBLIC HEALTH, V104, pE39, DOI 10.2105/AJPH.2013.301750
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fisher DL, 2006, INJURY PREV, V12, P25, DOI 10.1136/ip.2006.012021
   Galvez-Garcia G, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102931
   Garrido LE, 2022, VIRTUAL REAL-LONDON, V26, P1347, DOI 10.1007/s10055-022-00636-4
   Gianaros PJ, 2001, AVIAT SPACE ENVIR MD, V72, P115
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   GUEDRY F E Jr, 1964, Acta Otolaryngol, V58, P377, DOI 10.3109/00016486409121398
   Heinrichs WL, 2008, WORLD J SURG, V32, P161, DOI 10.1007/s00268-007-9354-2
   Hettinger J., 1992, Presence: Teleoperators Virtual Environ., V1, P306, DOI [10.1162/pres.1992.1.3.306, DOI 10.1162/PRES.1992.1.3.306]
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Hong Y, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281519
   Horberry T, 2006, ACCIDENT ANAL PREV, V38, P185, DOI 10.1016/j.aap.2005.09.007
   HU S, 1991, AVIAT SPACE ENVIR MD, V62, P53
   HU S, 1988, PSYCHOPHYSIOLOGY, V25, P456
   Johnson Malcolm H, 2005, Curr Pain Headache Rep, V9, P90, DOI 10.1007/s11916-005-0044-1
   JungHa Park, 2020, The International Journal of Advanced Culture Technology, V8, P89
   Kahneman D., 1973, Attention and Effort
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B., 2014, Handbook of Virtual Environments: Design, Implementation, and Applications, V2nd, P648
   Keshavarz B, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00472
   Keshavarz B, 2014, APPL ERGON, V45, P521, DOI 10.1016/j.apergo.2013.07.009
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kwok KKK, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P91, DOI 10.1109/ISMAR-Adjunct.2018.00041
   Kye S, 2022, IEEE SENSOR, DOI 10.1109/SENSORS52175.2022.9967138
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lampton DR., 1994, Presence: Teleoperators and Virtual Environments, V3, P145
   Lansdown T, 2004, ERGONOMICS, V47, P91, DOI 10.1080/00140130310001629775
   Legrain V, 2009, PAIN, V144, P230, DOI 10.1016/j.pain.2009.03.020
   Lier EJ, 2022, SCAND J PAIN, V22, P385, DOI 10.1515/sjpain-2021-0119
   Lin YX, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419984
   Lo WT, 2001, APPL ERGON, V32, P1, DOI 10.1016/S0003-6870(00)00059-4
   MCCAUL KD, 1984, PSYCHOL BULL, V95, P516, DOI 10.1037/0033-2909.95.3.516
   McCauley Michael E, 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI [10.1162/pres.1992.1.3.311, DOI 10.1162/PRES.1992.1.3.311]
   Meusel C. R., 2014, Exploring mental effort and nausea via electrodermal activity within scenario-based tasks
   Miller JamesC., 1993, Autonomic physiological data associated with simulator discomfort
   Mohammed S, 2017, J COGN ENHANCE, V1, P491, DOI 10.1007/s41465-017-0047-y
   MONEY KE, 1970, PHYSIOL REV, V50, P1, DOI 10.1152/physrev.1970.50.1.1
   Monk AF, 2011, BEHAV RES METHODS, V43, P888, DOI 10.3758/s13428-011-0074-z
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Osborne J.W., 2000, Practical Assessment, Research, Evaluation, V7, DOI DOI 10.7275/PMGN-ZX89
   Owen AM, 2005, HUM BRAIN MAPP, V25, P46, DOI 10.1002/hbm.20131
   Pohlmann Katharina Margareta Theresa, 2023, P 2023 CHI C HUM FAC, P1
   Ranney T.A., 2001, NHTSA DRIVER DISTRAC
   Reason J.T., 1975, Motion Sickness
   REASON JT, 1978, J ROY SOC MED, V71, P819, DOI 10.1177/014107687807101109
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Rebenitsch L., 2015, XRDS: Crossroads, The ACM Magazine for Students, V22, P46
   RICCIO G E, 1991, Ecological Psychology, V3, P195, DOI 10.1207/s15326969eco0303_2
   Rizzo A, 2005, PRESENCE-TELEOP VIRT, V14, P119, DOI 10.1162/1054746053967094
   Salgado DP, 2019, PROCEDIA COMPUT SCI, V160, P665, DOI 10.1016/j.procs.2019.11.030
   Samson MM, 2001, AGING CLIN EXP RES, V13, P16, DOI 10.1007/BF03351489
   Sang FDYP, 2003, J TRAVEL MED, V10, P108, DOI 10.2310/7060.2003.31768
   Sang FDYP, 2003, AVIAT SPACE ENVIR MD, V74, P998
   Sepich NC, 2022, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.943409
   Sherman CR, 2002, J TRAVEL MED, V9, P251
   Snijders T., 2011, INTRO BASIC ADV MULT, V2nd ed
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney KM, 2002, HUM PERFORM, V15, P339, DOI 10.1207/S15327043HUP1504_03
   Stein Michael., 2012, Aviation Psychology and Applied Human Factors
   Strayer DL, 2011, PSYCHOL LEARN MOTIV, V54, P29, DOI 10.1016/B978-0-12-385527-5.00002-4
   THORNDYKE PW, 1982, COGNITIVE PSYCHOL, V14, P560, DOI 10.1016/0010-0285(82)90019-6
   TREISMAN M, 1977, SCIENCE, V197, P493, DOI 10.1126/science.301659
   Tu F. K., 2020, Smooth locomotion in vr: Comparing head orientation and controller orientation locomotion
   Vallat-Azouvi C, 2012, NEUROPSYCHOL REHABIL, V22, P634, DOI 10.1080/09602011.2012.681110
   Venkatakrishnan R., 2023, The effects of primary and secondary task workloads on cybersickness in immersive virtual active exploration experiences
   Venkatakrishnan R., 2023, IEEE Transactions on Visualization and Computer Graphics
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P682, DOI [10.1109/VR46266.2020.00-13, 10.1109/VR46266.2020.1581195115265]
   Venkatakrishnan R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1201, DOI [10.1109/VR.2019.8797728, 10.1109/vr.2019.8797728]
   Venkatakrishnan R, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560817
   Venkatakrishnan R, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P672, DOI [10.1109/VR46266.2020.00-14, 10.1109/VR46266.2020.1581256520838]
   von Janczewski N, 2021, TRANSPORT RES F-TRAF, V76, P269, DOI 10.1016/j.trf.2020.11.014
   Wald J, 2000, J BEHAV THER EXP PSY, V31, P249, DOI 10.1016/S0005-7916(01)00009-X
   Weech S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00158
   Wickens C.D., 1984, Varieties of Attention, P63
   Wickens C. D., 1980, Attention Per- form. VIII, V8, P239
   Wickens C.D., 2021, Handbook of Human Factors and Ergonmics, P114, DOI [DOI 10.1002/9781119636113.CH5, 10.1002/9781119636113.ch5]
   Wu F., 2021, P 2021 ACM S SPAT US, P1
   Wu F, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P103, DOI 10.1109/VR51125.2022.00028
   Young K., 2007, Distracted driving, V2007, P379, DOI DOI 10.1201/9781420007497
   Zhou C, 2019, IEEE INT CONF MOB, P72, DOI 10.1109/MASSW.2019.00021
NR 96
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2745
EP 2755
DI 10.1109/TVCG.2024.3372080
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400046
PM 38437100
DA 2024-11-06
ER

PT J
AU Venkatakrishnan, R
   Venkatakrishnan, R
   Canales, R
   Raveendranath, B
   Pagano, CC
   Robb, AC
   Lin, WC
   Babu, SV
AF Venkatakrishnan, Roshan
   Venkatakrishnan, Rohith
   Canales, Ryan
   Raveendranath, Balagopal
   Pagano, Christopher C.
   Robb, Andrew C.
   Lin, Wen-Chieh
   Babu, Sabarish V.
TI Investigating the Effects of Avatarization and Interaction Techniques on
   Near-field Mixed Reality Interactions with Physical Components
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Mixed Reality; Self-Avatars; Interactions in MR; Tangible entities
ID AUGMENTED REALITY; USER-INTERFACE; PERFORMANCE; ONLINE
AB Mixed reality (MR) interactions feature users interacting with a combination of virtual and physical components. Inspired by research investigating aspects associated with near-field interactions in augmented and virtual reality (AR & VR), we investigated how avatarization, the physicality of the interacting components, and the interaction technique used to manipulate a virtual object affected performance and perceptions of user experience in a mixed reality fundamentals of laparoscopic peg-transfer task wherein users had to transfer a virtual ring from one peg to another for a number of trials. We employed a 3 (Physicality of pegs) X 3 (Augmented Avatar Representation) X 2 (Interaction Technique) multi-factorial design, manipulating the physicality of the pegs as a between-subjects factor, the type of augmented self-avatar representation, and the type of interaction technique used for object-manipulation as within-subjects factors. Results indicated that users were significantly more accurate when the pegs were virtual rather than physical because of the increased salience of the task-relevant visual information. From an avatar perspective, providing users with a reach envelope-extending representation, though useful, was found to worsen performance, while co-located avatarization significantly improved performance. Choosing an interaction technique to manipulate objects depends on whether accuracy or efficiency is a priority. Finally, the relationship between the avatar representation and interaction technique dictates just how usable mixed reality interactions are deemed to be.
C1 [Venkatakrishnan, Roshan; Venkatakrishnan, Rohith] Univ Florida, Gainesville, FL 32611 USA.
   [Canales, Ryan; Raveendranath, Balagopal] Clemson Univ, Clemson, SC USA.
   [Pagano, Christopher C.] Clemson Univ, Dept Psychol, Clemson, SC USA.
   [Lin, Wen-Chieh] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
   [Robb, Andrew C.; Babu, Sabarish V.] Clemson Univ, Sch Comp, Clemson, SC USA.
C3 State University System of Florida; University of Florida; Clemson
   University; Clemson University; National Yang Ming Chiao Tung
   University; Clemson University
RP Venkatakrishnan, R (corresponding author), Univ Florida, Gainesville, FL 32611 USA.
EM rvenkatakrishnan@ufl.edu; rohith.venkatakr@ufl.edu; rcanale@clemson.edu;
   braveen@g.clemson.edu; cpagano@clemson.edu; arobb@clemson.edu;
   wclin@cs.nctu.edu.tw; sbabu@clemson.edu
RI Venkatakrishnan, Rohith/JCE-8736-2023; Venkatakrishnan,
   Roshan/JDC-3508-2023
OI Canales, Ryan/0000-0003-0554-7817; Babu, Sabarish/0000-0002-8348-0534;
   Pagano, Christopher/0000-0002-0110-2055; Robb,
   Andrew/0000-0002-0398-5576; Venkatakrishnan, Roshan/0000-0002-6538-627X;
   Venkatakrishnan, Rohith/0000-0002-8484-3915
FU US National Science Foundation (CISE IIS HCC)
FX No Statement Available
CR Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Badam S. K., 2017, 2 WORKSH IMM AN, P3
   Bowman D. A., 1999, Interaction techniques for common tasks in immersive virtual environments: design, evaluation, and application, P5
   Bozgeyikli E, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P778, DOI 10.1109/VR50410.2021.00105
   Brickler D, 2021, ACM T APPL PERCEPT, V18, DOI 10.1145/3486583
   Brickler D, 2020, ACM T APPL PERCEPT, V17, DOI 10.1145/3419986
   Brickler D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P28, DOI [10.1109/VR.2019.8797744, 10.1109/vr.2019.8797744]
   Bullock IM, 2015, IEEE ENG MED BIO, P5768, DOI 10.1109/EMBC.2015.7319703
   Canales R, 2020, PROCEEDINGS OF THE 13TH ACM SIGGRAPH CONFERENCE ON MOTION, INTERACTION AND GAMES, MIG 2020, DOI 10.1145/3424636.3426897
   Chen ZR, 2017, IEEE SYS MAN CYBERN, P206, DOI 10.1109/SMC.2017.8122603
   Cheng KY, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1155
   Ebrahimi E, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225170
   Ehnes J, 2009, C HUM SYST INTERACT, P303, DOI 10.1109/HSI.2009.5090997
   Esmaeili S, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P453, DOI [10.1109/VR46266.2020.1581285352835, 10.1109/VR46266.2020.00-38]
   Fajen B. R., 2021, Visual control of locomotion, P8
   Feiner A.O.S., 2003, P UIST, P81
   Feuchtner T, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5145, DOI 10.1145/3025453.3025689
   Fried GM, 2008, J GASTROINTEST SURG, V12, P210, DOI 10.1007/s11605-007-0355-0
   Frutos-Pascual M, 2019, LECT NOTES COMPUT SC, V11749, P287, DOI 10.1007/978-3-030-29390-1_16
   Genay A, 2022, IEEE T VIS COMPUT GR, V28, P5071, DOI 10.1109/TVCG.2021.3099290
   Gerini L, 2022, IEEE INT SYMP M AU R, P566, DOI 10.1109/ISMAR-Adjunct57072.2022.00118
   Gomez SR, 2010, LECT NOTES COMPUT SC, V6454, P373, DOI 10.1007/978-3-642-17274-8_37
   Ha T, 2014, INT SYM MIX AUGMENT, P219, DOI 10.1109/ISMAR.2014.6948431
   Ha T, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P91, DOI 10.1109/3DUI.2010.5444713
   Heinrich C, 2021, VIRTUAL REAL-LONDON, V25, P313, DOI 10.1007/s10055-020-00456-4
   Hettiarachchi A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1957, DOI 10.1145/2858036.2858134
   Hoang TN, 2013, PROCEEDINGS OF 2013 23RD INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE (ICAT 2013), P46
   Hofmann DA, 1997, J MANAGE, V23, P723, DOI 10.1177/014920639702300602
   Ishiyama H, 2016, P IEEE VIRT REAL ANN, P187, DOI 10.1109/VR.2016.7504716
   Issarter P, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2014.6798839
   Johnson Adrian S., 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P169, DOI 10.1007/978-3-642-39405-8_20
   Kaiser E., 2003, ICMI 03, P12, DOI DOI 10.1145/958432.958438
   Kang HJ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P275, DOI [10.1109/VR46266.2020.00047, 10.1109/VR46266.2020.00-57]
   Kohm K, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3561055
   Kopper R, 2010, INT J HUM-COMPUT ST, V68, P603, DOI 10.1016/j.ijhcs.2010.05.001
   Kyriakou Panayiotis, 2019, Digital Applications in Archaeology and Cultural Heritage, V12, DOI 10.1016/j.daach.2018.e00088
   Kytö M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173655
   Lamounier E A., 2012, Journal of Bioengineering  Biomedical Science, V1, P010, DOI [DOI 10.4172/2155-9538.S1-010, 10.4172/2155-9538.S1-010]
   Lewis JR, 2002, INT J HUM-COMPUT INT, V14, P463, DOI 10.1080/10447318.2002.9669130
   Li K, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079400
   Li ZM, 2007, J BIOMECH, V40, P502, DOI 10.1016/j.jbiomech.2006.02.019
   Lu G, 2012, VIRTUAL REAL-LONDON, V16, P243, DOI 10.1007/s10055-011-0195-9
   Macaranas A, 2015, INTERACT COMPUT, V27, P357, DOI 10.1093/iwc/iwv003
   Marzke MW, 1997, AM J PHYS ANTHROPOL, V102, P91
   Merrill D, 2007, LECT NOTES COMPUT SC, V4480, P1
   Mifsud DM, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P581, DOI 10.1109/VRW55335.2022.00146
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Nagel T., 2011, GEOVIZ 2011, P10
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   Noh S., 2015, P INT C ART REAL TEL, P61
   O'Connor TF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179766
   Otono R, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2022), P721, DOI 10.1109/VRW55335.2022.00216
   Piekarski W., 2003, IPT/EGVE 2003. Seventh Immersive Projection Technology Workshop. Ninth Eurographics Workshop on Virtual Environments, P19, DOI 10.1145/769953.769956
   Pierce J. S., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P39, DOI 10.1145/253284.253303
   Piumsomboon T, 2013, LECT NOTES COMPUT SC, V8118, P282
   Piumsomboon Thammathip., 2011, Proc. Image and Vision Computing New Zealand (IVCNZ-2011), P161
   Poelman R., 2012, P ACM 2012 C COMP SU, P1267, DOI [10.1145/2145204.2145394, DOI 10.1145/2145204.2145394]
   Prilla Michael., 2019, AIS Transactions on Human-Computer Interaction, V11, P157, DOI DOI 10.17705/1THCI.00118
   Quandt M., 2020, DELIA@ EC-TEL
   Radkowski R., 2012, P 2012 INT C ADV COM, P303
   Robb A, 2022, ACM T APPL PERCEPT, V19, DOI 10.1145/3560818
   Rosa N, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P550, DOI 10.1145/2993148.2997618
   Schiettecatte B., 2008, Proceedings of the 2nd international conference on Tangible and embedded interaction, P3
   Schmidt S, 2019, ACM CONFERENCE ON SPATIAL USER INTERACTION (SUI 2019), DOI 10.1145/3357251.3357591
   Serrano R, 2022, MULTIMED TOOLS APPL, V81, P31657, DOI 10.1007/s11042-022-12864-6
   Sibert L. E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P281, DOI 10.1145/332040.332445
   Snijders T. A. B., 2012, Multilevel Analysis, V2nd
   Soares Alcimar Barbosa., 2012, Computational Intelligence in Electromyography Analysis-A Perspective on Current Applications and Future Challenges, P409
   Speicher M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300767
   Sroka G, 2010, AM J SURG, V199, P115, DOI 10.1016/j.amjsurg.2009.07.035
   Terrier R, 2018, LECT NOTES COMPUT SC, V11162, P190, DOI 10.1007/978-3-030-01790-3_12
   Valentini PP, 2018, INT J INTERACT DES M, V12, P1157, DOI 10.1007/s12008-018-0461-0
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2412, DOI 10.1109/TVCG.2023.3247105
   Venkatakrishnan R, 2023, IEEE T VIS COMPUT GR, V29, P2258, DOI 10.1109/TVCG.2023.3247041
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wen, 2023, Wen 3921 16-inch two-direction variable speed scroll saw
   Whitlock M, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P41, DOI 10.1109/VR.2018.8446381
   Wither J, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P124, DOI 10.1109/ISWC.2004.18
   Wolf E, 2020, INT SYM MIX AUGMENT, P462, DOI 10.1109/ISMAR50242.2020.00071
   Yee N, 2009, COMMUN RES, V36, P285, DOI 10.1177/0093650208330254
   Zenner A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P47, DOI [10.1109/vr.2019.8798143, 10.1109/VR.2019.8798143]
   Zhao HY, 2015, VISION RES, V110, P190, DOI 10.1016/j.visres.2014.10.008
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 84
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2756
EP 2766
DI 10.1109/TVCG.2024.3372050
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400039
PM 38437122
DA 2024-11-06
ER

PT J
AU Heagerty, J
   Li, SD
   Lee, ER
   Bhattacharyya, S
   Bista, S
   Brawn, B
   Feng, BY
   Jabbireddy, S
   Jaja, J
   Kacorri, H
   Li, DV
   Yarnell, D
   Zwicker, M
   Varshney, A
AF Heagerty, Jonathan
   Li, Sida
   Lee, Eric
   Bhattacharyya, Shuvra
   Bista, Sujal
   Brawn, Barbara
   Feng, Brandon Y.
   Jabbireddy, Susmija
   Jaja, Joseph
   Kacorri, Hernisa
   Li, David
   Yarnell, Derek
   Zwicker, Matthias
   Varshney, Amitabh
TI HoloCamera: Advanced Volumetric Capture for Cinematic-Quality VR
   Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Volumetric Capture; Light Fields; Holoportation; Multi-camera Array
AB High-precision virtual environments are increasingly important for various education, simulation, training, performance, and entertainment applications. We present HoloCamera, an innovative volumetric capture instrument to rapidly acquire, process, and create cinematic-quality virtual avatars and scenarios. The HoloCamera consists of a custom-designed free-standing structure with 300 high-resolution RGB cameras mounted with uniform spacing spanning the four sides and the ceiling of a room-sized studio. The light field acquired from these cameras is streamed through a distributed array of GPUs that interleave the processing and transmission of 4K resolution images. The distributed compute infrastructure that powers these RGB cameras consists of 50 Jetson AGX Xavier boards, with each processing unit dedicated to driving and processing imagery from six cameras. A high-speed Gigabit Ethernet network fabric seamlessly interconnects all computing boards. In this systems paper, we provide an in-depth description of the steps involved and lessons learned in constructing such a cutting-edge volumetric capture facility that can be generalized to other such facilities. We delve into the techniques employed to achieve precise frame synchronization and spatial calibration of cameras, careful determination of angled camera mounts, image processing from the camera sensors, and the need for a resilient and robust network infrastructure. To advance the field of volumetric capture, we are releasing a high-fidelity static light-field dataset, which will serve as a benchmark for further research and applications of cinematic-quality volumetric light fields.
C1 [Heagerty, Jonathan; Li, Sida; Lee, Eric; Bhattacharyya, Shuvra; Bista, Sujal; Brawn, Barbara; Feng, Brandon Y.; Jabbireddy, Susmija; Jaja, Joseph; Kacorri, Hernisa; Li, David; Yarnell, Derek; Zwicker, Matthias; Varshney, Amitabh] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Heagerty, J (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM jheager2@umd.edu; sidali@umd.edu; erclee2@gmail.com; ssb@umd.edu;
   sujal@umd.edu; bbrawn@umd.edu; yfeng97@umd.edu; jsreddy@umd.edu;
   josephj@umd.edu; hernisa@umd.edu; dli7319@umd.edu; derek@umiacs.umd.edu;
   zwicker@umd.edu; varshney@cs.umd.edu
RI ; Feng, Brandon Yushan/ABH-3517-2021
OI Heagerty, Jonathan/0009-0005-9761-0714; Kacorri,
   Hernisa/0000-0002-7798-308X; Li, Sida/0000-0003-2601-821X;
   Bhattacharyya, Shuvra/0000-0001-7719-1106; Feng, Brandon
   Yushan/0000-0001-7003-9128; JaJa, joseph/0000-0002-8620-5650
FU NSF
FX No Statement Available
CR 4Dviews, 2023, 4Dviews-Volumetric Video Capture Technology
   8i, 2023, ASPX Hologram Stages
   [Anonymous], 2023, Intel Studios Showcases Volumetric Production at 77th Venice International Film Festival
   Bradski G, 2000, DR DOBBS J, V25, P120
   Broxton M, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392485
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Dimension, 2023, Studio Overview
   Dou MS, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P15, DOI 10.1109/VR.2012.6180869
   Fang SK, 2023, AAAI CONF ARTIF INTE, P597
   Feng BY, 2022, LECT NOTES COMPUT SC, V13663, P138, DOI 10.1007/978-3-031-20062-5_9
   Feng BY, 2024, IEEE T VIS COMPUT GR, V30, P1685, DOI 10.1109/TVCG.2022.3224674
   Feng BY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14204, DOI 10.1109/ICCV48922.2021.01396
   Gross M, 2003, ACM T GRAPHIC, V22, P819, DOI 10.1145/882262.882350
   Isik M, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592415
   Kurillo G, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072469
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Li B, 2013, IEEE INT C INT ROBOT, P1301, DOI 10.1109/IROS.2013.6696517
   Li D., 2023, 34 BRIT MACHINE VIS
   Li D, 2022, INT CONF 3D VISION, P231, DOI 10.1109/3DV57658.2022.00035
   Lin SC, 2021, PROC CVPR IEEE, P8758, DOI 10.1109/CVPR46437.2021.00865
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maimone A., 2012, 2012 3DTV C TRUE VI, P1
   Metastage, 2023, Metastage: Our Tech
   Mildenhall B., 2020, P ECCV
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Reiser C, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592426
   Reiser C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14315, DOI 10.1109/ICCV48922.2021.01407
   Rogez B., 2023, SIGGRAPH 2023: 4Dviews unveils cutting edge volumetric capture system HOLOSYS+
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schreer O., 2020, SMPTE Motion Imag. J., V129, P31
   Schreer O, 2019, IEEE IMAGE PROC, P4310, DOI [10.1109/ICIP.2019.8803576, 10.1109/icip.2019.8803576]
   Sitzmann V, 2021, ADV NEUR IN, V34
   Sony, 2023, Volumetric Capture Technology That Goes Beyond Omnidirectional Visualization
   Tomar S., 2006, LINUX J, V2006, P10
   Wang H, 2022, LECT NOTES COMPUT SC, V13691, P612, DOI 10.1007/978-3-031-19821-2_35
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Wilburn B, 2002, PROC SPIE, V4674, P29
   Wu Y., 2023, P IEEECVF INT C COM, P18506
   Yu H, 2023, PROC CVPR IEEE, P12397, DOI 10.1109/CVPR52729.2023.01193
NR 40
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2767
EP 2775
DI 10.1109/TVCG.2024.3372123
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400031
PM 38564356
DA 2024-11-06
ER

PT J
AU Lenz, LS
   Fender, AR
   Chatain, J
   Holz, C
AF Lenz, Lara Sofie
   Fender, Andreas Rene
   Chatain, Julia
   Holz, Christian
TI Comparing Synchronous and Asynchronous Task Delivery in Mixed Reality
   Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Virtual reality; Mixed reality; Switches; Collaboration;
   Asynchronous communication; Training; Mixed Reality; Workspaces;
   Interruptions; Evaluation; Task focus
ID INTERRUPTIONS; WORK
AB Asynchronous digital communication is a widely applied and well-known form of information exchange. Most pieces of technology make use of some variation of asynchronous communication systems, be it messaging or email applications. This allows recipients to process digital messages immediately (synchronous) or whenever they have time (asynchronous), meaning that purely digital interruptions can be mitigated easily. Mixed Reality systems have the potential to not only handle digital interruptions but also interruptions in physical space, e.g., caused by co-workers in workspaces or learning environments. However, the benefits of such systems previously remained untested in the context of Mixed Reality. We conducted a user study (N=26) to investigate the impact that the timing of task delivery has on the participants' performance, workflow, and emotional state. Participants had to perform several cognitively demanding tasks in a Mixed Reality workspace. Inside the virtual workspace, we simulated in-person task delivery either during tasks (i.e., interrupting the participant) or between tasks (i.e., delaying the interruption). Our results show that delaying interruptions has a significant impact on subjective metrics like the perceived performance and workload.
C1 [Lenz, Lara Sofie; Fender, Andreas Rene; Holz, Christian] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Chatain, Julia] Swiss Fed Inst Technol, Dept Educ Dev & Technol, Zurich, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Swiss Federal
   Institutes of Technology Domain; ETH Zurich
RP Fender, AR (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
EM lara.lenz@gmx.ch; progga.af@gmail.com; jchatain@ethz.ch;
   christian.holz@inf.ethz.ch
RI Holz, Christian/AAV-4925-2020; Chatain, Julia/AEH-7938-2022
OI Holz, Christian/0000-0001-9655-9519; Fender, Andreas/0000-0002-5903-0736
FU Zurich Information Security and Privacy Center
FX No Statement Available
CR Adler RF, 2013, COMPUT HUM BEHAV, V29, P1441, DOI 10.1016/j.chb.2013.01.040
   Altmann EM, 2014, J EXP PSYCHOL GEN, V143, P215, DOI 10.1037/a0030986
   [Anonymous], NASA task load index
   Apple, 2023, Vision pro
   Bailey BP, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P593
   Bailey BP, 2000, IEEE SYS MAN CYBERN, P757, DOI 10.1109/ICSMC.2000.885940
   Bardram JE, 2010, COMPUT SUPP COOP W J, V19, P105, DOI 10.1007/s10606-010-9110-2
   Billinghurst M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1641, DOI 10.1109/ICME.2000.871085
   Blumberg EJ, 2015, HUM FACTORS, V57, P1051, DOI 10.1177/0018720814565189
   Chen A., 2014, AIS Transactions on Human-Computer Interaction, V6, P2
   Chen A, 2018, MIS QUART, V42, P1023, DOI 10.25300/MISQ/2018/13631
   Cutrell E, 2001, HUMAN-COMPUTER INTERACTION - INTERACT'01, P263
   Czerwinski M, 2000, PEOPL COMP 14 P HCI, P71
   Czerwinski M., 2000, P OZCHI, V2000, P356, DOI DOI 10.1016/S1361-3723(02)01112-0
   Czerwinski M., 1991, ACM SIGCHI Bulletin, V23, P38, DOI [DOI 10.1145/126729.1056014, 10.1145/126729.10560142, DOI 10.1145/126729.10560142]
   Danninger M., 2005, P GRAPHICS INTERFACE, P1
   Dubosc C, 2021, COMPUT GRAPH-UK, V101, P82, DOI 10.1016/j.cag.2021.08.011
   Dzardanova E, 2022, VIRTUAL REAL-LONDON, V26, P737, DOI 10.1007/s10055-021-00564-9
   Ens B, 2019, INT J HUM-COMPUT ST, V131, P81, DOI 10.1016/j.ijhcs.2019.05.011
   Eyrolle H, 2000, APPL ERGON, V31, P537, DOI 10.1016/S0003-6870(00)00019-3
   Federman JE, 2019, EUR J TRAIN DEV, V43, P490, DOI 10.1108/EJTD-10-2018-0100
   Fender A, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS'18), P73, DOI 10.1145/3279778.3279794
   Fender AR, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501836
   Fischer Joel E., 2010, P 12 INT C HUM COMP, P103, DOI [DOI 10.1145/1851600.1851620, 10.1145/1851600.1851620]
   Fitz N, 2019, COMPUT HUM BEHAV, V101, P84, DOI 10.1016/j.chb.2019.07.016
   George C, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P497, DOI 10.1145/3322276:3322363
   George C, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364273
   GILLIE T, 1989, PSYCHOL RES-PSYCH FO, V50, P243, DOI 10.1007/BF00309260
   Gopher D, 1996, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY - 40TH ANNUAL MEETING, VOLS 1 AND 2, P1060
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Hart Sandra G, 1986, NASA task load index (TTX)
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   HESS SM, 1994, HUM FAC ERG SOC P, P1173
   Horvitz E. J., 2013, arXiv
   Horvitz Eric, 2003, P 5 INT C MULT INT I, P20, DOI [DOI 10.1145/958432.958440, 10.1145/958432.958440]
   Jambon F., 1996, HUMAN FACTORS COMPUT, P45, DOI [10.1145/257089.2571282, DOI 10.1145/257089.2571282]
   Knierim P., 2020, P AUGM HUM INT C AHS, DOI [10.1145/3384657.3384659, DOI 10.1145/3384657.3384659]
   Kushlev K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1011, DOI 10.1145/2858036.2858359
   Lilija K, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376604
   Linde C., 1987, Technical report, P2
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Lopez-Rosenfeld M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125772
   Mandler G., 1966, Anxiety and behavior, V1, P2
   Mansi G, 2013, INT J INFORM MANAGE, V33, P591, DOI 10.1016/j.ijinfomgt.2013.01.011
   Mark G, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P107
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Meta, 2023, Meta quest 2
   Microsoft, 2023, Azure kinect
   Minassian S. O., 2004, Diverse strategies for interruption management in complex office activities, DOI 10.1.80.2944
   Miyata Y., 1986, User centered system design: New perspectives on humancomputer interaction, P2
   Monk CA, 2004, HUM FACTORS, V46, P650, DOI 10.1518/hfes.46.4.650.56816
   O'Hagan J, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581018
   O'Hagan J, 2022, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2022, DOI 10.1145/3531073.3531079
   OConaill Brid, 1995, C COMP HUM FACT COMP, P262, DOI [DOI 10.1145/223355.223665, 10.1145/223355.223665]
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Penichet VMR, 2007, ELECTRON NOTES THEOR, V168, P237, DOI 10.1016/j.entcs.2006.12.007
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132822
   Ratwani R M., 2006, P HUMAN FACTORS ERGO, DOI DOI 10.1177/154193120605000334
   Roo JS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P787, DOI 10.1145/3126594.3126638
   Salvucci DD, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P85
   Sasangohar F, 2017, HUM FACTORS, V59, P628, DOI 10.1177/0018720816689513
   Sykes ER, 2011, INT J INFORM MANAGE, V31, P385, DOI 10.1016/j.ijinfomgt.2010.10.010
   Tinwell A., 2014, Nonverbal Communication In Virtual Worlds, P325
   U. Technologies, 2023, Unity3d engine 2020.3.14
   van Solingen R, 1998, IEEE SOFTWARE, V15, P97, DOI 10.1109/52.714843
   Wilson AD, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P100, DOI 10.1145/3132272.3134144
NR 66
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2776
EP 2784
DI 10.1109/TVCG.2024.3372034
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400042
PM 38437079
DA 2024-11-06
ER

PT J
AU Yin, TR
   Hoyet, L
   Christie, M
   Cani, MP
   Pettré, J
AF Yin, Tairan
   Hoyet, Ludovic
   Christie, Marc
   Cani, Marie-Paule
   Pettre, Julien
TI With or Without You: Effect of Contextual and Responsive Crowds on
   VR-based Crowd Motion Capture
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Trajectory; Motion capture; Recording; Pedestrians;
   Data models; Solid modeling; Crowd Simulation; Human Interaction;
   Virtual Reality
ID VIRTUAL-REALITY; PERSONAL-SPACE; PERCEPTION; BEHAVIORS; MODEL
AB While data is vital to better understand and model interactions within human crowds, capturing real crowd motions is extremely challenging. Virtual Reality (VR) demonstrated its potential to help, by immersing users into either simulated virtual crowds based on autonomous agents, or within motion-capture-based crowds. In the latter case, users' own captured motion can be used to progressively extend the size of the crowd, a paradigm called Record-and-Replay (2R). However, both approaches demonstrated several limitations which impact the quality of the acquired crowd data. In this paper, we propose the new concept of contextual crowds to leverage both crowd simulation and the 2R paradigm towards more consistent crowd data. We evaluate two different strategies to implement it, namely a Replace-Record-Replay (3R) paradigm where users are initially immersed into a simulated crowd whose agents are successively replaced by the user's captured-data, and a Replace-Record-Replay-Responsive (4R) paradigm where the pre-recorded agents are additionally endowed with responsive capabilities. These two paradigms are evaluated through two real-world-based scenarios replicated in VR. Our results suggest that the behaviors observed in VR users with surrounding agents from the beginning of the recording process are made much more natural, enabling 3R or 4R paradigms to improve the consistency of captured crowd datasets.
C1 [Yin, Tairan; Hoyet, Ludovic; Christie, Marc; Pettre, Julien] Univ Rennes, CNRS, Inria, IRISA, Rennes, France.
   [Cani, Marie-Paule] CNRS, Ecole Polytech, IP Paris, LIX, Palaiseau, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Rennes; Inria; Institut Polytechnique de Paris; Ecole Polytechnique;
   Centre National de la Recherche Scientifique (CNRS)
RP Yin, TR (corresponding author), Univ Rennes, CNRS, Inria, IRISA, Rennes, France.
EM tairan.yin@inria.fr; ludovic.hoyet@inria.fr; marc.christie@irisa.fr;
   marie-paule.cani@polytechnique.edu; julien.pettre@inria.fr
RI Hoyet, Ludovic/IWU-9100-2023; Pettre, Julien/KZT-8249-2024
OI Hoyet, Ludovic/0000-0002-7373-6049; Pettre, Julien/0000-0003-1812-1436;
   Yin, Tairan/0000-0001-6023-6507; CANI, Marie-Paule/0000-0001-7752-9031
FU European Union's Horizon 2020 research and innovation programme
FX No Statement Available
CR Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Araújo JP, 2023, Arxiv, DOI arXiv:2303.17912
   Armbrüster C, 2008, CYBERPSYCHOL BEHAV, V11, P9, DOI 10.1089/cpb.2007.9935
   Bailenson JN, 2001, PRESENCE-VIRTUAL AUG, V10, P583, DOI 10.1162/105474601753272844
   Banton T, 2005, PRESENCE-TELEOP VIRT, V14, P394, DOI 10.1162/105474605774785262
   Berton F, 2022, IEEE T VIS COMPUT GR, V28, P2589, DOI 10.1109/TVCG.2020.3041341
   Berton F, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P322, DOI [10.1109/VR46266.2020.1581264804299, 10.1109/VR46266.2020.00-52]
   Berton F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P717, DOI [10.1109/VR.2019.8798204, 10.1109/vr.2019.8798204]
   Brscic D, 2013, IEEE T HUM-MACH SYST, V43, P522, DOI 10.1109/THMS.2013.2283945
   Bruneau J, 2015, IEEE T VIS COMPUT GR, V21, P520, DOI 10.1109/TVCG.2015.2391862
   Daniel BC, 2021, P ACM COMPUT GRAPH, V4, DOI 10.1145/3480136
   Cao SC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa620d
   Charalambous P, 2014, COMPUT GRAPH FORUM, V33, P95, DOI 10.1111/cgf.12403
   Conigliaro D, 2015, PROC CVPR IEEE, P2039, DOI 10.1109/CVPR.2015.7298815
   Dickinson P, 2019, VIRTUAL REAL-LONDON, V23, P19, DOI 10.1007/s10055-018-0365-0
   Echeverría-Huarte I, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79454-0
   Ezaki T., 2016, Collective Dynamics, V1, P1, DOI [10.17815/CD.2016.42, DOI 10.17815/CD.2016.42]
   Feldmann S, 2023, SAFETY SCI, V164, DOI 10.1016/j.ssci.2023.106173
   Feliciani C, 2020, TRANSPORT RES C-EMER, V114, P484, DOI 10.1016/j.trc.2020.02.019
   Feng Y, 2021, BUILD ENVIRON, V187, DOI 10.1016/j.buildenv.2020.107329
   Fink PW, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1227134.1227136
   Friston K, 2007, STATISTICAL PARAMETRIC MAPPING: THE ANALYSIS OF FUNCTIONAL BRAIN IMAGES, P10, DOI 10.1016/B978-012372560-8/50002-4
   Garcia W, 2021, SAFETY SCI, V144, DOI 10.1016/j.ssci.2021.105453
   Geoerg P, 2019, J ADV TRANSPORT, DOI 10.1155/2019/9717208
   Gérin-Lajoie M, 2008, GAIT POSTURE, V27, P239, DOI 10.1016/j.gaitpost.2007.03.015
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hessels RS, 2022, ATTEN PERCEPT PSYCHO, V84, P2623, DOI 10.3758/s13414-022-02541-z
   Hessels RS, 2020, ATTEN PERCEPT PSYCHO, V82, P2482, DOI 10.3758/s13414-019-01952-9
   Karamouzas I, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073705
   Kinateder M, 2021, PHYSICA A, V569, DOI 10.1016/j.physa.2021.125746
   Kwiatkowski A, 2023, COMPUT GRAPH-UK, V110, P28, DOI 10.1016/j.cag.2022.11.007
   Lemercier S, 2012, COMPUT GRAPH FORUM, V31, P489, DOI 10.1111/j.1467-8659.2012.03028.x
   Liu YJ, 2022, PROC CVPR IEEE, P17060, DOI 10.1109/CVPR52688.2022.01657
   Llobera J, 2010, ACM T APPL PERCEPT, V8, DOI 10.1145/1857893.1857896
   Lynch SD, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI 10.1109/VR.2018.8446180
   Moussaïd M, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0414
   Moussaïd M, 2009, P ROY SOC B-BIOL SCI, V276, P2755, DOI 10.1098/rspb.2009.0405
   Mullick P, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010210
   Nelson M, 2019, 17TH ACM SIGGRAPH INTERNATIONAL CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY (VRCAI 2019), DOI 10.1145/3359997.3365709
   Nicolas A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36711-7
   Olivier A.-H., 2018, Collective Dynamics
   Olivier AH, 2014, TRANSP RES PROC, V2, P114, DOI 10.1016/j.trpro.2014.09.015
   Ondrej J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778860
   Patotskaya Y, 2023, COMPUT GRAPH-UK, V110, P162, DOI 10.1016/j.cag.2023.01.001
   Pettre J., 2009, Proceedings of the 2009 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA '09, P189, DOI DOI 10.1145/1599470.1599495
   Podkosova I, 2018, ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES (I3D 2018), DOI 10.1145/3190834.3190845
   Raimbaud P, 2023, PROCEEDINGS OF THE ACM SYMPOSIUM ON APPLIED PERCEPTION, SAP 2023, DOI 10.1145/3605495.3605796
   Raimbaud P, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P281, DOI 10.1109/VR51125.2022.00047
   Renner RS, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543590
   Ríos A, 2020, VIRTUAL REAL-LONDON, V24, P683, DOI 10.1007/s10055-020-00428-8
   Sanz FA, 2015, P IEEE VIRT REAL ANN, P75, DOI 10.1109/VR.2015.7223327
   Seyfried A, 2008, LECT NOTES COMPUT SC, V5191, P563, DOI 10.1007/978-3-540-79992-4_77
   Seyfried A, 2009, TRANSPORT SCI, V43, P395, DOI 10.1287/trsc.1090.0263
   Sharma A, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-01932-7
   Shi XM, 2018, J ADV TRANSPORT, DOI 10.1155/2018/1063043
   Sundararaman R, 2021, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR46437.2021.00386
   Trivedi H, 2023, COMPUT ANIMAT VIRT W, V34, DOI 10.1002/cav.2169
   van den Berg J, 2008, IEEE INT CONF ROBOT, P1928, DOI 10.1109/ROBOT.2008.4543489
   van den Berg J, 2011, SPRINGER TRAC ADV RO, V70, P3
   van Toll W, 2021, COMPUT GRAPH FORUM, V40, P731, DOI 10.1111/cgf.142664
   van Toll W, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384532
   Wolinski D, 2014, COMPUT GRAPH FORUM, V33, P303, DOI 10.1111/cgf.12328
   Xu P, 2022, LECT NOTES COMPUT SC, V13664, P511, DOI 10.1007/978-3-031-19772-7_30
   Yersin B., 2009, ACM S INTERACTIVE 3D
   Yin TR, 2022, IEEE T VIS COMPUT GR, V28, P2245, DOI 10.1109/TVCG.2022.3150507
   Zhong JH, 2022, ACM T MODEL COMPUT S, V32, DOI 10.1145/3481299
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
NR 68
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2785
EP 2795
DI 10.1109/TVCG.2024.3372038
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400058
PM 38437106
DA 2024-11-06
ER

PT J
AU Biener, V
   Farzinnejad, F
   Schuster, R
   Tabaei, S
   Lindlein, L
   Hu, JH
   Nouri, N
   Dudley, JJ
   Krlstensson, PO
   Müller, J
   Grubert, J
AF Biener, Verena
   Farzinnejad, Forouzan
   Schuster, Rinaldo
   Tabaei, Seyedmasih
   Lindlein, Leon
   Hu, Jinghui
   Nouri, Negar
   Dudley, John J.
   Krlstensson, Per Ola
   Mueller, Joerg
   Grubert, Jens
TI Hold Tight: Identifying Behavioral Patterns During Prolonged Work in VR
   Through Video Analysis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Behavioral sciences; Resists; Task analysis; Headphones; Visualization;
   Keyboards; Human factors; virtual reality; video-analysis; productivity
   work; long-term; prolonged use; office work; future of work
AB VR devices have recently been actively promoted as tools for knowledge workers and prior work has demonstrated that VR can support some knowledge worker tasks. However, only a few studies have explored the effects of prolonged use of VR such as a study observing 16 participants working in VR and a physical environment for one work-week each and reporting mainly on subjective feedback. As a nuanced understanding of participants' behavior in VR and how it evolves over time is still missing, we report on the results from an analysis of 559 hours of video material obtained in this prior study. Among other findings, we report that (1) the frequency of actions related to adjusting the headset reduced by 46% and the frequency of actions related to supporting the headset reduced by 42% over the five days; (2) the HMD was removed 31% less frequently over the five days but for 41% longer periods; (3) wearing an HMD is disruptive to normal patterns of eating and drinking, but not to social interactions, such as talking. The combined findings in this work demonstrate the value of long-term studies of deployed VR systems and can be used to inform the design of better, more ergonomic VR systems as tools for knowledge workers.
C1 [Biener, Verena; Farzinnejad, Forouzan; Schuster, Rinaldo; Tabaei, Seyedmasih; Lindlein, Leon; Nouri, Negar; Grubert, Jens] Coburg Univ Appl Sci & Arts, Coburg, Germany.
   [Hu, Jinghui; Dudley, John J.; Krlstensson, Per Ola] Univ Cambridge, Cambridge, England.
   [Mueller, Joerg] Univ Bayreuth, Bayreuth, Germany.
C3 Klinikum Coburg; University of Cambridge; University of Bayreuth
RP Biener, V (corresponding author), Coburg Univ Appl Sci & Arts, Coburg, Germany.
EM verena.biener@hs-coburg.de; forouzan.farzinnejad@hs-coburg.de;
   Rinaldo.Schuster@stud.hs-coburg.de; Seyedmasih.Tabaei@stud.hs-coburg.de;
   Leon.Lindlein@stud.hs-coburg.de; jh2265@cam.ac.uk;
   negar.nouri@hs-coburg.de; jjd50@cam.ac.uk; pok21@cam.ac.uk;
   Joerg.Mueller@uni-bayreuth.de; jens.grubert@hs-coburg.de
RI Hu, Jinghui/ABH-8537-2020; Grubert, Jens/B-1012-2018
OI Kristensson, Per Ola/0000-0002-7139-871X
CR Bai HD, 2021, COMPUT GRAPH-UK, V97, P42, DOI 10.1016/j.cag.2021.04.004
   Berg LP, 2017, VIRTUAL REAL-LONDON, V21, P1, DOI 10.1007/s10055-016-0293-9
   Biener V, 2020, Arxiv, DOI arXiv:2008.04559
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P3810, DOI 10.1109/TVCG.2022.3203103
   Biener V, 2022, IEEE T VIS COMPUT GR, V28, P2069, DOI 10.1109/TVCG.2022.3150474
   Blanca MJ, 2023, PSICOTHEMA, V35, P21, DOI 10.7334/psicothema2022.292
   Brown E., 2018, IEEE VRS 4 WORKSH ON, V10, P3
   Brugman Hennie., 2004, Proceedings of LREC (Fourth International Conference on Language Resources and Evaluation), VVol. 4, P2065
   Chen YM, 2021, CCF T PERVAS COMPUT, V3, P99, DOI 10.1007/s42486-021-00062-6
   Ciccone BA, 2023, ERGON DES, V31, P24, DOI 10.1177/10648046211002578
   Das Thoondee K, 2017, 2017 COMPUTING CONFERENCE, P492, DOI 10.1109/SAI.2017.8252142
   Desai AP, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P217, DOI 10.1109/CRV.2017.16
   Gesslein T, 2020, INT SYM MIX AUGMENT, P361, DOI 10.1109/ISMAR50242.2020.00063
   Grajewski D, 2013, PROCEDIA COMPUT SCI, V25, P289, DOI 10.1016/j.procs.2013.11.035
   Grubert D., 2010, 2010 IEEE INT S MIX, P229
   Grubert J, 2018, IEEE COMPUT GRAPH, V38, P125, DOI 10.1109/MCG.2018.2875609
   Grubert J, 2015, PERVASIVE MOB COMPUT, V18, P88, DOI 10.1016/j.pmcj.2014.08.005
   Grubert Jens, 2013, P 15 INT C HUM COMP, P99, DOI DOI 10.1145/2493190.2493234
   Grubert Jens, 2012, P 14 INT C HUM COMP, P231, DOI DOI 10.1145/2371574.2371609
   Guo J, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P948, DOI 10.1109/vr.2019.8797972
   Guo J, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P443, DOI [10.1109/VR46266.2020.00-39, 10.1109/VR46266.2020.1581306543750]
   Guo J, 2019, INT SYM MIX AUGMENT, P224, DOI 10.1109/ISMAR.2019.00019
   Hartmann J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300577
   Hindmarsh J, 2007, SOCIOL COMPASS, V1, P156, DOI 10.1111/j.1751-9020.2007.00012.x
   Hirzle T, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3492802
   Hripcsak G, 2005, J AM MED INFORM ASSN, V12, P296, DOI 10.1197/jamia.M1733
   Kang S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376252
   Kim K, 2018, IEEE T VIS COMPUT GR, V24, P2947, DOI 10.1109/TVCG.2018.2868591
   Kim YM, 2020, INT J HUM-COMPUT INT, V36, P893, DOI 10.1080/10447318.2019.1699746
   Lee G, 2022, INT SYM MIX AUGMENT, P787, DOI 10.1109/ISMAR55827.2022.00097
   Li JY, 2021, MULTIMODAL TECHNOLOG, V5, DOI 10.3390/mti5040015
   Lu FY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P768, DOI 10.1109/VR50410.2021.00104
   Mcgill M, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3380959
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   Medeiros D, 2022, IEEE T VIS COMPUT GR, V28, P3640, DOI 10.1109/TVCG.2022.3203002
   Meng XR, 2022, INT SYM MIX AUGMENT, P74, DOI 10.1109/ISMAR55827.2022.00021
   Microsoft, 2023, Hololens 2 - overview, features and specs.
   Ng A, 2021, INT SYM MIX AUGMENT, P265, DOI 10.1109/ISMAR52148.2021.00042
   Nordahl N. C., 2019, 2019 IEEE C VIRT REA, V2
   O'Hagan J, 2020, PERVASIVE DISPLAYS 2020: THE 9TH ACM INTERNATIONAL SYMPOSIUM ON PERVASIVE DISPLAYS, P9, DOI 10.1145/3393712.3395334
   Ofek E., 2020, arXiv
   Pavanatto L, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P759, DOI 10.1109/VR50410.2021.00103
   Pretsch E., 2021, Improvingemployee well-being by means of virtual reality-realex: an empirical casestudy, V2
   Ruvimova A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376724
   Schneider D, 2019, IEEE T VIS COMPUT GR, V25, P3190, DOI 10.1109/TVCG.2019.2932239
   Segura Marquez, 2021, P 2021 CHI C HUM FAC, DOI [10.1145/3411764\n.34455923, DOI 10.1145/3411764]
   Shen RY, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P124, DOI 10.1109/ISMAR-Adjunct.2019.00-65
   Simeone AL, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P1, DOI 10.1109/WEVR.2016.7859535
   Souchet AD, 2023, VIRTUAL REAL-LONDON, V27, P19, DOI 10.1007/s10055-022-00672-0
   Steinicke Frank, 2014, P 2 ACM S SPAT US IN, P66
   Tao YJ, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545682
   Valtchanov D, 2010, CYBERPSYCH BEH SOC N, V13, P503, DOI 10.1089/cyber.2009.0308
   Verma H., 2019, Personal and UbiquitousComputing, P1
   Wang CH, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545686
   Wentzel J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376687
   Whitman LE, 2004, PROCEEDINGS OF THE 2004 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P1740
   Zhou Q, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501884
NR 57
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2796
EP 2806
DI 10.1109/TVCG.2024.3372048
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400040
PM 38437123
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Guarese, R
   Pretty, E
   Renata, A
   Polson, D
   Zambetta, F
AF Guarese, Renan
   Pretty, Emma
   Renata, Aidan
   Polson, Deb
   Zambetta, Fabio
TI Exploring Audio Interfaces for Vertical Guidance in Augmented Reality
   via Hand-Based Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Task analysis; Visualization; Sonification; Navigation; Cataracts;
   Three-dimensional displays; Blindness; Audio interfaces; augmented and
   mixed reality; assistive technologies
ID VIRTUAL-REALITY; BLIND; SYSTEM
AB This research proposes an evaluation of pitch-based sonification methods via user experiments in real-life scenarios, specifically vertical guidance, with the aim of standardizing the use of audio interfaces in AR in guidance tasks. Using literature on assistive technology for people who are blind or visually impaired, we aim to generalize their applicability to a broader population and for different use cases. We propose and test sonification methods for vertical guidance in a series of hand-navigation assessments with users without visual feedback. Including feedback from a visually impaired expert in digital accessibility, results (N=19) outlined that methods that do not rely on memorizing pitch had the most promising accuracy and self-reported workload performances. Ultimately, we argue for audio AR's ability to enhance user performance in different scenarios, from video games to finding objects in a pantry.
C1 [Guarese, Renan; Pretty, Emma; Zambetta, Fabio] RMIT Univ, Sch Comp Technol, Melbourne, Australia.
   [Renata, Aidan] Deakin Univ, Sch Psychol, Geelong, Australia.
   [Polson, Deb] RMIT Univ, Sch Design, Melbourne, Australia.
C3 Royal Melbourne Institute of Technology (RMIT); Deakin University; Royal
   Melbourne Institute of Technology (RMIT)
RP Guarese, R (corresponding author), RMIT Univ, Sch Comp Technol, Melbourne, Australia.
EM renan.guarese@rmit.edu.au; emma.pretty@rmit.edu.au;
   aidan.renata@research.deakin.edu.au; debra.polson@rmit.edu.au;
   fabio.zambetta@rmit.edu.au
RI Guarese, Renan/JEF-6933-2023
OI Renata, Aidan/0009-0001-8593-1757; Polson, Deb/0000-0002-5625-5980;
   Pretty, Emma/0000-0002-5108-5740; Guarese, Renan/0000-0003-1206-5701
FU Australian Technology Network of Universities
FX No Statement Available
CR Ahmetovic D, 2023, INT J HUM-COMPUT ST, V177, DOI 10.1016/j.ijhcs.2023.103057
   Arons Barry, 1992, J. Am. Voice I/O Soc., V12, P35
   Bandara D, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8121014
   Baranski P, 2015, C HUM SYST INTERACT, P173, DOI 10.1109/HSI.2015.7170662
   Barde A., 2020, Journal of the Audio Engineering Society
   Bigham Je.rey P., 2012, P TECHNOLOGY 23ND AN, DOI [10.1145/1866029.1866080, DOI 10.1145/1866029.1866080]
   Binetti N, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102032
   Bourhim E, 2022, LECT NOTE NETW SYST, V418, P277, DOI 10.1007/978-3-030-96308-8_25
   Branham SM, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2373, DOI 10.1145/2702123.2702511
   Bruno F, 2019, OCEAN ENG, V190, DOI 10.1016/j.oceaneng.2019.106487
   Bujacz M., 2008, 2008 Conference on Human System Interactions, P888, DOI 10.1109/HSI.2008.4581561
   Campos P., 2011, Human-Computer Interaction - INTERACT 2011, P584
   Chaudary B, 2023, VIRTUAL REAL-LONDON, V27, P141, DOI 10.1007/s10055-021-00536-z
   Chaudary B, 2017, L N INST COMP SCI SO, V181, P9, DOI 10.1007/978-3-319-49655-9_2
   Coughlan B., An audio-based3d spatial guidance ar system for blind users
   DAVIS FD, 1989, MANAGE SCI, V35, P982, DOI 10.1287/mnsc.35.8.982
   Oliveira VAD, 2017, IEEE T VIS COMPUT GR, V23, P1340, DOI 10.1109/TVCG.2017.2657238
   Delle Monache S, 2022, DESIGN STUD, V83, DOI 10.1016/j.destud.2022.101134
   Dinelli C, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7020136
   Faltaous Sarah, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P254, DOI 10.1145/3428361.3428389
   Fritsche P, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P96, DOI 10.1109/SSRR.2017.8088146
   Fröhler B, 2022, COMPUT GRAPH FORUM, V41, P465, DOI 10.1111/cgf.14447
   Grandi JG, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P127, DOI [10.1109/vr.2019.8798080, 10.1109/VR.2019.8798080]
   Gruenefeld U, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501821
   Gruenefeld U, 2018, AUTOMOTIVEUI'18: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P221, DOI 10.1145/3239060.3239080
   Guarese D., 2023, IN2023IEEE INT S MIX, P1
   Guarese R., 2022, INOZCHI 22 P 34 AUST, V11, DOI [10.1145/3572921.3572929[31]J, DOI 10.1145/3572921.3572929[31]J]
   Guarese R, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P324, DOI 10.1109/VRW58643.2023.00074
   Guarese R, 2023, Symposium Virtual Re, P184, DOI 10.1109/VR55154.2023.00034
   Günther S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P273, DOI 10.1145/3197768.3197785
   Guerreiro J, 2023, IEEE T VIS COMPUT GR, V29, P2763, DOI 10.1109/TVCG.2023.3247094
   Guerreiro J, 2020, INT J HUM-COMPUT ST, V135, DOI 10.1016/j.ijhcs.2019.102369
   HART S G, 1988, P139
   Hermann Thomas, 2011, The sonification handbook
   Holton B., 2015, A review of the be my eyes remote sighted helper app for appleios
   Hu XH, 2022, IEEE T NEUR SYS REH, V30, P1621, DOI 10.1109/TNSRE.2022.3182661
   Huber H.-C., Navi - a proof-of-concept of a mobile navigational aid for visually impaired based on the mi-crosoft kinect
   Jain Y. Teng, Proc. ACM Hum.-Comput. Interact., V7, DOI [10.1145/3579496[39]M.S., DOI 10.1145/3579496[39]M.S]
   Jensen MS, 2011, WIRES COGN SCI, V2, P529, DOI 10.1002/wcs.130
   Kasowski J, 2023, J VISION, V23, DOI 10.1167/jov.23.5.5
   Katz BFG, 2012, VIRTUAL REAL-LONDON, V16, P253, DOI 10.1007/s10055-012-0213-6
   Kaul M., 2016, INPROCEEDINGS 2016 C, P2533
   Keenan RY, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3378576
   Kerdegari Y. Kim, Head-mounted sensory augmen-tation device: Comparing haptic and audio modality
   Kim DH, 2023, INT SYM MIX AUGMENT, P990, DOI 10.1109/ISMAR59233.2023.00115
   Krösl K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P655, DOI [10.1109/VR.2019.8798239, 10.1109/vr.2019.8798239]
   Lee Y, 2021, J COMPUT DES ENG, V8, P756, DOI 10.1093/jcde/qwab012
   Lepora N. F., 2016, Biomimetic and Biohybrid Systems, P107
   Lin JC, 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD014953.pub2
   Liu Y, 2018, ELIFE, V7, DOI 10.7554/eLife.37841
   Liu YC, 2017, LANCET, V390, P600, DOI 10.1016/S0140-6736(17)30544-5
   Löcken A, 2017, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2017), DOI 10.1145/3119881.3119894
   Lovreglio R, 2020, SAFETY SCI, V128, DOI 10.1016/j.ssci.2020.104750
   Maneuvrier A, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.571713
   Marquardt A, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281525
   Marques Bernardo, 2022, MUM '22: Proceedings of the 21st International Conference on Mobile and Ubiquitous Multimedia, P276, DOI 10.1145/3568444.3570587
   Martin D, 2023, IEEE T VIS COMPUT GR, V29, P2446, DOI 10.1109/TVCG.2023.3247102
   Mascetti S, 2016, INT J HUM-COMPUT ST, V85, P16, DOI 10.1016/j.ijhcs.2015.08.003
   May K. R., 2019, P 25 INT C AUD DISPL, DOI DOI 10.21785/ICAD2019.008
   Miesenberger K., 2020, Computers HelpingPeople with Special Needs, P475
   Nair Vishnu, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P538, DOI 10.1145/3472749.3474768
   Nair V, 2022, PROCEEDINGS OF THE 24TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2022, DOI 10.1145/3517428.3544802
   Navolio N, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00231
   Neuhoff R., 2002, P 2002INTERNATIONAL
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Paré S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247448
   Schall MC, 2013, HUM FACTORS, V55, P643, DOI 10.1177/0018720812462029
   Schöne B, 2021, VIRTUAL REAL-LONDON, V25, P209, DOI 10.1007/s10055-020-00450-w
   Schofield A. Dasys, 2010, Journal of EmergencyManagement, V8, P45
   Senan B., 2022, INPROCEEDINGS 17 INT, P187, DOI [10.1145/3561212.3561239[71]B.A., DOI 10.1145/3561212.3561239[71]B.A]
   Smith BA, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174090
   Unertl R. J., 2016, Usability: Making It Realfrom Concepts to Implementation and End-User Adoption, P165, DOI [10.1007/978-3-319-20765-09[73]Y, DOI 10.1007/978-3-319-20765-09[73]Y]
   Wang YW, 2022, INT J HUM-COMPUT INT, V38, P837, DOI 10.1080/10447318.2021.1970434
   Wu RJ, 2023, INT SYM MIX AUGMENT, P1045, DOI 10.1109/ISMAR59233.2023.00121
   Yang J, 2022, J AUDIO ENG SOC, V70, P788, DOI 10.17743/jaes.2022.0048
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
   Zhao Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376516
   Zijlstra A.T., 2017, Masters thesis
NR 78
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2818
EP 2828
DI 10.1109/TVCG.2024.3372040
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400044
PM 38437120
DA 2024-11-06
ER

PT J
AU Samuel, S
   Elvezio, C
   Khan, S
   Bitzer, LZ
   Moss-Salentijn, L
   Feiner, S
AF Samuel, Sara
   Elvezio, Carmine
   Khan, Salaar
   Bitzer, Laureen Zubiaurre
   Moss-Salentijn, Letty
   Feiner, Steven
TI Visuo-Haptic VR and AR Guidance for Dental Nerve Block Education
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Dentistry; Haptic interfaces; Visualization; Three-dimensional displays;
   Training; Teeth; Electronic mail; Virtual reality; visualization
   techniques; mixed reality; augmented reality; health care information
   systems
ID VIRTUAL-REALITY SIMULATOR; AUGMENTED REALITY; LOCAL-ANESTHESIA;
   STUDENTS; SYSTEM
AB The inferior alveolar nerve block (IANB) is a dental anesthetic injection that is critical to the performance of many dental procedures. Dental students typically learn to administer an IANB through videos and practice on silicone molds and, in many dental schools, on other students. This causes significant stress for both the students and their early patients. To reduce discomfort and improve clinical outcomes, we created an anatomically informed virtual reality headset-based educational system for the IANB. It combines a layered 3D anatomical model, dynamic visual guidance for syringe position and orientation, and active force feedback to emulate syringe interaction with tissue. A companion mobile augmented reality application allows students to step through a visualization of the procedure on a phone or tablet. We conducted a user study to determine the advantages of preclinical training with our IANB simulator. We found that in comparison to dental students who were exposed only to traditional supplementary study materials, dental students who used our IANB simulator were more confident administering their first clinical injections, had less need for syringe readjustments, and had greater success in numbing patients.
C1 [Samuel, Sara; Elvezio, Carmine; Feiner, Steven] Columbia Univ, Dept Comp Sci, Columbia, NY 10027 USA.
   [Khan, Salaar; Bitzer, Laureen Zubiaurre; Moss-Salentijn, Letty] Columbia Univ, Coll Dent Med, New York, NY USA.
C3 Columbia University; Columbia University
RP Elvezio, C (corresponding author), Columbia Univ, Dept Comp Sci, Columbia, NY 10027 USA.
EM sas2361@columbia.edu; carmine@cs.columbia.edu;
   srk2143@cumc.columbia.edu; laz1@cumc.columbia.edu;
   lm23@cumc.columbia.edu; feiner@cs.columbia.edu
OI Feiner, Steven/0000-0001-9978-7090; Zubiaurre Bitzer,
   Laureen/0000-0002-1059-4063; Moss-Salentijn, Letty/0009-0003-3716-8915;
   Samuel, Sara/0009-0002-7802-7732
FU Columbia University Provost's Hybrid Learning Course Redesign and
   Delivery
FX No Statement Available
CR 3dsystems, 3D Systems Touch
   Ahmed S, 2021, J FAM MED PRIM CARE, V10, P1633, DOI 10.4103/jfmpc.jfmpc_282_20
   [Anonymous], 2011, EUR J DENT EDUC, V15, P98, DOI 10.1111/j.1600-0579.2010.00646.x
   [Anonymous], US
   [Anonymous], Oculus rift s
   Badiali G, 2014, J CRANIO MAXILL SURG, V42, P1970, DOI 10.1016/j.jcms.2014.09.001
   Ben-Gal G, 2013, EUR J DENT EDUC, V17, P138, DOI 10.1111/eje.12023
   Bruellmann DD, 2013, CLIN ORAL INVEST, V17, P441, DOI 10.1007/s00784-012-0718-0
   Corrêa CG, 2017, J APPL ORAL SCI, V25, P357, DOI 10.1590/1678-7757-2016-0386
   Dechev Nikola, Dental Skull.
   DiMaio SP, 2003, IEEE T ROBOTIC AUTOM, V19, P864, DOI 10.1109/TRA.2003.817044
   Evers H., 2001, Introduction to Dental Local Anaesthesia
   Gottlieb R, 2011, J DENT EDUC, V75, P1443
   Jasinevicius T Roma, 2004, J Dent Educ, V68, P1151
   Kanaa MD, 2006, J ENDODONT, V32, P919, DOI 10.1016/j.joen.2006.04.004
   Khalil Hesham, 2014, Anesth Essays Res, V8, P3, DOI 10.4103/0259-1162.128891
   Lamira JM, 2023, J DENT EDUC, V87, P583, DOI 10.1002/jdd.13151
   LeBlanc Vicki R, 2004, J Dent Educ, V68, P378
   Lee JS, 2015, J DENT EDUC, V79, P1411
   Li YN, 2022, JMIR SERIOUS GAMES, V10, DOI 10.2196/30653
   Li YN, 2021, J MED INTERNET RES, V23, DOI 10.2196/23635
   Malamed SF., 1997, HDB LOCAL ANESTHESIA, V4th
   Meechan Ronnie, 2011, Br J Nurs, V20, P445
   Mladenovic R, 2020, EUR J DENT EDUC, V24, P507, DOI 10.1111/eje.12529
   Mladenovic R, 2019, J DENT EDUC, V83, P423, DOI 10.21815/JDE.019.050
   Nassar HM, 2020, J DENT EDUC, V84, P812, DOI 10.1002/jdd.12138
   Newell Allen, 2013, Cognitive Skills and Their Acquisition, P1
   office, Microsoft excel
   OpenHaptics, ABOUT US
   Plessas A, 2017, SIMUL HEALTHC, V12, P332, DOI 10.1097/SIH.0000000000000250
   PRiSM, Philippine Rice Information System (PRiSM)
   Quinn Frank, 2003, Eur J Dent Educ, V7, P13, DOI 10.1034/j.1600-0579.2003.00264.x
   Ravali Gourishetti, 2017, IEEE Rev Biomed Eng, V10, P63, DOI 10.1109/RBME.2017.2706966
   Ria S, 2018, J DENT EDUC, V82, P277, DOI 10.21815/JDE.018.028
   Ribeiro MAO, 2019, SIGGRAPH '19 - ACM SIGGRAPH 2019 POSTERS, DOI 10.1145/3306214.3338592
   Ribeiro MAO, 2017, SYMP VIRTUAL AUGMENT, P271, DOI 10.1109/SVR.2017.42
   Rodrigues P, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29537-5
   Rodrigues P, 2022, COMPUT METH PROG BIO, V221, DOI 10.1016/j.cmpb.2022.106831
   Rosenberg M, 2009, J DENT EDUC, V73, P127
   Roy E, 2017, SAUDI DENT J, V29, P41, DOI 10.1016/j.sdentj.2017.02.001
   Simon J F, 1994, Quintessence Int, V25, P641
   Steinberg AD, 2007, J DENT EDUC, V71, P1574
   Vuforia, ABOUT US
   Werner B., 2012, MedEdPORTAL.
   Zafar S, 2021, EUR ARCH PAEDIATR DE, V22, P667, DOI 10.1007/s40368-021-00604-7
   Zhu M, 2017, SCI REP-UK, V7, DOI 10.1038/srep42365
NR 46
TC 0
Z9 0
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2839
EP 2848
DI 10.1109/TVCG.2024.3372125
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400069
PM 38498761
DA 2024-11-06
ER

PT J
AU Liang, ZC
   Liu, JH
   Dasari, M
   Wang, FX
AF Liang, Zhicheng
   Liu, Junhua
   Dasari, Mallesham
   Wang, Fangxin
TI Fumos: Neural Compression and Progressive Refinement for Continuous
   Point Cloud Video Streaming
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Streaming media; Point cloud compression; Deep learning; Virtual Reality
   (VR); User Experience
ID ATTRIBUTE COMPRESSION; CHALLENGES
AB Point cloud video (PCV) offers watching experiences in photorealistic 3D scenes with six-degree-of-freedom (6-DoF), enabling a variety of VR and AR applications. The user's Field of View (FoV) is more fickle with 6-DoF movement than 3-DoF movement in 360-degree video. PCV streaming is extremely bandwidth-intensive. However, current streaming systems require hundreds of Mbps bandwidth, exceeding the bandwidth capabilities of commodity devices. To save bandwidth, FoV-adaptive streaming predicts a user's FoV and only downloads point cloud data falling in the predicted FoV. But it is difficult to accurately predict the user's FoV even 2-3 seconds before playback due to 6-DoF. Misprediction of FoV or network bandwidth dips results in frequent stalls. To avoid rebuffering, existing systems would cause incomplete FoV and degraded experience, deteriorating the user's quality of experience (QoE). In this paper, we describe Fumos, a novel system that preserves interactive experience by avoiding playback stalls while maintaining high perceptual quality and high compression rate. We find a research gap in inter-frame redundant utilization and progressive mechaism. Fumos has three crucial designs, including (1) Neural compression framework with inter-frame coding, namely N-PCC, which achieves both bandwidth efficiency and high fidelity. (2) Progressive refinement streaming framework that enables continuous playback by incrementally upgrading a fetched portion to a higher quality (3) System-level adaptation that employs Lyapunov optimization to jointly optimize the long-term user QoE. Experimental results demonstrate that Fumos significantly outperforms Draco, achieving an average decoding rate acceleration of over 260x. Moreover, the proposed compression framework N-PCC attains remarkable BD-Rate gains, averaging 91.7% and 51.7% against the state-of-the-art point cloud compression methods G-PCC and V-PCC, respectively.
C1 [Liang, Zhicheng; Liu, Junhua; Wang, Fangxin] Chinese Univ Hong Kong, Future Network Intelligence Inst, Shenzhen, Peoples R China.
   [Liang, Zhicheng; Liu, Junhua; Wang, Fangxin] Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China.
   [Dasari, Mallesham] Carnegie Mellon Univ, Pittsburgh, PA USA.
   [Wang, Fangxin] Guangdong Prov Key Lab, Future Networks Intelligence, Shenzhen, Peoples R China.
C3 The Chinese University of Hong Kong, Shenzhen; The Chinese University of
   Hong Kong, Shenzhen; Carnegie Mellon University
RP Wang, FX (corresponding author), Chinese Univ Hong Kong, Future Network Intelligence Inst, Shenzhen, Peoples R China.; Wang, FX (corresponding author), Chinese Univ Hong Kong, Sch Sci & Engn, Shenzhen, Peoples R China.; Wang, FX (corresponding author), Guangdong Prov Key Lab, Future Networks Intelligence, Shenzhen, Peoples R China.
EM zhichengliang1@link.cuhk.edu.cn; junhualiu@cuhk.edu.cn;
   m.dasari@northeastern.edu; wangfangxin@cuhk.edu.cn
RI Wang, Fangxin/AGA-6693-2022; L, Ethan/KYQ-6391-2024
OI LIANG, Zhicheng/0009-0008-9015-8907
FU Basic Research
FX No Statement Available
CR [Anonymous], Draco 3d data compression
   [Anonymous], 2021, Geometry based point cloud compression (g-pcc) test model
   Balle J., 2017, INT C LEARN REPR
   Ball‚ J, 2018, Arxiv, DOI arXiv:1802.01436
   Cheng Yihua, 2022, arXiv
   Chopra L, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2379, DOI 10.1145/3442381.3450070
   Choy C, 2019, PROC CVPR IEEE, P3070, DOI 10.1109/CVPR.2019.00319
   de Queiroz RL, 2018, IEEE SIGNAL PROC LET, V25, P739, DOI 10.1109/LSP.2018.2823701
   dEon Eugene, 2017, ISO/IEC JTC1/SC29 Joint WG11/WG1 (MPEG/JPEG) Input Document M38673 7, P11
   Diederik P., 2015, ICLR
   Fu CY, 2022, AAAI CONF ARTIF INTE, P625
   Furht B., 2012, Motion estimation algorithms for video compression, V379
   Gao LY, 2021, IEEE IMAGE PROC, P3373, DOI 10.1109/ICIP42928.2021.9506631
   Garcia DC, 2020, IEEE T IMAGE PROCESS, V29, P313, DOI 10.1109/TIP.2019.2931466
   Garcia DC, 2017, IEEE IMAGE PROC, P1412, DOI 10.1109/ICIP.2017.8296514
   Ghabashneh E, 2023, PROCEEDINGS OF THE 2023 ACM SIGCOMM 2023 CONFERENCE, SIGCOMM 2023, P516, DOI 10.1145/3603269.3604876
   Graham B., 2015, Sparse 3d convolutional neural networks
   Graziosi D, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.12
   Guan Yongjie, 2023, P 29 ANN INT C MOBIL
   Guarda AFR, 2021, IEEE J-STSP, V15, P415, DOI 10.1109/JSTSP.2020.3047520
   Guo CJ, 2018, IEEE COMMUN LETT, V22, P2563, DOI 10.1109/LCOMM.2018.2873005
   Han B, 2020, MOBICOM '20: PROCEEDINGS OF THE 26TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM 2020), P137, DOI 10.1145/3372224.3380888
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hosseini M, 2018, PROCEEDINGS OF THE 23TH ACM WORKSHOP ON PACKET VIDEO (PV'18), P25, DOI 10.1145/3210424.3210429
   Huang LL, 2020, PROC CVPR IEEE, P1310, DOI 10.1109/CVPR42600.2020.00139
   Huang TX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P890, DOI 10.1145/3343031.3351061
   Jin YL, 2023, Arxiv, DOI arXiv:2309.05658
   Lai ZQ, 2020, IEEE T MOBILE COMPUT, V19, P1586, DOI 10.1109/TMC.2019.2913364
   Lee K., 2020, P 26 ANN INT C MOBIL
   Li JW, 2022, IEEE T IND ELECTRON, V69, P13394, DOI 10.1109/TIE.2022.3144590
   Li J, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148922
   Lin Y., 2022, Proc. Mach. Learn. Syst., V4, P302
   Liu JH, 2023, Symposium Virtual Re, P173, DOI [10.1007/978-3-031-31733-0_16, 10.1109/VR55154.2023.00033]
   Liu Y, 2022, PROCEEDINGS OF THE 2022 THE 28TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, ACM MOBICOM 2022, P514, DOI 10.1145/3495243.3517027
   Liu Z, 2021, IEEE NETWORK, V35, P202, DOI 10.1109/MNET.101.2000364
   MacMillan K, 2021, PROCEEDINGS OF THE 2021 ACM INTERNET MEASUREMENT CONFERENCE, IMC 2021, P229, DOI 10.1145/3487552.3487842
   Mei LF, 2020, COMPUT NETW, V182, DOI 10.1016/j.comnet.2020.107515
   Mekuria R., 2016, P 24 ACM INT C MULT, P1222
   Mekuria R, 2017, IEEE T CIRC SYST VID, V27, P828, DOI 10.1109/TCSVT.2016.2543039
   Pang Jiahao, 2022, APCCPA '22: Proceedings of the 1st International Workshop on Advances in Point Cloud Compression, Processing and Analysis, P11, DOI 10.1145/3552457.3555727
   Park J, 2019, IEEE J EM SEL TOP C, V9, P149, DOI 10.1109/JETCAS.2019.2898622
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Que ZZ, 2021, PROC CVPR IEEE, P6038, DOI 10.1109/CVPR46437.2021.00598
   Ren MY, 2018, PROC CVPR IEEE, P8711, DOI 10.1109/CVPR.2018.00908
   Schnabel Ruwen, 2006, PBG@ SIGGRAPH, V3
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sheng XH, 2022, IEEE T IMAGE PROCESS, V31, P3399, DOI 10.1109/TIP.2022.3170722
   Sivaraman V, 2023, Arxiv, DOI arXiv:2209.10507
   Spiteri K, 2020, IEEE ACM T NETWORK, V28, P1698, DOI 10.1109/TNET.2020.2996964
   Subramanyam S, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3669, DOI 10.1145/3394171.3413535
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   van der Hooft J, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2405, DOI 10.1145/3343031.3350917
   Wang JQ, 2021, IEEE T CIRC SYST VID, V31, P4909, DOI 10.1109/TCSVT.2021.3051377
   Wang JQ, 2021, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC50243.2021.00015
   Xu Y., 2018, ZTE Communications, V16, P8
   Xu Y., 2017, P 120 MPEG M, V1, P8
   Xu YQ, 2021, IEEE T CIRC SYST VID, V31, P1968, DOI 10.1109/TCSVT.2020.3015901
   Yili Jin, 2022, 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW), P600, DOI 10.1109/VRW55335.2022.00151
   Ying ZY, 2022, INT SYMP MICROARCH, P282, DOI 10.1109/MICRO56248.2022.00031
   Zhang A, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P137
   Zhang C, 2014, IEEE IMAGE PROC, P2066, DOI 10.1109/ICIP.2014.7025414
   Zink M, 2019, P IEEE, V107, P639, DOI 10.1109/JPROC.2019.2894817
NR 63
TC 1
Z9 1
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2849
EP 2859
DI 10.1109/TVCG.2024.3372096
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OF4H3
UT WOS:001205832400038
PM 38437108
DA 2024-11-06
ER

PT J
AU Weissker, T
   Franzgrote, M
   Kuhlen, T
AF Weissker, Tim
   Franzgrote, Matthis
   Kuhlen, Torsten
TI Try This for Size: Multi-Scale Teleportation in Immersive Virtual
   Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; 3D User Interfaces; 3D Navigation; Head-Mounted
   Display; Multi-Scale
ID NAVIGATION
AB The ability of a user to adjust their own scale while traveling through virtual environments enables them to inspect tiny features being ant-sized and to gain an overview of the surroundings as a giant. While prior work has almost exclusively focused on steering-based interfaces for multi-scale travel, we present three novel teleportation-based techniques that avoid continuous motion flow to reduce the risk of cybersickness. Our approaches build on the extension of known teleportation workflows and suggest specifying scale adjustments either simultaneously with, as a connected second step after, or separately from the user's new horizontal position. The results of a two-part user study with 30 participants indicate that the simultaneous and connected specification paradigms are both suitable candidates for effective and comfortable multi-scale teleportation with nuanced individual benefits. Scale specification as a separate mode, on the other hand, was considered less beneficial. We compare our findings to prior research and publish the executable of our user study to facilitate replication and further analyses.
C1 [Weissker, Tim; Franzgrote, Matthis; Kuhlen, Torsten] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
C3 RWTH Aachen University
RP Weissker, T (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM me@tim-weissker.de; matthis.franzgrote@rwth-aachen.de;
   kuhlen@vr.rwth-aachen.de
RI Kuhlen, Torsten/A-1059-2017
OI Kuhlen, Torsten/0000-0003-2144-4367; Weissker, Tim/0000-0001-9119-811X;
   Franzgrote, Matthis/0009-0002-6632-3841
FU Ministry of Economic Affairs
FX No Statement Available
CR Abtahi P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300752
   Argelaguet F, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P269, DOI 10.1145/2993369.2993391
   Argelaguet F, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P123, DOI 10.1109/3DUI.2014.7027325
   Bacim F, 2009, 3DUI : IEEE SYMPOSIUM ON 3D USER INTERFACES 2009, PROCEEDINGS, P67
   Bhandari Jiwan, 2018, GRAPHICS INTERFACE, P162, DOI [DOI 10.20380/GI2018.22, 10.20380/GI2018, DOI 10.20380/GI2018, 10. 20380/GI2018.22]
   Bimberg P, 2021, PROCEEDINGS OF 27TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, VRST 2021, DOI 10.1145/3489849.3489893
   Bowman DA, 1997, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VRAIS.1997.583043
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Cherep LA, 2020, J EXP PSYCHOL-APPL, V26, P480, DOI 10.1037/xap0000263
   Cho Isaac, 2015, 2015 IEEE Symposium on 3D User Interfaces (3DUI), P133, DOI 10.1109/3DUI.2015.7131738
   Cho I, 2018, IEEE T VIS COMPUT GR, V24, P1331, DOI 10.1109/TVCG.2017.2668405
   Christou CG, 2017, LECT NOTES COMPUT SC, V10325, P431, DOI 10.1007/978-3-319-60928-7_37
   Clifton J, 2020, VIRTUAL REAL-LONDON, V24, P453, DOI 10.1007/s10055-019-00407-8
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   Elvezio C, 2017, P IEEE VIRT REAL ANN, P475, DOI 10.1109/VR.2017.7892386
   Field A., 2013, Discovering statistics using IBM SPSS statistics, V4th ed.
   Funk M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300377
   Habgood MPJ, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P371
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Interrante V, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P167
   Kim Jangyoon, 2017, P 27 INT C ART REAL, P153
   Kopper R, 2006, P IEEE VIRT REAL ANN, P175, DOI 10.1109/VR.2006.47
   Krekhov A, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P243, DOI 10.1145/3242671.3242704
   Kulik A, 2017, PRESENCE-VIRTUAL AUG, V26, P297, DOI [10.1162/PRES_a_00297, 10.1162/pres_a_00297]
   Kunert A., 2014, P 17 ACM C COMPUTER, P1388, DOI [10.1145/2531602.25317274, DOI 10.1145/2531602.25317274]
   Langbehn E, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P211, DOI 10.1109/3DUI.2016.7460054
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LaViola JosephJ., 2001, Proceedings Symposium on Interactive 3D Graphics, P9
   Le Chenechal Morgan, 2016, 2016 IEEE Third VR International Workshop on Collaborative Virtual Environments (3DCVE), P18, DOI 10.1109/3DCVE.2016.7563562
   Lee JI, 2023, Symposium Virtual Re, P680, DOI 10.1109/VR55154.2023.00083
   Lee P., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189612[30]A., DOI 10.1145/3385956.3418961]
   Matviienko A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501983
   McCrae James., 2009, P 2009 S INT 3D GRAP, P7, DOI [10.1145/1507149.1507151, DOI 10.1145/1507149.1507151]
   Moghadam K, 2020, IEEE T VIS COMPUT GR, V26, P2273, DOI 10.1109/TVCG.2018.2884468
   Mori Shohei, 2023, Journal of Information Processing, V31, P392, DOI [10.2197/ipsjjip.31.392, DOI 10.2197/IPSJJIP.31.392]
   Pausch R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P399, DOI 10.1145/218380.218495
   Piumsomboon T, 2018, IEEE T VIS COMPUT GR, V24, P2974, DOI 10.1109/TVCG.2018.2868594
   Prithul A, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.730792
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Sargunam SP, 2018, PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON INTERACTIVE AND SPATIAL COMPUTING (IWISC 18), P74, DOI 10.1145/3191801.3191815
   Badr AS, 2023, FRONT VIRTUAL REAL, V3, DOI 10.3389/frvir.2022.1075811
   Song D., 1994, IEEE Computational Science and Engineering, V1, P53
   Stoakley R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P265
   Valentine JC, 2015, BASIC APPL SOC PSYCH, V37, P260, DOI 10.1080/01973533.2015.1060240
   Ware C., 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P127, DOI 10.1145/253284.253319
   Weissker Tim, 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2524, DOI 10.1109/TVCG.2021.3067756
   Weissker T., 2024, Try This for Size: Multi-Scale Teleportation in Immersive Virtual Reality (User Study Executable), DOI [10.5281/zenodo.105228832, DOI 10.5281/ZENODO.105228832]
   Weissker T., 2024, Try This for Size: Multi-Scale Teleportation in Immersive Virtual Reality (Study Data), DOI [10.5281/zenodo.105228297, DOI 10.5281/ZENODO.105228297]
   Weissker T, 2023, IEEE T VIS COMPUT GR, V29, P2467, DOI 10.1109/TVCG.2023.3247114
   Weissker T, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P363, DOI 10.1109/VRW52623.2021.00073
   Weissker T, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P136, DOI [10.1109/vr.2019.8797807, 10.1109/VR.2019.8797807]
   Weissker T, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P97, DOI 10.1109/VR.2018.8446620
   Xia HJ, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P853, DOI 10.1145/3242587.3242597
   Zhang N., 2020, P 26 ACM S VIRTUAL R, DOI [10.1145/3385956.34189493[49]D, DOI 10.1145/3385956.3418949]
   ZHANG X., 2002, Proceedings of the 4th International Conference on Collaborative Virtual Environments, p, P31, DOI [10.1145/571878.5718841,3, DOI 10.1145/571878.5718841,3]
   Zhang XL, 2005, PRESENCE-TELEOP VIRT, V14, P31, DOI 10.1162/1054746053890288
   Zielasko D, 2022, 2022 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2022), P693, DOI 10.1109/VR51125.2022.00090
NR 58
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2298
EP 2308
DI 10.1109/TVCG.2024.3372043
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200001
PM 38437134
DA 2024-11-06
ER

PT J
AU Tasnim, U
   Islam, R
   Desai, K
   Quarles, J
AF Tasnim, Umama
   Islam, Rifatul
   Desai, Kevin
   Quarles, John
TI Investigating Personalization Techniques for Improved Cybersickness
   Prediction in Virtual Reality Environments
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Cybersickness; Brain modeling; Predictive models; Solid modeling;
   Transfer learning; Data models; Physiology; Cybersickness
   Personalization; Cybersickness Prediction; Transfer Learning; Early
   Shaping; Deep Learning; Machine Learning
ID MOTION SICKNESS
AB In recent cybersickness research, there has been a growing interest in predicting cybersickness using real-time physiological data such as heart rate, galvanic skin response, eye tracking, postural sway, and electroencephalogram. However, the impact of individual factors such as age and gender, which are pivotal in determining cybersickness susceptibility, remains unknown in predictive models. Our research seeks to address this gap, underscoring the necessity for a more personalized approach to cybersickness prediction to ensure a better, more inclusive virtual reality experience. We hypothesize that a personalized cybersickness prediction model would outperform non-personalized models in predicting cybersickness. Evaluating this, we explored four personalization techniques: 1) data grouping, 2) transfer learning, 3) early shaping, and 4) sample weighing using an open-source cybersickness dataset. Our empirical results indicate that personalized models significantly improve prediction accuracy. For instance, with early shaping, the Deep Temporal Convolutional Neural Network (DeepTCN) model achieved a 69.7% reduction in RMSE compared to its non-personalized version. Our study provides evidence of personalization techniques' benefits in improving cybersickness prediction. These findings have implications for developing personalized cybersickness prediction models tailored to individual differences, which can be used to develop personalized cybersickness reduction techniques in the future.
C1 [Tasnim, Umama; Islam, Rifatul] Kennesaw State Univ, Kennesaw, GA 30144 USA.
   [Desai, Kevin; Quarles, John] Univ Texas San Antonio, San Antonio, TX USA.
C3 University System of Georgia; Kennesaw State University; University of
   Texas System; University of Texas at San Antonio (UTSA)
RP Islam, R (corresponding author), Kennesaw State Univ, Kennesaw, GA 30144 USA.
EM utasnim@kennesaw.edu; shovonis09@gmail.com; kevin.desai@utsa.edu;
   john.quarles@utsa.edu
RI Islam, Rifatul/GMW-6443-2022; Desai, Kevin/AAK-2200-2020
OI Islam, Rifatul/0000-0002-4305-9964
FU Intel Corporation
FX No Statement Available
CR Arcioni B, 2019, DISPLAYS, V58, P3, DOI 10.1016/j.displa.2018.07.001
   Arns LL, 2005, P IEEE VIRT REAL ANN, P267
   Bengio Y., 2009, P 26 ANN INT C MACH, P41
   Bockelman P., 2017, HCI INT 2017 POSTERS, P1
   Chang E, 2021, J COMPUT DES ENG, V8, P728, DOI 10.1093/jcde/qwab010
   Chen YT, 2020, NEUROCOMPUTING, V399, P491, DOI 10.1016/j.neucom.2020.03.011
   Cobb SVG, 1999, PRESENCE-TELEOP VIRT, V8, P169, DOI 10.1162/105474699566152
   Ferrari A., 2022, Journal of Reliable Intelligent Environments, P3
   Freiwald JP, 2020, MUC 2020: PROCEEDINGS OF MENSCH UND COMPUTER 2020, P115, DOI 10.1145/3404983.3410022
   Fulvio JM, 2021, ENTERTAIN COMPUT, V38, DOI 10.1016/j.entcom.2021.100423
   Gallagher M, 2018, MULTISENS RES, V31, P645, DOI 10.1163/22134808-20181293
   Garcia-Agundez A., 2019, International Journal of Virtual Reality, V19, P2
   Gavgani AM, 2017, AUTON NEUROSCI-BASIC, V203, P41, DOI 10.1016/j.autneu.2016.12.004
   Golding JF, 1998, BRAIN RES BULL, V47, P507, DOI 10.1016/S0361-9230(98)00091-4
   Islam R, 2022, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR55827.2022.00026
   Islam R, 2021, INT SYM MIX AUGMENT, P31, DOI 10.1109/ISMAR52148.2021.00017
   Islam R, 2021, 2021 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS (VRW 2021), P148, DOI 10.1109/VRW52623.2021.00035
   Islam R, 2020, INT SYM MIX AUGMENT, P400, DOI 10.1109/ISMAR50242.2020.00066
   Reyes-Lagos JJ, 2015, PHYSIOL BEHAV, V149, P255, DOI 10.1016/j.physbeh.2015.05.041
   Jeong D, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P827, DOI [10.1109/vr.2019.8798334, 10.1109/VR.2019.8798334]
   Jin XB, 2020, LECT NOTES ELECTR EN, V582, P631, DOI 10.1007/978-981-15-0474-7_59
   Kelly J. W., 2023, 2023 IEEE C VIRTUAL, P8
   Kennedy R. S., 1993, The international journal of aviation psychology, P2
   Kennedy RS., 1993, INT J AVIAT PSYCHOL, V3, P203, DOI [10.1207/s15327108ijap03033, DOI 10.1207/S15327108IJAP0303_3]
   Keshavarz B, 2022, CURR OPIN NEUROL, V35, P107, DOI 10.1097/WCO.0000000000001018
   Keshavarz B, 2011, HUM FACTORS, V53, P415, DOI 10.1177/0018720811403736
   Kim HK, 2018, APPL ERGON, V69, P66, DOI 10.1016/j.apergo.2017.12.016
   Kim J, 2019, IEEE I CONF COMP VIS, P10579, DOI 10.1109/ICCV.2019.01068
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Klosterhalfen S, 2005, AVIAT SPACE ENVIR MD, V76, P1051
   Kourtesis P., 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P2
   Kundu RK, 2022, INT SYM MIX AUGMENT, P777, DOI 10.1109/ISMAR55827.2022.00096
   LaViola Jr J. J., 2000, ACM Sigchi Bulletin, V32, P2
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lee TM, 2019, IEEE T VIS COMPUT GR, V25, P1919, DOI 10.1109/TVCG.2019.2899186
   Litleskare S, 2021, PHYSIOL BEHAV, V236, DOI 10.1016/j.physbeh.2021.113422
   Luong T, 2022, INT SYM MIX AUGMENT, P307, DOI 10.1109/ISMAR55827.2022.00046
   MacArthur C., 2021, P 2021 CHI C ONHUMAN, P1
   Martin N, 2020, INT SYM MIX AUGMENT, P387, DOI 10.1109/ISMAR50242.2020.00065
   Martingano AJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/36843
   Melo M., 2021, 2021 INT C GRAPHICS, P1
   Monteiro D, 2021, INT SYM MIX AUGMENT, P138, DOI 10.1109/ISMAR52148.2021.00028
   Munafo J, 2017, EXP BRAIN RES, V235, P889, DOI 10.1007/s00221-016-4846-7
   Nam Y, 2022, CYBERPSYCH BEH SOC N, V25, P135, DOI 10.1089/cyber.2021.0167
   Naqvi SAA, 2015, AUSTRALAS PHYS ENG S, V38, P721, DOI 10.1007/s13246-015-0379-9
   Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314
   Petri K., 2020, Amer. J. Biomed. Sci., V12, P107, DOI [10.5099/aj200200107, DOI 10.5099/AJ200200107]
   Pohlmann KMT, 2023, 2023 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES ABSTRACTS AND WORKSHOPS, VRW, P277, DOI 10.1109/VRW58643.2023.00066
   Rebenitsch L., 2014, P 27 ANN ACM S USERI, P1
   Reddy G. R., VIRTUAL AUGMENTED MI
   Rennie J. D., 2003, Computers in Biology and Medicine, P6
   Risi D, 2019, DISPLAYS, V60, P9, DOI 10.1016/j.displa.2019.08.003
   Saleem S., 2021, Pak. J. Stat, V37, P4
   Schneider J., 2020, P 3 INT DAT SCI C ID, P89, DOI DOI 10.1007/978-3-658-32182-6_14
   Siami-Namini S, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1394, DOI 10.1109/ICMLA.2018.00227
   Stanney K. M., 1997, P HUMAN FACTORS ER G, V41, P2
   Stanney K, 2020, INT J HUM-COMPUT INT, V36, P1783, DOI 10.1080/10447318.2020.1828535
   Stanney K, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00004
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Tektas M., 2010, Environ-mental Research, Engineering and Management, V51, P3
   Tian N, 2022, VIRTUAL REAL-LONDON, V26, P1409, DOI 10.1007/s10055-022-00638-2
   Wang YY, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P373, DOI 10.1109/VR50410.2021.00060
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0
NR 64
TC 1
Z9 1
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2368
EP 2378
DI 10.1109/TVCG.2024.3372122
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200004
PM 38437124
DA 2024-11-06
ER

PT J
AU Liao, SQ
   Byrd, V
   Popescu, V
AF Liao, Shuqi
   Byrd, Vetria
   Popescu, Voicu
TI PreVR: Variable-Distance Previews for Higher-Order Disocclusion in VR
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Navigation; Task analysis; Virtual environments;
   Three-dimensional displays; Teleportation; Measurement; Disocclusion;
   visualization; navigation; virtual reality
AB The paper introduces PreVR, a method for allowing the user of a VR application to preview a virtual environment (VE) around any number of corners. This way the user can gain line of sight to any part of the VE, no matter how distant or how heavily occluded it is. PreVR relies on a multiperspective visualization that implements a higher-order disocclusion effect with piecewise linear rays that bend multiple times as needed to reach the visualization target. PreVR was evaluated in a user study ($\mathrm{N}=88$) that investigates four points on the VR interface design continuum defined by the maximum disocclusion order $\delta$. In a first control condition (CC0), $\delta=0$, corresponds to conventional VR exploration with no preview capability. In a second control condition (CC1), $\delta=1$, corresponds to the prior art approach of giving the user a preview around the first corner. In a first experimental condition (EC3), $\delta=3$, so PreVR provided up to third-order disocclusion. In a second experimental condition (ECN), $\delta$ was not capped, so PreVR could provide a disocclusion effect of any order, as needed to reach any location in the VE. Participants searched for a stationary target, for a dynamic target moving on a random continuous trajectory, and for a transient dynamic target that appeared at random locations in the maze and disappeared 5s later. The study quantified VE exploration efficiency with four metrics: viewpoint translation, view direction rotation, number of teleportations, and task completion time. Results show that the previews afforded by PreVR bring a significant VE exploration efficiency advantage. ECN outperforms EC3, CC1, and CC0 for all metrics and all tasks, and EC3 frequently outperforms CC1 and CC0.
C1 [Liao, Shuqi; Byrd, Vetria; Popescu, Voicu] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Liao, SQ (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM liao201@purdue.edu; vlbyrd@purdue.edu; popescu@purdue.edu
RI Liao, Shuqi/KRP-3611-2024
OI Liao, Shuqi/0000-0002-9134-6845
FU National Science Foundation
FX No Statement Available
CR 2023 Electronic Arts Inc, 2023, Need for Speed.
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bimberg P, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P464, DOI [10.1109/VRW50115.2020.0-178, 10.1109/VRW50115.2020.00098]
   Bonferroni C.E., 1935, STUDI ONORE PROFESSO, P13
   Bozgeyikli E, 2016, CHI PLAY 2016: PROCEEDINGS OF THE 2016 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY, P205, DOI 10.1145/2967934.2968105
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Burns M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409107
   Buttussi F, 2021, IEEE T VIS COMPUT GR, V27, P125, DOI 10.1109/TVCG.2019.2928304
   Cohen J., 2013, Statistical power analysis for the behavioral sciences, P6
   Dennison M, 2018, APPL ERGON, V71, P9, DOI 10.1016/j.apergo.2018.03.015
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1095, DOI 10.1109/TVCG.2008.59
   Fernandes AS, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P201, DOI 10.1109/3DUI.2016.7460053
   Fisher RA, 1922, J R STAT SOC, V85, P87, DOI 10.2307/2340521
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Kennedy R. S., 1993, The international journal of aviation psychology, P5
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Langbehn E, 2018, PROCEEDINGS OF THE VIRTUAL REALITY INTERNATIONAL CONFERENCE - LAVAL VIRTUAL (ACM VRIC 2018), DOI 10.1145/3234253.3234291
   Langbehn E, 2017, P IEEE VIRT REAL ANN, P449, DOI 10.1109/VR.2017.7892373
   Liao SQ, 2023, Symposium Virtual Re, P530, DOI 10.1109/VR55154.2023.00068
   Lidal E. M., 2012, P 28 SPRING C COMPUT, P47
   Lin YT, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P255, DOI 10.1145/3126594.3126656
   meta, Quest 2 virtual reality headset
   Mirhosseini S, 2017, P IEEE VIRT REAL ANN, P29, DOI 10.1109/VR.2017.7892228
   Nakatani R, 2012, J ADV COMPUT INTELL, V16, P696, DOI 10.20965/jaciii.2012.p0696
   Popescu V, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618504
   Ragan ED, 2017, IEEE T VIS COMPUT GR, V23, P1880, DOI 10.1109/TVCG.2016.2601607
   Razzaque S, 2005, Redirected walking, P2
   Rietzler M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376821
   Sawilowsky SS, 2009, J MOD APPL STAT METH, V8, P597, DOI 10.22237/jmasm/1257035100
   See ZS, 2018, 2018 3RD DIGITAL HERITAGE INTERNATIONAL CONGRESS (DIGITALHERITAGE) HELD JOINTLY WITH 2018 24TH INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS & MULTIMEDIA (VSMM 2018), P213
   Simeone AL, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P598, DOI [10.1109/VR46266.2020.1581330966612, 10.1109/VR46266.2020.00082]
   Souman JL, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/2043603.2043607
   Stanney KM, 1997, PROCEEDINGS OF THE HUMAN FACTORS AND ERGONOMICS SOCIETY 41ST ANNUAL MEETING, 1997, VOLS 1 AND 2, P1138, DOI 10.1177/107118139704100292
   Suma EA, 2012, IEEE T VIS COMPUT GR, V18, P555, DOI 10.1109/TVCG.2012.47
   Suma EA, 2011, P IEEE VIRT REAL ANN, P159, DOI 10.1109/VR.2011.5759455
   Sun Q, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201294
   Sun Q, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925883
   Unity Software Inc, 2023, Unity Real-Time Development Platform (Version 2021.3.91)
   Wu ML, 2018, LECT NOTES COMPUT SC, V11162, P240, DOI 10.1007/978-3-030-01790-3_15
   Wu ML, 2018, IEEE T VIS COMPUT GR, V24, P3069, DOI 10.1109/TVCG.2017.2778249
   Yu JY, 2004, LECT NOTES COMPUT SC, V3022, P14
   Zollmann Stefanie, 2014, P 26 AUSTR COMP HUM, P194, DOI DOI 10.1145/2686612.2686642
NR 44
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2454
EP 2463
DI 10.1109/TVCG.2024.3372068
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200005
PM 38437137
DA 2024-11-06
ER

PT J
AU Novotny, J
   Laidlaw, DH
AF Novotny, Johannes
   Laidlaw, David H.
TI Evaluating Text Reading Speed in VR Scenes and 3D Particle
   Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Three-dimensional displays; Rendering (computer
   graphics); Task analysis; Two-dimensional displays; Resists; Data
   visualization; Virtual Reality; Scientific Visualization; Text
   Representation; Human-Computer Interaction; Perception
ID IMMERSIVE VIRTUAL-REALITY; LEGIBILITY; DISPLAYS; ACUITY; STATE
AB This work reports how text size and other rendering conditions affect reading speeds in a virtual reality environment and a scientific data analysis application. Displaying text legibly yet space-efficiently is a challenging problem in immersive displays. Effective text displays that enable users to read at their maximum speed must consider the variety of virtual reality (VR) display hardware and possible visual exploration tasks. We investigate how text size and display parameters affect reading speed and legibility in three state-of-the-art VR displays: two head-mounted displays and one CAVE. In our perception experiments, we establish limits where reading speed declines as the text size approaches the so-called critical print sizes (CPS) of individual displays, which can inform the design of uniform reading experiences across different VR systems. We observe an inverse correlation between display resolution and CPS. Yet, even in high-fidelity VR systems, the measured CPS was larger than in comparable physical text displays, highlighting the value of increased VR display resolutions in certain visualization scenarios. Our findings indicate that CPS can be an effective metric for evaluating VR display usability. Additionally, we evaluate the effects of text panel placement, orientation, and occlusion-reducing rendering methods on reading speeds in generic volumetric particle visualizations. Our study provides insights into the trade-off between text representation and legibility in cluttered immersive environments with specific suggestions for visualization designers and highlight areas for further research.
C1 [Novotny, Johannes] VRVis Zentrum Virtual Real & Visualisierung GmbH, Vienna, Austria.
   [Novotny, Johannes; Laidlaw, David H.] Brown Univ, Providence, RI 02912 USA.
C3 Brown University
RP Novotny, J (corresponding author), VRVis Zentrum Virtual Real & Visualisierung GmbH, Vienna, Austria.; Novotny, J (corresponding author), Brown Univ, Providence, RI 02912 USA.
EM jnovotny@vrvis.at; david_laidlaw@brown.edu
OI Laidlaw, David/0000-0002-3411-7376; Novotny,
   Johannes/0000-0001-6442-6172
FU National Science Foundation
FX No Statement Available
CR Bell B., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P101, DOI 10.1145/502348.502363
   Boletsis Costas, 2017, Multimodal Technologies and Interaction, V1, DOI 10.3390/mti1040024
   Borg O, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0129902
   Bowman D. A., 2003, P ACM S VIRT REAL SO, P81, DOI [DOI 10.1145/1008653.1008669, 10.1145/1008653.1008669]
   Büttner A, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P663, DOI [10.1109/VRW50115.2020.00182, 10.1109/VRW50115.2020.00-93]
   Calabrèse A, 2016, INVEST OPHTH VIS SCI, V57, P3836, DOI 10.1167/iovs.16-19580
   Chen J, 2004, P IEEE VIRT REAL ANN, P181, DOI 10.1109/VR.2004.1310072
   Cheung SH, 2008, INVEST OPHTH VIS SCI, V49, P828, DOI 10.1167/iovs.07-0555
   Debernardis S, 2014, IEEE T VIS COMPUT GR, V20, P125, DOI 10.1109/TVCG.2013.86
   Dingler T, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188695
   Dittrich Elisabeth, 2013, Virtual Augmented and Mixed Reality. Designing and Developing Augmented and Virtual Environments. 5th International Conference, VAMR 2013 Held as Part of HCI International 2013. Proceedings: LNCS 7936, P149, DOI 10.1007/978-3-642-39405-8_18
   Dobres J, 2018, APPL ERGON, V70, P240, DOI 10.1016/j.apergo.2018.03.007
   Elliott DB, 2016, OPHTHAL PHYSL OPT, V36, P355, DOI 10.1111/opo.12310
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Gabbard JL, 2006, PRESENCE-TELEOP VIRT, V15, P16, DOI 10.1162/pres.2006.15.1.16
   Gabbard JL, 2007, IEEE VIRTUAL REALITY 2007, PROCEEDINGS, P35
   Garcia-Hernandez R. J., 2016, PROCAEROCONF, P1
   Grout Cameron., 2015, P 15 NZ C HUMAN COMP, P9, DOI DOI 10.1145/2808047.2808055
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Hartmann K., 2005, Journal of the WSCG, V13, P1
   Hoffman DM, 2008, J VISION, V8, DOI 10.1167/8.3.33
   Iyer J, 2017, WEB3D 2017, DOI 10.1145/3055624.3075958
   Jankowski J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1321
   Kenyon A, 2014, 2014 IEEE VIRTUAL REALITY (VR), P89, DOI 10.1109/VR.2014.6802065
   Kilpelaeinen M, 2023, FRONT VIRTUAL REAL, V4, DOI 10.3389/frvir.2023.1243387
   Laha B, 2014, IEEE T VIS COMPUT GR, V20, P513, DOI 10.1109/TVCG.2014.20
   Lambooij M, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.030201
   Lee H, 2023, VIRTUAL REAL-LONDON, V27, P829, DOI 10.1007/s10055-022-00693-9
   Manghisi VM, 2017, PRESENCE-TELEOP VIRT, V26, P1, DOI 10.1162/PRES_a_00285
   Mayr S, 2017, DISPLAYS, V48, P41, DOI 10.1016/j.displa.2017.03.002
   MILLS CB, 1987, COMPUT SURV, V19, P329, DOI 10.1145/45075.46162
   Moran A, 2015, IEEE HIGH PERF EXTR
   Novotny J, 2019, IEEE T VIS COMPUT GR, V25, P2145, DOI 10.1109/TVCG.2019.2898796
   Oeltze-Jafra Steffen, 2014, P 4 EUR WORKSH VIS C, P199, DOI DOI 10.2312/VCBM.20141192
   Olshannikova E., 2015, J BIG DATA-GER, V2, P22
   Orlosky J, 2014, MOB COMPUT COMMUN RE, V18, P20, DOI 10.1145/2636242.2636246
   Polys N.F., 2005, Proceedings of ACM Symposium on Virtual Reality Software and Technology (VRST), P46
   Radner W, 2014, GRAEF ARCH CLIN EXP, V252, P1297, DOI 10.1007/s00417-014-2646-y
   Rzayev R., 2021, PROCCHI, P1
   Sadana R, 2017, COMPANION PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ISS 2016), P41, DOI 10.1145/3009939.3009946
   Shibata T, 2011, J VISION, V11, DOI 10.1167/11.8.11
   Silva JNA, 2018, JACC-BASIC TRANSL SC, V3, P420, DOI 10.1016/j.jacbts.2017.11.009
   Wagner JA, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P483, DOI 10.1109/VR.2018.8447558
   Wei CX, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P721, DOI [10.1109/VR46266.2020.000-9, 10.1109/VR46266.2020.1581590322523]
   Williams DR, 2001, CUSTOMIZED CORNEAL ABLATION, P11
   yougowords, You go words - word finder
   Zhao JY, 2019, GEO-SPAT INF SCI, V22, P237, DOI 10.1080/10095020.2019.1621544
NR 47
TC 0
Z9 0
U1 3
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2602
EP 2612
DI 10.1109/TVCG.2024.3372093
PG 11
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200002
PM 38437104
DA 2024-11-06
ER

PT J
AU Bernal-Berdun, E
   Vallejo, M
   Sun, Q
   Serrano, A
   Gutierrez, D
AF Bernal-Berdun, Edurne
   Vallejo, Mateo
   Sun, Qi
   Serrano, Ana
   Gutierrez, Diego
TI Modeling the Impact of Head-Body Rotations on Audio-Visual Spatial
   Perception for Virtual Reality Applications
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Virtual Reality; Audio-Visual Spatial Perception
ID SPACE; LOCALIZATION; COMPRESSION; THRESHOLDS
AB Humans perceive the world by integrating multimodal sensory feedback, including visual and auditory stimuli, which holds true in virtual reality (VR) environments. Proper synchronization of these stimuli is crucial for perceiving a coherent and immersive VR experience. In this work, we focus on the interplay between audio and vision during localization tasks involving natural head-body rotations. We explore the impact of audio-visual offsets and rotation velocities on users' directional localization acuity for various viewing modes. Using psychometric functions, we model perceptual disparities between visual and auditory cues and determine offset detection thresholds. Our findings reveal that target localization accuracy is affected by perceptual audio-visual disparities during head-body rotations, but remains consistent in the absence of stimuli-head relative motion. We then showcase the effectiveness of our approach in predicting and enhancing users' localization accuracy within realistic VR gaming applications. To provide additional support for our findings, we implement a natural VR game wherein we apply a compensatory audio-visual offset derived from our measured psychometric functions. As a result, we demonstrate a substantial improvement of up to 40% in participants' target localization accuracy. We additionally provide guidelines for content creation to ensure coherent and seamless VR experiences.
C1 [Bernal-Berdun, Edurne; Vallejo, Mateo; Serrano, Ana; Gutierrez, Diego] Univ Zaragoza, I3A, Zaragoza, Spain.
   [Sun, Qi] NYU, New York, NY USA.
C3 University of Zaragoza; New York University
RP Bernal-Berdun, E (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM edurnebernal@unizar.es; mvallejo@unizar.es; qisun@nyu.edu;
   anase@unizar.es; diegog@unizar.es
RI ; Serrano Pacheu, Ana Belen/ABC-3358-2021
OI Sun, Qi/0000-0002-3094-5844; Bernal-Berdun, Edurne/0000-0002-5275-8652;
   Vallejo Dominguez, Mateo/0009-0008-8365-2405; Serrano Pacheu, Ana
   Belen/0000-0002-7796-3177
FU European Union's Horizon 2020 research and innovation program
FX No Statement Available
CR ARNOULT MD, 1950, AM J PSYCHOL, V63, P229, DOI 10.2307/1418926
   Berger CC, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00021
   Berghi D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P667, DOI [10.1109/VRW50115.2020.00-91, 10.1109/VRW50115.2020.00184]
   CARPENTER RHS, 1988, MOVEMENTS EYES, V2
   Chen LH, 2013, ATTEN PERCEPT PSYCHO, V75, P790, DOI 10.3758/s13414-013-0475-4
   Chenechal M. L., 2018, INT C ARTIFICIAL REA
   Dufour A, 2007, NEUROPSYCHOLOGIA, V45, P447, DOI 10.1016/j.neuropsychologia.2006.05.027
   Duinkharjav B, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555473
   Erdfelder E, 1996, BEHAV RES METH INS C, V28, P1, DOI 10.3758/BF03203630
   Freeman TCA, 2017, J EXP PSYCHOL HUMAN, V43, P371, DOI 10.1037/xhp0000321
   Fukusima SS, 1997, J EXP PSYCHOL HUMAN, V23, P86, DOI 10.1037/0096-1523.23.1.86
   Gao PZ, 2020, INT SYM MIX AUGMENT, P639, DOI 10.1109/ISMAR50242.2020.00092
   Genzel D, 2018, P NATL ACAD SCI USA, V115, P4264, DOI 10.1073/pnas.1712058115
   Grantham DW, 2003, J ACOUST SOC AM, V114, P1009, DOI 10.1121/1.1590970
   Hu ZM, 2023, IEEE T VIS COMPUT GR, V29, P1992, DOI 10.1109/TVCG.2021.3138902
   Huang HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290605.3300851, 10.1109/TAFFC.2019.2901456]
   Iachini T, 2012, APPL COGNITIVE PSYCH, V26, P757, DOI 10.1002/acp.2856
   Kim E, 2021, ERGONOMICS, V64, P891, DOI 10.1080/00140139.2020.1869320
   Kim H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P120, DOI 10.1109/VR.2019.8798247
   Kim H, 2022, IEEE T VIS COMPUT GR, V28, P2080, DOI 10.1109/TVCG.2022.3150514
   Krajancich B, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459784
   Kytö M, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P49, DOI 10.1109/ISMAR.2015.18
   Larsson P, 2010, HUM-COMPUT INT-SPRIN, P143, DOI 10.1007/978-1-84882-733-2_8
   LESTER G, 1969, ACTA PSYCHOL, V31, P375, DOI 10.1016/0001-6918(69)90094-8
   Leung J, 2008, P NATL ACAD SCI USA, V105, P6492, DOI 10.1073/pnas.0710837105
   Lewald J, 2001, EUR J NEUROSCI, V13, P2268, DOI 10.1046/j.0953-816x.2001.01608.x
   Melo M, 2022, IEEE T VIS COMPUT GR, V28, P1428, DOI 10.1109/TVCG.2020.3010088
   Narbutt M., 2017, INT C VIRTUAL SYSTEM, P1
   Nidiffer AR, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32673-y
   Odegaard B, 2017, PEERJ, V5, DOI 10.7717/peerj.3143
   PERROTT DR, 1990, J ACOUST SOC AM, V87, P1728, DOI 10.1121/1.399421
   POSNER MI, 1976, PSYCHOL REV, V83, P157, DOI 10.1037/0033-295X.83.2.157
   Potter T, 2022, FRONT SIGNAL PROC-SW, V2, DOI 10.3389/frsip.2022.904866
   Poupyrev I., 1998, Computer Graphics Forum, V17, pC41, DOI 10.1111/1467-8659.00252
   Prinz J., 2006, Contemp. Debates Cogn. Sci., V14, P22
   Ross J, 1997, NATURE, V386, P598, DOI 10.1038/386598a0
   Schutt HH, 2016, VISION RES, V122, P105, DOI 10.1016/j.visres.2016.02.002
   Seitz AR, 2006, CURR BIOL, V16, P1422, DOI 10.1016/j.cub.2006.05.048
   Serrano A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417773
   Shams L, 2008, TRENDS COGN SCI, V12, P411, DOI 10.1016/j.tics.2008.07.006
   Shams L, 2010, PHYS LIFE REV, V7, P269, DOI 10.1016/j.plrev.2010.04.006
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Sosa Y, 2010, BRAIN COGNITION, V73, P229, DOI 10.1016/j.bandc.2010.05.007
   Stenzel H, 2018, 2018 AES INTERNATIONAL CONFERENCE ON AUDIO FOR VIRTUAL AND AUGMENTED REALITY
   THURLOW WR, 1970, AM J PSYCHOL, V83, P112, DOI 10.2307/1420861
   Van Barneveld DCPBM, 2010, EUR J NEUROSCI, V31, P920, DOI 10.1111/j.1460-9568.2010.07113.x
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Wexler M, 2005, TRENDS COGN SCI, V9, P431, DOI 10.1016/j.tics.2005.06.018
   Yoonessi A, 2011, J VISION, V11, DOI 10.1167/11.9.13
   Zhang J, 2018, IEEE T VIS COMPUT GR, V24, P1671, DOI 10.1109/TVCG.2018.2793679
NR 50
TC 2
Z9 2
U1 12
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2624
EP 2632
DI 10.1109/TVCG.2024.3372112
PG 9
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200006
PM 38446650
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Krüger, M
   Gerrits, T
   Römer, T
   Kuhlen, T
   Weissker, T
AF Krueger, Marcel
   Gerrits, Tim
   Roemer, Timon
   Kuhlen, Torsten
   Weissker, Tim
TI IntenSelect plus : Enhancing Score-Based Selection in Virtual Reality
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Three-dimensional displays; Task analysis; Usability;
   Virtual environments; Shape; Engines; Virtual Reality; 3D User
   Interfaces; 3D Interaction; Selection; Score-Based Selection; Temporal
   Selection; IntenSelect
ID OBJECT SELECTION
AB Object selection in virtual environments is one of the most common and recurring interaction tasks. Therefore, the used technique can critically influence a system's overall efficiency and usability. IntenSelect is a scoring-based selection-by-volume technique that was shown to offer improved selection performance over conventional raycasting in virtual reality. This initial method, however, is most pronounced for small spherical objects that converge to a point-like appearance only, is challenging to parameterize, and has inherent limitations in terms of flexibility. We present an enhanced version of IntenSelect called IntenSelect+ designed to overcome multiple shortcomings of the original IntenSelect approach. In an empirical within-subjects user study with 42 participants, we compared IntenSelect+ to IntenSelect and conventional raycasting on various complex object configurations motivated by prior work. In addition to replicating the previously shown benefits of IntenSelect over raycasting, our results demonstrate significant advantages of IntenSelect+ over IntenSelect regarding selection performance, task load, and user experience. We, therefore, conclude that IntenSelect+ is a promising enhancement of the original approach that enables faster, more precise, and more comfortable object selection in immersive virtual environments.
C1 [Krueger, Marcel; Gerrits, Tim; Roemer, Timon; Kuhlen, Torsten; Weissker, Tim] Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
C3 RWTH Aachen University
RP Krüger, M (corresponding author), Rhein Westfal TH Aachen, Visual Comp Inst, Aachen, Germany.
EM krueger@vis.rwth-aachen.de; gerrits@vr.rwth-aachen.de;
   t.roemer@vr.rwth-aachen.de; kuhlen@vr.rwth-aachen.de; me@tim-weissker.de
RI ; Kuhlen, Torsten/A-1059-2017
OI Kruger, Marcel/0000-0002-0085-268X; Weissker, Tim/0000-0001-9119-811X;
   Kuhlen, Torsten/0000-0003-2144-4367
FU German Federal Ministry of Education and Research
FX No Statement Available
CR Argelaguet F, 2008, LECT NOTES COMPUT SC, V5166, P45, DOI 10.1007/978-3-540-85412-8_5
   Argelaguet F, 2013, COMPUT GRAPH-UK, V37, P121, DOI 10.1016/j.cag.2012.12.003
   Argelaguet F, 2009, IEEE COMPUT GRAPH, V29, P34, DOI 10.1109/MCG.2009.117
   Argelaguet Ferran, 2008, P 2008 ACM S VIRT RE, P43, DOI DOI 10.1145/1450579.1450588
   Belgardt M., 2023, RWTH VR Group Unreal Engine Toolkit, DOI [10.5281/zenodo.102457472, DOI 10.5281/ZENODO.102457472]
   Besancon L., 2021, Computer Graphics Forum, V40, P2
   Bowman D., 2001, USING PINCH GLOVES T
   Bowman D. A., 1999, VRST'99. Proceedings of the ACM Symposium on Virtual Reality Software and Technology, P26, DOI 10.1145/323663.323667
   Bowman DA, 2001, PRESENCE-TELEOP VIRT, V10, P96, DOI 10.1162/105474601750182342
   Cohen J., 1998, Statistical power analysis for the behavioral sciences
   de Haan G., 2005, EUROGRAPHICS S VIRTU, DOI [10.2312/EGVE/IPT_EGVE2005/201-2091,2,3, DOI 10.2312/EGVE/IPT_EGVE2005/201-2091,2,3]
   de Haan G., 2006, EUROGRAPHICS S VIRTU, P109
   Ericson C., 2004, Real-time Collision Detection., P4
   Field A., 2013, Discovering statistics using IBM SPSS statistics, V4th ed.
   Forsberg Andrew, 1996, P 9 ANN ACM S US INT, P95, DOI DOI 10.1145/237091.237105
   Grossman Tovi, 2006, P 19 ANN ACM S US IN, P3, DOI [10.1145/1166253.1166257, DOI 10.1145/1166253.1166257]
   Han D., 2022, P VRST 2022, P1
   HART S G, 1988, P139
   Hart S. G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]
   Huang S., 2019, Virtual Reality & Intelligent Hardware, V1, P251
   Kim W, 2022, VIRTUAL REAL-LONDON, V26, P1573, DOI 10.1007/s10055-022-00649-z
   Kopper R., 2011, Proceedings 2011 IEEE Symposium on 3D User Interfaces (3DUI 2011), P67, DOI 10.1109/3DUI.2011.5759219
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   LaViola Jr J. J., 2017, 3D user interfaces: theory and practice
   Li HY, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-1517-3
   LIANG JD, 1994, COMPUT GRAPH, V18, P499, DOI 10.1016/0097-8493(94)90062-0
   Lu YQ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P35, DOI [10.1109/VR46266.2020.1581165829725, 10.1109/VR46266.2020.00-83]
   Mine M. R., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P19, DOI 10.1145/258734.258747
   Mine M.R., 1995, Virtual environment interaction techniques
   Moore AG, 2018, INT J HUM-COMPUT ST, V120, P36, DOI 10.1016/j.ijhcs.2018.07.003
   Ortega M, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P119, DOI 10.1109/3DUI.2013.6550208
   Pavlovych Andriy., 2012, P GRAPHICS INTERFACE, P109
   Poupyrev I, 1999, J VISUAL LANG COMPUT, V10, P19, DOI 10.1006/jvlc.1998.0112
   Rebenitsch L., 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology, P309, DOI [DOI 10.1145/2642918.2647394, 10.1145/2642918.2647394]
   Schrepp Martin, 2014, DESIGN USER EXPERIEN, P383, DOI [DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337, DOI 10.1007/978-3-319-07668-3_37]
   Steed A, 2006, IEEE SYMPOSIUM ON 3D USER INTERFACES 2006, PROCEEDINGS, P103, DOI 10.1109/TRIDUI.2006.1618279
   Steinicke F, 2006, COMPUT IMAGING VIS, V32, P320, DOI 10.1007/1-4020-4179-9_46
   Vanacken L, 2007, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2007, PROCEEDINGS, P115
   Wang YH, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.607165
   Weise Matthias, 2020, i-com: Journal of Interactive Media, V19, P67, DOI 10.1515/icom-2020-0011
   Weller R, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.684677
   Wolf D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376876
   Wyss HP, 2006, IEEE Symposium on 3D User Interfaces 2006, Proceedings, P59, DOI 10.1109/TRIDUI.2006.1618271
   Xu WG, 2022, INT SYM MIX AUGMENT, P131, DOI 10.1109/ISMAR55827.2022.00027
   Yu DF, 2020, IEEE T VIS COMPUT GR, V26, P3402, DOI [10.1109/TVCG.2020.3023606, 10.1109/TCVG.2020.3023606]
   Zhao L., 2024, IEEE Transactions on Visualization and Computer Graphics
NR 46
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD MAY
PY 2024
VL 30
IS 5
BP 2829
EP 2838
DI 10.1109/TVCG.2024.3372077
PG 10
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OT7U2
UT WOS:001209605200003
PM 38437105
DA 2024-11-06
ER

PT J
AU Zhang, W
   Kam-Kwai, W
   Chen, YT
   Jia, AL
   Wang, LW
   Zhang, JW
   Cheng, LC
   Qu, HM
   Chen, W
AF Zhang, Wei
   Kam-Kwai, Wong
   Chen, Yitian
   Jia, Ailing
   Wang, Luwei
   Zhang, Jian-Wei
   Cheng, Lechao
   Qu, Huamin
   Chen, Wei
TI ScrollTimes: Tracing the Provenance of Paintings as a Window Into
   History
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; digital humanities; painting analysis; traditional
   chinese painting
AB The study of cultural artifact provenance, tracing ownership and preservation, holds significant importance in archaeology and art history. Modern technology has advanced this field, yet challenges persist, including recognizing evidence from diverse sources, integrating sociocultural context, and enhancing interactive automation for comprehensive provenance analysis. In collaboration with art historians, we examined the handscroll, a traditional Chinese painting form that provides a rich source of historical data and a unique opportunity to explore history through cultural artifacts. We present a three-tiered methodology encompassing artifact, contextual, and provenance levels, designed to create a "Biography" for handscroll. Our approach incorporates the application of image processing techniques and language models to extract, validate, and augment elements within handscroll using various cultural heritage databases. To facilitate efficient analysis of non-contiguous extracted elements, we have developed a distinctive layout. Additionally, we introduce ScrollTimes, a visual analysis system tailored to support the three-tiered analysis of handscroll, allowing art historians to interactively create biographies tailored to their interests. Validated through case studies and expert interviews, our approach offers a window into history, fostering a holistic understanding of handscroll provenance and historical significance.
C1 [Zhang, Wei; Chen, Yitian; Jia, Ailing; Wang, Luwei; Zhang, Jian-Wei; Cheng, Lechao; Chen, Wei] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Kam-Kwai, Wong; Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong 999077, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310027, Peoples R China.
C3 Zhejiang University; Hong Kong University of Science & Technology;
   Zhejiang University
RP Chen, W (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM zw_yixian@zju.edu.cn; kkwongar@connect.ust.hk; oscarchen@zju.edu.cn;
   jiaailing@zju.edu.cn; ppwlwpp@zju.edu.cn; zjw.cs@zju.edu.cn;
   liygcheng@zju.edu.cn; huamin@cse.ust.hk; chenvis@zju.edu.cn
RI Wang, Luwei/HHZ-6184-2022; Chen, Wei/AAR-9817-2020
OI chen, yi tian/0009-0000-0590-594X; WONG, Kam Kwai/0000-0002-2813-1972;
   Zhang, Jianwei/0000-0001-8358-6278; Chen, Wei/0000-0002-8365-4741;
   Cheng, Lechao/0000-0002-7546-9052
FU Fundamental Research Funds for the Central Universities
FX No Statement Available
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Beijing Erudition Digital Technology Research Center,, About us
   Benard Elisabeth., 2000, GODDESSES WHO RULE
   Boutsi AM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11212508
   Burke Peter., 2001, Eyewitnessing: The Uses of Images as Historical Evidence
   Chen LC, 2017, Arxiv, DOI arXiv:1706.05587
   Cheng F., 1994, Empty and Full: The Language of Chinese Painting
   Cheng M., 2018, Essential Terms of Chinese Painting, Kowloon Tong
   Chung Hae-Kyung, 2016, Journal of Ethnic Foods, V3, P42
   Damova M, 2011, ADV INTEL SOFT COMPU, V101, P17
   David L, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9659547
   Davis E, 2021, ACM J COMPUT CULT HE, V14, DOI 10.1145/3429458
   Davis K, 2019, Art Libraries Journal, V44, P162, DOI DOI 10.1017/ALJ.2019.24
   dila, Place Authority Database (PlaAD)
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Dragoni M, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3012289
   Dragoni M, 2016, LECT NOTES COMPUT SC, V9678, P724, DOI 10.1007/978-3-319-34129-3_44
   Fan ZB, 2019, LEONARDO, V52, P111, DOI [10.1162/LEON_a_01409, 10.1162/leon_a_01409]
   Feigenbaum Gail., 2012, PROVENANCE ALTERNATE
   Feng Y, 2024, INT J ENVIRON HEAL R, V34, P2333, DOI [10.1109/TVCG.2023.3240003, 10.1080/09603123.2023.2246383]
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P295, DOI 10.1109/TVCG.2023.3327168
   Feng YCJ, 2022, J VISUAL-JAPAN, V25, P671, DOI 10.1007/s12650-021-00780-0
   Fong WC, 2003, ART BULL, V85, P258, DOI 10.2307/3177344
   García-Zarza P, 2022, LECT NOTES COMPUT SC, V13450, P441, DOI 10.1007/978-3-031-16290-9_34
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Guo Y, 2022, IEEE T VIS COMPUT GR, V28, P5091, DOI 10.1109/TVCG.2021.3100413
   Guo Z., 2020, ADV NEURAL INF PROCE, V33, P21271
   Haskell F., 1993, Hist. and its Images: Art and the Interpretation of the Past, DOI [10.5860/choice.31-1330, DOI 10.5860/CHOICE.31-1330]
   He H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091015
   He JB, 2024, IEEE T VIS COMPUT GR, V30, P87, DOI 10.1109/TVCG.2023.3326586
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh CK, 2013, IEEE COMPUT GRAPH, V33, P16, DOI 10.1109/MCG.2013.50
   Hung CC, 2018, ELECTRON LIBR, V36, P172, DOI 10.1108/EL-10-2016-0219
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jiang W, 2021, COGN COMPUT, V13, P1287, DOI 10.1007/s12559-021-09896-9
   Jiang W, 2019, NEUROCOMPUTING, V330, P280, DOI 10.1016/j.neucom.2018.11.003
   Jin S, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382934
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Krystalakos O, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3201011
   Kusnick J., 2021, Report on narrative visualization techniques for opdb data
   Lan XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445344
   Lengyel A., 2000, China Rev. Int., V7, P260, DOI DOI 10.1353/CRI.2000.0035
   Li JC, 2024, IEEE T VIS COMPUT GR, V30, P3022, DOI 10.1109/TVCG.2024.3388525
   Li M, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2021.12.006
   Lin YT, 2021, IEEE T VIS COMPUT GR, V27, P849, DOI 10.1109/TVCG.2020.3030370
   Liong ST, 2020, COMPUT INTELL-US, V36, P1183, DOI 10.1111/coin.12328
   Liu C, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC), P641, DOI 10.1109/ICSPCC.2014.6986272
   mappingpaintings, About us
   Mayr E, 2022, 2022 IEEE 7TH WORKSHOP ON VISUALIZATION FOR THE DIGITAL HUMANITIES (VIS4DH), P13, DOI 10.1109/VIS4DH57440.2022.00008
   Mohammad SM, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1225
   N. P. Museum, National palace museum open data
   Newman GE, 2011, J CONSUM RES, V38, P215, DOI 10.1086/658999
   Nishanbaev I, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10100684
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Person Authority Database (PerAD), About us
   Rodriguez-Gonzálvez P, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8020061
   Rodriguez-Gonzálvez P, 2017, INT ARCH PHOTOGRAMM, V42-2, P609, DOI 10.5194/isprs-archives-XLII-2-W3-609-2017
   Roth Kathe., 2002, Japan Encyclopedia
   Rowland D., 1997, The Intellectual Background of the Sch. of Athens: Tracking Divine Wisdom in the Rome of Julius II
   Ruiz-Calleja A, 2023, SEMANT WEB, V14, P181, DOI 10.3233/SW-212907
   sammlung, About us
   Shirato G, 2023, VIS INFORM, V7, P77, DOI 10.1016/j.visinf.2023.01.001
   Siren Osvald., 1963, CHINESE ART PAINTING, VSB57
   Tadalafil, ABOUT US
   Tang F, 2018, IEEE T VIS COMPUT GR, V24, P3019, DOI 10.1109/TVCG.2017.2774292
   Tang T., P 36 ANN ACM S US IN
   Tong W, 2023, Symposium Virtual Re, P387, DOI 10.1109/VR55154.2023.00054
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Wang R, 2021, INT C PATT RECOG, P3077, DOI 10.1109/ICPR48806.2021.9413063
   Wang XY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1800
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Wong KK, 2024, IEEE T VIS COMPUT GR, V30, P4008, DOI 10.1109/TVCG.2023.3245609
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Ye Shuainan, 2023, IEEE Trans Vis Comput Graph, V29, P429, DOI 10.1109/TVCG.2022.3209388
   Zhang FQ, 2020, IEEE ACCESS, V8, P132002, DOI 10.1109/ACCESS.2020.3009470
   Zhang KJ, 2022, FRONT INFORM TECH EL, V23, P1479, DOI 10.1631/FITEE.2100094
   Zhang W, 2023, Arxiv, DOI arXiv:2307.14227
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhang W, 2023, IEEE T VIS COMPUT GR, V29, P3009, DOI 10.1109/TVCG.2022.3146508
   Zhenhao Dong, 2020, 2020 International Conference on Culture-oriented Science & Technology (ICCST), P383, DOI 10.1109/ICCST50977.2020.00080
   zjlib, Chinese Historical Figures Seal Data (CHFSD)
NR 82
TC 0
Z9 0
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2981
EP 2994
DI 10.1109/TVCG.2024.3388523
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500015
PM 38625782
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Bearfield, CX
   van Weelden, L
   Waytz, A
   Franconeri, S
AF Bearfield, Cindy Xiong
   van Weelden, Lisanne
   Waytz, Adam
   Franconeri, Steven
TI Same Data, Diverging Perspectives: The Power of Visualizations to Elicit
   Competing Interpretations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Annotations; Market research; Bars;
   Image color analysis; Data mining; Affordances; annotations; bar chart;
   decisions; line chart; predictions; table; visual saliency;
   visualization design
ID SALIENCE; BAR
AB People routinely rely on data to make decisions, but the process can be riddled with biases. We show that patterns in data might be noticed first or more strongly, depending on how the data is visually represented or what the viewer finds salient. We also demonstrate that viewer interpretation of data is similar to that of 'ambiguous figures' such that two people looking at the same data can come to different decisions. In our studies, participants read visualizations depicting competitions between two entities, where one has a historical lead (A) but the other has been gaining momentum (B) and predicted a winner, across two chart types and three annotation approaches. They either saw the historical lead as salient and predicted that A would win, or saw the increasing momentum as salient and predicted B to win. These results suggest that decisions can be influenced by both how data are presented and what patterns people find visually salient.
C1 [Bearfield, Cindy Xiong] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [van Weelden, Lisanne] Univ Utrecht, NL-3584 Utrecht, Netherlands.
   [Waytz, Adam] Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
   [Franconeri, Steven] Northwestern Univ, Evanston, IL 60208 USA.
C3 University System of Georgia; Georgia Institute of Technology; Utrecht
   University; Northwestern University; Northwestern University
RP Bearfield, CX (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM cxiong@gatech.edu
RI Waytz, Adam/KCX-9453-2024
OI Xiong Bearfield, Cindy/0000-0002-1451-4083; Franconeri,
   Steven/0000-0001-5244-9764
FU NSF
FX No Statement Available
CR Ajani K, 2022, IEEE T VIS COMPUT GR, V28, P3351, DOI 10.1109/TVCG.2021.3068337
   Albers D., 2014, Journal of Vision, V14, DOI [10.1167/14.10.1056, DOI 10.1167/14.10.1056]
   Alves T, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P201, DOI 10.1109/VIS47514.2020.00047
   Andrews R., 2019, Info We Trust: How to Inspire the World With Data
   [Anonymous], 2014, Qualtrics [software]
   ATTNEAVE F, 1971, SCI AM, V225, P62, DOI 10.1038/scientificamerican1271-62
   Barocas S, 2017, COMMUN ACM, V60, P23, DOI 10.1145/3144172
   Bearfield CX, 2024, IEEE T VIS COMPUT GR, V30, P5097, DOI 10.1109/TVCG.2023.3289292
   Black Edwin, 2012, IBM and the Holocaust: the Strategic Alliance Between Nazi Germany and America's Most Powerful Corporation
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Bose D, 2022, REV FINANC STUD, V35, P5094, DOI 10.1093/rfs/hhac027
   Bostock M., 2012, The New York Times
   Bylinskii Z, 2017, Arxiv, DOI arXiv:1709.09215
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Ceja CR, 2021, IEEE T VIS COMPUT GR, V27, P1054, DOI 10.1109/TVCG.2020.3030422
   Chun MM, 2011, ANNU REV PSYCHOL, V62, P73, DOI 10.1146/annurev.psych.093008.100427
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Correll M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300418
   Dominitz J, 2011, J APPL ECONOMET, V26, P352, DOI 10.1002/jae.1225
   Egeth HE, 2010, ACTA PSYCHOL, V135, P130, DOI 10.1016/j.actpsy.2010.05.012
   Feng M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173711
   Fosco C., 2020, P 33 ANN ACM S US IN, P249, DOI DOI 10.1145/3379337.3415825
   Franken IHA, 2005, PERS INDIV DIFFER, V39, P991, DOI 10.1016/j.paid.2005.04.004
   FUNDER DC, 1991, J PERS SOC PSYCHOL, V60, P773, DOI 10.1037/0022-3514.60.5.773
   Gaba A, 2024, IEEE T VIS COMPUT GR, V30, P327, DOI 10.1109/TVCG.2023.3327192
   Gaba Aimen, 2023, IEEE Trans Vis Comput Graph, V29, P1211, DOI 10.1109/TVCG.2022.3209456
   Harmon-Jones E., 2019, An Introduction to Cognitive Dissonance Theory and an Overview of Current Perspectives on the Theory
   Hawley ST, 2008, PATIENT EDUC COUNS, V73, P448, DOI 10.1016/j.pec.2008.07.023
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Heer J, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P203
   Hill S., 2018, J. Inf. Syst. Appl. Res., V11, P1
   Hofman J. M., 2022, P ACM CHI C HUM FACT, P1
   Hofman JM, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376454
   Holder Eli, 2023, IEEE Trans Vis Comput Graph, V29, P624, DOI 10.1109/TVCG.2022.3209377
   Hullman J, 2013, IEEE T VIS COMPUT GR, V19, P2406, DOI 10.1109/TVCG.2013.119
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Inbar O., 2007, P ACM EUR C COGN ERG, P185, DOI DOI 10.1145/1362550.1362587
   Jänicke H, 2010, COMPUT GRAPH FORUM, V29, P1183, DOI 10.1111/j.1467-8659.2009.01667.x
   Jardine N, 2020, IEEE T VIS COMPUT GR, V26, P1012, DOI 10.1109/TVCG.2019.2934786
   Jones B., 2019, Avoiding data pitfalls: how to steer clear of common blunders when working with data and presenting analysis and visualizations
   Kale A, 2021, IEEE T VIS COMPUT GR, V27, P272, DOI 10.1109/TVCG.2020.3030335
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kim D. H., 2021, P ACM CHI C HUM FACT, P1
   Klein N, 2018, P NATL ACAD SCI USA, V115, P13222, DOI 10.1073/pnas.1805327115
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Kool W, 2010, J EXP PSYCHOL GEN, V139, P665, DOI 10.1037/a0020198
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Li XM, 2022, Q J ECON, V137, P1849, DOI 10.1093/qje/qjac025
   Luo Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01541
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mantri Prateek, 2023, IEEE Trans Vis Comput Graph, V29, P1005, DOI 10.1109/TVCG.2022.3209467
   Matzen LE, 2018, IEEE T VIS COMPUT GR, V24, P563, DOI 10.1109/TVCG.2017.2743939
   Michal AL, 2017, COGN RES, V2, DOI 10.1186/s41235-017-0059-2
   Michal AL, 2016, PSYCHON B REV, V23, P1802, DOI 10.3758/s13423-016-1047-0
   Nothelfer C, 2020, IEEE T VIS COMPUT GR, V26, P311, DOI 10.1109/TVCG.2019.2934801
   Ondov BD, 2021, IEEE T VIS COMPUT GR, V27, P1073, DOI 10.1109/TVCG.2020.3030429
   Ottley A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3251, DOI 10.1145/2702123.2702590
   Schneider H, 2017, LECT NOTES COMPUT SC, V10515, P374, DOI 10.1007/978-3-319-67687-6_25
   Schuhmacher D., 2017, "Package 'transport'," R Package Version, V1
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P972, DOI 10.1109/TVCG.2022.3209409
   Shin M, 2023, IEEE T VIS COMPUT GR, V29, P2980, DOI 10.1109/TVCG.2022.3146329
   Stokes Chase, 2023, IEEE Trans Vis Comput Graph, V29, P1233, DOI 10.1109/TVCG.2022.3209383
   Stolper C., 2016, Emerging and recurring data-driven storytelling techniques: analysis of a curated collection of recent stories
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   THEEUWES J, 1991, PERCEPT PSYCHOPHYS, V50, P184, DOI 10.3758/BF03212219
   Theeuwes J, 2010, ACTA PSYCHOL, V135, P77, DOI 10.1016/j.actpsy.2010.02.006
   Torsney-Weir T., 2015, P WORKSH VIS DEC MAK
   Tversky B., 2014, Handbook of Human Centric Visualization, P3
   Vora S., 2019, The Power of Data Storytelling
   Wang ZZ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300483
   Xiong C., 2019, P 1 EUROVIS WORKSH T, P19
   Xiong CY, 2024, IEEE T VIS COMPUT GR, V30, P3487, DOI 10.1109/TVCG.2022.3232959
   Xiong Cindy, 2023, IEEE Trans Vis Comput Graph, V29, P493, DOI 10.1109/TVCG.2022.3209405
   Xiong C, 2022, IEEE T VIS COMPUT GR, V28, P955, DOI 10.1109/TVCG.2021.3114823
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P853, DOI 10.1109/TVCG.2019.2934399
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P301, DOI 10.1109/TVCG.2019.2934400
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Yang LN, 2023, IEEE T VIS COMPUT GR, V29, P1638, DOI 10.1109/TVCG.2021.3128157
   Yarbus A.L., 1973, Eye movements and vision
   Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236
   Ziemkiewicz C, 2013, IEEE T VIS COMPUT GR, V19, P1109, DOI 10.1109/TVCG.2012.180
NR 88
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2995
EP 3007
DI 10.1109/TVCG.2024.3388515
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500003
PM 38619945
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, JC
   Lai, CF
   Zhang, H
   Yuan, XR
AF Li, Jincheng
   Lai, Chufan
   Zhang, Hai
   Yuan, Xiaoru
TI PM-Vis: A Visual Analytics System for Tracing and Analyzing the
   Evolution of Pottery Motifs
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Data visualization; Spatiotemporal phenomena; Urban
   areas; Documentation; Visual analytics; Semantics; Pottery motif
   evolution analysis; image analysis; spatial-temporal analysis; visual
   analytics
ID VISUALIZATION; SPACE; SIMILARITY; REDUCTION
AB In Chinese archaeological research, analyzing the evolution of motifs in ancient pottery is crucial for studying the spread and growth of cultures across various eras and regions. However, such analyses are often challenging due to the complexities of identifying motifs with evolutionary connections that may manifest concurrent changes in appearance, space, and time, compounded by ineffective documentation. We propose PM-Vis, a visual analytics system for tracing and analyzing the evolution of pottery motifs. PM-Vis is anchored in a "selection-organization-documentation" workflow. In the selection stage, we design a three-fold projection paired with a motif-based search mechanism, displaying the appearance similarity and temporal and spatial proximities of all motifs or a specific motif, aiding users in selecting motifs with evolutionary connections. The organization stage helps users establish the evolutionary sequence and segment the selected motifs into distinct evolutionary phases. Finally, the documentation stage enables users to record their observations and insights through various forms of annotation. We demonstrate the usefulness and effectiveness of PM-Vis through two case studies, expert feedback, and a user study.
C1 [Li, Jincheng; Yuan, Xiaoru] Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.
   [Li, Jincheng; Yuan, Xiaoru] Peking Univ, Sch Intelligence Sci & Technol, Beijing 100871, Peoples R China.
   [Li, Jincheng] Peking Univ, Ctr Computat Sci & Engn, Beijing 100871, Peoples R China.
   [Lai, Chufan] Chinese Acad Sci, Technol & Engn Ctr Space Utilizat, Beijing 100045, Peoples R China.
   [Zhang, Hai] Peking Univ, Sch Archaeol & Museol, Beijing 100871, Peoples R China.
   [Yuan, Xiaoru] Peking Univ, Natl Engn Lab Big Data Anal & Applicat, Beijing 100871, Peoples R China.
C3 Peking University; Peking University; Peking University; Chinese Academy
   of Sciences; Technology & Engineering Center for Space Utilization, CAS;
   Peking University; Peking University
RP Yuan, XR (corresponding author), Peking Univ, Natl Key Lab Gen Artificial Intelligence, Beijing 100871, Peoples R China.; Yuan, XR (corresponding author), Peking Univ, Sch Intelligence Sci & Technol, Beijing 100871, Peoples R China.
EM jincheng.li@pku.edu.cn; laichufan@csu.ac.cn; haizhang@pku.edu.cn;
   xiaoru.yuan@pku.edu.cn
RI Li, Jin-Cheng/L-3819-2017; Yuan, Xiaoru/E-1798-2013
OI Li, Jincheng/0000-0003-2328-3624; Yuan, Xiaoru/0000-0002-7233-980X
FU NSFC
FX No Statement Available
CR Bechtold S., 2010, 11 INT S VIRT REAL A, P79
   Bederson BB, 2002, ACM T GRAPHIC, V21, P833, DOI 10.1145/571647.571649
   Beham M, 2014, IEEE T VIS COMPUT GR, V20, P1693, DOI 10.1109/TVCG.2014.2346626
   Castermans T, 2019, IEEE T VIS COMPUT GR, V25, P2969, DOI 10.1109/TVCG.2018.2865361
   Chen SM, 2017, COMPUT GRAPH FORUM, V36, P563, DOI 10.1111/cgf.13211
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   de Bruijn O., 2000, Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '00), P189, DOI DOI 10.1145/345513.345309
   DUNNELL RC, 1970, AM ANTIQUITY, V35, P305, DOI 10.2307/278341
   Ellis G, 2007, IEEE T VIS COMPUT GR, V13, P1216, DOI 10.1109/TVCG.2007.70535
   github, Rembg
   Guo YH, 2024, IEEE T VIS COMPUT GR, V30, P529, DOI 10.1109/TVCG.2023.3326944
   Gupta N, 2017, J ARCHAEOL METHOD TH, V24, P852, DOI 10.1007/s10816-016-9298-7
   Hadlak S., 2015, P 17 EUR C VIS STAT, P1
   Han J., 2019, Cultural Relics Central China, V5, P60
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He XY, 2019, J VISUAL-JAPAN, V22, P897, DOI 10.1007/s12650-019-00584-3
   Hochman Nadav, 2013, First Monday, V18, P32, DOI 10.5210/fm.v18i7.4711
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Kapler T, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P25, DOI 10.1109/INFVIS.2004.27
   Karl S., 2021, P 19 EUR WORKSH GRAP
   Karl S, 2022, IT-INF TECHNOL, V64, P195, DOI 10.1515/itit-2022-0006
   Keim DA, 1998, VISUALIZATION '98, PROCEEDINGS, P181, DOI 10.1109/VISUAL.1998.745301
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Krishnamachari S, 1999, IEEE SYMP COMP COMMU, P301, DOI 10.1109/ISCC.1999.780837
   Laarhoven van, 1987, Simulated Annealing: Theory and Applications, P7, DOI DOI 10.1007/978-94-015-7744-1_2
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   National Museum of China, 2010, Ancient China in Artifacts
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Nocaj A, 2012, IEEE T VIS COMPUT GR, V18, P2546, DOI 10.1109/TVCG.2012.250
   Pak M, 2017, INT CONF COMP APPL I, P367
   Rafiei D, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P375
   Rice PrudenceM., 1987, Pottery Analysis: A Sourcebook
   Saraiya P, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P225, DOI 10.1109/INFVIS.2005.1532151
   Schulz HJ, 2011, IEEE T VIS COMPUT GR, V17, P393, DOI 10.1109/TVCG.2010.79
   Shu W, 2019, IOP CONF SER-MAT SCI, V573, DOI 10.1088/1757-899X/573/1/012012
   STEVENS SS, 1957, PSYCHOL REV, V64, P153, DOI 10.1037/h0046162
   Su B., 1965, Acta Archaeo- logica Sinica, P51
   Su B., 1988, Southeast Culture, P1
   tableau, Tableau 10 color palette
   Tainter J., 1988, The Collapse of Complex Societies
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Waldeck C, 2004, IEEE INFOR VIS, P494, DOI 10.1109/IV.2004.1320190
   Wang C., 2015, Proc. SPIE Vis. Data Anal.
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang LY, 2020, J ARCHAEOL SCI-REP, V33, DOI 10.1016/j.jasrep.2020.102554
   [王立夫 Wang Lifu], 2022, [中国陶瓷, China's Ceramics], V58, P78
   Wang R., 2010, Cultural Relics, P46
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Worring M, 2016, IEEE T MULTIMEDIA, V18, P2217, DOI 10.1109/TMM.2016.2614380
   Xia JZ, 2022, IEEE T VIS COMPUT GR, V28, P529, DOI 10.1109/TVCG.2021.3114694
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Ye L., 2022, Ceram. Stud., V37, P29
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu Y., 2022, BaiHuа, P62
   Zhang A., 2022, Archaeology, P78
   Zhang P., 2005, Chinese Painted Pottery Atlas
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu Y., 2021, Cultural Relics Southern China, P82
   [宗立成 Zong Licheng], 2022, [中国陶瓷, China's Ceramics], V58, P94
NR 65
TC 2
Z9 2
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3022
EP 3034
DI 10.1109/TVCG.2024.3388525
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500004
PM 38619950
DA 2024-11-06
ER

PT J
AU Elmqvist, N
   Liu, SX
   Pascucci, V
AF Elmqvist, Niklas
   Liu, Shixia
   Pascucci, Valerio
TI Editorial: Guest Editors' Introduction
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Editorial Material
C1 [Elmqvist, Niklas] Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
   [Liu, Shixia] Tsinghua Univ, Sch Software, Beijing, Peoples R China.
   [Pascucci, Valerio] Univ Utah, Sci & Imaging Inst, Salt Lake City, UT USA.
C3 Aarhus University; Tsinghua University; Utah System of Higher Education;
   University of Utah
RP Elmqvist, N (corresponding author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
EM elm@cs.au.dk
RI pascucci, Valerio/GXF-0616-2022; Liu, Shi-Xia/C-5574-2016
OI Elmqvist, Niklas/0000-0001-5805-5301
NR 0
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2860
EP 2861
DI 10.1109/TVCG.2024.3373233
PG 2
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500002
DA 2024-11-06
ER

PT J
AU Ruan, SL
   Liang, ZD
   Guan, Q
   Griffin, P
   Wen, XL
   Lin, YN
   Wang, Y
AF Ruan, Shaolun
   Liang, Zhiding
   Guan, Qiang
   Griffin, Paul
   Wen, Xiaolin
   Lin, Yanna
   Wang, Yong
TI <i>VIOLET</i>: <underline>V</underline>isual
   Analyt<underline>i</underline>cs f<underline>o</underline>r
   Exp<underline>l</underline>ainable Quantum N<underline>e</underline>ural
   Ne<underline>t</underline>works
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; explainable artificial intelligence (XAI); quantum
   machine learning; qunatum neural networks
ID VISUAL ANALYTICS; DESIGN; VISUALIZATION; INFORMATION
AB With the rapid development of Quantum Machine Learning, quantum neural networks (QNN) have experienced great advancement in the past few years, harnessing the advantages of quantum computing to significantly speed up classical machine learning tasks. Despite their increasing popularity, the quantum neural network is quite counter-intuitive and difficult to understand, due to their unique quantum-specific layers (e.g., data encoding and measurement) in their architecture. It prevents QNN users and researchers from effectively understanding its inner workings and exploring the model training status. To fill the research gap, we propose VIOLET, a novel visual analytics approach to improve the explainability of quantum neural networks. Guided by the design requirements distilled from the interviews with domain experts and the literature survey, we developed three visualization views: the Encoder View unveils the process of converting classical input data into quantum states, the Ansatz View reveals the temporal evolution of quantum states in the training process, and the Feature View displays the features a QNN has learned after the training process. Two novel visual designs, i.e., satellite chart and augmented heatmap, are proposed to visually explain the variational parameters and quantum circuit measurements respectively. We evaluate VIOLET through two case studies and in-depth interviews with 12 domain experts. The results demonstrate the effectiveness and usability of VIOLET in helping QNN users and developers intuitively understand and explore quantum neural networks.
C1 [Ruan, Shaolun; Griffin, Paul; Wen, Xiaolin; Wang, Yong] Singapore Management Univ, Singapore 188065, Singapore.
   [Liang, Zhiding] Univ Notre Dame, Notre Dame, IN 46556 USA.
   [Guan, Qiang] Kent State Univ, Kent, OH 44240 USA.
   [Lin, Yanna] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Singapore Management University; University of Notre Dame; University
   System of Ohio; Kent State University; Kent State University Kent; Kent
   State University Salem; Hong Kong University of Science & Technology
RP Wang, Y (corresponding author), Singapore Management Univ, Singapore 188065, Singapore.
EM slruan.2021@phdcs.smu.edu.sg; zliang5@nd.edu; qguan@kent.edu;
   paulgriffin@smu.edu.sg; xiaolinwen@smu.edu.sg; ylindg@connect.ust.hk;
   yongwang@smu.edu.sg
RI Liang, Zhiding/GYD-7280-2022; GRIFFIN, Paul/L-9582-2016; Griffin,
   Paul/L-4696-2014
OI Ruan, Shaolun/0000-0002-6163-9786; Griffin, Paul/0000-0002-1656-421X;
   Lin, Yanna/0000-0003-3730-0827; Griffin, Paul/0000-0003-2294-5980; Wen,
   Xiaolin/0000-0002-8562-7640
FU Lee Kong Chian Fellowship
FX No Statement Available
CR Acharya R, 2023, NATURE, V614, P676, DOI 10.1038/s41586-022-05434-1
   Altaisky M., 2001, arXiv, DOI [10.48550/arXiv.quant-ph/0107012, DOI 10.48550/ARXIV.QUANT-PH/0107012]
   Altepeter J. B., 2009, P C LAS EL C QUANT E, P1, DOI [10.1364/IQEC.2009.IWC1, DOI 10.1364/IQEC.2009.IWC1]
   [Anonymous], IBMQ Phase Disk
   [Anonymous], Paddle quantum: Quantum classifier
   [Anonymous], 2019, Quantum Computing: Progress and Prospects
   [Anonymous], Quantum neural networks
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Bardroff PJ, 1996, PHYS REV A, V53, P2736, DOI 10.1103/PhysRevA.53.2736
   Bausch J., 2020, P ADV NEUR INF PROC
   Beer K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14454-2
   Benedetti M, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab5944
   Bennett CH, 2000, NATURE, V404, P247, DOI 10.1038/35005001
   Blance A, 2021, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2021)212
   BLOCH F, 1946, PHYS REV, V70, P460, DOI 10.1103/PhysRev.70.460
   Cerezo M, 2022, NAT COMPUT SCI, V2, P567, DOI 10.1038/s43588-022-00311-3
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chalkiadakis I., 2018, Abrief survey of visualizationmethods for deep learning models from the perspective of explainable AI
   Chandarana P, 2023, PHYS REV APPL, V20, DOI 10.1103/PhysRevApplied.20.014024
   Cheng FR, 2022, IEEE T VIS COMPUT GR, V28, P378, DOI 10.1109/TVCG.2021.3114836
   Choo J, 2018, IEEE COMPUT GRAPH, V38, P84, DOI 10.1109/MCG.2018.042731661
   Chung S., 2016, P FUT INT LEARN MAN
   Daskin A, 2023, Arxiv, DOI arXiv:2301.05549
   Ding YF, 2022, IEEE INTERNET COMPUT, V26, P5, DOI 10.1109/MIC.2021.3133675
   Fong R, 2018, PROC CVPR IEEE, P8730, DOI 10.1109/CVPR.2018.00910
   Galambos M., 2012, Int. J. Adv. Syst. Meas., V5
   Griffin P. R., 2021, Quantum computing: Computational excellence for society 5.0
   Heese R., 2023, Explaining quantum circuits with shapley values: Towards explainable quantum machine learning
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Huang HL, 2023, SCI CHINA PHYS MECH, V66, DOI 10.1007/s11433-022-2057-y
   Huang R, 2021, NEUROCOMPUTING, V452, P89, DOI 10.1016/j.neucom.2021.04.074
   Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w
   Jia ZA, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201800077
   Jin ZH, 2023, IEEE T VIS COMPUT GR, V29, P3024, DOI 10.1109/TVCG.2022.3148107
   Kahng M, 2019, IEEE T VIS COMPUT GR, V25, P310, DOI 10.1109/TVCG.2018.2864500
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kandala A, 2017, NATURE, V549, P242, DOI 10.1038/nature23879
   Karafyllidis IG, 2003, QUANTUM INF PROCESS, V2, P271, DOI 10.1023/B:QINP.0000020076.36114.13
   Keyl M, 2002, PHYS REP, V369, P431, DOI 10.1016/S0370-1573(02)00266-1
   Li W., 2022, SciPost Phys. Lect. Notes, P61, DOI [10.21468/SciPostPhysLectNotes.61, DOI 10.21468/SCIPOSTPHYSLECTNOTES.61]
   Li WK, 2022, SCI CHINA PHYS MECH, V65, DOI 10.1007/s11433-021-1793-6
   Liu DY, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200489
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu ZP, 2022, IEEE T VIS COMPUT GR, V28, P2500, DOI 10.1109/TVCG.2022.3148197
   Mäkelä H, 2010, PHYS SCRIPTA, VT140, DOI 10.1088/0031-8949/2010/T140/014054
   Maheshwari D, 2022, IEEE ACCESS, V10, P3705, DOI 10.1109/ACCESS.2021.3139323
   Ming Y, 2019, IEEE T VIS COMPUT GR, V25, P342, DOI 10.1109/TVCG.2018.2864812
   Mohseni S, 2021, ACM T INTERACT INTEL, V11, DOI 10.1145/3387166
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Nielsen MA., 2010, Quantum computation and quantum information, VAnniversary, DOI 10.1017/cbo9780511976667
   Oh S, 2020, I C INF COMM TECH CO, P236, DOI 10.1109/ICTC49870.2020.9289439
   Olah C., 2017, DISTILL, DOI [10.23915/distill.00007, DOI 10.23915/DISTILL.00007]
   Park H, 2022, IEEE T VIS COMPUT GR, V28, P813, DOI 10.1109/TVCG.2021.3114858
   Piatrenka I, 2022, LECT NOTES COMPUT SC, P247, DOI 10.1007/978-3-031-08760-8_21
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Rieffel E. G., 2011, Quantum Computing:AGentle Introduction
   Ruan Shaolun, 2023, IEEE Transactions on Visualization and Computer Graphics, V29, P462, DOI 10.1109/TVCG.2022.3209455
   Ruan S., IEEE Trans. Visual. Comput. Graph., DOI [10.1109/TVCG.2023.3332999, DOI 10.1109/TVCG.2023.3332999]
   Ruan SL, 2023, COMPUT GRAPH FORUM, V42, P247, DOI 10.1111/cgf.14827
   Schneider B, 2021, IEEE T BIG DATA, V7, P483, DOI 10.1109/TBDATA.2018.2877350
   Schuld M, 2020, PHYS REV A, V101, DOI 10.1103/PhysRevA.101.032308
   Schuld M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.040504
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Sun D, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376866
   Takaki Y, 2021, PHYS REV A, V103, DOI 10.1103/PhysRevA.103.052414
   Tian JK, 2023, IEEE T PATTERN ANAL, V45, P12321, DOI 10.1109/TPAMI.2023.3272029
   TorchQuantum, About us
   Tyagi Anjul, 2023, IEEE Trans Vis Comput Graph, V29, P299, DOI 10.1109/TVCG.2022.3209361
   Vilone G, 2020, Arxiv, DOI [arXiv:2006.00093, 10.48550/arXiv.2006.00093]
   Wang Q., 2019, P CHI C HUM FACT COM, P12
   Wang QW, 2021, IEEE T VIS COMPUT GR, V27, P1470, DOI 10.1109/TVCG.2020.3030471
   Wang XB, 2022, IEEE T VIS COMPUT GR, V28, P802, DOI 10.1109/TVCG.2021.3114794
   Wang ZH, 2021, PROC SPIE, V11912, DOI 10.1117/12.2602493
   Wiebe N, 2015, Arxiv, DOI arXiv:1412.3489
   Wilde M. M., 2017, Quantum Information Theory, V2nd
   Wille R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P768, DOI 10.23919/DATE51398.2021.9474236
   Williams M. M., 2021, PhD thesis,
   Xiang SX, 2019, IEEE CONF VIS ANAL, P57, DOI [10.1109/vast47406.2019.8986943, 10.1109/VAST47406.2019.8986943]
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yao Zhang, 2020, Quantum Engineering, V2, DOI 10.1002/que2.34
   Chen SYC, 2020, Arxiv, DOI arXiv:2011.14651
   Zeng HP, 2017, Arxiv, DOI arXiv:1710.05285
   Zhou MG, 2023, RESEARCH-CHINA, V6, DOI 10.34133/research.0134
   Zulehner Alwin, 2019, ICCAD-IEEE ACM INT, P1, DOI DOI 10.1109/iccad45719.2019.8942057
NR 86
TC 0
Z9 0
U1 4
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2862
EP 2874
DI 10.1109/TVCG.2024.3388557
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500007
PM 38652613
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, YR
   Wang, JP
   Aboagye, P
   Yeh, CCM
   Zheng, Y
   Wang, L
   Zhang, W
   Ma, KL
AF Li, Yiran
   Wang, Junpeng
   Aboagye, Prince
   Yeh, Chin-Chia Michael
   Zheng, Yan
   Wang, Liang
   Zhang, Wei
   Ma, Kwan-Liu
TI Visual Analytics for Efficient Image Exploration and User-Guided Image
   Captioning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visual analytics; Analytical models; Training; Image segmentation;
   Transformers; Snow; Heating systems; Machine learning; visual analytics;
   data-centric AI; pre-trained language-image models; image captioning
ID VISION
AB Recent advancements in pre-trained language-image models have ushered in a new era of visual comprehension. Leveraging the power of these models, this article tackles two issues within the realm of visual analytics: (1) the efficient exploration of large-scale image datasets and identification of data biases within them; (2) the evaluation of image captions and steering of their generation process. On the one hand, by visually examining the captions generated from language-image models for an image dataset, we gain deeper insights into the visual contents, unearthing data biases that may be entrenched within the dataset. On the other hand, by depicting the association between visual features and textual captions, we expose the weaknesses of pre-trained language-image models in their captioning capability and propose an interactive interface to steer caption generation. The two parts have been coalesced into a coordinated visual analytics system, fostering the mutual enrichment of visual and textual contents. We validate the effectiveness of the system with domain practitioners through concrete case studies with large-scale image datasets.
C1 [Li, Yiran; Ma, Kwan-Liu] Univ Calif Davis, Davis, CA 95616 USA.
   [Wang, Junpeng; Aboagye, Prince; Yeh, Chin-Chia Michael; Zheng, Yan; Wang, Liang; Zhang, Wei] Visa Res, Foster City, CA 94404 USA.
C3 University of California System; University of California Davis
RP Li, YR (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.
EM ranli@ucdavis.edu; junpenwa@visa.com; priaboag@visa.com; miyeh@visa.com;
   yazheng@visa.com; liawang@visa.com; wzhan@visa.com; klma@ucdavis.edu
RI Yeh, Michael/J-1738-2019
OI Wang, Junpeng/0000-0002-1130-9914; Ma, Kwan-Liu/0000-0001-8086-0366; Li,
   Yiran/0000-0001-5204-4935
FU NIBIB
FX No Statement Available
CR Aflalo E, 2022, PROC CVPR IEEE, P21374, DOI 10.1109/CVPR52688.2022.02072
   Alsallakh B, 2018, IEEE T VIS COMPUT GR, V24, P152, DOI 10.1109/TVCG.2017.2744683
   [Anonymous], TEXTBLOB SIMPLIFIED
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bauerle A., 2023, P EUR C VIS SHORT PA, DOI [10.2312/evs.20231051, DOI 10.2312/EVS.20231051]
   Bertucci D., IEEE T VIS COMPUT GR, V29, P320
   Bird S., 2009, NATURAL LANGUAGE PRO
   Brade S., 2023, P 36 ANN ACM S US IN, P1, DOI [10.1145/3586183.3606725, DOI 10.1145/3586183.3606725]
   Cao KL, 2021, IEEE T VIS COMPUT GR, V27, P3289, DOI 10.1109/TVCG.2020.2969185
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong ZH, 2020, IEEE PAC VIS SYMP, P46, DOI 10.1109/PacificVis48177.2020.1031
   Dosovitskiy A., 2020, IMAGE IS WORTH 16X16
   Feng YCJ, 2024, IEEE T VIS COMPUT GR, V30, P295, DOI 10.1109/TVCG.2023.3327168
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gou L, 2021, IEEE T VIS COMPUT GR, V27, P261, DOI 10.1109/TVCG.2020.3030350
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683
   Jia SC, 2022, IEEE T VIS COMPUT GR, V28, P791, DOI 10.1109/TVCG.2021.3114793
   Karpathy A., T SNE VISUALIZATION
   Kaul S, 2022, IEEE T VIS COMPUT GR, V28, P998, DOI 10.1109/TVCG.2021.3114779
   Kazemzadeh Sahar, 2014, P 2014 C EMPIRICAL M, DOI DOI 10.3115/V1/D14-1086
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kirillov A., 2023, ARXIV
   Li DX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3, P31
   LI J, 2021, ADV NEURAL INFORM PR, V34
   Li JN, 2022, PR MACH LEARN RES
   Li YR, 2023, IEEE T VIS COMPUT GR, V29, P2888, DOI 10.1109/TVCG.2023.3261935
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ming Y, 2020, IEEE T VIS COMPUT GR, V26, P238, DOI 10.1109/TVCG.2019.2934267
   OpenAI, 2023, GPT 4 TECHN REP, DOI DOI 10.48550/ARXIV.2303.08774
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P146, DOI 10.1109/visual.2019.8933677
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren DH, 2017, IEEE T VIS COMPUT GR, V23, P61, DOI 10.1109/TVCG.2016.2598828
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]
   Smilkov D., 2016, STATIST MACH LEARN, V1050
   Strickland E., 2022, IEEE SPECTRUM, V59, P22, DOI [DOI 10.1109/MSPEC.2022.9754503, 10.1109/MSPEC.2022.9754503]
   Strobelt H, 2022, IEEE T VIS COMPUT GR, V28, P1106, DOI 10.1109/TVCG.2021.3114845
   Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044
   Touvron H, 2023, ARXIV
   Vaswani A., 2017, Advances in neural information processing systems
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087
   Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37
   Wang J, 2023, ARXIV
   Wang JP, 2019, IEEE T VIS COMPUT GR, V25, P288, DOI 10.1109/TVCG.2018.2864504
   Wang ZJ, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P132
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yang WK, 2021, IEEE T VIS COMPUT GR, V27, P3953, DOI 10.1109/TVCG.2020.2995100
   Yeh C., 2023, ARXIV
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Zhang Xiaoyu, 2023, IEEE Trans Vis Comput Graph, V29, P842, DOI 10.1109/TVCG.2022.3209465
   Zhao ZE, 2022, IEEE T VIS COMPUT GR, V28, P780, DOI 10.1109/TVCG.2021.3114837
NR 59
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2875
EP 2887
DI 10.1109/TVCG.2024.3388514
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500016
PM 38625780
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Hong, JY
   Hnatyshyn, R
   Santos, EAD
   Maciejewski, R
   Isenberg, T
AF Hong, Jiayi
   Hnatyshyn, Rostyslav
   Santos, Ebrar A. D.
   Maciejewski, Ross
   Isenberg, Tobias
TI A Survey of Designs for Combined 2D+3D Visual Representations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Data visualization; Visualization; Surveys;
   Two-dimensional displays; Layout; Task analysis; 2D visual
   representations; 3D visual representations; design space
ID DIRECT-TOUCH INTERACTION; COMBINED VISUALIZATION; WALL THICKNESS; 3D;
   EXPLORATION; FRAMEWORK; PERFORMANCE; TRACKING; TOOL; 2D
AB We examine visual representations of data that make use of combinations of both 2D and 3D data mappings. Combining 2D and 3D representations is a common technique that allows viewers to understand multiple facets of the data with which they are interacting. While 3D representations focus on the spatial character of the data or the dedicated 3D data mapping, 2D representations often show abstract data properties and take advantage of the unique benefits of mapping to a plane. Many systems have used unique combinations of both types of data mappings effectively. Yet there are no systematic reviews of the methods in linking 2D and 3D representations. We systematically survey the relationships between 2D and 3D visual representations in major visualization publications-IEEE VIS, IEEE TVCG, and EuroVis-from 2012 to 2022. We closely examined 105 articles where 2D and 3D representations are connected visually, interactively, or through animation. These approaches are designed based on their visual environment, the relationships between their visual representations, and their possible layouts. Through our analysis, we introduce a design space as well as provide design guidelines for effectively linking 2D and 3D visual representations.
C1 [Hong, Jiayi; Hnatyshyn, Rostyslav; Maciejewski, Ross] Arizona State Univ, Tempe, AZ 85287 USA.
   [Santos, Ebrar A. D.; Isenberg, Tobias] Univ Paris Saclay, CNRS, Inria, F-91190 Gif Sur Yvette, France.
C3 Arizona State University; Arizona State University-Tempe; Universite
   Paris Saclay; Inria; Universite Paris Cite; Centre National de la
   Recherche Scientifique (CNRS)
RP Hong, JY (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.
EM jhong76@asu.edu; rhnatysh@asu.edu; rmacieje@asu.edu;
   tobias.isenberg@inria.fr
RI ; Isenberg, Tobias/A-7575-2008
OI Hnatyshyn, Rostyslav/0009-0006-0510-1152; Hong,
   Jiayi/0000-0002-1332-5045; Isenberg, Tobias/0000-0001-7953-8644
FU U.S. Department of Homeland Security
FX No Statement Available
CR Abbasloo A, 2016, IEEE T VIS COMPUT GR, V22, P975, DOI 10.1109/TVCG.2015.2467031
   Aboulhassan A, 2015, COMPUT GRAPH FORUM, V34, P401, DOI 10.1111/cgf.12652
   Ageeli Amani, 2023, IEEE Trans Vis Comput Graph, V29, P646, DOI 10.1109/TVCG.2022.3209439
   Agus M, 2019, COMPUT GRAPH FORUM, V38, P427, DOI 10.1111/cgf.13700
   Al-Awami AK, 2016, IEEE T VIS COMPUT GR, V22, P738, DOI 10.1109/TVCG.2015.2467441
   Al-Awami AK, 2014, IEEE T VIS COMPUT GR, V20, P2369, DOI 10.1109/TVCG.2014.2346312
   Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Axelsson E, 2017, COMPUT GRAPH FORUM, V36, P459, DOI 10.1111/cgf.13202
   Bach Benjamin, 2023, IEEE Trans Vis Comput Graph, V29, P342, DOI 10.1109/TVCG.2022.3209448
   Badam SK, 2019, INFORM VISUAL, V18, P68, DOI 10.1177/1473871617725907
   Bader R, 2020, IEEE T VIS COMPUT GR, V26, P259, DOI 10.1109/TVCG.2019.2934310
   BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   Berge CSZ, 2014, IEEE T VIS COMPUT GR, V20, P2379, DOI 10.1109/TVCG.2014.2346317
   Besançon L, 2017, IEEE T VIS COMPUT GR, V23, P881, DOI 10.1109/TVCG.2016.2599217
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Biswas A, 2013, IEEE T VIS COMPUT GR, V19, P2683, DOI 10.1109/TVCG.2013.133
   Bock A, 2015, 2015 IEEE Scientific Visualization Conference (SciVis), P17, DOI 10.1109/SciVis.2015.7429487
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Bowman DA, 2007, COMPUTER, V40, P36, DOI 10.1109/MC.2007.257
   Brath R, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P25, DOI 10.1109/3DVis.2014.7160096
   Bruckner S, 2019, IEEE T VIS COMPUT GR, V25, P2514, DOI 10.1109/TVCG.2018.2848906
   Buja A., 1991, Proceedings Visualization '91 (Cat. No.91CH3046-0), P156, DOI 10.1109/VISUAL.1991.175794
   Burchett JN, 2019, COMPUT GRAPH FORUM, V38, P491, DOI 10.1111/cgf.13705
   Byska J, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12612
   Chen CM, 2016, IEEE T VIS COMPUT GR, V22, P847, DOI 10.1109/TVCG.2015.2467952
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Cornel D, 2015, COMPUT GRAPH FORUM, V34, P331, DOI 10.1111/cgf.12645
   Demir I, 2014, IEEE T VIS COMPUT GR, V20, P2694, DOI 10.1109/TVCG.2014.2346448
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P5406, DOI 10.1109/TVCG.2022.3213565
   Doraiswamy H, 2021, IEEE T VIS COMPUT GR, V27, P561, DOI 10.1109/TVCG.2020.3030441
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Duran D, 2019, IEEE T VIS COMPUT GR, V25, P987, DOI 10.1109/TVCG.2018.2864851
   Elek O, 2021, IEEE T VIS COMPUT GR, V27, P806, DOI 10.1109/TVCG.2020.3030407
   Elvins T. T., 1992, Computer Graphics, V26, P194, DOI 10.1145/142413.142427
   Eulzer P, 2021, COMPUT GRAPH FORUM, V40, P435, DOI 10.1111/cgf.14319
   Eulzer P, 2021, IEEE T VIS COMPUT GR, V27, P700, DOI 10.1109/TVCG.2020.3030388
   Eulzer P, 2020, IEEE T VIS COMPUT GR, V26, P971, DOI 10.1109/TVCG.2019.2934337
   Ferstl F, 2017, IEEE T VIS COMPUT GR, V23, P831, DOI 10.1109/TVCG.2016.2598868
   Fonnet A, 2021, IEEE T VIS COMPUT GR, V27, P2101, DOI 10.1109/TVCG.2019.2929033
   Fröhler B, 2019, COMPUT GRAPH FORUM, V38, P273, DOI 10.1111/cgf.13688
   Fu CW, 2007, IEEE T VIS COMPUT GR, V13, P108, DOI 10.1109/TVCG.2007.2
   Furmanová K, 2020, IEEE T VIS COMPUT GR, V26, P843, DOI 10.1109/TVCG.2019.2934333
   Glasser S, 2014, IEEE T VIS COMPUT GR, V20, P2506, DOI 10.1109/TVCG.2014.2346406
   Gu Y, 2016, IEEE T VIS COMPUT GR, V22, P965, DOI 10.1109/TVCG.2015.2468031
   Guo HQ, 2016, IEEE T VIS COMPUT GR, V22, P827, DOI 10.1109/TVCG.2015.2466838
   Guo HQ, 2013, IEEE T VIS COMPUT GR, V19, P2733, DOI 10.1109/TVCG.2013.144
   Hadlak S., 2015, P EUROVIS STARS GOSL, P1, DOI [10.2312/eurovisstar,20151109, DOI 10.2312/EUROVISSTAR,20151109]
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Haehn D, 2014, IEEE T VIS COMPUT GR, V20, P2466, DOI 10.1109/TVCG.2014.2346371
   Halladjian S, 2020, IEEE T VIS COMPUT GR, V26, P654, DOI 10.1109/TVCG.2019.2934334
   Hayward V., 2004, Sensor Review, V24, P16, DOI 10.1108/02602280410515770
   Hepperle D, 2019, COMPUT GRAPH-UK, V82, P321, DOI 10.1016/j.cag.2019.06.003
   Hermosilla P, 2017, IEEE T VIS COMPUT GR, V23, P731, DOI 10.1109/TVCG.2016.2598825
   Höllt T, 2012, IEEE T VIS COMPUT GR, V18, P2226, DOI 10.1109/TVCG.2012.259
   Hong F, 2014, IEEE T VIS COMPUT GR, V20, P2545, DOI 10.1109/TVCG.2014.2346416
   Hong JY, 2022, COMPUT GRAPH FORUM, V41, P195, DOI 10.1111/cgf.14533
   Hong Jiayi, 2021, GI 2021 GRAPHICS INT, P213, DOI [DOI 10.20380/GI2021.33, 10/kt3q, DOI 10.20380/G12021.33]
   Huang Jieying, 2023, IEEE Trans Vis Comput Graph, V29, P1200, DOI 10.1109/TVCG.2022.3209453
   Hubona G. S., 1997, Human Factors in Computing Systems. CHI 97 Extended Abstracts, P345
   Huron S, 2014, IEEE T VIS COMPUT GR, V20, P2102, DOI 10.1109/TVCG.2014.2346292
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Ip CY, 2012, IEEE T VIS COMPUT GR, V18, P2355, DOI 10.1109/TVCG.2012.231
   Jackson Bret, 2013, IEEE Trans Vis Comput Graph, V19, P2802, DOI 10.1109/TVCG.2013.121
   Jansen Y, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3227, DOI 10.1145/2702123.2702180
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jönsson D, 2016, IEEE T VIS COMPUT GR, V22, P896, DOI 10.1109/TVCG.2015.2467294
   Klein T, 2012, COMPUT GRAPH FORUM, V31, P1225, DOI 10.1111/j.1467-8659.2012.03115.x
   Klemm P, 2014, IEEE T VIS COMPUT GR, V20, P1673, DOI 10.1109/TVCG.2014.2346591
   Köhler B, 2018, COMPUT GRAPH FORUM, V37, P195, DOI 10.1111/cgf.13412
   Kolesár I, 2017, IEEE T VIS COMPUT GR, V23, P851, DOI 10.1109/TVCG.2016.2598870
   Kottravel S, 2019, COMPUT GRAPH FORUM, V38, P479, DOI 10.1111/cgf.13704
   Kretschmer J, 2014, IEEE T VIS COMPUT GR, V20, P2496, DOI 10.1109/TVCG.2014.2346405
   Kretschmer J, 2013, IEEE T VIS COMPUT GR, V19, P2828, DOI 10.1109/TVCG.2013.169
   Krone M, 2013, COMPUT GRAPH FORUM, V32, P331, DOI 10.1111/cgf.12120
   Krone M, 2017, IEEE T VIS COMPUT GR, V23, P701, DOI 10.1109/TVCG.2016.2598824
   Landge AG, 2012, IEEE T VIS COMPUT GR, V18, P2467, DOI 10.1109/TVCG.2012.286
   Langner Ricardo, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445593
   Langner R, 2018, IEEE T VIS COMPUT GR, V24, P626, DOI 10.1109/TVCG.2017.2744019
   Lawonn Kai, 2023, IEEE Trans Vis Comput Graph, V29, P526, DOI 10.1109/TVCG.2022.3209374
   Lawonn K, 2016, IEEE T VIS COMPUT GR, V22, P728, DOI 10.1109/TVCG.2015.2467961
   Le Goc M, 2019, IEEE T VIS COMPUT GR, V25, P737, DOI 10.1109/TVCG.2018.2865159
   Le Goc M, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/2984511.2984547
   LEDERMAN SJ, 1987, COGNITIVE PSYCHOL, V19, P342, DOI 10.1016/0010-0285(87)90008-9
   Lee B, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501859
   Lichtenberg N, 2018, COMPUT GRAPH FORUM, V37, P379, DOI 10.1111/cgf.13427
   Lindow N, 2019, IEEE T VIS COMPUT GR, V25, P967, DOI 10.1109/TVCG.2018.2864507
   Liu H, 2021, IEEE T VIS COMPUT GR, V27, P593, DOI 10.1109/TVCG.2020.3028893
   Liu JZ, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P588, DOI [10.1109/VR46266.2020.00-23, 10.1109/VR46266.2020.1581122519414]
   Liu XT, 2016, IEEE T VIS COMPUT GR, V22, P955, DOI 10.1109/TVCG.2015.2467431
   Luciani T, 2019, IEEE T VIS COMPUT GR, V25, P1225, DOI 10.1109/TVCG.2018.2864849
   Maries A, 2013, IEEE T VIS COMPUT GR, V19, P2916, DOI 10.1109/TVCG.2013.161
   Marriott K., 2018, Immersive Analytics, DOI [10.1515/itit-2022-0037, DOI 10.1515/ITIT-2022-0037]
   Marton F, 2019, COMPUT GRAPH FORUM, V38, P53, DOI 10.1111/cgf.13671
   Bin Masood T, 2021, COMPUT GRAPH FORUM, V40, P287, DOI 10.1111/cgf.14307
   Meuschke M, 2016, COMPUT GRAPH FORUM, V35, P351, DOI 10.1111/cgf.12911
   Meuschke M, 2023, IEEE T VIS COMPUT GR, V29, P1876, DOI 10.1109/TVCG.2021.3134083
   Meuschke M, 2019, IEEE T VIS COMPUT GR, V25, P997, DOI 10.1109/TVCG.2018.2864509
   Meuschke M, 2017, IEEE T VIS COMPUT GR, V23, P761, DOI 10.1109/TVCG.2016.2598795
   Miao H, 2018, COMPUT GRAPH FORUM, V37, P403, DOI 10.1111/cgf.13429
   Mistelbauer G, 2013, COMPUT GRAPH FORUM, V32, P231, DOI 10.1111/cgf.12110
   Mohammed H, 2018, IEEE T VIS COMPUT GR, V24, P853, DOI 10.1109/TVCG.2017.2744278
   Mohenska M, 2022, J MOL CELL CARDIOL, V163, P20, DOI 10.1016/j.yjmcc.2021.09.011
   Munzner T., 2014, Visualization Analysis and Design, DOI [10.1201/617511, DOI 10.1201/617511]
   Nadeem S, 2017, IEEE T VIS COMPUT GR, V23, P751, DOI 10.1109/TVCG.2016.2598791
   Neugebauer M, 2013, COMPUT GRAPH FORUM, V32, P251, DOI 10.1111/cgf.12112
   Neuroth Tyson, 2023, IEEE Trans Vis Comput Graph, V29, P548, DOI 10.1109/TVCG.2022.3209473
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nipu Nafiul, 2023, IEEE Trans Vis Comput Graph, V29, P798, DOI 10.1109/TVCG.2022.3209356
   Pálenik J, 2020, IEEE T VIS COMPUT GR, V26, P643, DOI 10.1109/TVCG.2019.2934258
   Palmas G, 2014, IEEE T VIS COMPUT GR, V20, P2359, DOI 10.1109/TVCG.2014.2346311
   Pavlopoulos GA, 2008, BMC SYST BIOL, V2, DOI 10.1186/1752-0509-2-104
   Peng HC, 2014, NAT PROTOC, V9, P193, DOI 10.1038/nprot.2014.011
   Poco J, 2012, COMPUT GRAPH FORUM, V31, P1075, DOI 10.1111/j.1467-8659.2012.03100.x
   Rapp T, 2021, IEEE T VIS COMPUT GR, V27, P1580, DOI 10.1109/TVCG.2020.3030379
   Reh A, 2013, IEEE T VIS COMPUT GR, V19, P2906, DOI 10.1109/TVCG.2013.177
   Reipschlager P, 2021, IEEE T VIS COMPUT GR, V27, P1182, DOI 10.1109/TVCG.2020.3030460
   Rieck B, 2012, IEEE T VIS COMPUT GR, V18, P2382, DOI 10.1109/TVCG.2012.248
   Robertson G. G., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P189, DOI 10.1145/108844.108883
   Rocha A, 2018, COMPUT GRAPH FORUM, V37, P465, DOI 10.1111/cgf.13434
   Sabando MV, 2021, IEEE T VIS COMPUT GR, V27, P891, DOI 10.1109/TVCG.2020.3030438
   Saffo D, 2020, COMPUT GRAPH FORUM, V39, P455, DOI 10.1111/cgf.13994
   Santos E. A. D., 2022, P POST IEEE VIS
   Satriadi Kadek Ananta, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3427329
   Satriadi K. A., 2022, P ANN ACM C HUM FACT, DOI [10.1145/34911023517715, DOI 10.1145/34911023517715]
   Schindler M, 2020, 2020 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2020), P1, DOI 10.1109/VIS47514.2020.00007
   Schroeder D, 2014, IEEE T VIS COMPUT GR, V20, P2644, DOI 10.1109/TVCG.2014.2346451
   Schroeder WJ, 1996, IEEE VISUAL, P93, DOI 10.1109/VISUAL.1996.567752
   Schulz HJ, 2013, IEEE T VIS COMPUT GR, V19, P2366, DOI 10.1109/TVCG.2013.120
   Sedlmair M, 2009, LECT NOTES COMPUT SC, V5531, P27
   Semmo A, 2012, COMPUT GRAPH FORUM, V31, P885, DOI 10.1111/j.1467-8659.2012.03081.x
   Siddiqui F, 2021, COMPUT GRAPH FORUM, V40, P411, DOI 10.1111/cgf.14317
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   Splechtna Rainer, 2023, IEEE Trans Vis Comput Graph, V29, P778, DOI 10.1109/TVCG.2022.3209478
   Sun MY, 2022, IEEE T VIS COMPUT GR, V28, P4741, DOI 10.1109/TVCG.2021.3102966
   Suzuki R, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P493, DOI 10.1145/3332165.3347911
   Tao J, 2019, IEEE T VIS COMPUT GR, V25, P1236, DOI 10.1109/TVCG.2018.2864808
   Tavanti M, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P139, DOI 10.1109/INFVIS.2001.963291
   Tierny J, 2018, IEEE T VIS COMPUT GR, V24, P832, DOI 10.1109/TVCG.2017.2743938
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tory M, 2006, IEEE T VIS COMPUT GR, V12, P2, DOI 10.1109/TVCG.2006.17
   Troidl J, 2022, COMPUT GRAPH FORUM, V41, P183, DOI 10.1111/cgf.14532
   Ulbrich P, 2023, IEEE T VIS COMPUT GR, V29, P581, DOI 10.1109/TVCG.2022.3209411
   Ullmer B, 2000, IBM SYST J, V39, P915, DOI 10.1147/sj.393.0915
   Unger A, 2012, IEEE T VIS COMPUT GR, V18, P2216, DOI 10.1109/TVCG.2012.190
   Vázquez P, 2018, COMPUT GRAPH FORUM, V37, P391, DOI 10.1111/cgf.13428
   Viola I., 2020, Foundations of Data Visualization, P15, DOI [DOI 10.1007/978-3-030-34444-3_2, 10/gk874c, DOI 10.1007/978-3-030-34444-32, 10.1007/978-3-030-34444-3_2]
   Viola I, 2018, IEEE T VIS COMPUT GR, V24, P2573, DOI 10.1109/TVCG.2017.2747545
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [DOI 10.1145/345513.345271, 10/cqq2cj]
   Wang XY, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376657
   Ware C., 2019, Information visualization: perception for design, V4th, DOI [DOI 10.1016/C2009-0-62432-6, 10.1016/C2009-0-62432-6]
   Waser J, 2014, COMPUT GRAPH FORUM, V33, P281, DOI 10.1111/cgf.12384
   Weissenböck J, 2019, IEEE T VIS COMPUT GR, V25, P1040, DOI 10.1109/TVCG.2018.2864510
   Wentzel A, 2020, IEEE T VIS COMPUT GR, V26, P949, DOI 10.1109/TVCG.2019.2934546
   Wills G., 2008, Handbook of Data Vi- sualization, P217, DOI [DOI 10.1007/978-3-540-33037-0_10, 10.1007/978-3-540-33037-0_10]
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2018, COMPUT GRAPH FORUM, V37, P427, DOI 10.1111/cgf.13431
   Ye SN, 2021, IEEE T VIS COMPUT GR, V27, P860, DOI 10.1109/TVCG.2020.3030392
   Yu LY, 2010, IEEE T VIS COMPUT GR, V16, P1613, DOI 10.1109/TVCG.2010.157
   Zhang H, 2014, IEEE T VIS COMPUT GR, V20, P2575, DOI 10.1109/TVCG.2014.2346425
   Zhang H, 2012, IEEE T VIS COMPUT GR, V18, P2051, DOI 10.1109/TVCG.2012.242
   Zhou L, 2021, IEEE T VIS COMPUT GR, V27, P1591, DOI 10.1109/TVCG.2020.3030473
NR 162
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2888
EP 2902
DI 10.1109/TVCG.2024.3388516
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500012
PM 38648152
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, CJ
   Chen, JS
   Yang, WK
   Wang, HZ
   Knittel, J
   Zhao, XB
   Koch, S
   Ertl, T
   Liu, SX
AF Chen, Changjian
   Chen, Jiashu
   Yang, Weikai
   Wang, Haoze
   Knittel, Johannes
   Zhao, Xibin
   Koch, Steffen
   Ertl, Thomas
   Liu, Shixia
TI Enhancing Single-Frame Supervision for Better Temporal Action
   Localization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Location awareness; Annotations; Videos; Visualization; Noise
   measurement; Data visualization; Uncertainty; Single-frame supervision;
   storyline visualization; temporal action localization
ID BODY-MASS INDEX; VIDEO; ALGORITHM; PATTERNS
AB Temporal action localization aims to identify the boundaries and categories of actions in videos, such as scoring a goal in a football match. Single-frame supervision has emerged as a labor-efficient way to train action localizers as it requires only one annotated frame per action. However, it often suffers from poor performance due to the lack of precise boundary annotations. To address this issue, we propose a visual analysis method that aligns similar actions and then propagates a few user-provided annotations (e.g., boundaries, category labels) to similar actions via the generated alignments. Our method models the alignment between actions as a heaviest path problem and the annotation propagation as a quadratic optimization problem. As the automatically generated alignments may not accurately match the associated actions and could produce inaccurate localization results, we develop a storyline visualization to explain the localization results of actions and their alignments. This visualization facilitates users in correcting wrong localization results and misalignments. The corrections are then used to improve the localization results of other actions. The effectiveness of our method in improving localization performance is demonstrated through quantitative evaluation and a case study.
C1 [Chen, Changjian] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410012, Hunan, Peoples R China.
   [Chen, Jiashu; Yang, Weikai; Wang, Haoze; Zhao, Xibin; Liu, Shixia] Tsinghua Univ, Sch Software, BNRist, Beijing 100190, Peoples R China.
   [Knittel, Johannes; Koch, Steffen; Ertl, Thomas] Univ Stuttgart, D-70174 Stuttgart, Germany.
C3 Hunan University; Tsinghua University; University of Stuttgart
RP Liu, SX (corresponding author), Tsinghua Univ, Sch Software, BNRist, Beijing 100190, Peoples R China.
EM changjianchen@hnu.edu.cn; johannes.knittel@vis.uni-stuttgart.de;
   zxb@tsinghua.edu.cn; steffen.koch@vis.uni-stuttgart.de;
   Thomas.Ertl@vis.uni-stuttgart.de; shixia@tsinghua.edu.cn
RI Haoze, Wang/T-8717-2019; Yin, Zhaoxia/HRD-7425-2023; Chen,
   Changjian/KBA-9462-2024; Liu, Shi-Xia/C-5574-2016
OI Ertl, Thomas/0000-0003-4019-2505
FU National Natural Science Foundation of China
FX No Statement Available
CR Abu Farha Y, 2019, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2019.00369
   [Anonymous], 2006, 2006 IEEE COMPUTER S, DOI DOI 10.1109/CVPR.2006.284
   [Anonymous], 2012, P SIGCHI C HUM FACT, DOI [10.1145/2207676.22077672, DOI 10.1145/2207676.22077672, DOI 10.1145/2207676.2207767]
   Arias-Hernandez R., 2011, P IEEE HAW INT C SYS, P1, DOI DOI 10.1109/HICSS.2011.339
   Arora P, 2016, PROCEDIA COMPUT SCI, V78, P507, DOI 10.1016/j.procs.2016.02.095
   Botchen RP, 2008, IEEE T VIS COMPUT GR, V14, P885, DOI 10.1109/TVCG.2008.40
   Cao KD, 2020, PROC CVPR IEEE, P10615, DOI 10.1109/CVPR42600.2020.01063
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CJ, 2024, IEEE T VIS COMPUT GR, V30, P76, DOI 10.1109/TVCG.2023.3326588
   Chen CJ, 2022, IEEE T VIS COMPUT GR, V28, P1941, DOI 10.1109/TVCG.2021.3138933
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3335, DOI 10.1109/TVCG.2020.2973258
   Chen CJ, 2021, IEEE T VIS COMPUT GR, V27, P3701, DOI 10.1109/TVCG.2021.3084694
   Chen M, 2006, IEEE T VIS COMPUT GR, V12, P1093, DOI 10.1109/TVCG.2006.194
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Daniel G, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P409, DOI 10.1109/VISUAL.2003.1250401
   Duffy B, 2015, IEEE T VIS COMPUT GR, V21, P980, DOI 10.1109/TVCG.2013.265
   Elhamifar E, 2016, IEEE T PATTERN ANAL, V38, P2182, DOI 10.1109/TPAMI.2015.2511748
   Fan Ma, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P420, DOI 10.1007/978-3-030-58548-8_25
   FENG DF, 1987, J MOL EVOL, V25, P351, DOI 10.1007/BF02603120
   Haines O., 2014, BMVC, V2, P3
   Han Z, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4165, DOI 10.1145/3474085.3475549
   He JB, 2024, IEEE T VIS COMPUT GR, V30, P87, DOI 10.1109/TVCG.2023.3326586
   HELD M, 1962, J SOC IND APPL MATH, V10, P196, DOI 10.1137/0110015
   Höferlin M, 2013, IEEE T MULTIMEDIA, V15, P908, DOI 10.1109/TMM.2013.2238521
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Ji JW, 2019, IEEE I CONF COMP VIS, P7072, DOI 10.1109/ICCV.2019.00717
   Kurzhals K, 2017, IEEE T VIS COMPUT GR, V23, P301, DOI 10.1109/TVCG.2016.2598695
   Kurzhals K, 2016, IEEE T MULTIMEDIA, V18, P2149, DOI 10.1109/TMM.2016.2614184
   Lekschas F, 2020, COMPUT GRAPH FORUM, V39, P167, DOI 10.1111/cgf.13971
   Lewis D. D., 1995, SIGIR Forum, V29, P13, DOI 10.1145/219587.219592
   Li Z, 2021, PROC CVPR IEEE, P8361, DOI 10.1109/CVPR46437.2021.00826
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2023, COMPUTER, V56, P4, DOI 10.1109/MC.2023.3304568
   Liu SX, 2019, IEEE T VIS COMPUT GR, V25, P235, DOI 10.1109/TVCG.2018.2864843
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu XL, 2022, IEEE T IMAGE PROCESS, V31, P5427, DOI 10.1109/TIP.2022.3195321
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Ma B, 2018, IEEE T VIS COMPUT GR, V24, P3253, DOI 10.1109/TVCG.2017.2776935
   Ma CX, 2020, J COMPUT SCI TECH-CH, V35, P576, DOI 10.1007/s11390-020-0271-2
   Meghdadi AH, 2013, IEEE T VIS COMPUT GR, V19, P2119, DOI 10.1109/TVCG.2013.168
   Muller M., 2007, Information Retrieval for Music and Motion, P69, DOI 10.1007/978-3-540-74048-34
   Newby P, 2003, AM J CLIN NUTR, V77, P1417, DOI 10.1093/ajcn/77.6.1417
   Ono JP, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300293
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Reddy CK, 2014, CH CRC DATA MIN KNOW, P87
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Swift ME, 2023, IEEE T VIS COMPUT GR, V29, P171, DOI 10.1109/TVCG.2022.3209454
   Tan H.-K., 2009, P 17 ACM INT C MULTI, P145, DOI [10.1145/1631272.1631295, 10.1145/1631272]
   Tan H.-K., 2008, P ACM INT C MULT, P861, DOI DOI 10.1145/1459359.1459506
   Tan L, 2012, IEEE COMPUT GRAPH, V32, P46, DOI 10.1109/MCG.2011.89
   Tanahashi Y, 2012, IEEE T VIS COMPUT GR, V18, P2679, DOI 10.1109/TVCG.2012.212
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Togo P, 2001, INT J OBESITY, V25, P1741, DOI 10.1038/sj.ijo.0801819
   Wang X, 2021, PROC CVPR IEEE, P1905, DOI 10.1109/CVPR46437.2021.00194
   Wang Y., 2012, P ACM INT C MULT, P941, DOI [DOI 10.1145/2393347.23963525, 10.1145/2393347.2396352, DOI 10.1145/2393347.2396352]
   Wu AY, 2020, IEEE T VIS COMPUT GR, V26, P2429, DOI 10.1109/TVCG.2018.2889081
   Xia HF, 2020, IEEE ACCESS, V8, P70477, DOI 10.1109/ACCESS.2020.2986861
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang L, 2022, IEEE T PATTERN ANAL, V44, P9814, DOI 10.1109/TPAMI.2021.3132058
   Yang WK, 2024, COMPUT VIS MEDIA, V10, P399, DOI 10.1007/s41095-023-0393-x
   Yang WK, 2022, IEEE T VIS COMPUT GR, V28, P3292, DOI 10.1109/TVCG.2022.3182488
   Yu Yuncong, 2023, IEEE Trans Vis Comput Graph, V29, P33, DOI 10.1109/TVCG.2022.3209431
   Zeng HP, 2021, IEEE T VIS COMPUT GR, V27, P3168, DOI 10.1109/TVCG.2019.2963659
   Zeng HP, 2020, IEEE T VIS COMPUT GR, V26, P927, DOI 10.1109/TVCG.2019.2934656
   Zhang CL, 2022, LECT NOTES COMPUT SC, V13664, P492, DOI 10.1007/978-3-031-19772-7_29
   Zhao PN, 2021, AAAI CONF ARTIF INTE, V35, P11007
   Zhao T, 2023, IEEE T PATTERN ANAL, V45, P3019, DOI 10.1109/TPAMI.2022.3178957
   Zhu X., 2005, PhD thesis
NR 69
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2903
EP 2915
DI 10.1109/TVCG.2024.3388521
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500008
PM 38619947
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, XJ
   Liu, QH
   Chen, YH
   Wang, RH
   You, Y
   Deng, WX
   Chen, W
   Wang, XS
AF Chen, Xiaojiao
   Liu, Qinghua
   Chen, Yonghao
   Wang, Ruihan
   You, Yang
   Deng, Wanxin
   Chen, Wei
   Wang, Xiaosong
TI ColorNetVis: An Interactive Color Network Analysis System for Exploring
   the Color Composition of Traditional Chinese Painting
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Painting; Visualization; Humanities; Shape;
   Clothing; Analytical models; Color analysis; color network; traditional
   chinese painting; visual analytic
ID DIFFERENCE
AB In the field of digital humanities, color research aims to discover explanations for painting history and color usage habits. However, researchers analyzing color relationships is challenging and time-consuming, as it requires color extraction and a detailed review of many painting images for reference and comparison of color relationships. In our work, we propose ColorNetVis, an interactive color network analysis tool that enables researchers to explore color relationships through color networks. The core of ColorNetVis is a bipartite network model that establishes a bipartite relationship between colors and Chinese painting within a scope based on color difference measurement. It constructs a one-mode color network through projection algorithms and similarity calculation methods to discover the relationship between colors. We propose a coordinated set of views to demonstrate the combination of determined color networks with painting types and real-world attributes. We use color space view, color attribute distribution view, and single color query components to assist researchers in conducting detailed color analysis and validation. Through case studies, researcher reviews, and user studies, we demonstrate that ColorNetVis can effectively help researchers discover knowledge of color relationships and potential color research directions.
C1 [Chen, Xiaojiao; Liu, Qinghua; Chen, Yonghao; Wang, Ruihan; You, Yang; Deng, Wanxin; Chen, Wei; Wang, Xiaosong] Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310000, Peoples R China.
   [Chen, Wei] Zhejiang Univ, State Key Lab, CAD & CG, Hangzhou 310000, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Chen, W; Wang, XS (corresponding author), Zhejiang Univ, Lab Art & Archaeol Image, Minist Educ, Hangzhou 310000, Peoples R China.
EM chenxiaojiao@zju.edu.cn; yazawaninico@163.com; chenyonghao@zju.edu.cn;
   ruihanwang@zju.edu.cn; 937659529@qq.com; 272293209@qq.com;
   chenvis@zju.edu.cn; wang64@zju.edu.cn
RI Chen, Wei/AAR-9817-2020; Chen, YongHao/KVB-1170-2024; 刘,
   清华/ABD-9106-2021
OI Chen, Wei/0000-0002-8365-4741; Liu, Qinghua/0000-0003-4644-5518; Chen,
   Yonghao/0000-0001-8960-6698
FU Interdisciplinary planning of philosophy and social sciences in Zhejiang
   Province [22JCXK03Z]; Major Projects of the National Social Science
   Foundation [19ZDA046]
FX This work was supported in part by the Key support project for
   interdisciplinary planning of philosophy and social sciences in Zhejiang
   Province under Grant 22JCXK03Z, and in part by the Major Projects of the
   National Social Science Foundation under Grant 19ZDA046. Recommended for
   acceptance by N. Elmqvist, S. Liu, and V. Pascucci.
CR Bonacich P, 2007, SOC NETWORKS, V29, P555, DOI 10.1016/j.socnet.2007.04.002
   Chan C, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P403, DOI 10.1109/PCCGA.2002.1167884
   Chang Y, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-021-0482-x
   Chunaev P, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100286
   Feng ZL, 2018, NEUROCOMPUTING, V273, P395, DOI 10.1016/j.neucom.2017.07.043
   Flueckiger B, 2020, DIGIT HUMANITIES Q, V14
   Flueckiger B, 2017, MOV IMAGE, V17, P71
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Goldsmith L.T., 1992, Creativity Research Journal, V5, P281, DOI DOI 10.1080/10400419209534441
   Guancan Yang, 2021, Diversity, Divergence, Dialogue. 16th International Conference, iConference 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12645), P490, DOI 10.1007/978-3-030-71292-1_38
   Guillaume JL, 2006, PHYSICA A, V371, P795, DOI 10.1016/j.physa.2006.04.047
   Haghani S, 2019, ARTIF INTELL REV, V52, P1961, DOI 10.1007/s10462-017-9590-2
   Hu Dongfang., 1995, International Journal of Politics, Culture, and Society, V8, P453
   Jiang SQ, 2006, PATTERN RECOGN LETT, V27, P734, DOI 10.1016/j.patrec.2005.10.017
   Jin Z, 2023, FRONT INFORM TECH EL, V24, P1416, DOI 10.1631/FITEE.2200662
   Jingwena C., 2023, DESIGN STUDIES INTEL, V365, DOI [10.3233/fain220707, DOI 10.3233/FAIN220707]
   Johnson GM, 2010, COLOR RES APPL, V35, P387, DOI 10.1002/col.20561
   Kaneko A, 2020, VIS COMPUT IND BIOME, V3, DOI 10.1186/s42492-019-0040-7
   Kumar A, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124289
   Li M, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2021.12.006
   Li R, 2022, VIS INFORM, V6, P35, DOI 10.1016/j.visinf.2022.02.002
   Li Yu, 2019, Computer Integrated Manufacturing Systems, V25, P2355, DOI 10.13196/j.cims.2019.09.022
   Liang K., 2021, Front. Art Res., V3, DOI [10.25236/FAR.2021.030101, DOI 10.25236/FAR.2021.030101]
   Liu XJ, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-1437-6
   Liu Xiaojian, 2016, Computer Integrated Manufacturing Systems, V22, P899, DOI 10.13196/j.cims.2016.04.003
   Lonapalawong S, 2022, FRONT INFORM TECH EL, V23, P382, DOI 10.1631/FITEE.2000596
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   Mao X, 2023, VIS INFORM, V7, P110, DOI 10.1016/j.visinf.2023.10.006
   Pei SC, 2004, IEEE T IMAGE PROCESS, V13, P414, DOI 10.1109/TIP.2003.821347
   Pei SC, 2006, IEEE T IMAGE PROCESS, V15, P3230, DOI 10.1109/TIP.2006.877478
   Sari C, 2019, DIGIT SCHOLARSH HUM, V34, P156, DOI 10.1093/llc/fqz055
   SILBERGELD J, 1987, ART J, V46, P103, DOI 10.2307/776887
   Stepanova E, 2019, EMPIR ECON, V56, P755, DOI 10.1007/s00181-017-1413-4
   Szafir DA, 2018, IEEE T VIS COMPUT GR, V24, P392, DOI 10.1109/TVCG.2017.2744359
   Thudt Alice, 2012, P SIGCHI C HUM FACT, P1461, DOI DOI 10.1145/2207676.2208607
   Vartija DevinJ., 2021, COLOR EQUALITY RACE
   Wu MG, 2022, CARTOGR GEOGR INF SC, V49, P289, DOI 10.1080/15230406.2021.1982009
   Xu BQ, 2019, COLOR RES APPL, V44, P205, DOI 10.1002/col.22339
   Xu H, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581429
   [徐明慧 Xu Minghui], 2021, [纺织学报, Journal of Textile Research], V42, P137
   Yu R., 2022, P INT C MACH LEARN C, P251, DOI [10.1007/978-3-031-20102-8_20, DOI 10.1007/978-3-031-20102-8_20]
   Yun SA, 2019, COLOR RES APPL, V44, P115, DOI 10.1002/col.22288
   Zhang Chenyang, 2023, IEEE Trans Vis Comput Graph, V29, P767, DOI 10.1109/TVCG.2022.3209440
   Zhang JL, 2017, ADV INTEL SYS RES, V132, P300
   Zhang M, 2024, FRONT COMPUT SCI-CHI, V18, DOI 10.1007/s11704-022-2336-6
   Zhang Wei, 2023, IEEE Trans Vis Comput Graph, V29, P756, DOI 10.1109/TVCG.2022.3209483
   Zhejiang University A, 2022, Comprehensive collection of ancient chinese paintings in national museum exhibition
   Zhou T, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.046115
   Zhu BT, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1942046
   Zweig KA, 2011, SOC NETW ANAL MIN, V1, P187, DOI 10.1007/s13278-011-0021-0
NR 50
TC 0
Z9 0
U1 14
U2 14
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2916
EP 2928
DI 10.1109/TVCG.2024.3388520
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500006
PM 38619944
DA 2024-11-06
ER

PT J
AU Rodrigues, N
   Dennig, FL
   Brandt, V
   Keim, DA
   Weiskopf, D
AF Rodrigues, Nils
   Dennig, Frederik L.
   Brandt, Vincent
   Keim, Daniel A.
   Weiskopf, Daniel
TI Comparative Evaluation of Animated Scatter Plot Transitions
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Animation; Data visualization; Task analysis; Three-dimensional
   displays; Visual analytics; Splines (mathematics); Shape; Visualization;
   scatter plot; animation; quantitative user study; multidimensional data;
   coordinated and multiple views
AB Scatter plots are popular for displaying 2D data, but in practice, many data sets have more than two dimensions. For the analysis of such multivariate data, it is often necessary to switch between scatter plots of different dimension pairs, e.g., in a scatter plot matrix (SPLOM). Alternative approaches include a "grand tour" for an overview of the entire data set or creating artificial axes from dimensionality reduction (DR). A cross-cutting concern in all techniques is the ability of viewers to find correspondence between data points in different views. Previous work proposed animations to preserve the mental map between view changes and to trace points as well as clusters between scatter plots of the same underlying data set. In this article, we evaluate a variety of spline- and rotation-based view transitions in a crowdsourced user study focusing on ecological validity. Using the study results, we assess each animation's suitability for tracing points and clusters across view changes. We evaluate whether the order of horizontal and vertical rotation is relevant for task accuracy. The results show that rotations with an orthographic camera or staged expansion of a depth axis significantly outperform all other animation techniques for the traceability of individual points. Further, we provide a ranking of the animated transition techniques for traceability of individual points. However, we could not find any significant differences for the traceability of clusters. Furthermore, we identified differences by animation direction that could guide further studies to determine potential confounds for these differences. We publish the study data for reuse and provide the animation framework as a D3.js plug-in.
C1 [Rodrigues, Nils; Keim, Daniel A.] Univ Stuttgart, Visualizat Res Ctr VISUS, D-70174 Stuttgart, Germany.
   [Dennig, Frederik L.; Keim, Daniel A.] Univ Konstanz, D-78464 Constance, Germany.
   [Brandt, Vincent] Univ Stuttgart, Stuttgart, Germany.
C3 University of Stuttgart; University of Konstanz; University of Stuttgart
RP Rodrigues, N (corresponding author), Univ Stuttgart, Visualizat Res Ctr VISUS, D-70174 Stuttgart, Germany.
EM nils.rodrigues@visus.uni-stuttgart.de;
   frederik.l.dennig@uni-konstanz.de; st161848@stud.uni-stuttgart.de;
   daniel.a.keim@uni-konstanz.de; daniel.weiskopf@visus.uni-stuttgart.de
RI Dennig, Frederik/HTL-3123-2023; Weiskopf, Daniel/KWT-7459-2024
OI Weiskopf, Daniel/0000-0003-1174-1026; Rodrigues,
   Nils/0000-0002-1485-8249; Dennig, Frederik L./0000-0003-1116-8450
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Amazon Mechanical Turk Inc, Amazon mechanical turk
   [Anonymous], 1988, Dynamic Graphics for Statistics
   ARMSTRONG RL, 1987, PERCEPT MOTOR SKILL, V64, P359, DOI 10.2466/pms.1987.64.2.359
   ASIMOV D, 1985, SIAM J SCI STAT COMP, V6, P128, DOI 10.1137/0906011
   Baudisch Patrick., 2001, 14 ANN ACM S USER IN, P31, DOI DOI 10.1145/502348.502354
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandt V., 2024, D3-plugin for animated scatter plot transi- tions
   Brehmer M, 2020, IEEE T VIS COMPUT GR, V26, P364, DOI 10.1109/TVCG.2019.2934397
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472
   Chevalier F, 2014, IEEE T VIS COMPUT GR, V20, P2241, DOI 10.1109/TVCG.2014.2346424
   Chyung S. Y. Y., 2020, Perform. Improvement, V59, P6, DOI DOI 10.1002/PFI.21920
   Dragicevic P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2009
   Drucker S., 2015, Tech. Rep. MSR-TR-2015-65
   Du F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P289
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Faul F, 2009, BEHAV RES METHODS, V41, P1149, DOI 10.3758/BRM.41.4.1149
   Footovision, 2023, Footovision: Level up your game
   Gadhave K, 2021, INFORM VISUAL, V20, P207, DOI 10.1177/14738716211038604
   Guo Y, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13179709
   Haji-Abolhassani A, 2013, J VISION, V13, DOI 10.1167/13.3.29
   HART S G, 1988, P139
   Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539
   Jolliffe T., 2002, Principal Component Analysis, DOI [10.1007/698835, DOI 10.1007/698835]
   Kim Y, 2019, COMPUT GRAPH FORUM, V38, P541, DOI 10.1111/cgf.13709
   Kriglstein S., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P30, DOI 10.1109/IV.2012.16
   Mcilreavy L, 2019, TRANSL VIS SCI TECHN, V8, DOI 10.1167/tvst.8.5.7
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   MILLER GA, 1956, IRE T INFORM THEOR, V2, P129, DOI 10.1109/TIT.1956.1056815
   Nakakoji K, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P77, DOI 10.1109/IV.2001.942042
   Perin C, 2018, IEEE T VIS COMPUT GR, V24, P698, DOI 10.1109/TVCG.2017.2743918
   Prolific Academic Ltd, 2001, Prolific - Quickly find research participants you can trust
   Purves D., 2001, Neuroscience, V2nd ed
   Nguyen QV, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.09.004
   Quinlan JR, 1993, P 10 INT C MACH LEAR, P236, DOI DOI 10.1016/B978-1-55860-307-3.50037-X
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   ROBINSON DA, 1965, J PHYSIOL-LONDON, V180, P569, DOI 10.1113/jphysiol.1965.sp007718
   Rodrigues N., 2024, Interactive demo of study: Evaluation of animated scat- ter plot transitions
   Rodrigues N., 2024, DaRUS, DOI [10.18419/darus-3451, DOI 10.18419/DARUS-3451]
   Rodrigues N., 2020, P GRAPH INT C, P382, DOI [10.20380/G12020.38, DOI 10.20380/G12020.38]
   Rodrigues N., 2022, OSF Preregistration, DOI [10.17605/OSE.IO/3E6G4, DOI 10.17605/OSE.IO/3E6G4]
   Rottach KG, 1996, VISION RES, V36, P2189, DOI 10.1016/0042-6989(95)00302-9
   Sanftmann H, 2012, IEEE T VIS COMPUT GR, V18, P1969, DOI 10.1109/TVCG.2012.35
   Schulz C, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P112, DOI 10.1145/2993901.2993907
   Stiftelsen Gapminder, Gapminder tools
   Taylor T., 2010, ENCY RES DESIGN, P133, DOI [DOI 10.4135/9781412961288.N44, 10.4135/9781412961288.n44.]
   Tekusová T, 2007, IEEE INT CONF INF VI, P101
   Thomas JG, 2022, PSYCHOTHER RES, V32, P128, DOI 10.1080/10503307.2021.1909770
   Tominski C, 2021, VIS INFORM, V5, P28, DOI 10.1016/j.visinf.2021.06.004
   Utts J.M., 2005, SEEING STAT
   Wang Y, 2018, IEEE T VIS COMPUT GR, V24, P2487, DOI 10.1109/TVCG.2017.2750689
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
NR 53
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2929
EP 2941
DI 10.1109/TVCG.2024.3388558
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500011
PM 38625781
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Koval, M
   Jansen, Y
   Chevalier, F
AF Koval, Morgane
   Jansen, Yvonne
   Chevalier, Fanny
TI Animating Hypothetical Trips to Communicate Space-Based Temporal
   Uncertainty on Digital Maps
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Uncertainty; Animation; Visualization; Data visualization; Task
   analysis; Substrates; Geometry; geospatial visualization; hypothetical
   outcome plot; uncertainty visualization
ID TIME; VISUALIZATION; PERCEPTION; PATTERNS; MOVEMENT
AB This paper explores a novel approach to communicating plausible space-based temporal variability of travel durations. Digital maps most often only convey single numerical values as the estimated duration for a path and this piece of information does not account for the multiple scenarios hidden behind this point estimate, nor for the temporal uncertainty along the route (e.g., the likelihood of being slowed down at an intersection). We explore conveying this uncertainty by animating hypothetical trips onto maps in the form of moving dots along one or more paths. We conducted a study with 16 participants and observed that they were able to correctly extract and infer simple information from our uncertainty visualizations but that identifying moving dots' changes in speed is a more complex task. We discuss design challenges and implications for future visualizations of space-based temporal uncertainty.
C1 [Koval, Morgane] Univ Bordeaux, Inria Ctr, F-33000 Bordeaux, France.
   [Jansen, Yvonne] Univ Bordeaux, CNRS, Inria, LaBRI, F-33000 Bordeaux, France.
   [Chevalier, Fanny] Univ Toronto, Toronto, ON M5S 1A1, Canada.
C3 Universite de Bordeaux; Universite de Bordeaux; Inria; Centre National
   de la Recherche Scientifique (CNRS); University of Toronto
RP Koval, M (corresponding author), Univ Bordeaux, Inria Ctr, F-33000 Bordeaux, France.
EM morgane.koval@inria.fr; yvonne.jansen@cnrs.fr; fanny@cs.toronto.edu
RI Jansen, Yvonne/A-9998-2015
OI Jansen, Yvonne/0000-0001-5092-551X; Chevalier, Fanny/0000-0002-5585-7971
FU ANR Ember
FX No Statement Available
CR Aerts C.J. H. J., 2003, Cartography and Geographic Information Science, V30, P249, DOI [DOI 10.1559/152304003100011180, 10.1559/152304003100011180 10.1559/152304003100011180]
   Amini F, 2015, IEEE T VIS COMPUT GR, V21, P122, DOI 10.1109/TVCG.2014.2329308
   Andrienko G., 2004, P WORK C ADV VIS INT, P417, DOI DOI 10.1145/989863.989940
   Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   Andrienko N, 2013, INFORM VISUAL, V12, P3, DOI 10.1177/1473871612457601
   [Anonymous], 2007, Cartogr Int J Geogr Inf Geovisualization, DOI [10.3138/carto.42.4.349, DOI 10.3138/CARTO.42.4.349]
   Bach B, 2015, COMPUT GRAPH FORUM, V34, P31, DOI 10.1111/cgf.12615
   Bach B, 2016, IEEE T VIS COMPUT GR, V22, P559, DOI 10.1109/TVCG.2015.2467851
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   Bach C., 2018, P 5 BIENN TRANSD IM, P1, DOI [10.6084/m9.figshare.6104705.8B, DOI 10.6084/M9.FIGSHARE.6104705.8B]
   Bartram L., 1997, P WORKSH NEW PAR INF, P3
   Bartram L., 2009, P 5 EUR C COMP AESTH, P129, DOI DOI 10.2312/COMPAESTH/COMPAESTH09/129-136
   Bartram L. R., 2001, PhD thesis
   Bertin J., 1983, Semiology of Graphics
   Bies Sandra, 2013, Graph Drawing. 20th International Symposium, GD 2012. Revised Selected Papers, P511, DOI 10.1007/978-3-642-36763-2_45
   Bilbily Vicky, 2021, 34 ANN ACM S USER IN, P484, DOI [10.1145/3472749.3474764, DOI 10.1145/3472749.3474764]
   Blenkinsop S., 2000, Cartographica: Int. J. Geographic Inf. Geovisualization, V37, P1, DOI [10.3138/3645-4V22-0M23-3T52, DOI 10.3138/3645-4V22-0M23-3T52]
   Boyandin I, 2012, COMPUT GRAPH FORUM, V31, P1005, DOI 10.1111/j.1467-8659.2012.03093.x
   Brosz J., 2013, P 26 ANN ACM S USER, P97
   Buchin K, 2014, LECT NOTES COMPUT SC, V8728, P18, DOI 10.1007/978-3-319-11593-1_2
   Buschmann S, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P174, DOI 10.1109/CW.2014.32
   Chevalier F., 2016, P INT WORK C ADY VIS, P280, DOI DOI 10.1145/2909132.2909255
   Deitrick S, 2015, ANN ASSOC AM GEOGR, V105, P531, DOI 10.1080/00045608.2015.1012635
   Ehlschlaeger CR, 1997, COMPUT GEOSCI, V23, P387, DOI 10.1016/S0098-3004(97)00005-8
   Evans BJ, 1997, COMPUT GEOSCI, V23, P409, DOI 10.1016/S0098-3004(97)00011-3
   Fekete JD, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P289
   Fernandes M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173718
   Fish C, 2011, CARTOGR GEOGR INF SC, V38, P350, DOI 10.1559/15230406384350
   Gatalsky P, 2004, IEEE INFOR VIS, P145, DOI 10.1109/IV.2004.1320137
   Goldsberry K., 2009, Cartographica, V44, P201
   Griffin AL, 2006, ANN ASSOC AM GEOGR, V96, P740, DOI 10.1111/j.1467-8306.2006.00514.x
   Gschwandtner T, 2016, IEEE T VIS COMPUT GR, V22, P539, DOI 10.1109/TVCG.2015.2467752
   Han PKJ, 2012, PATIENT EDUC COUNS, V86, P106, DOI 10.1016/j.pec.2011.01.033
   Harrower M., 2007, The Cartographic Journal, V44, P313
   Hong S, 2017, IEEE PAC VIS SYMP, P81, DOI 10.1109/PACIFICVIS.2017.8031582
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Kaiser C, 2010, LECT NOTES COMPUT SC, V6292, P85, DOI 10.1007/978-3-642-15300-6_7
   Kale A, 2019, IEEE T VIS COMPUT GR, V25, P892, DOI 10.1109/TVCG.2018.2864909
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kinkeldey C, 2014, CARTOGR J, V51, P372, DOI 10.1179/1743277414Y.0000000099
   Koval M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502010
   Kraak Menno-Jan, P 21 INT CART C, P1988
   Liu L, 2017, IEEE T VIS COMPUT GR, V23, P2165, DOI 10.1109/TVCG.2016.2607204
   MacEachren A. M., 1992, Cartographic Perspectives, V13, P10, DOI [10.14714/CP13.1000 10.14714/CP13.1000, DOI 10.14714/CP13.1000]
   Nagel T, 2017, LEONARDO, V50, P511, DOI 10.1162/LEON_a_01234
   Padilla M. Kay, 2021, Uncertainty Visualization, P1, DOI [10.1002/9781118445112.stat08296.48C, DOI 10.1002/9781118445112.STAT08296.48C]
   Perin C, 2018, IEEE T VIS COMPUT GR, V24, P698, DOI 10.1109/TVCG.2017.2743918
   Preston A, 2023, IEEE T VIS COMPUT GR, V29, P3746, DOI 10.1109/TVCG.2022.3171443
   Rhee I, 2011, IEEE ACM T NETWORK, V19, P630, DOI 10.1109/TNET.2011.2120618
   Robertson G, 2008, IEEE T VIS COMPUT GR, V14, P1325, DOI 10.1109/TVCG.2008.125
   Rosling H, 2011, J EPIDEMIOL GLOB HEA, V1, P11, DOI 10.1016/j.jegh.2011.07.001
   Scheepens R, 2016, IEEE T VIS COMPUT GR, V22, P379, DOI 10.1109/TVCG.2015.2467112
   Spiegelhalter D, 2017, ANNU REV STAT APPL, V4, P31, DOI 10.1146/annurev-statistics-010814-020148
   Talbot J, 2014, IEEE T VIS COMPUT GR, V20, P2152, DOI 10.1109/TVCG.2014.2346320
   Tang Anthony., 2008, AVI '08: Proceedings of the Working Conference on Advanced Visual Interfaces 2008, P191, DOI DOI 10.1145/1385569.1385601
   Thompson W., 1996, Cartographica: The International Journal for Geographic Information and Geovisualization, V33, P17
   Xie LWH, 2024, IEEE T VIS COMPUT GR, V30, P5198, DOI 10.1109/TVCG.2023.3286392
   Yusof N, 2016, INT J GEOGR INF SCI, V30, P1486, DOI 10.1080/13658816.2015.1135928
NR 59
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2942
EP 2954
DI 10.1109/TVCG.2024.3388517
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500014
PM 38619949
OA Green Published
DA 2024-11-06
ER

PT J
AU Wang, JC
   Ma, J
   Zhou, Z
   Xie, X
   Zhang, H
   Wu, YC
   Qu, HM
AF Wang, Jiachen
   Ma, Ji
   Zhou, Zheng
   Xie, Xiao
   Zhang, Hui
   Wu, Yingcai
   Qu, Huamin
TI TacPrint: Visualizing the Biomechanical Fingerprint in Table Tennis
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Biomechanics; Sports; Fingerprint recognition; Biological system
   modeling; Data visualization; Machine learning; Feature extraction; Data
   transformation; biomechanical data; machine learning
ID INTERACTIVE VISUALIZATION; RACKET SPORTS; PRESSURE; VIDEO
AB Table tennis is a sport that demands high levels of technical proficiency and body coordination from players. Biomechanical fingerprints can provide valuable insights into players' habitual movement patterns and characteristics, allowing them to identify and improve technical weaknesses. Despite the potential, few studies have developed effective methods for generating such fingerprints. To address this gap, we propose TacPrint, a framework for generating a biomechanical fingerprint for each player. TacPrint leverages machine learning techniques to extract comprehensive features from biomechanics data collected by inertial measurement units (IMU) and employs the attention mechanism to enhance model interpretability. After generating fingerprints, TacPrint provides a visualization system to facilitate the exploration and investigation of these fingerprints. In order to validate the effectiveness of the framework, we designed an experiment to evaluate the model's performance and conducted a case study with the system. The results of our experiment demonstrated the high accuracy and effectiveness of the model. Additionally, we discussed the potential of TacPrint to be extended to other sports.
C1 [Wang, Jiachen; Ma, Ji; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Zhou, Zheng; Xie, Xiao; Zhang, Hui] Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
   [Qu, Huamin] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang University; Hong Kong University of
   Science & Technology
RP Xie, X (corresponding author), Zhejiang Univ, Dept Sports Sci, Hangzhou 310027, Peoples R China.
EM wangjiachen@zju.edu.cn; zjumaji@zju.edu.cn; zheng.zhou@zju.edu.cn;
   xxie@zju.edu.cn; zhang_hui@zju.edu.cn; ycwu@zju.edu.cn;
   huamin@cse.ust.hk
RI 张, 智浩/KIC-8136-2024
OI , Hui/0000-0003-0601-3905; Ma, Ji/0000-0002-9018-4047; Wang,
   Jiachen/0000-0001-9630-9958
FU NSFC
FX No Statement Available
CR Andrienko G, 2017, DATA MIN KNOWL DISC, V31, P1793, DOI 10.1007/s10618-017-0513-2
   Bernard J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P217, DOI 10.5220/0006127502170224
   Blank P, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P2, DOI 10.1145/3123021.3123040
   Blank P, 2015, ISWC 2015: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P93, DOI 10.1145/2802083.2802087
   Borgo R., 2013, P EUR, P39, DOI [DOI 10.2312/CONF/EG2013/STARS/039-063, 10.2312/conf/EG2013/stars/039-063]
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen W, 2016, IEEE T MULTIMEDIA, V18, P2247, DOI 10.1109/TMM.2016.2614221
   Chen Zhutian, 2023, IEEE Trans Vis Comput Graph, V29, P918, DOI 10.1109/TVCG.2022.3209497
   Chung DHS, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.25
   Chung DHS, 2015, INFORM VISUAL, V14, P76, DOI 10.1177/1473871613511959
   Deng Dazhen, 2023, IEEE Trans Vis Comput Graph, V29, P690, DOI 10.1109/TVCG.2022.3209468
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Deng ZK, 2024, IEEE T VIS COMPUT GR, V30, P1194, DOI 10.1109/TVCG.2023.3327162
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Fu FQ, 2016, INT J SPORTS SCI COA, V11, P559, DOI 10.1177/1747954116654778
   Goldsberry Kirk., 2012, 2012 MIT Sloan Sports Analytics Conference, V9, P12
   Gravenhorst F., 2015, INT J COMPUT SCI SPO, V14, P4
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   He YQ, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9080336
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Ibrahim N, 2022, SPORT BIOMECH, V21, P1065, DOI 10.1080/14763141.2020.1726995
   Iino Y, 2017, HUM MOVEMENT SCI, V56, P98, DOI 10.1016/j.humov.2017.10.021
   Iino Y, 2016, J SPORT SCI, V34, P721, DOI 10.1080/02640414.2015.1069377
   Iino Y, 2011, SPORT BIOMECH, V10, P361, DOI 10.1080/14763141.2011.629304
   Iino Y, 2009, J SPORT SCI, V27, P1311, DOI 10.1080/02640410903264458
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Jino Y., 2018, ISBS Proc. Arch., V36
   Ke GL, 2017, ADV NEUR IN, V30
   Lam WK, 2019, EUR J SPORT SCI, V19, P471, DOI 10.1080/17461391.2018.1534993
   Lees A, 2003, J SPORT SCI, V21, P707, DOI 10.1080/0264041031000140275
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Legg PA, 2013, IEEE T VIS COMPUT GR, V19, P2109, DOI 10.1109/TVCG.2013.207
   Letarte Gael, 2018, P EMNLP WORKSH BLACK, P267, DOI DOI 10.18653/V1/W18-5429
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Lu SS, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/9958256
   Ma RJ, 2018, 2018 IEEE 1ST INTERNATIONAL CONFERENCE ON MICRO/NANO SENSORS FOR AI, HEALTHCARE, AND ROBOTICS (NSENS), P73, DOI 10.1109/NSENS.2018.8713634
   Mitsui T, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND UBIQUITOUS NETWORKING (ICMU), P100, DOI 10.1109/ICMU.2015.7061049
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Perin C, 2016, IEEE COMPUT GRAPH, V36, P38, DOI 10.1109/MCG.2016.100
   Polk T, 2014, IEEE T VIS COMPUT GR, V20, P2339, DOI 10.1109/TVCG.2014.2346445
   Rusu A, 2010, IEEE INT CONF INF VI, P207, DOI 10.1109/IV.2010.39
   Sisneros R., 2013, P 1 WORKSH SPORTS DA
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Stein M, 2015, ISPRS INT J GEO-INF, V4, P2159, DOI 10.3390/ijgi4042159
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang JC, 2021, IEEE T VIS COMPUT GR, V27, P2770, DOI 10.1109/TVCG.2021.3074576
   Wang JC, 2020, IEEE T VIS COMPUT GR, V26, P407, DOI 10.1109/TVCG.2019.2934630
   Wang YF, 2018, IEEE INTERNET THINGS, V5, P4558, DOI 10.1109/JIOT.2018.2837347
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11
   Wong DWC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155203
   Wongsuphasawat K, 2012, IEEE T VIS COMPUT GR, V18, P2659, DOI 10.1109/TVCG.2012.225
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wu J, 2022, IEEE T VIS COMPUT GR, V28, P835, DOI 10.1109/TVCG.2021.3114832
   Wu Yihong, 2023, IEEE Trans Vis Comput Graph, V29, P929, DOI 10.1109/TVCG.2022.3209373
   Wu Y, 2018, IEEE T VIS COMPUT GR, V24, P709, DOI 10.1109/TVCG.2017.2744218
   Xia K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061638
   Xie X, 2021, IEEE T VIS COMPUT GR, V27, P1322, DOI 10.1109/TVCG.2020.3030359
   Yang WK, 2024, COMPUT VIS MEDIA, V10, P399, DOI 10.1007/s41095-023-0393-x
   Yao LJ, 2022, IEEE T VIS COMPUT GR, V28, P3546, DOI 10.1109/TVCG.2022.3184993
   Yu CX, 2018, PEERJ, V6, DOI 10.7717/peerj.4760
   Zhou ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3553
NR 66
TC 0
Z9 0
U1 6
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2955
EP 2967
DI 10.1109/TVCG.2024.3388555
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500010
PM 38619948
DA 2024-11-06
ER

PT J
AU Lu, M
   Zeng, XF
   Lanir, J
   Sun, XQ
   Li, GZ
   Cohen-Or, D
   Huang, H
AF Lu, Min
   Zeng, Xiangfang
   Lanir, Joel
   Sun, Xiaoqin
   Li, Guozheng
   Cohen-Or, Daniel
   Huang, Hui
TI Sticky Links: Encoding Quantitative Data of Graph Edges
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Encoding; Layout; Shape; Clutter; Graph drawing;
   Uncertainty; Graph visualization; edge drawing; quantitative encoding
ID OF-THE-ART; VISUALIZATION; LAYOUT
AB Visually encoding quantitative information associated with graph links is an important problem in graph visualization. A conventional approach is to vary the thickness of lines to encode the strength of connections in node-link diagrams. In this paper, we present Sticky Links, a novel visual encoding method that draws graph links with stickiness. Taking the metaphor of links with glues, sticky links represent connection strength using spiky shapes, ranging from two broken spikes for weak connections to connected lines for strong connections. We conducted a controlled user study to compare the efficiency and aesthetic appeal of stickiness with conventional thickness encoding. Our results show that stickiness enables more effective and expressive quantitative encoding while maintaining the perception of node connectivity. Participants also found sticky links to be more aesthetic and less visually cluttering than conventional thickness encoding. Overall, our findings suggest that sticky links offer a promising alternative to conventional methods for encoding quantitative information in graphs.
C1 [Lu, Min; Zeng, Xiangfang; Sun, Xiaoqin; Huang, Hui] Shenzhen Univ, Shenzhen 518060, Peoples R China.
   [Lanir, Joel] Univ Haifa, IL-3498838 H_efa, Israel.
   [Li, Guozheng] Beijing Inst Technol, Beijing 100811, Peoples R China.
   [Cohen-Or, Daniel] Tel Aviv Univeristy, IL-6997801 Tel Aviv, Israel.
C3 Shenzhen University; University of Haifa; Beijing Institute of
   Technology
RP Huang, H (corresponding author), Shenzhen Univ, Shenzhen 518060, Peoples R China.
EM lumin.vis@gmail.com; xiangfangzeng15@gmail.com; ylanir@is.haifa.il;
   ssharonqin@gmail.com; guozheng.li@bit.edu.cn; cohenor@gmail.com;
   hhzhiyan@gmail.com
RI Huang, Hui/JGB-1049-2023
OI Huang, Hui/0000-0003-3212-0544; Li, Guozheng/0000-0001-6663-6712
FU NSFC
FX No Statement Available
CR Abello J, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P183, DOI 10.1109/INFVIS.2004.46
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Baur M, 2004, LECT NOTES COMPUT SC, V3353, P332
   BECKER RA, 1995, IEEE T VIS COMPUT GR, V1, P16, DOI 10.1109/2945.468391
   Bennett C., 2007, P EUR C COMP AESTH G, P57, DOI [10.2312/compaesth/compaesth07/057-064, DOI 10.2312/COMPAESTH/COMPAESTH07/057-064]
   Binucci C., 2016, 2016 P 7 INT C INF I, P1
   Bludau Mark-Jan, 2021, EuroVis 2021-Posters, P3, DOI [10.2312/evp.20211070, DOI 10.2312/EVP.20211070]
   Bruckdorfer Till, 2012, Fun with Algorithms. Proceedings 6th International Conference (FUN 2012), P40, DOI 10.1007/978-3-642-30347-0_7
   Bruckdorfer T., 2012, P INT S GRAPH DRAW, P67
   Burch M, 2014, IEEE INT CONF INF VI, P53, DOI 10.1109/IV.2014.45
   Burch M, 2017, IEEE INT CON INF VIS, P199, DOI 10.1109/iV.2017.43
   Burch M, 2012, LECT NOTES COMPUT SC, V7034, P226
   Buschel W., 2018, P CHI WORKSH DAT VIS
   Buschmann S, 2016, VISUAL COMPUT, V32, P371, DOI 10.1007/s00371-015-1185-9
   Cheong SH, 2020, INFORM VISUAL, V19, P65, DOI 10.1177/1473871618821740
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Collins Christopher, 2009, Proceedings of the 2009 IEEE Symposium on Visual Analytics Science and Technology. VAST 2009. Held co-jointly with VisWeek 2009, P91, DOI 10.1109/VAST.2009.5333443
   Didimo W, 2019, INFORM SCIENCES, V505, P406, DOI 10.1016/j.ins.2019.07.097
   Dong WH, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7070281
   Dunne C., 2013, P SIGCHI C HUMAN FAC, P3247, DOI DOI 10.1145/2470654.2466444
   Eades Peter, 1984, Congr Numer, V42, P149
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Goyal P, 2018, KNOWL-BASED SYST, V151, P78, DOI 10.1016/j.knosys.2018.03.022
   Guo H, 2015, IEEE T VIS COMPUT GR, V21, P1173, DOI 10.1109/TVCG.2015.2424872
   Hansen DL, 2011, ANALYZING SOCIAL MEDIA NETWORKS WITH NODEXL: INSIGHTS FROM A CONNECTED WORLD, P11, DOI 10.1016/B978-0-12-382229-1.00002-3
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Henry N, 2006, IEEE T VIS COMPUT GR, V12, P677, DOI 10.1109/TVCG.2006.160
   Herman I., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P13
   Herman I, 2000, IEEE T VIS COMPUT GR, V6, P24, DOI 10.1109/2945.841119
   Holten D, 2011, IEEE PAC VIS SYMP, P195, DOI 10.1109/PACIFICVIS.2011.5742390
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Holten D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2299
   Hummel M, 2019, LECT NOTES COMPUT SC, V11904, P323, DOI 10.1007/978-3-030-35802-0_25
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Jacomy M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098679
   Jankun-Kelly TJ, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P59, DOI 10.1109/INFVIS.2003.1249009
   Kale B, 2023, COMPUT GRAPH FORUM, V42, P471, DOI 10.1111/cgf.14856
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Kruiger JF, 2017, COMPUT GRAPH FORUM, V36, P283, DOI 10.1111/cgf.13187
   Landauer T.K., 1997, Handbood of Human-Computer Interaction, V2nd, P203, DOI DOI 10.1016/B978-044481862-1.50075-3
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Liu YK, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186727
   Liu Y, 2023, Arxiv, DOI [arXiv:2211.12875, 10.48550/arXiv.2211.12875, DOI 10.48550/ARXIV.2211.12875]
   Matuszewski C, 1999, LECT NOTES COMPUT SC, V1731, P217
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Misue K, 2019, LECT NOTES COMPUT SC, V11904, P337, DOI 10.1007/978-3-030-35802-0_26
   Navlakha S., 2008, P 2008 ACM SIGMOD IN, P419, DOI DOI 10.1145/1376616.1376661
   Pan JC, 2021, IEEE T VIS COMPUT GR, V27, P1655, DOI 10.1109/TVCG.2020.3030393
   Purchase H., 1997, Graph Drawing. 5th International Symposium, GD '97. Proceedings, P248, DOI 10.1007/3-540-63938-1_67
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   REINGOLD EM, 1981, IEEE T SOFTWARE ENG, V7, P223, DOI 10.1109/TSE.1981.234519
   Riche NH, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P506, DOI 10.1145/2254556.2254652
   Romat H, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173761
   Rusu A, 2011, IEEE INT CONF INF VI, P488, DOI 10.1109/IV.2011.63
   Sathiyanarayanan M, 2017, INT CONF COMMUN SYST, P570, DOI 10.1109/COMSNETS.2017.7945455
   Schmauder Hansjorg, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P123
   Schoffel S., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P2292
   Schwank J, 2016, IEEE INT CONF INF VI, P45, DOI 10.1109/IV.2016.19
   Streit M, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S6-S4
   Tufte E. R., 1985, TLS-TIMES LIT SUPPL, V7
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   van Ham F, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P199, DOI 10.1109/INFVIS.2004.43
   van Ham F, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P227, DOI 10.1109/INFVIS.2003.1249030
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Wilkinson L., 1999, The Grammar of Graphics
   Wong K, 2006, SOFTWARE QUAL J, V14, P233, DOI 10.1007/s11219-006-9218-2
   Yang WK, 2023, Arxiv, DOI arXiv:2310.05771
   Yuan XR, 2012, IEEE T VIS COMPUT GR, V18, P2699, DOI 10.1109/TVCG.2012.236
NR 70
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 2968
EP 2980
DI 10.1109/TVCG.2024.3388562
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500013
PM 38648150
DA 2024-11-06
ER

PT J
AU Xiong, K
   Xu, XY
   Fu, SW
   Weng, D
   Wang, YH
   Wu, YC
AF Xiong, Kai
   Xu, Xinyi
   Fu, Siwei
   Weng, Di
   Wang, Yongheng
   Wu, Yingcai
TI JsonCurer: Data Quality Management for JSON Based on an Aggregated
   Schema
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Data integrity; Taxonomy; Monitoring; Usability;
   Data mining; Data analysis; Data quality; JSON; schema aggregation;
   visualization
ID VISUALIZATION; DESIGN; METHODOLOGY; SETS
AB High-quality data is critical to deriving useful and reliable information. However, real-world data often contains quality issues undermining the value of the derived information. Most existing research on data quality management focuses on tabular data, leaving semi-structured data under-exploited. Due to the schema-less and hierarchical features of semi-structured data, discovering and fixing quality issues is challenging and time-consuming. To address the challenge, this paper presents JsonCurer, an interactive visualization system to assist with data quality management in the context of JSON data. To have an overview of quality issues, we first construct a taxonomy based on interviews with data practitioners and a review of 119 real-world JSON files. Then we highlight a schema visualization that presents structural information, statistical features, and quality issues of JSON data. Based on a similarity-based aggregation technique, the visualization depicts the entire JSON data with a concise tree, where summary visualizations are given above each node, and quality issues are illustrated using Bubble Sets across nodes. We evaluate the effectiveness and usability of JsonCurer with two case studies. One is in the domain of data analysis while the other concerns quality assurance in MongoDB documents.
C1 [Xiong, Kai; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Xu, Xinyi; Weng, Di] Zhejiang Univ, Sch Software Technol, Hangzhou 310027, Peoples R China.
   [Fu, Siwei; Wang, Yongheng] Zhejiang Lab, Hangzhou 311121, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang Laboratory
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.; Fu, SW (corresponding author), Zhejiang Lab, Hangzhou 311121, Peoples R China.
EM kaixiong@zju.edu.cn; xinyixu@zju.edu.cn; fusiwei339@gmail.com;
   dweng@zju.edu.cn; wangyh@zhejianglab.com; ycwu@zju.edu.cn
RI XU, XINYI/KHC-3348-2024; Weng, Di/ABG-7408-2020
OI Xiong, Kai/0000-0002-8203-9667; Weng, Di/0000-0003-2712-7274; Wang,
   Yongheng/0000-0002-7675-2327
FU NSFC
FX No Statement Available
CR Abedjan Z., 2018, SYNTH LECT DATA MANA, V10, P1
   Akbulut O, 2023, VIS INFORM, V7, P22, DOI 10.1016/j.visinf.2023.06.003
   Alper B, 2011, IEEE T VIS COMPUT GR, V17, P2259, DOI 10.1109/TVCG.2011.186
   Alsallakh B, 2017, IEEE T VIS COMPUT GR, V23, P361, DOI 10.1109/TVCG.2016.2598496
   Alsallakh B, 2013, IEEE T VIS COMPUT GR, V19, P2496, DOI 10.1109/TVCG.2013.184
   [Anonymous], 2023, JSON To CSV Converter
   [Anonymous], 2003, Exploratory data mining and data cleaning
   [Anonymous], 2023, 2022 January Bitcoin Tweets
   [Anonymous], 2023, JSON Crack - Crack your data into pieces
   [Anonymous], 2023, Tableau prepbuilder
   [Anonymous], 2023, Convert JSON to other formats and vice-versa
   [Anonymous], 2023, Flatten Complex Nested JSON
   [Anonymous], 2023, JSON Formatter, Validator, Viewer, Editor & Beautifier
   Arbesser C, 2017, IEEE T VIS COMPUT GR, V23, P641, DOI 10.1109/TVCG.2016.2598592
   Baazizi Mohamed-Amine, 2017, Movebank, V1, DOI 10.5441/002/edbt.2017.21
   Batini C., 2008, International Journal of Innovative Computing and Applications, V1, P205, DOI 10.1109/icdim.2007.369236
   Batini Carlo., 2006, Data Quality: Concepts, DOI [DOI 10.1007/3-540-33173-5, 10.1007/3- 540-33173-5]
   Josko JMB, 2017, INFORM VISUAL, V16, P93, DOI 10.1177/1473871616629516
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Boyer J., 2011, P W3C WORKSH DAT SER
   Byelas H., 2006, P ACM S SOFTWARE VIS, P105
   Cai SJ, 2022, VIS INFORM, V6, P50, DOI 10.1016/j.visinf.2022.04.001
   Izquierdo JLC, 2016, KNOWL-BASED SYST, V103, P52, DOI 10.1016/j.knosys.2016.03.020
   Chen Ran, 2023, IEEE Trans Vis Comput Graph, V29, P128, DOI 10.1109/TVCG.2022.3209385
   Chu X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2201, DOI 10.1145/2882903.2912574
   Chu X, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1247, DOI 10.1145/2723372.2749431
   Chu X, 2013, PROC INT CONF DATA, P458, DOI 10.1109/ICDE.2013.6544847
   Code Beautify, 2023, JSON cleaner online to clean messy JSON online
   Collins C, 2009, IEEE T VIS COMPUT GR, V15, P1009, DOI 10.1109/TVCG.2009.122
   Dallachiesa Michele, 2013, SIGMOD, P541
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Dinkla K, 2012, COMPUT GRAPH FORUM, V31, P875, DOI 10.1111/j.1467-8659.2012.03080.x
   Droettboom M, 2023, Understanding JSON Schema
   Durner D, 2021, INT CONF MANAGE DATA, P445, DOI 10.1145/3448016.3452809
   Ehrlinger L., 2017, P 22 INT C INF QUAL
   Ehrlinger L, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.850611
   Ehrlinger L, 2019, LECT NOTES COMPUT SC, V11235, P1, DOI 10.1007/978-3-030-19143-6_1
   Fletcher Sam, 2018, Australasian Journal of Information Systems, V22, P1
   Geerts F, 2013, PROC VLDB ENDOW, V6, P625, DOI 10.14778/2536360.2536363
   GitHub, 2023, About us
   Heer J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P33
   Jain A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3561, DOI 10.1145/3394486.3406477
   Judah S., 2023, Magic quadrant for data quality tools
   Kaggle, 2023, ABOUT US
   Kagkelidis K, 2021, J VISUAL-JAPAN, V24, P631, DOI 10.1007/s12650-020-00718-y
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2011, INFORM VISUAL, V10, P271, DOI 10.1177/1473871611415994
   Kasica S, 2021, IEEE T VIS COMPUT GR, V27, P957, DOI 10.1109/TVCG.2020.3030462
   Khayyat Z, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1215, DOI 10.1145/2723372.2747646
   Kim W., 2002, J. Object Technol., V1, P39, DOI [10.5381/jot.2002.1.4.c3, DOI 10.5381/JOT.2002.1.4.C3]
   Kui XY, 2022, VIS INFORM, V6, P67, DOI 10.1016/j.visinf.2022.07.004
   Laranjeiro N, 2015, IEEE PAC RIM INT SYM, P179, DOI 10.1109/PRDC.2015.41
   Lee YW, 2002, INFORM MANAGE-AMSTER, V40, P133, DOI 10.1016/S0378-7206(02)00043-5
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Li GY, 2022, IEEE INFOCOM SER, P1, DOI [10.1109/INFOCOM48880.2022.9796694, 10.1109/TVCG.2022.3209354]
   LI L., 2011, GSTF International Journal on Computing, V1, P140
   Meulemans W, 2013, IEEE T VIS COMPUT GR, V19, P1846, DOI 10.1109/TVCG.2013.76
   Micic N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P155, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.28
   Moore S., 2023, How to create a business case for data quality improvement
   Moseler O, 2022, J VISUAL-JAPAN, V25, P1267, DOI 10.1007/s12650-022-00843-w
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Naumann F, 2013, SIGMOD REC, V42, P40, DOI 10.1145/2590989.2590995
   Oetting J., 2019, Data visualization 101: How to choose the right chart or graph for your data
   OpenRefine, 2023, about us
   Oracle Enterprise Data Quality, 2023, about us
   Papadakis G, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3377455
   Park H, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P577, DOI 10.1145/2588555.2610503
   Parra A. V., 2019, P INT C INF SYST, P1
   Rahm E., 2000, IEEE Data Engineering Bulletin, V23, P3, DOI DOI 10.1186/1472-6947-13-9
   Raman V., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P381
   Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750
   Sandrih B, 2017, IPSI BDG TRANS INTER, V13
   Schmidt CO, 2021, BMC MED RES METHODOL, V21, DOI 10.1186/s12874-021-01252-7
   Sebastian-Coleman L., 2012, Measuring data quality for ongoing improvement: a data quality assessment framework
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Simoes G, 2013, PROC VLDB ENDOW, V6, P1462, DOI 10.14778/2536258.2536259
   Skoutas D, 2007, INT J SEMANT WEB INF, V3, P1, DOI 10.4018/jswis.2007100101
   Spoth W, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209908
   Stackoverflow, 2023, About us
   Tong YX, 2014, PROC INT CONF DATA, P1182, DOI 10.1109/ICDE.2014.6816736
   Tuura L, 2010, J PHYS CONF SER, V219, DOI 10.1088/1742-6596/219/7/072020
   Wang JN, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P457, DOI 10.1145/2588555.2610494
   Wang JN, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P469, DOI 10.1145/2588555.2610505
   Wang R. Y., 1996, Journal of Management Information Systems, V12, P5
   Wang RY, 1998, COMMUN ACM, V41, P58, DOI 10.1145/269012.269022
   Wang YC, 2022, VIS INFORM, V6, P12, DOI 10.1016/j.visinf.2022.09.001
   Wang ZY, 2017, PROC VLDB ENDOW, V10, P1897, DOI 10.14778/3137765.3137803
   Xiong Kai, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209470
   Xiong K, 2023, IEEE T VIS COMPUT GR, V29, P2950, DOI 10.1109/TVCG.2022.3144975
   Yang WK, 2023, Arxiv, DOI arXiv:2310.05771
   Zhu SJ, 2020, VIS INFORM, V4, P24, DOI 10.1016/j.visinf.2020.07.002
NR 91
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3008
EP 3021
DI 10.1109/TVCG.2024.3388556
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500009
PM 38625779
DA 2024-11-06
ER

PT J
AU Rezaie, M
   Tory, M
   Carpendale, S
AF Rezaie, Maryam
   Tory, Melanie
   Carpendale, Sheelagh
TI Struggles and Strategies in Understanding Information Visualizations
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Task analysis; Encoding; Training;
   Bars; Standards; Information visualization; qualitative study;
   visualization sensemaking
ID CONCEPTUAL-FRAMEWORK; INSIGHT; SPACE
AB While the visualization community is increasingly aware that people often find visualizations difficult to understand, there is less information about what we need to do to create comprehensible visualizations. To help visualization creators and designers improve their visualizations, we need to better understand what kind of support people are looking for in their sensemaking process. Empirical studies are needed to tease apart the details of what makes the process of understanding difficult for visualization viewers. We conducted a qualitative study with 14 participants, observing them as they described how they were trying to make sense of 20 information visualizations. We identified the challenges participants faced throughout their sensemaking process and the strategies they employed to help themselves in overcoming the challenges. Our findings show how details and nuances within visualizations can impact comprehensibility and offer research suggestions to help us move toward more understandable visualizations.
C1 [Rezaie, Maryam; Carpendale, Sheelagh] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
   [Tory, Melanie] Northeastern Univ, Boston, MA 02115 USA.
C3 Simon Fraser University; Northeastern University
RP Rezaie, M (corresponding author), Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
EM maryam_rezaie@sfu.ca; m.tory@northeastern.edu; sheelagh@sfu.ca
OI Rezaie, Maryam/0000-0002-0708-8020; Tory, Melanie/0000-0002-6806-9253;
   Carpendale, Sheelagh/0000-0002-5127-9780
FU NSERC
FX No Statement Available
CR Ainsworth S, 2006, LEARN INSTR, V16, P183, DOI 10.1016/j.learninstruc.2006.03.001
   Alsaiari A., 2020, P EUROVIS SHORT PAP, P91, DOI [DOI 10.2312/EVS.20201054, 10.2312/evs.20201054]
   BACHCHHAV BD, 2018, P TRIBOINDIA 2018 IN, DOI DOI 10.2139/SSRN.3332391
   Bartram L, 2022, IEEE T VIS COMPUT GR, V28, P686, DOI 10.1109/TVCG.2021.3114830
   Bigelow A, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P17, DOI 10.1145/2598153.2598175
   Blascheck T, 2019, IEEE T VIS COMPUT GR, V25, P1407, DOI 10.1109/TVCG.2018.2802520
   Bloom B. S., 1956, COGNITIVE DOMAIN, DOI [10.1007/978-1-4419-1428-6, DOI 10.1007/978-1-4419-1428-6]
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Boy J, 2014, IEEE T VIS COMPUT GR, V20, P1963, DOI 10.1109/TVCG.2014.2346984
   Burns A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581524
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Campbell JL, 2013, SOCIOL METHOD RES, V42, P294, DOI 10.1177/0049124113500475
   Canham M, 2010, LEARN INSTR, V20, P155, DOI 10.1016/j.learninstruc.2009.02.014
   Card SK., 1999, READINGS INFORM VISU
   Choe EK, 2015, IEEE COMPUT GRAPH, V35, P28, DOI 10.1109/MCG.2015.51
   Collins C, 2007, IEEE T VIS COMPUT GR, V13, P1192, DOI 10.1109/TVCG.2007.70521
   Convertino G., 2017, P 2017 CHI C HUM FAC, P1075, DOI [10.1145/3027063.3053359, DOI 10.1145/3027063.3053359]
   Cui Z, 2019, INFORM VISUAL, V18, P251, DOI 10.1177/1473871618806555
   Dasgupta A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1193, DOI 10.1145/3025453.3025882
   Davidson K, 2023, IEEE T VIS COMPUT GR, V29, P5294, DOI 10.1109/TVCG.2022.3207357
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Edsall R. M., 1997, PROC GISLIS, V97, P28
   Elgendi M, 2017, NAT BIOTECHNOL, V35, P990, DOI 10.1038/nbt.3986
   Erete S, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1273, DOI 10.1145/2818048.2820068
   Freedman EG, 2002, LECT NOTES ARTIF INT, V2317, P18
   Göbel F, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204544
   Grammel L, 2010, IEEE T VIS COMPUT GR, V16, P943, DOI 10.1109/TVCG.2010.164
   Grolemund G, 2014, INT STAT REV, V82, P184, DOI 10.1111/insr.12028
   Grossman T, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1515
   Guo H, 2016, IEEE T VIS COMPUT GR, V22, P51, DOI 10.1109/TVCG.2015.2467613
   Haider Johanna Doppler, 2017, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V61, P193, DOI 10.1177/1541931213601532
   He C, 2021, IEEE T VIS COMPUT GR, V27, P3410, DOI 10.1109/TVCG.2020.2977634
   Isenberg P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1217
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Karer B, 2021, IEEE T VIS COMPUT GR, V27, P1011, DOI 10.1109/TVCG.2020.3030376
   Kong HK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174012
   Lee S, 2017, IEEE T VIS COMPUT GR, V23, P551, DOI 10.1109/TVCG.2016.2598920
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Lo LYH, 2022, COMPUT GRAPH FORUM, V41, P515, DOI 10.1111/cgf.14559
   LOWE R, 1988, RES SCI ED, V18, P112, DOI 10.1007/BF02356586
   Luo WH, 2023, J COMPUT INFORM SYST, V63, P81, DOI 10.1080/08874417.2021.2023338
   Ma J, 2020, IEEE T VIS COMPUT GR, V26, P472, DOI 10.1109/TVCG.2019.2934401
   Mahmud S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376414
   Masson D, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501895
   Mayr E., 2010, P BELIV WORKSH, P8, DOI 10.1145/2110192.2110194
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   Novick DG, 2009, SIGDOC'09: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, P97
   O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801
   Perkhofer LM, 2019, J APPL ACCOUNT RES, V20, P497, DOI 10.1108/JAAR-10-2017-0114
   Pirolli P., 2005, P INT C INT AN MCLEA, V5, P2
   Rosenthal S., 2022, P IEEE S VIS LANG HU, P1, DOI [10.1109/VL/HCC53370.2022.9833097, DOI 10.1109/VL/HCC53370.2022.9833097]
   Russell D. M., 2008, CHI 08 EXTENDED ABST, P3981, DOI [10.1145/1358628.1358972, DOI 10.1145/1358628.1358972]
   Saket B., 2015, ARXIV
   Saraiya P, 2005, IEEE T VIS COMPUT GR, V11, P443, DOI 10.1109/TVCG.2005.53
   Shah P, 2011, TOP COGN SCI, V3, P560, DOI 10.1111/j.1756-8765.2009.01066.x
   Stoiber C, 2022, VIS INFORM, V6, P34, DOI 10.1016/j.visinf.2022.07.001
   Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354
   Tobiasz M, 2009, IEEE T VIS COMPUT GR, V15, P1065, DOI 10.1109/TVCG.2009.162
   Todorovic D., 2008, SCHOLARPEDIA, V3, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   Tory M, 2023, IEEE COMPUT GRAPH, V43, P22, DOI 10.1109/MCG.2021.3136545
   Vears DF, 2022, FOCUS HEALTH PROF ED, V23, P111
   Viau C, 2012, COMPUT GRAPH FORUM, V31, P1285, DOI 10.1111/j.1467-8659.2012.03121.x
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [10.1145/345513.345271, DOI 10.1145/345513.345271]
   Wang JH, 2021, J MED VIROL, V93, P2908, DOI 10.1002/jmv.26771
   Yi J.S., 2008, P 2008 WORKSHOP TIME, P4, DOI [DOI 10.1145/1377966.1377971, 10.1145/1377966.1377971]
   Zgraggen E, 2014, IEEE T VIS COMPUT GR, V20, P2112, DOI 10.1109/TVCG.2014.2346293
NR 66
TC 0
Z9 0
U1 5
U2 5
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3035
EP 3048
DI 10.1109/TVCG.2024.3388560
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500001
PM 38619946
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Li, GZ
   Li, RF
   Feng, YS
   Zhang, Y
   Luo, YY
   Liu, CH
AF Li, Guozheng
   Li, Runfei
   Feng, Yunshan
   Zhang, Yu
   Luo, Yuyu
   Liu, Chi Harold
TI CoInsight: Visual Storytelling for Hierarchical Tables With Connected
   Insights
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Data mining; Task analysis; Europe;
   Usability; Natural languages; Data insight; hierarchical table; table
   data visualization; tabular data; visual storytelling
ID VISUALIZATION; DESIGN
AB Extracting data insights and generating visual data stories from tabular data are critical parts of data analysis. However, most existing studies primarily focus on tabular data stored as flat tables, typically without leveraging the relations between cells in the headers of hierarchical tables. When properly used, rich table headers can enable the extraction of many additional data stories. To assist analysts in visual data storytelling, an approach is needed to organize these data insights efficiently. In this work, we propose CoInsight, a system to facilitate visual storytelling for hierarchical tables by connecting insights. CoInsight extracts data insights from hierarchical tables and builds insight relations according to the structure of table headers. It further visualizes related data insights using a nested graph with edge bundling. We evaluate the CoInsight system through a usage scenario and a user experiment. The results demonstrate the utility and usability of CoInsight for converting data insights in hierarchical tables into visual data stories.
C1 [Li, Guozheng; Li, Runfei; Feng, Yunshan; Liu, Chi Harold] Beijing Inst Technol, Beijing 100811, Peoples R China.
   [Zhang, Yu] Univ Oxford, Oxford OX1 2JD, England.
   [Luo, Yuyu] Hong Kong Univ Sci & Technol, Clear Water Bay, Hong Kong, Peoples R China.
C3 Beijing Institute of Technology; University of Oxford; Hong Kong
   University of Science & Technology
RP Luo, YY (corresponding author), Hong Kong Univ Sci & Technol, Clear Water Bay, Hong Kong, Peoples R China.
EM guozheng.li@bit.edu.cn; chiliu@bit.edu.cn; yuyuluo@hkust-gz.edu.cn
OI Liu, Chi Harold/0000-0002-0252-329X; Zhang, Yu/0000-0002-9035-0463; Li,
   Guozheng/0000-0001-6663-6712
FU National Key R#x0026;D Program of China
FX No Statement Available
CR A. W. Services, 2012, Amazon quicksight
   Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   Bach B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173612
   Brehmer M., 2019, P COMPUT JOURNALISM
   Brehmer M, 2017, IEEE T VIS COMPUT GR, V23, P2151, DOI 10.1109/TVCG.2016.2614803
   Chai CL, 2023, IEEE T KNOWL DATA EN, V35, P4646, DOI 10.1109/TKDE.2022.3148237
   Chai CL, 2022, PROC VLDB ENDOW, V15, P1466, DOI 10.14778/3523210.3523223
   Chen Z., 2013, P 3 INT WORKSH SEM S, DOI [DOI 10.1145/2509908.2509909, 10.1145/2509908.2509909]
   Chen Z, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1126, DOI 10.1145/2623330.2623617
   Cheng ZJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1094
   Demiralp C, 2017, PROC VLDB ENDOW, V10, P1937, DOI 10.14778/3137765.3137813
   Ding R, 2019, INT CONF MANAGE DATA, P317, DOI 10.1145/3299869.3314037
   Dou WS, 2018, IEEE INT CONF AUTOM, P498, DOI 10.1145/3238147.3238222
   Han Y, 2020, IEEE PAC VIS SYMP, P236, DOI [10.1109/PacificVis48177.2020.1027x, 10.1109/PasificVis48177.2020.1027x]
   Henry N, 2007, IEEE T VIS COMPUT GR, V13, P1302, DOI 10.1109/TVCG.2007.70582
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Holten D, 2009, COMPUT GRAPH FORUM, V28, P983, DOI 10.1111/j.1467-8659.2009.01450.x
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Kim N. W., 2019, P ACM C HUM FACT COM, P1
   Kim Y, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2628, DOI 10.1145/3025453.3025866
   Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99
   Li GZ, 2023, IEEE T VIS COMPUT GR, V29, P5451, DOI 10.1109/TVCG.2022.3215070
   Li GZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376297
   Li GZ, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383150
   Li GZ, 2020, IEEE T VIS COMPUT GR, V26, P1022, DOI 10.1109/TVCG.2019.2934535
   Li GY, 2022, IEEE INFOCOM SER, P1, DOI [10.1109/INFOCOM48880.2022.9796694, 10.1109/TVCG.2022.3209354]
   Li HT, 2024, Arxiv, DOI arXiv:2309.15723
   Lin QW, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P547, DOI 10.1145/3219819.3219867
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P1, DOI 10.1007/978-3-642-14267-3
   Luo YY, 2021, INT CONF MANAGE DATA, P1235, DOI 10.1145/3448016.3457261
   Luo YY, 2022, IEEE T VIS COMPUT GR, V28, P217, DOI 10.1109/TVCG.2021.3114848
   Luo YY, 2022, IEEE T KNOWL DATA EN, V34, P475, DOI 10.1109/TKDE.2020.2981464
   Luo YY, 2020, PROC VLDB ENDOW, V13, P2841, DOI 10.14778/3415478.3415489
   Luo YY, 2020, PROC VLDB ENDOW, V13, P2821, DOI 10.14778/3415478.3415484
   Luo YY, 2020, PROC INT CONF DATA, P733, DOI 10.1109/ICDE48307.2020.00069
   Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma PC, 2021, INT CONF MANAGE DATA, P1262, DOI 10.1145/3448016.3457267
   MACKINLAY J, 1986, ACM T GRAPHIC, V5, P110, DOI 10.1145/22949.22950
   Mackinlay JD, 2007, IEEE T VIS COMPUT GR, V13, P1137, DOI 10.1109/TVCG.2007.70594
   Min Lu, 2017, 2017 IEEE Pacific Visualization Symposium (PacificVis), P61, DOI 10.1109/PACIFICVIS.2017.8031580
   Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240
   Mörth E, 2023, IEEE T VIS COMPUT GR, V29, P5165, DOI 10.1109/TVCG.2022.3205769
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Peng JL, 2021, INT CONF MANAGE DATA, P2271, DOI 10.1145/3448016.3457330
   Qin X., 2018, P INT C EXT DAT TECH, P441
   Qin XD, 2022, VLDB J, V31, P753, DOI 10.1007/s00778-021-00714-0
   Qin XD, 2020, VLDB J, V29, P93, DOI 10.1007/s00778-019-00588-3
   Qinl XD, 2022, PROC INT CONF DATA, P2359, DOI 10.1109/ICDE53745.2022.00222
   Research M., 2016, Quickinsight
   Satyanarayan A, 2014, COMPUT GRAPH FORUM, V33, P361, DOI 10.1111/cgf.12392
   Schaechtle U., 2013, P INT JOINT C ART IN, P1649
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403
   Siddiqui T, 2016, PROC VLDB ENDOW, V10, P457
   Stolper C. D., 2016, MSRTR201614 MICR RES
   Sun Mengdi, 2023, IEEE Trans Vis Comput Graph, V29, P983, DOI 10.1109/TVCG.2022.3209428
   Tang B, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1509, DOI 10.1145/3035918.3035922
   Tang JW, 2022, INT CONF MANAGE DATA, P2353, DOI 10.1145/3514221.3520150
   Tian M, 2023, J VISUAL-JAPAN, V26, P1445, DOI 10.1007/s12650-023-00941-3
   Tong C, 2018, INFORMATION, V9, DOI 10.3390/info9030065
   Vartak M, 2015, PROC VLDB ENDOW, V8, P2182, DOI 10.14778/2831360.2831371
   Wang Xinxin, 1996, Technical Report
   Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398
   Wang Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173909
   Wang ZR, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1780, DOI 10.1145/3447548.3467434
   Ward M.O., 2015, INTERACTIVE DATA VIS
   Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648
   Wongsuphasawat K, 2016, IEEE T VIS COMPUT GR, V22, P649, DOI 10.1109/TVCG.2015.2467191
   Wu ZL, 2023, FRONT INFORM TECH EL, V24, P1007, DOI 10.1631/FITEE.2200409
   Xu SY, 2018, COMPUT GRAPH FORUM, V37, P75, DOI 10.1111/cgf.13402
   Yang W., 2023, Comput. Vis. Media
   Zeng ZH, 2022, IEEE T VIS COMPUT GR, V28, P346, DOI 10.1109/TVCG.2021.3114814
   Zhao J, 2023, IEEE T VIS COMPUT GR, V29, P1384, DOI 10.1109/TVCG.2021.3114211
   Zhao ZP, 2023, IEEE COMPUT GRAPH, V43, P97, DOI 10.1109/MCG.2023.3269850
   Zhou MY, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2389, DOI 10.1145/3447548.3467279
NR 76
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUN
PY 2024
VL 30
IS 6
BP 3049
EP 3061
DI 10.1109/TVCG.2024.3388553
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WC8Z6
UT WOS:001252775500005
PM 38619943
DA 2024-11-06
ER

PT J
AU Davidson, T
   Wall, E
   Mace, J
AF Davidson, Thomas
   Wall, Emily
   Mace, Jonathan
TI A Qualitative Interview Study of Distributed Tracing Visualisation: A
   Characterisation of Challenges and Opportunities
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Interviews; Distributed databases; Task analysis;
   Social networking (online); Microservice architectures; Guidelines;
   Distributed tracing; systems; visualisation
ID EXPLORATION; TIME
AB Distributed tracing tools have emerged in recent years to enable operators of modern internet applications to troubleshoot cross-component problems in deployed applications. Due to the rich, detailed diagnostic data captured by distributed tracing tools, effectively presenting this data is important. However, use of visualisation to enable sensemaking of this complex data in distributed tracing tools has received relatively little attention. Consequently, operators struggle to make effective use of existing tools. In this article we present the first characterisation of distributed tracing visualisation through a qualitative interview study with six practitioners from two large internet companies. Across two rounds of 1-on-1 interviews we use grounded theory coding to establish users, extract concrete use cases and identify shortcomings of existing distributed tracing tools. We derive guidelines for development of future distributed tracing tools and expose several open research problems that have wide reaching implications for visualisation research and other domains.
C1 [Davidson, Thomas; Mace, Jonathan] Univ Saarland, Max Planck Inst Software Syst, D-66123 Saarbrucken, Germany.
   [Wall, Emily] Emory Univ, Cognit & Visualizat Lab, Comp Sci, Atlanta, GA 30322 USA.
C3 Max Planck Society; Saarland University; Emory University
RP Davidson, T (corresponding author), Univ Saarland, Max Planck Inst Software Syst, D-66123 Saarbrucken, Germany.
EM tdavidso@mpi-sws.org; emily.wall@emory.edu; jcmace@mpi-sws.org
OI Davidson, Thomas James/0000-0003-3467-6925
CR Ahlberg C., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P619, DOI 10.1145/142750.143054
   Alexander J, 2008, BEHAV RES METHODS, V40, P413, DOI 10.3758/BRM.40.2.413
   Andrews K, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P62, DOI 10.1109/IV.2009.108
   Apache, Zipkin
   Attwood TK, 2010, BIOINFORMATICS, V26, pi568, DOI 10.1093/bioinformatics/btq383
   Beck F, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P592, DOI 10.1109/IV.2009.42
   Beschastnikh I, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3375633
   Bethel H. Childs, 2012, High Performance Visualization:Enabling Extreme-Scale Scientific Insight
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Ceneda D, 2017, IEEE T VIS COMPUT GR, V23, P111, DOI 10.1109/TVCG.2016.2598468
   Chametzky B., 2016, Sociol. Mind, V6, DOI [DOI 10.4236/SM.2016.64014, 10.4236/sm.2016.64014]
   Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1145/3491102.3517485, 10.1109/TENCON55691.2022.9978005]
   CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400
   Craft B, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P110, DOI 10.1109/IV.2005.28
   Creswell J. W., 2016, Qualitative inquiry and research design: choosing from among the five approaches
   De Pauw W, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P143
   deMarrais K., 2004, Foundations for research, P51
   Elias M, 2011, LECT NOTES COMPUT SC, V6949, P274, DOI 10.1007/978-3-642-23768-3_23
   Elmqvist N, 2015, INFORM VISUAL, V14, P250, DOI 10.1177/1473871613513228
   Engebretsen M, 2017, IEEE INT CON INF VIS, P296, DOI 10.1109/iV.2017.54
   Farro J., 2018, Trace comparisons arrive in jaeger 1.7
   Fekete D., 2018, DAGST SEM
   Fonseca G., 2007, P 4 USENIX S NETW SY
   Furnas G. W., 1986, SIGCHI Bull, V17, P16, DOI DOI 10.1145/22339.22342
   Gan Y, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P3, DOI 10.1145/3297858.3304013
   García A, 2010, EICS 2010: PROCEEDINGS OF THE 2010 ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS, P41
   Gregg B, 2016, COMMUN ACM, V59, P48, DOI 10.1145/2909476
   Guan-Jun Ding, 2020, Advances in Usability, User Experience, Wearable and Assistive Technology. Proceedings of the AHFE 2020 Virtual Conferences on Usability and User Experience, Human Factors and Assistive Technology, Human Factors and Wearable Technologies, and Virtual Environments and Game Design. Advances in Intelligent Systems and Computing (AISC 1217), P173, DOI 10.1007/978-3-030-51828-8_23
   Han HL, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502052
   Hoffswell J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174106
   Honeycomb, about us
   Horvitz E., 1999, P CHI C HUM FACT COM, P1159
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hutchins J. D., 1985, Hum.-Comput. Interact., V1, P311, DOI [DOI 10.1207/S15327051HCI0104, DOI 10.1207/S15327051HCI0104_2]
   Isaacs KE, 2014, IEEE T VIS COMPUT GR, V20, P2349, DOI 10.1109/TVCG.2014.2346456
   Isaacs KatherineE., 2014, EuroVis - STARs, DOI [DOI 10.2312/EUROVISSTAR.20141177, 10.2312/eurovisstar.20141177]
   Janes A., 2013, Cutter ITJ., V26, P17
   Jansen BJ., 2020, Data and Information Management, V4, P1, DOI DOI 10.2478/DIM-2020-0005
   Johnson J.C., 2002, HDB INTERVIEW RES, P491
   Kaldor J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P34, DOI 10.1145/3132747.3132749
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Kang J., 2011, 2011 IEEE C VIS AN S, P21, DOI DOI 10.1109/VAST.2011.6102438
   Kerracher N., 2014, EuroVis - Short Papers, DOI [DOI 10.2312/EUROVISSHORT.20141149, 10.2312/10, DOI 10.2312/10]
   Kobayashi H, 2015, IEEE INT CONF INF VI, P310, DOI 10.1109/iV.2015.61
   LAMPORT L, 1978, COMMUN ACM, V21, P558, DOI 10.1145/359545.359563
   Lightstep, about us
   Liu ZC, 2013, COMPUT GRAPH FORUM, V32, P421, DOI 10.1111/cgf.12129
   Mann TM, 2000, 11TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATION, PROCEEDINGS, P586, DOI 10.1109/DEXA.2000.875084
   Martins LEG, 2020, IEEE T SOFTWARE ENG, V46, P346, DOI 10.1109/TSE.2018.2854716
   McKenna S, 2015, IEEE SYM VIS CYB SEC
   Molina-Solana M, 2017, APPL SOFT COMPUT, V53, P227, DOI 10.1016/j.asoc.2016.12.044
   Morrow B, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P1, DOI [10.1109/visual.2019.8933582, 10.1109/VISUAL.2019.8933582]
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nonnemann L., 2021, P EUROVIS WORKSH VIS, DOI [10.2312/eurova.20211094, DOI 10.2312/EUROVA.20211094]
   North C, 2006, IEEE COMPUT GRAPH, V26, P6, DOI 10.1109/MCG.2006.70
   North C., 2011, Proceedings of the 2011 annual conference extended abstracts on Human factors in computing systems, P33, DOI 10.1145/1979742.1979570
   Nurwidyantoro A., 2021, P IEEE ACM 15 INT S, P1
   Olson J. S., 2014, Ways of Knowing in HCI, V2
   Ottogalli FG, 2001, LECT NOTES COMPUT SC, V2074, P831
   Pan Z., 2020, P 7 ACM C LEARN SCAL, P393, DOI [10.1145/3386527.3406751, DOI 10.1145/3386527.3406751]
   Parker A., 2020, Distributed Tracing in Practice: Instrumenting, Analyzing, and Debugging Microservices
   RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776
   Roberts J. C., 2005, Exploring Geovisualization, P159, DOI [10.1016/B978-008044531-1/50426-7, DOI 10.1016/B978-008044531-1/50426-7]
   Rule A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173606
   Saket B, 2017, IEEE T VIS COMPUT GR, V23, P331, DOI 10.1109/TVCG.2016.2598839
   Sambasivan RR, 2016, PROCEEDINGS OF THE SEVENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC 2016), P401, DOI 10.1145/2987550.2987568
   Sambasivan RR, 2013, IEEE T VIS COMPUT GR, V19, P2466, DOI 10.1109/TVCG.2013.233
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Scaife M, 1996, INT J HUM-COMPUT ST, V45, P185, DOI 10.1006/ijhc.1996.0048
   Sedlmair M, 2012, IEEE T VIS COMPUT GR, V18, P2431, DOI 10.1109/TVCG.2012.213
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Sigelman B. H., 2010, Dapper, a large-scale distributed systems tracing infrastructure
   Song H, 2019, IEEE T VIS COMPUT GR, V25, P914, DOI 10.1109/TVCG.2018.2864914
   Sridharan C., 2019, Distributed tracingweve been doing it wrong
   Trümper J, 2010, SOFTVIS 2010: PROCEEDINGS OF THE 2010 INTERNATIONAL SYMPOSIUM ON SOFTWARE VISUALIZATION, P133
   Uber, Jaeger
   Users J., 2022, Jaeger UI open issues page
   van Ham F, 2009, IEEE T VIS COMPUT GR, V15, P953, DOI 10.1109/TVCG.2009.108
   W. W. W. C. (W3C, Trace context
   Wall E, 2019, IEEE T VIS COMPUT GR, V25, P491, DOI 10.1109/TVCG.2018.2865146
   Walny J, 2020, IEEE T VIS COMPUT GR, V26, P12, DOI 10.1109/TVCG.2019.2934538
   WANG QQ, 1994, PERCEPT PSYCHOPHYS, V56, P495, DOI 10.3758/BF03206946
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Xu K, 2020, IEEE T VIS COMPUT GR, V26, P1107, DOI 10.1109/TVCG.2019.2934613
   Yang W., 2022, P CHI C HUM FACT COM, P1
   Zuo CY, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9110636
NR 87
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3828
EP 3840
DI 10.1109/TVCG.2023.3241596
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700022
PM 37022365
DA 2024-11-06
ER

PT J
AU Zhu, Z
   Nan, LL
   Xie, HR
   Chen, HH
   Wang, J
   Wei, MQ
   Qin, J
AF Zhu, Zhe
   Nan, Liangliang
   Xie, Haoran
   Chen, Honghua
   Wang, Jun
   Wei, Mingqiang
   Qin, Jing
TI CSDN: Cross-Modal Shape-Transfer Dual-Refinement Network for Point Cloud
   Completion
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Shape; Point cloud compression; Three-dimensional displays; Maintenance
   engineering; Geometry; Transformers; Fuses; CSDN; cross modality;
   multi-feature fusion; point cloud completion
AB How will you repair a physical object with some missings? You may imagine its original shape from previously captured images, recover its overall (global) but coarse shape first, and then refine its local details. We are motivated to imitate the physical repair procedure to address point cloud completion. To this end, we propose a cross-modal shape-transfer dual-refinement network (termed CSDN), a coarse-to-fine paradigm with images of full-cycle participation, for quality point cloud completion. CSDN mainly consists of "shape fusion" and "dual-refinement" modules to tackle the cross-modal challenge. The first module transfers the intrinsic shape characteristics from single images to guide the geometry generation of the missing regions of point clouds, in which we propose IPAdaIN to embed the global features of both the image and the partial point cloud into completion. The second module refines the coarse output by adjusting the positions of the generated points, where the local refinement unit exploits the geometric relation between the novel and the input points by graph convolution, and the global constraint unit utilizes the input image to fine-tune the generated offset. Different from most existing approaches, CSDN not only explores the complementary information from images but also effectively exploits cross-modal data in the whole coarse-to-fine completion procedure. Experimental results indicate that CSDN performs favorably against twelve competitors on the cross-modal benchmark.
C1 [Zhu, Zhe; Chen, Honghua; Wang, Jun; Wei, Mingqiang] Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
   [Nan, Liangliang] Delft Univ Technol, Urban Data Sci Sect, NL-2628 CD Delft, Netherlands.
   [Xie, Haoran] Lingnan Univ, Dept Comp & Decis Sci, Hong Kong, Peoples R China.
   [Qin, Jing] Hong Kong Polytech Univ, Sch Nursing, Hong Kong, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Delft University of
   Technology; Lingnan University; Hong Kong Polytechnic University
RP Chen, HH; Wei, MQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
EM zhuzhe0619@nuaa.edu.cn; liangliang.nan@tudelft.nl; hrxie@ln.edu.hk;
   chenhonghuacn@gmail.com; wjun@nuaa.edu.cn; mingqiang.wei@gmail.com;
   harry.qin@polyu.edu.hk
RI Xie, Haoran/ADP-8087-2022; Qin, Jing/J-9807-2016; Xie,
   Haoran/AFS-3515-2022
OI Nan, Liangliang/0000-0002-5629-9975; Xie, Haoran/0000-0003-0965-3617;
   Honghua, Chen/0000-0001-7473-1146; Zhu, Zhe/0000-0001-5314-9392
FU National Natural Science Foundation of China [62172218, 62032011];
   Shenzhen University-Lingnan University Joint Research Programme
   [SZU-LU006/2122, 871228]; Lingnan University [DR22A2]; General Research
   Fund under Hong Kong Research Grants Council [15218521]; Innovation and
   Technology Fund-Midstream Research Programme for Universities(ITF-MRP)
   [MRP/022/20X]
FX This work was supported in part by National Natural Science Foundation
   of China under Grants 62172218 and 62032011, in part by Shenzhen
   University-Lingnan University Joint Research Programme under Grant
   SZU-LU006/2122,in part by Research Grant entitled "Self-Supervised
   Learning for Medical Images" under Grant 871228, in part by Direct Grant
   of Lingnan University under Grant DR22A2, in part by General Research
   Fund under Hong Kong Research Grants Council under Grant 15218521 and in
   part by Innovation and Technology Fund-Midstream Research Programme for
   Universities(ITF-MRP) under Grant MRP/022/20X.
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Berger M., 2014, Eurographics Assoc, V1, P161, DOI DOI 10.2312/EGST.20141040
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cai R., 2020, EUR C COMP VIS, P364
   Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824
   Chen B., 2020, INT C LEARN REPR, P1
   Chen YC, 2022, PROC CVPR IEEE, P12714, DOI 10.1109/CVPR52688.2022.01239
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098
   Duggal S, 2022, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR52688.2022.00159
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fei B, 2022, IEEE T INTELL TRANSP, V23, P22862, DOI 10.1109/TITS.2022.3195555
   Geiger P., Vision meets robotics:The KITTI dataset
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Han F, 2009, IEEE T PATTERN ANAL, V31, P59, DOI [10.1109/TPAMI.2008.65, 10.1109/TPAMI.2008.55]
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huang ZT, 2020, PROC CVPR IEEE, P7659, DOI 10.1109/CVPR42600.2020.00768
   Jiang L, 2018, LECT NOTES COMPUT SC, V11212, P820, DOI 10.1007/978-3-030-01237-3_49
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li JX, 2021, PROC CVPR IEEE, P15955, DOI 10.1109/CVPR46437.2021.01570
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459766
   Li X, 2020, LECT NOTES COMPUT SC, V12113, P677, DOI 10.1007/978-3-030-59416-9_44
   Li YZ, 2018, ADV NEUR IN, V31
   Lin C., 2020, Adv. Neural Inf. Process.Syst., V33, p11 453
   Lin ZH, 2020, PROC CVPR IEEE, P1797, DOI 10.1109/CVPR42600.2020.00187
   Liu MH, 2020, AAAI CONF ARTIF INTE, V34, P11596
   Lu DN, 2022, Arxiv, DOI arXiv:2205.07417
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Mitra NJ, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12010
   Mittal P, 2022, PROC CVPR IEEE, P306, DOI 10.1109/CVPR52688.2022.00040
   Nan LL, 2014, COMPUT GRAPH FORUM, V33, P249, DOI 10.1111/cgf.12493
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Pistilli Francesca, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P103, DOI 10.1007/978-3-030-58565-5_7
   Qi C.R., 2017, P 31 INT C NEUR INF, P5105, DOI DOI 10.1109/CVPR.2017.16
   Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446
   Qian GC, 2021, PROC CVPR IEEE, P11678, DOI 10.1109/CVPR46437.2021.01151
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Shu DW, 2019, IEEE I CONF COMP VIS, P3858, DOI 10.1109/ICCV.2019.00396
   Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209
   Sun YB, 2020, IEEE WINT CONF APPL, P61, DOI [10.1109/WACV45572.2020.9093430, 10.1109/wacv45572.2020.9093430]
   Sung M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818094
   Tang YZ, 2022, PROC CVPR IEEE, P6387, DOI 10.1109/CVPR52688.2022.00629
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Thrun S, 2005, IEEE I CONF COMP VIS, P1824
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J., 2022, arXiv
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZT, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3462219
   Wei MQ, 2022, Arxiv, DOI arXiv:2206.04665
   Wen C, 2019, IEEE I CONF COMP VIS, P1042, DOI 10.1109/ICCV.2019.00113
   Wen X, 2021, PROC CVPR IEEE, P13075, DOI 10.1109/CVPR46437.2021.01288
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xiang P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5479, DOI 10.1109/ICCV48922.2021.00545
   Xie CL, 2021, PROC CVPR IEEE, P4617, DOI 10.1109/CVPR46437.2021.00459
   Xie H., 2020, P EUR C COMP VIS, P365, DOI DOI 10.1007/978-3-030-58545-721
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xie HZ, 2020, INT J COMPUT VISION, V128, P2919, DOI 10.1007/s11263-020-01347-6
   Xu C., 2021, arXiv
   Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang Q., 2020, P EUR C COMP VIS, P512, DOI 10.1007/978-3-030-58595-2_31
   Zhang WX, 2023, IEEE T VIS COMPUT GR, V29, P4229, DOI 10.1109/TVCG.2022.3185247
   Zhang X., 2021, P IEEE CVF C COMP VI
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhao WB, 2022, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR52688.2022.00204
   Zhou HR, 2022, LECT NOTES COMPUT SC, V13663, P416, DOI 10.1007/978-3-031-20062-5_24
NR 85
TC 3
Z9 3
U1 6
U2 13
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3545
EP 3563
DI 10.1109/TVCG.2023.3236061
PG 19
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700004
PM 37018698
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Wei, ZZ
   Zhu, QT
   Min, C
   Chen, YS
   Wang, GP
AF Wei, Zizhuang
   Zhu, Qingtian
   Min, Chen
   Chen, Yisong
   Wang, Guoping
TI Bidirectional Hybrid LSTM Based Recurrent Neural Network for Multi-View
   Stereo
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Costs; Feature extraction; Three-dimensional displays; Runtime; Point
   cloud compression; Image reconstruction; Recurrent neural networks; 3D
   reconstruction; deep learning; multi-view stereo; recurrent neural
   network; point clouds
AB Recently, deep learning based multi-view stereo (MVS) networks have demonstrated their excellent performance on various benchmarks. In this paper, we present an effective and efficient recurrent neural network (RNN) for accurate and complete dense point cloud reconstruction. Instead of regularizing the cost volume via conventional 3D CNN or unidirectional RNN like previous attempts, we adopt a bidirectional hybrid Long Short-Term Memory (LSTM) based structure for cost volume regularization. The proposed bidirectional recurrent regularization is able to perceive full-space context information comparable to 3D CNNs while saving runtime memory. For post-processing, we introduce a visibility based approach for depth map refinement to obtain more accurate dense point clouds. Extensive experiments on DTU, Tanks and Temples and ETH3D datasets demonstrate that our method outperforms previous state-of-the-art MVS methods and exhibits high memory efficiency at runtime.
C1 [Wei, Zizhuang; Zhu, Qingtian; Min, Chen; Chen, Yisong; Wang, Guoping] Peking Univ, Dept EECS, Beijing 100871, Peoples R China.
C3 Peking University
RP Wang, GP (corresponding author), Peking Univ, Dept EECS, Beijing 100871, Peoples R China.
EM weizizhuang@pku.edu.cn; zqt@stu.pku.edu.cn; minchen@stu.pku.edu.cn;
   chenyisong@pku.edu.cn; wgp@pku.edu.cn
RI wang, guoping/KQU-3394-2024; Zhu, Qingtian/KPA-3166-2024; CHEN,
   SI/GZL-4800-2022
FU National Key Technology Research and Development Program of China
   [2017YFB1002601]; National Natural Science Foundation of China (NSFC)
   [61632003]
FX This work was supported in part by the National Key Technology Research
   and Development Program of China under Grant 2017YFB1002601, in part by
   the National Natural Science Foundation of China (NSFC) under Grant
   61632003.
CR Aanæs H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Cheng S, 2020, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR42600.2020.00260
   Fuhrmann S., 2014, P WORKSH GRAPH CULT, P11, DOI [10.2312/gch.20141299, DOI 10.2312/GCH.20141299]
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Huang PH, 2018, PROC CVPR IEEE, P2821, DOI 10.1109/CVPR.2018.00298
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Jianfeng Yan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P674, DOI 10.1007/978-3-030-58548-8_39
   Kar A, 2017, Arxiv, DOI arXiv:1708.05375
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kingma D.P., 2014, P INT C LEARNING REP
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Kuhn A, 2020, INT CONF 3D VISION, P404, DOI 10.1109/3DV50981.2020.00050
   Liu HM, 2020, PATTERN RECOGN, V99, DOI 10.1016/j.patcog.2019.107112
   Luo KY, 2020, PROC CVPR IEEE, P1587, DOI 10.1109/CVPR42600.2020.00166
   Luo KY, 2019, IEEE I CONF COMP VIS, P10451, DOI 10.1109/ICCV.2019.01055
   Ma XJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5712, DOI 10.1109/ICCV48922.2021.00568
   OpenMVS, 2015, About us
   Paszke A., 2017, P NEUR INF PROC SYST, P1
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   tanksandtemples, 2017, Tanks-and-temples
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Wang FJ, 2021, PROC CVPR IEEE, P14189, DOI 10.1109/CVPR46437.2021.01397
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xu QS, 2020, Arxiv, DOI arXiv:2007.07714
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12508
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12516
   Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563
   Yang JY, 2020, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, 2018, LECT NOTES COMPUT SC, V11212, P785, DOI 10.1007/978-3-030-01237-3_47
   Yao Y, 2020, PROC CVPR IEEE, P1787, DOI 10.1109/CVPR42600.2020.00186
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   Zhang JY, 2023, INT J COMPUT VISION, V131, P199, DOI 10.1007/s11263-022-01697-3
NR 41
TC 6
Z9 6
U1 5
U2 9
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3062
EP 3073
DI 10.1109/TVCG.2022.3165860
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700051
PM 35394911
DA 2024-11-06
ER

PT J
AU Song, SC
   Li, CH
   Li, D
   Chen, JT
   Wang, CB
AF Song, Sicheng
   Li, Chenhui
   Li, Dong
   Chen, Juntong
   Wang, Changbo
TI GraphDecoder: Recovering Diverse Network Graphs From Visualization
   Images via Attention-Aware Learning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Attention mechanism; chart mining; information visualization; network
   graph; semantic segmentation
ID CHART IMAGES; INFORMATION; RELIABILITY; EXTRACTION; FIGURES
AB DNGs are diverse network graphs with texts and different styles of nodes and edges, including mind maps, modeling graphs, and flowcharts. They are high-level visualizations that are easy for humans to understand but difficult for machines. Inspired by the process of human perception of graphs, we propose a method called GraphDecoder to extract data from raster images. Given a raster image, we extract the content based on a neural network. We built a semantic segmentation network based on U-Net. We increase the attention mechanism module, simplify the network model, and design a specific loss function to improve the model's ability to extract graph data. After this semantic segmentation network, we can extract the data of all nodes and edges. We then combine these data to obtain the topological relationship of the entire DNG. We also provide an interactive interface for users to redesign the DNGs. We verify the effectiveness of our method by evaluations and user studies on datasets collected on the internet and generated datasets.
C1 [Song, Sicheng; Li, Chenhui; Li, Dong; Chen, Juntong; Wang, Changbo] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
C3 East China Normal University
RP Li, CH; Wang, CB (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200062, Peoples R China.
EM scsong@stu.ecnu.edu.cn; chli@cs.ecnu.edu.cn;
   51194501141@stu.ecnu.edu.cn; jtchen@stu.ecnu.edu.cn;
   cbwang@cs.ecnu.edu.cn
RI Li, Chenhui/AAR-3682-2020; Chen, Juntong/KBV-8278-2024
OI Song, Sicheng/0000-0002-2158-0353; Li, Chenhui/0000-0001-9835-2650;
   Chen, Juntong/0000-0001-9343-4032; Wang, Changbo/0000-0001-8940-6418
FU NSFC [62072183]
FX This work was supported by the NSFC under Grant 62072183.
CR Al-Zaidy RA, 2017, AAAI CONF ARTIF INTE, P4644
   Alper B., 2013, P SIGCHI C HUM FACT, P483, DOI [DOI 10.1145/2470654.24707243,4,5, 10.1145/2470654.2470724]
   ANTV, 2018, About us
   Auer C., 2012, P INT S GRAPH DRAW, P529
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balaji A, 2018, Arxiv, DOI arXiv:1812.10636
   Berlingerio M, 2012, Arxiv, DOI [arXiv:1209.2684, 10.48550/arXiv.1209.2684, DOI 10.48550/ARXIV.1209.2684]
   Böschen F, 2018, MULTIMED TOOLS APPL, V77, P29475, DOI 10.1007/s11042-018-6162-7
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brynjolfsson E, 2016, AM ECON REV, V106, P133, DOI 10.1257/aer.p20161016
   Burns R, 2019, COMPUT INTELL-US, V35, P955, DOI 10.1111/coin.12227
   Buzan T., 1983, Use Both Sides of Your Brain
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Choi JO, 2019, COMPUT GRAPH FORUM, V38, P249, DOI 10.1111/cgf.13686
   Chollet F., 2015, KERAS
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cleveland W.S., 1985, The Elements of Graphing Data
   Cook C, 2001, EDUC PSYCHOL MEAS, V61, P697, DOI 10.1177/00131640121971356
   Dai WJ, 2018, J VISUAL LANG COMPUT, V48, P101, DOI 10.1016/j.jvlc.2018.08.005
   datadigitization, 2021, Dagra data digitizer
   Davila K, 2021, IEEE T PATTERN ANAL, V43, P3799, DOI 10.1109/TPAMI.2020.2992028
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   De P, 2018, IEEE INT ADV COMPUT, P20, DOI 10.1109/IADCC.2018.8692104
   Flower A, 2016, BEHAV MODIF, V40, P396, DOI 10.1177/0145445515616105
   Fu JY, 2021, IEEE T VIS COMPUT GR, V27, P337, DOI 10.1109/TVCG.2020.3030351
   Giovannangeli L, 2020, VIS INFORM, V4, P86, DOI 10.1016/j.visinf.2020.04.002
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Haehn D, 2019, IEEE T VIS COMPUT GR, V25, P641, DOI 10.1109/TVCG.2018.2865138
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Hu J., 2018, P 2018 IEEE CVF C CO, P7132
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kadic AJ, 2016, J CLIN EPIDEMIOL, V74, P119, DOI 10.1016/j.jclinepi.2016.01.002
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Kim DH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376467
   Kim D, 2018, PROC CVPR IEEE, P4167, DOI 10.1109/CVPR.2018.00438
   Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P465, DOI 10.1007/978-981-15-3863-6_51
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu MN, 2019, SOC SCI COMPUT REV, V37, P248, DOI 10.1177/0894439318755336
   Liu X., 2019, arXiv
   Liu Y, 2013, PROC SPIE, V8654, DOI 10.1117/12.2008467
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo JY, 2021, IEEE WINT CONF APPL, P1916, DOI 10.1109/WACV48630.2021.00196
   Ma KF, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540016
   Méndez GG, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4073, DOI 10.1145/2858036.2858435
   Mitchell M., 2020, markummitchell/engaugedigitizer: Nonrelease (v12.2.1). Zenodo, DOI [10.5281/zenodo.3941227, DOI 10.5281/ZENODO.3941227]
   Molla MKI, 2003, LECT NOTES COMPUT SC, V2690, P865
   Nassi I., 1973, SIGPLAN Notices, V8, P12, DOI 10.1145/953349.953350
   Oktay O., 2018, ARXIV
   Oldenhof M, 2020, J CHEM INF MODEL, V60, P4506, DOI 10.1021/acs.jcim.0c00459
   Opmanis R., 2018, P 13 INT JOINT C COM, P184
   Pin-Shan Chen P., 1976, ACM Transactions on Database Systems, V1, P9, DOI 10.1145/320434.320440
   Poco J, 2018, IEEE T VIS COMPUT GR, V24, P637, DOI 10.1109/TVCG.2017.2744320
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Reddy VK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P190, DOI 10.1109/CGVIS.2015.7449920
   Ren SQ, 2015, ADV NEUR IN, V28, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song S., IEEE Trans. Vis. Comput. Graph., DOI [10.1109/TVCG.2022.3153514.2I, DOI 10.1109/TVCG.2022.3153514.2I]
   Tian Z, 2016, LECT NOTES COMPUT SC, V9912, P56, DOI 10.1007/978-3-319-46484-8_4
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang QW, 2022, IEEE T VIS COMPUT GR, V28, P5134, DOI 10.1109/TVCG.2021.3106142
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   WILDER RL, 1978, AM MATH MON, V85, P720, DOI 10.2307/2321676
   Wu J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1200
   Wu RQ, 2009, J COMPUT SCI TECHNOL, V9, P58
   Yee KP, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P43
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Yun XL, 2019, LECT NOTES COMPUT SC, V11901, P232, DOI 10.1007/978-3-030-34120-6_19
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhou FF, 2021, J VISUAL-JAPAN, V24, P419, DOI 10.1007/s12650-020-00702-6
NR 84
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3074
EP 3088
DI 10.1109/TVCG.2022.3225554
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700086
PM 36449586
DA 2024-11-06
ER

PT J
AU Liu, SQ
   Tao, MT
   Huang, YF
   Wang, CB
   Li, CH
AF Liu, Shuqi
   Tao, Mingtian
   Huang, Yifei
   Wang, Changbo
   Li, Chenhui
TI Image-Driven Harmonious Color Palette Generation for Diverse Information
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image color analysis; Data visualization; Visualization; Task analysis;
   Encoding; Visual perception; Media; Visualization design; color palette;
   color assignment; information visualization; visual perception
ID MAPS
AB Color has been widely used to encode data in all types of visualizations. Effective color palettes contain discriminable and harmonious colors, which allow information from visualizations to be accurately and aesthetically conveyed. However, predefined color palettes not only lack the flexibility of custom color palette generation but also ignore the context in which the visualizations are used. Designing an effective color palette is a time-consuming and challenging process for users, even experts. In this work, we propose the generation of an image-based visualization color palette to exploit the human perception of visually appealing images while considering visualization cognition. By analyzing color palette constraints, including harmony, discrimination, and context, we propose an image-driven color generation method. We design a color clustering method in the saliency-hue plane based on visual importance detection and then select the palette based on the visualization color constraints. In addition, we design two color optimization and assignment strategies for visualizations of different data types. Evaluations through numeric indicators and user experiments demonstrate that the palettes predicted by our method are visually related to the original images and are aesthetically pleasing, supporting diverse visualization contexts and data types in practical applications.
C1 [Liu, Shuqi; Tao, Mingtian; Huang, Yifei; Wang, Changbo; Li, Chenhui] East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
C3 East China Normal University
RP Li, CH (corresponding author), East China Normal Univ, Sch Comp Sci & Technol, Shanghai 200050, Peoples R China.
EM shuqiliu234@gmail.com; 51205901082@stu.ecnu.edu.cn;
   yifeihuang17@gmail.com; cbwang@cs.ecnu.edu.cn; chli@cs.ecnu.edu.cn
RI Li, Chenhui/AAR-3682-2020; Huang, Yifei/J-6430-2019
OI Li, Chenhui/0000-0001-9835-2650; Wang, Changbo/0000-0001-8940-6418
FU NSFC [62072183]; Shanghai Committee of Science and Technology, China
   [22511104600]
FX This work was supported in part by NSFC under Grant 62072183 and in
   partby the Shanghai Committee of Science and Technology, China under
   Grant 22511104600.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Adobe color, 2022, About us
   Ahmad J, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P56, DOI 10.1109/VIS49827.2021.9623314
   Aksoy Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3002176
   [Anonymous], 2022, Aliyun Luban color-recog
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borland D, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.323435
   Borland D, 2011, IEEE COMPUT GRAPH, V31, P7, DOI 10.1109/MCG.2011.55
   Brewer C. A., 2005, Designing Better Maps: A Guide for GIS Users, V1
   Brewer C. A., 1994, Visual. Mod Cartogr., V1994, P123, DOI [DOI 10.1016/B978-0-08-042415-6.50014-4, 10.1016/b978-0-08-042415-6.50014-4]
   Burchett KE, 2002, COLOR RES APPL, V27, P28, DOI 10.1002/col.10004
   Chang HW, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766978
   Cohen-Or D, 2006, ACM T GRAPHIC, V25, P624, DOI 10.1145/1141911.1141933
   Cui WW, 2020, IEEE T VIS COMPUT GR, V26, P906, DOI 10.1109/TVCG.2019.2934785
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Du ZJ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459675
   Feng ZL, 2018, NEUROCOMPUTING, V273, P395, DOI 10.1016/j.neucom.2017.07.043
   Gerstner T., 2012, P S NONPH AN REND, P29
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Healey CG, 1996, IEEE VISUAL, P263, DOI 10.1109/VISUAL.1996.568118
   Huang YF, 2018, COMPUT GRAPH FORUM, V37, P421, DOI 10.1111/cgf.13579
   Kim EunJin, 2016, MM 16, P1316
   Kim SYO, 2020, INT CONF INTERNET, P154, DOI [10.23919/ICITST51030.2020.9351315, 10.1145/3372278.3390685]
   Kita N, 2016, COMPUT GRAPH FORUM, V35, P127, DOI 10.1111/cgf.13010
   Lara-Alvarez C, 2019, COLOR RES APPL, V44, P106, DOI 10.1002/col.22292
   Lee S, 2013, IEEE T VIS COMPUT GR, V19, P1746, DOI 10.1109/TVCG.2012.315
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu KC, 2021, IEEE T VIS COMPUT GR, V27, P475, DOI 10.1109/TVCG.2020.3030406
   Matsuda Y., 1995, Asakura Shoten, V2
   Maxwell BA, 2000, CARTOGR J, V37, P93
   Moreland K, 2009, LECT NOTES COMPUT SC, V5876, P92, DOI 10.1007/978-3-642-10520-3_9
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   O'Donovan P, 2014, IEEE T VIS COMPUT GR, V20, P1200, DOI 10.1109/TVCG.2014.48
   O'Donovan P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964958
   Ou LC, 2004, COLOR RES APPL, V29, P381, DOI 10.1002/col.20047
   Pan Q., 2018, COLOR IMAGING C, P110
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rogowitz BE, 2001, IEEE VISUAL, P183, DOI 10.1109/VISUAL.2001.964510
   Samsel F, 2021, 2021 IEEE VIS ARTS PROGRAM (VISAP 2021), P20, DOI 10.1109/VISAP52981.2021.00009
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shi Yang, 2023, IEEE Trans Vis Comput Graph, V29, P236, DOI 10.1109/TVCG.2022.3209486
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smart S, 2020, IEEE T VIS COMPUT GR, V26, P1215, DOI 10.1109/TVCG.2019.2934284
   Tan JC, 2017, ACM T GRAPHIC, V36, DOI 10.1145/2988229
   Tan KS, 2011, PATTERN RECOGN, V44, P1, DOI 10.1016/j.patcog.2010.07.013
   Tennekes M, 2014, IEEE T VIS COMPUT GR, V20, P2072, DOI 10.1109/TVCG.2014.2346277
   Tokumaru M, 2002, PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOL 1 & 2, P378, DOI 10.1109/FUZZ.2002.1005020
   Tominski C, 2008, IEEE INT CONF INF VI, P373, DOI 10.1109/IV.2008.24
   Tu WC, 2018, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2018.00066
   Tufte E., 1990, Envisioning information, V2
   Wang LJ, 2008, IEEE T VIS COMPUT GR, V14, P1739, DOI 10.1109/TVCG.2008.118
   Wang XR, 2020, PROC CVPR IEEE, P8087, DOI 10.1109/CVPR42600.2020.00811
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   WARE C, 1988, IEEE COMPUT GRAPH, V8, P41, DOI 10.1109/38.7760
   Weingerl P, 2020, COLOR RES APPL, V45, P409, DOI 10.1002/col.22485
   Xia HJ, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173797
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang FT, 2020, PROC CVPR IEEE, P13961, DOI 10.1109/CVPR42600.2020.01398
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4252, DOI 10.1109/TVCG.2021.3085327
   Zeileis A, 2009, COMPUT STAT DATA AN, V53, P3259, DOI 10.1016/j.csda.2008.11.033
   Zeng Q, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P266, DOI [10.1109/VISUAL.2019.8933764, 10.1109/visual.2019.8933764]
   Zhang Q, 2017, IEEE T IMAGE PROCESS, V26, P1952, DOI 10.1109/TIP.2017.2671779
   Zhao NX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201355
   Zheng XR, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322971
NR 70
TC 2
Z9 2
U1 4
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3089
EP 3103
DI 10.1109/TVCG.2022.3226218
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700073
PM 36459606
DA 2024-11-06
ER

PT J
AU Xiao, WP
   Xu, C
   Mai, JJ
   Xu, XM
   Li, Y
   Li, CZ
   Liu, XT
   He, SF
AF Xiao, Wenpeng
   Xu, Cheng
   Mai, Jiajie
   Xu, Xuemiao
   Li, Yue
   Li, Chengze
   Liu, Xueting
   He, Shengfeng
TI Appearance-Preserved Portrait-to-Anime Translation via Proxy-Guided
   Domain Adaptation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Adaptation models; Training; Strain; Shape; Semantics; Faces; Deformable
   models; Portrait-to-anime translation; coser portrait proxy; domain
   adaptation
ID GENERATIVE ADVERSARIAL NETWORKS
AB Converting a human portrait to anime style is a desirable but challenging problem. Existing methods fail to resolve this problem due to the large inherent gap between two domains that cannot be overcome by a simple direct mapping. For this reason, these methods struggle to preserve the appearance features in the original photo. In this article, we discover an intermediate domain, the coser portrait (portraits of humans costuming as anime characters), that helps bridge this gap. It alleviates the learning ambiguity and loosens the mapping difficulty in a progressive manner. Specifically, we start from learning the mapping between coser and anime portraits, and present a proxy-guided domain adaptation learning scheme with three progressive adaptation stages to shift the initial model to the human portrait domain. In this way, our model can generate visually pleasant anime portraits with well-preserved appearances given the human portrait. Our model adopts a disentangled design by breaking down the translation problem into two specific subtasks of face deformation and portrait stylization. This further elevates the generation quality. Extensive experimental results show that our model can achieve visually compelling translation with better appearance preservation and perform favorably against the existing methods both qualitatively and quantitatively. Our code and datasets are available at https://github.com/NeverGiveU/PDA-Translation.
C1 [Xiao, Wenpeng; Xu, Cheng; Xu, Xuemiao; Li, Yue] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Mai, Jiajie] Kings Coll London, London WC2R 2LS, England.
   [Xu, Xuemiao] Minist Educ, Key Lab Big Data & Intelligent Robot & Guangdong, State Key Lab Subtrop Bldg Sci, Prov Key Lab Computat Intelligence & Cyberspace In, Guangdong Province510641, Guangzhou, Peoples R China.
   [Li, Chengze; Liu, Xueting] Caritas Inst Higher Educ, Hong Kong, Peoples R China.
   [He, Shengfeng] Singapore Management Univ, Sch Comp & Informat Syst, Singapore 188065, Singapore.
C3 South China University of Technology; University of London; King's
   College London; Saint Francis University Hong Kong; Singapore Management
   University
RP Xu, XM (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Guangdong, Peoples R China.; He, SF (corresponding author), Singapore Management Univ, Sch Comp & Informat Syst, Singapore 188065, Singapore.
EM wpxiao.littleblack@gmail.com; cschengxu@gmail.com; k20035517@kcl.ac.uk;
   xuemx@scut.edu.cn; liyue@scut.edu.cn; czli@cihe.edu.hk;
   tliu@cihe.edu.hk; shengfenghe7@gmail.com
RI Xu, Cheng/HZL-1279-2023; Liu, Xueting/AAG-9648-2019; Xiao,
   Wenpeng/IQR-6827-2023; He, Shengfeng/E-5682-2016; Li,
   Chengze/AAU-7168-2021
OI Liu, Xueting/0000-0002-0868-5353; He, Shengfeng/0000-0002-3802-4644; Xu,
   Cheng/0000-0002-4281-6214; Li, Chengze/0000-0002-1519-750X
FU Guangdong International Technology Cooperation Project
   [2022A0505050009]; Key-Area Research and Development Program of
   Guangdong Province, China [2020B010165004, 2020B010166003]; National
   Natural Science Foundation of China [61972162]; Guangdong International
   Science and Technology Cooperation Project [2021A0505030009]; Guangdong
   Natural Science Foundation [2021A1515012625]; Guangzhou Basic and
   Applied Research Project [202102021074]; CCF-Tencent Open Research fund
   under Grant CCF-Tencent [RAGR20210114]; Research Grants Council of the
   Hong Kong Special Administrative Region, China, Project
   [UGC/FDS11/E02/21]
FX This work was supported in part by Guangdong International Technology
   Cooperation Project under Grant 2022A0505050009, in part by the Key-Area
   Research and Development Program of Guangdong Province, China under
   Grants 2020B010165004 and 2020B010166003, in part by the National
   Natural Science Foundation of China under Grant 61972162, in part by
   Guangdong International Science and Technology Cooperation Project under
   Grant 2021A0505030009, in part by Guangdong Natural Science Foundation
   under Grant 2021A1515012625, in part by Guangzhou Basic and Applied
   Research Project under Grant 202102021074, in part by CCF-Tencent Open
   Research fund under Grant CCF-Tencent RAGR20210114, and in part by Grant
   from the Research Grants Council of the Hong Kong Special Administrative
   Region, China, Project under Grant UGC/FDS11/E02/21.
CR [Anonymous], 2021, Danbooru2020: A Large-Scale Crowdsourced and Tagged Anime Illustration Dataset
   Back J., 2021, arXiv
   Cao J. Liao, 2018, ACM Trans. Graphics, V37, P1, DOI [10.1145/3272127.3275046, DOI 10.1145/3272127.3275046]
   Cheng JX, 2021, PROC CVPR IEEE, P134, DOI 10.1109/CVPR46437.2021.00020
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chong D., 2021, arXiv
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fang Gongfan, 2021, Advances in Neural Information Processing Systems, V34
   Furusawa C, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149430
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Han FZ, 2023, IEEE T VIS COMPUT GR, V29, P1371, DOI 10.1109/TVCG.2021.3114308
   Heusel M., 2017, Advances in neural information processing systems, P6629
   Huang JL, 2022, IEEE T MULTIMEDIA, V24, P1435, DOI 10.1109/TMM.2021.3065230
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P., 2017, P IEEE C COMPUTER VI, P1125, DOI 10.1109/CVPR.2017.632
   Jang W, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459860
   Karras T., 2018, INT C LEARNING REPRE, P1
   Karras T, 2020, Arxiv, DOI arXiv:2006.06676
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim J, 2020, PROC INT C LEARN REP
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D.P., 2014, P INT C LEARNING REP
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li B, 2022, IEEE T MULTIMEDIA, V24, P4077, DOI 10.1109/TMM.2021.3113786
   Li HL, 2011, IEEE T MULTIMEDIA, V13, P1230, DOI 10.1109/TMM.2011.2168814
   Liu M.-Y., 2017, INT C ADV NEURAL INF, P700
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Pinkney JNM, 2020, Arxiv, DOI arXiv:2010.05334
   Nagadomi, 2014, lbpcascade_animeface
   Paszke A, 2019, ADV NEUR IN, V32
   Rosin PL, 2022, COMPUT VIS MEDIA, V8, P445, DOI 10.1007/s41095-021-0255-3
   Shi J.-Q., IEEE Trans. Vis.Comp. Graph., DOI [10.1109/TVCG.2022.3146000.11R, DOI 10.1109/TVCG.2022.3146000.11R]
   Shu YZ, 2022, IEEE T VIS COMPUT GR, V28, P3376, DOI 10.1109/TVCG.2021.3067201
   Song GX, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459771
   Su H, 2021, AAAI CONF ARTIF INTE, V35, P2611
   Sun Y. Hou, 2021, P IEEE CVF INT C COM, p11 761
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wei YX, 2021, PROC CVPR IEEE, P13380, DOI 10.1109/CVPR46437.2021.01318
   Wu RZ, 2019, Arxiv, DOI arXiv:1907.01424
   Xu C, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3554739
   Xu W. Qu, IEEETrans. Vis. Comp. Graph., DOI [10.1109/TVCG.2022.3174656.10M., DOI 10.1109/TVCG.2022.3174656.10M]
   Yao Yue, 2020, ECCV, P775
   Ye ZP, 2023, IEEE T VIS COMPUT GR, V29, P2203, DOI 10.1109/TVCG.2021.3126659
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang W., 2014, inSIGGRAPH Asia, P1
   Zhang Y, 2017, IEEE T IMAGE PROCESS, V26, P464, DOI 10.1109/TIP.2016.2628581
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 1
Z9 1
U1 7
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3104
EP 3120
DI 10.1109/TVCG.2022.3228707
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700032
PM 37015410
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Diller, F
   Scheuermann, G
   Wiebel, A
AF Diller, Florian
   Scheuermann, Gerik
   Wiebel, Alexander
TI Visual Cue Based Corrective Feedback for Motor Skill Training in Mixed
   Reality: A Survey
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Mixed reality; Augmented reality; Training; Task
   analysis; Sports; Feedback loop; Human-centered computing;
   visualization; visualization techniques and methodologies; interaction
   techniques; virtual and augmented reality
AB When learning a motor skill it is helpful to get corrective feedback from an instructor. This will support the learner to execute the movement correctly. With modern technology, it is possible to provide this feedback via mixed reality. In most cases, this involves visual cues to help the user understand the corrective feedback. We analyzed recent research approaches utilizing visual cues for feedback in mixed reality. The scope of this article is visual feedback for motor skill learning, which involves physical therapy, exercise, rehabilitation etc. While some of the surveyed literature discusses therapeutic effects of the training, this article focuses on visualization techniques. We categorized the literature from a visualization standpoint, including visual cues, technology and characteristics of the feedback. This provided insights into how visual feedback in mixed reality is applied in the literature and how different aspects of the feedback are related. The insights obtained can help to better adjust future feedback systems to the target group and their needs. This article also provides a deeper understanding of the characteristics of the visual cues in general and promotes future, more detailed research on this topic.
C1 [Diller, Florian; Wiebel, Alexander] Hsch Worms Univ Appl Sci, UX Vis Grp, D-67549 Worms, Germany.
   [Scheuermann, Gerik] Univ Leipzig, BSV Grp, D-04109 Leipzig, Germany.
C3 Leipzig University
RP Diller, F (corresponding author), Hsch Worms Univ Appl Sci, UX Vis Grp, D-67549 Worms, Germany.
EM diller@hs-worms.de; scheuermann@informatik.uni-leipzig.de;
   wiebel@hs-worms.de
OI Wiebel, Alexander/0000-0002-6583-3092; Diller,
   Florian/0000-0001-7421-750X
FU ProFIL -Programm zur Forderung des Forschungspersonals, Infrastruktur
   und forschendem Lernenof HSWorms; German Federal Ministry for Economic
   Affairs and Energy [16KN087122]
FX This work was supported in part by ProFIL -Programm zur Forderung des
   Forschungspersonals, Infrastruktur und forschendem Lernenof HSWorms. All
   other work was supported in part by ZIM under Grant 16KN087122 from the
   German Federal Ministry for Economic Affairs and Energy.
CR Afyouni I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247037
   Badampudi C., 2015, P 19 INT C EV ASS SO, P1
   Barioni RR, 2019, SYMP VIRTUAL AUGMENT, P10, DOI 10.1109/SVR.2019.00018
   Booth ATC, 2019, CLIN BIOMECH, V70, P146, DOI 10.1016/j.clinbiomech.2019.08.013
   Booth ATC, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.01208
   Brennan L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010181
   Butterfield A., 2016, A Dictionary of ComputerScience
   Cao X., 2020, P CHI C HUM FACT COM, P1
   Caserman P, 2022, IEEE T GAMES, V14, P243, DOI 10.1109/TG.2021.3064749
   Clarke Christopher, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P196, DOI 10.1145/3379337.3415591
   Conner Caleb., 2016, Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems, P3028, DOI DOI 10.1145/2851581.2892519
   Davies E., 2003, P SPAC REQ WHEEL MOB, P62
   Debarba HG, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P537, DOI 10.1109/VR.2018.8446368
   Escalona F, 2020, VIRTUAL REAL-LONDON, V24, P567, DOI 10.1007/s10055-019-00419-4
   Fitts PM., 1967, Human performance
   Furukawa Shiho, 2018, TOHOKU SEC TION JOIN, P213
   Gandhi DBC, 2020, THER CLIN RISK MANAG, V16, P75, DOI 10.2147/TCRM.S206883
   Gattullo M, 2022, IEEE T VIS COMPUT GR, V28, P1443, DOI 10.1109/TVCG.2020.3014614
   Greenhalgh T, 2005, BRIT MED J, V331, P1064, DOI 10.1136/bmj.38636.593461.68
   Han PH, 2016, PROCEEDINGS OF THE 7TH AUGMENTED HUMAN INTERNATIONAL CONFERENCE (AUGMENTED HUMAN 2016), DOI 10.1145/2875194.2875237
   Han Y.-S., 2017, P 8 AUGM HUM INT C, P1
   Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487
   Hilton D, 2011, STUD COMPUT INTELL, V337, P193
   Hoang TN, 2016, PROCEEDINGS OF THE NORDICHI '16: THE 9TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION - GAME CHANGING DESIGN, DOI 10.1145/2971485.2971521
   Huber J., 2013, Applying educational psychology in coaching athletes
   Hülsmann F, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00043
   IJsselsteijn Y. D., 2004, P 3 INT C ENT COMP, P46
   Ikeda A, 2018, P INT C ART REAL TEL, P171
   Ikeda A, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1527, DOI [10.1109/vr.2019.8798196, 10.1109/VR.2019.8798196]
   Karatsidis A, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0419-2
   Kosmalla F, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE SURFACES AND SPACES (ACM ISS 2017), P270, DOI 10.1145/3132272.3134119
   Liebermann DG, 2002, J SPORT SCI, V20, P755, DOI 10.1080/026404102320675611
   LYSAKOWSKI RS, 1982, AM EDUC RES J, V19, P559, DOI 10.2307/1162544
   Ma MH, 2011, STUD COMPUT INTELL, V337, P169
   Marti K. C. S., 2019, Masters Thesis
   Meyer B, 2018, ADJUNCT PUBLICATION OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST'18 ADJUNCT), P54, DOI 10.1145/3266037.3266099
   MILGRAM P, 1994, P SOC PHOTO-OPT INS, V2351, P282
   Mills KR, 2005, J NEUROL NEUROSUR PS, V76, P32, DOI 10.1136/jnnp.2005.069211
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.1136/bmj.i4086, 10.1186/2046-4053-4-1, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299, 10.1371/journal.pmed.1000097]
   Mohr P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6547, DOI 10.1145/3025453.3025688
   Morone G, 2021, EXPERT REV MED DEVIC, V18, P513, DOI 10.1080/17434440.2021.1927704
   Mostajeran F, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1465, DOI [10.1109/vr.2019.8797813, 10.1109/VR.2019.8797813]
   Mubin O, 2022, DISABIL REHABIL-ASSI, V17, P159, DOI 10.1080/17483107.2020.1768309
   Murlowski C, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313250
   Naour T.L, 2019, Front. ICT, V6
   Neumann DL, 2018, VIRTUAL REAL-LONDON, V22, P183, DOI 10.1007/s10055-017-0320-5
   Nilsson N.C., 2016, HUMAN TECHNOLOGY, V12, P108, DOI [10.17011/ht/urn.201611174652, DOI 10.17011/HT/URN.201611174652]
   Oh Y., 2010, Proceedings of Meaningful Play 2010, P1
   Oka M, 2021, PROC SPIE, V11766, DOI 10.1117/12.2591035
   Oshita M, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P82, DOI 10.1109/CW.2018.00025
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167259
   Pereira V., 2017, P 11 EAI INT C PERV, P146
   Perin C, 2018, COMPUT GRAPH FORUM, V37, P663, DOI 10.1111/cgf.13447
   Pucihar KC, 2015, LECT NOTES COMPUT SC, V9299, P523, DOI 10.1007/978-3-319-22723-8_53
   Quevedo WX, 2017, LECT NOTES COMPUT SC, V10325, P166, DOI 10.1007/978-3-319-60928-7_14
   Raffe WL, 2018, IEEE INT CONF SERIOU
   Rutkowski S, 2020, J REHABIL MED, V52, DOI 10.2340/16501977-2755
   Sawan Nedal, 2020, EBEE 2020: 2020 2nd International Conference on E-Business and E-commerce Engineering, P55, DOI 10.1145/3446922.3446932
   Schiza E, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00100
   Schmalstieg T., 2016, Augmented Reality: Principles andPractice
   Schmidt C., 2004, Motor Learning and Performance, P62
   Sekhavat YA, 2018, IEEE T HUM-MACH SYST, V48, P626, DOI 10.1109/THMS.2018.2860579
   Shiro K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1563, DOI [10.1109/vr.2019.8798366, 10.1109/VR.2019.8798366]
   SINGH R, 1978, LINGUISTICS, P79
   Sousa M, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P175, DOI 10.1145/2856767.2856773
   Speicher B. D., 2019, P CHI C HUM FACT COM, P1
   Swinnen SP, 1997, HUM MOVEMENT SCI, V16, P749, DOI 10.1016/S0167-9457(97)00020-1
   Takahashi K, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1353, DOI 10.1109/vr.2019.8798005
   Tang R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4123, DOI 10.1145/2702123.2702401
   Taylor JA, 2012, ANN NY ACAD SCI, V1251, P1, DOI 10.1111/j.1749-6632.2011.06430.x
   Trajkova Milka, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191770
   Trepkowski C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P575, DOI [10.1109/VR.2019.8798312, 10.1109/vr.2019.8798312]
   Vidal LT, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376268
   Viglialoro RM, 2019, INFORMATION, V10, DOI 10.3390/info10050154
   Waltemate T, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P27, DOI 10.1145/2993369.2993381
   Ware J.B, 2020, International Patent, Patent No. [WO2020/163163A1, 2020163163]
   Wiehr Frederik, 2016, P CHI C HUM FACT COM, P1998
   Wohlin C., 2014, P 18 INT C EV ASS SO, P1, DOI [10.1145/2601248.2601268, DOI 10.1145/2601248.2601268]
   Yu XY, 2020, INT SYM MIX AUGMENT, P577, DOI 10.1109/ISMAR50242.2020.00085
NR 79
TC 2
Z9 2
U1 4
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3121
EP 3134
DI 10.1109/TVCG.2022.3227999
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700064
PM 37015488
OA hybrid
DA 2024-11-06
ER

PT J
AU Deng, ZK
   Chen, SF
   Xie, X
   Sun, GD
   Xu, ML
   Weng, D
   Wu, YC
AF Deng, Zikun
   Chen, Shifu
   Xie, Xiao
   Sun, Guodao
   Xu, Mingliang
   Weng, Di
   Wu, Yingcai
TI Multilevel Visual Analysis of Aggregate Geo-Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Geospatial network; multilevel analysis; information visualization;
   graph drawing
ID OF-THE-ART; MASS MOBILITY; MAP LAYOUT; VISUALIZATION; ABSTRACTION;
   EVOLUTION; DYNAMICS; PATTERNS; AWARE
AB Numerous patterns found in urban phenomena, such as air pollution and human mobility, can be characterized as many directed geospatial networks (geo-networks) that represent spreading processes in urban space. These geo-networks can be analyzed from multiple levels, ranging from the macro-level of summarizing all geo-networks, meso-level of comparing or summarizing parts of geo-networks, and micro-level of inspecting individual geo-networks. Most of the existing visualizations cannot support multilevel analysis well. These techniques work by: 1) showing geo-networks separately with multiple maps leads to heavy context switching costs between different maps; 2) summarizing all geo-networks into a single network can lead to the loss of individual information; 3) drawing all geo-networks onto one map might suffer from the visual scalability issue in distinguishing individual geo-networks. In this study, we propose GeoNetverse, a novel visualization technique for analyzing aggregate geo-networks from multiple levels. Inspired by metro maps, GeoNetverse balances the overview and details of the geo-networks by placing the edges shared between geo-networks in a stacked manner. To enhance the visual scalability, GeoNetverse incorporates a level-of-detail rendering, a progressive crossing minimization, and a coloring technique. A set of evaluations was conducted to evaluate GeoNetverse from multiple perspectives.
C1 [Deng, Zikun; Chen, Shifu; Wu, Yingcai] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
   [Xie, Xiao] Zhejiang Univ, Dept Sport Sci, Hangzhou 310058, Zhejiang, Peoples R China.
   [Sun, Guodao] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310014, Zhejiang, Peoples R China.
   [Xu, Mingliang] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450052, Peoples R China.
   [Xu, Mingliang] MOE China Natl Supercomp Ctr Zhengzhou, Engn Res Ctr Intelligent Swarm Syst, Zhengzhou 450052, Peoples R China.
   [Weng, Di] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Zhejiang University; Zhejiang University; Zhejiang University of
   Technology; Zhengzhou University; Microsoft; Microsoft Research Asia
RP Wu, YC (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.; Weng, D (corresponding author), Microsoft Res Asia, Beijing 100080, Peoples R China.
EM zikun_rain@zju.edu.cn; sfchen@zju.edu.cn; xxie@zju.edu.cn;
   guodao@zjut.edu.cn; iexumingliang@zzu.edu.cn; mystery.wd@gmail.com;
   ycwu@zju.edu.cn
RI Deng, Zikun/IQT-3106-2023; Sun, Guodao/AAN-4428-2021; Weng,
   Di/ABG-7408-2020
OI Deng, Zikun/0000-0002-4477-5292; Sun, Guodao/0000-0002-8383-8153; Weng,
   Di/0000-0003-2712-7274
FU NSFC [62072400, 61972356, 62036010]; Collaborative Innovation Center of
   Artificial Intelligence by MOE; Zhejiang Provincial Government (ZJU)
FX This work was supported in part by NSFC under Grants 62072400, 61972356,
   and 62036010 and in part by the Collaborative Innovation Center of
   Artificial Intelligence by MOE and Zhejiang Provincial Government (ZJU).
   Yingcai Wu and Di Weng are the co-corresponding authors.
CR Andrienko G, 2017, IEEE T VIS COMPUT GR, V23, P2120, DOI 10.1109/TVCG.2016.2616404
   Andrienko N, 2016, INFORM SYST, V57, P172, DOI 10.1016/j.is.2015.08.007
   Andrienko N, 2011, IEEE T VIS COMPUT GR, V17, P205, DOI 10.1109/TVCG.2010.44
   Arendt D, 2017, IEEE CONF VIS ANAL, P81, DOI 10.1109/VAST.2017.8585487
   Bach B., 2011, P INT C WORLD WID WE, P177
   Bast H, 2019, ACM TRANS SPAT ALGOR, V5, DOI 10.1145/3337790
   BENDER EA, 1985, J ALGORITHM, V6, P275, DOI 10.1016/0196-6774(85)90044-6
   Bourqui R, 2016, IEEE PAC VIS SYMP, P184, DOI 10.1109/PACIFICVIS.2016.7465267
   Cakmak E, 2020, COMPUT GRAPH FORUM, V39, P63, DOI 10.1111/cgf.13963
   Chen W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200766
   Deng Z., 2022, J. Vis., P1
   Deng ZK, 2023, COMPUT VIS MEDIA, V9, P3, DOI 10.1007/s41095-022-0275-7
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P1051, DOI 10.1109/TVCG.2021.3114875
   Deng ZK, 2022, IEEE T VIS COMPUT GR, V28, P2486, DOI 10.1109/TVCG.2021.3071387
   Deng ZK, 2020, IEEE T VIS COMPUT GR, V26, P800, DOI 10.1109/TVCG.2019.2934670
   Dong Y., 2022, J. Vis.
   Ducruet C, 2017, J TRANSP GEOGR, V60, P47, DOI 10.1016/j.jtrangeo.2017.02.007
   Dübel S, 2014, 2014 IEEE VIS INTERNATIONAL WORKSHOP ON 3DVIS (3DVIS), P11, DOI 10.1109/3DVis.2014.7160094
   Feng ZZ, 2021, IEEE T VIS COMPUT GR, V27, P828, DOI 10.1109/TVCG.2020.3030469
   Fink Martin, 2013, Graph Drawing. 21st International Symposium, GD 2013. Revised Selected Papers: LNCS 8242, P328, DOI 10.1007/978-3-319-03841-4_29
   Gansner ER, 2011, IEEE PAC VIS SYMP, P187, DOI 10.1109/PACIFICVIS.2011.5742389
   Garcia G, 2021, IEEE T VIS COMPUT GR, V27, P2313, DOI 10.1109/TVCG.2019.2947515
   Guo DS, 2012, T GIS, V16, P411, DOI 10.1111/j.1467-9671.2012.01344.x
   Hong L, 2015, 23RD ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2015), DOI 10.1145/2820783.2820811
   Hou YJ, 2022, IEEE T VIS COMPUT GR, V28, P1030, DOI 10.1109/TVCG.2021.3114777
   Huang XK, 2016, IEEE T VIS COMPUT GR, V22, P160, DOI 10.1109/TVCG.2015.2467771
   HUFF DL, 1963, LAND ECON, V39, P81, DOI 10.2307/3144521
   Hurter C, 2012, COMPUT GRAPH FORUM, V31, P865, DOI 10.1111/j.1467-8659.2012.03079.x
   Hurter C, 2019, IEEE T VIS COMPUT GR, V25, P704, DOI 10.1109/TVCG.2018.2865191
   Jamonnak S, 2022, IEEE T VIS COMPUT GR, V28, P1019, DOI 10.1109/TVCG.2021.3114853
   Jensen T. R., 2011, Graph Coloring Problems
   Ko S, 2014, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2014.7042484
   Lee B., 2006, P AVI WORKSH TIM ERR, P1, DOI [DOI 10.1145/1168149.1168168, 10.1145/1168149.1168168]
   Li XC, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1863, DOI 10.1145/3097983.3098090
   Liang YX, 2017, 25TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2017), DOI 10.1145/3139958.3139960
   Liu DY, 2017, IEEE T VIS COMPUT GR, V23, P1, DOI 10.1109/TVCG.2016.2598432
   Liu HY, 2021, VIS INFORM, V5, P1, DOI 10.1016/j.visinf.2021.10.002
   Liu SX, 2013, IEEE T VIS COMPUT GR, V19, P2436, DOI 10.1109/TVCG.2013.196
   Liu Shuhan, 2023, IEEE Trans Vis Comput Graph, V29, P1091, DOI 10.1109/TVCG.2022.3209430
   Lu M, 2017, IEEE T BIG DATA, V3, P234, DOI 10.1109/TBDATA.2017.2667700
   Malaguti E, 2010, INT T OPER RES, V17, P1, DOI 10.1111/j.1475-3995.2009.00696.x
   McGee F, 2019, COMPUT GRAPH FORUM, V38, P125, DOI 10.1111/cgf.13610
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Mutzel P, 2001, SIAM J OPTIMIZ, V11, P1065, DOI 10.1137/S1052623498334013
   Nobre C, 2019, COMPUT GRAPH FORUM, V38, P807, DOI 10.1111/cgf.13728
   Nollenburg M., 2014, P SCHEM MAPP WORKSH
   Pérez-Messina I, 2020, ALGORITHMS, V13, DOI 10.3390/a13110298
   Peysakhovich V, 2015, IEEE PAC VIS SYMP, P39, DOI 10.1109/PACIFICVIS.2015.7156354
   Roth RE, 2013, IEEE T VIS COMPUT GR, V19, P2356, DOI 10.1109/TVCG.2013.130
   Schöttler S, 2021, COMPUT GRAPH FORUM, V40, P5, DOI 10.1111/cgf.14198
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Tang T, 2022, IEEE T VIS COMPUT GR, V28, P846, DOI 10.1109/TVCG.2021.3114781
   Tang T, 2021, IEEE T VIS COMPUT GR, V27, P294, DOI 10.1109/TVCG.2020.3030467
   Tang T, 2019, IEEE T VIS COMPUT GR, V25, P769, DOI 10.1109/TVCG.2018.2864899
   Tao Y., 2012, J. Vis., P1
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P2310, DOI 10.1109/TVCG.2014.2346441
   Vehlow C, 2015, COMPUT GRAPH FORUM, V34, P277, DOI 10.1111/cgf.12512
   Verbeek K, 2011, IEEE T VIS COMPUT GR, V17, P2536, DOI 10.1109/TVCG.2011.202
   von Landesberger T, 2016, IEEE T VIS COMPUT GR, V22, P11, DOI 10.1109/TVCG.2015.2468111
   Wang Baldonado M. Q., 2000, P WORK C ADV VIS INT, P110, DOI [DOI 10.1145/345513.345271, 10/cqq2cj]
   Wang HX, 2021, VIS INFORM, V5, P82, DOI 10.1016/j.visinf.2021.09.001
   Wang ZC, 2013, IEEE T VIS COMPUT GR, V19, P2159, DOI 10.1109/TVCG.2013.228
   Weng D, 2021, IEEE T INTELL TRANSP, V22, P1185, DOI 10.1109/TITS.2020.2964012
   Weng D, 2021, IEEE T VIS COMPUT GR, V27, P817, DOI 10.1109/TVCG.2020.3030458
   Weng D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173821
   Weng D, 2019, IEEE T VIS COMPUT GR, V25, P459, DOI 10.1109/TVCG.2018.2865126
   Wood J, 2010, CARTOGR J, V47, P117, DOI 10.1179/000870410X12658023467367
   Wu HY, 2020, COMPUT GRAPH FORUM, V39, P618, DOI 10.1111/cgf.14030
   Wu WC, 2016, IEEE T VIS COMPUT GR, V22, P935, DOI 10.1109/TVCG.2015.2467194
   Wu YC, 2021, IEEE T INTELL TRANSP, V22, P3387, DOI 10.1109/TITS.2020.2983226
   Yang C, 2023, IEEE T VIS COMPUT GR, V29, P3586, DOI 10.1109/TVCG.2022.3165385
   Yang YL, 2019, IEEE T VIS COMPUT GR, V25, P693, DOI 10.1109/TVCG.2018.2865192
   Yang YL, 2017, IEEE T VIS COMPUT GR, V23, P411, DOI 10.1109/TVCG.2016.2598885
   Zarate DC, 2018, IEEE PAC VIS SYMP, P135, DOI 10.1109/PacificVis.2018.00025
   Zhao WX, 2022, VIS INFORM, V6, P1, DOI 10.1016/j.visinf.2022.06.002
   Zhao Y, 2021, IEEE T VIS COMPUT GR, V27, P1698, DOI 10.1109/TVCG.2020.3030428
   Zheng JX, 2021, IEEE T VIS COMPUT GR, V27, P2244, DOI 10.1109/TVCG.2019.2944619
NR 79
TC 1
Z9 1
U1 3
U2 7
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3135
EP 3150
DI 10.1109/TVCG.2022.3229953
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700049
PM 37015452
DA 2024-11-06
ER

PT J
AU Zhou, H
   Ma, R
   Zhang, LX
   Gao, L
   Mahdavi-Amiri, A
   Zhang, H
AF Zhou, Hang
   Ma, Rui
   Zhang, Ling-Xiao
   Gao, Lin
   Mahdavi-Amiri, Ali
   Zhang, Hao
TI SAC-GAN: Structure-Aware Image Composition
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Layout; Transforms; Semantics; Three-dimensional displays; Image edge
   detection; Codes; Coherence; Structure-aware image composition;
   self-supervision; GANs
ID VISION
AB We introduce an end-to-end learning framework for image-to-image composition, aiming to plausibly compose an object represented as a cropped patch from an object image into a background scene image. As our approach emphasizes more on semantic and structural coherence of the composed images, rather than their pixel-level RGB accuracies, we tailor the input and output of our network with structure-aware features and design our network losses accordingly, with ground truth established in a self-supervised setting through the object cropping. Specifically, our network takes the semantic layout features from the input scene image, features encoded from the edges and silhouette in the input object patch, as well as a latent code as inputs, and generates a 2D spatial affine transform defining the translation and scaling of the object patch. The learned parameters are further fed into a differentiable spatial transformer network to transform the object patch into the target image, where our model is trained adversarially using an affine transform discriminator and a layout discriminator. We evaluate our network, coined SAC-GAN, for various image composition scenarios in terms of quality, composability, and generalizability of the composite images. Comparisons are made to state-of-the-art alternatives, including Instance Insertion, ST-GAN, CompGAN and PlaceNet, confirming superiority of our method.
C1 [Zhou, Hang; Mahdavi-Amiri, Ali; Zhang, Hao] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   [Ma, Rui] Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
   [Ma, Rui] Minist Educ, Engn Res Ctr Knowledge Driven Human Machine Intell, Changchun 130012, Peoples R China.
   [Zhang, Ling-Xiao; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing 100045, Peoples R China.
C3 Simon Fraser University; Jilin University; Chinese Academy of Sciences;
   Institute of Computing Technology, CAS
RP Ma, R (corresponding author), Jilin Univ, Sch Artificial Intelligence, Changchun 130012, Peoples R China.
EM zhouhang2991@gmail.com; ruim@jlu.edu.cn; zhanglingxiao@ict.ac.cn;
   gaolin@ict.ac.cn; amahdavi@sfu.ca; haoz@sfu.ca
RI Gao, Lin/JNF-0375-2023; Ma, Rui/Y-3479-2019; Zhou, Hang/AAI-5565-2021;
   wu, tong/ITV-6896-2023
OI Ma, Rui/0000-0002-3477-1466; Zhang, Ling-Xiao/0000-0001-8922-7639; Zhou,
   Hang/0000-0001-7860-8452; Zhang, Hao/0000-0003-1991-119X
FU NSERC Discovery [611370]; National Natural Science Funds of China
   [62202199]
FX This work was supported in part by NSERC Discovery under Grant 611370,
   and in part by National Natural Science Funds of China under Grant
   62202199.
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   Antoniou A., 2017, Data augmentation generative adversarial networks
   Azadi S, 2020, INT J COMPUT VISION, V128, P2570, DOI 10.1007/s11263-020-01336-9
   Bhattad A., 2020, AR XIV201005907
   Brinkmann R., 2008, The Art and Science of Digital Compositing
   Chang T.-Y., 2020, P AS C COMP VIS, P509
   Chaudhuri S, 2020, COMPUT GRAPH FORUM, V39, P643, DOI 10.1111/cgf.14020
   Chen BC, 2019, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2019.00861
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Y, 2021, PROC CVPR IEEE, P7226, DOI 10.1109/CVPR46437.2021.00715
   Cong WY, 2020, PROC CVPR IEEE, P8391, DOI 10.1109/CVPR42600.2020.00842
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Ding H., IEEE T PATTERN ANAL, DOI 10.1109/TauRhoAlphaMuIota2022.3217852
   Ding HH, 2020, IEEE T IMAGE PROCESS, V29, P3520, DOI 10.1109/TIP.2019.2962685
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   Einabadi F, 2021, COMPUT GRAPH FORUM, V40, P315, DOI 10.1111/cgf.14283
   Fu H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10913, DOI 10.1109/ICCV48922.2021.01075
   Fu H, 2021, INT J COMPUT VISION, V129, P3313, DOI 10.1007/s11263-021-01534-z
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gu JQ, 2022, PROC CVPR IEEE, P12084, DOI 10.1109/CVPR52688.2022.01178
   Guo Michelle, 2020, arXiv
   Hensel M, 2017, ADV NEUR IN, V30
   Hong S., 2018, Advances in Neural Information Processing Systems, P2713
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin JC, 2021, IEEE INT CONF COMP V, P2951, DOI 10.1109/ICCVW54120.2021.00330
   Jocher G., 2021, YOLOv5
   Karsch K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602146
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kholgade N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601209
   Kim T, 2017, PR MACH LEARN RES, V70
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276381
   Larsen ABL, 2016, PR MACH LEARN RES, V48
   Le Moing G, 2021, PROC CVPR IEEE, P9338, DOI 10.1109/CVPR46437.2021.00922
   Lee D, 2018, ADV NEUR IN, V31
   Lin CH, 2018, PROC CVPR IEEE, P9455, DOI 10.1109/CVPR.2018.00985
   Lingzhi Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P566, DOI 10.1007/978-3-030-58601-0_34
   Liu, 2021, ARXIV
   Liu DQ, 2020, PROC CVPR IEEE, P8136, DOI 10.1109/CVPR42600.2020.00816
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mitra NJ, 2013, EUROGRAPHICS STATE A, P175
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Niemeyer M, 2021, PROC CVPR IEEE, P11448, DOI 10.1109/CVPR46437.2021.01129
   Niu L., 2021, ARXIV
   Ntavelis Evangelos, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P394, DOI 10.1007/978-3-030-58542-6_24
   Ost J, 2021, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR46437.2021.00288
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Porter T., 1984, P SIGGRAPH, P253, DOI DOI 10.1145/964965.808606
   Radford A, 2021, PR MACH LEARN RES, V139
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Tan FW, 2018, IEEE WINT CONF APPL, P1519, DOI 10.1109/WACV.2018.00170
   Tao A., 2020, ARXIV
   Tewari A, 2020, COMPUT GRAPH FORUM, V39, P701, DOI 10.1111/cgf.14022
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wang J, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/969456
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang YF, 2021, PROC CVPR IEEE, P5106, DOI 10.1109/CVPR46437.2021.00507
   Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139
   Xu Z., 2017, ARXIV
   Yang BB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13759, DOI 10.1109/ICCV48922.2021.01352
   Yang ZP, 2022, PROC CVPR IEEE, P7754, DOI 10.1109/CVPR52688.2022.00761
   Yi RJ, 2018, LECT NOTES COMPUT SC, V11213, P321, DOI 10.1007/978-3-030-01240-3_20
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yifan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P438, DOI 10.1007/978-3-030-58607-2_26
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Zhan FN, 2019, PROC CVPR IEEE, P3648, DOI 10.1109/CVPR.2019.00377
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao S., 2020, P INT C LEARN REPR, P1
   Zhou SY, 2022, LECT NOTES COMPUT SC, V13677, P373, DOI 10.1007/978-3-031-19790-1_23
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 74
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3151
EP 3165
DI 10.1109/TVCG.2022.3226689
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700035
PM 37015486
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Chen, HR
   Wei, LT
   Liu, HM
   Shi, BX
   Zhang, GF
   Zha, HB
AF Chen, Haoran
   Wei, Lantian
   Liu, Haomin
   Shi, Boxin
   Zhang, Guofeng
   Zha, Hongbin
TI MOUNT: Learning 6DoF Motion Prediction Based on Uncertainty Estimation
   for Delayed AR Rendering
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Rendering (computer graphics); Uncertainty; Task analysis; Delays; Head;
   Hardware; Glass; Virtual and augmented reality; learning environments;
   learning technologies
ID LOCALIZATION; VERSATILE; TRACKING; VISION; ROBUST
AB The delay of rendering on AR devices requires prediction of head motion using sensor data acquired tens of even one hundred milliseconds ago to avoid misalignment between the virtual content and the physical world, where the misalignment will lead to a sense of time latency and dizziness for users. To solve the problem, we propose a method for the 6DoF motion prediction to compensate for the time latency. Compared with traditional hand-crafted methods, our method is based on deep learning, which has better motion prediction ability to deal with complex human motion. In particular, we propose a MOtion UNcerTainty encode decode network (MOUNT) that estimates the uncertainty of input data and predicts the uncertainty of output motion to improve the prediction accuracy and smoothness. Experiments on the EuRoC and our collected dataset demonstrate that our method significantly outperforms the traditional method and greatly improves AR visual effects.
C1 [Chen, Haoran] Peking Univ, AI Innovat Ctr, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Wei, Lantian; Liu, Haomin; Zha, Hongbin] Peking Univ, Sch Intelligence Sci & Technol, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
   [Liu, Haomin] Sense Time Res, Beijing 200233, Peoples R China.
   [Shi, Boxin] Peking Univ, Natl Engn Res Ctr Visual Technol, Sch Comp Sci, Beijing 100871, Peoples R China.
   [Zhang, Guofeng] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Peoples R China.
C3 Peking University; Peking University; Peking University; Zhejiang
   University
RP Chen, HR (corresponding author), Peking Univ, AI Innovat Ctr, Sch Comp Sci, Beijing 100871, Peoples R China.
EM chrer@pku.edu.cn; weilantian@pku.edu.cn; liuhaomin@sensetime.com;
   shiboxin@pku.edu.cn; zhangguofeng@zju.edu.cn; zha@cis.pku.edu.cn
RI Zhao, Gang/JMC-6248-2023; Liu, Haomin/IXW-5373-2023
OI Zhang, Guofeng/0000-0001-5661-8430; Liu, Haomin/0000-0001-9511-2416
FU National Key Research and Development Program of China [2020YFF0304300];
   National Natural Science Foundation of China [62136001, U22A2061]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2020YFF0304300, and in part by
   the National Natural Science Foundation of China under Grants 62136001
   and U22A2061.
CR Agarwal S., 2012, Google, Inc., V2, P8
   Azuma R., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P401, DOI 10.1145/218380.218496
   Borges M, 2018, IEEE INT C INT ROBOT, P2610, DOI 10.1109/IROS.2018.8593707
   Brajdic A, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P225, DOI 10.1145/2493432.2493449
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chatzopoulos D, 2017, IEEE ACCESS, V5, P6917, DOI 10.1109/ACCESS.2017.2698164
   Chen CH, 2021, IEEE T MOBILE COMPUT, V20, P1351, DOI 10.1109/TMC.2019.2960780
   Chen CH, 2018, AAAI CONF ARTIF INTE, P6468
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140
   Foxlin EM, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P527, DOI 10.1109/IRDS.2002.1041444
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Harle R, 2013, IEEE COMMUN SURV TUT, V15, P1281, DOI 10.1109/SURV.2012.121912.00075
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Herath S, 2020, IEEE INT CONF ROBOT, P3146, DOI 10.1109/icra40945.2020.9196860
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Kingma D.P., 2015, P 2015 INT C LEARNIN
   Klein George, 2007, P1
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   List U.H., 1983, Nonlinear prediction of head movements for helmet-mounted displays
   Liu HM, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P219, DOI 10.1109/ISMAR-Adjunct51615.2020.00065
   Liu HM, 2018, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR.2018.00211
   Liu WX, 2020, IEEE ROBOT AUTOM LET, V5, P5653, DOI 10.1109/LRA.2020.3007421
   MAZURYK T, 1995, COMPUT GRAPH FORUM, V14, pC29, DOI 10.1111/j.1467-8659.1995.cgf143_0029.x
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nowacki Pawel, 2020, Engineering in Dependability of Computer Systems and Networks. Proceedings of the Fourteenth International Conference on Dependability of Computer Systems DepCoS-RELCOMEX. Advances in Intelligent Systems and Computing (AISC 987), P358, DOI 10.1007/978-3-030-19501-4_36
   Nützi G, 2011, J INTELL ROBOT SYST, V61, P287, DOI 10.1007/s10846-010-9490-z
   Oufqir Z., 2020, P INT C INT SYST COM, P1
   Paszke A, 2019, ADV NEUR IN, V32
   Pittelkau ME, 2003, J GUID CONTROL DYNAM, V26, P855, DOI 10.2514/2.6929
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Radwan N, 2018, IEEE ROBOT AUTOM LET, V3, P4407, DOI 10.1109/LRA.2018.2869640
   Rajagopal S., 2008, Personal dead reckoning system with shoe mounted inertial sensors
   Rambach J, 2017, ADJUNCT PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT), P109, DOI 10.1109/ISMAR-Adjunct.2017.43
   Rambach JR, 2016, INT SYM MIX AUGMENT, P71, DOI 10.1109/ISMAR.2016.19
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Suleiman A, 2019, IEEE J SOLID-ST CIRC, V54, P1106, DOI 10.1109/JSSC.2018.2886342
   Suto J, 2017, INT J COMPUT COMMUN, V12, P116
   van Waveren JMP, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P37, DOI 10.1145/2993369.2993375
   Watson A., 1983, A look at motion in the frequency domain
   Weberruss J, 2017, I C FIELD PROG LOGIC
   Weyand PG, 2010, J APPL PHYSIOL, V108, P950, DOI 10.1152/japplphysiol.00947.2009
   WINOGRAD S, 1978, MATH COMPUT, V32, P175, DOI 10.1090/S0025-5718-1978-0468306-4
   Wu KJ, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Yan H, 2018, LECT NOTES COMPUT SC, V11217, P641, DOI 10.1007/978-3-030-01261-8_38
   Zhang Zhengdong., 2017, Visual-inertial odometry on chip: An algorithm-and-hardware co-design approach
   Zhou Y, 2019, PROC CVPR IEEE, P5738, DOI 10.1109/CVPR.2019.00589
NR 55
TC 0
Z9 0
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3166
EP 3179
DI 10.1109/TVCG.2022.3228807
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700091
PM 37015352
DA 2024-11-06
ER

PT J
AU Liu, JY
   Saquib, N
   Zhutian, C
   Kazi, RH
   Wei, LY
   Fu, HB
   Tai, CL
AF Liu, Jingyuan
   Saquib, Nazmus
   Zhutian, Chen
   Kazi, Rubaiat Habib
   Wei, Li-Yi
   Fu, Hongbo
   Tai, Chiew-Lan
TI PoseCoach: A Customizable Analysis and Visualization System for
   Video-Based Running Coaching
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Videos; Sports; Three-dimensional displays; Data visualization; Data
   analysis; Analytical models; Solid modeling; Human pose; video
   processing; sports data analysis
ID BIOMECHANICS; RELIABILITY
AB Videos are an accessible form of media for analyzing sports postures and providing feedback to athletes. Existing sport-specific systems embed bespoke human pose attributes and thus can be hard to scale for new attributes, especially for users without programming experiences. Some systems retain scalability by directly showing the differences between two poses, but they might not clearly visualize the key differences that viewers would like to pursue. Besides, video-based coaching systems often present feedback on the correctness of poses by augmenting videos with visual markers or reference poses. However, previewing and augmenting videos limit the analysis and visualization of human poses due to the fixed viewpoints in videos, which confine the observation of captured human movements and cause ambiguity in the augmented feedback. To address these issues, we study customizable human pose data analysis and visualization in the context of running pose attributes, such as joint angles and step distances. Based on existing literature and a formative study, we have designed and implemented a system, PoseCoach, to provide feedback on running poses for amateurs by comparing the running poses between a novice and an expert. PoseCoach adopts a customizable data analysis model to allow users' controllability in defining pose attributes of their interests through our interface. To avoid the influence of viewpoint differences and provide intuitive feedback, PoseCoach visualizes the pose differences as part-based 3D animations on a human model to imitate the demonstration of a human coach. We conduct a user study to verify our design components and conduct expert interviews to evaluate the usefulness of the system.
C1 [Liu, Jingyuan; Tai, Chiew-Lan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
   [Saquib, Nazmus] Tero Labs, Santa Clara, CA 95051 USA.
   [Zhutian, Chen] Harvard Univ, Cambridge, MA 02138 USA.
   [Kazi, Rubaiat Habib; Wei, Li-Yi] Adobe Res, San Jose, CA 95110 USA.
   [Fu, Hongbo] City Univ Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Harvard University; Adobe
   Systems Inc.; City University of Hong Kong
RP Liu, JY (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM jliucb@connect.ust.hk; nzm.saquib@gmail.com; ztchen@seas.harvard.edu;
   rhabib@adobe.com; review@liyiwei.org; fuplus@gmail.com; taicl@cse.ust.hk
RI Wei, Li-Yi/F-4469-2011; Saquib, Nazmus/GWM-5475-2022
OI Liu, Jingyuan/0000-0002-4648-5555; Wei, Li-Yi/0000-0002-1076-6339; FU,
   Hongbo/0000-0002-0284-726X
FU Research Grants Council of HKSAR [HKUST16206722]
FX This work was supported by the Research Grants Council of HKSAR under
   Grant HKUST16206722. We thank the anonymous reviewers for the valuable
   feedback and the userstudy participants for their great help.
CR Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [10.1145/2501988.2502045, DOI 10.1145/2501988.2502045]
   Aristidou A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275038
   Barre A, 2014, COMPUT METH PROG BIO, V114, DOI 10.1016/j.cmpb.2014.01.012
   Bartlett R., 2007, Introduction to Sports Biomechanics: Analysing Human Movement Patterns, V2nd
   Berndt D. J., 1994, P KDD WORKSH SEATTL, P359, DOI DOI 10.5555/3000850.3000887
   Brooke J., 1995, USABILITY EVAL IND, P189
   Chen HT, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2027, DOI 10.1145/2556288.2557009
   Chen HT, 2018, MULTIMED TOOLS APPL, V77, P23969, DOI 10.1007/s11042-018-5721-2
   Chen ZT, 2022, IEEE T VIS COMPUT GR, V28, P824, DOI 10.1109/TVCG.2021.3114806
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Chu XT, 2022, IEEE T VIS COMPUT GR, V28, P118, DOI 10.1109/TVCG.2021.3114861
   Clarke Christopher, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P196, DOI 10.1145/3379337.3415591
   Dreyer D., 2009, ChiRunning: A revolutionary approach to effortless, injury-free running
   Fieraru M, 2021, PROC CVPR IEEE, P9914, DOI 10.1109/CVPR46437.2021.00979
   Fu HB, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360641
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Hanley B, 2018, J SPORT SCI, V36, P1250, DOI 10.1080/02640414.2017.1372928
   Hay J., 1978, The biomechanics of sports techniques
   Hinrichs R. N., 1990, Multiple Muscle Systems, P694, DOI DOI 10.1007/978-1-4613-9030-5_45
   Holden D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073663
   Kiciroglu S, 2020, PROC CVPR IEEE, P100, DOI 10.1109/CVPR42600.2020.00018
   Kinovea, 2012, A microscope for your videos
   Kuhtz-Buschbeck JP, 2012, J ELECTROMYOGR KINES, V22, P199, DOI 10.1016/j.jelekin.2011.08.014
   Kwon B, 2022, IEEE T SYST MAN CY-S, V52, P533, DOI 10.1109/TSMC.2020.3004338
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lin Tica, 2022, IEEE Trans Vis Comput Graph, VPP, DOI 10.1109/TVCG.2022.3209353
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Mathis A, 2018, NAT NEUROSCI, V21, P1281, DOI 10.1038/s41593-018-0209-y
   Microsoft, 2017, Visual gesture builder (VGB)
   Mirzabekiantz E, 2016, SPRINGER TRAC ADV RO, V111, P299, DOI 10.1007/978-3-319-25739-6_14
   MotionPro, 2018, Motion analysis software for all sports
   Nebeling Michael, 2015, P 7 ACM SIGCHI S ENG, V15, P142, DOI DOI 10.1145/2774225.2774846
   Novacheck TF, 1998, GAIT POSTURE, V7, P77, DOI 10.1016/S0966-6362(97)00038-6
   Once, 2019, Basketball video analysis all-in-one program
   OnForm, 2021, Video analysis for skill development in any sport
   Ortiz-Padilla VE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083981
   Pipkin A, 2016, J ORTHOP SPORT PHYS, V46, P556, DOI 10.2519/jospt.2016.6280
   Q. System, 2015, A leading provider of precision motion capture and 3D positioning tracking system
   Reinking MF, 2018, INT J SPORTS PHYS TH, V13, P453, DOI 10.26603/ijspt20180453
   Romanov N., 2002, Dr. Nicholas Romanov's pose method of running companion drill book - video I
   Semeraro A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517735
   Seth A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1006223
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shu XH, 2021, IEEE T VIS COMPUT GR, V27, P1492, DOI 10.1109/TVCG.2020.3030396
   Stein M., 2018, P INT S BIG DAT VIS, P1
   Stein M, 2018, IEEE T VIS COMPUT GR, V24, P13, DOI 10.1109/TVCG.2017.2745181
   Su WC, 2023, IEEE T VIS COMPUT GR, V29, P4074, DOI 10.1109/TVCG.2022.3178734
   Su WC, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203186
   Suzuki Ryo, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P166, DOI 10.1145/3379337.3415892
   Tang R, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4123, DOI 10.1145/2702123.2702401
   Techiques H., 2007, Hudl: Performance analysis tools for sports teams and athletes at every level
   TechSmith, 2011, Coach's eye
   van Oeveren BT, 2024, SPORT BIOMECH, V23, P516, DOI 10.1080/14763141.2021.1873411
   Velloso E., 2013, P SIGCHI C HUM FACT, P1309
   Video4coach, 2010, Video based motion and skill analysis
   Wang Jiachen, 2023, IEEE Trans Vis Comput Graph, V29, P951, DOI 10.1109/TVCG.2022.3209352
   Wang JB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P374, DOI 10.1145/3343031.3350910
   Wei RXY, 2021, BRAZ J PHYS THER, V25, P162, DOI 10.1016/j.bjpt.2020.05.003
   WILLIAMS KR, 1987, J APPL PHYSIOL, V63, P1236, DOI 10.1152/jappl.1987.63.3.1236
   Wozniak P. W., 2021, P CHI C HUM FACT COM
   Wu Jiang, 2023, IEEE Trans Vis Comput Graph, V29, P940, DOI 10.1109/TVCG.2022.3209452
   Wulf G, 2010, MED EDUC, V44, P75, DOI 10.1111/j.1365-2923.2009.03421.x
   Zecha D, 2018, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON MULTIMEDIA CONTENT ANALYSIS IN SPORTS (MMSPORTS'18), P11, DOI 10.1145/3265845.3265855
NR 63
TC 2
Z9 2
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3180
EP 3195
DI 10.1109/TVCG.2022.3230855
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700045
PM 37015423
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Lv, CL
   Lin, WS
   Zheng, JM
AF Lv, Chenlei
   Lin, Weisi
   Zheng, Jianmin
TI Adaptively Isotropic Remeshing Based on Curvature Smoothed Field
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Optimization; Faces; Adaptation models; Aerospace electronics;
   Three-dimensional displays; Solid modeling; Histograms; Adaptively
   isotropic; remeshing; curvature smoothed field
ID SURFACES
AB With the development of 3D digital geometry technology, 3D triangular meshes are becoming more useful and valuable in industrial manufacturing and digital entertainment. A high quality triangular mesh can be used to represent a real world object with geometric and physical characteristics. While anisotropic meshes have advantages of representing shapes with sharp features (such as trimmed surfaces) more efficiently and accurately, isotropic meshes allow more numerically stable computations. When there is no anisotropic mesh requirement, isotropic triangles are always a good choice. In this paper, we propose a remeshing method to convert an input mesh into an adaptively isotropic one based on a curvature smoothed field (CSF). With the help of the CSF, adaptively isotropic remeshing can retain the curvature sensitivity, which enables more geometric features to be kept, and avoid the occurrence of obtuse triangles in the remeshed model as much as possible. The remeshed triangles with locally isotropic property benefit various geometric processes such as neighbor-based feature extraction and analysis. The experimental results show that our method achieves better balance between geometric feature preservation and mesh quality improvement compared to peers. We provide the implementation codes of our resampling method at github.com/vvvwo/Adaptively-Isotropic-Remeshing.
C1 [Lv, Chenlei; Lin, Weisi; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.
   [Lin, Weisi] Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.; Lin, WS (corresponding author), Nanyang Technol Univ, Singtel Cognit & Artificial Intelligence Lab, Singapore, Singapore.
EM chenleilv@mail.bnu.edu.cn; WSLin@ntu.edu.sg; asjmzheng@ntu.edu.sg
RI Lin, Weisi/A-8011-2012; Lin, Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947; Chenlei, Lv/0000-0002-8203-3118
FU Ministry of Education, Singapore [RG14/21]; Industry Alignment Fund -
   Industry Collaboration Projects Funding Initiative [RIE2020]
FX This work was supported by the Ministry of Education, Singapore, under
   its Tier-1 Fund MOE2021, RG14/21, and RIE2020 Industry Alignment Fund -
   Industry Collaboration Projects Funding Initiative, as well as cash and
   in-kind contribution from Singapore Telecommunications Limited
   (Singtel), through Singtel Cognitive and Artificial Intelligence Lab for
   Enterprises, SCALE@NTU.
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   Alliez P, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P49
   Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   [Anonymous], 2013, P 21 INT MESH ROUNDT, DOI DOI 10.1007/978-3-642-33573-021
   BAGNARA R, 1995, SIAM REV, V37, P93, DOI 10.1137/1037008
   Berger M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451246
   Botsch Mario, 2004, P 2004 EUR ACM SIGGR, P185, DOI DOI 10.1145/1057432.1057457
   Botsch Mario., 2010, POLYGON MESH PROCESS
   Bronstein A. M., 2010, Proc. 3DOR, P71
   Chen ZG, 2018, COMPUT AIDED DESIGN, V102, P12, DOI 10.1016/j.cad.2018.04.010
   Cheng XX, 2019, COMPUT GRAPH-UK, V82, P163, DOI 10.1016/j.cag.2019.05.019
   Crane K, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2516971.2516977
   Dapogny C, 2014, J COMPUT PHYS, V262, P358, DOI 10.1016/j.jcp.2014.01.005
   Dassi F., 2015, New Challenges in Grid Generation and Adap- tivity for Scientific Computing, P19
   Dassi F, 2014, PROCEDIA ENGINEER, V82, P253, DOI 10.1016/j.proeng.2014.10.388
   de Goes F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2602143
   Dunyach M., 2013, EUROGRAPHICS, P29
   Frey PJ, 1999, INT J NUMER METH ENG, V45, P101
   Guo YW, 2005, COMPUT GRAPH-UK, V29, P972, DOI 10.1016/j.cag.2005.09.013
   Hieber Simone E, 2004, Technol Health Care, V12, P305
   Hou WJ, 2022, COMPUT AIDED DESIGN, V144, DOI 10.1016/j.cad.2021.103166
   Hu BY, 2023, IEEE T VIS COMPUT GR, V29, P1318, DOI 10.1109/TVCG.2021.3112896
   Jiao XM, 2010, ENG COMPUT-GERMANY, V26, P363, DOI 10.1007/s00366-009-0170-1
   Jin M, 2008, IEEE T VIS COMPUT GR, V14, P1030, DOI 10.1109/TVCG.2008.57
   Lei N, 2019, COMPUT AIDED GEOM D, V68, P1, DOI 10.1016/j.cagd.2018.10.005
   Liu YJ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818076
   Liu ZY, 2021, COMPUT AIDED DESIGN, V139, DOI 10.1016/j.cad.2021.103080
   Lv C., IEEE Trans. Pattern Anal. Mach. Intell., DOI 10.1109/TauRhoAlphaMuIota.2022.3185644
   Lv CL, 2022, IEEE T MULTIMEDIA, V24, P1815, DOI 10.1109/TMM.2021.3073265
   Lv CL, 2019, MULTIMED TOOLS APPL, V78, P14753, DOI 10.1007/s11042-018-6839-y
   Lv CL, 2019, PATTERN RECOGN, V88, P458, DOI 10.1016/j.patcog.2018.12.006
   Meyer M, 2008, IEEE T VIS COMPUT GR, V14, P1539, DOI 10.1109/TVCG.2008.154
   Narain R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366171
   O'Sullivan C, 2011, INT J GEOMECH, V11, P449, DOI 10.1061/(ASCE)GM.1943-5622.0000024
   Ovsjanikov M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185526
   Premoze S, 2003, COMPUT GRAPH FORUM, V22, P401, DOI 10.1111/1467-8659.00687
   Shimada K, 2000, INT J COMPUT GEOM AP, V10, P417, DOI 10.1142/S0218195900000243
   Su KH, 2019, COMPUT AIDED DESIGN, V111, P1, DOI 10.1016/j.cad.2019.01.004
   Takamatsu Kenji, 2011, International Journal of Virtual Reality, V10, P29
   Verhoeven F, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3510002
   Wang YQ, 2019, IEEE T VIS COMPUT GR, V25, P2430, DOI 10.1109/TVCG.2018.2837115
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xu QC, 2019, COMPUT GRAPH FORUM, V38, P755, DOI 10.1111/cgf.13877
   Yan DM, 2014, COMPUT GRAPH FORUM, V33, P167, DOI 10.1111/cgf.12442
   Yan DM, 2009, COMPUT GRAPH FORUM, V28, P1445, DOI 10.1111/j.1467-8659.2009.01521.x
   Ye ZP, 2019, Arxiv, DOI arXiv:1907.00523
   Yi R, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275068
   Zhang WX, 2022, COMPUT GRAPH FORUM, V41, P237, DOI 10.1111/cgf.14471
   Zheng JQ, 2020, I3D 2020: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, DOI 10.1145/3384382.3384520
   Zhong SK, 2019, COMPUT AIDED GEOM D, V71, P43, DOI 10.1016/j.cagd.2019.04.011
   Zhong ZC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461946
NR 51
TC 2
Z9 2
U1 1
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3196
EP 3209
DI 10.1109/TVCG.2022.3227970
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700056
PM 37015489
DA 2024-11-06
ER

PT J
AU Hirao, Y
   Narumi, T
   Argelaguet, F
   Lécuyer, A
AF Hirao, Yutaro
   Narumi, Takuji
   Argelaguet, Ferran
   Lecuyer, Anatole
TI Revisiting Walking-in-Place by Introducing Step-Height Control, Elastic
   Input, and Pseudo-Haptic Feedback
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Legged locomotion; Haptic interfaces; Frequency control; Force;
   Mathematical models; Foot; Visualization; Walking-in-place;
   pseudo-haptics; passive haptics; elastic input; virtual reality;
   locomotion
ID LOCOMOTION
AB Walking-in-place (WIP) is a locomotion technique that enables users to "walk infinitely" through vast virtual environments using walking-like gestures within a limited physical space. This article investigates alternative interaction schemes for WIP, addressing successively the control, input, and output of WIP. First, we introduce a novel height-based control to increase advanced speed. Second, we introduce a novel input system for WIP based on elastic and passive strips. Third, we introduce the use of pseudo-haptic feedback as a novel output for WIP meant to alter walking sensations. The results of a series of user studies show that height and frequency based control of WIP can facilitate higher virtual speed with greater efficacy and ease than in frequency-based WIP. Second, using an upward elastic input system can result in a stable virtual speed control, although excessively strong elastic forces may impact the usability and user experience. Finally, using a pseudo-haptic approach can improve the perceived realism of virtual slopes. Taken together, our results suggest that, for future VR applications, there is value in further research into the use of alternative interaction schemes for walking-in-place.
C1 [Hirao, Yutaro] Univ Tokyo, Tokyo 1138654, Japan.
   [Narumi, Takuji] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138654, Japan.
   [Argelaguet, Ferran; Lecuyer, Anatole] Univ Rennes, Inria, IRISA, CNRS, F-35000 Rennes, France.
C3 University of Tokyo; University of Tokyo; Centre National de la
   Recherche Scientifique (CNRS); Universite de Rennes; Inria
RP Hirao, Y (corresponding author), Univ Tokyo, Tokyo 1138654, Japan.
EM hirao@cyber.t.u-tokyo.ac.jp; narumi@cyber.t.u-tokyo.ac.jp;
   ferran.argelaguet@inria.fr; anatole.lecuyer@inria.fr
RI ; Narumi, Takuji/K-3925-2014
OI Hirao, Yutaro/0000-0003-3546-3454; Narumi, Takuji/0000-0002-9010-1491
FU MEXT Grant-in-Aid for Scientific Research(S) [19H05661]; JSPS Fellows
   [21J12284]; Grants-in-Aid for Scientific Research [21J12284, 23K24884,
   20K21801, 22H03628] Funding Source: KAKEN
FX This work was supported by the MEXT Grant-in-Aid for Scientific
   Research(S) under Grant 19H05661 and JSPS Fellows under Grant 21J12284.
CR Achibet M, 2015, P IEEE VIRT REAL ANN, P63, DOI 10.1109/VR.2015.7223325
   Achibet M, 2014, 2014 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P59, DOI 10.1109/3DUI.2014.6798843
   [Anonymous], 2004, P INT C EUROHAPTICS
   Bhandari J, 2017, VRST'17: PROCEEDINGS OF THE 23RD ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY, DOI 10.1145/3139131.3139133
   Bouguila L., 2003, P 13 INT C ART REAL
   Brooke J., 1996, Usability Eval. Ind./Taylor Fr, V189, P4, DOI DOI 10.1201/9781498710411-35
   Bruno L, 2013, LECT NOTES COMPUT SC, V8119, P370
   Cybershoes Inc., 2016, Cybershoes: VR locomotion interface
   Darken R. P., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P213, DOI 10.1145/263407.263550
   DEAN GA, 1965, ERGONOMICS, V8, P31, DOI 10.1080/00140136508930772
   Feasel J, 2008, 3DUI: IEEE SYMPOSIUM ON 3D USER INTERFACES 2008, PROCEEDINGS, P97
   Hanson S, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P367, DOI [10.1109/vr.2019.8797751, 10.1109/VR.2019.8797751]
   Hejrati B, 2015, IEEE T HAPTICS, V8, P176, DOI 10.1109/TOH.2015.2404357
   Hoppe M., 2019, P CHI C HUM FACT COM, P1
   Ishikawa R, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P559, DOI 10.1145/3292147.3292234
   Iwata H, 2005, IEEE COMPUT GRAPH, V25, P64, DOI 10.1109/MCG.2005.5
   Iwata H, 2001, P IEEE VIRT REAL ANN, P131, DOI 10.1109/VR.2001.913779
   Kim W, 2021, INT J HUM-COMPUT ST, V152, DOI 10.1016/j.ijhcs.2021.102648
   Langbehn E., 2015, P GI WORKSH VIRT AUG, P149
   Law AW, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P126, DOI 10.1109/HAVE.2008.4685311
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Magaña M, 2008, 2008 IEEE INTERNATIONAL WORKSHOP ON HAPTIC AUDIO VISUAL ENVIRONMENTS AND THEIR APPLICATIONS, P114, DOI 10.1109/HAVE.2008.4685309
   Marchal M, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P19, DOI 10.1109/3DUI.2010.5446238
   Matsumoto K., 2017, P ACM SIGGRAPH POST, P1
   Nguyen A, 2018, ACM SYMPOSIUM ON APPLIED PERCEPTION (SAP 2018), DOI 10.1145/3225153.3225155
   Nilsson Niels Christian, 2016, Human-Computer Interaction. Interaction Platforms and Techniques. 18th International Conference, HCI International 2016. Proceedings: LNCS 9732, P37, DOI 10.1007/978-3-319-39516-6_4
   Nilsson N. C., 2013, P MOT GAM, P155, DOI DOI 10.1145/2522628.2522655
   Nilsson NC, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P31, DOI 10.1109/3DUI.2013.6550193
   Nilsson NC, 2018, COMPUT ENTERTAIN, V16, DOI 10.1145/3180658
   Nilsson NC, 2014, IEEE T VIS COMPUT GR, V20, P569, DOI 10.1109/TVCG.2014.21
   Ogawa N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376562
   Paljic A, 2004, 12TH INTERNATIONAL SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P216, DOI 10.1109/HAPTIC.2004.1287199
   Papetti S, 2010, LECT NOTES COMPUT SC, V6306, P117, DOI 10.1007/978-3-642-15841-4_13
   Pusch A., 2011, P 13 INT C MULT INT, P57
   Shimamura R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1154, DOI [10.1109/vr.2019.8797960, 10.1109/VR.2019.8797960]
   Slater M., 1995, ACM Transactions on Computer Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Son H., 2018, P CHI C HUM FACT COM, P1
   Swanson D. K., 2002, PhD thesis
   Templeman JN, 2007, IEEE Virtual Reality 2007, Proceedings, P285
   Templeman JN, 1999, PRESENCE-TELEOP VIRT, V8, P598, DOI 10.1162/105474699566512
   Terziman L., 2010, P 17 ACM S VIRT REAL, P27
   Tremblay L, 2004, PERCEPTION, V33, P329, DOI 10.1068/p5209
   Virtuix Inc., 2014, Virtuix Omni: VR locomotion interface
   Visell Y, 2008, LECT NOTES COMPUT SC, V5024, P420, DOI 10.1007/978-3-540-69057-3_55
   Wang CZ, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281536
   Wendt JD, 2010, P IEEE VIRT REAL ANN, P51
   ZHAI SM, 1993, P SOC PHOTO-OPT INS, V2057, P130, DOI 10.1117/12.164895
NR 47
TC 1
Z9 1
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3210
EP 3223
DI 10.1109/TVCG.2022.3228171
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700080
PM 37015485
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Ye, YL
   Huang, R
   Zeng, W
AF Ye, Yilin
   Huang, Rong
   Zeng, Wei
TI VISAtlas: An Image-Based Exploration and Query System for Large
   Visualization Collections via Neural Image Embedding
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Visualization; Feature extraction; Task analysis;
   Layout; Taxonomy; Semantics; Visualization collection; image embedding;
   visual query; image visualization; design pattern
ID INFORMATION VISUALIZATION; VISUAL ANALYSIS; KNOWLEDGE; DESIGN; SPACE
AB High-quality visualization collections are beneficial for a variety of applications including visualization reference and data-driven visualization design. The visualization community has created many visualization collections, and developed interactive exploration systems for the collections. However, the systems are mainly based on extrinsic attributes like authors and publication years, whilst neglect intrinsic property (i.e., visual appearance) of visualizations, hindering visual comparison and query of visualization designs. This paper presents VISAtlas, an image-based approach empowered by neural image embedding, to facilitate exploration and query for visualization collections. To improve embedding accuracy, we create a comprehensive collection of synthetic and real-world visualizations, and use it to train a convolutional neural network (CNN) model with a triplet loss for taxonomical classification of visualizations. Next, we design a coordinated multiple view (CMV) system that enables multi-perspective exploration and design retrieval based on visualization embeddings. Specifically, we design a novel embedding overview that leverages contextual layout framework to preserve the context of the embedding vectors with the associated visualization taxonomies, and density plot and sampling techniques to address the overdrawing problem. We demonstrate in three case studies and one user study the effectiveness of VISAtlas in supporting comparative analysis of visualization collections, exploration of composite visualizations, and image-based retrieval of visualization designs. The studies reveal that real-world visualization collections (e.g., Beagle and VIS30K) better accord with the richness and diversity of visualization designs than synthetic collections (e.g., Data2Vis), inspiring composite visualizations are identified in real-world collections, and distinct design patterns exist in visualizations from different sources.
C1 [Ye, Yilin; Huang, Rong; Zeng, Wei] Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Guangdong, Peoples R China.
   [Ye, Yilin; Huang, Rong; Zeng, Wei] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology (Guangzhou); Hong Kong
   University of Science & Technology
RP Zeng, W (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Guangzhou 511400, Guangdong, Peoples R China.; Zeng, W (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.
EM yyebd@connect.ust.hk; rhuang421@connect.hkust-gz.edu.cn; weizeng@ust.hk
RI Ye, Yilin/GRR-8394-2022
OI Huang, Rong/0000-0002-6807-3148; Ye, Yilin/0000-0001-8874-5928
FU National Natural Science Foundation of China [62172398]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62172398.
CR Aigner W, 2011, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-0-85729-079-3
   Battle L, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174168
   Behrisch M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13446
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Borkin MA, 2013, IEEE T VIS COMPUT GR, V19, P2306, DOI 10.1109/TVCG.2013.234
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chagas P, 2018, IEEE IJCNN
   Chen J, 2021, IEEE T VIS COMPUT GR, V27, P3826, DOI 10.1109/TVCG.2021.3054916
   Chen M, 2009, IEEE COMPUT GRAPH, V29, P12, DOI 10.1109/MCG.2009.6
   Chen X, 2021, IEEE T VIS COMPUT GR, V27, P1514, DOI 10.1109/TVCG.2020.3030338
   Chen ZT, 2020, IEEE T VIS COMPUT GR, V26, P917, DOI 10.1109/TVCG.2019.2934810
   Cheng SH, 2017, PROCESSES, V5, DOI 10.3390/pr5040075
   Cheng SH, 2015, IEEE PAC VIS SYMP, P295, DOI 10.1109/PACIFICVIS.2015.7156390
   Colorbrewer2, 2013, About us
   Cox M. A., 2008, Handbook of data visualization, P315, DOI DOI 10.1007/978-3-540-33037-014
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de Rooij O, 2010, IEEE COMPUT GRAPH, V30, P42, DOI 10.1109/MCG.2010.66
   Deng DZ, 2022, Arxiv, DOI [arXiv:2203.10476, 10.48550/arXiv.2203.10476, DOI 10.48550/ARXIV.2203.10476]
   Deng DZ, 2023, IEEE T VIS COMPUT GR, V29, P3298, DOI 10.1109/TVCG.2022.3155440
   Di Caro L, 2010, LECT NOTES ARTIF INT, V6119, P125
   Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636
   github, 2018, D3-scale-chromatic
   github, 2016, Colorcet
   Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549
   Gomez SR, 2012, IEEE T VIS COMPUT GR, V18, P2411, DOI 10.1109/TVCG.2012.214
   Han J, 2020, IEEE T VIS COMPUT GR, V26, P1732, DOI 10.1109/TVCG.2018.2880207
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman P, 1997, VISUALIZATION '97 - PROCEEDINGS, P437, DOI 10.1109/VISUAL.1997.663916
   Hoque E, 2020, IEEE T VIS COMPUT GR, V26, P1236, DOI 10.1109/TVCG.2019.2934431
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300358
   Hu K, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300892
   Jänicke H, 2010, COMPUT GRAPH FORUM, V29, P1183, DOI 10.1111/j.1467-8659.2009.01667.x
   Javed W, 2012, IEEE PAC VIS SYMP, P1, DOI 10.1109/PacificVis.2012.6183556
   Jung D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6706, DOI 10.1145/3025453.3025957
   Kim MC, 2016, SCIENTOMETRICS, V107, P123, DOI 10.1007/s11192-015-1830-0
   Li H., 2022, P ACM CHI C HUM FACT, P1
   Li HT, 2022, IEEE T VIS COMPUT GR, V28, P195, DOI 10.1109/TVCG.2021.3114863
   Liu Y, 2019, COMPUT GRAPH FORUM, V38, P67, DOI 10.1111/cgf.13672
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JY, 2021, IEEE WINT CONF APPL, P1916, DOI 10.1109/WACV48630.2021.00196
   Luo YY, 2018, PROC INT CONF DATA, P101, DOI 10.1109/ICDE.2018.00019
   Ma RX, 2021, IEEE T VIS COMPUT GR, V27, P3717, DOI 10.1109/TVCG.2020.2980227
   Ma YX, 2020, IEEE T VIS COMPUT GR, V26, P1562, DOI 10.1109/TVCG.2018.2875702
   Mayorga A, 2013, IEEE T VIS COMPUT GR, V19, P1526, DOI 10.1109/TVCG.2013.65
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Plant W, 2011, STUD COMPUT INTELL, V346, P3
   Poco J, 2017, COMPUT GRAPH FORUM, V36, P353, DOI 10.1111/cgf.13193
   Qian CY, 2021, IEEE T VIS COMPUT GR, V27, P443, DOI 10.1109/TVCG.2020.3030448
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030
   Savva Manolis, 2011, P 24 ANN ACM S US IN, P393
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Schulz HJ, 2011, IEEE COMPUT GRAPH, V31, P11, DOI 10.1109/MCG.2011.103
   Sechler J., 2017, P ACM CHI C HUM FACT, P2049
   Shen QM, 2018, IEEE T VIS COMPUT GR, V24, P1004, DOI 10.1109/TVCG.2017.2744159
   Siegel N, 2016, LECT NOTES COMPUT SC, V9911, P664, DOI 10.1007/978-3-319-46478-7_41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SC, 2023, IEEE T VIS COMPUT GR, V29, P3169, DOI 10.1109/TVCG.2022.3153514
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Corput P, 2017, COMPUT GRAPH FORUM, V36, P295, DOI 10.1111/cgf.13188
   van der Corput P, 2016, IEEE PAC VIS SYMP, P152, DOI 10.1109/PACIFICVIS.2016.7465263
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang CL, 2015, INFORM VISUAL, V14, P183, DOI 10.1177/1473871613498519
   Wickham H, 2009, USE R, P1, DOI 10.1007/978-0-387-98141-3
   Willett W, 2007, IEEE T VIS COMPUT GR, V13, P1129, DOI 10.1109/TVCG.2007.70589
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie X, 2019, IEEE T VIS COMPUT GR, V25, P2362, DOI 10.1109/TVCG.2018.2835485
   Yang J, 2006, IEEE CONF VIS ANAL, P191
   Yee Ka-Ping, 2003, P SIGCHI C HUM FACT, P401, DOI [DOI 10.1145/642611.642681, 10.1145/642611.642681]
   Yuan LP, 2022, IEEE T VIS COMPUT GR, V28, P4048, DOI 10.1109/TVCG.2021.3070876
   Zeng W, 2021, J VISUAL-JAPAN, V24, P69, DOI 10.1007/s12650-020-00688-1
   Zhang PY, 2021, IEEE T VIS COMPUT GR, V27, P326, DOI 10.1109/TVCG.2020.3030343
   Zhao BC, 2021, ADV NEUR IN, V34
   Zhao J, 2022, IEEE T VIS COMPUT GR, V28, P1500, DOI 10.1109/TVCG.2020.3018724
NR 76
TC 5
Z9 5
U1 3
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3224
EP 3240
DI 10.1109/TVCG.2022.3229023
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700076
PM 37015539
DA 2024-11-06
ER

PT J
AU Meidiana, A
   Hong, SH
   Eades, P
   Keim, D
AF Meidiana, Amyra
   Hong, Seok-Hee
   Eades, Peter
   Keim, Daniel
TI Automorphism Faithfulness Metrics for Symmetric Graph Drawings
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Measurement; Graph drawing; Orbits; Vehicle dynamics; Time measurement;
   Stress measurement; Stress; Automorphism; faithfulness metrics; graph
   drawing; symmetry
ID PLANAR GRAPHS
AB In this article, we present new quality metrics for symmetric graph drawing based on group theory. Roughly speaking, the new metrics are faithfulness metrics, i.e., they measure how faithfully a drawing of a graph displays the ground truth (i.e., geometric automorphisms) of the graph as symmetries. More specifically, we introduce two types of automorphism faithfulness metrics for displaying: (1) a single geometric automorphism as a symmetry (axial or rotational), and (2) a group of geometric automorphisms (cyclic or dihedral). We present algorithms to compute the automorphism faithfulness metrics in O(n log n) time. Moreover, we also present efficient algorithms to detect exact symmetries in a graph drawing. We then validate our automorphism faithfulness metrics using deformation experiments. Finally, we use the metrics to evaluate existing graph drawing algorithms to compare how faithfully they display geometric automorphisms of a graph as symmetries.
C1 [Meidiana, Amyra; Hong, Seok-Hee; Eades, Peter] Univ Sydney, Camperdown, NSW 2006, Australia.
   [Keim, Daniel] Univ Konstanz, D-78464 Constance, Germany.
C3 University of Sydney; University of Konstanz
RP Meidiana, A (corresponding author), Univ Sydney, Camperdown, NSW 2006, Australia.
EM amyra.meidiana@sydney.edu.au; seokhee.hong@sydney.edu.au;
   peter.eades@sydney.edu.au; keim@uni-konstanz.de
FU ARC (Australian Research Council) DP (Discovery Project) [DP190103301]
FX This work was supported by an ARC (Australian Research Council) DP
   (Discovery Project) under grant (# DP190103301).
CR Abelson D, 2007, DISCRETE APPL MATH, V155, P2211, DOI 10.1016/j.dam.2007.04.027
   ALT H, 1988, DISCRETE COMPUT GEOM, V3, P237, DOI 10.1007/BF02187910
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Brandes U, 2007, LECT NOTES COMPUT SC, V4372, P42
   Buchheim C, 2003, MATH PROGRAM, V98, P369, DOI 10.1007/s10107-003-0409-3
   Chen H.-L., 2000, P 8 INT S GRAPH DRAW, P372
   Chin KW, 2001, INFORM PROCESS LETT, V79, P73, DOI 10.1016/S0020-0190(00)00174-5
   De Luca F, 2019, LECT NOTES COMPUT SC, V11904, P499, DOI 10.1007/978-3-030-35802-0_38
   Eades P, 2000, THEOR COMPUT SCI, V240, P379, DOI 10.1016/S0304-3975(99)00239-X
   Eades P., 2013, Handbook of Graph Drawing and Visualisation
   Eades P, 2015, LECT NOTES COMPUT SC, V9411, P502, DOI 10.1007/978-3-319-27261-0_41
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Hong SH, 2006, DISCRETE COMPUT GEOM, V36, P283, DOI 10.1007/s00454-006-1231-5
   Hong SH, 2010, ALGORITHMICA, V58, P433, DOI 10.1007/s00453-008-9275-y
   Hong SH, 2006, ALGORITHMICA, V44, P67, DOI 10.1007/s00453-005-1149-y
   Hong SH, 2005, ALGORITHMICA, V42, P159, DOI 10.1007/s00453-004-1132-z
   Hong SH, 2003, LECT NOTES COMPUT SC, V2906, P405
   Hong SH, 2000, COMP GEOM-THEOR APPL, V17, P165, DOI 10.1016/S0925-7721(00)00020-1
   Klapaukh R, 2018, LECT NOTES ARTIF INT, V10871, P739, DOI 10.1007/978-3-319-91376-6_71
   Knuth D. E., 1977, SIAM Journal on Computing, V6, P323, DOI 10.1137/0206024
   Koren Y, 2005, COMPUT MATH APPL, V49, P1867, DOI 10.1016/j.camwa.2004.08.015
   LUBIW A, 1981, SIAM J COMPUT, V10, P11, DOI 10.1137/0210002
   MANNING J, 1992, DISCRETE APPL MATH, V39, P13, DOI 10.1016/0166-218X(92)90112-N
   Manning J., 1988, CONGR NUMER CONF J N, V64, P159
   Manning J. B., 1991, Ph.D. dissertation
   Meidiana Amyra, 2020, Graph Drawing and Network Visualization. 28th International Symposium, GD 2020. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12590), P450, DOI 10.1007/978-3-030-68766-3_35
   Meidiana A, 2020, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis48177.2020.1022
   Meidiana A, 2019, LECT NOTES COMPUT SC, V11904, P125, DOI 10.1007/978-3-030-35802-0_10
   Purchase HC, 2002, J VISUAL LANG COMPUT, V13, P501, DOI 10.1006/S1045-926X(02)00016-2
   Nguyen Q, 2013, IEEE PAC VIS SYMP, P209, DOI 10.1109/PacificVis.2013.6596147
   Tutte W.T., 1963, Proc. Lond. Math. Soc, Vs3-13, P743, DOI DOI 10.1112/PLMS/S3-13.1.743
   Wang Y, 2016, IEEE T VIS COMPUT GR, V22, P359, DOI 10.1109/TVCG.2015.2467691
   Welch E, 2017, COMPUT GRAPH FORUM, V36, P341, DOI 10.1111/cgf.13192
   Wolter J. D., 1985, Vis. Comput., V1, P37, DOI DOI 10.1007/BF01901268
   ZABRODSKY H, 1995, J AM CHEM SOC, V117, P462, DOI 10.1021/ja00106a053
   ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508
NR 37
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3241
EP 3255
DI 10.1109/TVCG.2022.3229354
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700079
PM 37015686
DA 2024-11-06
ER

PT J
AU Taka, E
   Stein, S
   Williamson, JH
AF Taka, Evdoxia
   Stein, Sebastian
   Williamson, John H.
TI Does Interactive Conditioning Help Users Better Understand the Structure
   of Probabilistic Models?
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Probabilistic logic; Mathematical models; Temperature distribution;
   Visualization; Computational modeling; Shape; Bayes methods;
   Brushing-and-linking; empirical study; interactive conditioning; prior
   distribution; probabilistic models; scatter plot matrix
ID VISUALIZATION
AB Despite growing interest in probabilistic modeling approaches and availability of learning tools, people are hesitant to use them. There is a need for tools to communicate probabilistic models more intuitively and help users build, validate, use effectively or trust probabilistic models. We focus on visual representations of probabilistic models and introduce the Interactive Pair Plot (IPP) for visualization of a model's uncertainty, a scatter plot matrix of a probabilistic model allowing interactive conditioning on the model's variables. We investigate whether the use of interactive conditioning in a scatter plot matrix of a model helps users better understand variables' relations. We conducted a user study and the findings suggest that improvements in the understanding of the interaction group are the most pronounced for more exotic structures, such as hierarchical models or unfamiliar parameterizations, in comparison to the understanding of the static group. As the detail of the inferred information increases, interactive conditioning does not lead to considerably longer response times. Finally, interactive conditioning improves participants' confidence about their responses.
C1 [Taka, Evdoxia; Stein, Sebastian; Williamson, John H.] Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Scotland.
C3 University of Glasgow
RP Taka, E (corresponding author), Univ Glasgow, Sch Comp Sci, Glasgow G12 8QQ, Scotland.
EM e.taka.1@research.gla.ac.uk; sebastian.stein@glasgow.ac.uk;
   johnh.williamson@glasgow.ac.uk
OI Williamson, John/0000-0001-8085-7853; Taka, Evdoxia/0000-0001-7011-3367;
   Stein, Sebastian/0000-0003-1828-4008
FU EPSRC [EP/R018634/1]
FX This work was supported by the Closed-Loop Data Science for Complex,
   Computationally- and Data-Intensive Analytics, EPSRC Project under Grant
   EP/R018634/1.
CR BECKER RA, 1987, TECHNOMETRICS, V29, P127, DOI 10.2307/1269768
   Brase GL, 2009, APPL COGNITIVE PSYCH, V23, P369, DOI 10.1002/acp.1460
   Breslav S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P245, DOI 10.1145/2598153.2598168
   Cole W. G., 1989, SIGCHI Bulletin, P381, DOI 10.1145/67450.67522
   Correll M, 2014, IEEE T VIS COMPUT GR, V20, P2142, DOI 10.1109/TVCG.2014.2346298
   Ellson J, 2004, MATH VIS, P127
   Elmqvist N, 2008, IEEE T VIS COMPUT GR, V14, P1141, DOI 10.1109/TVCG.2008.153
   Gabry J., Bayesplot
   github, Interactive Probabilistic Models Explorer
   github, ArviZ Point Estimate Pairplot
   Hullman J, 2019, IEEE T VIS COMPUT GR, V25, P903, DOI 10.1109/TVCG.2018.2864889
   Hullman J, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0142444
   Kay M, Tidybayes
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5092, DOI 10.1145/2858036.2858558
   Kay M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4521, DOI 10.1145/2858036.2858465
   Khan A, 2018, HUM-COMPUT INTERACT, V33, P207, DOI 10.1080/07370024.2016.1203264
   Koller N., 2009, Probabilistic Graphical Models: Principlesand Techniques - Adaptive Computation and Machine Learning
   Kruschke J., 2014, Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan
   Kulesza Todd, 2015, P 20 INT C INT US IN, P126, DOI [DOI 10.1145/2678025.2701399, 10.1145/2678025.2701399]
   Kumar C., 2019, J. Open Source Softw., V4
   Lambert B, 2018, 12.3. The difficulty with real-life Bayesian inference,inA Students Guide to Bayesian Statistics, P265
   Martin AR, 1995, VISUALIZATION '95 - PROCEEDINGS, P271, DOI 10.1109/VISUAL.1995.485139
   McDonald J. A., 1982, Ph.D.dissertation
   Micallef L, 2012, IEEE T VIS COMPUT GR, V18, P2536, DOI 10.1109/TVCG.2012.199
   Mosca A., 2021, P CHI C HUM FACT COM, P1
   Newton C. M., 1978, Graphics: From alpha to omega in data analysis,inGraphical Representation of Multivariate Data, P59
   Nguyen Q.V, 2016, P INT S VIS INF COMM, P43
   Ottley A, 2016, IEEE T VIS COMPUT GR, V22, P529, DOI 10.1109/TVCG.2015.2467758
   Ottley B., 2012, Tech. Rep.
   Phelan J., 2019, P CHI C HUM FACT COM, P1
   Nguyen QV, 2020, VIS INFORM, V4, P1, DOI 10.1016/j.visinf.2020.09.004
   Sankaran K, 2018, J COMPUT GRAPH STAT, V27, P553, DOI 10.1080/10618600.2017.1392866
   Sarma M., 2020, P CHI C HUM FACT COM, P1
   Spiegelhalter D., 2003, WinBUGS Ver-sion 2.0 Users Manual
   Stan Develop. Team, Shinystan
   Taka E, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.567344
   Taka S., 2022, University of Glasgow enlighten repository, DOI [10.5525/gla.researchdata.1248</p>n, DOI 10.5525/GLA.RESEARCHDATA.1248</P>N]
   Tsai J., 2011, P HUM FACT ERG SOC A, P385, DOI DOI 10.1177/1071181311551079
NR 38
TC 0
Z9 0
U1 1
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3256
EP 3267
DI 10.1109/TVCG.2022.3231967
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700030
PM 37018342
OA Green Accepted
DA 2024-11-06
ER

PT J
AU Li, ZM
   Menon, H
   Mohror, K
   Liu, SS
   Guo, LZ
   Bremer, PT
   Pascucci, V
AF Li, Zhimin
   Menon, Harshitha
   Mohror, Kathryn
   Liu, Shusen
   Guo, Luanzheng
   Bremer, Peer-Timo
   Pascucci, Valerio
TI A Visual Comparison of Silent Error Propagation
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Fault tolerance boundary; information visualization; graph
   visualization; error propagation; silent data corruption
ID VISUALIZATION; GRAPHS
AB High-performance computing (HPC) systems play a critical role in facilitating scientific discoveries. Their scale and complexity (e.g., the number of computational units and software stack) continue to grow as new systems are expected to process increasingly more data and reduce computing time. However, with more processing elements, the probability that these systems will experience a random bit-flip error that corrupts a program's output also increases, which is often recognized as silent data corruption. Analyzing the resiliency of HPC applications in extreme-scale computing to silent data corruption is crucial but difficult. An HPC application often contains a large number of computation units that need to be tested, and error propagation caused by error corruption is complex and difficult to interpret. To accommodate this challenge, we propose an interactive visualization system that helps HPC researchers understand the resiliency of HPC applications and compare their error propagation. Our system models an application's error propagation to study a program's resiliency by constructing and visualizing its fault tolerance boundary. Coordinating with multiple interactive designs, our system enables domain experts to efficiently explore the complicated spatial and temporal correlation between error propagations. At the end, the system integrated a nonmonotonic error propagation analysis with an adjustable graph propagation visualization to help domain experts examine the details of error propagation and answer such questions as why an error is mitigated or amplified by program execution.
C1 [Li, Zhimin; Pascucci, Valerio] Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
   [Menon, Harshitha; Mohror, Kathryn; Liu, Shusen; Bremer, Peer-Timo] Lawrence Livermore Natl Lab, Livermore, CA 94550 USA.
   [Guo, Luanzheng] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
C3 Utah System of Higher Education; University of Utah; United States
   Department of Energy (DOE); Lawrence Livermore National Laboratory;
   United States Department of Energy (DOE); Pacific Northwest National
   Laboratory
RP Li, ZM (corresponding author), Univ Utah, Sci Comp & Imaging Inst, Salt Lake City, UT 84112 USA.
EM zhimin@sci.utah.edu; gopalakrishn1@llnl.gov; mohror1@llnl.gov;
   liu42@llnl.gov; lenny.guo@pnnl.gov; bremer5@llnl.gov;
   pascucci@sci.utah.edu
RI pascucci, Valerio/GXF-0616-2022
OI pascucci, valerio/0000-0002-8877-2042; Bremer,
   Peer-Timo/0000-0003-4107-3831; Guo, Luanzheng/0000-0001-8266-0923
FU U.S. Department of Energy, Office of Science, Office of Advanced
   Scientific Computing Research [DE-SC0014098]; Lawrence Livermore
   National Laboratory, U.S. Department of Energy [DE-AC52-07NA27344
   (LLNL-JRNL-843184)]
FX This work was supported in part by the U.S. Department of Energy, Office
   of Science, Office of Advanced Scientific Computing Research under Award
   DE-SC0014098 and Lawrence Livermore National Laboratory, U.S. Department
   of Energy, under Contract DE-AC52-07NA27344 (LLNL-JRNL-843184).
CR Anwer AR, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00092
   Bautista-Gomez L., 2015, P 22 EUR MPI US GROU, P1
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Benacchio T., 2020, Int. J. High Perform. Comput. Appl., V35, P85
   Berrocal Eduardo., 2015, P 24 INT S HIGH PERF, P275, DOI [10.1145/2749246.2749253, DOI 10.1145/2749246.2749253]
   Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440
   Burtini G., 2013, P IEEE 26 CAN C EL C, P1
   Calhoun J, 2017, HPDC'17: PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P131, DOI 10.1145/3078597.3078617
   Cappello F., 2017, P EUR C PAR PROC, P545
   Chen ZT, 2021, I C DEPEND SYS NETWO, P1, DOI 10.1109/DSN48987.2021.00018
   Chiang WF, 2017, ACM SIGPLAN NOTICES, V52, P300, DOI 10.1145/3093333.3009846
   Di S, 2015, IEEE ACM INT SYMP, P271, DOI 10.1109/CCGrid.2015.17
   Di S, 2016, INT PARALL DISTRIB P, P730, DOI 10.1109/IPDPS.2016.11
   Dixit H. D., 2021, arXiv
   Feng SG, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P385
   Geist Al, 2016, IEEE Spectrum, V53, P30, DOI 10.1109/MSPEC.2016.7420396
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Gogolouis A, 2019, IEEE T VIS COMPUT GR, V25, P523, DOI 10.1109/TVCG.2018.2865077
   Guhur PL, 2017, IEEE INT C CL COMP, P592, DOI 10.1109/CLUSTER.2017.13
   Guo H., 2018, P EUR S PAR GRAPH VI, P91
   Guo LZ, 2021, J PARALLEL DISTR COM, V152, P111, DOI 10.1016/j.jpdc.2021.02.015
   Guo LZ, 2019, INT PARALL DISTRIB P, P878, DOI 10.1109/IPDPS.2019.00096
   Guo LZ, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18), DOI 10.1109/SC.2018.00011
   Hari SKS, 2012, ACM SIGPLAN NOTICES, V47, P123, DOI 10.1145/2189750.2150990
   Hari SKS, 2014, CONF PROC INT SYMP C, P61, DOI 10.1109/ISCA.2014.6853212
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Isaacs K. E., 2014, P EUR C VIS, P141
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   Jugel U, 2014, PROC VLDB ENDOW, V7, P797, DOI 10.14778/2732951.2732953
   Jugel U, 2014, PROC VLDB ENDOW, V7, P1705, DOI 10.14778/2733004.2733066
   Keller R., 2006, Information Visualization, V5, P62, DOI 10.1057/palgrave.ivs.9500116
   Kim A, 2015, PROC VLDB ENDOW, V8, P521, DOI 10.14778/2735479.2735485
   Laguna I, 2016, INT SYM CODE GENER, P227, DOI 10.1145/2854038.2854059
   Leveugle R, 2009, DES AUT TEST EUROPE, P502
   Li GP, 2018, I C DEPEND SYS NETWO, P27, DOI 10.1109/DSN.2018.00016
   Li ZM, 2021, IEEE T VIS COMPUT GR, V27, P3938, DOI 10.1109/TVCG.2020.2994954
   Lindstrom P, 2014, IEEE T VIS COMPUT GR, V20, P2674, DOI 10.1109/TVCG.2014.2346458
   Longabaugh WJR, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-275
   Lu QN, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3014586
   MAY TC, 1979, IEEE T ELECTRON DEV, V26, P2, DOI 10.1109/T-ED.1979.19370
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Menon H, 2018, ACM SIGPLAN NOTICES, V53, P195, DOI 10.1145/3200691.3178502
   Mukherjee SS, 2005, INT S HIGH PERF COMP, P243, DOI 10.1109/HPCA.2005.37
   Nobre C, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376381
   Rakthanmanon Thanawin, 2012, KDD, V2012, P262, DOI 10.1145/2339530.2339576
   Ruta N, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P236, DOI [10.1109/visual.2019.8933618, 10.1109/VISUAL.2019.8933618]
   Siddiqui T, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P51, DOI 10.1145/3318464.3389722
   Snir M, 2014, INT J HIGH PERFORM C, V28, P129, DOI 10.1177/1094342014522573
   Sorzano COS, 2014, Arxiv, DOI [arXiv:1403.2877, 10.48550/arXiv.1403.2877]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Wijk J. J., 1999, Proceedings 1999 IEEE Symposium on Information Visualization (InfoVis'99), P4, DOI 10.1109/INFVIS.1999.801851
   Vehlow C, 2017, COMPUT GRAPH FORUM, V36, P201, DOI 10.1111/cgf.12872
   Venkatagiri R, 2016, INT SYMP MICROARCH
   Venkatagiri R, 2019, I C DEPEND SYS NETWO, P214, DOI 10.1109/DSN.2019.00033
   Watson B., 2008, Visualizing very large layered graphs with quilts
   Wei JS, 2014, I C DEPEND SYS NETWO, P375, DOI 10.1109/DSN.2014.2
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xie C, 2019, IEEE T VIS COMPUT GR, V25, P215, DOI 10.1109/TVCG.2018.2865026
   Zhimin Li, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P362, DOI 10.1145/3437801.3441589
NR 59
TC 0
Z9 0
U1 0
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3268
EP 3282
DI 10.1109/TVCG.2022.3230636
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700085
PM 37015425
DA 2024-11-06
ER

PT J
AU Guo, JW
   Liu, YC
   Song, X
   Liu, HY
   Zhang, XP
   Cheng, ZL
AF Guo, Jianwei
   Liu, Yanchao
   Song, Xin
   Liu, Haoyu
   Zhang, Xiaopeng
   Cheng, Zhanglin
TI Line-Based 3D Building Abstraction and Polygonal Surface Reconstruction
   From Images
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE 3D reconstruction; 3D line cloud; scene abstraction; polygonal mesh
   model
ID STRUCTURE-FROM-MOTION; STEREO; REPRESENTATION; SCENE; EDGE
AB Textureless objects, repetitive patterns and limited computational resources pose significant challenges to man-made structure reconstruction from images, because feature-points-based reconstruction methods usually fail due to the lack of distinct texture or ambiguous point matches. Meanwhile multi-view stereo approaches also suffer from high computational complexity. In this article, we present a new framework to reconstruct 3D surfaces for buildings from multi-view images by leveraging another fundamental geometric primitive: line segments. To this end, we first propose a new multi-resolution line segment detector to extract 2D line segments from each image. Then, we construct a 3D line cloud by introducing an improved Line3D++ algorithm to match 2D line segments from different images. Finally, we reconstruct a complete and manifold surface mesh from 3D line segments by formulating a Bayesian probabilistic modeling problem, which accurately generates a set of underlying planes. This output model is simple and has low performance requirements for hardware devices. Experimental results demonstrate the validity of the proposed approach and its ability to generate abstract and compact surface meshes from the 3D line cloud with low computational costs.
C1 [Guo, Jianwei; Liu, Yanchao; Liu, Haoyu; Zhang, Xiaopeng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
   [Liu, Yanchao; Liu, Haoyu] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 101408, Peoples R China.
   [Song, Xin; Cheng, Zhanglin] Chinese Acad Sci, Shenzhen Inst Adv Technol SIAT, Shenzhen Key Lab Visual Comp & Analyt VisuCA, Shenzhen 518055, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Cheng, ZL (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol SIAT, Shenzhen Key Lab Visual Comp & Analyt VisuCA, Shenzhen 518055, Peoples R China.
EM jianwei.guo@nlpr.ia.ac.cn; liuyanchao18@mails.ucas.ac.cn;
   xinsong.1990@gmail.com; liuhaoyu2020@ia.ac.cn; xiaopeng.zhang@ia.ac.cn;
   zhanglin.cheng@gmail.com
RI Cheng, Zhanglin/AAP-1760-2021
OI ZHANG, Xiaopeng/0000-0002-0092-6474; Cheng,
   Zhanglin/0000-0002-3360-2679; Guo, Jianwei/0000-0002-3376-1725; Liu,
   Yanchao/0000-0002-2571-7628
FU National Natural Science Foundation of China [62172416, U22B2034,
   U21A20515, 61972388]; Shenzhen Science and Technology Program
   [JCYJ20180507182222355, GJHZ20210705141402008]; Youth Innovation
   Promotion Association of the Chinese Academy of Sciences [2022131]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62172416, U22B2034, U21A20515 and
   61972388, in part by Shenzhen Science and Technology Program under
   Grants JCYJ20180507182222355 and GJHZ20210705141402008, and in part by
   the Youth Innovation Promotion Association of the Chinese Academy of
   Sciences under Grant 2022131.
CR Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293
   Almazàn EJ, 2017, PROC CVPR IEEE, P5854, DOI 10.1109/CVPR.2017.620
   Araújo AMC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107115
   Baillard C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P559, DOI 10.1109/CVPR.1999.784966
   Baillard C., 1999, Conference on Automatic Extraction of GIS Objects from Digital Imagery, IAPRS, V32, P69
   Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001
   Bay H, 2005, PROC CVPR IEEE, P329
   Bay H, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P496
   Berger M, 2017, COMPUT GRAPH FORUM, V36, P301, DOI 10.1111/cgf.12802
   Boulch A, 2014, COMPUT GRAPH FORUM, V33, P55, DOI 10.1111/cgf.12431
   Bullen P. S., 2013, Handbook of Means and Their Inequalities
   Chen JY, 2003, PATTERN RECOGN, V36, P943, DOI 10.1016/S0031-3203(02)00128-0
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Elqursh A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3049, DOI 10.1109/CVPR.2011.5995512
   Ester M., 1996, P KDD, P226
   Fabbri R, 2016, INT J COMPUT VISION, V120, P324, DOI 10.1007/s11263-016-0912-7
   Fuhrmann S, 2015, COMPUT GRAPH-UK, V53, P44, DOI 10.1016/j.cag.2015.09.003
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Gu Y., 2013, P HIGH PERF GRAPH C, P81
   Vu HH, 2012, IEEE T PATTERN ANAL, V34, P889, DOI 10.1109/TPAMI.2011.172
   Hofer Manuel, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P535, DOI 10.1109/3DV.2014.14
   Hofer M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.92
   Hofer M, 2017, COMPUT VIS IMAGE UND, V157, P167, DOI 10.1016/j.cviu.2016.03.017
   Hofer M, 2015, LECT NOTES COMPUT SC, V9358, P237, DOI 10.1007/978-3-319-24947-6_19
   Jain A, 2010, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2010.5539781
   Kaiser A, 2019, COMPUT GRAPH FORUM, V38, P167, DOI 10.1111/cgf.13451
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Lafarge F, 2010, IEEE T IMAGE PROCESS, V19, P1683, DOI 10.1109/TIP.2010.2045695
   Langlois PA, 2019, INT CONF 3D VISION, P553, DOI 10.1109/3DV.2019.00067
   Li ML, 2016, LECT NOTES COMPUT SC, V9908, P54, DOI 10.1007/978-3-319-46493-0_4
   Li YY, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964947
   Limberger FA, 2015, PATTERN RECOGN, V48, P2043, DOI 10.1016/j.patcog.2014.12.020
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Lu XH, 2015, IEEE IMAGE PROC, P507, DOI 10.1109/ICIP.2015.7350850
   Luo YC, 2022, Arxiv, DOI arXiv:2208.11948
   Micusik B, 2017, INT J COMPUT VISION, V124, P65, DOI 10.1007/s11263-016-0971-9
   Micusik B, 2015, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2015.7298936
   Monszpart A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766995
   Mullner D., 2011, arXiv, DOI [10.48550/ARXIV.1109.2378, DOI 10.48550/ARXIV.1109.2378]
   Mura C, 2014, COMPUT GRAPH-UK, V44, P20, DOI 10.1016/j.cag.2014.07.005
   Nan LL, 2017, IEEE I CONF COMP VIS, P2372, DOI 10.1109/ICCV.2017.258
   Nan LL, 2015, COMPUT GRAPH FORUM, V34, P217, DOI 10.1111/cgf.12554
   Ramalingam S, 2013, IEEE I CONF COMP VIS, P497, DOI 10.1109/ICCV.2013.67
   Salaün Y, 2016, LECT NOTES COMPUT SC, V9911, P801, DOI 10.1007/978-3-319-46478-7_49
   Schindler G, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P846
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Smith Paul, 2006, Bellbird, V1, P17
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sugiura T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P264, DOI 10.1109/3DV.2015.37
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang JL, 2016, IEEE T VIS COMPUT GR, V22, P1760, DOI 10.1109/TVCG.2015.2461163
   Witt J, 2014, IEEE INT CONF ROBOT, P2029, DOI 10.1109/ICRA.2014.6907128
   Wu C., 2011, VisualSFM: A visual structure from motion system
   Zebedin L, 2008, LECT NOTES COMPUT SC, V5305, P873, DOI 10.1007/978-3-540-88693-8_64
   Zhang G, 2015, IEEE T ROBOT, V31, P1364, DOI 10.1109/TRO.2015.2489498
   Zhang LL, 2014, J VIS COMMUN IMAGE R, V25, P904, DOI 10.1016/j.jvcir.2014.02.013
   Zhang L, 2022, IEEE T VIS COMPUT GR, V28, P2879, DOI 10.1109/TVCG.2020.3045450
   Zhao K, 2022, IEEE T PATTERN ANAL, V44, P4793, DOI 10.1109/TPAMI.2021.3077129
NR 66
TC 8
Z9 9
U1 9
U2 24
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3283
EP 3297
DI 10.1109/TVCG.2022.3230369
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700063
PM 37015424
DA 2024-11-06
ER

PT J
AU Tian, Y
   Bai, HL
   Zhao, SD
   Fu, CW
   Yu, C
   Qin, HZ
   Wang, Q
   Heng, PA
AF Tian, Yang
   Bai, Hualong
   Zhao, Shengdong
   Fu, Chi-Wing
   Yu, Chun
   Qin, Haozhao
   Wang, Qiong
   Heng, Pheng-Ann
TI Kine-Appendage: Enhancing Freehand VR Interaction Through
   Transformations of Virtual Appendages
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Avatars; Visualization; Tracking; Hardware; Haptic interfaces;
   Performance evaluation; Headphones; Visual kinesthetic feedback; virtual
   appendage; visual transformation; isomorphic typing
ID FEEDBACK; DESIGN
AB Kinesthetic feedback, the feeling of restriction or resistance when hands contact objects, is essential for natural freehand interaction in VR. However, inducing kinesthetic feedback using mechanical hardware can be cumbersome and hard to control in commodity VR systems. We propose the kine-appendage concept to compensate for the loss of kinesthetic feedback in virtual environments, i.e., a virtual appendage is added to the user's avatar hand; when the appendage contacts a virtual object, it exhibits transformations (rotation and deformation); when it disengages from the contact, it recovers its original appearance. A proof-of-concept kine-appendage technique, BrittleStylus, was designed to enhance isomorphic typing. Our empirical evaluations demonstrated that (i) BrittleStylus significantly reduced the uncorrected error rate of naive isomorphic typing from 6.53% to 1.92% without compromising the typing speed; (ii) BrittleStylus could induce the sense of kinesthetic feedback, the degree of which was parity with that induced by pseudo-haptic (+ visual cue) methods; and (iii) participants preferred BrittleStylus over pseudo-haptic (+ visual cue) methods because of not only good performance but also fluent hand movements.
C1 [Tian, Yang; Bai, Hualong; Qin, Haozhao] Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techno, Nanning 530004, Guangxi, Peoples R China.
   [Zhao, Shengdong] Natl Univ Singapore, NUS HCI lab, Singapore 119077, Singapore.
   [Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China.
   [Fu, Chi-Wing; Heng, Pheng-Ann] Chinese Univ Hong Kong, Inst Med Intelligence & XR, Hong Kong, Peoples R China.
   [Yu, Chun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Wang, Qiong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Comp Vis & Virtual Real Tec, Shenzhen 518055, Guangdong, Peoples R China.
C3 Guangxi University; National University of Singapore; Chinese University
   of Hong Kong; Chinese University of Hong Kong; Tsinghua University;
   Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS
RP Tian, Y (corresponding author), Guangxi Univ, Guangxi Key Lab Multimedia Commun & Network Techno, Nanning 530004, Guangxi, Peoples R China.
EM ytian@gxu.edu.cn; baihl@st.gxu.edu.cn; zhaosd@comp.nus.edu.sg;
   cwfu@cse.cuhk.edu.hk; chunyu@tsinghua.edu.cn; haozhaoqin@st.gxu.edu.cn;
   wangqiong@siat.ac.cn; pheng@cse.cuhk.edu.hk
RI Fu, Chi-Wing/X-4703-2019; bai, hualong/CAH-7465-2022
OI Tian, Yang/0000-0002-6633-8579; Fu, Chi Wing/0000-0002-5238-593X; Yu,
   Chun/0000-0003-2591-7993; Heng, Pheng Ann/0000-0003-3055-5034
FU National Natural Science Foundation of China [62171145, 62072452];
   Key-Area Research and Development Program of Guangdong Province, China
   [2019B010149002]; Guangdong Provincial Basic and Applied Basic Research
   Fund- Regional Joint Fund [2020B1515130004]; Research Grants Council of
   the Hong Kong Special Administrative Region, China [T45-401/22-N];
   National Research Foundation, Singapore [AISG2-RP-2020-016]; Ministry of
   Education, Singapore; MOE Academic Research Fund Tier 2 programme
   [MOE-T2EP20221-0010]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62171145 and 62072452, in part by
   Key-Area Research and Development Program of Guangdong Province, China
   under Grant 2019B010149002, in part by Guangdong Provincial Basic and
   Applied Basic Research Fund- Regional Joint Fund under Grant
   2020B1515130004, in part by the Research Grants Council of the Hong Kong
   Special Administrative Region, China under Grant T45-401/22-N, in part
   by National Research Foundation, Singapore under its AI Singapore
   Programme AISG Award under Grant AISG2-RP-2020-016, and in part by the
   Ministry of Education, Singapore, under its MOE Academic Research Fund
   Tier 2 programme under Grant MOE-T2EP20221-0010.
CR AAlzayat M., 2019, Quantitative Measure-ment of Tool Embodiment for Virtual Reality Input Alternatives, P11
   Adhikary J, 2021, IEEE T VIS COMPUT GR, V27, P2648, DOI 10.1109/TVCG.2021.3067776
   [Anonymous], HTC Vive Pro
   [Anonymous], Oculus Integration SDK.
   [Anonymous], Gorrila Arm.
   [Anonymous], OptiTrack motion capture system.
   [Anonymous], HTC VIVE hand tracking SDK.
   [Anonymous], Levenshtein Distance
   [Anonymous], Oculus quest
   [Anonymous], LEAP MOTION
   Azmandian M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1968, DOI 10.1145/2858036.2858226
   Balakrishnan R., 1997, Proceedings of the ACM SIGCHI Conference on Human Factors in Computing Systems, P303, DOI [10.1145/258549. 258764, DOI 10.1145/258549.258764]
   Ban Y, 2021, 2021 IEEE WORLD HAPTICS CONFERENCE (WHC), P991, DOI 10.1109/WHC49131.2021.9517129
   Benko H., 2006, Conference on Human Factors in Computing Systems. CHI2006, P1263
   Blake J, 2009, IEEE-ASME T MECH, V14, P606, DOI 10.1109/TMECH.2008.2010934
   Bouzit M, 2002, IEEE-ASME T MECH, V7, P256, DOI 10.1109/TMECH.2002.1011262
   Canales R, 2019, ACM CONFERENCE ON APPLIED PERCEPTION (SAP 2019), DOI 10.1145/3343036.3343132
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Dube TJ, 2019, IN SY AP IN WE HC, V11567, P419, DOI 10.1007/978-3-030-22643-5_33
   Dudley JJ, 2019, INT SYM MIX AUGMENT, P289, DOI 10.1109/ISMAR.2019.00027
   Endo T, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P458, DOI 10.1109/WHC.2009.4810812
   Farbiz Z. H., 2007, P C ACM SIGGRAPH, P140, DOI DOI 10.1145/1280720.1280873
   Fashimpaur J, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382888
   Gruenbaum PE, 1997, PRESENCE-TELEOP VIRT, V6, P118, DOI 10.1162/pres.1997.6.1.118
   Gupta A, 2020, INT SYM MIX AUGMENT, P350, DOI 10.1109/ISMAR50242.2020.00062
   Hoffman HG, 1998, P IEEE VIRT REAL ANN, P59, DOI 10.1109/VRAIS.1998.658423
   Jackson L. B., 2020, P S SPAT US INT, P1
   Jiang HY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P692, DOI [10.1109/VR46266.2020.1581236395562, 10.1109/VR46266.2020.00-12]
   Kang H, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P38, DOI [10.1109/VR.2019.8798300, 10.1109/vr.2019.8798300]
   Kohli L, 2010, IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI 2010), P129, DOI 10.1109/3DUI.2010.5444703
   Kron A, 2003, 11TH SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS - HAPTICS 2003, PROCEEDINGS, P16, DOI 10.1109/HAPTIC.2003.1191219
   Lécuyer A, 2009, PRESENCE-TELEOP VIRT, V18, P39, DOI 10.1162/pres.18.1.39
   Lee EC, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P259, DOI [10.1109/vr.2019.8798154, 10.1109/VR.2019.8798154]
   Lijuan Liu, 2020, HCI International 2020 - Late Breaking Papers. Digital Human Modeling and Ergonomics, Mobility and Intelligent Environments. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12429), P316, DOI 10.1007/978-3-030-59987-4_23
   Lin JJW, 2002, P IEEE VIRT REAL ANN, P164, DOI 10.1109/VR.2002.996519
   Lopes P, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1471, DOI 10.1145/3025453.3025600
   Lopes P, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P11, DOI 10.1145/2807442.2807443
   Lopes Pedro, 2013, P SIGCHI C HUM FACT, P2577, DOI [DOI 10.1145/2470654.2481355EVENT-PLACE:PARIS,FRANCE, 10.1145/2470654.2481355, DOI 10.1145/2470654.2481355]
   MCNEELY WA, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P336, DOI 10.1109/VRAIS.1993.380761
   NASA TLX, ABOUT US
   Ni T, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2473
   Perry JC, 2007, IEEE-ASME T MECH, V12, P408, DOI 10.1109/TMECH.2007.901934
   Pfeiffer M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2505, DOI 10.1145/2702123.2702190
   Pham W., 2019, P 25 ACM S VIRT REAL, P1
   Prachyabrued M, 2016, IEEE T VIS COMPUT GR, V22, P1718, DOI 10.1109/TVCG.2015.2456917
   Richardson Mark., 2020, P 33 ANN ACM S US IN, P686, DOI DOI 10.1145/3379337.3415816
   Rietzler F., 2018, Breakingthe Tracking: Enabling Weight Perception Using Perceivable TrackingOffsets, P1
   Rietzler M., 2018, P CHI C HUM FACT COM, P1
   Rietzler M, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P913, DOI 10.1145/3332165.3347871
   Schneider D, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES WORKSHOPS (VRW 2020), P805, DOI [10.1109/VRW50115.2020.00-22, 10.1109/VRW50115.2020.00253]
   Shapira L, 2016, INT SYM MIX AUGMENT, P115, DOI 10.1109/ISMAR.2016.23
   Simeone AL, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3307, DOI 10.1145/2702123.2702389
   Simon T.M., 2014, P 2014 ACM C UB COMP, DOI [10.1145/2634317.2634342, DOI 10.1145/2634317.2634342]
   Soukoreff R. W., 2003, P SIGCHI C HUM FACT, P113, DOI DOI 10.1145/642611.642632
   Speicher M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174221
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Tamaki E, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P543
   Tian Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376557
   Tsetserukou K., 2010, P 1 AUGM HUM INT C, P1
   Vogel D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P657
   Wobbrock JO, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P143, DOI 10.1145/1978942.1978963
   Yi X, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P539, DOI 10.1145/2807442.2807504
   Yokokohji Y, 2003, SPRINGER TRAC ADV RO, V6, P499
   Yu R, 2020, IEEE T VIS COMPUT GR, V26, P2094, DOI 10.1109/TVCG.2020.2973056
NR 64
TC 2
Z9 2
U1 7
U2 10
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3298
EP 3313
DI 10.1109/TVCG.2022.3230746
PG 16
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700033
PM 37015422
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Richer, G
   Pister, A
   Abdelaal, M
   Fekete, JD
   Sedlmair, M
   Weiskopf, D
AF Richer, Gaelle
   Pister, Alexis
   Abdelaal, Moataz
   Fekete, Jean-Daniel
   Sedlmair, Michael
   Weiskopf, Daniel
TI Scalability in Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Scalability; Visualization; Computational modeling; Encoding;
   Psychology; Human computer interaction; Computer science; Conceptual
   framework; scalability; structured literature analysis; visualization
ID SCALE; EXPLORATION; CHALLENGES; DESIGN; GRAPHS; MEMORY
AB We introduce a conceptual model for scalability designed for visualization research. With this model, we systematically analyze over 120 visualization publications from 1990 to 2020 to characterize the different notions of scalability in these works. While many article have addressed scalability issues, our survey identifies a lack of consistency in the use of the term in the visualization research community. We address this issue by introducing a consistent terminology meant to help visualization researchers better characterize the scalability aspects in their research. It also helps in providing multiple methods for supporting the claim that a work is "scalable." Our model is centered around an effort function with inputs and outputs. The inputs are the problem size and resources, whereas the outputs are the actual efforts, for instance, in terms of computational run time or visual clutter. We select representative examples to illustrate different approaches and facets of what scalability can mean in visualization literature. Finally, targeting the diverse crowd of visualization researchers without a scalability tradition, we provide a set of recommendations for how scalability can be presented in a clear and consistent way to improve fair comparison between visualization techniques and systems and foster reproducibility.
C1 [Richer, Gaelle; Pister, Alexis; Fekete, Jean-Daniel] Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
   [Pister, Alexis] Inst Polytech Paris, CNRS, Telecom Paris, I3, Paris, France.
   [Abdelaal, Moataz; Sedlmair, Michael; Weiskopf, Daniel] Univ Stuttgart, Stuttgart, Germany.
C3 Inria; Centre National de la Recherche Scientifique (CNRS); Universite
   Paris Cite; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; University of Stuttgart
RP Richer, G (corresponding author), Univ Paris Saclay, CNRS, Inria, LISN, Gif Sur Yvette, France.
EM gaelle.richer@inria.fr; alexis.pister@inria.fr;
   moataz.abdelaal@visus.uni-stuttgart.de; jean-daniel.fekete@inria.fr;
   michael.sedlmair@visus.uni-stuttgart.de;
   daniel.weiskopf@visus.uni-stuttgart.de
RI Richer, Gaëlle/AAA-6760-2019; Weiskopf, Daniel/KWT-7459-2024; Fekete,
   Jean-Daniel/N-9175-2018
OI Fekete, Jean-Daniel/0000-0003-3770-8726; Abdelaal,
   MOATAZ/0000-0003-4630-7916; Weiskopf, Daniel/0000-0003-1174-1026;
   Pister, Alexis/0000-0002-2817-020X
FU Deutsche Forschungsgemeinschaft(DFG, German Research Foundation) [EXC
   2120/1 - 390831618]; DFG [251654672 - TRR 161]; DATAIA Convergence
   Institute [ANR-17-CONV-0003]
FX The work of Moataz Abdelaal was supported by Deutsche
   Forschungsgemeinschaft(DFG, German Research Foundation) under Germany's
   Excellence Strategy -EXC 2120/1 - 390831618. The work of Michael
   Sedlmair and Daniel Weiskopf was supported by DFG - Project-ID 251654672
   - TRR 161. The work of Alexis Pister was supported by the DATAIA
   Convergence Institute, part of the Programmed'Investissement d'Avenir,
   under Grant ANR-17-CONV-0003, operated by Inria and Telecom Paris.
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   Aigner W, 2013, COMPUT GRAPH FORUM, V32, P41, DOI 10.1111/cgf.12091
   [Anonymous], 1952, Quart. J. Exp. Psy-chol., V4, P11
   [Anonymous], 2006, P INT S SOFTW TEST A
   Battle L, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1571, DOI 10.1145/3318464.3389732
   Bennett FM, 1954, PUBLIC OPIN QUART, V18, P303
   Beyer J, 2013, IEEE T VIS COMPUT GR, V19, P2868, DOI 10.1109/TVCG.2013.142
   Bondi A. B., 2000, Proceedings Second International Workshop on Software and Performance. WOSP2000, P195, DOI 10.1145/350391.350432
   Brown B., 2017, INTERACTIONS, V24, P28, DOI DOI 10.1145/3125387
   Brown ET, 2012, IEEE CONF VIS ANAL, P83, DOI 10.1109/VAST.2012.6400486
   Budiu Raluca., 2014, Scaling User Interfaces: An Information-Processing Approach to Multi--Device Design
   Card T. P., 1983, The Psychology of Human-Computer Interaction
   Charmaz K., 2006, Constructing grounded theory: a practical guide through quantitative analysis
   Chen H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P339, DOI 10.1109/VISUAL.2002.1183793
   Cockburn A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P627
   Deng J, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3099, DOI 10.1145/2556288.2557011
   Duboc L., 2006, 28th International Conference on Software Engineering Proceedings, P949, DOI 10.1145/1134285.1134460
   Eick SG, 2002, J COMPUT GRAPH STAT, V11, P22, DOI 10.1198/106186002317375604
   Eiselmayer C., 2019, P SIGCHI C HUM FACT, P1
   Falk M, 2008, IEEE T VIS COMPUT GR, V14, P820, DOI 10.1109/TVCG.2008.25
   Fekete J.-D., 2019, DAGSTUHL REPORTS, V8, P1, DOI [DOI 10.4230/DAGREP.8.10.1, 10.4230/DAGREP.8.10.1]
   Fekete JD, 2020, IEEE COMPUT GRAPH, V40, P108, DOI 10.1109/MCG.2020.3006412
   FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392
   Georgii J, 2006, IEEE T VIS COMPUT GR, V12, P1345, DOI 10.1109/TVCG.2006.110
   Ghoniem M, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P17, DOI 10.1109/INFVIS.2004.1
   Glémarec Y, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364784
   Guiard Y, 2001, BCS CONF SERIES, P573
   GUSTAFSON JL, 1988, COMMUN ACM, V31, P532, DOI 10.1145/42411.42415
   Hadwiger M, 2012, IEEE T VIS COMPUT GR, V18, P2285, DOI 10.1109/TVCG.2012.240
   Healey CG, 1999, IEEE T VIS COMPUT GR, V5, P145, DOI 10.1109/2945.773807
   Heer J, 2010, IEEE T VIS COMPUT GR, V16, P1149, DOI 10.1109/TVCG.2010.144
   Hill M. D., 1990, Computer Architecture News, V18, P18, DOI 10.1145/121973.121975
   Howison M, 2012, IEEE T VIS COMPUT GR, V18, P17, DOI 10.1109/TVCG.2011.24
   Ip CY, 2011, IEEE T VIS COMPUT GR, V17, P1737, DOI 10.1109/TVCG.2011.231
   Isenberg P, 2017, IEEE T VIS COMPUT GR, V23, P2199, DOI 10.1109/TVCG.2016.2615308
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Jakobsen MR, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1451
   Jo J, 2019, IEEE T VIS COMPUT GR, V25, P470, DOI 10.1109/TVCG.2018.2865141
   Jo J, 2014, IEEE T VIS COMPUT GR, V20, P2329, DOI 10.1109/TVCG.2014.2346454
   Johnson C, 2004, IEEE COMPUT GRAPH, V24, P13, DOI 10.1109/MCG.2004.20
   Keim J., 2010, Mastering the Information Age - Solving Problems with Visual Analyt-ics
   Khoury M, 2012, COMPUT GRAPH FORUM, V31, P975, DOI 10.1111/j.1467-8659.2012.03090.x
   Kurzhals K, 2016, IEEE T VIS COMPUT GR, V22, P1005, DOI 10.1109/TVCG.2015.2468091
   Lam H, 2012, IEEE T VIS COMPUT GR, V18, P1520, DOI 10.1109/TVCG.2011.279
   Lex A, 2014, IEEE T VIS COMPUT GR, V20, P1983, DOI 10.1109/TVCG.2014.2346248
   Lins L, 2013, IEEE T VIS COMPUT GR, V19, P2456, DOI 10.1109/TVCG.2013.179
   Ma KL, 2009, IEEE COMPUT GRAPH, V29, P14, DOI 10.1109/MCG.2009.120
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.21105/JOSS.00861, 10.21105/joss.00861]
   Michael Maged, 2007, 2007 IEEE INT PARALL, P1, DOI DOI 10.1109/IPDPS.2007.370631
   Moritz D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300924
   Munzner T, 2009, IEEE T VIS COMPUT GR, V15, P921, DOI 10.1109/TVCG.2009.111
   Pahins CAL, 2017, IEEE T VIS COMPUT GR, V23, P671, DOI 10.1109/TVCG.2016.2598624
   Papadopoulos C, 2016, IEEE T VIS COMPUT GR, V22, P111, DOI 10.1109/TVCG.2015.2467954
   Perrot A, 2015, SYMP LARG DATA ANAL, P99, DOI 10.1109/LDAV.2015.7348077
   Pezzotti N, 2020, IEEE T VIS COMPUT GR, V26, P1172, DOI 10.1109/TVCG.2019.2934307
   Plaisant C, 2008, IEEE T VIS COMPUT GR, V14, P120, DOI 10.1109/TVCG.2007.70412
   Qiao W, 2006, IEEE T VIS COMPUT GR, V12, P1061, DOI 10.1109/TVCG.2006.150
   Robertson G, 2009, INFORM VISUAL, V8, P247, DOI 10.1057/ivs.2009.23
   Sacha D, 2017, IEEE T VIS COMPUT GR, V23, P241, DOI 10.1109/TVCG.2016.2598495
   Schreiber F, 2022, IT-INF TECHNOL, V64, P119, DOI 10.1515/itit-2022-0048
   Schulz C, 2016, BEYOND TIME AND ERRORS: NOVEL EVALUATION METHODS FOR VISUALIZATION, BELIV 2016, P112, DOI 10.1145/2993901.2993907
   Sedlmair M, 2014, IEEE T VIS COMPUT GR, V20, P2161, DOI 10.1109/TVCG.2014.2346321
   Slack J, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P41, DOI 10.1109/INFVIS.2005.1532127
   Strobelt H, 2016, IEEE T VIS COMPUT GR, V22, P399, DOI 10.1109/TVCG.2015.2467911
   Szafir DA, 2016, J VISION, V16, DOI 10.1167/16.5.11
   Thomas K. A., 2005, Illuminating the Path: TheResearch and Development Agenda for Visual Analytics
   Tierny J, 2009, IEEE T VIS COMPUT GR, V15, P1177, DOI 10.1109/TVCG.2009.163
   TREISMAN A, 1985, COMPUT VISION GRAPH, V31, P156, DOI 10.1016/S0734-189X(85)80004-9
   Veras R, 2020, IEEE T VIS COMPUT GR, V26, P749, DOI 10.1109/TVCG.2019.2934432
   Wang YH, 2019, IEEE T VIS COMPUT GR, V25, P566, DOI 10.1109/TVCG.2018.2864911
   Weinstock J. B., 2006, Tech. Rep. CMU/SEI-2006-TN-012
   Wenwen Dou, 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P231, DOI 10.1109/VAST.2011.6102461
   Wilkinson L, 2008, J COMPUT GRAPH STAT, V17, P473, DOI 10.1198/106186008X320465
   Wong PC, 2012, IEEE COMPUT GRAPH, V32, P63, DOI 10.1109/MCG.2012.87
   Yoghourdjian V, 2021, IEEE T VIS COMPUT GR, V27, P1677, DOI 10.1109/TVCG.2020.3030459
   Yost B, 2006, IEEE T VIS COMPUT GR, V12, P837, DOI 10.1109/TVCG.2006.184
NR 76
TC 7
Z9 7
U1 0
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3314
EP 3330
DI 10.1109/TVCG.2022.3231230
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700008
PM 37015637
OA Green Submitted, hybrid
DA 2024-11-06
ER

PT J
AU Ramirez, JR
   Rautek, P
   Bohak, C
   Strnad, O
   Zhang, ZY
   Li, S
   Viola, I
   Heidrich, W
AF Ramirez, Julio Rey
   Rautek, Peter
   Bohak, Ciril
   Strnad, Ondrej
   Zhang, Zheyuan
   Li, Sai
   Viola, Ivan
   Heidrich, Wolfgang
TI GPU Accelerated 3D Tomographic Reconstruction and Visualization From
   Noisy Electron Microscopy Tilt-Series
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Image reconstruction; Noise reduction; Uncertainty; Three-dimensional
   displays; Iterative methods; Visualization; Electron microscopy;
   Cryo-ET; electron tomography; GPU acceleration; tilt-series; tomographic
   reconstruction; visualization
ID ALGEBRAIC RECONSTRUCTION; IMAGE-RECONSTRUCTION; UNCERTAINTY
   VISUALIZATION; PLATFORM; ART
AB We present a novel framework for 3D tomographic reconstruction and visualization of tomograms from noisy electron microscopy tilt-series. Our technique takes as an input aligned tilt-series from cryogenic electron microscopy and creates denoised 3D tomograms using a proximal jointly-optimized approach that iteratively performs reconstruction and denoising, relieving the users of the need to select appropriate denoising algorithms in the pre-reconstruction or post-reconstruction steps. The whole process is accelerated by exploiting parallelism on modern GPUs, and the results can be visualized immediately after the reconstruction using volume rendering tools incorporated in the framework. We show that our technique can be used with multiple combinations of reconstruction algorithms and regularizers, thanks to the flexibility provided by proximal algorithms. Additionally, the reconstruction framework is open-source and can be easily extended with additional reconstruction and denoising methods. Furthermore, our approach enables visualization of reconstruction error throughout the iterative process within the reconstructed tomogram and on projection planes of the input tilt-series. We evaluate our approach in comparison with state-of-the-art approaches and additionally show how our error visualization can be used for reconstruction evaluation.
C1 [Ramirez, Julio Rey; Rautek, Peter; Bohak, Ciril; Strnad, Ondrej; Viola, Ivan; Heidrich, Wolfgang] King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
   [Zhang, Zheyuan; Li, Sai] Tsinghua Univ, Sch Life Sci, Beijing 100084, Peoples R China.
C3 King Abdullah University of Science & Technology; Tsinghua University
RP Ramirez, JR (corresponding author), King Abdullah Univ Sci & Technol KAUST, Visual Comp Ctr, Thuwal 23955, Saudi Arabia.
EM julio.reyramirez@kaust.edu.sa; peter.rautek@kaust.edu.sa;
   ciril.bohak@kaust.edu.sa; ondrej.strnad@kaust.edu.sa;
   zheyuanzhang@tsinghua.edu.cn; sai@tsinghua.edu.cn;
   ivan.viola@kaust.edu.sa; wolfgang.heidrich@kaust.edu.sa
RI Strnad, Ondřej/GXV-9172-2022; Li, Sai/AAC-5187-2019; Viola,
   Ivan/O-8944-2014
OI Heidrich, Wolfgang/0000-0002-4227-8508; Strnad,
   Ondrej/0000-0002-8077-4692; Viola, Ivan/0000-0003-4248-6574; Li,
   Sai/0000-0002-9353-0355; Rautek, Peter/0000-0003-4821-7404
FU King Abdullah University of Science and Technology through a Competitive
   Research Grant (CRG); VCC Center Competitive Funding (CCF)
   [BAS/1/1680-01-01]; Tsinghua University Spring Breeze Fund
   [2021Z99CFZ004]; National Natural Science Foundation of China [32171195]
FX This work was supported in part by the King Abdullah University of
   Science and Technology through a Competitive Research Grant (CRG), in
   part by the VCC Center Competitive Funding (CCF) under Grant
   BAS/1/1680-01-01, in part by the Tsinghua University Spring Breeze Fund
   under Grant 2021Z99CFZ004, and in part by the National Natural Science
   Foundation of China under Grant 32171195.
CR ANDERSEN AH, 1984, ULTRASONIC IMAGING, V6, P81, DOI 10.1016/0161-7346(84)90008-7
   ANDERSEN AH, 1989, IEEE T MED IMAGING, V8, P50, DOI 10.1109/42.20361
   Appel A, 1968, P APR 30 MAY2 1968 S, P37, DOI 10.1145/1468075.1468082
   Bailey D.L., 2005, Positron Emission Tomography, V2
   Bepler T, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18952-1
   Böhning J, 2022, STRUCTURE, V30, P408, DOI 10.1016/j.str.2021.12.010
   Bonneau G.-P., 2014, Overview and State-of-the-Art of Uncertainty Visualization, V37, P3, DOI [10.1007/978-1-4471-6497-5_1, DOI 10.1007/978-1-4471-6497-5_1]
   BRACEWELL RN, 1967, ASTROPHYS J, V150, P427, DOI 10.1086/149346
   Brodlie K., 2012, Expanding the Frontiers of Visual Analytics and Visualization, P81, DOI [10.1007/978-1-4471-2804-5_6, 10.1007/978-1-4471-2804-56, DOI 10.1007/978-1-4471-2804-56]
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Budinger T. F., 1979, Image reconstruction from projections. Implementation and applications, P147
   Dinesha V, 2012, VISUAL COMPUT, V28, P265, DOI 10.1007/s00371-011-0614-7
   Ding GL, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49267-x
   Donati L., 2020, PhD Thesis
   FELDKAMP LA, 1984, J OPT SOC AM A, V1, P612, DOI 10.1364/JOSAA.1.000612
   Frangakis AS, 2021, J STRUCT BIOL, V213, DOI 10.1016/j.jsb.2021.107804
   Frikel J, 2013, APPL COMPUT HARMON A, V34, P117, DOI 10.1016/j.acha.2012.03.005
   GILBERT P, 1972, J THEOR BIOL, V36, P105, DOI 10.1016/0022-5193(72)90180-4
   Gillmann C, 2021, COMPUT GRAPH FORUM, V40, P665, DOI 10.1111/cgf.14333
   GORDON R, 1970, J THEOR BIOL, V29, P471, DOI 10.1016/0022-5193(70)90109-8
   Goris B, 2013, ULTRAMICROSCOPY, V127, P40, DOI 10.1016/j.ultramic.2012.07.003
   Gürsoy D, 2014, J SYNCHROTRON RADIAT, V21, P1188, DOI 10.1107/S1600577514013939
   Han RM, 2017, J STRUCT BIOL, V199, P196, DOI 10.1016/j.jsb.2017.07.008
   Hansen PC, 2018, NUMER ALGORITHMS, V79, P107, DOI 10.1007/s11075-017-0430-x
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260
   Hernell F, 2010, IEEE T VIS COMPUT GR, V16, P548, DOI 10.1109/TVCG.2009.45
   Hsieh J., 2015, Computed Tomography: Principles, Design, Artifacts, and Recent Advances, V3, DOI [10.1117/3.2197756, DOI 10.1117/3.2197756]
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732
   Huettel S. A., 2014, Functional Magnetic Resonance Imaging, V1
   Iudin A, 2016, NAT METHODS, V13, P387, DOI 10.1038/nmeth.3806
   Johnson CR, 2003, IEEE COMPUT GRAPH, V23, P6, DOI 10.1109/MCG.2003.1231171
   Kak A. C., 1988, Principles of computerized tomographic imaging, DOI 10.1118/1.1455742
   Kak A. C., 2001, Principles of computerized tomo- graphic imaging, P37
   Kamal A, 2021, J VISUAL-JAPAN, V24, P861, DOI 10.1007/s12650-021-00755-1
   Kniss JM, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P287
   Kremer JR, 1996, J STRUCT BIOL, V116, P71, DOI 10.1006/jsbi.1996.0013
   Kuba J, 2021, J MICROSC-OXFORD, V281, P112, DOI 10.1111/jmi.12939
   Li S, 2022, TRENDS BIOCHEM SCI, V47, P173, DOI 10.1016/j.tibs.2021.08.005
   Lindholm S, 2010, IEEE T VIS COMPUT GR, V16, P1301, DOI 10.1109/TVCG.2010.195
   Liu YT, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33957-8
   Lundström C, 2007, IEEE T VIS COMPUT GR, V13, P1648, DOI 10.1109/TVCG.2007.70518
   MAX N, 1995, IEEE T VIS COMPUT GR, V1, P99, DOI 10.1109/2945.468400
   Nguyen K T., 2010, IEEE/EG Volume Graphics, P53, DOI DOI 10.2312/VG/VG10/053-060
   Ni T, 2022, NAT PROTOC, V17, P421, DOI 10.1038/s41596-021-00648-5
   Noo F, 2002, PHYS MED BIOL, V47, P2525, DOI 10.1088/0031-9155/47/14/311
   Ollinger JM, 1997, IEEE SIGNAL PROC MAG, V14, P43, DOI 10.1109/79.560323
   Palovcak E, 2020, IUCRJ, V7, P1142, DOI 10.1107/S2052252520013184
   Parikh N., 2014, FoundationsandTrendsR inOptimization, V1, P127, DOI 10.1561/2400000003
   Pyle E, 2021, BIOCHEM J, V478, P1827, DOI 10.1042/BCJ20200715
   Radermacher M., 1992, Electron Tomography, P245
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sorzano COS, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/6482567
   STEARNS CW, 1987, IEEE T NUCL SCI, V34, P374, DOI 10.1109/TNS.1987.4337366
   Su M., 2018, Generative adversarial networks as a tool to recover structural information from cryo-electron microscopy data
   Suetens P, 2017, FUNDAMENTALS OF MEDICAL IMAGING, 3RD EDITION, P1, DOI 10.1017/9781316671849
   Trampert P, 2018, ULTRAMICROSCOPY, V191, P1, DOI 10.1016/j.ultramic.2018.04.001
   Trifonov B., 2006, PROC EUROGRAPHICS S, P51, DOI DOI 10.1145/1179849.1179918
   Turk M, 2020, FEBS LETT, V594, P3243, DOI 10.1002/1873-3468.13948
   van Aarle W, 2016, OPT EXPRESS, V24, P25129, DOI 10.1364/OE.24.025129
   van Aarle W, 2015, ULTRAMICROSCOPY, V157, P35, DOI 10.1016/j.ultramic.2015.05.002
   Veach E., 1997, Robust monte carlo methods for light transport simulation
   Venkatakrishnan SV, 2015, IEEE TRANS COMPUT IM, V1, P1, DOI 10.1109/TCI.2014.2371751
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang G, 2018, IEEE T MED IMAGING, V37, P1289, DOI 10.1109/TMI.2018.2833635
   Wang TH, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.4.043504
   Westover L. A., 1991, Splatting: A parallel, feed-forward volume ren- dering algorithm
   Würfl T, 2018, IEEE T MED IMAGING, V37, P1454, DOI 10.1109/TMI.2018.2833499
   Xu JQ, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab08f9
   Xue L, 2022, NATURE, V610, P205, DOI 10.1038/s41586-022-05255-2
   Yan R, 2019, J STRUCT BIOL, V206, P183, DOI 10.1016/j.jsb.2019.03.002
   Yao HP, 2020, CELL, V183, P730, DOI 10.1016/j.cell.2020.09.018
   Zang GM, 2018, LECT NOTES COMPUT SC, V11220, P145, DOI 10.1007/978-3-030-01270-0_9
NR 72
TC 0
Z9 0
U1 2
U2 3
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3331
EP 3345
DI 10.1109/TVCG.2022.3230445
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700037
PM 37015451
OA hybrid
DA 2024-11-06
ER

PT J
AU Ghaffari, B
   Gatti, D
   Westermann, R
AF Ghaffari, Behdad
   Gatti, Davide
   Westermann, Rudiger
TI Spatio-Temporal Visual Analysis of Turbulent Superstructures in Unsteady
   Flow
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Three-dimensional displays; Visualization; Graphics processing units;
   Periodic structures; Data visualization; Feature extraction; Bandwidth;
   Flow visualization; large-scale data techniques; animation and
   motion-related techniques
ID SCALE STRUCTURES; WALL; VISUALIZATION; THERAPIES; FRAMEWORK
AB The large-scale motions in 3D turbulent channel flows, known as Turbulent Superstructures (TSS), play an essential role in the dynamics of small-scale structures within the turbulent boundary layer. However, as of today, there is no common agreement on the spatial and temporal relationships between these multiscale structures. We propose a novel space-time visualization technique for analyzing the temporal evolution of these multiscale structures in their spatial context and, thus, to further shed light on the conceptually different explanations of their dynamics. Since the temporal dynamics of TSS are believed to influence the structures in the turbulent boundary layer, we propose a combination of a 2D space-time velocity plot with an orthogonal 2D plot of projected 3D flow structures, which can interactively span the time and the space axis. Besides flow structures indicating the fluid motion, we propose showing the variations in derived fields as an additional source of explanation. The relationships between the structures in different spatial and temporal scales can be more effectively resolved by using various filtering operations and image registration algorithms. To reduce the information loss due to the non-injective nature of projection, spatial information is encoded into transparency or color. Since the proposed visualization is heavily demanding computational resources and memory bandwidth to stream unsteady flow fields and instantly compute derived 3D flow structures, the implementation exploits data compression, parallel computation capabilities, and high memory bandwidth on recent GPUs via the CUDA compute library.
C1 [Ghaffari, Behdad; Westermann, Rudiger] Tech Univ Munich, D-80333 Munich, Germany.
   [Gatti, Davide] Karlsruhe Inst Technol, D-76131 Karlsruhe, Germany.
C3 Technical University of Munich; Helmholtz Association; Karlsruhe
   Institute of Technology
RP Ghaffari, B (corresponding author), Tech Univ Munich, D-80333 Munich, Germany.
EM behdad.ghaffari@tum.de; davide.gatti@kit.edu; westermann@tum.de
RI Gatti, Davide/AAY-1842-2021
OI Westermann, Rudiger/0000-0002-3394-0731
FU German Research Foundation (DFG) [SPP 1881]
FX This work was supported by the German Research Foundation (DFG) within
   the Priority Programme Turbulent Superstructures under Grant SPP 1881.
CR Abe H, 2018, J FLUID MECH, V850, P733, DOI 10.1017/jfm.2018.434
   Adrian RJ, 2007, PHYS FLUIDS, V19, DOI 10.1063/1.2717527
   Amanatides A., 1987, Tech. Papers, P3
   Buerger PolinaKondratieva Kai., 2007, EUROGRAPHICS, P251
   Bujack R, 2020, ENVIRON EARTH SCI, V79, DOI 10.1007/s12665-019-8800-4
   Burger K., 2012, Proc. Vis. Data Anal
   Chernyshenko SI, 2005, J FLUID MECH, V544, P99, DOI 10.1017/S0022112005006506
   Childs H., 2012, HIGH PERFORMANCE VIS, P395
   Cimarelli A, 2016, J FLUID MECH, V796, DOI 10.1017/jfm.2016.275
   Del Alamo JC, 2009, J FLUID MECH, V640, P5, DOI 10.1017/S0022112009991029
   Dickey JW, 2009, PUBLIC ADMINISTRATION (P. A.) GENOME PROJECT: CAPTURING MAPPING AND DEPLOYING THE GENES OF P. A., P43
   Dogan E, 2019, FLUID DYN RES, V51, DOI 10.1088/1873-7005/aaca81
   Frasson A, 2019, IEEE PAC VIS SYMP, P202, DOI 10.1109/PacificVis.2019.00031
   Garth K., 2014, Math. Vis., V37, P327
   Günther T, 2018, COMPUT GRAPH FORUM, V37, P149, DOI 10.1111/cgf.13319
   Guo HQ, 2019, IEEE T VIS COMPUT GR, V25, P2710, DOI 10.1109/TVCG.2018.2856772
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hutchins N, 2007, J FLUID MECH, V579, P1, DOI 10.1017/S0022112006003946
   Hutchins N, 2007, PHILOS T R SOC A, V365, P647, DOI 10.1098/rsta.2006.1942
   Jankowai J, 2020, IEEE T VIS COMPUT GR, V26, P1308, DOI 10.1109/TVCG.2018.2867488
   Jiménez J, 1999, J FLUID MECH, V389, P335, DOI 10.1017/S0022112099005066
   Kern M, 2021, IEEE T VIS COMPUT GR, V27, P3361, DOI 10.1109/TVCG.2020.2975795
   LELE SK, 1992, J COMPUT PHYS, V103, P16, DOI 10.1016/0021-9991(92)90324-R
   Liu XP, 2019, COMPUT GRAPH FORUM, V38, P300, DOI 10.1111/cgf.13532
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674
   Luchini P, 2006, J COMPUT PHYS, V211, P551, DOI 10.1016/j.jcp.2005.06.003
   Mathis R, 2009, J FLUID MECH, V628, P311, DOI 10.1017/S0022112009006946
   McLoughlin R. S., 2009, Eurographics State Art Rep., P1807
   Nguyen DB, 2021, IEEE T VIS COMPUT GR, V27, P902, DOI 10.1109/TVCG.2020.3028892
   Nsonga B, 2020, IEEE T VIS COMPUT GR, V26, P3147, DOI 10.1109/TVCG.2019.2920157
   Peterka T., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P580, DOI 10.1109/IPDPS.2011.62
   Pope S., 2000, Turbulent Flows, V35
   Quadrio M, 2003, PHYS FLUIDS, V15, P2219, DOI 10.1063/1.1586273
   Schirski M., 2004, Proceedings of the 2004 ACMSIGGRAPH international conference on Virtual Reality continuum and its applications in industry, P141
   Smits AJ, 2011, ANNU REV FLUID MECH, V43, P353, DOI 10.1146/annurev-fluid-122109-160753
   Sreenivasan KR, 1997, ANNU REV FLUID MECH, V29, P435, DOI 10.1146/annurev.fluid.29.1.435
   Talluru KM, 2014, J FLUID MECH, V746, DOI 10.1017/jfm.2014.132
   Toh S, 2005, J FLUID MECH, V524, P249, DOI 10.1017/S002211200400237X
   Treib Marc, 2015, 6th International Conference on Information Visualization Theory and Applications (VISIGRAPP 2015). Proceedings, P279
   Treib M., 2014, Ph.D. dissertation
   Treib M, 2012, IEEE T VIS COMPUT GR, V18, P2169, DOI 10.1109/TVCG.2012.274
   Zachiu C, 2015, PHYS MED BIOL, V60, P9003, DOI 10.1088/0031-9155/60/23/9003
   Zachiua C, 2015, MED PHYS, V42, P4137, DOI 10.1118/1.4922403
   Zhang J, 2018, J VISUAL-JAPAN, V21, P351, DOI 10.1007/s12650-017-0470-2
NR 44
TC 0
Z9 0
U1 2
U2 2
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3346
EP 3358
DI 10.1109/TVCG.2022.3232367
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700052
PM 37015508
DA 2024-11-06
ER

PT J
AU Pan, RS
   Wang, ZY
   Wei, YT
   Gao, H
   Ou, GC
   Cao, CC
   Xu, JL
   Xu, T
   Chen, W
AF Pan, Rusheng
   Wang, Zhiyong
   Wei, Yating
   Gao, Han
   Ou, Gongchang
   Cao, Caleb Chen
   Xu, Jingli
   Xu, Tong
   Chen, Wei
TI Towards Efficient Visual Simplification of Computational Graphs in Deep
   Neural Networks
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Visualization; Computational modeling; Tensors; Layout; Bit error rate;
   Graph drawing; Computational efficiency; Deep neural networks;
   computational graphs; graph visualization; graph layout; visual
   simplifications
ID OF-THE-ART; LEARNING-MODELS; VISUALIZATION; EXPLORATION
AB A computational graph in a deep neural network (DNN) denotes a specific data flow diagram (DFD) composed of many tensors and operators. Existing toolkits for visualizing computational graphs are not applicable when the structure is highly complicated and large-scale (e.g., BERT (Devlin et al. 2019)). To address this problem, we propose leveraging a suite of visual simplification techniques, including a cycle-removing method, a module-based edge-pruning algorithm, and an isomorphic subgraph stacking strategy. We design and implement an interactive visualization system that is suitable for computational graphs with up to 10 thousand elements. Experimental results and usage scenarios demonstrate that our tool reduces 60% elements on average and hence enhances the performance for recognizing and diagnosing DNN models. Our contributions are integrated into an open-source DNN visualization toolkit, namely, MindInsight [2].
C1 [Pan, Rusheng; Wang, Zhiyong; Wei, Yating; Xu, Jingli; Xu, Tong; Chen, Wei] Zhejiang Univ, Stake key Lab CAD&CG, Hangzhou 310027, Peoples R China.
   [Gao, Han; Ou, Gongchang; Cao, Caleb Chen] Huawei Technol Co Ltd, Distributed Data Lab, Shenzhen 518129, Peoples R China.
C3 Zhejiang University; Huawei Technologies
RP Chen, W (corresponding author), Zhejiang Univ, Stake key Lab CAD&CG, Hangzhou 310027, Peoples R China.
EM panrusheng@zju.edu.cn; zerowangzy@outlook.com; weiyating@zju.edu.cn;
   gaohan19@huawei.com; ougongchang@huawei.com; caleb.cao@huawei.com;
   xu1220341948@gmail.com; xutong8@zju.edu.cn; chenvis@zju.edu.cn
RI Li, Jicheng/HLH-8596-2023; Pan, Rusheng/AAA-7007-2020; Chen,
   Wei/AAR-9817-2020
OI Chen, Wei/0000-0002-8365-4741
FU National Natural Science Foundation of China [62132017]; Fundamental
   Research Funds for the Central Universities [226-2022-00235]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62132017, and in part by the Fundamental
   Research Funds for the Central Universities under Grant 226-2022-00235.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahn Y, 2020, IEEE T VIS COMPUT GR, V26, P1086, DOI 10.1109/TVCG.2019.2934262
   Andrienko G, 2021, IEEE T VIS COMPUT GR, V27, P2280, DOI 10.1109/TVCG.2019.2952129
   [Anonymous], 2006, J. Graph Algorithms Appl.
   [Anonymous], 1996, Graph Drawing, DOI DOI 10.1007/3-540-62495-3_41
   Archambault D, 2008, IEEE T VIS COMPUT GR, V14, P900, DOI 10.1109/TVCG.2008.34
   Bäuerle A, 2021, IEEE T VIS COMPUT GR, V27, P2980, DOI 10.1109/TVCG.2021.3057483
   Balzer M, 2007, ASIA-PACIFIC SYMPOSIUM ON VISUALISATION 2007, PROCEEDINGS, P133
   BATINI C, 1986, IEEE T SOFTWARE ENG, V12, P538, DOI 10.1109/TSE.1986.6312901
   Berger M, 2017, IEEE T VIS COMPUT GR, V23, P691, DOI 10.1109/TVCG.2016.2598667
   Bernard J, 2018, IEEE T VIS COMPUT GR, V24, P298, DOI 10.1109/TVCG.2017.2744818
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Chatzimparmpas A, 2020, COMPUT GRAPH FORUM, V39, P713, DOI 10.1111/cgf.14034
   Chollet F., 2015, KERAS
   Cockburn A, 2008, ACM COMPUT SURV, V41, DOI 10.1145/1456650.1456652
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dingen D, 2019, IEEE T VIS COMPUT GR, V25, P246, DOI 10.1109/TVCG.2018.2865043
   Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786
   Du MN, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1358, DOI 10.1145/3219819.3220099
   Eades Q.-W., 1996, Graph Drawing, P1
   Ehrlinger L, 2019, LECT NOTES COMPUT SC, V11706, P227, DOI 10.1007/978-3-030-27615-7_17
   Estébanez C, 2014, SOFTWARE PRACT EXPER, V44, P681, DOI 10.1002/spe.2179
   GANSNER ER, 1993, IEEE T SOFTWARE ENG, V19, P214, DOI 10.1109/32.221135
   Gunning D, 2019, AI MAG, V40, P44, DOI 10.1609/aimag.v40i2.2850
   gwding, 2016, The draw-convnet repository on github
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Huang XD, 2006, J VISUAL LANG COMPUT, V17, P225, DOI 10.1016/j.jvlc.2005.10.003
   Jia J. J., 2019, Mach. Learn. Syst., P1
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Krause J, 2014, IEEE T VIS COMPUT GR, V20, P1614, DOI 10.1109/TVCG.2014.2346482
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulesza Todd, 2015, P 20 INT C INT US IN, P126, DOI [DOI 10.1145/2678025.2701399, 10.1145/2678025.2701399]
   Larman C., 2012, Applying UMLand Patterns: An Introduction to Object Oriented Analysis and Designand Interative Development, P127
   Larochelle H, 2009, J MACH LEARN RES, V10, P1
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu MC, 2018, IEEE T VIS COMPUT GR, V24, P77, DOI 10.1109/TVCG.2017.2744938
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Liu SX, 2017, VIS INFORM, V1, P48, DOI 10.1016/j.visinf.2017.01.006
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   lutzroeder, 2017, The NETRON repository on github
   mindspore-ai, 2020, The MindSpore repository on github
   mindspore-ai, 2020, The MindInsight repository on github
   Ming Y, 2017, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2017.8585721
   Owhadi H, 2022, RES MATH SCI, V9, DOI 10.1007/s40687-022-00320-8
   PaddlePaddle, 2016, The VisualDL repository on github
   Paszke A, 2019, ADV NEUR IN, V32
   Quigley A., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P197
   Samek W., 2017, arXiv preprint arXiv:1708.08296
   Sander G., 1995, Graph Drawing. DIMACS International Workshop, GD'94. Proceedings, P194
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schaffer D., 1996, ACM Transactions on ComputerHuman Interaction (TOCHI), V3, P162, DOI [DOI 10.1145/230562.2305772, DOI 10.1145/230562.230577]
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spönemann M, 2010, LECT NOTES COMPUT SC, V5849, P135, DOI 10.1007/978-3-642-11805-0_14
   Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158
   SUGIYAMA K, 1981, IEEE T SYST MAN CYB, V11, P109, DOI 10.1109/TSMC.1981.4308636
   Sun MY, 2016, IEEE T VIS COMPUT GR, V22, P310, DOI 10.1109/TVCG.2015.2467813
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tzeng FY, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P383
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   waleedka, 2018, The HiddenLayer repository on github
   Wang JP, 2018, IEEE T VIS COMPUT GR, V24, P1905, DOI 10.1109/TVCG.2018.2816223
   Wongsuphasawat K, 2018, IEEE T VIS COMPUT GR, V24, P1, DOI 10.1109/TVCG.2017.2744878
   Xu K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174237
   yu4u, 2018, The convnet-drawer repository on github
   Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7
NR 68
TC 0
Z9 0
U1 2
U2 4
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3359
EP 3373
DI 10.1109/TVCG.2022.3230832
PG 15
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700062
PM 37015673
OA Green Submitted
DA 2024-11-06
ER

PT J
AU Gong, MJ
   Chen, XJ
AF Gong, Mingjun
   Chen, Xiaojun
TI 3D Surface-Closed Mesh Clipping Based on Polygonal Partitioning for
   Surgical Planning
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Surgery; Planning; Partitioning algorithms; Computational modeling;
   Three-dimensional displays; Software algorithms; Software; Model
   clipping; surgical planning; triangular mesh; partitioning
ID MAXILLOFACIAL SURGERY; TIME; SEGMENTATION; NAVIGATION; SIMULATION
AB How to create an efficient and accurate interactive tool for triangular mesh clipping is one of the key problems to be solved in computer-assisted surgical planning. Although the existing algorithms can realize three-dimensional model clipping, problems still remain unsolved regarding the flexibility of clipping paths and the capping of clipped cross-sections. In this study, we propose a mesh clipping algorithm for surgical planning based on polygonal convex partitioning. First, two-dimensional polygonal regions are extended to three-dimensional clipping paths generated from selected reference points. Second, the convex regions are partitioned with a recursive algorithm to obtain the clipped and residual models with closed surfaces. Finally, surgical planning software with the function of mesh clipping has been developed, which is capable to create complex clipping paths by normal vector adjustment and thickness control. The robustness and efficiency of our algorithm have been demonstrated by surgical planning of craniomaxillofacial osteotomy, pelvis tumor resection and cranial vault remodeling.
C1 [Gong, Mingjun] Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Biomed Mfg & Life Qual Engn, Shanghai 200240, Peoples R China.
   [Chen, Xiaojun] Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Med Robot, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Chen, XJ (corresponding author), Shanghai Jiao Tong Univ, Sch Mech Engn, Inst Med Robot, Shanghai 200240, Peoples R China.
EM 897774009@sjtu.edu.cn; xiaojunchen@sjtu.edu.cn
FU National Key R&D Program of China [2022YFE0197900]; National Natural
   Science Foundation of China [81971709, M-0019, 82011530141]; Foundation
   of Science and Technology Commission of Shanghai Municipality
   [20490740700]; Shanghai Jiao Tong University Foundation on Medical and
   Technological Joint Science Research [YG2019ZDA06, YG2021ZD21,
   YG2021QN72, YG2022QN056]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2022YFE0197900, in part by the National Natural Science
   Foundation of China under Grants 81971709, M-0019, and 82011530141, in
   part by the Foundation of Science and Technology Commission of Shanghai
   Municipality under Grant 20490740700, and in part by Shanghai Jiao Tong
   University Foundation on Medical and Technological Joint Science
   Research under Grants YG2019ZDA06, YG2021ZD21, YG2021QN72, and
   YG2022QN056.
CR Chahhou M, 2014, IEEE T PATTERN ANAL, V36, P1687, DOI 10.1109/TPAMI.2013.2297314
   CHAZELLE B, 1991, DISCRETE COMPUT GEOM, V6, P485, DOI 10.1007/BF02574703
   Chen XJ, 2016, EXPERT REV MED DEVIC, V13, P1043, DOI 10.1080/17434440.2016.1243054
   Chen ZX, 2021, J ORAL MAXIL SURG, V79, DOI 10.1016/j.joms.2020.09.005
   Eberly D., 2022, Triangulation by ear clipping
   Franz L, 2017, J ORAL MAXIL SURG, V75, P1971, DOI 10.1016/j.joms.2017.04.043
   García-Mato D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-54148-4
   Greene D. H., 1983, Comput. Geometry, V1, P235
   Greiner G, 1998, ACM T GRAPHIC, V17, P71, DOI 10.1145/274363.274364
   Hammoudeh JA, 2015, PRS-GLOB OPEN, V3, DOI 10.1097/GOX.0000000000000184
   HERTEL S, 1983, LECT NOTES COMPUT SC, V158, P207
   Hu YX, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323011
   Jiao X, 2018, J COMPUT APPL MATH, V329, P134, DOI 10.1016/j.cam.2017.05.007
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Li Z., 2020, Int. J. Adv. Robotic Syst., V17
   Mardini S, 2014, J PLAST RECONSTR AES, V67, P336, DOI 10.1016/j.bjps.2013.11.004
   Mehta VA, 2010, NEUROSURG FOCUS, V29, DOI 10.3171/2010.9.FOCUS10204
   Nilsson J, 2020, J CRANIO MAXILL SURG, V48, P132, DOI 10.1016/j.jcms.2019.11.024
   Pan JJ, 2015, COMPUT ANIMAT VIRT W, V26, P321, DOI 10.1002/cav.1655
   Paulus CJ, 2015, VISUAL COMPUT, V31, P831, DOI 10.1007/s00371-015-1123-x
   Phillips Bradley J, 2017, Bull Emerg Trauma, V5, P221, DOI 10.18869/acadpub.beat.5.4.499.
   Qin YG, 2019, ENERGY SCI ENG, V7, P1154, DOI 10.1002/ese3.335
   Shewchuk J.R., 1996, WORKSH APPL COMP GEO, P203
   Simonson LJ, 2010, COMPUT AIDED DESIGN, V42, P1189, DOI 10.1016/j.cad.2010.06.008
   Smit N, 2017, IEEE T VIS COMPUT GR, V23, P741, DOI 10.1109/TVCG.2016.2598826
   SUTHERLAND IE, 1974, COMMUN ACM, V17, P32, DOI 10.1145/360767.360802
   Theologou P, 2015, COMPUT VIS IMAGE UND, V135, P49, DOI 10.1016/j.cviu.2014.12.008
   Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38
   VATTI BR, 1992, COMMUN ACM, V35, P56, DOI 10.1145/129902.129906
   Vercruysse H, 2021, J CRANIO MAXILL SURG, V49, P341, DOI 10.1016/j.jcms.2021.01.011
   Wang CCL, 2011, IEEE T VIS COMPUT GR, V17, P836, DOI 10.1109/TVCG.2010.106
   Wang MN, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1923
   Weiler K., 1977, ACM SIGGRAPH Comput. Graph., V11, P214, DOI [10.1145/563858.563896, DOI 10.1145/965141.563896, 10.1145/965141.563896]
   Wong KC, 2015, COMPUT AIDED SURG, V20, P14, DOI 10.3109/10929088.2015.1076039
   Wong KC, 2016, INT J COMPUT ASS RAD, V11, P307, DOI 10.1007/s11548-015-1250-x
   Wu J, 2015, COMPUT GRAPH FORUM, V34, P161, DOI 10.1111/cgf.12528
   Yiannakopoulou E, 2015, INT J SURG, V13, P60, DOI 10.1016/j.ijsu.2014.11.014
   Zhan QQ, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145987
   Zhang Y, 2020, IEEE T MED IMAGING, V39, P1511, DOI 10.1109/TMI.2019.2951838
   Zheng YY, 2012, IEEE T VIS COMPUT GR, V18, P1304, DOI 10.1109/TVCG.2011.140
NR 40
TC 0
Z9 0
U1 3
U2 6
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3374
EP 3385
DI 10.1109/TVCG.2022.3230739
PG 12
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700090
PM 37015426
DA 2024-11-06
ER

PT J
AU Meidiana, A
   Hong, SH
   Cai, SJ
   Torkel, M
   Eades, P
AF Meidiana, Amyra
   Hong, Seok-Hee
   Cai, Shijun
   Torkel, Marnijati
   Eades, Peter
TI SubLinearForce: Fully Sublinear-Time Force Computation for Large Complex
   Graph Drawing
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Force; Runtime; Measurement; Resistance; Approximation algorithms;
   Springs; Scalability; Graph drawing; force-directed algorithms;
   sublinear-time algorithms
ID SPARSIFICATION; ALGORITHM
AB Recent works in graph visualization attempt to reduce the runtime of repulsion force computation of force-directed algorithms using sampling. However, they fail to reduce the runtime for attraction force computation to sublinear in the number of edges. We present the SubLinearForce framework for a fully sublinear-time force computation algorithm for drawing large complex graphs. More precisely, we present new sublinear-time algorithms for the attraction force computation of force-directed algorithms. We then integrate them with sublinear-time repulsion force computation to give a fully sublinear-time force computation. Extensive experiments show that our algorithms compute layouts on average 80% faster than the existing linear-time force computation algorithm, while obtaining significantly better quality metrics such as edge crossing and shape-based metrics.
C1 [Meidiana, Amyra; Hong, Seok-Hee; Cai, Shijun; Torkel, Marnijati; Eades, Peter] Univ Sydney, Sydney, NSW 2006, Australia.
C3 University of Sydney
RP Meidiana, A (corresponding author), Univ Sydney, Sydney, NSW 2006, Australia.
EM amyra.meidiana@sydney.edu.au; seokhee.hong@sydney.edu.au;
   shijun.cai@sydney.edu.au; marnijati.torkel@sydney.edu.au;
   peter.eades@sydney.edu.au
FU ARC (Australian Research Council) DP (Discovery Project) [DP180102553]
FX This work was supported by ARC (Australian Research Council) DP
   (Discovery Project) under grant DP180102553.
CR Nguyen A, 2017, IEEE PAC VIS SYMP, P21, DOI 10.1109/PACIFICVIS.2017.8031574
   Archambault D, 2007, IEEE T VIS COMPUT GR, V13, P305, DOI 10.1109/TVCG.2007.46
   Arleo A, 2016, LECT NOTES COMPUT SC, V9801, P3, DOI 10.1007/978-3-319-50106-2_1
   Auber D., 2017, Encyclopedia of Social Network Analysis and Mining, P1, DOI [DOI 10.1007/978-1-4614-7163-9315-1, 10.1007/978-1-4614-7163-9_315-1, DOI 10.1007/978-1-4614-7163-9_315-1]
   BARNES J, 1986, NATURE, V324, P446, DOI 10.1038/324446a0
   Battista G. D., 1998, Graph Draw- ing: Algorithms for the Visualization of Graphs
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Brandes U., 2016, Encyclopedia of Algorithms, P768
   Eades Peter, 2018, Graph Drawing and Network Visualization. 25th International Symposium, GD 2017. Revised Selected Papers: LNCS 10692, P272, DOI 10.1007/978-3-319-73915-1_22
   Eades Peter, 1984, Congr Numer, V42, P149
   Eades Peter., 1991, Drawing Free Trees
   Eades S., 2017, J Graph Algorithms Appl, V21, P29, DOI DOI 10.7155/JGAA.00405
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   Kobourov SG, 2012, Arxiv, DOI [arXiv:1201.3011, 10.48550/arXiv.1201.3011]
   Gajer P., 2000, INT S GRAPH DRAW, P222, DOI [10.5555/647552.729406, DOI 10.5555/647552.729406]
   Gansner ER, 2004, LECT NOTES COMPUT SC, V3383, P239
   Gove R, 2019, COMPUT GRAPH FORUM, V38, P739, DOI 10.1111/cgf.13724
   Gove R, 2019, SYMP LARG DATA ANAL, P1, DOI [10.1109/LDAV48142.2019.8944364, 10.1109/ldav48142.2019.8944364]
   Hachul S, 2004, LECT NOTES COMPUT SC, V3383, P285
   Hagberg A., 2008, P 7 PYTH SCI C
   Hong S.-H., 2020, P IEEE PAC VIS S, P146
   Hong SH, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1843, DOI 10.1145/3341105.3373976
   Hong SH, 2019, LECT NOTES COMPUT SC, V11904, P139, DOI 10.1007/978-3-030-35802-0_11
   Hong SH, 2018, IEEE PAC VIS SYMP, P11, DOI 10.1109/PacificVis.2018.00011
   Hu J., 2019, P COMPL NETW, P216
   Hu Yifan, 2005, Mathematica J., V10, P37
   Jaccard P., 1912, New Phytologist, V11, P37, DOI DOI 10.1111/J.1469-8137.1912.TB05611.X
   KAMADA T, 1989, INFORM PROCESS LETT, V31, P7, DOI 10.1016/0020-0190(89)90102-6
   Leskovec J., 2006, P 12 ACM SIGKDD INT, P631
   Meidiana A, 2021, IEEE PAC VIS SYMP, P166, DOI 10.1109/PacificVis52677.2021.00030
   Meidiana A, 2021, IEEE PAC VIS SYMP, P146, DOI 10.1109/PacificVis52677.2021.00027
   Meidiana A, 2019, SYMP LARG DATA ANAL, P73, DOI [10.1109/LDAV48142.2019.8944358, 10.1109/ldav48142.2019.8944358]
   Meyerhenke H, 2015, LECT NOTES COMPUT SC, V9411, P30, DOI 10.1007/978-3-319-27261-0_3
   Ortmann M, 2016, LECT NOTES COMPUT SC, V9801, P18, DOI 10.1007/978-3-319-50106-2_2
   Quigley A., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P197
   Spielman DA, 2007, ANN IEEE SYMP FOUND, P29, DOI 10.1109/FOCS.2007.56
   Spielman DA, 2011, SIAM J COMPUT, V40, P1913, DOI 10.1137/080734029
   Spielman DA, 2011, SIAM J COMPUT, V40, P981, DOI 10.1137/08074489X
   SUGIYAMA K, 1995, J VISUAL LANG COMPUT, V6, P217, DOI 10.1006/jvlc.1995.1013
   Tamassia R., 2013, Handbook of graph drawing and visualization
   Tutte W.T., 1963, Proc. Lond. Math. Soc, Vs3-13, P743, DOI DOI 10.1112/PLMS/S3-13.1.743
   van Ham F, 2008, COMPUT GRAPH FORUM, V27, P975, DOI 10.1111/j.1467-8659.2008.01232.x
   WALKER AJ, 1974, ELECTRON LETT, V10, P127, DOI 10.1049/el:19740097
   Walshaw C., 2001, Graph Drawing. 8th International Symposium, GD 2000. Proceedings (Lecture Notes in Computer Science Vol.1984), P171
   Wu YH, 2017, IEEE T VIS COMPUT GR, V23, P401, DOI 10.1109/TVCG.2016.2598867
   Zheng JX, 2019, IEEE T VIS COMPUT GR, V25, P2738, DOI 10.1109/TVCG.2018.2859997
NR 46
TC 0
Z9 0
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3386
EP 3399
DI 10.1109/TVCG.2022.3233287
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700018
DA 2024-11-06
ER

PT J
AU Ruddle, RA
   Cheshire, J
   Fernstad, SJ
AF Ruddle, Roy A.
   Cheshire, James
   Fernstad, Sara Johansson
TI Tasks and Visualizations Used for Data Profiling: A Survey and Interview
   Study
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Task analysis; Data integrity; Interviews;
   Visualization; Bars; Industries; Data profiling; data quality; survey;
   interview
ID DATA QUALITY ASSESSMENT; VISUAL ANALYTICS
AB The use of good-quality data to inform decision making is entirely dependent on robust processes to ensure it is fit for purpose. Such processes vary between organisations, and between those tasked with designing and following them. In this article we report on a survey of 53 data analysts from many industry sectors, 24 of whom also participated in in-depth interviews, about computational and visual methods for characterizing data and investigating data quality. The paper makes contributions in two key areas. The first is to data science fundamentals, because our lists of data profiling tasks and visualization techniques are more comprehensive than those published elsewhere. The second concerns the application question "what does good profiling look like to those who routinely perform it?", which we answer by highlighting the diversity of profiling tasks, unusual practice and exemplars of visualization, and recommendations about formalizing processes and creating rulebooks.
C1 [Ruddle, Roy A.] Univ Leeds, Leeds LS2 9JT, England.
   [Cheshire, James] UCL, London LS2 9JT, England.
   [Fernstad, Sara Johansson] Newcastle Univ, Newcastle Upon Tyne NE1 7RU, England.
C3 University of Leeds; University of London; University College London;
   Newcastle University - UK
RP Ruddle, RA (corresponding author), Univ Leeds, Leeds LS2 9JT, England.
EM R.A.Ruddle@leeds.ac.uk; james.cheshire@ucl.ac.uk;
   sara.fernstad@newcastle.ac.uk
OI Johansson Fernstad, Sara/0000-0003-4518-5144
FU Alan Turing Institute
FX This research was supported by the Alan Turing Institute.
CR Abedjan Z, 2015, VLDB J, V24, P557, DOI 10.1007/s00778-015-0389-y
   Alspaugh S, 2019, IEEE T VIS COMPUT GR, V25, P22, DOI 10.1109/TVCG.2018.2865040
   ANSCOMBE FJ, 1973, AM STAT, V27, P17, DOI 10.2307/2682899
   Arbesser C, 2017, IEEE T VIS COMPUT GR, V23, P641, DOI 10.1109/TVCG.2016.2598592
   Batch A, 2018, IEEE T VIS COMPUT GR, V24, P278, DOI 10.1109/TVCG.2017.2743990
   Battle L, 2019, COMPUT GRAPH FORUM, V38, P145, DOI 10.1111/cgf.13678
   Bigelow A., 2020, IEEE Trans. Vis. Comput. Graph., V27, P1503
   Brehmer M, 2013, IEEE T VIS COMPUT GR, V19, P2376, DOI 10.1109/TVCG.2013.124
   Cashman D, 2019, COMPUT GRAPH FORUM, V38, P185, DOI 10.1111/cgf.13681
   Crisan A, 2021, IEEE T VIS COMPUT GR, V27, P1860, DOI 10.1109/TVCG.2020.3030340
   D. V. Society, 2021, Data visualization state of the industry survey
   Dimara E, 2022, IEEE T VIS COMPUT GR, V28, P4101, DOI 10.1109/TVCG.2021.3074023
   Eaton C, 2005, LECT NOTES COMPUT SC, V3585, P861, DOI 10.1007/11555261_68
   Estiri Hossein, 2016, AMIA Jt Summits Transl Sci Proc, V2016, P60
   Fernstad SJ, 2019, INFORM VISUAL, V18, P230, DOI 10.1177/1473871618785387
   gartner, 2022, Data preparation tools reviews and ratings
   Gschwandtner T., 2014, P 14 INT C KNOWL TEC, P1
   Gschwandtner T, 2018, IEEE PAC VIS SYMP, P205, DOI 10.1109/PacificVis.2018.00034
   Hynes N., 2017, P 31 C NEUR INF PROC
   Kandel S, 2012, PROCEEDINGS OF THE INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, P547, DOI 10.1145/2254556.2254659
   Kandel S, 2012, IEEE T VIS COMPUT GR, V18, P2917, DOI 10.1109/TVCG.2012.219
   Little R. J., 2019, STAT ANAL MISSING DA, V793
   Liu JL, 2020, IEEE T VIS COMPUT GR, V26, P66, DOI 10.1109/TVCG.2019.2934593
   Liu SX, 2018, VIS INFORM, V2, P191, DOI 10.1016/j.visinf.2018.12.001
   Matejka J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1290, DOI 10.1145/3025453.3025912
   Menon S., 2019, Market guide for data preparation tools
   Mosca A., 2019, P 21 EUR C VIS, P73
   Naumann F, 2013, SIGMOD REC, V42, P40, DOI 10.1145/2590989.2590995
   Milani AMP, 2020, INFORM VISUAL, V19, P273, DOI 10.1177/1473871619896101
   Ruddle RA, 2019, HEALTHINF: PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 5: HEALTHINF, P230, DOI 10.5220/0007354802300238
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Shome A., 2022, P IEEE ACM 1 INT C A, P205, DOI [10.1145/3522664.3528621, DOI 10.1145/3522664.3528621]
   Song H, 2019, IEEE T VIS COMPUT GR, V25, P914, DOI 10.1109/TVCG.2018.2864914
   Weiskopf NG, 2013, J AM MED INFORM ASSN, V20, P144, DOI 10.1136/amiajnl-2011-000681
   Wood J, 2019, IEEE T VIS COMPUT GR, V25, P759, DOI 10.1109/TVCG.2018.2864836
   Zernichow Bjorn Marius, 2017, On the Move to Meaningful Internet Systems. OTM 2017 Conferences. Confederated International Conferences: CoopIS, C&TC, and ODBASE 2017. Proceedings: LNCS 10574, P480, DOI 10.1007/978-3-319-69459-7_32
NR 36
TC 1
Z9 1
U1 0
U2 0
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3400
EP 3412
DI 10.1109/TVCG.2023.3234337
PG 13
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700028
PM 37018563
OA Green Published, Green Accepted
DA 2024-11-06
ER

PT J
AU Zhao, TM
   Gao, P
   Tian, T
   Ma, JY
   Tian, JW
AF Zhao, Tianming
   Gao, Peng
   Tian, Tian
   Ma, Jiayi
   Tian, Jinwen
TI From Noise Addition to Denoising: A Self-Variation Capture Network for
   Point Cloud Optimization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Point cloud compression; Noise reduction; Noise measurement; Manifolds;
   Optimization; Three-dimensional displays; Surface cleaning; Commonality
   capture; noise perturbation; point clouds denoising; self-variation
AB Point clouds obtained from 3D scanners are often noisy and cannot be directly used for subsequent high-level tasks. In this article, we propose a novel point cloud optimization method capable of denoising and homogenizing point clouds. Our idea is based on the assumption that the noise is generally much smaller than the effective signal. We perform noise perturbation on the noisy point cloud to get a new noisy point cloud, called self-variation point cloud. The noisy point cloud and self-variation point cloud have different noise distribution, but the same point cloud distribution. We compute the potential commonality between two noisy point clouds to obtain a clean point cloud. To implement our idea, we propose a Self-Variation Capture Network (SVCNet). We perturb the point cloud features in the latent space to obtain self-variation feature vectors, and capture the commonality between two noisy feature vectors through the feature aggregation and averaging. In addition, an edge constraint module is introduced to suppress low-pass effects during denoising. Our denoising method does not take into account the noise characteristics, and can filter the drift noise located on the underlying surface, resulting in a uniform distribution of the generated point cloud. The experimental results show that our algorithm outperforms the current state-of-the-art algorithms, especially in generating more uniform point clouds. In addition, extended experiments demonstrate the potential of our algorithm for point clouds upsampling.
C1 [Zhao, Tianming; Gao, Peng; Tian, Tian; Tian, Jinwen] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Multispectral Informat Intelligent Pr, Wuhan 430074, Peoples R China.
   [Ma, Jiayi] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
C3 Huazhong University of Science & Technology; Wuhan University
RP Tian, T (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Multispectral Informat Intelligent Pr, Wuhan 430074, Peoples R China.
EM tming@hust.edu.cn; gaopengde@hust.edu.cn; ttian@hust.edu.cn;
   jyma2010@gmail.com; jwtian@mail.hust.edu.cn
RI Tian, Tian/AAO-6980-2021; Ma, Jiayi/Y-2470-2019
OI Tian, Tian/0000-0003-0148-4900; Ma, Jiayi/0000-0003-3264-3265
FU National Natural Science Foundation of China [42071339, 62276192];
   National Key Laboratory Fund [6142113210310]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 42071339 and 62276192 and in part by
   National Key Laboratory Fund under Grant 6142113210310.
CR Avron H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1857907.1857911
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Cazals F, 2005, COMPUT AIDED GEOM D, V22, P121, DOI 10.1016/j.cagd.2004.09.004
   Cazals F, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1404582
   Chen HL, 2023, IEEE T PATTERN ANAL, V45, P2913, DOI 10.1109/TPAMI.2022.3175183
   Chen HH, 2022, INT J COMPUT VISION, V130, P615, DOI 10.1007/s11263-021-01564-7
   Cignoni P., 2008, COMPUTING, V1, P129, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Digne J, 2017, IMAGE PROCESS ON LIN, V7, P278, DOI 10.5201/ipol.2017.179
   Dinesh C, 2018, Arxiv, DOI arXiv:1812.07711
   Dinesh C, 2018, Arxiv, DOI arXiv:1804.10831
   Duan CJ, 2019, INT CONF ACOUST SPEE, P8553, DOI [10.1109/ICASSP.2019.8682812, 10.1109/icassp.2019.8682812]
   Fleishman S, 2003, ACM T GRAPHIC, V22, P950, DOI 10.1145/882262.882368
   Gao W., 2018, P IEEE 4 INT C MULT, P1
   Gschwandtner Michael, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P199, DOI 10.1007/978-3-642-24031-7_20
   Guennebaud G, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239474
   HEISLEY DD, 1991, J CONSUM RES, V18, P257, DOI 10.1086/209258
   Hermosilla P, 2019, IEEE I CONF COMP VIS, P52, DOI 10.1109/ICCV.2019.00014
   Hu W, 2020, IEEE T SIGNAL PROCES, V68, P2841, DOI 10.1109/TSP.2020.2978617
   Huang H., IEEETrans. Visualization Comput. Graph., DOI [10.1109/TVCG.2021.3137912.3, DOI 10.1109/TVCG.2021.3137912.3]
   Huang H, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2421636.2421645
   Li RH, 2021, PROC CVPR IEEE, P344, DOI 10.1109/CVPR46437.2021.00041
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Luo ST, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1330, DOI 10.1145/3394171.3413727
   Luo W., 2021, P IEEE CVF INT C COM, P4583
   Mattei E, 2017, COMPUT GRAPH FORUM, V36, P123, DOI 10.1111/cgf.13068
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Öztireli AC, 2009, COMPUT GRAPH FORUM, V28, P493, DOI 10.1111/j.1467-8659.2009.01388.x
   Pistilli F, 2021, IEEE J-STSP, V15, P402, DOI 10.1109/JSTSP.2020.3047471
   Rakotosaona MJ, 2020, COMPUT GRAPH FORUM, V39, P185, DOI 10.1111/cgf.13753
   Schoenenberger Y, 2015, 3DTV CONF
   Sun YJ, 2015, COMPUT AIDED GEOM D, V35-36, P2, DOI 10.1016/j.cagd.2015.03.011
   Vaswani A, 2023, Arxiv, DOI arXiv:1706.03762
   Wang PS, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980232
   Wang YF, 2019, PROC CVPR IEEE, P5951, DOI 10.1109/CVPR.2019.00611
   Wei MQ, 2023, IEEE T VIS COMPUT GR, V29, P1357, DOI 10.1109/TVCG.2021.3113463
   Xu LL, 2015, GRAPH MODELS, V82, P160, DOI 10.1016/j.gmod.2015.06.012
   Yu LQ, 2018, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2018.00295
   Yu LQ, 2018, LECT NOTES COMPUT SC, V11211, P398, DOI 10.1007/978-3-030-01234-2_24
   Zeng J, 2020, IEEE T IMAGE PROCESS, V29, P3474, DOI 10.1109/TIP.2019.2961429
   Zhang DB, 2021, IEEE T VIS COMPUT GR, V27, P2015, DOI 10.1109/TVCG.2020.3027069
   Zhang Z., IEEE Trans. VisualizationComput. Graph., DOI [10.1109/TVCG.2022.3148245.4, DOI 10.1109/TVCG.2022.3148245.4]
NR 44
TC 3
Z9 3
U1 10
U2 17
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3413
EP 3426
DI 10.1109/TVCG.2022.3231680
PG 14
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700069
PM 37015380
DA 2024-11-06
ER

PT J
AU Burns, A
   Lee, C
   On, T
   Xiong, CY
   Peck, E
   Mahyar, N
AF Burns, Alyxander
   Lee, Christiana
   On, Thai
   Xiong, Cindy
   Peck, Evan
   Mahyar, Narges
TI From Invisible to Visible: Impacts of Metadata in Communicative Data
   Visualization
SO IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS
LA English
DT Article
DE Data visualization; Metadata; Encoding; Soft sensors; Stakeholders;
   Organizations; Data mining; trust; transparency; understanding;
   visualization
ID TRANSPARENCY; TRUST; PROVENANCE; KNOWLEDGE; SCIENCE
AB Leaving the context of visualizations invisible can have negative impacts on understanding and transparency. While common wisdom suggests that recontextualizing visualizations with metadata (e.g., disclosing the data source or instructions for decoding the visualizations' encoding) may counter these effects, the impact remains largely unknown. To fill this gap, we conducted two experiments. In Experiment 1, we explored how chart type, topic, and user goal impacted which categories of metadata participants deemed most relevant. We presented 64 participants with four real-world visualizations. For each visualization, participants were given four goals and selected the type of metadata they most wanted from a set of 18 types. Our results indicated that participants were most interested in metadata which explained the visualization's encoding for goals related to understanding and metadata about the source of the data for assessing trustworthiness. In Experiment 2, we explored how these two types of metadata impact transparency, trustworthiness and persuasiveness, information relevance, and understanding. We asked 144 participants to explain the main message of two pairs of visualizations (one with metadata and one without); rate them on scales of transparency and relevance; and then predict the likelihood that they were selected for a presentation to policymakers. Our results suggested that visualizations with metadata were perceived as more thorough than those without metadata, but similarly relevant, accurate, clear, and complete. Additionally, we found that metadata did not impact the accuracy of the information extracted from visualizations, but may have influenced which information participants remembered as important or interesting.
C1 [Burns, Alyxander] Mt Holyoke Coll, South Hadley, MA 01075 USA.
   [Lee, Christiana; On, Thai; Xiong, Cindy; Mahyar, Narges] Univ Massachusetts, Amherst, MA 01003 USA.
   [Peck, Evan] Bucknell Univ, Lewisburg, PA 17837 USA.
C3 Mount Holyoke College; University of Massachusetts System; University of
   Massachusetts Amherst; Bucknell University
RP Burns, A (corresponding author), Mt Holyoke Coll, South Hadley, MA 01075 USA.
EM ajburns@mtholyoke.edu; christianale@umass.edu; ton@umass.edu;
   cindy.xiong@cs.umass.edu; evan.peck@bucknell.edu; nmahyar@cs.umass.edu
OI Burns, Alyxander/0000-0002-2784-3011; Xiong Bearfield,
   Cindy/0000-0002-1451-4083
CR Adar E, 2021, IEEE T VIS COMPUT GR, V27, P946, DOI 10.1109/TVCG.2020.3030375
   Alarcon GM, 2020, SYSTEMS-BASEL, V8, DOI 10.3390/systems8030028
   Alharbi M, 2019, COMPUTERS, V8, DOI 10.3390/computers8010017
   [Anonymous], 2022, Prolific
   [Anonymous], 2022, Qualtrics
   [Anonymous], 1998, Proceedings of the Survey Research Methods Section
   Bach B, 2017, IEEE COMPUT GRAPH, V37, P6, DOI 10.1109/MCG.2017.33
   Bateman S, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2573
   Bates D., 2015, Convergence, V12, P2, DOI DOI 10.18637/JSS.V067.I01
   Battle L, 2018, HILDA'18: PROCEEDINGS OF THE WORKSHOP ON HUMAN-IN-THE-LOOP DATA ANALYTICS, DOI 10.1145/3209900.3209901
   Ben Wasike, 2022, J COMPUT-MEDIAT COMM, V27, DOI 10.1093/jcmc/zmab024
   Borenstein M., 2021, Introduction to Meta-Analysis, DOI 10.1002/9781119558378
   Borkin MA, 2016, IEEE T VIS COMPUT GR, V22, P519, DOI 10.1109/TVCG.2015.2467732
   Börner K, 2016, INFORM VISUAL, V15, P198, DOI 10.1177/1473871615594652
   Davis SB, 2021, INTERDISCIPL SCI REV, V46, P522, DOI 10.1080/03080188.2021.1872874
   Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01
   Buneman P, 2001, LECT NOTES COMPUT SC, V1973, P316
   Burgess L. C., 2016, Building Trust in Information, P81
   Burns A, 2021, 2021 IEEE WORKSHOP ON VISUALIZATION FOR SOCIAL GOOD (VIS4GOOD 2021), P11, DOI 10.1109/VIS4Good54225.2021.00008
   Burns A, 2020, 2020 IEEE WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2020), P19, DOI 10.1109/BELIV51497.2020.00010
   Burns A, 2022, IEEE T VIS COMPUT GR, V28, P4515, DOI 10.1109/TVCG.2021.3092680
   Cao N., 2016, Overview of Text Visualization Techniques, P11
   Correll M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376222
   Costante E., 2011, 2011 Workshop on Socio-Technical Aspects in Security and Trust, P52, DOI 10.1109/STAST.2011.6059256
   D'Ignazio C, 2020, STRONG IDEAS SERIES, P97
   Dork Marian, 2013, CHI 13 EXTENDED ABST, P2189, DOI [10.1145/2468356.2468739, DOI 10.1145/2468356.2468739, DOI 10.1145/2468356.24687392,9]
   Dragicevic P, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300295
   Elhamdadi H, 2022, 2022 IEEE 9TH WORKSHOP ON EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES TO VISUALIZATION (BELIV 2022), P85, DOI 10.1109/BELIV57783.2022.00014
   Elliott KC, 2014, ENVIRON HEALTH PERSP, V122, P647, DOI 10.1289/ehp.1408107
   Figueiras A, 2014, IEEE INT CONF INF VI, P46, DOI 10.1109/IV.2014.79
   Finch H., 2005, Methodol.: Eur. J. Res. Methods Behav. Social Sci., V1
   Foote MQ, 2011, EDUC STUD MATH, V78, P45, DOI 10.1007/s10649-011-9309-2
   Frank Rebecca D., 2017, Proceedings of the Association for Information Science and Technology, V54, DOI 10.1002/pra2.2017.14505401012
   Fyfe P, 2016, VIC PERIOD REV, V49, P546, DOI 10.1353/vpr.2016.0039
   Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723
   Greenland S, 2016, EUR J EPIDEMIOL, V31, P337, DOI 10.1007/s10654-016-0149-3
   Gunn Bill., 2019, ESSENTIAL ESSAYS VOL, V1, P257
   Hall CC, 2007, ORGAN BEHAV HUM DEC, V103, P277, DOI 10.1016/j.obhdp.2007.01.003
   HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066
   Haroz S, 2018, 2018 IEEE EVALUATION AND BEYOND - METHODOLOGICAL APPROACHES FOR VISUALIZATION (BELIV), P46, DOI 10.1109/BELIV.2018.8634427
   Herve M., 2020, Package 'RVAideMemoire', P0
   Holmes Andrew Gary Darwin., 2020, SHANLAX INT J ED, V8, P1, DOI DOI 10.34293/EDUCATION.V8I4.3232
   Horvath R, 2016, APPL ECON, V48, P5625, DOI 10.1080/00036846.2016.1181833
   Hullman J, 2020, IEEE T VIS COMPUT GR, V26, P130, DOI 10.1109/TVCG.2019.2934287
   Hullman J, 2011, IEEE T VIS COMPUT GR, V17, P2231, DOI 10.1109/TVCG.2011.255
   Jach HK, 2022, J EXP PSYCHOL GEN, V151, P934, DOI 10.1037/xge0001109
   Jaimes Luis G., 2013, Design, User Experience, and Usability. User Experience in Novel Technological Environments. Second International Conference, DUXU 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8014, P520, DOI 10.1007/978-3-642-39238-2_57
   Kelton K, 2008, J AM SOC INF SCI TEC, V59, P363, DOI 10.1002/asi.20722
   Kennedy Helen, 2016, First Monday, V21, DOI 10.5210/fm.v21i11.6389
   Kiernan M, 2018, HEALTH PSYCHOL, V37, P782, DOI 10.1037/hea0000631
   Kim Y.-S., 2019, P CHI C HUM FACT COM, P1
   Kim YS, 2018, IEEE T VIS COMPUT GR, V24, P760, DOI 10.1109/TVCG.2017.2745240
   Kizilcec RF, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2390, DOI 10.1145/2858036.2858402
   Kong HK, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300576
   LAMAL PA, 1990, J SOC BEHAV PERS, V5, P31
   Lee C, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445211
   Lee S, 2016, IEEE T VIS COMPUT GR, V22, P499, DOI 10.1109/TVCG.2015.2467195
   Li N, 2018, JCOM-J SCI COMMUN, V17, DOI 10.22323/2.17020206
   Lin XL, 2016, COMPUT HUM BEHAV, V63, P264, DOI 10.1016/j.chb.2016.05.002
   Luo Y, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01541
   Mack K, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445412
   Mayr E., 2019, EUROVIS WORKSHOP TRU, P5, DOI [DOI 10.2312/TRVIS.20191187, 10.2312/TRVIS.20191187, DOI 10.2312/TRVIS.201911872]
   Munzel A, 2016, J RETAIL CONSUM SERV, V32, P96, DOI 10.1016/j.jretconser.2016.06.002
   Munzner T., 2014, Visualization analysis and design, DOI 10.1201/b17511
   Nightingale Virginia., 2011, The Handbook of Media Audiences
   OReilly J., 2009, P INT BLAIS US C
   Ottley A., 2019, P 2019 EUR IEEE VGTC, DOI DOI 10.2312/EVS.20191181
   Padilla L., 2021, Uncertainty Visualization, P1, DOI [DOI 10.1002/9781118445112.STAT08296, 10.1002/ 9781118445112.stat08296]
   Peck EM, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300474
   Pirson M, 2011, ORGAN SCI, V22, P1087, DOI 10.1287/orsc.1100.0581
   Pu X., 2021, P CHI C HUM FACT COM, P1
   Quispel A, 2016, INFORM VISUAL, V15, P238, DOI 10.1177/1473871615606478
   Ragan ED, 2016, IEEE T VIS COMPUT GR, V22, P31, DOI 10.1109/TVCG.2015.2467551
   Romano A, 2020, HEALTH ECON, V29, P1482, DOI 10.1002/hec.4143
   Rowe WendyE., 2014, SAGE ENCY ACTION RES
   Ruchikachorn P, 2015, IEEE T VIS COMPUT GR, V21, P1028, DOI 10.1109/TVCG.2015.2413786
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Salem M., 2015, Emerg. Policy Ethics Hum.-Robot Interaction
   Savin-Baden M., 2013, Qualitative Research: The essential guide to theory and practice
   Schnackenberg AK, 2016, J MANAGE, V42, P1784, DOI 10.1177/0149206314525202
   Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179
   Setlur V, 2022, Arxiv, DOI arXiv:2203.08420
   Sigma Awards, Rough justice: How police are failing survivors of sexual assault
   Sigma Awards, Who gets to breathe clean air in new delhi?
   Sigma Awards, Land-grab universities: How expropriated indig- enous land became the foundation of the land-grant university system
   Sigma Awards, The COVID Tracking Project at The Atlantic
   Sigma Awards, Mapping makoko
   Sigma Awards, About the sigma awards
   Simmhan YL, 2005, SIGMOD REC, V34, P31, DOI 10.1145/1084805.1084812
   Sohn D, 2019, INT J ADVERT, V38, P824, DOI 10.1080/02650487.2018.1536507
   Steve H., 2022, Email communication
   Stokes C., 2021, P WORKSH EXPL OPP CH
   TAYLOR R, 1990, J DIAGN MED SONOG, V6, P219, DOI 10.1177/875647939000600404
   Thomas J, 2009, INFORM VISUAL, V8, P309, DOI 10.1057/ivs.2009.26
   Thompson CG, 2017, BASIC APPL SOC PSYCH, V39, P81, DOI 10.1080/01973533.2016.1277529
   van der Cruijsen CAB, 2010, J ECON PSYCHOL, V31, P388, DOI 10.1016/j.joep.2010.01.007
   Wang QW, 2019, IEEE T VIS COMPUT GR, V25, P779, DOI 10.1109/TVCG.2018.2865232
   Wang ZZ, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376271
   Warne R.T., 2014, PRACTICAL ASSESSMENT, V19, P2, DOI DOI 10.7275/SM63-7H70
   Windhager F, 2019, IEEE T VIS COMPUT GR, V25, P2311, DOI 10.1109/TVCG.2018.2830759
   Xiong C., 2019, P 1 EUROVIS WORKSH T, P19
   Xiong C, 2020, IEEE T VIS COMPUT GR, V26, P3051, DOI 10.1109/TVCG.2019.2917689
   Xu K, 2020, COMPUT GRAPH FORUM, V39, P757, DOI 10.1111/cgf.14035
   Yakel E., 2013, International Journal of Digital Curation, V8, P143, DOI DOI 10.2218/IJDC.V8I1.251
NR 104
TC 5
Z9 5
U1 1
U2 1
PU IEEE COMPUTER SOC
PI LOS ALAMITOS
PA 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA
SN 1077-2626
EI 1941-0506
J9 IEEE T VIS COMPUT GR
JI IEEE Trans. Vis. Comput. Graph.
PD JUL
PY 2024
VL 30
IS 7
BP 3427
EP 3443
DI 10.1109/TVCG.2022.3231716
PG 17
WC Computer Science, Software Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XA4B5
UT WOS:001258936700066
PM 37015379
DA 2024-11-06
ER

EF