[
  {
    "file_id": 1,
    "block_id": 1,
    "PT": "J",
    "AU": [
      "Jiang, YR",
      "Chen, SY",
      "Fu, HB",
      "Gao, L"
    ],
    "AF": [
      "Jiang, Yue-Ren",
      "Chen, Shu-Yu",
      "Fu, Hongbo",
      "Gao, Lin"
    ],
    "TI": "Identity-Aware and Shape-Aware Propagation of Face Editing in Videos",
    "SO": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS",
    "LA": "English",
    "DT": "Article",
    "CT": "empty",
    "CY": "empty",
    "CL": "empty",
    "DE": [
      "Videos",
      "Shape",
      "Faces",
      "Three-dimensional displays",
      "Codes",
      "Aerospace electronics",
      "Semantics",
      "Editing propagation",
      "face editing",
      "video editing"
    ],
    "ID": [
      "MANIPULATION",
      "IMAGE"
    ],
    "AB": "The development of deep generative models has inspired various facial image editing methods, but many of them are difficult to be directly applied to video editing due to various challenges ranging from imposing 3D constraints, preserving identity consistency, ensuring temporal coherence, etc. To address these challenges, we propose a new framework operating on the StyleGAN2 latent space for identity-aware and shape-aware edit propagation on face videos. In order to reduce the difficulties of maintaining the identity, keeping the original 3D motion, and avoiding shape distortions, we disentangle the StyleGAN2 latent vectors of human face video frames to decouple the appearance, shape, expression, and motion from identity. An edit encoding module is used to map a sequence of image frames to continuous latent codes with 3D parametric control and is trained in a self-supervised manner with identity loss and triple shape losses. Our model supports propagation of edits in various forms: I. direct appearance editing on a specific keyframe, II. implicit editing of face shape via a given reference image, and III. existing latent-based semantic edits. Experiments show that our method works well for various forms of videos in the wild and outperforms an animation-based approach and the recent deep generative techniques.",
    "C1": "[Jiang, Yue-Ren; Chen, Shu-Yu; Gao, Lin] Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100045, Peoples R China. [Jiang, Yue-Ren; Gao, Lin] Univ Chinese Acad Sci, Beijing 101408, Peoples R China. [Fu, Hongbo] City Univ Hong Kong, Sch Creat Media, Hong Kong, Peoples R China.",
    "C3": "Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; City University of Hong Kong",
    "RP": "Gao, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing Key Lab Mobile Comp & Pervas Device, Beijing 100045, Peoples R China.; Gao, L (corresponding author), Univ Chinese Acad Sci, Beijing 101408, Peoples R China.",
    "EM": "jiangyueren19s@ict.ac.cn; chenshuyu@ict.ac.cn; hongbofu@cityu.edu.hk; gaolin@ict.ac.cn",
    "RI": "empty",
    "OI": "FU, Hongbo/0000-0002-0284-726X",
    "FU": "National Natural Science Foundation of China [62102403, 61872440]; Beijing Municipal Natural Science Foundation for Distinguished Young Scholars [JQ21013]; China Postdoctoral Science Foundation [2022M713205]; Open Research Projects of Zhejiang Lab [2021KE0AB06]; Youth Innovation Promotion Association CAS; Centre for Applied Computing and Interactive Media (ACIM) of School of Creative Media, CityU",
    "FX": "This work was supported in part by the National Natural Science Foundation of China under Grants 62102403 and 61872440, in part by the Beijing Municipal Natural Science Foundation for Distinguished Young Scholars under Grant JQ21013, in part by China Postdoctoral Science Foundation under Grant 2022M713205, in part by the Open Research Projects of Zhejiang Lab under Grant 2021KE0AB06, in part by Youth Innovation Promotion Association CAS, and in part by the Centre for Applied Computing and Interactive Media (ACIM) of School of Creative Media, CityU.",
    "CR": [
      "Abdal R, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3447648",
      "Abdal R, 2020, PROC CVPR IEEE, P8293, DOI 10.1109/CVPR42600.2020.00832",
      "Alaluf Y, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459805"
    ],
    "NR": "74",
    "TC": "0",
    "Z9": "0",
    "U1": "1",
    "U2": "2",
    "PU": "IEEE COMPUTER SOC",
    "PI": "LOS ALAMITOS",
    "PA": "10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",
    "SN": "1077-2626",
    "EI": "1941-0506",
    "J9": "IEEE T VIS COMPUT GR",
    "JI": "IEEE Trans. Vis. Comput. Graph.",
    "PD": "JUL",
    "PY": "2024",
    "VL": "30",
    "IS": "7",
    "BP": "3444",
    "EP": "3456",
    "DI": "10.1109/TVCG.2023.3235364",
    "PG": "13",
    "WC": "Computer Science, Software Engineering",
    "WE": "Science Citation Index Expanded (SCI-EXPANDED)",
    "SC": "Computer Science",
    "GA": "XA4B5",
    "UT": "WOS:001258936700019",
    "PM": "37018564",
    "OA": "empty",
    "DA": "2024-11-06"
  },
  {
    "file_id": 1,
    "block_id": 2,
    "PT": "J",
    "AU": [
      "Choi, J",
      "Oh, HJ",
      "Lee, H",
      "Kim, S",
      "Kwon, SK",
      "Jeong, WK"
    ],
    "AF": [
      "Choi, JunYoung",
      "Oh, Hyun-Jic",
      "Lee, Hakjun",
      "Kim, Suyeon",
      "Kwon, Seok-Kyu",
      "Jeong, Won-Ki"
    ],
    "TI": "MitoVis: A Unified Visual Analytics System for End-to-End Neuronal Mitochondria Analysis",
    "SO": "IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS",
    "LA": "English",
    "DT": "Article",
    "CT": "empty",
    "CY": "empty",
    "CL": "empty",
    "DE": [
      "Data visualization",
      "Morphology",
      "Neurons",
      "Microscopy",
      "Dendrites (neurons)",
      "Deep learning",
      "Axons",
      "Biomedical and medical visualization"
    ],
    "ID": [
      "VISUALIZATION",
      "FISSION"
    ],
    "AB": "Neurons have a polarized structure, with dendrites and axons, and compartment-specific functions can be affected by the dwelling mitochondria. Recent studies have shown that the morphology of mitochondria is closely related to the functions of neurons and neurodegenerative diseases. However, the conventional mitochondria analysis workflow mainly relies on manual annotations and generic image-processing software. Moreover, even though there have been recent developments in automatic mitochondria analysis using deep learning, the application of existing methods in a daily analysis remains challenging because the performance of a pretrained deep learning model can vary depending on the target data, and there are always errors in inference time, requiring human proofreading. To address these issues, we introduce MitoVis, a novel visualization system for end-to-end data processing and an interactive analysis of the morphology of neuronal mitochondria. MitoVis introduces a novel active learning framework based on recent contrastive learning, which allows accurate fine-tuning of the neural network model. MitoVis also provides novel visual guides for interactive proofreading so that users can quickly identify and correct errors in the result with minimal effort. We demonstrate the usefulness and efficacy of the system via case studies conducted by neuroscientists. The results show that MitoVis achieved up to 13.3x faster total analysis time in the case study compared to the conventional manual analysis workflow.",
    "C1": "[Choi, JunYoung; Oh, Hyun-Jic; Lee, Hakjun; Jeong, Won-Ki] Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea. [Kim, Suyeon; Kwon, Seok-Kyu] Korea Inst Sci & Technol, Brain Sci Inst, Seoul 02792, South Korea.",
    "C3": "Korea University; Korea Institute of Science & Technology (KIST)",
    "RP": "Jeong, WK (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 02841, South Korea.",
    "EM": "juny0603@gmail.com; hyunjic0127@korea.ac.kr; hjlee0413@korea.ac.kr; imas3104@kist.re.kr; skkwon@kist.re.kr; wkjeong@korea.ac.kr",
    "RI": "choi, junyoung/T-4389-2019; Jeong, Won-Ki/F-8171-2011",
    "OI": ", hjoh/0000-0002-4599-151X; Jeong, Won-Ki/0000-0002-9393-6451; Kwon, Seok-Kyu/0000-0002-7280-9867; Choi, JunYoung/0000-0002-4255-4402",
    "FU": "Bio & Medical Technology Development Program of the National Research Foundation of Korea (NRF) - Ministry of Science and ICT (MSIT) [NRF-2019M3E5D2A01063819, NRF-2019M3E5D2A01063794]; Basic Science Research Program through the NRF - Ministry of Education [NRF-2021R1A6A1A13044830]; Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI) - Ministry of Health Welfare [HI18C0316]; ICT Creative Consilience program of the Institute for Information & communications Technology Planning& Evaluation (IITP) - MSIT [IITP-2023-2020-0-01819]; Korea Institute of Science and Technology (KIST) Institutional Program, Republic of Korea [2E31511]; Korea University Grant",
    "FX": "This work was supported in part by the Bio & Medical Technology Development Program of the National Research Foundation of Korea (NRF)funded by the Ministry of Science and ICT (MSIT) under Grants NRF-2019M3E5D2A01063819 and NRF-2019M3E5D2A01063794, in part by the Basic Science Research Program through the NRF funded by the Ministry of Education under Grant NRF-2021R1A6A1A13044830, in part by a grant from the Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI) funded by the Ministry of Health & Welfare under Grant HI18C0316, in part by the ICT Creative Consilience program under Grant IITP-2023-2020-0-01819 of the Institute for Information & communications Technology Planning& Evaluation (IITP) funded by MSIT, in part by the Korea Institute of Science and Technology (KIST) Institutional Program, Republic of Korea under Grant 2E31511, and in part by a Korea University Grant.",
    "CR": [
      "Agus M, 2019, COMPUT GRAPH FORUM, V38, P427, DOI 10.1111/cgf.13700",
      "[Anonymous], 2021, R LANG ENV STAT COMP",
      "Baek SH, 2017, J NEUROSCI, V37, P5099, DOI 10.1523/JNEUROSCI.2385-16.2017"
    ],
    "NR": "68",
    "TC": "0",
    "Z9": "0",
    "U1": "1",
    "U2": "1",
    "PU": "IEEE COMPUTER SOC",
    "PI": "LOS ALAMITOS",
    "PA": "10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA",
    "SN": "1077-2626",
    "EI": "1941-0506",
    "J9": "IEEE T VIS COMPUT GR",
    "JI": "IEEE Trans. Vis. Comput. Graph.",
    "PD": "JUL",
    "PY": "2024",
    "VL": "30",
    "IS": "7",
    "BP": "3457",
    "EP": "3473",
    "DI": "10.1109/TVCG.2022.3233548",
    "PG": "17",
    "WC": "Computer Science, Software Engineering",
    "WE": "Science Citation Index Expanded (SCI-EXPANDED)",
    "SC": "Computer Science",
    "GA": "XA4B5",
    "UT": "WOS:001258936700077",
    "PM": "empty",
    "OA": "empty",
    "DA": "2024-11-06"
  }
]